I0615 14:05:56.637063 29366 caffe.cpp:218] Using GPUs 3
I0615 14:05:56.674881 29366 caffe.cpp:223] GPU 3: Tesla K40m
I0615 14:05:57.027434 29366 solver.cpp:44] Initializing solver from parameters: 
base_lr: 0.01
display: 50
max_iter: 200000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 50000
snapshot: 10000
snapshot_prefix: "mobilenet/mobile_2"
solver_mode: GPU
device_id: 3
net: "/home/xingzhaolong/caffe_project/caffe_mobile/models/oxford/mobilenet/mobilenet_deploy.prototxt"
train_state {
  level: 0
  stage: ""
}
I0615 14:05:57.027819 29366 solver.cpp:87] Creating training net from net file: /home/xingzhaolong/caffe_project/caffe_mobile/models/oxford/mobilenet/mobilenet_deploy.prototxt
I0615 14:05:57.030488 29366 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/xingzhaolong/caffe_project/caffe_mobile/models/oxford/mobilenet/mobilenet_deploy.prototxt
I0615 14:05:57.030521 29366 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0615 14:05:57.030833 29366 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0615 14:05:57.030930 29366 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0615 14:05:57.031867 29366 net.cpp:51] Initializing net from parameters: 
name: "MOBILENET"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_file: "/home/xingzhaolong/caffe_project/caffe/models/caffe-oxford102/imagenet_mean.binaryproto"
  }
  image_data_param {
    source: "/home/xingzhaolong/caffe_project/caffe/models/caffe-oxford102/test.txt"
    batch_size: 50
    new_height: 256
    new_width: 256
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv1/bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1/scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2_1/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv1"
  top: "conv2_1/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 32
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv2_1/dw"
  top: "conv2_1/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_1/dw/scale"
  type: "Scale"
  bottom: "conv2_1/dw"
  top: "conv2_1/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_1/dw"
  type: "ReLU"
  bottom: "conv2_1/dw"
  top: "conv2_1/dw"
}
layer {
  name: "conv2_1/sep"
  type: "Convolution"
  bottom: "conv2_1/dw"
  top: "conv2_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv2_1/sep"
  top: "conv2_1/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_1/sep/scale"
  type: "Scale"
  bottom: "conv2_1/sep"
  top: "conv2_1/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_1/sep"
  type: "ReLU"
  bottom: "conv2_1/sep"
  top: "conv2_1/sep"
}
layer {
  name: "conv2_2/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv2_1/sep"
  top: "conv2_2/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 64
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv2_2/dw"
  top: "conv2_2/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_2/dw/scale"
  type: "Scale"
  bottom: "conv2_2/dw"
  top: "conv2_2/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_2/dw"
  type: "ReLU"
  bottom: "conv2_2/dw"
  top: "conv2_2/dw"
}
layer {
  name: "conv2_2/sep"
  type: "Convolution"
  bottom: "conv2_2/dw"
  top: "conv2_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv2_2/sep"
  top: "conv2_2/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_2/sep/scale"
  type: "Scale"
  bottom: "conv2_2/sep"
  top: "conv2_2/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_2/sep"
  type: "ReLU"
  bottom: "conv2_2/sep"
  top: "conv2_2/sep"
}
layer {
  name: "conv3_1/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv2_2/sep"
  top: "conv3_1/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv3_1/dw"
  top: "conv3_1/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_1/dw/scale"
  type: "Scale"
  bottom: "conv3_1/dw"
  top: "conv3_1/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_1/dw"
  type: "ReLU"
  bottom: "conv3_1/dw"
  top: "conv3_1/dw"
}
layer {
  name: "conv3_1/sep"
  type: "Convolution"
  bottom: "conv3_1/dw"
  top: "conv3_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv3_1/sep"
  top: "conv3_1/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_1/sep/scale"
  type: "Scale"
  bottom: "conv3_1/sep"
  top: "conv3_1/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_1/sep"
  type: "ReLU"
  bottom: "conv3_1/sep"
  top: "conv3_1/sep"
}
layer {
  name: "conv3_2/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv3_1/sep"
  top: "conv3_2/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv3_2/dw"
  top: "conv3_2/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_2/dw/scale"
  type: "Scale"
  bottom: "conv3_2/dw"
  top: "conv3_2/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_2/dw"
  type: "ReLU"
  bottom: "conv3_2/dw"
  top: "conv3_2/dw"
}
layer {
  name: "conv3_2/sep"
  type: "Convolution"
  bottom: "conv3_2/dw"
  top: "conv3_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv3_2/sep"
  top: "conv3_2/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_2/sep/scale"
  type: "Scale"
  bottom: "conv3_2/sep"
  top: "conv3_2/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_2/sep"
  type: "ReLU"
  bottom: "conv3_2/sep"
  top: "conv3_2/sep"
}
layer {
  name: "conv4_1/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv3_2/sep"
  top: "conv4_1/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv4_1/dw"
  top: "conv4_1/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv4_1/dw/scale"
  type: "Scale"
  bottom: "conv4_1/dw"
  top: "conv4_1/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu4_1/dw"
  type: "ReLU"
  bottom: "conv4_1/dw"
  top: "conv4_1/dw"
}
layer {
  name: "conv4_1/sep"
  type: "Convolution"
  bottom: "conv4_1/dw"
  top: "conv4_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv4_1/sep"
  top: "conv4_1/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv4_1/sep/scale"
  type: "Scale"
  bottom: "conv4_1/sep"
  top: "conv4_1/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu4_1/sep"
  type: "ReLU"
  bottom: "conv4_1/sep"
  top: "conv4_1/sep"
}
layer {
  name: "conv4_2/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv4_1/sep"
  top: "conv4_2/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv4_2/dw"
  top: "conv4_2/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv4_2/dw/scale"
  type: "Scale"
  bottom: "conv4_2/dw"
  top: "conv4_2/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu4_2/dw"
  type: "ReLU"
  bottom: "conv4_2/dw"
  top: "conv4_2/dw"
}
layer {
  name: "conv4_2/sep"
  type: "Convolution"
  bottom: "conv4_2/dw"
  top: "conv4_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv4_2/sep"
  top: "conv4_2/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv4_2/sep/scale"
  type: "Scale"
  bottom: "conv4_2/sep"
  top: "conv4_2/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu4_2/sep"
  type: "ReLU"
  bottom: "conv4_2/sep"
  top: "conv4_2/sep"
}
layer {
  name: "conv5_1/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv4_2/sep"
  top: "conv5_1/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_1/dw"
  top: "conv5_1/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_1/dw/scale"
  type: "Scale"
  bottom: "conv5_1/dw"
  top: "conv5_1/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_1/dw"
  type: "ReLU"
  bottom: "conv5_1/dw"
  top: "conv5_1/dw"
}
layer {
  name: "conv5_1/sep"
  type: "Convolution"
  bottom: "conv5_1/dw"
  top: "conv5_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_1/sep"
  top: "conv5_1/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_1/sep/scale"
  type: "Scale"
  bottom: "conv5_1/sep"
  top: "conv5_1/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_1/sep"
  type: "ReLU"
  bottom: "conv5_1/sep"
  top: "conv5_1/sep"
}
layer {
  name: "conv5_2/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_1/sep"
  top: "conv5_2/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_2/dw"
  top: "conv5_2/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_2/dw/scale"
  type: "Scale"
  bottom: "conv5_2/dw"
  top: "conv5_2/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_2/dw"
  type: "ReLU"
  bottom: "conv5_2/dw"
  top: "conv5_2/dw"
}
layer {
  name: "conv5_2/sep"
  type: "Convolution"
  bottom: "conv5_2/dw"
  top: "conv5_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_2/sep"
  top: "conv5_2/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_2/sep/scale"
  type: "Scale"
  bottom: "conv5_2/sep"
  top: "conv5_2/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_2/sep"
  type: "ReLU"
  bottom: "conv5_2/sep"
  top: "conv5_2/sep"
}
layer {
  name: "conv5_3/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_2/sep"
  top: "conv5_3/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_3/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_3/dw"
  top: "conv5_3/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_3/dw/scale"
  type: "Scale"
  bottom: "conv5_3/dw"
  top: "conv5_3/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_3/dw"
  type: "ReLU"
  bottom: "conv5_3/dw"
  top: "conv5_3/dw"
}
layer {
  name: "conv5_3/sep"
  type: "Convolution"
  bottom: "conv5_3/dw"
  top: "conv5_3/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_3/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_3/sep"
  top: "conv5_3/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_3/sep/scale"
  type: "Scale"
  bottom: "conv5_3/sep"
  top: "conv5_3/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_3/sep"
  type: "ReLU"
  bottom: "conv5_3/sep"
  top: "conv5_3/sep"
}
layer {
  name: "conv5_4/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_3/sep"
  top: "conv5_4/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_4/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_4/dw"
  top: "conv5_4/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_4/dw/scale"
  type: "Scale"
  bottom: "conv5_4/dw"
  top: "conv5_4/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_4/dw"
  type: "ReLU"
  bottom: "conv5_4/dw"
  top: "conv5_4/dw"
}
layer {
  name: "conv5_4/sep"
  type: "Convolution"
  bottom: "conv5_4/dw"
  top: "conv5_4/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_4/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_4/sep"
  top: "conv5_4/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_4/sep/scale"
  type: "Scale"
  bottom: "conv5_4/sep"
  top: "conv5_4/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_4/sep"
  type: "ReLU"
  bottom: "conv5_4/sep"
  top: "conv5_4/sep"
}
layer {
  name: "conv5_5/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_4/sep"
  top: "conv5_5/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_5/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_5/dw"
  top: "conv5_5/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_5/dw/scale"
  type: "Scale"
  bottom: "conv5_5/dw"
  top: "conv5_5/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_5/dw"
  type: "ReLU"
  bottom: "conv5_5/dw"
  top: "conv5_5/dw"
}
layer {
  name: "conv5_5/sep"
  type: "Convolution"
  bottom: "conv5_5/dw"
  top: "conv5_5/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_5/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_5/sep"
  top: "conv5_5/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_5/sep/scale"
  type: "Scale"
  bottom: "conv5_5/sep"
  top: "conv5_5/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_5/sep"
  type: "ReLU"
  bottom: "conv5_5/sep"
  top: "conv5_5/sep"
}
layer {
  name: "conv5_6/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_5/sep"
  top: "conv5_6/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_6/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_6/dw"
  top: "conv5_6/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_6/dw/scale"
  type: "Scale"
  bottom: "conv5_6/dw"
  top: "conv5_6/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_6/dw"
  type: "ReLU"
  bottom: "conv5_6/dw"
  top: "conv5_6/dw"
}
layer {
  name: "conv5_6/sep"
  type: "Convolution"
  bottom: "conv5_6/dw"
  top: "conv5_6/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_6/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_6/sep"
  top: "conv5_6/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_6/sep/scale"
  type: "Scale"
  bottom: "conv5_6/sep"
  top: "conv5_6/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_6/sep"
  type: "ReLU"
  bottom: "conv5_6/sep"
  top: "conv5_6/sep"
}
layer {
  name: "conv6/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_6/sep"
  top: "conv6/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 1024
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv6/dw/bn"
  type: "BatchNorm"
  bottom: "conv6/dw"
  top: "conv6/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv6/dw/scale"
  type: "Scale"
  bottom: "conv6/dw"
  top: "conv6/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu6/dw"
  type: "ReLU"
  bottom: "conv6/dw"
  top: "conv6/dw"
}
layer {
  name: "conv6/sep"
  type: "Convolution"
  bottom: "conv6/dw"
  top: "conv6/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv6/sep/bn"
  type: "BatchNorm"
  bottom: "conv6/sep"
  top: "conv6/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv6/sep/scale"
  type: "Scale"
  bottom: "conv6/sep"
  top: "conv6/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu6/sep"
  type: "ReLU"
  bottom: "conv6/sep"
  top: "conv6/sep"
}
layer {
  name: "pool6"
  type: "Pooling"
  bottom: "conv6/sep"
  top: "pool6"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc7"
  type: "Convolution"
  bottom: "pool6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 102
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc7"
  bottom: "label"
  top: "loss"
}
I0615 14:05:57.032390 29366 layer_factory.hpp:77] Creating layer data
I0615 14:05:57.032488 29366 net.cpp:84] Creating Layer data
I0615 14:05:57.032521 29366 net.cpp:380] data -> data
I0615 14:05:57.032575 29366 net.cpp:380] data -> label
I0615 14:05:57.032613 29366 data_transformer.cpp:25] Loading mean file from: /home/xingzhaolong/caffe_project/caffe/models/caffe-oxford102/imagenet_mean.binaryproto
I0615 14:05:57.037662 29366 image_data_layer.cpp:38] Opening file /home/xingzhaolong/caffe_project/caffe/models/caffe-oxford102/test.txt
I0615 14:05:57.039911 29366 image_data_layer.cpp:63] A total of 6149 images.
I0615 14:05:57.048498 29366 image_data_layer.cpp:90] output data size: 50,3,224,224
I0615 14:05:57.151716 29366 net.cpp:122] Setting up data
I0615 14:05:57.151796 29366 net.cpp:129] Top shape: 50 3 224 224 (7526400)
I0615 14:05:57.151810 29366 net.cpp:129] Top shape: 50 (50)
I0615 14:05:57.151819 29366 net.cpp:137] Memory required for data: 30105800
I0615 14:05:57.151834 29366 layer_factory.hpp:77] Creating layer conv1
I0615 14:05:57.151883 29366 net.cpp:84] Creating Layer conv1
I0615 14:05:57.151899 29366 net.cpp:406] conv1 <- data
I0615 14:05:57.151938 29366 net.cpp:380] conv1 -> conv1
I0615 14:05:57.373487 29366 net.cpp:122] Setting up conv1
I0615 14:05:57.373555 29366 net.cpp:129] Top shape: 50 32 112 112 (20070400)
I0615 14:05:57.373567 29366 net.cpp:137] Memory required for data: 110387400
I0615 14:05:57.373608 29366 layer_factory.hpp:77] Creating layer conv1/bn
I0615 14:05:57.373639 29366 net.cpp:84] Creating Layer conv1/bn
I0615 14:05:57.373651 29366 net.cpp:406] conv1/bn <- conv1
I0615 14:05:57.373667 29366 net.cpp:367] conv1/bn -> conv1 (in-place)
I0615 14:05:57.374718 29366 net.cpp:122] Setting up conv1/bn
I0615 14:05:57.374742 29366 net.cpp:129] Top shape: 50 32 112 112 (20070400)
I0615 14:05:57.374750 29366 net.cpp:137] Memory required for data: 190669000
I0615 14:05:57.374773 29366 layer_factory.hpp:77] Creating layer conv1/scale
I0615 14:05:57.374795 29366 net.cpp:84] Creating Layer conv1/scale
I0615 14:05:57.374805 29366 net.cpp:406] conv1/scale <- conv1
I0615 14:05:57.374817 29366 net.cpp:367] conv1/scale -> conv1 (in-place)
I0615 14:05:57.374886 29366 layer_factory.hpp:77] Creating layer conv1/scale
I0615 14:05:57.375046 29366 net.cpp:122] Setting up conv1/scale
I0615 14:05:57.375063 29366 net.cpp:129] Top shape: 50 32 112 112 (20070400)
I0615 14:05:57.375072 29366 net.cpp:137] Memory required for data: 270950600
I0615 14:05:57.375087 29366 layer_factory.hpp:77] Creating layer relu1
I0615 14:05:57.375105 29366 net.cpp:84] Creating Layer relu1
I0615 14:05:57.375115 29366 net.cpp:406] relu1 <- conv1
I0615 14:05:57.375126 29366 net.cpp:367] relu1 -> conv1 (in-place)
I0615 14:05:57.375545 29366 net.cpp:122] Setting up relu1
I0615 14:05:57.375567 29366 net.cpp:129] Top shape: 50 32 112 112 (20070400)
I0615 14:05:57.375576 29366 net.cpp:137] Memory required for data: 351232200
I0615 14:05:57.375586 29366 layer_factory.hpp:77] Creating layer conv2_1/dw
I0615 14:05:57.375607 29366 net.cpp:84] Creating Layer conv2_1/dw
I0615 14:05:57.375617 29366 net.cpp:406] conv2_1/dw <- conv1
I0615 14:05:57.375629 29366 net.cpp:380] conv2_1/dw -> conv2_1/dw
I0615 14:05:57.378078 29366 net.cpp:122] Setting up conv2_1/dw
I0615 14:05:57.378103 29366 net.cpp:129] Top shape: 50 32 112 112 (20070400)
I0615 14:05:57.378124 29366 net.cpp:137] Memory required for data: 431513800
I0615 14:05:57.378157 29366 layer_factory.hpp:77] Creating layer conv2_1/dw/bn
I0615 14:05:57.378171 29366 net.cpp:84] Creating Layer conv2_1/dw/bn
I0615 14:05:57.378180 29366 net.cpp:406] conv2_1/dw/bn <- conv2_1/dw
I0615 14:05:57.378192 29366 net.cpp:367] conv2_1/dw/bn -> conv2_1/dw (in-place)
I0615 14:05:57.378415 29366 net.cpp:122] Setting up conv2_1/dw/bn
I0615 14:05:57.378433 29366 net.cpp:129] Top shape: 50 32 112 112 (20070400)
I0615 14:05:57.378442 29366 net.cpp:137] Memory required for data: 511795400
I0615 14:05:57.378459 29366 layer_factory.hpp:77] Creating layer conv2_1/dw/scale
I0615 14:05:57.378473 29366 net.cpp:84] Creating Layer conv2_1/dw/scale
I0615 14:05:57.378482 29366 net.cpp:406] conv2_1/dw/scale <- conv2_1/dw
I0615 14:05:57.378494 29366 net.cpp:367] conv2_1/dw/scale -> conv2_1/dw (in-place)
I0615 14:05:57.378554 29366 layer_factory.hpp:77] Creating layer conv2_1/dw/scale
I0615 14:05:57.378715 29366 net.cpp:122] Setting up conv2_1/dw/scale
I0615 14:05:57.378732 29366 net.cpp:129] Top shape: 50 32 112 112 (20070400)
I0615 14:05:57.378741 29366 net.cpp:137] Memory required for data: 592077000
I0615 14:05:57.378753 29366 layer_factory.hpp:77] Creating layer relu2_1/dw
I0615 14:05:57.378767 29366 net.cpp:84] Creating Layer relu2_1/dw
I0615 14:05:57.378775 29366 net.cpp:406] relu2_1/dw <- conv2_1/dw
I0615 14:05:57.378787 29366 net.cpp:367] relu2_1/dw -> conv2_1/dw (in-place)
I0615 14:05:57.379050 29366 net.cpp:122] Setting up relu2_1/dw
I0615 14:05:57.379070 29366 net.cpp:129] Top shape: 50 32 112 112 (20070400)
I0615 14:05:57.379078 29366 net.cpp:137] Memory required for data: 672358600
I0615 14:05:57.379086 29366 layer_factory.hpp:77] Creating layer conv2_1/sep
I0615 14:05:57.379106 29366 net.cpp:84] Creating Layer conv2_1/sep
I0615 14:05:57.379117 29366 net.cpp:406] conv2_1/sep <- conv2_1/dw
I0615 14:05:57.379133 29366 net.cpp:380] conv2_1/sep -> conv2_1/sep
I0615 14:05:57.381278 29366 net.cpp:122] Setting up conv2_1/sep
I0615 14:05:57.381304 29366 net.cpp:129] Top shape: 50 64 112 112 (40140800)
I0615 14:05:57.381314 29366 net.cpp:137] Memory required for data: 832921800
I0615 14:05:57.381325 29366 layer_factory.hpp:77] Creating layer conv2_1/sep/bn
I0615 14:05:57.381341 29366 net.cpp:84] Creating Layer conv2_1/sep/bn
I0615 14:05:57.381351 29366 net.cpp:406] conv2_1/sep/bn <- conv2_1/sep
I0615 14:05:57.381363 29366 net.cpp:367] conv2_1/sep/bn -> conv2_1/sep (in-place)
I0615 14:05:57.381616 29366 net.cpp:122] Setting up conv2_1/sep/bn
I0615 14:05:57.381635 29366 net.cpp:129] Top shape: 50 64 112 112 (40140800)
I0615 14:05:57.381644 29366 net.cpp:137] Memory required for data: 993485000
I0615 14:05:57.381661 29366 layer_factory.hpp:77] Creating layer conv2_1/sep/scale
I0615 14:05:57.381675 29366 net.cpp:84] Creating Layer conv2_1/sep/scale
I0615 14:05:57.381685 29366 net.cpp:406] conv2_1/sep/scale <- conv2_1/sep
I0615 14:05:57.381696 29366 net.cpp:367] conv2_1/sep/scale -> conv2_1/sep (in-place)
I0615 14:05:57.381757 29366 layer_factory.hpp:77] Creating layer conv2_1/sep/scale
I0615 14:05:57.381913 29366 net.cpp:122] Setting up conv2_1/sep/scale
I0615 14:05:57.381932 29366 net.cpp:129] Top shape: 50 64 112 112 (40140800)
I0615 14:05:57.381939 29366 net.cpp:137] Memory required for data: 1154048200
I0615 14:05:57.381963 29366 layer_factory.hpp:77] Creating layer relu2_1/sep
I0615 14:05:57.381976 29366 net.cpp:84] Creating Layer relu2_1/sep
I0615 14:05:57.381985 29366 net.cpp:406] relu2_1/sep <- conv2_1/sep
I0615 14:05:57.381999 29366 net.cpp:367] relu2_1/sep -> conv2_1/sep (in-place)
I0615 14:05:57.382412 29366 net.cpp:122] Setting up relu2_1/sep
I0615 14:05:57.382433 29366 net.cpp:129] Top shape: 50 64 112 112 (40140800)
I0615 14:05:57.382443 29366 net.cpp:137] Memory required for data: 1314611400
I0615 14:05:57.382452 29366 layer_factory.hpp:77] Creating layer conv2_2/dw
I0615 14:05:57.382465 29366 net.cpp:84] Creating Layer conv2_2/dw
I0615 14:05:57.382475 29366 net.cpp:406] conv2_2/dw <- conv2_1/sep
I0615 14:05:57.382499 29366 net.cpp:380] conv2_2/dw -> conv2_2/dw
I0615 14:05:57.383556 29366 net.cpp:122] Setting up conv2_2/dw
I0615 14:05:57.383579 29366 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0615 14:05:57.383589 29366 net.cpp:137] Memory required for data: 1354752200
I0615 14:05:57.383599 29366 layer_factory.hpp:77] Creating layer conv2_2/dw/bn
I0615 14:05:57.383615 29366 net.cpp:84] Creating Layer conv2_2/dw/bn
I0615 14:05:57.383625 29366 net.cpp:406] conv2_2/dw/bn <- conv2_2/dw
I0615 14:05:57.383637 29366 net.cpp:367] conv2_2/dw/bn -> conv2_2/dw (in-place)
I0615 14:05:57.383867 29366 net.cpp:122] Setting up conv2_2/dw/bn
I0615 14:05:57.383883 29366 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0615 14:05:57.383891 29366 net.cpp:137] Memory required for data: 1394893000
I0615 14:05:57.383905 29366 layer_factory.hpp:77] Creating layer conv2_2/dw/scale
I0615 14:05:57.383922 29366 net.cpp:84] Creating Layer conv2_2/dw/scale
I0615 14:05:57.383932 29366 net.cpp:406] conv2_2/dw/scale <- conv2_2/dw
I0615 14:05:57.383944 29366 net.cpp:367] conv2_2/dw/scale -> conv2_2/dw (in-place)
I0615 14:05:57.384002 29366 layer_factory.hpp:77] Creating layer conv2_2/dw/scale
I0615 14:05:57.384162 29366 net.cpp:122] Setting up conv2_2/dw/scale
I0615 14:05:57.384179 29366 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0615 14:05:57.384188 29366 net.cpp:137] Memory required for data: 1435033800
I0615 14:05:57.384201 29366 layer_factory.hpp:77] Creating layer relu2_2/dw
I0615 14:05:57.384217 29366 net.cpp:84] Creating Layer relu2_2/dw
I0615 14:05:57.384227 29366 net.cpp:406] relu2_2/dw <- conv2_2/dw
I0615 14:05:57.384238 29366 net.cpp:367] relu2_2/dw -> conv2_2/dw (in-place)
I0615 14:05:57.384457 29366 net.cpp:122] Setting up relu2_2/dw
I0615 14:05:57.384476 29366 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0615 14:05:57.384485 29366 net.cpp:137] Memory required for data: 1475174600
I0615 14:05:57.384493 29366 layer_factory.hpp:77] Creating layer conv2_2/sep
I0615 14:05:57.384512 29366 net.cpp:84] Creating Layer conv2_2/sep
I0615 14:05:57.384531 29366 net.cpp:406] conv2_2/sep <- conv2_2/dw
I0615 14:05:57.384548 29366 net.cpp:380] conv2_2/sep -> conv2_2/sep
I0615 14:05:57.386008 29366 net.cpp:122] Setting up conv2_2/sep
I0615 14:05:57.386034 29366 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0615 14:05:57.386042 29366 net.cpp:137] Memory required for data: 1555456200
I0615 14:05:57.386054 29366 layer_factory.hpp:77] Creating layer conv2_2/sep/bn
I0615 14:05:57.386070 29366 net.cpp:84] Creating Layer conv2_2/sep/bn
I0615 14:05:57.386080 29366 net.cpp:406] conv2_2/sep/bn <- conv2_2/sep
I0615 14:05:57.386095 29366 net.cpp:367] conv2_2/sep/bn -> conv2_2/sep (in-place)
I0615 14:05:57.386327 29366 net.cpp:122] Setting up conv2_2/sep/bn
I0615 14:05:57.386343 29366 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0615 14:05:57.386353 29366 net.cpp:137] Memory required for data: 1635737800
I0615 14:05:57.386366 29366 layer_factory.hpp:77] Creating layer conv2_2/sep/scale
I0615 14:05:57.386382 29366 net.cpp:84] Creating Layer conv2_2/sep/scale
I0615 14:05:57.386392 29366 net.cpp:406] conv2_2/sep/scale <- conv2_2/sep
I0615 14:05:57.386404 29366 net.cpp:367] conv2_2/sep/scale -> conv2_2/sep (in-place)
I0615 14:05:57.386461 29366 layer_factory.hpp:77] Creating layer conv2_2/sep/scale
I0615 14:05:57.386620 29366 net.cpp:122] Setting up conv2_2/sep/scale
I0615 14:05:57.386639 29366 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0615 14:05:57.386648 29366 net.cpp:137] Memory required for data: 1716019400
I0615 14:05:57.386659 29366 layer_factory.hpp:77] Creating layer relu2_2/sep
I0615 14:05:57.386672 29366 net.cpp:84] Creating Layer relu2_2/sep
I0615 14:05:57.386680 29366 net.cpp:406] relu2_2/sep <- conv2_2/sep
I0615 14:05:57.386690 29366 net.cpp:367] relu2_2/sep -> conv2_2/sep (in-place)
I0615 14:05:57.386921 29366 net.cpp:122] Setting up relu2_2/sep
I0615 14:05:57.386940 29366 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0615 14:05:57.386948 29366 net.cpp:137] Memory required for data: 1796301000
I0615 14:05:57.386956 29366 layer_factory.hpp:77] Creating layer conv3_1/dw
I0615 14:05:57.386991 29366 net.cpp:84] Creating Layer conv3_1/dw
I0615 14:05:57.387001 29366 net.cpp:406] conv3_1/dw <- conv2_2/sep
I0615 14:05:57.387019 29366 net.cpp:380] conv3_1/dw -> conv3_1/dw
I0615 14:05:57.388062 29366 net.cpp:122] Setting up conv3_1/dw
I0615 14:05:57.388085 29366 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0615 14:05:57.388093 29366 net.cpp:137] Memory required for data: 1876582600
I0615 14:05:57.388104 29366 layer_factory.hpp:77] Creating layer conv3_1/dw/bn
I0615 14:05:57.388121 29366 net.cpp:84] Creating Layer conv3_1/dw/bn
I0615 14:05:57.388131 29366 net.cpp:406] conv3_1/dw/bn <- conv3_1/dw
I0615 14:05:57.388142 29366 net.cpp:367] conv3_1/dw/bn -> conv3_1/dw (in-place)
I0615 14:05:57.388370 29366 net.cpp:122] Setting up conv3_1/dw/bn
I0615 14:05:57.388386 29366 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0615 14:05:57.388394 29366 net.cpp:137] Memory required for data: 1956864200
I0615 14:05:57.388417 29366 layer_factory.hpp:77] Creating layer conv3_1/dw/scale
I0615 14:05:57.388432 29366 net.cpp:84] Creating Layer conv3_1/dw/scale
I0615 14:05:57.388442 29366 net.cpp:406] conv3_1/dw/scale <- conv3_1/dw
I0615 14:05:57.388453 29366 net.cpp:367] conv3_1/dw/scale -> conv3_1/dw (in-place)
I0615 14:05:57.388522 29366 layer_factory.hpp:77] Creating layer conv3_1/dw/scale
I0615 14:05:57.388684 29366 net.cpp:122] Setting up conv3_1/dw/scale
I0615 14:05:57.388701 29366 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0615 14:05:57.388710 29366 net.cpp:137] Memory required for data: 2037145800
I0615 14:05:57.388722 29366 layer_factory.hpp:77] Creating layer relu3_1/dw
I0615 14:05:57.388734 29366 net.cpp:84] Creating Layer relu3_1/dw
I0615 14:05:57.388747 29366 net.cpp:406] relu3_1/dw <- conv3_1/dw
I0615 14:05:57.388757 29366 net.cpp:367] relu3_1/dw -> conv3_1/dw (in-place)
I0615 14:05:57.389281 29366 net.cpp:122] Setting up relu3_1/dw
I0615 14:05:57.389302 29366 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0615 14:05:57.389312 29366 net.cpp:137] Memory required for data: 2117427400
I0615 14:05:57.389320 29366 layer_factory.hpp:77] Creating layer conv3_1/sep
I0615 14:05:57.389339 29366 net.cpp:84] Creating Layer conv3_1/sep
I0615 14:05:57.389350 29366 net.cpp:406] conv3_1/sep <- conv3_1/dw
I0615 14:05:57.389366 29366 net.cpp:380] conv3_1/sep -> conv3_1/sep
I0615 14:05:57.392143 29366 net.cpp:122] Setting up conv3_1/sep
I0615 14:05:57.392168 29366 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0615 14:05:57.392177 29366 net.cpp:137] Memory required for data: 2197709000
I0615 14:05:57.392189 29366 layer_factory.hpp:77] Creating layer conv3_1/sep/bn
I0615 14:05:57.392205 29366 net.cpp:84] Creating Layer conv3_1/sep/bn
I0615 14:05:57.392215 29366 net.cpp:406] conv3_1/sep/bn <- conv3_1/sep
I0615 14:05:57.392226 29366 net.cpp:367] conv3_1/sep/bn -> conv3_1/sep (in-place)
I0615 14:05:57.392464 29366 net.cpp:122] Setting up conv3_1/sep/bn
I0615 14:05:57.392482 29366 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0615 14:05:57.392489 29366 net.cpp:137] Memory required for data: 2277990600
I0615 14:05:57.392504 29366 layer_factory.hpp:77] Creating layer conv3_1/sep/scale
I0615 14:05:57.392524 29366 net.cpp:84] Creating Layer conv3_1/sep/scale
I0615 14:05:57.392535 29366 net.cpp:406] conv3_1/sep/scale <- conv3_1/sep
I0615 14:05:57.392550 29366 net.cpp:367] conv3_1/sep/scale -> conv3_1/sep (in-place)
I0615 14:05:57.392606 29366 layer_factory.hpp:77] Creating layer conv3_1/sep/scale
I0615 14:05:57.392755 29366 net.cpp:122] Setting up conv3_1/sep/scale
I0615 14:05:57.392776 29366 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0615 14:05:57.392784 29366 net.cpp:137] Memory required for data: 2358272200
I0615 14:05:57.392796 29366 layer_factory.hpp:77] Creating layer relu3_1/sep
I0615 14:05:57.392808 29366 net.cpp:84] Creating Layer relu3_1/sep
I0615 14:05:57.392817 29366 net.cpp:406] relu3_1/sep <- conv3_1/sep
I0615 14:05:57.392827 29366 net.cpp:367] relu3_1/sep -> conv3_1/sep (in-place)
I0615 14:05:57.393065 29366 net.cpp:122] Setting up relu3_1/sep
I0615 14:05:57.393097 29366 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0615 14:05:57.393115 29366 net.cpp:137] Memory required for data: 2438553800
I0615 14:05:57.393124 29366 layer_factory.hpp:77] Creating layer conv3_2/dw
I0615 14:05:57.393138 29366 net.cpp:84] Creating Layer conv3_2/dw
I0615 14:05:57.393148 29366 net.cpp:406] conv3_2/dw <- conv3_1/sep
I0615 14:05:57.393167 29366 net.cpp:380] conv3_2/dw -> conv3_2/dw
I0615 14:05:57.395952 29366 net.cpp:122] Setting up conv3_2/dw
I0615 14:05:57.395975 29366 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0615 14:05:57.395984 29366 net.cpp:137] Memory required for data: 2458624200
I0615 14:05:57.395995 29366 layer_factory.hpp:77] Creating layer conv3_2/dw/bn
I0615 14:05:57.396011 29366 net.cpp:84] Creating Layer conv3_2/dw/bn
I0615 14:05:57.396021 29366 net.cpp:406] conv3_2/dw/bn <- conv3_2/dw
I0615 14:05:57.396036 29366 net.cpp:367] conv3_2/dw/bn -> conv3_2/dw (in-place)
I0615 14:05:57.396268 29366 net.cpp:122] Setting up conv3_2/dw/bn
I0615 14:05:57.396286 29366 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0615 14:05:57.396294 29366 net.cpp:137] Memory required for data: 2478694600
I0615 14:05:57.396307 29366 layer_factory.hpp:77] Creating layer conv3_2/dw/scale
I0615 14:05:57.396324 29366 net.cpp:84] Creating Layer conv3_2/dw/scale
I0615 14:05:57.396333 29366 net.cpp:406] conv3_2/dw/scale <- conv3_2/dw
I0615 14:05:57.396344 29366 net.cpp:367] conv3_2/dw/scale -> conv3_2/dw (in-place)
I0615 14:05:57.396402 29366 layer_factory.hpp:77] Creating layer conv3_2/dw/scale
I0615 14:05:57.396564 29366 net.cpp:122] Setting up conv3_2/dw/scale
I0615 14:05:57.396582 29366 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0615 14:05:57.396591 29366 net.cpp:137] Memory required for data: 2498765000
I0615 14:05:57.396603 29366 layer_factory.hpp:77] Creating layer relu3_2/dw
I0615 14:05:57.396618 29366 net.cpp:84] Creating Layer relu3_2/dw
I0615 14:05:57.396627 29366 net.cpp:406] relu3_2/dw <- conv3_2/dw
I0615 14:05:57.396641 29366 net.cpp:367] relu3_2/dw -> conv3_2/dw (in-place)
I0615 14:05:57.397063 29366 net.cpp:122] Setting up relu3_2/dw
I0615 14:05:57.397084 29366 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0615 14:05:57.397094 29366 net.cpp:137] Memory required for data: 2518835400
I0615 14:05:57.397101 29366 layer_factory.hpp:77] Creating layer conv3_2/sep
I0615 14:05:57.397120 29366 net.cpp:84] Creating Layer conv3_2/sep
I0615 14:05:57.397130 29366 net.cpp:406] conv3_2/sep <- conv3_2/dw
I0615 14:05:57.397146 29366 net.cpp:380] conv3_2/sep -> conv3_2/sep
I0615 14:05:57.398907 29366 net.cpp:122] Setting up conv3_2/sep
I0615 14:05:57.398931 29366 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0615 14:05:57.398941 29366 net.cpp:137] Memory required for data: 2558976200
I0615 14:05:57.398952 29366 layer_factory.hpp:77] Creating layer conv3_2/sep/bn
I0615 14:05:57.398967 29366 net.cpp:84] Creating Layer conv3_2/sep/bn
I0615 14:05:57.398977 29366 net.cpp:406] conv3_2/sep/bn <- conv3_2/sep
I0615 14:05:57.398991 29366 net.cpp:367] conv3_2/sep/bn -> conv3_2/sep (in-place)
I0615 14:05:57.399226 29366 net.cpp:122] Setting up conv3_2/sep/bn
I0615 14:05:57.399245 29366 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0615 14:05:57.399252 29366 net.cpp:137] Memory required for data: 2599117000
I0615 14:05:57.399266 29366 layer_factory.hpp:77] Creating layer conv3_2/sep/scale
I0615 14:05:57.399281 29366 net.cpp:84] Creating Layer conv3_2/sep/scale
I0615 14:05:57.399289 29366 net.cpp:406] conv3_2/sep/scale <- conv3_2/sep
I0615 14:05:57.399303 29366 net.cpp:367] conv3_2/sep/scale -> conv3_2/sep (in-place)
I0615 14:05:57.399359 29366 layer_factory.hpp:77] Creating layer conv3_2/sep/scale
I0615 14:05:57.399507 29366 net.cpp:122] Setting up conv3_2/sep/scale
I0615 14:05:57.399534 29366 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0615 14:05:57.399544 29366 net.cpp:137] Memory required for data: 2639257800
I0615 14:05:57.399555 29366 layer_factory.hpp:77] Creating layer relu3_2/sep
I0615 14:05:57.399567 29366 net.cpp:84] Creating Layer relu3_2/sep
I0615 14:05:57.399576 29366 net.cpp:406] relu3_2/sep <- conv3_2/sep
I0615 14:05:57.399603 29366 net.cpp:367] relu3_2/sep -> conv3_2/sep (in-place)
I0615 14:05:57.399829 29366 net.cpp:122] Setting up relu3_2/sep
I0615 14:05:57.399852 29366 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0615 14:05:57.399860 29366 net.cpp:137] Memory required for data: 2679398600
I0615 14:05:57.399869 29366 layer_factory.hpp:77] Creating layer conv4_1/dw
I0615 14:05:57.399883 29366 net.cpp:84] Creating Layer conv4_1/dw
I0615 14:05:57.399893 29366 net.cpp:406] conv4_1/dw <- conv3_2/sep
I0615 14:05:57.399910 29366 net.cpp:380] conv4_1/dw -> conv4_1/dw
I0615 14:05:57.400096 29366 net.cpp:122] Setting up conv4_1/dw
I0615 14:05:57.400118 29366 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0615 14:05:57.400127 29366 net.cpp:137] Memory required for data: 2719539400
I0615 14:05:57.400137 29366 layer_factory.hpp:77] Creating layer conv4_1/dw/bn
I0615 14:05:57.400149 29366 net.cpp:84] Creating Layer conv4_1/dw/bn
I0615 14:05:57.400158 29366 net.cpp:406] conv4_1/dw/bn <- conv4_1/dw
I0615 14:05:57.400171 29366 net.cpp:367] conv4_1/dw/bn -> conv4_1/dw (in-place)
I0615 14:05:57.400400 29366 net.cpp:122] Setting up conv4_1/dw/bn
I0615 14:05:57.400418 29366 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0615 14:05:57.400426 29366 net.cpp:137] Memory required for data: 2759680200
I0615 14:05:57.400439 29366 layer_factory.hpp:77] Creating layer conv4_1/dw/scale
I0615 14:05:57.400452 29366 net.cpp:84] Creating Layer conv4_1/dw/scale
I0615 14:05:57.400461 29366 net.cpp:406] conv4_1/dw/scale <- conv4_1/dw
I0615 14:05:57.400472 29366 net.cpp:367] conv4_1/dw/scale -> conv4_1/dw (in-place)
I0615 14:05:57.400542 29366 layer_factory.hpp:77] Creating layer conv4_1/dw/scale
I0615 14:05:57.400697 29366 net.cpp:122] Setting up conv4_1/dw/scale
I0615 14:05:57.400714 29366 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0615 14:05:57.400722 29366 net.cpp:137] Memory required for data: 2799821000
I0615 14:05:57.400734 29366 layer_factory.hpp:77] Creating layer relu4_1/dw
I0615 14:05:57.400749 29366 net.cpp:84] Creating Layer relu4_1/dw
I0615 14:05:57.400759 29366 net.cpp:406] relu4_1/dw <- conv4_1/dw
I0615 14:05:57.400769 29366 net.cpp:367] relu4_1/dw -> conv4_1/dw (in-place)
I0615 14:05:57.401196 29366 net.cpp:122] Setting up relu4_1/dw
I0615 14:05:57.401221 29366 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0615 14:05:57.401231 29366 net.cpp:137] Memory required for data: 2839961800
I0615 14:05:57.401238 29366 layer_factory.hpp:77] Creating layer conv4_1/sep
I0615 14:05:57.401254 29366 net.cpp:84] Creating Layer conv4_1/sep
I0615 14:05:57.401264 29366 net.cpp:406] conv4_1/sep <- conv4_1/dw
I0615 14:05:57.401280 29366 net.cpp:380] conv4_1/sep -> conv4_1/sep
I0615 14:05:57.403347 29366 net.cpp:122] Setting up conv4_1/sep
I0615 14:05:57.403370 29366 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0615 14:05:57.403380 29366 net.cpp:137] Memory required for data: 2880102600
I0615 14:05:57.403391 29366 layer_factory.hpp:77] Creating layer conv4_1/sep/bn
I0615 14:05:57.403408 29366 net.cpp:84] Creating Layer conv4_1/sep/bn
I0615 14:05:57.403417 29366 net.cpp:406] conv4_1/sep/bn <- conv4_1/sep
I0615 14:05:57.403429 29366 net.cpp:367] conv4_1/sep/bn -> conv4_1/sep (in-place)
I0615 14:05:57.403708 29366 net.cpp:122] Setting up conv4_1/sep/bn
I0615 14:05:57.403728 29366 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0615 14:05:57.403738 29366 net.cpp:137] Memory required for data: 2920243400
I0615 14:05:57.403751 29366 layer_factory.hpp:77] Creating layer conv4_1/sep/scale
I0615 14:05:57.403765 29366 net.cpp:84] Creating Layer conv4_1/sep/scale
I0615 14:05:57.403774 29366 net.cpp:406] conv4_1/sep/scale <- conv4_1/sep
I0615 14:05:57.403785 29366 net.cpp:367] conv4_1/sep/scale -> conv4_1/sep (in-place)
I0615 14:05:57.403846 29366 layer_factory.hpp:77] Creating layer conv4_1/sep/scale
I0615 14:05:57.403997 29366 net.cpp:122] Setting up conv4_1/sep/scale
I0615 14:05:57.404014 29366 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0615 14:05:57.404023 29366 net.cpp:137] Memory required for data: 2960384200
I0615 14:05:57.404063 29366 layer_factory.hpp:77] Creating layer relu4_1/sep
I0615 14:05:57.404095 29366 net.cpp:84] Creating Layer relu4_1/sep
I0615 14:05:57.404105 29366 net.cpp:406] relu4_1/sep <- conv4_1/sep
I0615 14:05:57.404116 29366 net.cpp:367] relu4_1/sep -> conv4_1/sep (in-place)
I0615 14:05:57.404551 29366 net.cpp:122] Setting up relu4_1/sep
I0615 14:05:57.404574 29366 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0615 14:05:57.404583 29366 net.cpp:137] Memory required for data: 3000525000
I0615 14:05:57.404592 29366 layer_factory.hpp:77] Creating layer conv4_2/dw
I0615 14:05:57.404605 29366 net.cpp:84] Creating Layer conv4_2/dw
I0615 14:05:57.404614 29366 net.cpp:406] conv4_2/dw <- conv4_1/sep
I0615 14:05:57.404631 29366 net.cpp:380] conv4_2/dw -> conv4_2/dw
I0615 14:05:57.404808 29366 net.cpp:122] Setting up conv4_2/dw
I0615 14:05:57.404826 29366 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0615 14:05:57.404834 29366 net.cpp:137] Memory required for data: 3010560200
I0615 14:05:57.404845 29366 layer_factory.hpp:77] Creating layer conv4_2/dw/bn
I0615 14:05:57.404858 29366 net.cpp:84] Creating Layer conv4_2/dw/bn
I0615 14:05:57.404867 29366 net.cpp:406] conv4_2/dw/bn <- conv4_2/dw
I0615 14:05:57.404881 29366 net.cpp:367] conv4_2/dw/bn -> conv4_2/dw (in-place)
I0615 14:05:57.405122 29366 net.cpp:122] Setting up conv4_2/dw/bn
I0615 14:05:57.405138 29366 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0615 14:05:57.405148 29366 net.cpp:137] Memory required for data: 3020595400
I0615 14:05:57.405161 29366 layer_factory.hpp:77] Creating layer conv4_2/dw/scale
I0615 14:05:57.405174 29366 net.cpp:84] Creating Layer conv4_2/dw/scale
I0615 14:05:57.405184 29366 net.cpp:406] conv4_2/dw/scale <- conv4_2/dw
I0615 14:05:57.405194 29366 net.cpp:367] conv4_2/dw/scale -> conv4_2/dw (in-place)
I0615 14:05:57.405254 29366 layer_factory.hpp:77] Creating layer conv4_2/dw/scale
I0615 14:05:57.405406 29366 net.cpp:122] Setting up conv4_2/dw/scale
I0615 14:05:57.405423 29366 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0615 14:05:57.405431 29366 net.cpp:137] Memory required for data: 3030630600
I0615 14:05:57.405443 29366 layer_factory.hpp:77] Creating layer relu4_2/dw
I0615 14:05:57.405455 29366 net.cpp:84] Creating Layer relu4_2/dw
I0615 14:05:57.405464 29366 net.cpp:406] relu4_2/dw <- conv4_2/dw
I0615 14:05:57.405478 29366 net.cpp:367] relu4_2/dw -> conv4_2/dw (in-place)
I0615 14:05:57.405894 29366 net.cpp:122] Setting up relu4_2/dw
I0615 14:05:57.405920 29366 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0615 14:05:57.405928 29366 net.cpp:137] Memory required for data: 3040665800
I0615 14:05:57.405937 29366 layer_factory.hpp:77] Creating layer conv4_2/sep
I0615 14:05:57.405952 29366 net.cpp:84] Creating Layer conv4_2/sep
I0615 14:05:57.405962 29366 net.cpp:406] conv4_2/sep <- conv4_2/dw
I0615 14:05:57.405978 29366 net.cpp:380] conv4_2/sep -> conv4_2/sep
I0615 14:05:57.409965 29366 net.cpp:122] Setting up conv4_2/sep
I0615 14:05:57.409991 29366 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0615 14:05:57.410001 29366 net.cpp:137] Memory required for data: 3060736200
I0615 14:05:57.410012 29366 layer_factory.hpp:77] Creating layer conv4_2/sep/bn
I0615 14:05:57.410027 29366 net.cpp:84] Creating Layer conv4_2/sep/bn
I0615 14:05:57.410037 29366 net.cpp:406] conv4_2/sep/bn <- conv4_2/sep
I0615 14:05:57.410049 29366 net.cpp:367] conv4_2/sep/bn -> conv4_2/sep (in-place)
I0615 14:05:57.410300 29366 net.cpp:122] Setting up conv4_2/sep/bn
I0615 14:05:57.410316 29366 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0615 14:05:57.410325 29366 net.cpp:137] Memory required for data: 3080806600
I0615 14:05:57.410338 29366 layer_factory.hpp:77] Creating layer conv4_2/sep/scale
I0615 14:05:57.410351 29366 net.cpp:84] Creating Layer conv4_2/sep/scale
I0615 14:05:57.410360 29366 net.cpp:406] conv4_2/sep/scale <- conv4_2/sep
I0615 14:05:57.410375 29366 net.cpp:367] conv4_2/sep/scale -> conv4_2/sep (in-place)
I0615 14:05:57.410429 29366 layer_factory.hpp:77] Creating layer conv4_2/sep/scale
I0615 14:05:57.410593 29366 net.cpp:122] Setting up conv4_2/sep/scale
I0615 14:05:57.410619 29366 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0615 14:05:57.410640 29366 net.cpp:137] Memory required for data: 3100877000
I0615 14:05:57.410653 29366 layer_factory.hpp:77] Creating layer relu4_2/sep
I0615 14:05:57.410665 29366 net.cpp:84] Creating Layer relu4_2/sep
I0615 14:05:57.410675 29366 net.cpp:406] relu4_2/sep <- conv4_2/sep
I0615 14:05:57.410684 29366 net.cpp:367] relu4_2/sep -> conv4_2/sep (in-place)
I0615 14:05:57.411108 29366 net.cpp:122] Setting up relu4_2/sep
I0615 14:05:57.411128 29366 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0615 14:05:57.411137 29366 net.cpp:137] Memory required for data: 3120947400
I0615 14:05:57.411145 29366 layer_factory.hpp:77] Creating layer conv5_1/dw
I0615 14:05:57.411164 29366 net.cpp:84] Creating Layer conv5_1/dw
I0615 14:05:57.411173 29366 net.cpp:406] conv5_1/dw <- conv4_2/sep
I0615 14:05:57.411190 29366 net.cpp:380] conv5_1/dw -> conv5_1/dw
I0615 14:05:57.411403 29366 net.cpp:122] Setting up conv5_1/dw
I0615 14:05:57.411422 29366 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0615 14:05:57.411430 29366 net.cpp:137] Memory required for data: 3141017800
I0615 14:05:57.411440 29366 layer_factory.hpp:77] Creating layer conv5_1/dw/bn
I0615 14:05:57.411456 29366 net.cpp:84] Creating Layer conv5_1/dw/bn
I0615 14:05:57.411466 29366 net.cpp:406] conv5_1/dw/bn <- conv5_1/dw
I0615 14:05:57.411481 29366 net.cpp:367] conv5_1/dw/bn -> conv5_1/dw (in-place)
I0615 14:05:57.411723 29366 net.cpp:122] Setting up conv5_1/dw/bn
I0615 14:05:57.411743 29366 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0615 14:05:57.411751 29366 net.cpp:137] Memory required for data: 3161088200
I0615 14:05:57.411764 29366 layer_factory.hpp:77] Creating layer conv5_1/dw/scale
I0615 14:05:57.411777 29366 net.cpp:84] Creating Layer conv5_1/dw/scale
I0615 14:05:57.411787 29366 net.cpp:406] conv5_1/dw/scale <- conv5_1/dw
I0615 14:05:57.411801 29366 net.cpp:367] conv5_1/dw/scale -> conv5_1/dw (in-place)
I0615 14:05:57.411855 29366 layer_factory.hpp:77] Creating layer conv5_1/dw/scale
I0615 14:05:57.412012 29366 net.cpp:122] Setting up conv5_1/dw/scale
I0615 14:05:57.412029 29366 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0615 14:05:57.412039 29366 net.cpp:137] Memory required for data: 3181158600
I0615 14:05:57.412050 29366 layer_factory.hpp:77] Creating layer relu5_1/dw
I0615 14:05:57.412061 29366 net.cpp:84] Creating Layer relu5_1/dw
I0615 14:05:57.412070 29366 net.cpp:406] relu5_1/dw <- conv5_1/dw
I0615 14:05:57.412081 29366 net.cpp:367] relu5_1/dw -> conv5_1/dw (in-place)
I0615 14:05:57.412312 29366 net.cpp:122] Setting up relu5_1/dw
I0615 14:05:57.412330 29366 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0615 14:05:57.412339 29366 net.cpp:137] Memory required for data: 3201229000
I0615 14:05:57.412348 29366 layer_factory.hpp:77] Creating layer conv5_1/sep
I0615 14:05:57.412366 29366 net.cpp:84] Creating Layer conv5_1/sep
I0615 14:05:57.412376 29366 net.cpp:406] conv5_1/sep <- conv5_1/dw
I0615 14:05:57.412389 29366 net.cpp:380] conv5_1/sep -> conv5_1/sep
I0615 14:05:57.418318 29366 net.cpp:122] Setting up conv5_1/sep
I0615 14:05:57.418344 29366 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0615 14:05:57.418354 29366 net.cpp:137] Memory required for data: 3221299400
I0615 14:05:57.418365 29366 layer_factory.hpp:77] Creating layer conv5_1/sep/bn
I0615 14:05:57.418381 29366 net.cpp:84] Creating Layer conv5_1/sep/bn
I0615 14:05:57.418391 29366 net.cpp:406] conv5_1/sep/bn <- conv5_1/sep
I0615 14:05:57.418403 29366 net.cpp:367] conv5_1/sep/bn -> conv5_1/sep (in-place)
I0615 14:05:57.418668 29366 net.cpp:122] Setting up conv5_1/sep/bn
I0615 14:05:57.418689 29366 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0615 14:05:57.418696 29366 net.cpp:137] Memory required for data: 3241369800
I0615 14:05:57.418710 29366 layer_factory.hpp:77] Creating layer conv5_1/sep/scale
I0615 14:05:57.418723 29366 net.cpp:84] Creating Layer conv5_1/sep/scale
I0615 14:05:57.418733 29366 net.cpp:406] conv5_1/sep/scale <- conv5_1/sep
I0615 14:05:57.418745 29366 net.cpp:367] conv5_1/sep/scale -> conv5_1/sep (in-place)
I0615 14:05:57.418820 29366 layer_factory.hpp:77] Creating layer conv5_1/sep/scale
I0615 14:05:57.418975 29366 net.cpp:122] Setting up conv5_1/sep/scale
I0615 14:05:57.418992 29366 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0615 14:05:57.419000 29366 net.cpp:137] Memory required for data: 3261440200
I0615 14:05:57.419013 29366 layer_factory.hpp:77] Creating layer relu5_1/sep
I0615 14:05:57.419028 29366 net.cpp:84] Creating Layer relu5_1/sep
I0615 14:05:57.419037 29366 net.cpp:406] relu5_1/sep <- conv5_1/sep
I0615 14:05:57.419047 29366 net.cpp:367] relu5_1/sep -> conv5_1/sep (in-place)
I0615 14:05:57.419469 29366 net.cpp:122] Setting up relu5_1/sep
I0615 14:05:57.419493 29366 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0615 14:05:57.419502 29366 net.cpp:137] Memory required for data: 3281510600
I0615 14:05:57.419512 29366 layer_factory.hpp:77] Creating layer conv5_2/dw
I0615 14:05:57.419535 29366 net.cpp:84] Creating Layer conv5_2/dw
I0615 14:05:57.419545 29366 net.cpp:406] conv5_2/dw <- conv5_1/sep
I0615 14:05:57.419561 29366 net.cpp:380] conv5_2/dw -> conv5_2/dw
I0615 14:05:57.419775 29366 net.cpp:122] Setting up conv5_2/dw
I0615 14:05:57.419795 29366 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0615 14:05:57.419802 29366 net.cpp:137] Memory required for data: 3301581000
I0615 14:05:57.419812 29366 layer_factory.hpp:77] Creating layer conv5_2/dw/bn
I0615 14:05:57.419826 29366 net.cpp:84] Creating Layer conv5_2/dw/bn
I0615 14:05:57.419834 29366 net.cpp:406] conv5_2/dw/bn <- conv5_2/dw
I0615 14:05:57.419848 29366 net.cpp:367] conv5_2/dw/bn -> conv5_2/dw (in-place)
I0615 14:05:57.420084 29366 net.cpp:122] Setting up conv5_2/dw/bn
I0615 14:05:57.420101 29366 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0615 14:05:57.420109 29366 net.cpp:137] Memory required for data: 3321651400
I0615 14:05:57.420123 29366 layer_factory.hpp:77] Creating layer conv5_2/dw/scale
I0615 14:05:57.420136 29366 net.cpp:84] Creating Layer conv5_2/dw/scale
I0615 14:05:57.420145 29366 net.cpp:406] conv5_2/dw/scale <- conv5_2/dw
I0615 14:05:57.420156 29366 net.cpp:367] conv5_2/dw/scale -> conv5_2/dw (in-place)
I0615 14:05:57.420217 29366 layer_factory.hpp:77] Creating layer conv5_2/dw/scale
I0615 14:05:57.420372 29366 net.cpp:122] Setting up conv5_2/dw/scale
I0615 14:05:57.420388 29366 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0615 14:05:57.420397 29366 net.cpp:137] Memory required for data: 3341721800
I0615 14:05:57.420409 29366 layer_factory.hpp:77] Creating layer relu5_2/dw
I0615 14:05:57.420431 29366 net.cpp:84] Creating Layer relu5_2/dw
I0615 14:05:57.420441 29366 net.cpp:406] relu5_2/dw <- conv5_2/dw
I0615 14:05:57.420454 29366 net.cpp:367] relu5_2/dw -> conv5_2/dw (in-place)
I0615 14:05:57.420688 29366 net.cpp:122] Setting up relu5_2/dw
I0615 14:05:57.420711 29366 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0615 14:05:57.420720 29366 net.cpp:137] Memory required for data: 3361792200
I0615 14:05:57.420729 29366 layer_factory.hpp:77] Creating layer conv5_2/sep
I0615 14:05:57.420747 29366 net.cpp:84] Creating Layer conv5_2/sep
I0615 14:05:57.420758 29366 net.cpp:406] conv5_2/sep <- conv5_2/dw
I0615 14:05:57.420770 29366 net.cpp:380] conv5_2/sep -> conv5_2/sep
I0615 14:05:57.426476 29366 net.cpp:122] Setting up conv5_2/sep
I0615 14:05:57.426501 29366 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0615 14:05:57.426511 29366 net.cpp:137] Memory required for data: 3381862600
I0615 14:05:57.426532 29366 layer_factory.hpp:77] Creating layer conv5_2/sep/bn
I0615 14:05:57.426548 29366 net.cpp:84] Creating Layer conv5_2/sep/bn
I0615 14:05:57.426559 29366 net.cpp:406] conv5_2/sep/bn <- conv5_2/sep
I0615 14:05:57.426571 29366 net.cpp:367] conv5_2/sep/bn -> conv5_2/sep (in-place)
I0615 14:05:57.426826 29366 net.cpp:122] Setting up conv5_2/sep/bn
I0615 14:05:57.426843 29366 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0615 14:05:57.426852 29366 net.cpp:137] Memory required for data: 3401933000
I0615 14:05:57.426870 29366 layer_factory.hpp:77] Creating layer conv5_2/sep/scale
I0615 14:05:57.426892 29366 net.cpp:84] Creating Layer conv5_2/sep/scale
I0615 14:05:57.426914 29366 net.cpp:406] conv5_2/sep/scale <- conv5_2/sep
I0615 14:05:57.426926 29366 net.cpp:367] conv5_2/sep/scale -> conv5_2/sep (in-place)
I0615 14:05:57.426987 29366 layer_factory.hpp:77] Creating layer conv5_2/sep/scale
I0615 14:05:57.427146 29366 net.cpp:122] Setting up conv5_2/sep/scale
I0615 14:05:57.427163 29366 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0615 14:05:57.427171 29366 net.cpp:137] Memory required for data: 3422003400
I0615 14:05:57.427184 29366 layer_factory.hpp:77] Creating layer relu5_2/sep
I0615 14:05:57.427199 29366 net.cpp:84] Creating Layer relu5_2/sep
I0615 14:05:57.427208 29366 net.cpp:406] relu5_2/sep <- conv5_2/sep
I0615 14:05:57.427219 29366 net.cpp:367] relu5_2/sep -> conv5_2/sep (in-place)
I0615 14:05:57.427652 29366 net.cpp:122] Setting up relu5_2/sep
I0615 14:05:57.427677 29366 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0615 14:05:57.427687 29366 net.cpp:137] Memory required for data: 3442073800
I0615 14:05:57.427695 29366 layer_factory.hpp:77] Creating layer conv5_3/dw
I0615 14:05:57.427711 29366 net.cpp:84] Creating Layer conv5_3/dw
I0615 14:05:57.427719 29366 net.cpp:406] conv5_3/dw <- conv5_2/sep
I0615 14:05:57.427736 29366 net.cpp:380] conv5_3/dw -> conv5_3/dw
I0615 14:05:57.427948 29366 net.cpp:122] Setting up conv5_3/dw
I0615 14:05:57.427970 29366 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0615 14:05:57.427979 29366 net.cpp:137] Memory required for data: 3462144200
I0615 14:05:57.427989 29366 layer_factory.hpp:77] Creating layer conv5_3/dw/bn
I0615 14:05:57.428002 29366 net.cpp:84] Creating Layer conv5_3/dw/bn
I0615 14:05:57.428011 29366 net.cpp:406] conv5_3/dw/bn <- conv5_3/dw
I0615 14:05:57.428030 29366 net.cpp:367] conv5_3/dw/bn -> conv5_3/dw (in-place)
I0615 14:05:57.428277 29366 net.cpp:122] Setting up conv5_3/dw/bn
I0615 14:05:57.428294 29366 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0615 14:05:57.428303 29366 net.cpp:137] Memory required for data: 3482214600
I0615 14:05:57.428316 29366 layer_factory.hpp:77] Creating layer conv5_3/dw/scale
I0615 14:05:57.428329 29366 net.cpp:84] Creating Layer conv5_3/dw/scale
I0615 14:05:57.428339 29366 net.cpp:406] conv5_3/dw/scale <- conv5_3/dw
I0615 14:05:57.428349 29366 net.cpp:367] conv5_3/dw/scale -> conv5_3/dw (in-place)
I0615 14:05:57.428408 29366 layer_factory.hpp:77] Creating layer conv5_3/dw/scale
I0615 14:05:57.428580 29366 net.cpp:122] Setting up conv5_3/dw/scale
I0615 14:05:57.428599 29366 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0615 14:05:57.428607 29366 net.cpp:137] Memory required for data: 3502285000
I0615 14:05:57.428619 29366 layer_factory.hpp:77] Creating layer relu5_3/dw
I0615 14:05:57.428632 29366 net.cpp:84] Creating Layer relu5_3/dw
I0615 14:05:57.428640 29366 net.cpp:406] relu5_3/dw <- conv5_3/dw
I0615 14:05:57.428654 29366 net.cpp:367] relu5_3/dw -> conv5_3/dw (in-place)
I0615 14:05:57.428881 29366 net.cpp:122] Setting up relu5_3/dw
I0615 14:05:57.428900 29366 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0615 14:05:57.428910 29366 net.cpp:137] Memory required for data: 3522355400
I0615 14:05:57.428917 29366 layer_factory.hpp:77] Creating layer conv5_3/sep
I0615 14:05:57.428936 29366 net.cpp:84] Creating Layer conv5_3/sep
I0615 14:05:57.428946 29366 net.cpp:406] conv5_3/sep <- conv5_3/dw
I0615 14:05:57.428959 29366 net.cpp:380] conv5_3/sep -> conv5_3/sep
I0615 14:05:57.434661 29366 net.cpp:122] Setting up conv5_3/sep
I0615 14:05:57.434686 29366 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0615 14:05:57.434696 29366 net.cpp:137] Memory required for data: 3542425800
I0615 14:05:57.434707 29366 layer_factory.hpp:77] Creating layer conv5_3/sep/bn
I0615 14:05:57.434725 29366 net.cpp:84] Creating Layer conv5_3/sep/bn
I0615 14:05:57.434734 29366 net.cpp:406] conv5_3/sep/bn <- conv5_3/sep
I0615 14:05:57.434746 29366 net.cpp:367] conv5_3/sep/bn -> conv5_3/sep (in-place)
I0615 14:05:57.435000 29366 net.cpp:122] Setting up conv5_3/sep/bn
I0615 14:05:57.435019 29366 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0615 14:05:57.435035 29366 net.cpp:137] Memory required for data: 3562496200
I0615 14:05:57.435060 29366 layer_factory.hpp:77] Creating layer conv5_3/sep/scale
I0615 14:05:57.435078 29366 net.cpp:84] Creating Layer conv5_3/sep/scale
I0615 14:05:57.435088 29366 net.cpp:406] conv5_3/sep/scale <- conv5_3/sep
I0615 14:05:57.435099 29366 net.cpp:367] conv5_3/sep/scale -> conv5_3/sep (in-place)
I0615 14:05:57.435160 29366 layer_factory.hpp:77] Creating layer conv5_3/sep/scale
I0615 14:05:57.435322 29366 net.cpp:122] Setting up conv5_3/sep/scale
I0615 14:05:57.435338 29366 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0615 14:05:57.435346 29366 net.cpp:137] Memory required for data: 3582566600
I0615 14:05:57.435358 29366 layer_factory.hpp:77] Creating layer relu5_3/sep
I0615 14:05:57.435369 29366 net.cpp:84] Creating Layer relu5_3/sep
I0615 14:05:57.435379 29366 net.cpp:406] relu5_3/sep <- conv5_3/sep
I0615 14:05:57.435392 29366 net.cpp:367] relu5_3/sep -> conv5_3/sep (in-place)
I0615 14:05:57.435634 29366 net.cpp:122] Setting up relu5_3/sep
I0615 14:05:57.435654 29366 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0615 14:05:57.435663 29366 net.cpp:137] Memory required for data: 3602637000
I0615 14:05:57.435672 29366 layer_factory.hpp:77] Creating layer conv5_4/dw
I0615 14:05:57.435689 29366 net.cpp:84] Creating Layer conv5_4/dw
I0615 14:05:57.435699 29366 net.cpp:406] conv5_4/dw <- conv5_3/sep
I0615 14:05:57.435714 29366 net.cpp:380] conv5_4/dw -> conv5_4/dw
I0615 14:05:57.435930 29366 net.cpp:122] Setting up conv5_4/dw
I0615 14:05:57.435947 29366 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0615 14:05:57.435956 29366 net.cpp:137] Memory required for data: 3622707400
I0615 14:05:57.435966 29366 layer_factory.hpp:77] Creating layer conv5_4/dw/bn
I0615 14:05:57.435981 29366 net.cpp:84] Creating Layer conv5_4/dw/bn
I0615 14:05:57.435992 29366 net.cpp:406] conv5_4/dw/bn <- conv5_4/dw
I0615 14:05:57.436002 29366 net.cpp:367] conv5_4/dw/bn -> conv5_4/dw (in-place)
I0615 14:05:57.436255 29366 net.cpp:122] Setting up conv5_4/dw/bn
I0615 14:05:57.436272 29366 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0615 14:05:57.436280 29366 net.cpp:137] Memory required for data: 3642777800
I0615 14:05:57.436295 29366 layer_factory.hpp:77] Creating layer conv5_4/dw/scale
I0615 14:05:57.436307 29366 net.cpp:84] Creating Layer conv5_4/dw/scale
I0615 14:05:57.436316 29366 net.cpp:406] conv5_4/dw/scale <- conv5_4/dw
I0615 14:05:57.436331 29366 net.cpp:367] conv5_4/dw/scale -> conv5_4/dw (in-place)
I0615 14:05:57.436386 29366 layer_factory.hpp:77] Creating layer conv5_4/dw/scale
I0615 14:05:57.436556 29366 net.cpp:122] Setting up conv5_4/dw/scale
I0615 14:05:57.436578 29366 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0615 14:05:57.436588 29366 net.cpp:137] Memory required for data: 3662848200
I0615 14:05:57.436600 29366 layer_factory.hpp:77] Creating layer relu5_4/dw
I0615 14:05:57.436611 29366 net.cpp:84] Creating Layer relu5_4/dw
I0615 14:05:57.436620 29366 net.cpp:406] relu5_4/dw <- conv5_4/dw
I0615 14:05:57.436630 29366 net.cpp:367] relu5_4/dw -> conv5_4/dw (in-place)
I0615 14:05:57.437048 29366 net.cpp:122] Setting up relu5_4/dw
I0615 14:05:57.437070 29366 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0615 14:05:57.437079 29366 net.cpp:137] Memory required for data: 3682918600
I0615 14:05:57.437088 29366 layer_factory.hpp:77] Creating layer conv5_4/sep
I0615 14:05:57.437106 29366 net.cpp:84] Creating Layer conv5_4/sep
I0615 14:05:57.437117 29366 net.cpp:406] conv5_4/sep <- conv5_4/dw
I0615 14:05:57.437134 29366 net.cpp:380] conv5_4/sep -> conv5_4/sep
I0615 14:05:57.442837 29366 net.cpp:122] Setting up conv5_4/sep
I0615 14:05:57.442862 29366 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0615 14:05:57.442873 29366 net.cpp:137] Memory required for data: 3702989000
I0615 14:05:57.442883 29366 layer_factory.hpp:77] Creating layer conv5_4/sep/bn
I0615 14:05:57.442900 29366 net.cpp:84] Creating Layer conv5_4/sep/bn
I0615 14:05:57.442910 29366 net.cpp:406] conv5_4/sep/bn <- conv5_4/sep
I0615 14:05:57.442925 29366 net.cpp:367] conv5_4/sep/bn -> conv5_4/sep (in-place)
I0615 14:05:57.443197 29366 net.cpp:122] Setting up conv5_4/sep/bn
I0615 14:05:57.443226 29366 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0615 14:05:57.443235 29366 net.cpp:137] Memory required for data: 3723059400
I0615 14:05:57.443249 29366 layer_factory.hpp:77] Creating layer conv5_4/sep/scale
I0615 14:05:57.443262 29366 net.cpp:84] Creating Layer conv5_4/sep/scale
I0615 14:05:57.443272 29366 net.cpp:406] conv5_4/sep/scale <- conv5_4/sep
I0615 14:05:57.443287 29366 net.cpp:367] conv5_4/sep/scale -> conv5_4/sep (in-place)
I0615 14:05:57.443346 29366 layer_factory.hpp:77] Creating layer conv5_4/sep/scale
I0615 14:05:57.443508 29366 net.cpp:122] Setting up conv5_4/sep/scale
I0615 14:05:57.443534 29366 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0615 14:05:57.443542 29366 net.cpp:137] Memory required for data: 3743129800
I0615 14:05:57.443555 29366 layer_factory.hpp:77] Creating layer relu5_4/sep
I0615 14:05:57.443567 29366 net.cpp:84] Creating Layer relu5_4/sep
I0615 14:05:57.443577 29366 net.cpp:406] relu5_4/sep <- conv5_4/sep
I0615 14:05:57.443586 29366 net.cpp:367] relu5_4/sep -> conv5_4/sep (in-place)
I0615 14:05:57.443823 29366 net.cpp:122] Setting up relu5_4/sep
I0615 14:05:57.443842 29366 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0615 14:05:57.443850 29366 net.cpp:137] Memory required for data: 3763200200
I0615 14:05:57.443858 29366 layer_factory.hpp:77] Creating layer conv5_5/dw
I0615 14:05:57.443872 29366 net.cpp:84] Creating Layer conv5_5/dw
I0615 14:05:57.443882 29366 net.cpp:406] conv5_5/dw <- conv5_4/sep
I0615 14:05:57.443898 29366 net.cpp:380] conv5_5/dw -> conv5_5/dw
I0615 14:05:57.444113 29366 net.cpp:122] Setting up conv5_5/dw
I0615 14:05:57.444131 29366 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0615 14:05:57.444140 29366 net.cpp:137] Memory required for data: 3783270600
I0615 14:05:57.444151 29366 layer_factory.hpp:77] Creating layer conv5_5/dw/bn
I0615 14:05:57.444164 29366 net.cpp:84] Creating Layer conv5_5/dw/bn
I0615 14:05:57.444174 29366 net.cpp:406] conv5_5/dw/bn <- conv5_5/dw
I0615 14:05:57.444187 29366 net.cpp:367] conv5_5/dw/bn -> conv5_5/dw (in-place)
I0615 14:05:57.444440 29366 net.cpp:122] Setting up conv5_5/dw/bn
I0615 14:05:57.444458 29366 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0615 14:05:57.444466 29366 net.cpp:137] Memory required for data: 3803341000
I0615 14:05:57.444506 29366 layer_factory.hpp:77] Creating layer conv5_5/dw/scale
I0615 14:05:57.444531 29366 net.cpp:84] Creating Layer conv5_5/dw/scale
I0615 14:05:57.444541 29366 net.cpp:406] conv5_5/dw/scale <- conv5_5/dw
I0615 14:05:57.444553 29366 net.cpp:367] conv5_5/dw/scale -> conv5_5/dw (in-place)
I0615 14:05:57.444617 29366 layer_factory.hpp:77] Creating layer conv5_5/dw/scale
I0615 14:05:57.444780 29366 net.cpp:122] Setting up conv5_5/dw/scale
I0615 14:05:57.444797 29366 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0615 14:05:57.444805 29366 net.cpp:137] Memory required for data: 3823411400
I0615 14:05:57.444818 29366 layer_factory.hpp:77] Creating layer relu5_5/dw
I0615 14:05:57.444833 29366 net.cpp:84] Creating Layer relu5_5/dw
I0615 14:05:57.444842 29366 net.cpp:406] relu5_5/dw <- conv5_5/dw
I0615 14:05:57.444852 29366 net.cpp:367] relu5_5/dw -> conv5_5/dw (in-place)
I0615 14:05:57.445289 29366 net.cpp:122] Setting up relu5_5/dw
I0615 14:05:57.445310 29366 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0615 14:05:57.445319 29366 net.cpp:137] Memory required for data: 3843481800
I0615 14:05:57.445327 29366 layer_factory.hpp:77] Creating layer conv5_5/sep
I0615 14:05:57.445348 29366 net.cpp:84] Creating Layer conv5_5/sep
I0615 14:05:57.445358 29366 net.cpp:406] conv5_5/sep <- conv5_5/dw
I0615 14:05:57.445374 29366 net.cpp:380] conv5_5/sep -> conv5_5/sep
I0615 14:05:57.451136 29366 net.cpp:122] Setting up conv5_5/sep
I0615 14:05:57.451161 29366 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0615 14:05:57.451171 29366 net.cpp:137] Memory required for data: 3863552200
I0615 14:05:57.451182 29366 layer_factory.hpp:77] Creating layer conv5_5/sep/bn
I0615 14:05:57.451206 29366 net.cpp:84] Creating Layer conv5_5/sep/bn
I0615 14:05:57.451233 29366 net.cpp:406] conv5_5/sep/bn <- conv5_5/sep
I0615 14:05:57.451246 29366 net.cpp:367] conv5_5/sep/bn -> conv5_5/sep (in-place)
I0615 14:05:57.451521 29366 net.cpp:122] Setting up conv5_5/sep/bn
I0615 14:05:57.451540 29366 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0615 14:05:57.451550 29366 net.cpp:137] Memory required for data: 3883622600
I0615 14:05:57.451563 29366 layer_factory.hpp:77] Creating layer conv5_5/sep/scale
I0615 14:05:57.451581 29366 net.cpp:84] Creating Layer conv5_5/sep/scale
I0615 14:05:57.451591 29366 net.cpp:406] conv5_5/sep/scale <- conv5_5/sep
I0615 14:05:57.451601 29366 net.cpp:367] conv5_5/sep/scale -> conv5_5/sep (in-place)
I0615 14:05:57.451663 29366 layer_factory.hpp:77] Creating layer conv5_5/sep/scale
I0615 14:05:57.451829 29366 net.cpp:122] Setting up conv5_5/sep/scale
I0615 14:05:57.451845 29366 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0615 14:05:57.451854 29366 net.cpp:137] Memory required for data: 3903693000
I0615 14:05:57.451866 29366 layer_factory.hpp:77] Creating layer relu5_5/sep
I0615 14:05:57.451877 29366 net.cpp:84] Creating Layer relu5_5/sep
I0615 14:05:57.451886 29366 net.cpp:406] relu5_5/sep <- conv5_5/sep
I0615 14:05:57.451900 29366 net.cpp:367] relu5_5/sep -> conv5_5/sep (in-place)
I0615 14:05:57.452158 29366 net.cpp:122] Setting up relu5_5/sep
I0615 14:05:57.452178 29366 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0615 14:05:57.452185 29366 net.cpp:137] Memory required for data: 3923763400
I0615 14:05:57.452193 29366 layer_factory.hpp:77] Creating layer conv5_6/dw
I0615 14:05:57.452210 29366 net.cpp:84] Creating Layer conv5_6/dw
I0615 14:05:57.452220 29366 net.cpp:406] conv5_6/dw <- conv5_5/sep
I0615 14:05:57.452236 29366 net.cpp:380] conv5_6/dw -> conv5_6/dw
I0615 14:05:57.452450 29366 net.cpp:122] Setting up conv5_6/dw
I0615 14:05:57.452467 29366 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0615 14:05:57.452476 29366 net.cpp:137] Memory required for data: 3928781000
I0615 14:05:57.452486 29366 layer_factory.hpp:77] Creating layer conv5_6/dw/bn
I0615 14:05:57.452502 29366 net.cpp:84] Creating Layer conv5_6/dw/bn
I0615 14:05:57.452512 29366 net.cpp:406] conv5_6/dw/bn <- conv5_6/dw
I0615 14:05:57.452544 29366 net.cpp:367] conv5_6/dw/bn -> conv5_6/dw (in-place)
I0615 14:05:57.452806 29366 net.cpp:122] Setting up conv5_6/dw/bn
I0615 14:05:57.452823 29366 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0615 14:05:57.452831 29366 net.cpp:137] Memory required for data: 3933798600
I0615 14:05:57.452846 29366 layer_factory.hpp:77] Creating layer conv5_6/dw/scale
I0615 14:05:57.452858 29366 net.cpp:84] Creating Layer conv5_6/dw/scale
I0615 14:05:57.452867 29366 net.cpp:406] conv5_6/dw/scale <- conv5_6/dw
I0615 14:05:57.452883 29366 net.cpp:367] conv5_6/dw/scale -> conv5_6/dw (in-place)
I0615 14:05:57.452939 29366 layer_factory.hpp:77] Creating layer conv5_6/dw/scale
I0615 14:05:57.453104 29366 net.cpp:122] Setting up conv5_6/dw/scale
I0615 14:05:57.453120 29366 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0615 14:05:57.453128 29366 net.cpp:137] Memory required for data: 3938816200
I0615 14:05:57.453140 29366 layer_factory.hpp:77] Creating layer relu5_6/dw
I0615 14:05:57.453152 29366 net.cpp:84] Creating Layer relu5_6/dw
I0615 14:05:57.453161 29366 net.cpp:406] relu5_6/dw <- conv5_6/dw
I0615 14:05:57.453171 29366 net.cpp:367] relu5_6/dw -> conv5_6/dw (in-place)
I0615 14:05:57.453618 29366 net.cpp:122] Setting up relu5_6/dw
I0615 14:05:57.453639 29366 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0615 14:05:57.453649 29366 net.cpp:137] Memory required for data: 3943833800
I0615 14:05:57.453657 29366 layer_factory.hpp:77] Creating layer conv5_6/sep
I0615 14:05:57.453678 29366 net.cpp:84] Creating Layer conv5_6/sep
I0615 14:05:57.453689 29366 net.cpp:406] conv5_6/sep <- conv5_6/dw
I0615 14:05:57.453703 29366 net.cpp:380] conv5_6/sep -> conv5_6/sep
I0615 14:05:57.464206 29366 net.cpp:122] Setting up conv5_6/sep
I0615 14:05:57.464233 29366 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0615 14:05:57.464251 29366 net.cpp:137] Memory required for data: 3953869000
I0615 14:05:57.464273 29366 layer_factory.hpp:77] Creating layer conv5_6/sep/bn
I0615 14:05:57.464292 29366 net.cpp:84] Creating Layer conv5_6/sep/bn
I0615 14:05:57.464301 29366 net.cpp:406] conv5_6/sep/bn <- conv5_6/sep
I0615 14:05:57.464314 29366 net.cpp:367] conv5_6/sep/bn -> conv5_6/sep (in-place)
I0615 14:05:57.464599 29366 net.cpp:122] Setting up conv5_6/sep/bn
I0615 14:05:57.464618 29366 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0615 14:05:57.464627 29366 net.cpp:137] Memory required for data: 3963904200
I0615 14:05:57.464640 29366 layer_factory.hpp:77] Creating layer conv5_6/sep/scale
I0615 14:05:57.464654 29366 net.cpp:84] Creating Layer conv5_6/sep/scale
I0615 14:05:57.464663 29366 net.cpp:406] conv5_6/sep/scale <- conv5_6/sep
I0615 14:05:57.464674 29366 net.cpp:367] conv5_6/sep/scale -> conv5_6/sep (in-place)
I0615 14:05:57.464737 29366 layer_factory.hpp:77] Creating layer conv5_6/sep/scale
I0615 14:05:57.464907 29366 net.cpp:122] Setting up conv5_6/sep/scale
I0615 14:05:57.464925 29366 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0615 14:05:57.464932 29366 net.cpp:137] Memory required for data: 3973939400
I0615 14:05:57.464944 29366 layer_factory.hpp:77] Creating layer relu5_6/sep
I0615 14:05:57.464959 29366 net.cpp:84] Creating Layer relu5_6/sep
I0615 14:05:57.464969 29366 net.cpp:406] relu5_6/sep <- conv5_6/sep
I0615 14:05:57.464980 29366 net.cpp:367] relu5_6/sep -> conv5_6/sep (in-place)
I0615 14:05:57.465227 29366 net.cpp:122] Setting up relu5_6/sep
I0615 14:05:57.465247 29366 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0615 14:05:57.465256 29366 net.cpp:137] Memory required for data: 3983974600
I0615 14:05:57.465265 29366 layer_factory.hpp:77] Creating layer conv6/dw
I0615 14:05:57.465286 29366 net.cpp:84] Creating Layer conv6/dw
I0615 14:05:57.465297 29366 net.cpp:406] conv6/dw <- conv5_6/sep
I0615 14:05:57.465313 29366 net.cpp:380] conv6/dw -> conv6/dw
I0615 14:05:57.465603 29366 net.cpp:122] Setting up conv6/dw
I0615 14:05:57.465622 29366 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0615 14:05:57.465631 29366 net.cpp:137] Memory required for data: 3994009800
I0615 14:05:57.465641 29366 layer_factory.hpp:77] Creating layer conv6/dw/bn
I0615 14:05:57.465653 29366 net.cpp:84] Creating Layer conv6/dw/bn
I0615 14:05:57.465662 29366 net.cpp:406] conv6/dw/bn <- conv6/dw
I0615 14:05:57.465677 29366 net.cpp:367] conv6/dw/bn -> conv6/dw (in-place)
I0615 14:05:57.465937 29366 net.cpp:122] Setting up conv6/dw/bn
I0615 14:05:57.465955 29366 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0615 14:05:57.465963 29366 net.cpp:137] Memory required for data: 4004045000
I0615 14:05:57.465977 29366 layer_factory.hpp:77] Creating layer conv6/dw/scale
I0615 14:05:57.465993 29366 net.cpp:84] Creating Layer conv6/dw/scale
I0615 14:05:57.466003 29366 net.cpp:406] conv6/dw/scale <- conv6/dw
I0615 14:05:57.466014 29366 net.cpp:367] conv6/dw/scale -> conv6/dw (in-place)
I0615 14:05:57.466071 29366 layer_factory.hpp:77] Creating layer conv6/dw/scale
I0615 14:05:57.466240 29366 net.cpp:122] Setting up conv6/dw/scale
I0615 14:05:57.466258 29366 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0615 14:05:57.466265 29366 net.cpp:137] Memory required for data: 4014080200
I0615 14:05:57.466277 29366 layer_factory.hpp:77] Creating layer relu6/dw
I0615 14:05:57.466289 29366 net.cpp:84] Creating Layer relu6/dw
I0615 14:05:57.466298 29366 net.cpp:406] relu6/dw <- conv6/dw
I0615 14:05:57.466312 29366 net.cpp:367] relu6/dw -> conv6/dw (in-place)
I0615 14:05:57.466759 29366 net.cpp:122] Setting up relu6/dw
I0615 14:05:57.466781 29366 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0615 14:05:57.466790 29366 net.cpp:137] Memory required for data: 4024115400
I0615 14:05:57.466799 29366 layer_factory.hpp:77] Creating layer conv6/sep
I0615 14:05:57.466819 29366 net.cpp:84] Creating Layer conv6/sep
I0615 14:05:57.466830 29366 net.cpp:406] conv6/sep <- conv6/dw
I0615 14:05:57.466842 29366 net.cpp:380] conv6/sep -> conv6/sep
I0615 14:05:57.485363 29366 net.cpp:122] Setting up conv6/sep
I0615 14:05:57.485412 29366 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0615 14:05:57.485435 29366 net.cpp:137] Memory required for data: 4034150600
I0615 14:05:57.485448 29366 layer_factory.hpp:77] Creating layer conv6/sep/bn
I0615 14:05:57.485465 29366 net.cpp:84] Creating Layer conv6/sep/bn
I0615 14:05:57.485474 29366 net.cpp:406] conv6/sep/bn <- conv6/sep
I0615 14:05:57.485491 29366 net.cpp:367] conv6/sep/bn -> conv6/sep (in-place)
I0615 14:05:57.485786 29366 net.cpp:122] Setting up conv6/sep/bn
I0615 14:05:57.485805 29366 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0615 14:05:57.485813 29366 net.cpp:137] Memory required for data: 4044185800
I0615 14:05:57.485828 29366 layer_factory.hpp:77] Creating layer conv6/sep/scale
I0615 14:05:57.485841 29366 net.cpp:84] Creating Layer conv6/sep/scale
I0615 14:05:57.485851 29366 net.cpp:406] conv6/sep/scale <- conv6/sep
I0615 14:05:57.485862 29366 net.cpp:367] conv6/sep/scale -> conv6/sep (in-place)
I0615 14:05:57.485926 29366 layer_factory.hpp:77] Creating layer conv6/sep/scale
I0615 14:05:57.486100 29366 net.cpp:122] Setting up conv6/sep/scale
I0615 14:05:57.486117 29366 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0615 14:05:57.486126 29366 net.cpp:137] Memory required for data: 4054221000
I0615 14:05:57.486138 29366 layer_factory.hpp:77] Creating layer relu6/sep
I0615 14:05:57.486150 29366 net.cpp:84] Creating Layer relu6/sep
I0615 14:05:57.486160 29366 net.cpp:406] relu6/sep <- conv6/sep
I0615 14:05:57.486174 29366 net.cpp:367] relu6/sep -> conv6/sep (in-place)
I0615 14:05:57.486619 29366 net.cpp:122] Setting up relu6/sep
I0615 14:05:57.486641 29366 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0615 14:05:57.486650 29366 net.cpp:137] Memory required for data: 4064256200
I0615 14:05:57.486660 29366 layer_factory.hpp:77] Creating layer pool6
I0615 14:05:57.486673 29366 net.cpp:84] Creating Layer pool6
I0615 14:05:57.486682 29366 net.cpp:406] pool6 <- conv6/sep
I0615 14:05:57.486699 29366 net.cpp:380] pool6 -> pool6
I0615 14:05:57.487026 29366 net.cpp:122] Setting up pool6
I0615 14:05:57.487046 29366 net.cpp:129] Top shape: 50 1024 1 1 (51200)
I0615 14:05:57.487056 29366 net.cpp:137] Memory required for data: 4064461000
I0615 14:05:57.487063 29366 layer_factory.hpp:77] Creating layer fc7
I0615 14:05:57.487084 29366 net.cpp:84] Creating Layer fc7
I0615 14:05:57.487095 29366 net.cpp:406] fc7 <- pool6
I0615 14:05:57.487112 29366 net.cpp:380] fc7 -> fc7
I0615 14:05:57.490088 29366 net.cpp:122] Setting up fc7
I0615 14:05:57.490113 29366 net.cpp:129] Top shape: 50 102 1 1 (5100)
I0615 14:05:57.490123 29366 net.cpp:137] Memory required for data: 4064481400
I0615 14:05:57.490134 29366 layer_factory.hpp:77] Creating layer loss
I0615 14:05:57.490151 29366 net.cpp:84] Creating Layer loss
I0615 14:05:57.490161 29366 net.cpp:406] loss <- fc7
I0615 14:05:57.490171 29366 net.cpp:406] loss <- label
I0615 14:05:57.490190 29366 net.cpp:380] loss -> loss
I0615 14:05:57.490212 29366 layer_factory.hpp:77] Creating layer loss
I0615 14:05:57.490825 29366 net.cpp:122] Setting up loss
I0615 14:05:57.490849 29366 net.cpp:129] Top shape: (1)
I0615 14:05:57.490856 29366 net.cpp:132]     with loss weight 1
I0615 14:05:57.490923 29366 net.cpp:137] Memory required for data: 4064481404
I0615 14:05:57.490933 29366 net.cpp:198] loss needs backward computation.
I0615 14:05:57.490942 29366 net.cpp:198] fc7 needs backward computation.
I0615 14:05:57.490952 29366 net.cpp:198] pool6 needs backward computation.
I0615 14:05:57.490960 29366 net.cpp:198] relu6/sep needs backward computation.
I0615 14:05:57.490968 29366 net.cpp:198] conv6/sep/scale needs backward computation.
I0615 14:05:57.490975 29366 net.cpp:198] conv6/sep/bn needs backward computation.
I0615 14:05:57.490983 29366 net.cpp:198] conv6/sep needs backward computation.
I0615 14:05:57.490993 29366 net.cpp:198] relu6/dw needs backward computation.
I0615 14:05:57.491000 29366 net.cpp:198] conv6/dw/scale needs backward computation.
I0615 14:05:57.491008 29366 net.cpp:198] conv6/dw/bn needs backward computation.
I0615 14:05:57.491016 29366 net.cpp:198] conv6/dw needs backward computation.
I0615 14:05:57.491041 29366 net.cpp:198] relu5_6/sep needs backward computation.
I0615 14:05:57.491050 29366 net.cpp:198] conv5_6/sep/scale needs backward computation.
I0615 14:05:57.491060 29366 net.cpp:198] conv5_6/sep/bn needs backward computation.
I0615 14:05:57.491067 29366 net.cpp:198] conv5_6/sep needs backward computation.
I0615 14:05:57.491075 29366 net.cpp:198] relu5_6/dw needs backward computation.
I0615 14:05:57.491083 29366 net.cpp:198] conv5_6/dw/scale needs backward computation.
I0615 14:05:57.491091 29366 net.cpp:198] conv5_6/dw/bn needs backward computation.
I0615 14:05:57.491099 29366 net.cpp:198] conv5_6/dw needs backward computation.
I0615 14:05:57.491107 29366 net.cpp:198] relu5_5/sep needs backward computation.
I0615 14:05:57.491116 29366 net.cpp:198] conv5_5/sep/scale needs backward computation.
I0615 14:05:57.491123 29366 net.cpp:198] conv5_5/sep/bn needs backward computation.
I0615 14:05:57.491132 29366 net.cpp:198] conv5_5/sep needs backward computation.
I0615 14:05:57.491139 29366 net.cpp:198] relu5_5/dw needs backward computation.
I0615 14:05:57.491147 29366 net.cpp:198] conv5_5/dw/scale needs backward computation.
I0615 14:05:57.491155 29366 net.cpp:198] conv5_5/dw/bn needs backward computation.
I0615 14:05:57.491163 29366 net.cpp:198] conv5_5/dw needs backward computation.
I0615 14:05:57.491175 29366 net.cpp:198] relu5_4/sep needs backward computation.
I0615 14:05:57.491184 29366 net.cpp:198] conv5_4/sep/scale needs backward computation.
I0615 14:05:57.491192 29366 net.cpp:198] conv5_4/sep/bn needs backward computation.
I0615 14:05:57.491200 29366 net.cpp:198] conv5_4/sep needs backward computation.
I0615 14:05:57.491209 29366 net.cpp:198] relu5_4/dw needs backward computation.
I0615 14:05:57.491217 29366 net.cpp:198] conv5_4/dw/scale needs backward computation.
I0615 14:05:57.491225 29366 net.cpp:198] conv5_4/dw/bn needs backward computation.
I0615 14:05:57.491233 29366 net.cpp:198] conv5_4/dw needs backward computation.
I0615 14:05:57.491241 29366 net.cpp:198] relu5_3/sep needs backward computation.
I0615 14:05:57.491250 29366 net.cpp:198] conv5_3/sep/scale needs backward computation.
I0615 14:05:57.491257 29366 net.cpp:198] conv5_3/sep/bn needs backward computation.
I0615 14:05:57.491266 29366 net.cpp:198] conv5_3/sep needs backward computation.
I0615 14:05:57.491274 29366 net.cpp:198] relu5_3/dw needs backward computation.
I0615 14:05:57.491282 29366 net.cpp:198] conv5_3/dw/scale needs backward computation.
I0615 14:05:57.491291 29366 net.cpp:198] conv5_3/dw/bn needs backward computation.
I0615 14:05:57.491298 29366 net.cpp:198] conv5_3/dw needs backward computation.
I0615 14:05:57.491307 29366 net.cpp:198] relu5_2/sep needs backward computation.
I0615 14:05:57.491314 29366 net.cpp:198] conv5_2/sep/scale needs backward computation.
I0615 14:05:57.491322 29366 net.cpp:198] conv5_2/sep/bn needs backward computation.
I0615 14:05:57.491331 29366 net.cpp:198] conv5_2/sep needs backward computation.
I0615 14:05:57.491339 29366 net.cpp:198] relu5_2/dw needs backward computation.
I0615 14:05:57.491348 29366 net.cpp:198] conv5_2/dw/scale needs backward computation.
I0615 14:05:57.491356 29366 net.cpp:198] conv5_2/dw/bn needs backward computation.
I0615 14:05:57.491364 29366 net.cpp:198] conv5_2/dw needs backward computation.
I0615 14:05:57.491372 29366 net.cpp:198] relu5_1/sep needs backward computation.
I0615 14:05:57.491380 29366 net.cpp:198] conv5_1/sep/scale needs backward computation.
I0615 14:05:57.491389 29366 net.cpp:198] conv5_1/sep/bn needs backward computation.
I0615 14:05:57.491396 29366 net.cpp:198] conv5_1/sep needs backward computation.
I0615 14:05:57.491405 29366 net.cpp:198] relu5_1/dw needs backward computation.
I0615 14:05:57.491412 29366 net.cpp:198] conv5_1/dw/scale needs backward computation.
I0615 14:05:57.491420 29366 net.cpp:198] conv5_1/dw/bn needs backward computation.
I0615 14:05:57.491428 29366 net.cpp:198] conv5_1/dw needs backward computation.
I0615 14:05:57.491437 29366 net.cpp:198] relu4_2/sep needs backward computation.
I0615 14:05:57.491451 29366 net.cpp:198] conv4_2/sep/scale needs backward computation.
I0615 14:05:57.491467 29366 net.cpp:198] conv4_2/sep/bn needs backward computation.
I0615 14:05:57.491477 29366 net.cpp:198] conv4_2/sep needs backward computation.
I0615 14:05:57.491485 29366 net.cpp:198] relu4_2/dw needs backward computation.
I0615 14:05:57.491493 29366 net.cpp:198] conv4_2/dw/scale needs backward computation.
I0615 14:05:57.491502 29366 net.cpp:198] conv4_2/dw/bn needs backward computation.
I0615 14:05:57.491509 29366 net.cpp:198] conv4_2/dw needs backward computation.
I0615 14:05:57.491526 29366 net.cpp:198] relu4_1/sep needs backward computation.
I0615 14:05:57.491535 29366 net.cpp:198] conv4_1/sep/scale needs backward computation.
I0615 14:05:57.491544 29366 net.cpp:198] conv4_1/sep/bn needs backward computation.
I0615 14:05:57.491551 29366 net.cpp:198] conv4_1/sep needs backward computation.
I0615 14:05:57.491560 29366 net.cpp:198] relu4_1/dw needs backward computation.
I0615 14:05:57.491569 29366 net.cpp:198] conv4_1/dw/scale needs backward computation.
I0615 14:05:57.491576 29366 net.cpp:198] conv4_1/dw/bn needs backward computation.
I0615 14:05:57.491583 29366 net.cpp:198] conv4_1/dw needs backward computation.
I0615 14:05:57.491592 29366 net.cpp:198] relu3_2/sep needs backward computation.
I0615 14:05:57.491600 29366 net.cpp:198] conv3_2/sep/scale needs backward computation.
I0615 14:05:57.491608 29366 net.cpp:198] conv3_2/sep/bn needs backward computation.
I0615 14:05:57.491616 29366 net.cpp:198] conv3_2/sep needs backward computation.
I0615 14:05:57.491624 29366 net.cpp:198] relu3_2/dw needs backward computation.
I0615 14:05:57.491632 29366 net.cpp:198] conv3_2/dw/scale needs backward computation.
I0615 14:05:57.491641 29366 net.cpp:198] conv3_2/dw/bn needs backward computation.
I0615 14:05:57.491648 29366 net.cpp:198] conv3_2/dw needs backward computation.
I0615 14:05:57.491657 29366 net.cpp:198] relu3_1/sep needs backward computation.
I0615 14:05:57.491664 29366 net.cpp:198] conv3_1/sep/scale needs backward computation.
I0615 14:05:57.491672 29366 net.cpp:198] conv3_1/sep/bn needs backward computation.
I0615 14:05:57.491680 29366 net.cpp:198] conv3_1/sep needs backward computation.
I0615 14:05:57.491688 29366 net.cpp:198] relu3_1/dw needs backward computation.
I0615 14:05:57.491696 29366 net.cpp:198] conv3_1/dw/scale needs backward computation.
I0615 14:05:57.491705 29366 net.cpp:198] conv3_1/dw/bn needs backward computation.
I0615 14:05:57.491714 29366 net.cpp:198] conv3_1/dw needs backward computation.
I0615 14:05:57.491721 29366 net.cpp:198] relu2_2/sep needs backward computation.
I0615 14:05:57.491729 29366 net.cpp:198] conv2_2/sep/scale needs backward computation.
I0615 14:05:57.491737 29366 net.cpp:198] conv2_2/sep/bn needs backward computation.
I0615 14:05:57.491745 29366 net.cpp:198] conv2_2/sep needs backward computation.
I0615 14:05:57.491755 29366 net.cpp:198] relu2_2/dw needs backward computation.
I0615 14:05:57.491762 29366 net.cpp:198] conv2_2/dw/scale needs backward computation.
I0615 14:05:57.491770 29366 net.cpp:198] conv2_2/dw/bn needs backward computation.
I0615 14:05:57.491777 29366 net.cpp:198] conv2_2/dw needs backward computation.
I0615 14:05:57.491786 29366 net.cpp:198] relu2_1/sep needs backward computation.
I0615 14:05:57.491794 29366 net.cpp:198] conv2_1/sep/scale needs backward computation.
I0615 14:05:57.491802 29366 net.cpp:198] conv2_1/sep/bn needs backward computation.
I0615 14:05:57.491811 29366 net.cpp:198] conv2_1/sep needs backward computation.
I0615 14:05:57.491818 29366 net.cpp:198] relu2_1/dw needs backward computation.
I0615 14:05:57.491827 29366 net.cpp:198] conv2_1/dw/scale needs backward computation.
I0615 14:05:57.491834 29366 net.cpp:198] conv2_1/dw/bn needs backward computation.
I0615 14:05:57.491842 29366 net.cpp:198] conv2_1/dw needs backward computation.
I0615 14:05:57.491850 29366 net.cpp:198] relu1 needs backward computation.
I0615 14:05:57.491858 29366 net.cpp:198] conv1/scale needs backward computation.
I0615 14:05:57.491866 29366 net.cpp:198] conv1/bn needs backward computation.
I0615 14:05:57.491881 29366 net.cpp:198] conv1 needs backward computation.
I0615 14:05:57.491902 29366 net.cpp:200] data does not need backward computation.
I0615 14:05:57.491910 29366 net.cpp:242] This network produces output loss
I0615 14:05:57.491986 29366 net.cpp:255] Network initialization done.
I0615 14:05:57.492303 29366 solver.cpp:56] Solver scaffolding done.
I0615 14:05:57.500010 29366 caffe.cpp:248] Starting Optimization
I0615 14:05:57.500032 29366 solver.cpp:272] Solving MOBILENET
I0615 14:05:57.500041 29366 solver.cpp:273] Learning Rate Policy: step
I0615 14:05:57.506103 29366 blocking_queue.cpp:49] Waiting for data
I0615 14:05:58.780298 29366 solver.cpp:218] Iteration 0 (0 iter/s, 1.28015s/50 iters), loss = 4.97972
I0615 14:05:58.780570 29366 solver.cpp:237]     Train net output #0: loss = 4.97972 (* 1 = 4.97972 loss)
I0615 14:05:58.780674 29366 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I0615 14:06:56.608541 29366 solver.cpp:218] Iteration 50 (0.864636 iter/s, 57.8278s/50 iters), loss = 4.44373
I0615 14:06:56.608759 29366 solver.cpp:237]     Train net output #0: loss = 4.44373 (* 1 = 4.44373 loss)
I0615 14:06:56.608783 29366 sgd_solver.cpp:105] Iteration 50, lr = 0.01
I0615 14:07:54.382669 29366 solver.cpp:218] Iteration 100 (0.865448 iter/s, 57.7736s/50 iters), loss = 4.24115
I0615 14:07:54.382863 29366 solver.cpp:237]     Train net output #0: loss = 4.24115 (* 1 = 4.24115 loss)
I0615 14:07:54.382886 29366 sgd_solver.cpp:105] Iteration 100, lr = 0.01
I0615 14:08:52.164428 29366 solver.cpp:218] Iteration 150 (0.865333 iter/s, 57.7812s/50 iters), loss = 4.0911
I0615 14:08:52.164593 29366 solver.cpp:237]     Train net output #0: loss = 4.0911 (* 1 = 4.0911 loss)
I0615 14:08:52.164615 29366 sgd_solver.cpp:105] Iteration 150, lr = 0.01
I0615 14:09:49.948981 29366 solver.cpp:218] Iteration 200 (0.865291 iter/s, 57.784s/50 iters), loss = 4.00727
I0615 14:09:49.949164 29366 solver.cpp:237]     Train net output #0: loss = 4.00727 (* 1 = 4.00727 loss)
I0615 14:09:49.949187 29366 sgd_solver.cpp:105] Iteration 200, lr = 0.01
I0615 14:10:47.722820 29366 solver.cpp:218] Iteration 250 (0.865451 iter/s, 57.7733s/50 iters), loss = 3.96016
I0615 14:10:47.722976 29366 solver.cpp:237]     Train net output #0: loss = 3.96016 (* 1 = 3.96016 loss)
I0615 14:10:47.723000 29366 sgd_solver.cpp:105] Iteration 250, lr = 0.01
I0615 14:11:45.496163 29366 solver.cpp:218] Iteration 300 (0.865459 iter/s, 57.7728s/50 iters), loss = 3.95743
I0615 14:11:45.496320 29366 solver.cpp:237]     Train net output #0: loss = 3.95743 (* 1 = 3.95743 loss)
I0615 14:11:45.496343 29366 sgd_solver.cpp:105] Iteration 300, lr = 0.01
I0615 14:12:43.265923 29366 solver.cpp:218] Iteration 350 (0.865512 iter/s, 57.7693s/50 iters), loss = 3.32983
I0615 14:12:43.266060 29366 solver.cpp:237]     Train net output #0: loss = 3.32983 (* 1 = 3.32983 loss)
I0615 14:12:43.266083 29366 sgd_solver.cpp:105] Iteration 350, lr = 0.01
I0615 14:13:41.047015 29366 solver.cpp:218] Iteration 400 (0.865342 iter/s, 57.7806s/50 iters), loss = 3.72394
I0615 14:13:41.047148 29366 solver.cpp:237]     Train net output #0: loss = 3.72394 (* 1 = 3.72394 loss)
I0615 14:13:41.047169 29366 sgd_solver.cpp:105] Iteration 400, lr = 0.01
I0615 14:14:38.813637 29366 solver.cpp:218] Iteration 450 (0.865559 iter/s, 57.7661s/50 iters), loss = 3.64081
I0615 14:14:38.813768 29366 solver.cpp:237]     Train net output #0: loss = 3.64081 (* 1 = 3.64081 loss)
I0615 14:14:38.813789 29366 sgd_solver.cpp:105] Iteration 450, lr = 0.01
I0615 14:15:36.584818 29366 solver.cpp:218] Iteration 500 (0.865491 iter/s, 57.7707s/50 iters), loss = 3.45764
I0615 14:15:36.584957 29366 solver.cpp:237]     Train net output #0: loss = 3.45764 (* 1 = 3.45764 loss)
I0615 14:15:36.584980 29366 sgd_solver.cpp:105] Iteration 500, lr = 0.01
I0615 14:16:34.368077 29366 solver.cpp:218] Iteration 550 (0.86531 iter/s, 57.7828s/50 iters), loss = 3.1433
I0615 14:16:34.368352 29366 solver.cpp:237]     Train net output #0: loss = 3.1433 (* 1 = 3.1433 loss)
I0615 14:16:34.368376 29366 sgd_solver.cpp:105] Iteration 550, lr = 0.01
I0615 14:17:32.146944 29366 solver.cpp:218] Iteration 600 (0.865378 iter/s, 57.7782s/50 iters), loss = 3.08899
I0615 14:17:32.147116 29366 solver.cpp:237]     Train net output #0: loss = 3.08899 (* 1 = 3.08899 loss)
I0615 14:17:32.147138 29366 sgd_solver.cpp:105] Iteration 600, lr = 0.01
I0615 14:18:29.926127 29366 solver.cpp:218] Iteration 650 (0.865372 iter/s, 57.7786s/50 iters), loss = 2.55723
I0615 14:18:29.926301 29366 solver.cpp:237]     Train net output #0: loss = 2.55723 (* 1 = 2.55723 loss)
I0615 14:18:29.926323 29366 sgd_solver.cpp:105] Iteration 650, lr = 0.01
I0615 14:19:27.702567 29366 solver.cpp:218] Iteration 700 (0.865413 iter/s, 57.7759s/50 iters), loss = 2.86481
I0615 14:19:27.702734 29366 solver.cpp:237]     Train net output #0: loss = 2.86481 (* 1 = 2.86481 loss)
I0615 14:19:27.702756 29366 sgd_solver.cpp:105] Iteration 700, lr = 0.01
I0615 14:20:25.491804 29366 solver.cpp:218] Iteration 750 (0.865221 iter/s, 57.7887s/50 iters), loss = 2.59333
I0615 14:20:25.491971 29366 solver.cpp:237]     Train net output #0: loss = 2.59333 (* 1 = 2.59333 loss)
I0615 14:20:25.491997 29366 sgd_solver.cpp:105] Iteration 750, lr = 0.01
I0615 14:21:23.272697 29366 solver.cpp:218] Iteration 800 (0.865346 iter/s, 57.7804s/50 iters), loss = 2.95316
I0615 14:21:23.272832 29366 solver.cpp:237]     Train net output #0: loss = 2.95316 (* 1 = 2.95316 loss)
I0615 14:21:23.272855 29366 sgd_solver.cpp:105] Iteration 800, lr = 0.01
I0615 14:22:21.054124 29366 solver.cpp:218] Iteration 850 (0.865338 iter/s, 57.7809s/50 iters), loss = 2.68804
I0615 14:22:21.054280 29366 solver.cpp:237]     Train net output #0: loss = 2.68804 (* 1 = 2.68804 loss)
I0615 14:22:21.054303 29366 sgd_solver.cpp:105] Iteration 850, lr = 0.01
I0615 14:23:18.826416 29366 solver.cpp:218] Iteration 900 (0.865475 iter/s, 57.7718s/50 iters), loss = 2.49474
I0615 14:23:18.826580 29366 solver.cpp:237]     Train net output #0: loss = 2.49474 (* 1 = 2.49474 loss)
I0615 14:23:18.826601 29366 sgd_solver.cpp:105] Iteration 900, lr = 0.01
I0615 14:24:16.608979 29366 solver.cpp:218] Iteration 950 (0.865321 iter/s, 57.782s/50 iters), loss = 2.70497
I0615 14:24:16.609232 29366 solver.cpp:237]     Train net output #0: loss = 2.70497 (* 1 = 2.70497 loss)
I0615 14:24:16.609254 29366 sgd_solver.cpp:105] Iteration 950, lr = 0.01
I0615 14:25:14.379015 29366 solver.cpp:218] Iteration 1000 (0.86551 iter/s, 57.7694s/50 iters), loss = 2.36948
I0615 14:25:14.379180 29366 solver.cpp:237]     Train net output #0: loss = 2.36948 (* 1 = 2.36948 loss)
I0615 14:25:14.379204 29366 sgd_solver.cpp:105] Iteration 1000, lr = 0.01
I0615 14:26:12.162158 29366 solver.cpp:218] Iteration 1050 (0.865313 iter/s, 57.7826s/50 iters), loss = 2.65489
I0615 14:26:12.162422 29366 solver.cpp:237]     Train net output #0: loss = 2.65489 (* 1 = 2.65489 loss)
I0615 14:26:12.162446 29366 sgd_solver.cpp:105] Iteration 1050, lr = 0.01
I0615 14:27:09.941440 29366 solver.cpp:218] Iteration 1100 (0.865372 iter/s, 57.7786s/50 iters), loss = 2.42885
I0615 14:27:09.941604 29366 solver.cpp:237]     Train net output #0: loss = 2.42885 (* 1 = 2.42885 loss)
I0615 14:27:09.941632 29366 sgd_solver.cpp:105] Iteration 1100, lr = 0.01
I0615 14:28:07.704169 29366 solver.cpp:218] Iteration 1150 (0.865621 iter/s, 57.762s/50 iters), loss = 2.49735
I0615 14:28:07.704330 29366 solver.cpp:237]     Train net output #0: loss = 2.49735 (* 1 = 2.49735 loss)
I0615 14:28:07.704352 29366 sgd_solver.cpp:105] Iteration 1150, lr = 0.01
I0615 14:29:05.466773 29366 solver.cpp:218] Iteration 1200 (0.865622 iter/s, 57.7619s/50 iters), loss = 2.23495
I0615 14:29:05.466897 29366 solver.cpp:237]     Train net output #0: loss = 2.23495 (* 1 = 2.23495 loss)
I0615 14:29:05.466919 29366 sgd_solver.cpp:105] Iteration 1200, lr = 0.01
I0615 14:30:03.231487 29366 solver.cpp:218] Iteration 1250 (0.86559 iter/s, 57.764s/50 iters), loss = 2.30315
I0615 14:30:03.231657 29366 solver.cpp:237]     Train net output #0: loss = 2.30315 (* 1 = 2.30315 loss)
I0615 14:30:03.231680 29366 sgd_solver.cpp:105] Iteration 1250, lr = 0.01
I0615 14:31:00.982300 29366 solver.cpp:218] Iteration 1300 (0.865799 iter/s, 57.7501s/50 iters), loss = 1.88027
I0615 14:31:00.982527 29366 solver.cpp:237]     Train net output #0: loss = 1.88027 (* 1 = 1.88027 loss)
I0615 14:31:00.982550 29366 sgd_solver.cpp:105] Iteration 1300, lr = 0.01
I0615 14:31:58.745828 29366 solver.cpp:218] Iteration 1350 (0.865609 iter/s, 57.7628s/50 iters), loss = 2.16316
I0615 14:31:58.745975 29366 solver.cpp:237]     Train net output #0: loss = 2.16316 (* 1 = 2.16316 loss)
I0615 14:31:58.746004 29366 sgd_solver.cpp:105] Iteration 1350, lr = 0.01
I0615 14:32:56.502068 29366 solver.cpp:218] Iteration 1400 (0.865718 iter/s, 57.7556s/50 iters), loss = 2.18619
I0615 14:32:56.502190 29366 solver.cpp:237]     Train net output #0: loss = 2.18619 (* 1 = 2.18619 loss)
I0615 14:32:56.502213 29366 sgd_solver.cpp:105] Iteration 1400, lr = 0.01
I0615 14:33:54.273722 29366 solver.cpp:218] Iteration 1450 (0.865486 iter/s, 57.771s/50 iters), loss = 2.16169
I0615 14:33:54.273876 29366 solver.cpp:237]     Train net output #0: loss = 2.16169 (* 1 = 2.16169 loss)
I0615 14:33:54.273898 29366 sgd_solver.cpp:105] Iteration 1450, lr = 0.01
I0615 14:34:52.038755 29366 solver.cpp:218] Iteration 1500 (0.865586 iter/s, 57.7643s/50 iters), loss = 2.18921
I0615 14:34:52.038887 29366 solver.cpp:237]     Train net output #0: loss = 2.18921 (* 1 = 2.18921 loss)
I0615 14:34:52.038909 29366 sgd_solver.cpp:105] Iteration 1500, lr = 0.01
I0615 14:35:49.797782 29366 solver.cpp:218] Iteration 1550 (0.865676 iter/s, 57.7584s/50 iters), loss = 2.21689
I0615 14:35:49.797905 29366 solver.cpp:237]     Train net output #0: loss = 2.21689 (* 1 = 2.21689 loss)
I0615 14:35:49.797927 29366 sgd_solver.cpp:105] Iteration 1550, lr = 0.01
I0615 14:36:47.556283 29366 solver.cpp:218] Iteration 1600 (0.865684 iter/s, 57.7578s/50 iters), loss = 2.35963
I0615 14:36:47.556479 29366 solver.cpp:237]     Train net output #0: loss = 2.35963 (* 1 = 2.35963 loss)
I0615 14:36:47.556504 29366 sgd_solver.cpp:105] Iteration 1600, lr = 0.01
I0615 14:37:45.327680 29366 solver.cpp:218] Iteration 1650 (0.865491 iter/s, 57.7707s/50 iters), loss = 2.13158
I0615 14:37:45.327803 29366 solver.cpp:237]     Train net output #0: loss = 2.13158 (* 1 = 2.13158 loss)
I0615 14:37:45.327831 29366 sgd_solver.cpp:105] Iteration 1650, lr = 0.01
I0615 14:38:43.097156 29366 solver.cpp:218] Iteration 1700 (0.865519 iter/s, 57.7688s/50 iters), loss = 1.94391
I0615 14:38:43.097295 29366 solver.cpp:237]     Train net output #0: loss = 1.94391 (* 1 = 1.94391 loss)
I0615 14:38:43.097317 29366 sgd_solver.cpp:105] Iteration 1700, lr = 0.01
I0615 14:39:40.867382 29366 solver.cpp:218] Iteration 1750 (0.865508 iter/s, 57.7696s/50 iters), loss = 1.70147
I0615 14:39:40.867504 29366 solver.cpp:237]     Train net output #0: loss = 1.70147 (* 1 = 1.70147 loss)
I0615 14:39:40.867534 29366 sgd_solver.cpp:105] Iteration 1750, lr = 0.01
I0615 14:40:38.637217 29366 solver.cpp:218] Iteration 1800 (0.865513 iter/s, 57.7692s/50 iters), loss = 1.94966
I0615 14:40:38.637341 29366 solver.cpp:237]     Train net output #0: loss = 1.94966 (* 1 = 1.94966 loss)
I0615 14:40:38.637363 29366 sgd_solver.cpp:105] Iteration 1800, lr = 0.01
I0615 14:41:36.396603 29366 solver.cpp:218] Iteration 1850 (0.86567 iter/s, 57.7587s/50 iters), loss = 1.58244
I0615 14:41:36.396917 29366 solver.cpp:237]     Train net output #0: loss = 1.58244 (* 1 = 1.58244 loss)
I0615 14:41:36.396939 29366 sgd_solver.cpp:105] Iteration 1850, lr = 0.01
I0615 14:42:34.162374 29366 solver.cpp:218] Iteration 1900 (0.865577 iter/s, 57.7649s/50 iters), loss = 1.55721
I0615 14:42:34.162503 29366 solver.cpp:237]     Train net output #0: loss = 1.55721 (* 1 = 1.55721 loss)
I0615 14:42:34.162533 29366 sgd_solver.cpp:105] Iteration 1900, lr = 0.01
I0615 14:43:31.919075 29366 solver.cpp:218] Iteration 1950 (0.86571 iter/s, 57.756s/50 iters), loss = 1.96486
I0615 14:43:31.919234 29366 solver.cpp:237]     Train net output #0: loss = 1.96486 (* 1 = 1.96486 loss)
I0615 14:43:31.919255 29366 sgd_solver.cpp:105] Iteration 1950, lr = 0.01
I0615 14:44:29.691416 29366 solver.cpp:218] Iteration 2000 (0.865477 iter/s, 57.7716s/50 iters), loss = 1.30086
I0615 14:44:29.691597 29366 solver.cpp:237]     Train net output #0: loss = 1.30086 (* 1 = 1.30086 loss)
I0615 14:44:29.691620 29366 sgd_solver.cpp:105] Iteration 2000, lr = 0.01
I0615 14:45:27.453364 29366 solver.cpp:218] Iteration 2050 (0.865634 iter/s, 57.7611s/50 iters), loss = 1.82008
I0615 14:45:27.453502 29366 solver.cpp:237]     Train net output #0: loss = 1.82008 (* 1 = 1.82008 loss)
I0615 14:45:27.453529 29366 sgd_solver.cpp:105] Iteration 2050, lr = 0.01
I0615 14:46:25.216936 29366 solver.cpp:218] Iteration 2100 (0.865609 iter/s, 57.7628s/50 iters), loss = 1.58203
I0615 14:46:25.217072 29366 solver.cpp:237]     Train net output #0: loss = 1.58203 (* 1 = 1.58203 loss)
I0615 14:46:25.217095 29366 sgd_solver.cpp:105] Iteration 2100, lr = 0.01
I0615 14:47:23.001011 29366 solver.cpp:218] Iteration 2150 (0.865302 iter/s, 57.7833s/50 iters), loss = 1.45545
I0615 14:47:23.001210 29366 solver.cpp:237]     Train net output #0: loss = 1.45545 (* 1 = 1.45545 loss)
I0615 14:47:23.001232 29366 sgd_solver.cpp:105] Iteration 2150, lr = 0.01
I0615 14:48:20.778856 29366 solver.cpp:218] Iteration 2200 (0.865396 iter/s, 57.777s/50 iters), loss = 1.91711
I0615 14:48:20.778980 29366 solver.cpp:237]     Train net output #0: loss = 1.91711 (* 1 = 1.91711 loss)
I0615 14:48:20.779000 29366 sgd_solver.cpp:105] Iteration 2200, lr = 0.01
I0615 14:49:18.620667 29366 solver.cpp:218] Iteration 2250 (0.864438 iter/s, 57.8411s/50 iters), loss = 1.36238
I0615 14:49:18.620811 29366 solver.cpp:237]     Train net output #0: loss = 1.36238 (* 1 = 1.36238 loss)
I0615 14:49:18.620833 29366 sgd_solver.cpp:105] Iteration 2250, lr = 0.01
I0615 14:50:16.410392 29366 solver.cpp:218] Iteration 2300 (0.865217 iter/s, 57.789s/50 iters), loss = 0.825037
I0615 14:50:16.410560 29366 solver.cpp:237]     Train net output #0: loss = 0.825037 (* 1 = 0.825037 loss)
I0615 14:50:16.410585 29366 sgd_solver.cpp:105] Iteration 2300, lr = 0.01
I0615 14:51:14.186112 29366 solver.cpp:218] Iteration 2350 (0.865427 iter/s, 57.7749s/50 iters), loss = 1.46111
I0615 14:51:14.186269 29366 solver.cpp:237]     Train net output #0: loss = 1.46111 (* 1 = 1.46111 loss)
I0615 14:51:14.186291 29366 sgd_solver.cpp:105] Iteration 2350, lr = 0.01
I0615 14:52:11.961937 29366 solver.cpp:218] Iteration 2400 (0.865426 iter/s, 57.775s/50 iters), loss = 1.57136
I0615 14:52:11.962100 29366 solver.cpp:237]     Train net output #0: loss = 1.57136 (* 1 = 1.57136 loss)
I0615 14:52:11.962122 29366 sgd_solver.cpp:105] Iteration 2400, lr = 0.01
I0615 14:53:09.734866 29366 solver.cpp:218] Iteration 2450 (0.865469 iter/s, 57.7721s/50 iters), loss = 1.22182
I0615 14:53:09.735054 29366 solver.cpp:237]     Train net output #0: loss = 1.22182 (* 1 = 1.22182 loss)
I0615 14:53:09.735080 29366 sgd_solver.cpp:105] Iteration 2450, lr = 0.01
I0615 14:54:07.503100 29366 solver.cpp:218] Iteration 2500 (0.86554 iter/s, 57.7674s/50 iters), loss = 1.08379
I0615 14:54:07.503552 29366 solver.cpp:237]     Train net output #0: loss = 1.08379 (* 1 = 1.08379 loss)
I0615 14:54:07.503577 29366 sgd_solver.cpp:105] Iteration 2500, lr = 0.01
I0615 14:55:05.273388 29366 solver.cpp:218] Iteration 2550 (0.865513 iter/s, 57.7692s/50 iters), loss = 1.66394
I0615 14:55:05.273561 29366 solver.cpp:237]     Train net output #0: loss = 1.66394 (* 1 = 1.66394 loss)
I0615 14:55:05.273584 29366 sgd_solver.cpp:105] Iteration 2550, lr = 0.01
I0615 14:56:03.052253 29366 solver.cpp:218] Iteration 2600 (0.86538 iter/s, 57.7781s/50 iters), loss = 0.930502
I0615 14:56:03.052408 29366 solver.cpp:237]     Train net output #0: loss = 0.930502 (* 1 = 0.930502 loss)
I0615 14:56:03.052430 29366 sgd_solver.cpp:105] Iteration 2600, lr = 0.01
I0615 14:57:00.880841 29366 solver.cpp:218] Iteration 2650 (0.864636 iter/s, 57.8278s/50 iters), loss = 0.922294
I0615 14:57:00.881044 29366 solver.cpp:237]     Train net output #0: loss = 0.922294 (* 1 = 0.922294 loss)
I0615 14:57:00.881067 29366 sgd_solver.cpp:105] Iteration 2650, lr = 0.01
I0615 14:57:58.654848 29366 solver.cpp:218] Iteration 2700 (0.865454 iter/s, 57.7732s/50 iters), loss = 0.917728
I0615 14:57:58.657213 29366 solver.cpp:237]     Train net output #0: loss = 0.917728 (* 1 = 0.917728 loss)
I0615 14:57:58.657238 29366 sgd_solver.cpp:105] Iteration 2700, lr = 0.01
I0615 14:58:56.436544 29366 solver.cpp:218] Iteration 2750 (0.865371 iter/s, 57.7787s/50 iters), loss = 0.97627
I0615 14:58:56.436751 29366 solver.cpp:237]     Train net output #0: loss = 0.97627 (* 1 = 0.97627 loss)
I0615 14:58:56.436774 29366 sgd_solver.cpp:105] Iteration 2750, lr = 0.01
I0615 14:59:54.218227 29366 solver.cpp:218] Iteration 2800 (0.865338 iter/s, 57.7809s/50 iters), loss = 0.802646
I0615 14:59:54.218410 29366 solver.cpp:237]     Train net output #0: loss = 0.802646 (* 1 = 0.802646 loss)
I0615 14:59:54.218432 29366 sgd_solver.cpp:105] Iteration 2800, lr = 0.01
I0615 15:00:51.995919 29366 solver.cpp:218] Iteration 2850 (0.865398 iter/s, 57.7769s/50 iters), loss = 0.936056
I0615 15:00:51.996063 29366 solver.cpp:237]     Train net output #0: loss = 0.936056 (* 1 = 0.936056 loss)
I0615 15:00:51.996085 29366 sgd_solver.cpp:105] Iteration 2850, lr = 0.01
I0615 15:01:49.772115 29366 solver.cpp:218] Iteration 2900 (0.865418 iter/s, 57.7755s/50 iters), loss = 1.08393
I0615 15:01:49.772253 29366 solver.cpp:237]     Train net output #0: loss = 1.08393 (* 1 = 1.08393 loss)
I0615 15:01:49.772274 29366 sgd_solver.cpp:105] Iteration 2900, lr = 0.01
I0615 15:02:47.546015 29366 solver.cpp:218] Iteration 2950 (0.865452 iter/s, 57.7733s/50 iters), loss = 1.18673
I0615 15:02:47.546175 29366 solver.cpp:237]     Train net output #0: loss = 1.18673 (* 1 = 1.18673 loss)
I0615 15:02:47.546198 29366 sgd_solver.cpp:105] Iteration 2950, lr = 0.01
I0615 15:03:45.333403 29366 solver.cpp:218] Iteration 3000 (0.86525 iter/s, 57.7868s/50 iters), loss = 0.92521
I0615 15:03:45.333556 29366 solver.cpp:237]     Train net output #0: loss = 0.92521 (* 1 = 0.92521 loss)
I0615 15:03:45.333580 29366 sgd_solver.cpp:105] Iteration 3000, lr = 0.01
I0615 15:04:43.111420 29366 solver.cpp:218] Iteration 3050 (0.86539 iter/s, 57.7774s/50 iters), loss = 1.19351
I0615 15:04:43.111553 29366 solver.cpp:237]     Train net output #0: loss = 1.19351 (* 1 = 1.19351 loss)
I0615 15:04:43.111575 29366 sgd_solver.cpp:105] Iteration 3050, lr = 0.01
I0615 15:05:40.875957 29366 solver.cpp:218] Iteration 3100 (0.865592 iter/s, 57.7639s/50 iters), loss = 0.690896
I0615 15:05:40.876098 29366 solver.cpp:237]     Train net output #0: loss = 0.690896 (* 1 = 0.690896 loss)
I0615 15:05:40.876121 29366 sgd_solver.cpp:105] Iteration 3100, lr = 0.01
I0615 15:06:38.642096 29366 solver.cpp:218] Iteration 3150 (0.865568 iter/s, 57.7655s/50 iters), loss = 0.782787
I0615 15:06:38.642264 29366 solver.cpp:237]     Train net output #0: loss = 0.782787 (* 1 = 0.782787 loss)
I0615 15:06:38.642287 29366 sgd_solver.cpp:105] Iteration 3150, lr = 0.01
I0615 15:07:36.417971 29366 solver.cpp:218] Iteration 3200 (0.865423 iter/s, 57.7752s/50 iters), loss = 0.719053
I0615 15:07:36.418133 29366 solver.cpp:237]     Train net output #0: loss = 0.719053 (* 1 = 0.719053 loss)
I0615 15:07:36.418155 29366 sgd_solver.cpp:105] Iteration 3200, lr = 0.01
I0615 15:08:34.203263 29366 solver.cpp:218] Iteration 3250 (0.865282 iter/s, 57.7846s/50 iters), loss = 0.681046
I0615 15:08:34.203428 29366 solver.cpp:237]     Train net output #0: loss = 0.681046 (* 1 = 0.681046 loss)
I0615 15:08:34.203450 29366 sgd_solver.cpp:105] Iteration 3250, lr = 0.01
I0615 15:09:31.975673 29366 solver.cpp:218] Iteration 3300 (0.865475 iter/s, 57.7718s/50 iters), loss = 0.573971
I0615 15:09:31.975847 29366 solver.cpp:237]     Train net output #0: loss = 0.573971 (* 1 = 0.573971 loss)
I0615 15:09:31.975870 29366 sgd_solver.cpp:105] Iteration 3300, lr = 0.01
I0615 15:10:29.807451 29366 solver.cpp:218] Iteration 3350 (0.864586 iter/s, 57.8311s/50 iters), loss = 0.851398
I0615 15:10:29.807605 29366 solver.cpp:237]     Train net output #0: loss = 0.851398 (* 1 = 0.851398 loss)
I0615 15:10:29.807626 29366 sgd_solver.cpp:105] Iteration 3350, lr = 0.01
I0615 15:11:27.660953 29366 solver.cpp:218] Iteration 3400 (0.864262 iter/s, 57.8529s/50 iters), loss = 0.946717
I0615 15:11:27.662863 29366 solver.cpp:237]     Train net output #0: loss = 0.946717 (* 1 = 0.946717 loss)
I0615 15:11:27.662886 29366 sgd_solver.cpp:105] Iteration 3400, lr = 0.01
I0615 15:12:25.455510 29366 solver.cpp:218] Iteration 3450 (0.865169 iter/s, 57.7922s/50 iters), loss = 0.456332
I0615 15:12:25.455672 29366 solver.cpp:237]     Train net output #0: loss = 0.456332 (* 1 = 0.456332 loss)
I0615 15:12:25.455693 29366 sgd_solver.cpp:105] Iteration 3450, lr = 0.01
I0615 15:13:23.233625 29366 solver.cpp:218] Iteration 3500 (0.865389 iter/s, 57.7775s/50 iters), loss = 0.632762
I0615 15:13:23.233757 29366 solver.cpp:237]     Train net output #0: loss = 0.632762 (* 1 = 0.632762 loss)
I0615 15:13:23.233783 29366 sgd_solver.cpp:105] Iteration 3500, lr = 0.01
I0615 15:14:21.014814 29366 solver.cpp:218] Iteration 3550 (0.865343 iter/s, 57.7806s/50 iters), loss = 0.500678
I0615 15:14:21.014948 29366 solver.cpp:237]     Train net output #0: loss = 0.500678 (* 1 = 0.500678 loss)
I0615 15:14:21.014973 29366 sgd_solver.cpp:105] Iteration 3550, lr = 0.01
I0615 15:15:18.788871 29366 solver.cpp:218] Iteration 3600 (0.865449 iter/s, 57.7735s/50 iters), loss = 0.603033
I0615 15:15:18.789013 29366 solver.cpp:237]     Train net output #0: loss = 0.603033 (* 1 = 0.603033 loss)
I0615 15:15:18.789044 29366 sgd_solver.cpp:105] Iteration 3600, lr = 0.01
I0615 15:16:16.608634 29366 solver.cpp:218] Iteration 3650 (0.864765 iter/s, 57.8191s/50 iters), loss = 0.672081
I0615 15:16:16.608808 29366 solver.cpp:237]     Train net output #0: loss = 0.672081 (* 1 = 0.672081 loss)
I0615 15:16:16.608834 29366 sgd_solver.cpp:105] Iteration 3650, lr = 0.01
I0615 15:17:14.372051 29366 solver.cpp:218] Iteration 3700 (0.865609 iter/s, 57.7628s/50 iters), loss = 0.560269
I0615 15:17:14.372184 29366 solver.cpp:237]     Train net output #0: loss = 0.560269 (* 1 = 0.560269 loss)
I0615 15:17:14.372210 29366 sgd_solver.cpp:105] Iteration 3700, lr = 0.01
I0615 15:18:12.205236 29366 solver.cpp:218] Iteration 3750 (0.864565 iter/s, 57.8326s/50 iters), loss = 0.492256
I0615 15:18:12.208612 29366 solver.cpp:237]     Train net output #0: loss = 0.492256 (* 1 = 0.492256 loss)
I0615 15:18:12.208640 29366 sgd_solver.cpp:105] Iteration 3750, lr = 0.01
I0615 15:19:10.220185 29366 solver.cpp:218] Iteration 3800 (0.861908 iter/s, 58.0108s/50 iters), loss = 0.68212
I0615 15:19:10.220504 29366 solver.cpp:237]     Train net output #0: loss = 0.68212 (* 1 = 0.68212 loss)
I0615 15:19:10.220544 29366 sgd_solver.cpp:105] Iteration 3800, lr = 0.01
I0615 15:20:08.225538 29366 solver.cpp:218] Iteration 3850 (0.862006 iter/s, 58.0042s/50 iters), loss = 0.828338
I0615 15:20:08.225772 29366 solver.cpp:237]     Train net output #0: loss = 0.828338 (* 1 = 0.828338 loss)
I0615 15:20:08.225800 29366 sgd_solver.cpp:105] Iteration 3850, lr = 0.01
I0615 15:21:06.428010 29366 solver.cpp:218] Iteration 3900 (0.859086 iter/s, 58.2014s/50 iters), loss = 0.688392
I0615 15:21:06.428246 29366 solver.cpp:237]     Train net output #0: loss = 0.688392 (* 1 = 0.688392 loss)
I0615 15:21:06.428272 29366 sgd_solver.cpp:105] Iteration 3900, lr = 0.01
I0615 15:22:04.808594 29366 solver.cpp:218] Iteration 3950 (0.856472 iter/s, 58.379s/50 iters), loss = 0.670569
I0615 15:22:04.812628 29366 solver.cpp:237]     Train net output #0: loss = 0.670569 (* 1 = 0.670569 loss)
I0615 15:22:04.812662 29366 sgd_solver.cpp:105] Iteration 3950, lr = 0.01
I0615 15:23:03.280189 29366 solver.cpp:218] Iteration 4000 (0.855187 iter/s, 58.4667s/50 iters), loss = 0.530016
I0615 15:23:03.280416 29366 solver.cpp:237]     Train net output #0: loss = 0.530016 (* 1 = 0.530016 loss)
I0615 15:23:03.280444 29366 sgd_solver.cpp:105] Iteration 4000, lr = 0.01
I0615 15:24:01.567307 29366 solver.cpp:218] Iteration 4050 (0.857837 iter/s, 58.2861s/50 iters), loss = 0.511197
I0615 15:24:01.575574 29366 solver.cpp:237]     Train net output #0: loss = 0.511197 (* 1 = 0.511197 loss)
I0615 15:24:01.575624 29366 sgd_solver.cpp:105] Iteration 4050, lr = 0.01
I0615 15:25:00.795337 29366 solver.cpp:218] Iteration 4100 (0.844323 iter/s, 59.219s/50 iters), loss = 0.593912
I0615 15:25:00.795686 29366 solver.cpp:237]     Train net output #0: loss = 0.593912 (* 1 = 0.593912 loss)
I0615 15:25:00.795711 29366 sgd_solver.cpp:105] Iteration 4100, lr = 0.01
I0615 15:25:58.620570 29366 solver.cpp:218] Iteration 4150 (0.864691 iter/s, 57.8241s/50 iters), loss = 0.374446
I0615 15:25:58.621248 29366 solver.cpp:237]     Train net output #0: loss = 0.374446 (* 1 = 0.374446 loss)
I0615 15:25:58.621273 29366 sgd_solver.cpp:105] Iteration 4150, lr = 0.01
I0615 15:26:57.154057 29366 solver.cpp:218] Iteration 4200 (0.854233 iter/s, 58.5321s/50 iters), loss = 0.353619
I0615 15:26:57.154225 29366 solver.cpp:237]     Train net output #0: loss = 0.353619 (* 1 = 0.353619 loss)
I0615 15:26:57.154251 29366 sgd_solver.cpp:105] Iteration 4200, lr = 0.01
I0615 15:27:54.918536 29366 solver.cpp:218] Iteration 4250 (0.865598 iter/s, 57.7636s/50 iters), loss = 0.458695
I0615 15:27:54.918694 29366 solver.cpp:237]     Train net output #0: loss = 0.458695 (* 1 = 0.458695 loss)
I0615 15:27:54.918720 29366 sgd_solver.cpp:105] Iteration 4250, lr = 0.01
I0615 15:28:52.734652 29366 solver.cpp:218] Iteration 4300 (0.864824 iter/s, 57.8152s/50 iters), loss = 0.498393
I0615 15:28:52.734838 29366 solver.cpp:237]     Train net output #0: loss = 0.498393 (* 1 = 0.498393 loss)
I0615 15:28:52.734864 29366 sgd_solver.cpp:105] Iteration 4300, lr = 0.01
I0615 15:29:50.503479 29366 solver.cpp:218] Iteration 4350 (0.865533 iter/s, 57.7679s/50 iters), loss = 0.39941
I0615 15:29:50.503634 29366 solver.cpp:237]     Train net output #0: loss = 0.39941 (* 1 = 0.39941 loss)
I0615 15:29:50.503659 29366 sgd_solver.cpp:105] Iteration 4350, lr = 0.01
I0615 15:30:48.329434 29366 solver.cpp:218] Iteration 4400 (0.864677 iter/s, 57.8251s/50 iters), loss = 0.404197
I0615 15:30:48.329586 29366 solver.cpp:237]     Train net output #0: loss = 0.404197 (* 1 = 0.404197 loss)
I0615 15:30:48.329612 29366 sgd_solver.cpp:105] Iteration 4400, lr = 0.01
I0615 15:31:46.100106 29366 solver.cpp:218] Iteration 4450 (0.865504 iter/s, 57.7698s/50 iters), loss = 0.368241
I0615 15:31:46.100236 29366 solver.cpp:237]     Train net output #0: loss = 0.368241 (* 1 = 0.368241 loss)
I0615 15:31:46.100261 29366 sgd_solver.cpp:105] Iteration 4450, lr = 0.01
I0615 15:32:43.859969 29366 solver.cpp:218] Iteration 4500 (0.865666 iter/s, 57.759s/50 iters), loss = 0.373279
I0615 15:32:43.860124 29366 solver.cpp:237]     Train net output #0: loss = 0.373279 (* 1 = 0.373279 loss)
I0615 15:32:43.860149 29366 sgd_solver.cpp:105] Iteration 4500, lr = 0.01
I0615 15:33:41.667611 29366 solver.cpp:218] Iteration 4550 (0.864951 iter/s, 57.8068s/50 iters), loss = 0.269237
I0615 15:33:41.667754 29366 solver.cpp:237]     Train net output #0: loss = 0.269237 (* 1 = 0.269237 loss)
I0615 15:33:41.667781 29366 sgd_solver.cpp:105] Iteration 4550, lr = 0.01
I0615 15:34:39.406538 29366 solver.cpp:218] Iteration 4600 (0.86598 iter/s, 57.738s/50 iters), loss = 0.398338
I0615 15:34:39.409595 29366 solver.cpp:237]     Train net output #0: loss = 0.398338 (* 1 = 0.398338 loss)
I0615 15:34:39.409621 29366 sgd_solver.cpp:105] Iteration 4600, lr = 0.01
I0615 15:35:37.202039 29366 solver.cpp:218] Iteration 4650 (0.865176 iter/s, 57.7917s/50 iters), loss = 0.349568
I0615 15:35:37.202172 29366 solver.cpp:237]     Train net output #0: loss = 0.349568 (* 1 = 0.349568 loss)
I0615 15:35:37.202199 29366 sgd_solver.cpp:105] Iteration 4650, lr = 0.01
I0615 15:36:34.924813 29366 solver.cpp:218] Iteration 4700 (0.866222 iter/s, 57.7219s/50 iters), loss = 0.303451
I0615 15:36:34.924963 29366 solver.cpp:237]     Train net output #0: loss = 0.303451 (* 1 = 0.303451 loss)
I0615 15:36:34.924996 29366 sgd_solver.cpp:105] Iteration 4700, lr = 0.01
I0615 15:37:32.657383 29366 solver.cpp:218] Iteration 4750 (0.866075 iter/s, 57.7317s/50 iters), loss = 0.15951
I0615 15:37:32.657529 29366 solver.cpp:237]     Train net output #0: loss = 0.15951 (* 1 = 0.15951 loss)
I0615 15:37:32.657564 29366 sgd_solver.cpp:105] Iteration 4750, lr = 0.01
I0615 15:38:30.475620 29366 solver.cpp:218] Iteration 4800 (0.864792 iter/s, 57.8174s/50 iters), loss = 0.239046
I0615 15:38:30.475929 29366 solver.cpp:237]     Train net output #0: loss = 0.239046 (* 1 = 0.239046 loss)
I0615 15:38:30.475955 29366 sgd_solver.cpp:105] Iteration 4800, lr = 0.01
I0615 15:39:28.363142 29366 solver.cpp:218] Iteration 4850 (0.863759 iter/s, 57.8865s/50 iters), loss = 0.233591
I0615 15:39:28.363299 29366 solver.cpp:237]     Train net output #0: loss = 0.233591 (* 1 = 0.233591 loss)
I0615 15:39:28.363327 29366 sgd_solver.cpp:105] Iteration 4850, lr = 0.01
I0615 15:40:26.129556 29366 solver.cpp:218] Iteration 4900 (0.865568 iter/s, 57.7656s/50 iters), loss = 0.142653
I0615 15:40:26.129693 29366 solver.cpp:237]     Train net output #0: loss = 0.142653 (* 1 = 0.142653 loss)
I0615 15:40:26.129719 29366 sgd_solver.cpp:105] Iteration 4900, lr = 0.01
I0615 15:41:23.897588 29366 solver.cpp:218] Iteration 4950 (0.865553 iter/s, 57.7666s/50 iters), loss = 0.42568
I0615 15:41:23.901621 29366 solver.cpp:237]     Train net output #0: loss = 0.42568 (* 1 = 0.42568 loss)
I0615 15:41:23.901653 29366 sgd_solver.cpp:105] Iteration 4950, lr = 0.01
I0615 15:42:21.730739 29366 solver.cpp:218] Iteration 5000 (0.864627 iter/s, 57.8284s/50 iters), loss = 0.300416
I0615 15:42:21.730929 29366 solver.cpp:237]     Train net output #0: loss = 0.300416 (* 1 = 0.300416 loss)
I0615 15:42:21.730957 29366 sgd_solver.cpp:105] Iteration 5000, lr = 0.01
I0615 15:43:19.555263 29366 solver.cpp:218] Iteration 5050 (0.864698 iter/s, 57.8237s/50 iters), loss = 0.27219
I0615 15:43:19.555387 29366 solver.cpp:237]     Train net output #0: loss = 0.27219 (* 1 = 0.27219 loss)
I0615 15:43:19.555413 29366 sgd_solver.cpp:105] Iteration 5050, lr = 0.01
I0615 15:44:17.333075 29366 solver.cpp:218] Iteration 5100 (0.865396 iter/s, 57.777s/50 iters), loss = 0.183169
I0615 15:44:17.333230 29366 solver.cpp:237]     Train net output #0: loss = 0.183169 (* 1 = 0.183169 loss)
I0615 15:44:17.333256 29366 sgd_solver.cpp:105] Iteration 5100, lr = 0.01
I0615 15:45:15.165307 29366 solver.cpp:218] Iteration 5150 (0.864582 iter/s, 57.8314s/50 iters), loss = 0.159514
I0615 15:45:15.165436 29366 solver.cpp:237]     Train net output #0: loss = 0.159514 (* 1 = 0.159514 loss)
I0615 15:45:15.165460 29366 sgd_solver.cpp:105] Iteration 5150, lr = 0.01
I0615 15:46:12.938411 29366 solver.cpp:218] Iteration 5200 (0.865467 iter/s, 57.7723s/50 iters), loss = 0.104752
I0615 15:46:12.938596 29366 solver.cpp:237]     Train net output #0: loss = 0.104752 (* 1 = 0.104752 loss)
I0615 15:46:12.938622 29366 sgd_solver.cpp:105] Iteration 5200, lr = 0.01
I0615 15:47:10.718426 29366 solver.cpp:218] Iteration 5250 (0.865364 iter/s, 57.7792s/50 iters), loss = 0.177523
I0615 15:47:10.718555 29366 solver.cpp:237]     Train net output #0: loss = 0.177523 (* 1 = 0.177523 loss)
I0615 15:47:10.718581 29366 sgd_solver.cpp:105] Iteration 5250, lr = 0.01
I0615 15:48:08.690040 29366 solver.cpp:218] Iteration 5300 (0.862504 iter/s, 57.9708s/50 iters), loss = 0.193365
I0615 15:48:08.693621 29366 solver.cpp:237]     Train net output #0: loss = 0.193365 (* 1 = 0.193365 loss)
I0615 15:48:08.693651 29366 sgd_solver.cpp:105] Iteration 5300, lr = 0.01
I0615 15:49:06.820108 29366 solver.cpp:218] Iteration 5350 (0.860205 iter/s, 58.1257s/50 iters), loss = 0.217286
I0615 15:49:06.821825 29366 solver.cpp:237]     Train net output #0: loss = 0.217286 (* 1 = 0.217286 loss)
I0615 15:49:06.821851 29366 sgd_solver.cpp:105] Iteration 5350, lr = 0.01
I0615 15:50:06.190378 29366 solver.cpp:218] Iteration 5400 (0.842207 iter/s, 59.3678s/50 iters), loss = 0.237099
I0615 15:50:06.194561 29366 solver.cpp:237]     Train net output #0: loss = 0.237099 (* 1 = 0.237099 loss)
I0615 15:50:06.194609 29366 sgd_solver.cpp:105] Iteration 5400, lr = 0.01
I0615 15:51:04.627962 29366 solver.cpp:218] Iteration 5450 (0.855686 iter/s, 58.4327s/50 iters), loss = 0.160916
I0615 15:51:04.635571 29366 solver.cpp:237]     Train net output #0: loss = 0.160916 (* 1 = 0.160916 loss)
I0615 15:51:04.635622 29366 sgd_solver.cpp:105] Iteration 5450, lr = 0.01
I0615 15:52:02.753098 29366 solver.cpp:218] Iteration 5500 (0.860336 iter/s, 58.1168s/50 iters), loss = 0.119592
I0615 15:52:02.757638 29366 solver.cpp:237]     Train net output #0: loss = 0.119592 (* 1 = 0.119592 loss)
I0615 15:52:02.757680 29366 sgd_solver.cpp:105] Iteration 5500, lr = 0.01
I0615 15:53:00.883710 29366 solver.cpp:218] Iteration 5550 (0.86021 iter/s, 58.1253s/50 iters), loss = 0.154501
I0615 15:53:00.883889 29366 solver.cpp:237]     Train net output #0: loss = 0.154501 (* 1 = 0.154501 loss)
I0615 15:53:00.883915 29366 sgd_solver.cpp:105] Iteration 5550, lr = 0.01
I0615 15:53:58.653475 29366 solver.cpp:218] Iteration 5600 (0.865519 iter/s, 57.7688s/50 iters), loss = 0.227944
I0615 15:53:58.653632 29366 solver.cpp:237]     Train net output #0: loss = 0.227944 (* 1 = 0.227944 loss)
I0615 15:53:58.653657 29366 sgd_solver.cpp:105] Iteration 5600, lr = 0.01
I0615 15:54:56.439993 29366 solver.cpp:218] Iteration 5650 (0.865267 iter/s, 57.7856s/50 iters), loss = 0.168283
I0615 15:54:56.440160 29366 solver.cpp:237]     Train net output #0: loss = 0.168283 (* 1 = 0.168283 loss)
I0615 15:54:56.440186 29366 sgd_solver.cpp:105] Iteration 5650, lr = 0.01
I0615 15:55:54.208906 29366 solver.cpp:218] Iteration 5700 (0.865531 iter/s, 57.768s/50 iters), loss = 0.0813647
I0615 15:55:54.209076 29366 solver.cpp:237]     Train net output #0: loss = 0.0813647 (* 1 = 0.0813647 loss)
I0615 15:55:54.209110 29366 sgd_solver.cpp:105] Iteration 5700, lr = 0.01
I0615 15:56:51.988171 29366 solver.cpp:218] Iteration 5750 (0.865376 iter/s, 57.7784s/50 iters), loss = 0.114863
I0615 15:56:51.988329 29366 solver.cpp:237]     Train net output #0: loss = 0.114863 (* 1 = 0.114863 loss)
I0615 15:56:51.988355 29366 sgd_solver.cpp:105] Iteration 5750, lr = 0.01
I0615 15:57:49.774919 29366 solver.cpp:218] Iteration 5800 (0.865264 iter/s, 57.7859s/50 iters), loss = 0.193024
I0615 15:57:49.775089 29366 solver.cpp:237]     Train net output #0: loss = 0.193024 (* 1 = 0.193024 loss)
I0615 15:57:49.775115 29366 sgd_solver.cpp:105] Iteration 5800, lr = 0.01
I0615 15:58:47.618026 29366 solver.cpp:218] Iteration 5850 (0.864421 iter/s, 57.8422s/50 iters), loss = 0.145413
I0615 15:58:47.618208 29366 solver.cpp:237]     Train net output #0: loss = 0.145413 (* 1 = 0.145413 loss)
I0615 15:58:47.618235 29366 sgd_solver.cpp:105] Iteration 5850, lr = 0.01
I0615 15:59:45.406869 29366 solver.cpp:218] Iteration 5900 (0.865233 iter/s, 57.7879s/50 iters), loss = 0.112158
I0615 15:59:45.407035 29366 solver.cpp:237]     Train net output #0: loss = 0.112159 (* 1 = 0.112159 loss)
I0615 15:59:45.407060 29366 sgd_solver.cpp:105] Iteration 5900, lr = 0.01
I0615 16:00:43.237884 29366 solver.cpp:218] Iteration 5950 (0.864601 iter/s, 57.8301s/50 iters), loss = 0.151674
I0615 16:00:43.242728 29366 solver.cpp:237]     Train net output #0: loss = 0.151674 (* 1 = 0.151674 loss)
I0615 16:00:43.242761 29366 sgd_solver.cpp:105] Iteration 5950, lr = 0.01
I0615 16:01:41.019683 29366 solver.cpp:218] Iteration 6000 (0.865408 iter/s, 57.7762s/50 iters), loss = 0.0731968
I0615 16:01:41.019855 29366 solver.cpp:237]     Train net output #0: loss = 0.0731969 (* 1 = 0.0731969 loss)
I0615 16:01:41.019881 29366 sgd_solver.cpp:105] Iteration 6000, lr = 0.01
I0615 16:02:38.803372 29366 solver.cpp:218] Iteration 6050 (0.86531 iter/s, 57.7828s/50 iters), loss = 0.0881746
I0615 16:02:38.803550 29366 solver.cpp:237]     Train net output #0: loss = 0.0881746 (* 1 = 0.0881746 loss)
I0615 16:02:38.803577 29366 sgd_solver.cpp:105] Iteration 6050, lr = 0.01
I0615 16:03:36.589062 29366 solver.cpp:218] Iteration 6100 (0.86528 iter/s, 57.7848s/50 iters), loss = 0.179326
I0615 16:03:36.589239 29366 solver.cpp:237]     Train net output #0: loss = 0.179326 (* 1 = 0.179326 loss)
I0615 16:03:36.589265 29366 sgd_solver.cpp:105] Iteration 6100, lr = 0.01
I0615 16:04:34.380884 29366 solver.cpp:218] Iteration 6150 (0.865188 iter/s, 57.7909s/50 iters), loss = 0.0993139
I0615 16:04:34.381253 29366 solver.cpp:237]     Train net output #0: loss = 0.0993138 (* 1 = 0.0993138 loss)
I0615 16:04:34.381280 29366 sgd_solver.cpp:105] Iteration 6150, lr = 0.01
I0615 16:05:32.164666 29366 solver.cpp:218] Iteration 6200 (0.865311 iter/s, 57.7827s/50 iters), loss = 0.115314
I0615 16:05:32.164937 29366 solver.cpp:237]     Train net output #0: loss = 0.115314 (* 1 = 0.115314 loss)
I0615 16:05:32.164964 29366 sgd_solver.cpp:105] Iteration 6200, lr = 0.01
I0615 16:06:29.944131 29366 solver.cpp:218] Iteration 6250 (0.865374 iter/s, 57.7785s/50 iters), loss = 0.101042
I0615 16:06:29.944293 29366 solver.cpp:237]     Train net output #0: loss = 0.101042 (* 1 = 0.101042 loss)
I0615 16:06:29.944319 29366 sgd_solver.cpp:105] Iteration 6250, lr = 0.01
I0615 16:07:27.726990 29366 solver.cpp:218] Iteration 6300 (0.865322 iter/s, 57.782s/50 iters), loss = 0.0890082
I0615 16:07:27.727179 29366 solver.cpp:237]     Train net output #0: loss = 0.0890081 (* 1 = 0.0890081 loss)
I0615 16:07:27.727205 29366 sgd_solver.cpp:105] Iteration 6300, lr = 0.01
I0615 16:08:25.518015 29366 solver.cpp:218] Iteration 6350 (0.8652 iter/s, 57.7901s/50 iters), loss = 0.0695502
I0615 16:08:25.518182 29366 solver.cpp:237]     Train net output #0: loss = 0.0695502 (* 1 = 0.0695502 loss)
I0615 16:08:25.518209 29366 sgd_solver.cpp:105] Iteration 6350, lr = 0.01
I0615 16:09:23.309118 29366 solver.cpp:218] Iteration 6400 (0.865199 iter/s, 57.7902s/50 iters), loss = 0.0950191
I0615 16:09:23.309288 29366 solver.cpp:237]     Train net output #0: loss = 0.0950191 (* 1 = 0.0950191 loss)
I0615 16:09:23.309314 29366 sgd_solver.cpp:105] Iteration 6400, lr = 0.01
I0615 16:10:21.101585 29366 solver.cpp:218] Iteration 6450 (0.865176 iter/s, 57.7917s/50 iters), loss = 0.0477549
I0615 16:10:21.101742 29366 solver.cpp:237]     Train net output #0: loss = 0.0477548 (* 1 = 0.0477548 loss)
I0615 16:10:21.101768 29366 sgd_solver.cpp:105] Iteration 6450, lr = 0.01
I0615 16:11:18.883172 29366 solver.cpp:218] Iteration 6500 (0.865338 iter/s, 57.7809s/50 iters), loss = 0.113637
I0615 16:11:18.883349 29366 solver.cpp:237]     Train net output #0: loss = 0.113637 (* 1 = 0.113637 loss)
I0615 16:11:18.883375 29366 sgd_solver.cpp:105] Iteration 6500, lr = 0.01
I0615 16:12:16.672340 29366 solver.cpp:218] Iteration 6550 (0.865225 iter/s, 57.7884s/50 iters), loss = 0.0618639
I0615 16:12:16.672616 29366 solver.cpp:237]     Train net output #0: loss = 0.0618639 (* 1 = 0.0618639 loss)
I0615 16:12:16.672643 29366 sgd_solver.cpp:105] Iteration 6550, lr = 0.01
I0615 16:13:14.457108 29366 solver.cpp:218] Iteration 6600 (0.865293 iter/s, 57.7839s/50 iters), loss = 0.113107
I0615 16:13:14.457289 29366 solver.cpp:237]     Train net output #0: loss = 0.113107 (* 1 = 0.113107 loss)
I0615 16:13:14.457324 29366 sgd_solver.cpp:105] Iteration 6600, lr = 0.01
I0615 16:14:12.248173 29366 solver.cpp:218] Iteration 6650 (0.865197 iter/s, 57.7903s/50 iters), loss = 0.0787361
I0615 16:14:12.248320 29366 solver.cpp:237]     Train net output #0: loss = 0.078736 (* 1 = 0.078736 loss)
I0615 16:14:12.248345 29366 sgd_solver.cpp:105] Iteration 6650, lr = 0.01
I0615 16:15:10.045403 29366 solver.cpp:218] Iteration 6700 (0.865104 iter/s, 57.7965s/50 iters), loss = 0.0777977
I0615 16:15:10.045588 29366 solver.cpp:237]     Train net output #0: loss = 0.0777976 (* 1 = 0.0777976 loss)
I0615 16:15:10.045616 29366 sgd_solver.cpp:105] Iteration 6700, lr = 0.01
I0615 16:16:07.826118 29366 solver.cpp:218] Iteration 6750 (0.865352 iter/s, 57.78s/50 iters), loss = 0.0674982
I0615 16:16:07.828586 29366 solver.cpp:237]     Train net output #0: loss = 0.0674981 (* 1 = 0.0674981 loss)
I0615 16:16:07.828616 29366 sgd_solver.cpp:105] Iteration 6750, lr = 0.01
I0615 16:17:05.607363 29366 solver.cpp:218] Iteration 6800 (0.865378 iter/s, 57.7782s/50 iters), loss = 0.0449138
I0615 16:17:05.607501 29366 solver.cpp:237]     Train net output #0: loss = 0.0449137 (* 1 = 0.0449137 loss)
I0615 16:17:05.607530 29366 sgd_solver.cpp:105] Iteration 6800, lr = 0.01
I0615 16:18:03.379614 29366 solver.cpp:218] Iteration 6850 (0.865478 iter/s, 57.7716s/50 iters), loss = 0.0408564
I0615 16:18:03.379868 29366 solver.cpp:237]     Train net output #0: loss = 0.0408564 (* 1 = 0.0408564 loss)
I0615 16:18:03.379894 29366 sgd_solver.cpp:105] Iteration 6850, lr = 0.01
I0615 16:19:01.158511 29366 solver.cpp:218] Iteration 6900 (0.86538 iter/s, 57.7781s/50 iters), loss = 0.106949
I0615 16:19:01.158665 29366 solver.cpp:237]     Train net output #0: loss = 0.106949 (* 1 = 0.106949 loss)
I0615 16:19:01.158691 29366 sgd_solver.cpp:105] Iteration 6900, lr = 0.01
I0615 16:19:58.934963 29366 solver.cpp:218] Iteration 6950 (0.865415 iter/s, 57.7757s/50 iters), loss = 0.080903
I0615 16:19:58.935101 29366 solver.cpp:237]     Train net output #0: loss = 0.080903 (* 1 = 0.080903 loss)
I0615 16:19:58.935124 29366 sgd_solver.cpp:105] Iteration 6950, lr = 0.01
I0615 16:20:56.698269 29366 solver.cpp:218] Iteration 7000 (0.865612 iter/s, 57.7626s/50 iters), loss = 0.0464631
I0615 16:20:56.698413 29366 solver.cpp:237]     Train net output #0: loss = 0.046463 (* 1 = 0.046463 loss)
I0615 16:20:56.698446 29366 sgd_solver.cpp:105] Iteration 7000, lr = 0.01
I0615 16:21:54.451133 29366 solver.cpp:218] Iteration 7050 (0.865768 iter/s, 57.7522s/50 iters), loss = 0.0575471
I0615 16:21:54.451263 29366 solver.cpp:237]     Train net output #0: loss = 0.0575471 (* 1 = 0.0575471 loss)
I0615 16:21:54.451292 29366 sgd_solver.cpp:105] Iteration 7050, lr = 0.01
I0615 16:22:52.212949 29366 solver.cpp:218] Iteration 7100 (0.865634 iter/s, 57.7611s/50 iters), loss = 0.0542329
I0615 16:22:52.213102 29366 solver.cpp:237]     Train net output #0: loss = 0.0542329 (* 1 = 0.0542329 loss)
I0615 16:22:52.213127 29366 sgd_solver.cpp:105] Iteration 7100, lr = 0.01
I0615 16:23:49.967454 29366 solver.cpp:218] Iteration 7150 (0.865744 iter/s, 57.7538s/50 iters), loss = 0.018905
I0615 16:23:49.967594 29366 solver.cpp:237]     Train net output #0: loss = 0.018905 (* 1 = 0.018905 loss)
I0615 16:23:49.967618 29366 sgd_solver.cpp:105] Iteration 7150, lr = 0.01
I0615 16:24:47.740819 29366 solver.cpp:218] Iteration 7200 (0.865461 iter/s, 57.7727s/50 iters), loss = 0.0294612
I0615 16:24:47.740959 29366 solver.cpp:237]     Train net output #0: loss = 0.0294612 (* 1 = 0.0294612 loss)
I0615 16:24:47.740984 29366 sgd_solver.cpp:105] Iteration 7200, lr = 0.01
I0615 16:25:45.509564 29366 solver.cpp:218] Iteration 7250 (0.86553 iter/s, 57.768s/50 iters), loss = 0.0692036
I0615 16:25:45.509703 29366 solver.cpp:237]     Train net output #0: loss = 0.0692036 (* 1 = 0.0692036 loss)
I0615 16:25:45.509729 29366 sgd_solver.cpp:105] Iteration 7250, lr = 0.01
I0615 16:26:43.280673 29366 solver.cpp:218] Iteration 7300 (0.865495 iter/s, 57.7704s/50 iters), loss = 0.0533964
I0615 16:26:43.280803 29366 solver.cpp:237]     Train net output #0: loss = 0.0533964 (* 1 = 0.0533964 loss)
I0615 16:26:43.280829 29366 sgd_solver.cpp:105] Iteration 7300, lr = 0.01
I0615 16:27:41.038964 29366 solver.cpp:218] Iteration 7350 (0.865687 iter/s, 57.7576s/50 iters), loss = 0.0833878
I0615 16:27:41.039374 29366 solver.cpp:237]     Train net output #0: loss = 0.0833877 (* 1 = 0.0833877 loss)
I0615 16:27:41.039400 29366 sgd_solver.cpp:105] Iteration 7350, lr = 0.01
I0615 16:28:38.801244 29366 solver.cpp:218] Iteration 7400 (0.865631 iter/s, 57.7613s/50 iters), loss = 0.0461413
I0615 16:28:38.801381 29366 solver.cpp:237]     Train net output #0: loss = 0.0461412 (* 1 = 0.0461412 loss)
I0615 16:28:38.801414 29366 sgd_solver.cpp:105] Iteration 7400, lr = 0.01
I0615 16:29:36.555832 29366 solver.cpp:218] Iteration 7450 (0.865743 iter/s, 57.7539s/50 iters), loss = 0.0378592
I0615 16:29:36.555966 29366 solver.cpp:237]     Train net output #0: loss = 0.0378592 (* 1 = 0.0378592 loss)
I0615 16:29:36.555991 29366 sgd_solver.cpp:105] Iteration 7450, lr = 0.01
I0615 16:30:34.321533 29366 solver.cpp:218] Iteration 7500 (0.865576 iter/s, 57.765s/50 iters), loss = 0.0530313
I0615 16:30:34.321677 29366 solver.cpp:237]     Train net output #0: loss = 0.0530313 (* 1 = 0.0530313 loss)
I0615 16:30:34.321702 29366 sgd_solver.cpp:105] Iteration 7500, lr = 0.01
I0615 16:31:32.091926 29366 solver.cpp:218] Iteration 7550 (0.865506 iter/s, 57.7697s/50 iters), loss = 0.0249175
I0615 16:31:32.092083 29366 solver.cpp:237]     Train net output #0: loss = 0.0249174 (* 1 = 0.0249174 loss)
I0615 16:31:32.092125 29366 sgd_solver.cpp:105] Iteration 7550, lr = 0.01
I0615 16:32:29.871065 29366 solver.cpp:218] Iteration 7600 (0.865375 iter/s, 57.7784s/50 iters), loss = 0.0178553
I0615 16:32:29.871274 29366 solver.cpp:237]     Train net output #0: loss = 0.0178552 (* 1 = 0.0178552 loss)
I0615 16:32:29.871300 29366 sgd_solver.cpp:105] Iteration 7600, lr = 0.01
I0615 16:33:27.642506 29366 solver.cpp:218] Iteration 7650 (0.865491 iter/s, 57.7707s/50 iters), loss = 0.038591
I0615 16:33:27.642628 29366 solver.cpp:237]     Train net output #0: loss = 0.038591 (* 1 = 0.038591 loss)
I0615 16:33:27.642654 29366 sgd_solver.cpp:105] Iteration 7650, lr = 0.01
I0615 16:34:25.409070 29366 solver.cpp:218] Iteration 7700 (0.865563 iter/s, 57.7659s/50 iters), loss = 0.0356493
I0615 16:34:25.409258 29366 solver.cpp:237]     Train net output #0: loss = 0.0356492 (* 1 = 0.0356492 loss)
I0615 16:34:25.409284 29366 sgd_solver.cpp:105] Iteration 7700, lr = 0.01
I0615 16:35:23.171070 29366 solver.cpp:218] Iteration 7750 (0.865632 iter/s, 57.7612s/50 iters), loss = 0.0249166
I0615 16:35:23.171221 29366 solver.cpp:237]     Train net output #0: loss = 0.0249165 (* 1 = 0.0249165 loss)
I0615 16:35:23.171247 29366 sgd_solver.cpp:105] Iteration 7750, lr = 0.01
I0615 16:36:20.950788 29366 solver.cpp:218] Iteration 7800 (0.865366 iter/s, 57.779s/50 iters), loss = 0.0208414
I0615 16:36:20.950944 29366 solver.cpp:237]     Train net output #0: loss = 0.0208413 (* 1 = 0.0208413 loss)
I0615 16:36:20.950978 29366 sgd_solver.cpp:105] Iteration 7800, lr = 0.01
I0615 16:37:18.715560 29366 solver.cpp:218] Iteration 7850 (0.86559 iter/s, 57.764s/50 iters), loss = 0.0262112
I0615 16:37:18.715700 29366 solver.cpp:237]     Train net output #0: loss = 0.0262111 (* 1 = 0.0262111 loss)
I0615 16:37:18.715731 29366 sgd_solver.cpp:105] Iteration 7850, lr = 0.01
I0615 16:38:16.487607 29366 solver.cpp:218] Iteration 7900 (0.865481 iter/s, 57.7713s/50 iters), loss = 0.0240679
I0615 16:38:16.487807 29366 solver.cpp:237]     Train net output #0: loss = 0.0240678 (* 1 = 0.0240678 loss)
I0615 16:38:16.487833 29366 sgd_solver.cpp:105] Iteration 7900, lr = 0.01
I0615 16:39:14.257529 29366 solver.cpp:218] Iteration 7950 (0.865514 iter/s, 57.7691s/50 iters), loss = 0.0550637
I0615 16:39:14.257658 29366 solver.cpp:237]     Train net output #0: loss = 0.0550636 (* 1 = 0.0550636 loss)
I0615 16:39:14.257683 29366 sgd_solver.cpp:105] Iteration 7950, lr = 0.01
I0615 16:40:12.021018 29366 solver.cpp:218] Iteration 8000 (0.865609 iter/s, 57.7628s/50 iters), loss = 0.0251384
I0615 16:40:12.021164 29366 solver.cpp:237]     Train net output #0: loss = 0.0251383 (* 1 = 0.0251383 loss)
I0615 16:40:12.021189 29366 sgd_solver.cpp:105] Iteration 8000, lr = 0.01
I0615 16:41:09.798758 29366 solver.cpp:218] Iteration 8050 (0.865396 iter/s, 57.777s/50 iters), loss = 0.0630067
I0615 16:41:09.798997 29366 solver.cpp:237]     Train net output #0: loss = 0.0630066 (* 1 = 0.0630066 loss)
I0615 16:41:09.799023 29366 sgd_solver.cpp:105] Iteration 8050, lr = 0.01
I0615 16:42:07.558799 29366 solver.cpp:218] Iteration 8100 (0.865663 iter/s, 57.7592s/50 iters), loss = 0.0210971
I0615 16:42:07.558967 29366 solver.cpp:237]     Train net output #0: loss = 0.0210971 (* 1 = 0.0210971 loss)
I0615 16:42:07.558993 29366 sgd_solver.cpp:105] Iteration 8100, lr = 0.01
I0615 16:43:05.337019 29366 solver.cpp:218] Iteration 8150 (0.865389 iter/s, 57.7775s/50 iters), loss = 0.0157936
I0615 16:43:05.337167 29366 solver.cpp:237]     Train net output #0: loss = 0.0157935 (* 1 = 0.0157935 loss)
I0615 16:43:05.337191 29366 sgd_solver.cpp:105] Iteration 8150, lr = 0.01
I0615 16:44:03.114368 29366 solver.cpp:218] Iteration 8200 (0.865403 iter/s, 57.7766s/50 iters), loss = 0.0306388
I0615 16:44:03.114497 29366 solver.cpp:237]     Train net output #0: loss = 0.0306387 (* 1 = 0.0306387 loss)
I0615 16:44:03.114528 29366 sgd_solver.cpp:105] Iteration 8200, lr = 0.01
I0615 16:45:00.892096 29366 solver.cpp:218] Iteration 8250 (0.865397 iter/s, 57.7769s/50 iters), loss = 0.0433737
I0615 16:45:00.892284 29366 solver.cpp:237]     Train net output #0: loss = 0.0433736 (* 1 = 0.0433736 loss)
I0615 16:45:00.892320 29366 sgd_solver.cpp:105] Iteration 8250, lr = 0.01
I0615 16:45:58.659664 29366 solver.cpp:218] Iteration 8300 (0.865551 iter/s, 57.7667s/50 iters), loss = 0.0279666
I0615 16:45:58.659765 29366 solver.cpp:237]     Train net output #0: loss = 0.0279665 (* 1 = 0.0279665 loss)
I0615 16:45:58.659791 29366 sgd_solver.cpp:105] Iteration 8300, lr = 0.01
I0615 16:46:56.427378 29366 solver.cpp:218] Iteration 8350 (0.865547 iter/s, 57.7669s/50 iters), loss = 0.0234745
I0615 16:46:56.427543 29366 solver.cpp:237]     Train net output #0: loss = 0.0234744 (* 1 = 0.0234744 loss)
I0615 16:46:56.427572 29366 sgd_solver.cpp:105] Iteration 8350, lr = 0.01
I0615 16:47:54.206887 29366 solver.cpp:218] Iteration 8400 (0.865371 iter/s, 57.7787s/50 iters), loss = 0.0287042
I0615 16:47:54.207037 29366 solver.cpp:237]     Train net output #0: loss = 0.0287041 (* 1 = 0.0287041 loss)
I0615 16:47:54.207062 29366 sgd_solver.cpp:105] Iteration 8400, lr = 0.01
I0615 16:48:51.975263 29366 solver.cpp:218] Iteration 8450 (0.865538 iter/s, 57.7676s/50 iters), loss = 0.0168697
I0615 16:48:51.975409 29366 solver.cpp:237]     Train net output #0: loss = 0.0168696 (* 1 = 0.0168696 loss)
I0615 16:48:51.975435 29366 sgd_solver.cpp:105] Iteration 8450, lr = 0.01
I0615 16:49:49.744648 29366 solver.cpp:218] Iteration 8500 (0.865523 iter/s, 57.7686s/50 iters), loss = 0.025513
I0615 16:49:49.744802 29366 solver.cpp:237]     Train net output #0: loss = 0.0255129 (* 1 = 0.0255129 loss)
I0615 16:49:49.744827 29366 sgd_solver.cpp:105] Iteration 8500, lr = 0.01
I0615 16:50:47.512610 29366 solver.cpp:218] Iteration 8550 (0.865544 iter/s, 57.7671s/50 iters), loss = 0.0219034
I0615 16:50:47.512750 29366 solver.cpp:237]     Train net output #0: loss = 0.0219033 (* 1 = 0.0219033 loss)
I0615 16:50:47.512775 29366 sgd_solver.cpp:105] Iteration 8550, lr = 0.01
I0615 16:51:45.293125 29366 solver.cpp:218] Iteration 8600 (0.865356 iter/s, 57.7797s/50 iters), loss = 0.041029
I0615 16:51:45.293262 29366 solver.cpp:237]     Train net output #0: loss = 0.041029 (* 1 = 0.041029 loss)
I0615 16:51:45.293287 29366 sgd_solver.cpp:105] Iteration 8600, lr = 0.01
I0615 16:52:43.062273 29366 solver.cpp:218] Iteration 8650 (0.865526 iter/s, 57.7683s/50 iters), loss = 0.107709
I0615 16:52:43.062413 29366 solver.cpp:237]     Train net output #0: loss = 0.107709 (* 1 = 0.107709 loss)
I0615 16:52:43.062439 29366 sgd_solver.cpp:105] Iteration 8650, lr = 0.01
I0615 16:53:40.825690 29366 solver.cpp:218] Iteration 8700 (0.865612 iter/s, 57.7626s/50 iters), loss = 0.0386261
I0615 16:53:40.825824 29366 solver.cpp:237]     Train net output #0: loss = 0.038626 (* 1 = 0.038626 loss)
I0615 16:53:40.825850 29366 sgd_solver.cpp:105] Iteration 8700, lr = 0.01
I0615 16:54:38.595381 29366 solver.cpp:218] Iteration 8750 (0.865518 iter/s, 57.7689s/50 iters), loss = 0.0501697
I0615 16:54:38.595566 29366 solver.cpp:237]     Train net output #0: loss = 0.0501697 (* 1 = 0.0501697 loss)
I0615 16:54:38.595594 29366 sgd_solver.cpp:105] Iteration 8750, lr = 0.01
I0615 16:55:36.706532 29366 solver.cpp:218] Iteration 8800 (0.860441 iter/s, 58.1098s/50 iters), loss = 0.046521
I0615 16:55:36.708343 29366 solver.cpp:237]     Train net output #0: loss = 0.0465209 (* 1 = 0.0465209 loss)
I0615 16:55:36.708369 29366 sgd_solver.cpp:105] Iteration 8800, lr = 0.01
I0615 16:56:36.223740 29366 solver.cpp:218] Iteration 8850 (0.840129 iter/s, 59.5147s/50 iters), loss = 0.0153902
I0615 16:56:36.223985 29366 solver.cpp:237]     Train net output #0: loss = 0.0153901 (* 1 = 0.0153901 loss)
I0615 16:56:36.224012 29366 sgd_solver.cpp:105] Iteration 8850, lr = 0.01
I0615 16:57:34.423271 29366 solver.cpp:218] Iteration 8900 (0.859128 iter/s, 58.1985s/50 iters), loss = 0.0304892
I0615 16:57:34.426753 29366 solver.cpp:237]     Train net output #0: loss = 0.0304891 (* 1 = 0.0304891 loss)
I0615 16:57:34.426792 29366 sgd_solver.cpp:105] Iteration 8900, lr = 0.01
I0615 16:58:32.601018 29366 solver.cpp:218] Iteration 8950 (0.859496 iter/s, 58.1736s/50 iters), loss = 0.052007
I0615 16:58:32.602216 29366 solver.cpp:237]     Train net output #0: loss = 0.0520069 (* 1 = 0.0520069 loss)
I0615 16:58:32.602241 29366 sgd_solver.cpp:105] Iteration 8950, lr = 0.01
I0615 16:59:31.968117 29366 solver.cpp:218] Iteration 9000 (0.842259 iter/s, 59.3642s/50 iters), loss = 0.017986
I0615 16:59:31.975610 29366 solver.cpp:237]     Train net output #0: loss = 0.0179859 (* 1 = 0.0179859 loss)
I0615 16:59:31.975639 29366 sgd_solver.cpp:105] Iteration 9000, lr = 0.01
I0615 17:00:30.502804 29366 solver.cpp:218] Iteration 9050 (0.854313 iter/s, 58.5265s/50 iters), loss = 0.0165924
I0615 17:00:30.506602 29366 solver.cpp:237]     Train net output #0: loss = 0.0165923 (* 1 = 0.0165923 loss)
I0615 17:00:30.506629 29366 sgd_solver.cpp:105] Iteration 9050, lr = 0.01
I0615 17:01:29.046628 29366 solver.cpp:218] Iteration 9100 (0.854127 iter/s, 58.5393s/50 iters), loss = 0.0116212
I0615 17:01:29.050647 29366 solver.cpp:237]     Train net output #0: loss = 0.0116211 (* 1 = 0.0116211 loss)
I0615 17:01:29.050675 29366 sgd_solver.cpp:105] Iteration 9100, lr = 0.01
I0615 17:02:27.677173 29366 solver.cpp:218] Iteration 9150 (0.852867 iter/s, 58.6258s/50 iters), loss = 0.0342331
I0615 17:02:27.681568 29366 solver.cpp:237]     Train net output #0: loss = 0.034233 (* 1 = 0.034233 loss)
I0615 17:02:27.681615 29366 sgd_solver.cpp:105] Iteration 9150, lr = 0.01
I0615 17:03:25.858033 29366 solver.cpp:218] Iteration 9200 (0.859464 iter/s, 58.1758s/50 iters), loss = 0.0383354
I0615 17:03:25.858184 29366 solver.cpp:237]     Train net output #0: loss = 0.0383353 (* 1 = 0.0383353 loss)
I0615 17:03:25.858211 29366 sgd_solver.cpp:105] Iteration 9200, lr = 0.01
I0615 17:04:23.606070 29366 solver.cpp:218] Iteration 9250 (0.865843 iter/s, 57.7472s/50 iters), loss = 0.0169237
I0615 17:04:23.606241 29366 solver.cpp:237]     Train net output #0: loss = 0.0169236 (* 1 = 0.0169236 loss)
I0615 17:04:23.606269 29366 sgd_solver.cpp:105] Iteration 9250, lr = 0.01
I0615 17:05:21.361524 29366 solver.cpp:218] Iteration 9300 (0.865732 iter/s, 57.7546s/50 iters), loss = 0.0308718
I0615 17:05:21.361680 29366 solver.cpp:237]     Train net output #0: loss = 0.0308717 (* 1 = 0.0308717 loss)
I0615 17:05:21.361707 29366 sgd_solver.cpp:105] Iteration 9300, lr = 0.01
I0615 17:06:19.122521 29366 solver.cpp:218] Iteration 9350 (0.865649 iter/s, 57.7602s/50 iters), loss = 0.0202398
I0615 17:06:19.122699 29366 solver.cpp:237]     Train net output #0: loss = 0.0202397 (* 1 = 0.0202397 loss)
I0615 17:06:19.122725 29366 sgd_solver.cpp:105] Iteration 9350, lr = 0.01
I0615 17:07:16.872037 29366 solver.cpp:218] Iteration 9400 (0.865821 iter/s, 57.7487s/50 iters), loss = 0.0193138
I0615 17:07:16.872211 29366 solver.cpp:237]     Train net output #0: loss = 0.0193137 (* 1 = 0.0193137 loss)
I0615 17:07:16.872239 29366 sgd_solver.cpp:105] Iteration 9400, lr = 0.01
I0615 17:08:14.628494 29366 solver.cpp:218] Iteration 9450 (0.865717 iter/s, 57.7556s/50 iters), loss = 0.0160114
I0615 17:08:14.634174 29366 solver.cpp:237]     Train net output #0: loss = 0.0160113 (* 1 = 0.0160113 loss)
I0615 17:08:14.634204 29366 sgd_solver.cpp:105] Iteration 9450, lr = 0.01
I0615 17:09:12.398663 29366 solver.cpp:218] Iteration 9500 (0.865594 iter/s, 57.7638s/50 iters), loss = 0.0175127
I0615 17:09:12.398928 29366 solver.cpp:237]     Train net output #0: loss = 0.0175126 (* 1 = 0.0175126 loss)
I0615 17:09:12.398958 29366 sgd_solver.cpp:105] Iteration 9500, lr = 0.01
I0615 17:10:10.159152 29366 solver.cpp:218] Iteration 9550 (0.865658 iter/s, 57.7595s/50 iters), loss = 0.014326
I0615 17:10:10.159314 29366 solver.cpp:237]     Train net output #0: loss = 0.0143259 (* 1 = 0.0143259 loss)
I0615 17:10:10.159342 29366 sgd_solver.cpp:105] Iteration 9550, lr = 0.01
I0615 17:11:07.900916 29366 solver.cpp:218] Iteration 9600 (0.865937 iter/s, 57.7409s/50 iters), loss = 0.020017
I0615 17:11:07.901068 29366 solver.cpp:237]     Train net output #0: loss = 0.0200169 (* 1 = 0.0200169 loss)
I0615 17:11:07.901096 29366 sgd_solver.cpp:105] Iteration 9600, lr = 0.01
I0615 17:12:05.653831 29366 solver.cpp:218] Iteration 9650 (0.86577 iter/s, 57.7521s/50 iters), loss = 0.0148039
I0615 17:12:05.654059 29366 solver.cpp:237]     Train net output #0: loss = 0.0148038 (* 1 = 0.0148038 loss)
I0615 17:12:05.654086 29366 sgd_solver.cpp:105] Iteration 9650, lr = 0.01
I0615 17:13:03.406550 29366 solver.cpp:218] Iteration 9700 (0.865773 iter/s, 57.7518s/50 iters), loss = 0.0216888
I0615 17:13:03.406682 29366 solver.cpp:237]     Train net output #0: loss = 0.0216887 (* 1 = 0.0216887 loss)
I0615 17:13:03.406708 29366 sgd_solver.cpp:105] Iteration 9700, lr = 0.01
I0615 17:14:01.142176 29366 solver.cpp:218] Iteration 9750 (0.866028 iter/s, 57.7348s/50 iters), loss = 0.0205923
I0615 17:14:01.142305 29366 solver.cpp:237]     Train net output #0: loss = 0.0205922 (* 1 = 0.0205922 loss)
I0615 17:14:01.142333 29366 sgd_solver.cpp:105] Iteration 9750, lr = 0.01
I0615 17:14:58.875968 29366 solver.cpp:218] Iteration 9800 (0.866056 iter/s, 57.733s/50 iters), loss = 0.0225797
I0615 17:14:58.876116 29366 solver.cpp:237]     Train net output #0: loss = 0.0225796 (* 1 = 0.0225796 loss)
I0615 17:14:58.876145 29366 sgd_solver.cpp:105] Iteration 9800, lr = 0.01
I0615 17:15:56.608659 29366 solver.cpp:218] Iteration 9850 (0.866072 iter/s, 57.7319s/50 iters), loss = 0.0248856
I0615 17:15:56.608811 29366 solver.cpp:237]     Train net output #0: loss = 0.0248855 (* 1 = 0.0248855 loss)
I0615 17:15:56.608839 29366 sgd_solver.cpp:105] Iteration 9850, lr = 0.01
I0615 17:16:54.344218 29366 solver.cpp:218] Iteration 9900 (0.86603 iter/s, 57.7347s/50 iters), loss = 0.0139778
I0615 17:16:54.344393 29366 solver.cpp:237]     Train net output #0: loss = 0.0139777 (* 1 = 0.0139777 loss)
I0615 17:16:54.344420 29366 sgd_solver.cpp:105] Iteration 9900, lr = 0.01
I0615 17:17:52.088584 29366 solver.cpp:218] Iteration 9950 (0.865898 iter/s, 57.7435s/50 iters), loss = 0.024229
I0615 17:17:52.088757 29366 solver.cpp:237]     Train net output #0: loss = 0.0242289 (* 1 = 0.0242289 loss)
I0615 17:17:52.088783 29366 sgd_solver.cpp:105] Iteration 9950, lr = 0.01
I0615 17:18:48.674953 29366 solver.cpp:447] Snapshotting to binary proto file mobilenet/mobile_2_iter_10000.caffemodel
I0615 17:18:48.773123 29366 sgd_solver.cpp:273] Snapshotting solver state to binary proto file mobilenet/mobile_2_iter_10000.solverstate
I0615 17:18:49.952854 29366 solver.cpp:218] Iteration 10000 (0.864104 iter/s, 57.8634s/50 iters), loss = 0.0149619
I0615 17:18:49.952973 29366 solver.cpp:237]     Train net output #0: loss = 0.0149618 (* 1 = 0.0149618 loss)
I0615 17:18:49.953008 29366 sgd_solver.cpp:105] Iteration 10000, lr = 0.01
I0615 17:19:48.490597 29366 solver.cpp:218] Iteration 10050 (0.854176 iter/s, 58.536s/50 iters), loss = 0.0353979
I0615 17:19:48.498572 29366 solver.cpp:237]     Train net output #0: loss = 0.0353978 (* 1 = 0.0353978 loss)
I0615 17:19:48.498615 29366 sgd_solver.cpp:105] Iteration 10050, lr = 0.01
I0615 17:20:48.462486 29366 solver.cpp:218] Iteration 10100 (0.833845 iter/s, 59.9632s/50 iters), loss = 0.0125343
I0615 17:20:48.465646 29366 solver.cpp:237]     Train net output #0: loss = 0.0125342 (* 1 = 0.0125342 loss)
I0615 17:20:48.465680 29366 sgd_solver.cpp:105] Iteration 10100, lr = 0.01
I0615 17:21:47.262611 29366 solver.cpp:218] Iteration 10150 (0.850448 iter/s, 58.7925s/50 iters), loss = 0.0166411
I0615 17:21:47.266613 29366 solver.cpp:237]     Train net output #0: loss = 0.016641 (* 1 = 0.016641 loss)
I0615 17:21:47.266644 29366 sgd_solver.cpp:105] Iteration 10150, lr = 0.01
I0615 17:22:46.019584 29366 solver.cpp:218] Iteration 10200 (0.851031 iter/s, 58.7523s/50 iters), loss = 0.0170164
I0615 17:22:46.023645 29366 solver.cpp:237]     Train net output #0: loss = 0.0170163 (* 1 = 0.0170163 loss)
I0615 17:22:46.023684 29366 sgd_solver.cpp:105] Iteration 10200, lr = 0.01
I0615 17:23:45.134326 29366 solver.cpp:218] Iteration 10250 (0.845881 iter/s, 59.11s/50 iters), loss = 0.0145705
I0615 17:23:45.134567 29366 solver.cpp:237]     Train net output #0: loss = 0.0145704 (* 1 = 0.0145704 loss)
I0615 17:23:45.134598 29366 sgd_solver.cpp:105] Iteration 10250, lr = 0.01
I0615 17:24:42.898236 29366 solver.cpp:218] Iteration 10300 (0.865606 iter/s, 57.763s/50 iters), loss = 0.00854922
I0615 17:24:42.898473 29366 solver.cpp:237]     Train net output #0: loss = 0.00854912 (* 1 = 0.00854912 loss)
I0615 17:24:42.898504 29366 sgd_solver.cpp:105] Iteration 10300, lr = 0.01
I0615 17:25:40.669833 29366 solver.cpp:218] Iteration 10350 (0.86549 iter/s, 57.7707s/50 iters), loss = 0.0138819
I0615 17:25:40.670012 29366 solver.cpp:237]     Train net output #0: loss = 0.0138818 (* 1 = 0.0138818 loss)
I0615 17:25:40.670053 29366 sgd_solver.cpp:105] Iteration 10350, lr = 0.01
I0615 17:26:38.429600 29366 solver.cpp:218] Iteration 10400 (0.865667 iter/s, 57.7589s/50 iters), loss = 0.0132847
I0615 17:26:38.429759 29366 solver.cpp:237]     Train net output #0: loss = 0.0132846 (* 1 = 0.0132846 loss)
I0615 17:26:38.429785 29366 sgd_solver.cpp:105] Iteration 10400, lr = 0.01
I0615 17:27:36.196409 29366 solver.cpp:218] Iteration 10450 (0.865561 iter/s, 57.766s/50 iters), loss = 0.00991735
I0615 17:27:36.196565 29366 solver.cpp:237]     Train net output #0: loss = 0.00991724 (* 1 = 0.00991724 loss)
I0615 17:27:36.196596 29366 sgd_solver.cpp:105] Iteration 10450, lr = 0.01
I0615 17:28:33.969002 29366 solver.cpp:218] Iteration 10500 (0.865474 iter/s, 57.7718s/50 iters), loss = 0.0134535
I0615 17:28:33.969178 29366 solver.cpp:237]     Train net output #0: loss = 0.0134534 (* 1 = 0.0134534 loss)
I0615 17:28:33.969208 29366 sgd_solver.cpp:105] Iteration 10500, lr = 0.01
I0615 17:29:31.846412 29366 solver.cpp:218] Iteration 10550 (0.863907 iter/s, 57.8766s/50 iters), loss = 0.0157045
I0615 17:29:31.846597 29366 solver.cpp:237]     Train net output #0: loss = 0.0157044 (* 1 = 0.0157044 loss)
I0615 17:29:31.846624 29366 sgd_solver.cpp:105] Iteration 10550, lr = 0.01
I0615 17:30:29.604756 29366 solver.cpp:218] Iteration 10600 (0.865688 iter/s, 57.7575s/50 iters), loss = 0.0104398
I0615 17:30:29.604895 29366 solver.cpp:237]     Train net output #0: loss = 0.0104397 (* 1 = 0.0104397 loss)
I0615 17:30:29.604923 29366 sgd_solver.cpp:105] Iteration 10600, lr = 0.01
I0615 17:31:27.374406 29366 solver.cpp:218] Iteration 10650 (0.865518 iter/s, 57.7689s/50 iters), loss = 0.0146379
I0615 17:31:27.374680 29366 solver.cpp:237]     Train net output #0: loss = 0.0146378 (* 1 = 0.0146378 loss)
I0615 17:31:27.374709 29366 sgd_solver.cpp:105] Iteration 10650, lr = 0.01
I0615 17:32:25.131436 29366 solver.cpp:218] Iteration 10700 (0.865709 iter/s, 57.7561s/50 iters), loss = 0.0213928
I0615 17:32:25.131626 29366 solver.cpp:237]     Train net output #0: loss = 0.0213927 (* 1 = 0.0213927 loss)
I0615 17:32:25.131654 29366 sgd_solver.cpp:105] Iteration 10700, lr = 0.01
I0615 17:33:22.883800 29366 solver.cpp:218] Iteration 10750 (0.865778 iter/s, 57.7515s/50 iters), loss = 0.0340557
I0615 17:33:22.883960 29366 solver.cpp:237]     Train net output #0: loss = 0.0340556 (* 1 = 0.0340556 loss)
I0615 17:33:22.883986 29366 sgd_solver.cpp:105] Iteration 10750, lr = 0.01
I0615 17:34:20.647147 29366 solver.cpp:218] Iteration 10800 (0.865613 iter/s, 57.7625s/50 iters), loss = 0.0292234
I0615 17:34:20.647281 29366 solver.cpp:237]     Train net output #0: loss = 0.0292233 (* 1 = 0.0292233 loss)
I0615 17:34:20.647310 29366 sgd_solver.cpp:105] Iteration 10800, lr = 0.01
I0615 17:35:18.400652 29366 solver.cpp:218] Iteration 10850 (0.86576 iter/s, 57.7527s/50 iters), loss = 0.038179
I0615 17:35:18.400784 29366 solver.cpp:237]     Train net output #0: loss = 0.0381789 (* 1 = 0.0381789 loss)
I0615 17:35:18.400810 29366 sgd_solver.cpp:105] Iteration 10850, lr = 0.01
I0615 17:36:16.173763 29366 solver.cpp:218] Iteration 10900 (0.865467 iter/s, 57.7723s/50 iters), loss = 0.0155933
I0615 17:36:16.173898 29366 solver.cpp:237]     Train net output #0: loss = 0.0155932 (* 1 = 0.0155932 loss)
I0615 17:36:16.173925 29366 sgd_solver.cpp:105] Iteration 10900, lr = 0.01
I0615 17:37:13.981333 29366 solver.cpp:218] Iteration 10950 (0.864951 iter/s, 57.8067s/50 iters), loss = 0.0140955
I0615 17:37:13.981534 29366 solver.cpp:237]     Train net output #0: loss = 0.0140954 (* 1 = 0.0140954 loss)
I0615 17:37:13.981575 29366 sgd_solver.cpp:105] Iteration 10950, lr = 0.01
I0615 17:38:11.736450 29366 solver.cpp:218] Iteration 11000 (0.865737 iter/s, 57.7542s/50 iters), loss = 0.0129991
I0615 17:38:11.736605 29366 solver.cpp:237]     Train net output #0: loss = 0.012999 (* 1 = 0.012999 loss)
I0615 17:38:11.736632 29366 sgd_solver.cpp:105] Iteration 11000, lr = 0.01
I0615 17:39:09.508502 29366 solver.cpp:218] Iteration 11050 (0.865483 iter/s, 57.7712s/50 iters), loss = 0.0105459
I0615 17:39:09.508656 29366 solver.cpp:237]     Train net output #0: loss = 0.0105458 (* 1 = 0.0105458 loss)
I0615 17:39:09.508684 29366 sgd_solver.cpp:105] Iteration 11050, lr = 0.01
I0615 17:40:07.271756 29366 solver.cpp:218] Iteration 11100 (0.865615 iter/s, 57.7624s/50 iters), loss = 0.0122381
I0615 17:40:07.271900 29366 solver.cpp:237]     Train net output #0: loss = 0.012238 (* 1 = 0.012238 loss)
I0615 17:40:07.271925 29366 sgd_solver.cpp:105] Iteration 11100, lr = 0.01
I0615 17:41:05.032629 29366 solver.cpp:218] Iteration 11150 (0.86565 iter/s, 57.76s/50 iters), loss = 0.00974026
I0615 17:41:05.032780 29366 solver.cpp:237]     Train net output #0: loss = 0.00974016 (* 1 = 0.00974016 loss)
I0615 17:41:05.032809 29366 sgd_solver.cpp:105] Iteration 11150, lr = 0.01
I0615 17:42:02.787454 29366 solver.cpp:218] Iteration 11200 (0.865741 iter/s, 57.754s/50 iters), loss = 0.0193492
I0615 17:42:02.787580 29366 solver.cpp:237]     Train net output #0: loss = 0.0193491 (* 1 = 0.0193491 loss)
I0615 17:42:02.787606 29366 sgd_solver.cpp:105] Iteration 11200, lr = 0.01
I0615 17:43:00.551515 29366 solver.cpp:218] Iteration 11250 (0.865602 iter/s, 57.7633s/50 iters), loss = 0.0109489
I0615 17:43:00.551643 29366 solver.cpp:237]     Train net output #0: loss = 0.0109488 (* 1 = 0.0109488 loss)
I0615 17:43:00.551671 29366 sgd_solver.cpp:105] Iteration 11250, lr = 0.01
I0615 17:43:58.316875 29366 solver.cpp:218] Iteration 11300 (0.865583 iter/s, 57.7645s/50 iters), loss = 0.00908307
I0615 17:43:58.317021 29366 solver.cpp:237]     Train net output #0: loss = 0.00908297 (* 1 = 0.00908297 loss)
I0615 17:43:58.317047 29366 sgd_solver.cpp:105] Iteration 11300, lr = 0.01
I0615 17:44:56.072643 29366 solver.cpp:218] Iteration 11350 (0.865727 iter/s, 57.7549s/50 iters), loss = 0.0105964
I0615 17:44:56.072775 29366 solver.cpp:237]     Train net output #0: loss = 0.0105963 (* 1 = 0.0105963 loss)
I0615 17:44:56.072803 29366 sgd_solver.cpp:105] Iteration 11350, lr = 0.01
I0615 17:45:53.841336 29366 solver.cpp:218] Iteration 11400 (0.865533 iter/s, 57.7679s/50 iters), loss = 0.0128548
I0615 17:45:53.841470 29366 solver.cpp:237]     Train net output #0: loss = 0.0128547 (* 1 = 0.0128547 loss)
I0615 17:45:53.841496 29366 sgd_solver.cpp:105] Iteration 11400, lr = 0.01
I0615 17:46:51.602676 29366 solver.cpp:218] Iteration 11450 (0.865643 iter/s, 57.7605s/50 iters), loss = 0.0255701
I0615 17:46:51.602808 29366 solver.cpp:237]     Train net output #0: loss = 0.02557 (* 1 = 0.02557 loss)
I0615 17:46:51.602833 29366 sgd_solver.cpp:105] Iteration 11450, lr = 0.01
I0615 17:47:49.363266 29366 solver.cpp:218] Iteration 11500 (0.865654 iter/s, 57.7598s/50 iters), loss = 0.015419
I0615 17:47:49.363402 29366 solver.cpp:237]     Train net output #0: loss = 0.0154189 (* 1 = 0.0154189 loss)
I0615 17:47:49.363430 29366 sgd_solver.cpp:105] Iteration 11500, lr = 0.01
I0615 17:48:47.119293 29366 solver.cpp:218] Iteration 11550 (0.865723 iter/s, 57.7552s/50 iters), loss = 0.0339311
I0615 17:48:47.119441 29366 solver.cpp:237]     Train net output #0: loss = 0.0339311 (* 1 = 0.0339311 loss)
I0615 17:48:47.119467 29366 sgd_solver.cpp:105] Iteration 11550, lr = 0.01
I0615 17:49:44.879856 29366 solver.cpp:218] Iteration 11600 (0.865655 iter/s, 57.7597s/50 iters), loss = 0.0409006
I0615 17:49:44.879986 29366 solver.cpp:237]     Train net output #0: loss = 0.0409006 (* 1 = 0.0409006 loss)
I0615 17:49:44.880012 29366 sgd_solver.cpp:105] Iteration 11600, lr = 0.01
I0615 17:50:42.650987 29366 solver.cpp:218] Iteration 11650 (0.865496 iter/s, 57.7703s/50 iters), loss = 0.0278085
I0615 17:50:42.651228 29366 solver.cpp:237]     Train net output #0: loss = 0.0278084 (* 1 = 0.0278084 loss)
I0615 17:50:42.651264 29366 sgd_solver.cpp:105] Iteration 11650, lr = 0.01
I0615 17:51:40.409540 29366 solver.cpp:218] Iteration 11700 (0.865686 iter/s, 57.7576s/50 iters), loss = 0.0329435
I0615 17:51:40.409682 29366 solver.cpp:237]     Train net output #0: loss = 0.0329434 (* 1 = 0.0329434 loss)
I0615 17:51:40.409708 29366 sgd_solver.cpp:105] Iteration 11700, lr = 0.01
I0615 17:52:38.172931 29366 solver.cpp:218] Iteration 11750 (0.865612 iter/s, 57.7626s/50 iters), loss = 0.0250152
I0615 17:52:38.173055 29366 solver.cpp:237]     Train net output #0: loss = 0.0250151 (* 1 = 0.0250151 loss)
I0615 17:52:38.173084 29366 sgd_solver.cpp:105] Iteration 11750, lr = 0.01
I0615 17:53:35.942180 29366 solver.cpp:218] Iteration 11800 (0.865524 iter/s, 57.7684s/50 iters), loss = 0.0213555
I0615 17:53:35.942322 29366 solver.cpp:237]     Train net output #0: loss = 0.0213555 (* 1 = 0.0213555 loss)
I0615 17:53:35.942348 29366 sgd_solver.cpp:105] Iteration 11800, lr = 0.01
I0615 17:54:33.703143 29366 solver.cpp:218] Iteration 11850 (0.865649 iter/s, 57.7601s/50 iters), loss = 0.0226593
I0615 17:54:33.703316 29366 solver.cpp:237]     Train net output #0: loss = 0.0226592 (* 1 = 0.0226592 loss)
I0615 17:54:33.703343 29366 sgd_solver.cpp:105] Iteration 11850, lr = 0.01
I0615 17:55:31.463392 29366 solver.cpp:218] Iteration 11900 (0.86566 iter/s, 57.7594s/50 iters), loss = 0.00935657
I0615 17:55:31.463542 29366 solver.cpp:237]     Train net output #0: loss = 0.0093565 (* 1 = 0.0093565 loss)
I0615 17:55:31.463578 29366 sgd_solver.cpp:105] Iteration 11900, lr = 0.01
I0615 17:56:29.204345 29366 solver.cpp:218] Iteration 11950 (0.865949 iter/s, 57.7401s/50 iters), loss = 0.017243
I0615 17:56:29.204480 29366 solver.cpp:237]     Train net output #0: loss = 0.0172429 (* 1 = 0.0172429 loss)
I0615 17:56:29.204509 29366 sgd_solver.cpp:105] Iteration 11950, lr = 0.01
I0615 17:57:26.941596 29366 solver.cpp:218] Iteration 12000 (0.866005 iter/s, 57.7364s/50 iters), loss = 0.0381229
I0615 17:57:26.941751 29366 solver.cpp:237]     Train net output #0: loss = 0.0381228 (* 1 = 0.0381228 loss)
I0615 17:57:26.941786 29366 sgd_solver.cpp:105] Iteration 12000, lr = 0.01
I0615 17:58:24.683861 29366 solver.cpp:218] Iteration 12050 (0.86593 iter/s, 57.7414s/50 iters), loss = 0.0128044
I0615 17:58:24.684052 29366 solver.cpp:237]     Train net output #0: loss = 0.0128044 (* 1 = 0.0128044 loss)
I0615 17:58:24.684087 29366 sgd_solver.cpp:105] Iteration 12050, lr = 0.01
I0615 17:59:22.416383 29366 solver.cpp:218] Iteration 12100 (0.866076 iter/s, 57.7316s/50 iters), loss = 0.0102231
I0615 17:59:22.416559 29366 solver.cpp:237]     Train net output #0: loss = 0.0102231 (* 1 = 0.0102231 loss)
I0615 17:59:22.416591 29366 sgd_solver.cpp:105] Iteration 12100, lr = 0.01
I0615 18:00:20.146234 29366 solver.cpp:218] Iteration 12150 (0.866116 iter/s, 57.729s/50 iters), loss = 0.0212094
I0615 18:00:20.146379 29366 solver.cpp:237]     Train net output #0: loss = 0.0212093 (* 1 = 0.0212093 loss)
I0615 18:00:20.146407 29366 sgd_solver.cpp:105] Iteration 12150, lr = 0.01
I0615 18:01:17.882177 29366 solver.cpp:218] Iteration 12200 (0.866024 iter/s, 57.7351s/50 iters), loss = 0.00749876
I0615 18:01:17.882316 29366 solver.cpp:237]     Train net output #0: loss = 0.00749869 (* 1 = 0.00749869 loss)
I0615 18:01:17.882346 29366 sgd_solver.cpp:105] Iteration 12200, lr = 0.01
I0615 18:02:15.617532 29366 solver.cpp:218] Iteration 12250 (0.866033 iter/s, 57.7345s/50 iters), loss = 0.0133068
I0615 18:02:15.617758 29366 solver.cpp:237]     Train net output #0: loss = 0.0133067 (* 1 = 0.0133067 loss)
I0615 18:02:15.617786 29366 sgd_solver.cpp:105] Iteration 12250, lr = 0.01
I0615 18:03:13.355546 29366 solver.cpp:218] Iteration 12300 (0.865994 iter/s, 57.7371s/50 iters), loss = 0.018521
I0615 18:03:13.355705 29366 solver.cpp:237]     Train net output #0: loss = 0.0185209 (* 1 = 0.0185209 loss)
I0615 18:03:13.355733 29366 sgd_solver.cpp:105] Iteration 12300, lr = 0.01
I0615 18:04:11.105276 29366 solver.cpp:218] Iteration 12350 (0.865817 iter/s, 57.7489s/50 iters), loss = 0.0154156
I0615 18:04:11.105463 29366 solver.cpp:237]     Train net output #0: loss = 0.0154156 (* 1 = 0.0154156 loss)
I0615 18:04:11.105490 29366 sgd_solver.cpp:105] Iteration 12350, lr = 0.01
I0615 18:05:08.830479 29366 solver.cpp:218] Iteration 12400 (0.866186 iter/s, 57.7243s/50 iters), loss = 0.00953108
I0615 18:05:08.830634 29366 solver.cpp:237]     Train net output #0: loss = 0.00953101 (* 1 = 0.00953101 loss)
I0615 18:05:08.830663 29366 sgd_solver.cpp:105] Iteration 12400, lr = 0.01
I0615 18:06:06.562011 29366 solver.cpp:218] Iteration 12450 (0.86609 iter/s, 57.7307s/50 iters), loss = 0.0102001
I0615 18:06:06.562153 29366 solver.cpp:237]     Train net output #0: loss = 0.0102001 (* 1 = 0.0102001 loss)
I0615 18:06:06.562182 29366 sgd_solver.cpp:105] Iteration 12450, lr = 0.01
I0615 18:07:04.290346 29366 solver.cpp:218] Iteration 12500 (0.866138 iter/s, 57.7275s/50 iters), loss = 0.0300444
I0615 18:07:04.290488 29366 solver.cpp:237]     Train net output #0: loss = 0.0300444 (* 1 = 0.0300444 loss)
I0615 18:07:04.290520 29366 sgd_solver.cpp:105] Iteration 12500, lr = 0.01
I0615 18:08:02.018703 29366 solver.cpp:218] Iteration 12550 (0.866138 iter/s, 57.7275s/50 iters), loss = 0.0797801
I0615 18:08:02.018847 29366 solver.cpp:237]     Train net output #0: loss = 0.07978 (* 1 = 0.07978 loss)
I0615 18:08:02.018875 29366 sgd_solver.cpp:105] Iteration 12550, lr = 0.01
I0615 18:08:59.759959 29366 solver.cpp:218] Iteration 12600 (0.865944 iter/s, 57.7404s/50 iters), loss = 0.123585
I0615 18:08:59.760114 29366 solver.cpp:237]     Train net output #0: loss = 0.123585 (* 1 = 0.123585 loss)
I0615 18:08:59.760141 29366 sgd_solver.cpp:105] Iteration 12600, lr = 0.01
I0615 18:09:57.494984 29366 solver.cpp:218] Iteration 12650 (0.866037 iter/s, 57.7343s/50 iters), loss = 0.0352267
I0615 18:09:57.495122 29366 solver.cpp:237]     Train net output #0: loss = 0.0352267 (* 1 = 0.0352267 loss)
I0615 18:09:57.495151 29366 sgd_solver.cpp:105] Iteration 12650, lr = 0.01
I0615 18:10:55.229229 29366 solver.cpp:218] Iteration 12700 (0.866048 iter/s, 57.7335s/50 iters), loss = 0.0549996
I0615 18:10:55.229372 29366 solver.cpp:237]     Train net output #0: loss = 0.0549996 (* 1 = 0.0549996 loss)
I0615 18:10:55.229406 29366 sgd_solver.cpp:105] Iteration 12700, lr = 0.01
I0615 18:11:52.961004 29366 solver.cpp:218] Iteration 12750 (0.866085 iter/s, 57.7311s/50 iters), loss = 0.0521628
I0615 18:11:52.961148 29366 solver.cpp:237]     Train net output #0: loss = 0.0521627 (* 1 = 0.0521627 loss)
I0615 18:11:52.961177 29366 sgd_solver.cpp:105] Iteration 12750, lr = 0.01
I0615 18:12:50.702854 29366 solver.cpp:218] Iteration 12800 (0.865934 iter/s, 57.7411s/50 iters), loss = 0.0153388
I0615 18:12:50.702996 29366 solver.cpp:237]     Train net output #0: loss = 0.0153387 (* 1 = 0.0153387 loss)
I0615 18:12:50.703024 29366 sgd_solver.cpp:105] Iteration 12800, lr = 0.01
I0615 18:13:48.436626 29366 solver.cpp:218] Iteration 12850 (0.866055 iter/s, 57.7331s/50 iters), loss = 0.0452527
I0615 18:13:48.436776 29366 solver.cpp:237]     Train net output #0: loss = 0.0452527 (* 1 = 0.0452527 loss)
I0615 18:13:48.436803 29366 sgd_solver.cpp:105] Iteration 12850, lr = 0.01
I0615 18:14:46.166133 29366 solver.cpp:218] Iteration 12900 (0.866119 iter/s, 57.7288s/50 iters), loss = 0.0243789
I0615 18:14:46.166267 29366 solver.cpp:237]     Train net output #0: loss = 0.0243788 (* 1 = 0.0243788 loss)
I0615 18:14:46.166296 29366 sgd_solver.cpp:105] Iteration 12900, lr = 0.01
I0615 18:15:43.906126 29366 solver.cpp:218] Iteration 12950 (0.865962 iter/s, 57.7393s/50 iters), loss = 0.0237176
I0615 18:15:43.906394 29366 solver.cpp:237]     Train net output #0: loss = 0.0237176 (* 1 = 0.0237176 loss)
I0615 18:15:43.906424 29366 sgd_solver.cpp:105] Iteration 12950, lr = 0.01
I0615 18:16:41.653864 29366 solver.cpp:218] Iteration 13000 (0.865847 iter/s, 57.7469s/50 iters), loss = 0.0169093
I0615 18:16:41.654070 29366 solver.cpp:237]     Train net output #0: loss = 0.0169092 (* 1 = 0.0169092 loss)
I0615 18:16:41.654100 29366 sgd_solver.cpp:105] Iteration 13000, lr = 0.01
I0615 18:17:39.395321 29366 solver.cpp:218] Iteration 13050 (0.865941 iter/s, 57.7407s/50 iters), loss = 0.0231892
I0615 18:17:39.395474 29366 solver.cpp:237]     Train net output #0: loss = 0.0231891 (* 1 = 0.0231891 loss)
I0615 18:17:39.395501 29366 sgd_solver.cpp:105] Iteration 13050, lr = 0.01
I0615 18:18:37.123962 29366 solver.cpp:218] Iteration 13100 (0.866132 iter/s, 57.7279s/50 iters), loss = 0.0287779
I0615 18:18:37.124094 29366 solver.cpp:237]     Train net output #0: loss = 0.0287778 (* 1 = 0.0287778 loss)
I0615 18:18:37.124122 29366 sgd_solver.cpp:105] Iteration 13100, lr = 0.01
I0615 18:19:34.855482 29366 solver.cpp:218] Iteration 13150 (0.866089 iter/s, 57.7308s/50 iters), loss = 0.0266907
I0615 18:19:34.855636 29366 solver.cpp:237]     Train net output #0: loss = 0.0266906 (* 1 = 0.0266906 loss)
I0615 18:19:34.855665 29366 sgd_solver.cpp:105] Iteration 13150, lr = 0.01
I0615 18:20:32.581542 29366 solver.cpp:218] Iteration 13200 (0.866171 iter/s, 57.7253s/50 iters), loss = 0.0177145
I0615 18:20:32.581686 29366 solver.cpp:237]     Train net output #0: loss = 0.0177144 (* 1 = 0.0177144 loss)
I0615 18:20:32.581712 29366 sgd_solver.cpp:105] Iteration 13200, lr = 0.01
I0615 18:21:30.306944 29366 solver.cpp:218] Iteration 13250 (0.866181 iter/s, 57.7247s/50 iters), loss = 0.0154547
I0615 18:21:30.307088 29366 solver.cpp:237]     Train net output #0: loss = 0.0154546 (* 1 = 0.0154546 loss)
I0615 18:21:30.307118 29366 sgd_solver.cpp:105] Iteration 13250, lr = 0.01
I0615 18:22:28.035791 29366 solver.cpp:218] Iteration 13300 (0.866129 iter/s, 57.7281s/50 iters), loss = 0.0120767
I0615 18:22:28.035938 29366 solver.cpp:237]     Train net output #0: loss = 0.0120767 (* 1 = 0.0120767 loss)
I0615 18:22:28.035966 29366 sgd_solver.cpp:105] Iteration 13300, lr = 0.01
I0615 18:23:25.769224 29366 solver.cpp:218] Iteration 13350 (0.86606 iter/s, 57.7327s/50 iters), loss = 0.0345463
I0615 18:23:25.769403 29366 solver.cpp:237]     Train net output #0: loss = 0.0345462 (* 1 = 0.0345462 loss)
I0615 18:23:25.769433 29366 sgd_solver.cpp:105] Iteration 13350, lr = 0.01
I0615 18:24:23.509506 29366 solver.cpp:218] Iteration 13400 (0.865958 iter/s, 57.7395s/50 iters), loss = 0.0130766
I0615 18:24:23.509671 29366 solver.cpp:237]     Train net output #0: loss = 0.0130765 (* 1 = 0.0130765 loss)
I0615 18:24:23.509706 29366 sgd_solver.cpp:105] Iteration 13400, lr = 0.01
I0615 18:25:21.246223 29366 solver.cpp:218] Iteration 13450 (0.866011 iter/s, 57.736s/50 iters), loss = 0.0122546
I0615 18:25:21.246366 29366 solver.cpp:237]     Train net output #0: loss = 0.0122545 (* 1 = 0.0122545 loss)
I0615 18:25:21.246394 29366 sgd_solver.cpp:105] Iteration 13450, lr = 0.01
I0615 18:26:18.979770 29366 solver.cpp:218] Iteration 13500 (0.866059 iter/s, 57.7328s/50 iters), loss = 0.0099889
I0615 18:26:18.979933 29366 solver.cpp:237]     Train net output #0: loss = 0.00998883 (* 1 = 0.00998883 loss)
I0615 18:26:18.979961 29366 sgd_solver.cpp:105] Iteration 13500, lr = 0.01
I0615 18:27:16.731462 29366 solver.cpp:218] Iteration 13550 (0.865787 iter/s, 57.7509s/50 iters), loss = 0.00981941
I0615 18:27:16.731642 29366 solver.cpp:237]     Train net output #0: loss = 0.00981934 (* 1 = 0.00981934 loss)
I0615 18:27:16.731669 29366 sgd_solver.cpp:105] Iteration 13550, lr = 0.01
I0615 18:28:14.492350 29366 solver.cpp:218] Iteration 13600 (0.865649 iter/s, 57.7601s/50 iters), loss = 0.0146123
I0615 18:28:14.492532 29366 solver.cpp:237]     Train net output #0: loss = 0.0146122 (* 1 = 0.0146122 loss)
I0615 18:28:14.492563 29366 sgd_solver.cpp:105] Iteration 13600, lr = 0.01
I0615 18:29:12.261847 29366 solver.cpp:218] Iteration 13650 (0.86552 iter/s, 57.7687s/50 iters), loss = 0.0152805
I0615 18:29:12.262120 29366 solver.cpp:237]     Train net output #0: loss = 0.0152805 (* 1 = 0.0152805 loss)
I0615 18:29:12.262148 29366 sgd_solver.cpp:105] Iteration 13650, lr = 0.01
I0615 18:30:10.027518 29366 solver.cpp:218] Iteration 13700 (0.865579 iter/s, 57.7648s/50 iters), loss = 0.00694855
I0615 18:30:10.027748 29366 solver.cpp:237]     Train net output #0: loss = 0.00694848 (* 1 = 0.00694848 loss)
I0615 18:30:10.027791 29366 sgd_solver.cpp:105] Iteration 13700, lr = 0.01
I0615 18:31:07.796857 29366 solver.cpp:218] Iteration 13750 (0.865524 iter/s, 57.7685s/50 iters), loss = 0.0117863
I0615 18:31:07.797049 29366 solver.cpp:237]     Train net output #0: loss = 0.0117862 (* 1 = 0.0117862 loss)
I0615 18:31:07.797077 29366 sgd_solver.cpp:105] Iteration 13750, lr = 0.01
I0615 18:32:05.570929 29366 solver.cpp:218] Iteration 13800 (0.865452 iter/s, 57.7733s/50 iters), loss = 0.00706669
I0615 18:32:05.571118 29366 solver.cpp:237]     Train net output #0: loss = 0.00706662 (* 1 = 0.00706662 loss)
I0615 18:32:05.571147 29366 sgd_solver.cpp:105] Iteration 13800, lr = 0.01
I0615 18:33:03.334282 29366 solver.cpp:218] Iteration 13850 (0.865613 iter/s, 57.7626s/50 iters), loss = 0.0160324
I0615 18:33:03.334614 29366 solver.cpp:237]     Train net output #0: loss = 0.0160324 (* 1 = 0.0160324 loss)
I0615 18:33:03.334645 29366 sgd_solver.cpp:105] Iteration 13850, lr = 0.01
I0615 18:34:01.104343 29366 solver.cpp:218] Iteration 13900 (0.865514 iter/s, 57.7691s/50 iters), loss = 0.0116202
I0615 18:34:01.104542 29366 solver.cpp:237]     Train net output #0: loss = 0.0116202 (* 1 = 0.0116202 loss)
I0615 18:34:01.104571 29366 sgd_solver.cpp:105] Iteration 13900, lr = 0.01
I0615 18:34:58.872608 29366 solver.cpp:218] Iteration 13950 (0.865539 iter/s, 57.7675s/50 iters), loss = 0.00813832
I0615 18:34:58.872802 29366 solver.cpp:237]     Train net output #0: loss = 0.00813825 (* 1 = 0.00813825 loss)
I0615 18:34:58.872830 29366 sgd_solver.cpp:105] Iteration 13950, lr = 0.01
I0615 18:35:56.639117 29366 solver.cpp:218] Iteration 14000 (0.865565 iter/s, 57.7657s/50 iters), loss = 0.00903424
I0615 18:35:56.639339 29366 solver.cpp:237]     Train net output #0: loss = 0.00903417 (* 1 = 0.00903417 loss)
I0615 18:35:56.639369 29366 sgd_solver.cpp:105] Iteration 14000, lr = 0.01
I0615 18:36:54.405865 29366 solver.cpp:218] Iteration 14050 (0.865562 iter/s, 57.7659s/50 iters), loss = 0.00836061
I0615 18:36:54.406061 29366 solver.cpp:237]     Train net output #0: loss = 0.00836054 (* 1 = 0.00836054 loss)
I0615 18:36:54.406090 29366 sgd_solver.cpp:105] Iteration 14050, lr = 0.01
I0615 18:37:52.149708 29366 solver.cpp:218] Iteration 14100 (0.865905 iter/s, 57.743s/50 iters), loss = 0.00973448
I0615 18:37:52.149847 29366 solver.cpp:237]     Train net output #0: loss = 0.00973441 (* 1 = 0.00973441 loss)
I0615 18:37:52.149875 29366 sgd_solver.cpp:105] Iteration 14100, lr = 0.01
I0615 18:38:49.888860 29366 solver.cpp:218] Iteration 14150 (0.865975 iter/s, 57.7384s/50 iters), loss = 0.0110341
I0615 18:38:49.889091 29366 solver.cpp:237]     Train net output #0: loss = 0.011034 (* 1 = 0.011034 loss)
I0615 18:38:49.889120 29366 sgd_solver.cpp:105] Iteration 14150, lr = 0.01
I0615 18:39:47.637948 29366 solver.cpp:218] Iteration 14200 (0.865827 iter/s, 57.7483s/50 iters), loss = 0.0109954
I0615 18:39:47.638108 29366 solver.cpp:237]     Train net output #0: loss = 0.0109953 (* 1 = 0.0109953 loss)
I0615 18:39:47.638137 29366 sgd_solver.cpp:105] Iteration 14200, lr = 0.01
I0615 18:40:45.437845 29366 solver.cpp:218] Iteration 14250 (0.865065 iter/s, 57.7991s/50 iters), loss = 0.0117331
I0615 18:40:45.438026 29366 solver.cpp:237]     Train net output #0: loss = 0.011733 (* 1 = 0.011733 loss)
I0615 18:40:45.438056 29366 sgd_solver.cpp:105] Iteration 14250, lr = 0.01
I0615 18:41:43.218485 29366 solver.cpp:218] Iteration 14300 (0.865354 iter/s, 57.7798s/50 iters), loss = 0.0070208
I0615 18:41:43.221902 29366 solver.cpp:237]     Train net output #0: loss = 0.00702073 (* 1 = 0.00702073 loss)
I0615 18:41:43.221933 29366 sgd_solver.cpp:105] Iteration 14300, lr = 0.01
I0615 18:42:41.673458 29366 solver.cpp:218] Iteration 14350 (0.855418 iter/s, 58.4509s/50 iters), loss = 0.00616296
I0615 18:42:41.677604 29366 solver.cpp:237]     Train net output #0: loss = 0.00616289 (* 1 = 0.00616289 loss)
I0615 18:42:41.677635 29366 sgd_solver.cpp:105] Iteration 14350, lr = 0.01
I0615 18:43:39.432006 29366 solver.cpp:218] Iteration 14400 (0.865743 iter/s, 57.7538s/50 iters), loss = 0.0135348
I0615 18:43:39.432241 29366 solver.cpp:237]     Train net output #0: loss = 0.0135347 (* 1 = 0.0135347 loss)
I0615 18:43:39.432271 29366 sgd_solver.cpp:105] Iteration 14400, lr = 0.01
I0615 18:44:37.175263 29366 solver.cpp:218] Iteration 14450 (0.865914 iter/s, 57.7425s/50 iters), loss = 0.00959714
I0615 18:44:37.175415 29366 solver.cpp:237]     Train net output #0: loss = 0.00959708 (* 1 = 0.00959708 loss)
I0615 18:44:37.175441 29366 sgd_solver.cpp:105] Iteration 14450, lr = 0.01
I0615 18:45:34.924330 29366 solver.cpp:218] Iteration 14500 (0.865825 iter/s, 57.7484s/50 iters), loss = 0.00553093
I0615 18:45:34.924494 29366 solver.cpp:237]     Train net output #0: loss = 0.00553086 (* 1 = 0.00553086 loss)
I0615 18:45:34.924528 29366 sgd_solver.cpp:105] Iteration 14500, lr = 0.01
I0615 18:46:32.671866 29366 solver.cpp:218] Iteration 14550 (0.865848 iter/s, 57.7468s/50 iters), loss = 0.0105119
I0615 18:46:32.672014 29366 solver.cpp:237]     Train net output #0: loss = 0.0105118 (* 1 = 0.0105118 loss)
I0615 18:46:32.672044 29366 sgd_solver.cpp:105] Iteration 14550, lr = 0.01
I0615 18:47:30.404953 29366 solver.cpp:218] Iteration 14600 (0.866065 iter/s, 57.7324s/50 iters), loss = 0.00592411
I0615 18:47:30.405092 29366 solver.cpp:237]     Train net output #0: loss = 0.00592404 (* 1 = 0.00592404 loss)
I0615 18:47:30.405119 29366 sgd_solver.cpp:105] Iteration 14600, lr = 0.01
I0615 18:48:28.140045 29366 solver.cpp:218] Iteration 14650 (0.866035 iter/s, 57.7344s/50 iters), loss = 0.0168297
I0615 18:48:28.140180 29366 solver.cpp:237]     Train net output #0: loss = 0.0168296 (* 1 = 0.0168296 loss)
I0615 18:48:28.140210 29366 sgd_solver.cpp:105] Iteration 14650, lr = 0.01
I0615 18:49:25.865310 29366 solver.cpp:218] Iteration 14700 (0.866182 iter/s, 57.7246s/50 iters), loss = 0.0123033
I0615 18:49:25.865455 29366 solver.cpp:237]     Train net output #0: loss = 0.0123032 (* 1 = 0.0123032 loss)
I0615 18:49:25.865483 29366 sgd_solver.cpp:105] Iteration 14700, lr = 0.01
I0615 18:50:23.605940 29366 solver.cpp:218] Iteration 14750 (0.865952 iter/s, 57.7399s/50 iters), loss = 0.0170871
I0615 18:50:23.606081 29366 solver.cpp:237]     Train net output #0: loss = 0.0170871 (* 1 = 0.0170871 loss)
I0615 18:50:23.606114 29366 sgd_solver.cpp:105] Iteration 14750, lr = 0.01
I0615 18:51:21.332937 29366 solver.cpp:218] Iteration 14800 (0.866156 iter/s, 57.7263s/50 iters), loss = 0.0120399
I0615 18:51:21.333091 29366 solver.cpp:237]     Train net output #0: loss = 0.0120398 (* 1 = 0.0120398 loss)
I0615 18:51:21.333118 29366 sgd_solver.cpp:105] Iteration 14800, lr = 0.01
I0615 18:52:19.068557 29366 solver.cpp:218] Iteration 14850 (0.866027 iter/s, 57.7349s/50 iters), loss = 0.00669249
I0615 18:52:19.068698 29366 solver.cpp:237]     Train net output #0: loss = 0.00669241 (* 1 = 0.00669241 loss)
I0615 18:52:19.068728 29366 sgd_solver.cpp:105] Iteration 14850, lr = 0.01
I0615 18:53:16.802721 29366 solver.cpp:218] Iteration 14900 (0.866049 iter/s, 57.7335s/50 iters), loss = 0.0165075
I0615 18:53:16.802891 29366 solver.cpp:237]     Train net output #0: loss = 0.0165074 (* 1 = 0.0165074 loss)
I0615 18:53:16.802920 29366 sgd_solver.cpp:105] Iteration 14900, lr = 0.01
I0615 18:54:14.545099 29366 solver.cpp:218] Iteration 14950 (0.865926 iter/s, 57.7417s/50 iters), loss = 0.00877206
I0615 18:54:14.545241 29366 solver.cpp:237]     Train net output #0: loss = 0.00877198 (* 1 = 0.00877198 loss)
I0615 18:54:14.545269 29366 sgd_solver.cpp:105] Iteration 14950, lr = 0.01
I0615 18:55:12.268877 29366 solver.cpp:218] Iteration 15000 (0.866204 iter/s, 57.7231s/50 iters), loss = 0.00718759
I0615 18:55:12.269017 29366 solver.cpp:237]     Train net output #0: loss = 0.00718751 (* 1 = 0.00718751 loss)
I0615 18:55:12.269047 29366 sgd_solver.cpp:105] Iteration 15000, lr = 0.01
I0615 18:56:10.008615 29366 solver.cpp:218] Iteration 15050 (0.865965 iter/s, 57.739s/50 iters), loss = 0.00930869
I0615 18:56:10.008837 29366 solver.cpp:237]     Train net output #0: loss = 0.00930861 (* 1 = 0.00930861 loss)
I0615 18:56:10.008872 29366 sgd_solver.cpp:105] Iteration 15050, lr = 0.01
I0615 18:57:07.745759 29366 solver.cpp:218] Iteration 15100 (0.866005 iter/s, 57.7364s/50 iters), loss = 0.0150503
I0615 18:57:07.745913 29366 solver.cpp:237]     Train net output #0: loss = 0.0150502 (* 1 = 0.0150502 loss)
I0615 18:57:07.745941 29366 sgd_solver.cpp:105] Iteration 15100, lr = 0.01
I0615 18:58:05.480734 29366 solver.cpp:218] Iteration 15150 (0.866037 iter/s, 57.7343s/50 iters), loss = 0.00946761
I0615 18:58:05.480891 29366 solver.cpp:237]     Train net output #0: loss = 0.00946754 (* 1 = 0.00946754 loss)
I0615 18:58:05.480919 29366 sgd_solver.cpp:105] Iteration 15150, lr = 0.01
I0615 18:59:03.216636 29366 solver.cpp:218] Iteration 15200 (0.866023 iter/s, 57.7352s/50 iters), loss = 0.00864734
I0615 18:59:03.216771 29366 solver.cpp:237]     Train net output #0: loss = 0.00864727 (* 1 = 0.00864727 loss)
I0615 18:59:03.216801 29366 sgd_solver.cpp:105] Iteration 15200, lr = 0.01
I0615 19:00:00.945896 29366 solver.cpp:218] Iteration 15250 (0.866122 iter/s, 57.7286s/50 iters), loss = 0.0113254
I0615 19:00:00.946048 29366 solver.cpp:237]     Train net output #0: loss = 0.0113253 (* 1 = 0.0113253 loss)
I0615 19:00:00.946077 29366 sgd_solver.cpp:105] Iteration 15250, lr = 0.01
I0615 19:00:58.687125 29366 solver.cpp:218] Iteration 15300 (0.865942 iter/s, 57.7406s/50 iters), loss = 0.013852
I0615 19:00:58.687301 29366 solver.cpp:237]     Train net output #0: loss = 0.0138519 (* 1 = 0.0138519 loss)
I0615 19:00:58.687330 29366 sgd_solver.cpp:105] Iteration 15300, lr = 0.01
I0615 19:01:56.428872 29366 solver.cpp:218] Iteration 15350 (0.865934 iter/s, 57.7411s/50 iters), loss = 0.00961378
I0615 19:01:56.429004 29366 solver.cpp:237]     Train net output #0: loss = 0.00961371 (* 1 = 0.00961371 loss)
I0615 19:01:56.429034 29366 sgd_solver.cpp:105] Iteration 15350, lr = 0.01
I0615 19:02:54.157071 29366 solver.cpp:218] Iteration 15400 (0.866137 iter/s, 57.7276s/50 iters), loss = 0.0122662
I0615 19:02:54.157202 29366 solver.cpp:237]     Train net output #0: loss = 0.0122661 (* 1 = 0.0122661 loss)
I0615 19:02:54.157230 29366 sgd_solver.cpp:105] Iteration 15400, lr = 0.01
I0615 19:03:51.885126 29366 solver.cpp:218] Iteration 15450 (0.866139 iter/s, 57.7274s/50 iters), loss = 0.0254143
I0615 19:03:51.885274 29366 solver.cpp:237]     Train net output #0: loss = 0.0254142 (* 1 = 0.0254142 loss)
I0615 19:03:51.885303 29366 sgd_solver.cpp:105] Iteration 15450, lr = 0.01
I0615 19:04:49.615231 29366 solver.cpp:218] Iteration 15500 (0.866109 iter/s, 57.7295s/50 iters), loss = 0.00903917
I0615 19:04:49.615363 29366 solver.cpp:237]     Train net output #0: loss = 0.00903909 (* 1 = 0.00903909 loss)
I0615 19:04:49.615391 29366 sgd_solver.cpp:105] Iteration 15500, lr = 0.01
I0615 19:05:47.364606 29366 solver.cpp:218] Iteration 15550 (0.86582 iter/s, 57.7487s/50 iters), loss = 0.0113614
I0615 19:05:47.365106 29366 solver.cpp:237]     Train net output #0: loss = 0.0113613 (* 1 = 0.0113613 loss)
I0615 19:05:47.365135 29366 sgd_solver.cpp:105] Iteration 15550, lr = 0.01
I0615 19:06:45.146966 29366 solver.cpp:218] Iteration 15600 (0.865331 iter/s, 57.7814s/50 iters), loss = 0.00872146
I0615 19:06:45.147104 29366 solver.cpp:237]     Train net output #0: loss = 0.00872138 (* 1 = 0.00872138 loss)
I0615 19:06:45.147133 29366 sgd_solver.cpp:105] Iteration 15600, lr = 0.01
I0615 19:07:42.882892 29366 solver.cpp:218] Iteration 15650 (0.866021 iter/s, 57.7353s/50 iters), loss = 0.00998807
I0615 19:07:42.883039 29366 solver.cpp:237]     Train net output #0: loss = 0.00998799 (* 1 = 0.00998799 loss)
I0615 19:07:42.883066 29366 sgd_solver.cpp:105] Iteration 15650, lr = 0.01
I0615 19:08:40.630081 29366 solver.cpp:218] Iteration 15700 (0.865853 iter/s, 57.7465s/50 iters), loss = 0.009768
I0615 19:08:40.630220 29366 solver.cpp:237]     Train net output #0: loss = 0.00976792 (* 1 = 0.00976792 loss)
I0615 19:08:40.630249 29366 sgd_solver.cpp:105] Iteration 15700, lr = 0.01
I0615 19:09:38.363800 29366 solver.cpp:218] Iteration 15750 (0.866055 iter/s, 57.7331s/50 iters), loss = 0.0172225
I0615 19:09:38.364015 29366 solver.cpp:237]     Train net output #0: loss = 0.0172224 (* 1 = 0.0172224 loss)
I0615 19:09:38.364055 29366 sgd_solver.cpp:105] Iteration 15750, lr = 0.01
I0615 19:10:36.093104 29366 solver.cpp:218] Iteration 15800 (0.866122 iter/s, 57.7286s/50 iters), loss = 0.0139252
I0615 19:10:36.093262 29366 solver.cpp:237]     Train net output #0: loss = 0.0139251 (* 1 = 0.0139251 loss)
I0615 19:10:36.093292 29366 sgd_solver.cpp:105] Iteration 15800, lr = 0.01
I0615 19:11:33.828913 29366 solver.cpp:218] Iteration 15850 (0.866024 iter/s, 57.7351s/50 iters), loss = 0.0126733
I0615 19:11:33.829090 29366 solver.cpp:237]     Train net output #0: loss = 0.0126732 (* 1 = 0.0126732 loss)
I0615 19:11:33.829118 29366 sgd_solver.cpp:105] Iteration 15850, lr = 0.01
I0615 19:12:31.553907 29366 solver.cpp:218] Iteration 15900 (0.866186 iter/s, 57.7243s/50 iters), loss = 0.00817072
I0615 19:12:31.554059 29366 solver.cpp:237]     Train net output #0: loss = 0.00817064 (* 1 = 0.00817064 loss)
I0615 19:12:31.554088 29366 sgd_solver.cpp:105] Iteration 15900, lr = 0.01
I0615 19:13:29.284325 29366 solver.cpp:218] Iteration 15950 (0.866105 iter/s, 57.7298s/50 iters), loss = 0.0112207
I0615 19:13:29.284482 29366 solver.cpp:237]     Train net output #0: loss = 0.0112207 (* 1 = 0.0112207 loss)
I0615 19:13:29.284509 29366 sgd_solver.cpp:105] Iteration 15950, lr = 0.01
I0615 19:14:27.018489 29366 solver.cpp:218] Iteration 16000 (0.866048 iter/s, 57.7335s/50 iters), loss = 0.0140666
I0615 19:14:27.018980 29366 solver.cpp:237]     Train net output #0: loss = 0.0140665 (* 1 = 0.0140665 loss)
I0615 19:14:27.019008 29366 sgd_solver.cpp:105] Iteration 16000, lr = 0.01
I0615 19:15:24.762157 29366 solver.cpp:218] Iteration 16050 (0.865911 iter/s, 57.7427s/50 iters), loss = 0.0187019
I0615 19:15:24.762312 29366 solver.cpp:237]     Train net output #0: loss = 0.0187018 (* 1 = 0.0187018 loss)
I0615 19:15:24.762341 29366 sgd_solver.cpp:105] Iteration 16050, lr = 0.01
I0615 19:16:22.503232 29366 solver.cpp:218] Iteration 16100 (0.865945 iter/s, 57.7404s/50 iters), loss = 0.00929292
I0615 19:16:22.503360 29366 solver.cpp:237]     Train net output #0: loss = 0.00929284 (* 1 = 0.00929284 loss)
I0615 19:16:22.503388 29366 sgd_solver.cpp:105] Iteration 16100, lr = 0.01
I0615 19:17:20.467113 29366 solver.cpp:218] Iteration 16150 (0.862616 iter/s, 57.9632s/50 iters), loss = 0.0160468
I0615 19:17:20.473817 29366 solver.cpp:237]     Train net output #0: loss = 0.0160467 (* 1 = 0.0160467 loss)
I0615 19:17:20.473855 29366 sgd_solver.cpp:105] Iteration 16150, lr = 0.01
I0615 19:18:18.547099 29366 solver.cpp:218] Iteration 16200 (0.860986 iter/s, 58.0729s/50 iters), loss = 0.0181348
I0615 19:18:18.547263 29366 solver.cpp:237]     Train net output #0: loss = 0.0181347 (* 1 = 0.0181347 loss)
I0615 19:18:18.547291 29366 sgd_solver.cpp:105] Iteration 16200, lr = 0.01
I0615 19:19:16.295584 29366 solver.cpp:218] Iteration 16250 (0.865831 iter/s, 57.748s/50 iters), loss = 0.0359855
I0615 19:19:16.295727 29366 solver.cpp:237]     Train net output #0: loss = 0.0359854 (* 1 = 0.0359854 loss)
I0615 19:19:16.295756 29366 sgd_solver.cpp:105] Iteration 16250, lr = 0.01
I0615 19:20:14.038319 29366 solver.cpp:218] Iteration 16300 (0.865917 iter/s, 57.7422s/50 iters), loss = 0.0193498
I0615 19:20:14.038465 29366 solver.cpp:237]     Train net output #0: loss = 0.0193497 (* 1 = 0.0193497 loss)
I0615 19:20:14.038494 29366 sgd_solver.cpp:105] Iteration 16300, lr = 0.01
I0615 19:21:11.796222 29366 solver.cpp:218] Iteration 16350 (0.86569 iter/s, 57.7574s/50 iters), loss = 0.0273604
I0615 19:21:11.796378 29366 solver.cpp:237]     Train net output #0: loss = 0.0273603 (* 1 = 0.0273603 loss)
I0615 19:21:11.796406 29366 sgd_solver.cpp:105] Iteration 16350, lr = 0.01
I0615 19:22:09.545024 29366 solver.cpp:218] Iteration 16400 (0.865826 iter/s, 57.7483s/50 iters), loss = 0.0680836
I0615 19:22:09.545172 29366 solver.cpp:237]     Train net output #0: loss = 0.0680835 (* 1 = 0.0680835 loss)
I0615 19:22:09.545200 29366 sgd_solver.cpp:105] Iteration 16400, lr = 0.01
I0615 19:23:07.290894 29366 solver.cpp:218] Iteration 16450 (0.86587 iter/s, 57.7454s/50 iters), loss = 0.0151104
I0615 19:23:07.291107 29366 solver.cpp:237]     Train net output #0: loss = 0.0151103 (* 1 = 0.0151103 loss)
I0615 19:23:07.291134 29366 sgd_solver.cpp:105] Iteration 16450, lr = 0.01
I0615 19:24:05.082617 29366 solver.cpp:218] Iteration 16500 (0.865184 iter/s, 57.7911s/50 iters), loss = 0.0288267
I0615 19:24:05.082759 29366 solver.cpp:237]     Train net output #0: loss = 0.0288266 (* 1 = 0.0288266 loss)
I0615 19:24:05.082788 29366 sgd_solver.cpp:105] Iteration 16500, lr = 0.01
I0615 19:25:02.831456 29366 solver.cpp:218] Iteration 16550 (0.865826 iter/s, 57.7483s/50 iters), loss = 0.0261192
I0615 19:25:02.831624 29366 solver.cpp:237]     Train net output #0: loss = 0.0261191 (* 1 = 0.0261191 loss)
I0615 19:25:02.831651 29366 sgd_solver.cpp:105] Iteration 16550, lr = 0.01
I0615 19:26:00.576542 29366 solver.cpp:218] Iteration 16600 (0.865883 iter/s, 57.7445s/50 iters), loss = 0.254311
I0615 19:26:00.576668 29366 solver.cpp:237]     Train net output #0: loss = 0.254311 (* 1 = 0.254311 loss)
I0615 19:26:00.576696 29366 sgd_solver.cpp:105] Iteration 16600, lr = 0.01
I0615 19:26:58.312919 29366 solver.cpp:218] Iteration 16650 (0.866013 iter/s, 57.7359s/50 iters), loss = 0.292619
I0615 19:26:58.313057 29366 solver.cpp:237]     Train net output #0: loss = 0.292619 (* 1 = 0.292619 loss)
I0615 19:26:58.313087 29366 sgd_solver.cpp:105] Iteration 16650, lr = 0.01
I0615 19:27:56.067478 29366 solver.cpp:218] Iteration 16700 (0.86574 iter/s, 57.754s/50 iters), loss = 0.438862
I0615 19:27:56.067623 29366 solver.cpp:237]     Train net output #0: loss = 0.438862 (* 1 = 0.438862 loss)
I0615 19:27:56.067651 29366 sgd_solver.cpp:105] Iteration 16700, lr = 0.01
I0615 19:28:53.819595 29366 solver.cpp:218] Iteration 16750 (0.865777 iter/s, 57.7516s/50 iters), loss = 0.368559
I0615 19:28:53.819754 29366 solver.cpp:237]     Train net output #0: loss = 0.368559 (* 1 = 0.368559 loss)
I0615 19:28:53.819782 29366 sgd_solver.cpp:105] Iteration 16750, lr = 0.01
I0615 19:29:51.573967 29366 solver.cpp:218] Iteration 16800 (0.865743 iter/s, 57.7538s/50 iters), loss = 0.379426
I0615 19:29:51.574127 29366 solver.cpp:237]     Train net output #0: loss = 0.379426 (* 1 = 0.379426 loss)
I0615 19:29:51.574154 29366 sgd_solver.cpp:105] Iteration 16800, lr = 0.01
I0615 19:30:49.331898 29366 solver.cpp:218] Iteration 16850 (0.86569 iter/s, 57.7574s/50 iters), loss = 0.285202
I0615 19:30:49.332051 29366 solver.cpp:237]     Train net output #0: loss = 0.285202 (* 1 = 0.285202 loss)
I0615 19:30:49.332079 29366 sgd_solver.cpp:105] Iteration 16850, lr = 0.01
I0615 19:31:47.103642 29366 solver.cpp:218] Iteration 16900 (0.865483 iter/s, 57.7712s/50 iters), loss = 0.165249
I0615 19:31:47.103776 29366 solver.cpp:237]     Train net output #0: loss = 0.165249 (* 1 = 0.165249 loss)
I0615 19:31:47.103803 29366 sgd_solver.cpp:105] Iteration 16900, lr = 0.01
I0615 19:32:44.904815 29366 solver.cpp:218] Iteration 16950 (0.865042 iter/s, 57.8006s/50 iters), loss = 0.208541
I0615 19:32:44.904978 29366 solver.cpp:237]     Train net output #0: loss = 0.208541 (* 1 = 0.208541 loss)
I0615 19:32:44.905009 29366 sgd_solver.cpp:105] Iteration 16950, lr = 0.01
I0615 19:33:42.654228 29366 solver.cpp:218] Iteration 17000 (0.865818 iter/s, 57.7489s/50 iters), loss = 0.128119
I0615 19:33:42.654366 29366 solver.cpp:237]     Train net output #0: loss = 0.128119 (* 1 = 0.128119 loss)
I0615 19:33:42.654395 29366 sgd_solver.cpp:105] Iteration 17000, lr = 0.01
I0615 19:34:40.413547 29366 solver.cpp:218] Iteration 17050 (0.865669 iter/s, 57.7588s/50 iters), loss = 0.0987685
I0615 19:34:40.413687 29366 solver.cpp:237]     Train net output #0: loss = 0.0987685 (* 1 = 0.0987685 loss)
I0615 19:34:40.413715 29366 sgd_solver.cpp:105] Iteration 17050, lr = 0.01
I0615 19:35:38.152235 29366 solver.cpp:218] Iteration 17100 (0.865979 iter/s, 57.7381s/50 iters), loss = 0.0816012
I0615 19:35:38.152459 29366 solver.cpp:237]     Train net output #0: loss = 0.0816012 (* 1 = 0.0816012 loss)
I0615 19:35:38.152488 29366 sgd_solver.cpp:105] Iteration 17100, lr = 0.01
I0615 19:36:35.900058 29366 solver.cpp:218] Iteration 17150 (0.865843 iter/s, 57.7472s/50 iters), loss = 0.0620993
I0615 19:36:35.900218 29366 solver.cpp:237]     Train net output #0: loss = 0.0620993 (* 1 = 0.0620993 loss)
I0615 19:36:35.900244 29366 sgd_solver.cpp:105] Iteration 17150, lr = 0.01
I0615 19:37:33.663887 29366 solver.cpp:218] Iteration 17200 (0.865602 iter/s, 57.7633s/50 iters), loss = 0.0366147
I0615 19:37:33.664077 29366 solver.cpp:237]     Train net output #0: loss = 0.0366147 (* 1 = 0.0366147 loss)
I0615 19:37:33.664105 29366 sgd_solver.cpp:105] Iteration 17200, lr = 0.01
I0615 19:38:31.438084 29366 solver.cpp:218] Iteration 17250 (0.865447 iter/s, 57.7736s/50 iters), loss = 0.0259246
I0615 19:38:31.438274 29366 solver.cpp:237]     Train net output #0: loss = 0.0259246 (* 1 = 0.0259246 loss)
I0615 19:38:31.438303 29366 sgd_solver.cpp:105] Iteration 17250, lr = 0.01
I0615 19:39:29.252135 29366 solver.cpp:218] Iteration 17300 (0.864851 iter/s, 57.8134s/50 iters), loss = 0.0602348
I0615 19:39:29.252321 29366 solver.cpp:237]     Train net output #0: loss = 0.0602348 (* 1 = 0.0602348 loss)
I0615 19:39:29.252351 29366 sgd_solver.cpp:105] Iteration 17300, lr = 0.01
I0615 19:40:27.028914 29366 solver.cpp:218] Iteration 17350 (0.865409 iter/s, 57.7762s/50 iters), loss = 0.0181373
I0615 19:40:27.029083 29366 solver.cpp:237]     Train net output #0: loss = 0.0181373 (* 1 = 0.0181373 loss)
I0615 19:40:27.029111 29366 sgd_solver.cpp:105] Iteration 17350, lr = 0.01
I0615 19:41:24.798315 29366 solver.cpp:218] Iteration 17400 (0.865519 iter/s, 57.7688s/50 iters), loss = 0.0223634
I0615 19:41:24.798492 29366 solver.cpp:237]     Train net output #0: loss = 0.0223634 (* 1 = 0.0223634 loss)
I0615 19:41:24.798533 29366 sgd_solver.cpp:105] Iteration 17400, lr = 0.01
I0615 19:42:22.569651 29366 solver.cpp:218] Iteration 17450 (0.86549 iter/s, 57.7707s/50 iters), loss = 0.0194194
I0615 19:42:22.569790 29366 solver.cpp:237]     Train net output #0: loss = 0.0194194 (* 1 = 0.0194194 loss)
I0615 19:42:22.569819 29366 sgd_solver.cpp:105] Iteration 17450, lr = 0.01
I0615 19:43:20.340234 29366 solver.cpp:218] Iteration 17500 (0.865501 iter/s, 57.77s/50 iters), loss = 0.023057
I0615 19:43:20.340935 29366 solver.cpp:237]     Train net output #0: loss = 0.023057 (* 1 = 0.023057 loss)
I0615 19:43:20.340963 29366 sgd_solver.cpp:105] Iteration 17500, lr = 0.01
I0615 19:44:18.114464 29366 solver.cpp:218] Iteration 17550 (0.865455 iter/s, 57.7731s/50 iters), loss = 0.0147034
I0615 19:44:18.114645 29366 solver.cpp:237]     Train net output #0: loss = 0.0147034 (* 1 = 0.0147034 loss)
I0615 19:44:18.114675 29366 sgd_solver.cpp:105] Iteration 17550, lr = 0.01
I0615 19:45:15.884306 29366 solver.cpp:218] Iteration 17600 (0.865513 iter/s, 57.7692s/50 iters), loss = 0.0119764
I0615 19:45:15.884459 29366 solver.cpp:237]     Train net output #0: loss = 0.0119764 (* 1 = 0.0119764 loss)
I0615 19:45:15.884486 29366 sgd_solver.cpp:105] Iteration 17600, lr = 0.01
I0615 19:46:13.668723 29366 solver.cpp:218] Iteration 17650 (0.865294 iter/s, 57.7838s/50 iters), loss = 0.018473
I0615 19:46:13.669013 29366 solver.cpp:237]     Train net output #0: loss = 0.018473 (* 1 = 0.018473 loss)
I0615 19:46:13.669044 29366 sgd_solver.cpp:105] Iteration 17650, lr = 0.01
I0615 19:47:11.434788 29366 solver.cpp:218] Iteration 17700 (0.865571 iter/s, 57.7653s/50 iters), loss = 0.0138352
I0615 19:47:11.434945 29366 solver.cpp:237]     Train net output #0: loss = 0.0138351 (* 1 = 0.0138351 loss)
I0615 19:47:11.434974 29366 sgd_solver.cpp:105] Iteration 17700, lr = 0.01
I0615 19:48:09.194222 29366 solver.cpp:218] Iteration 17750 (0.865668 iter/s, 57.7588s/50 iters), loss = 0.0093587
I0615 19:48:09.194424 29366 solver.cpp:237]     Train net output #0: loss = 0.00935869 (* 1 = 0.00935869 loss)
I0615 19:48:09.194453 29366 sgd_solver.cpp:105] Iteration 17750, lr = 0.01
I0615 19:49:06.952247 29366 solver.cpp:218] Iteration 17800 (0.86569 iter/s, 57.7574s/50 iters), loss = 0.00735575
I0615 19:49:06.952443 29366 solver.cpp:237]     Train net output #0: loss = 0.00735574 (* 1 = 0.00735574 loss)
I0615 19:49:06.952481 29366 sgd_solver.cpp:105] Iteration 17800, lr = 0.01
I0615 19:50:04.694449 29366 solver.cpp:218] Iteration 17850 (0.865928 iter/s, 57.7416s/50 iters), loss = 0.00797239
I0615 19:50:04.694600 29366 solver.cpp:237]     Train net output #0: loss = 0.00797237 (* 1 = 0.00797237 loss)
I0615 19:50:04.694634 29366 sgd_solver.cpp:105] Iteration 17850, lr = 0.01
I0615 19:51:02.436779 29366 solver.cpp:218] Iteration 17900 (0.865925 iter/s, 57.7417s/50 iters), loss = 0.00782377
I0615 19:51:02.436920 29366 solver.cpp:237]     Train net output #0: loss = 0.00782376 (* 1 = 0.00782376 loss)
I0615 19:51:02.436950 29366 sgd_solver.cpp:105] Iteration 17900, lr = 0.01
I0615 19:52:00.179703 29366 solver.cpp:218] Iteration 17950 (0.865917 iter/s, 57.7423s/50 iters), loss = 0.00975706
I0615 19:52:00.179842 29366 solver.cpp:237]     Train net output #0: loss = 0.00975705 (* 1 = 0.00975705 loss)
I0615 19:52:00.179869 29366 sgd_solver.cpp:105] Iteration 17950, lr = 0.01
I0615 19:52:57.909531 29366 solver.cpp:218] Iteration 18000 (0.866114 iter/s, 57.7291s/50 iters), loss = 0.0130587
I0615 19:52:57.909660 29366 solver.cpp:237]     Train net output #0: loss = 0.0130587 (* 1 = 0.0130587 loss)
I0615 19:52:57.909688 29366 sgd_solver.cpp:105] Iteration 18000, lr = 0.01
I0615 19:53:55.642130 29366 solver.cpp:218] Iteration 18050 (0.866072 iter/s, 57.7319s/50 iters), loss = 0.00806735
I0615 19:53:55.642285 29366 solver.cpp:237]     Train net output #0: loss = 0.00806734 (* 1 = 0.00806734 loss)
I0615 19:53:55.642314 29366 sgd_solver.cpp:105] Iteration 18050, lr = 0.01
I0615 19:54:53.378170 29366 solver.cpp:218] Iteration 18100 (0.866021 iter/s, 57.7353s/50 iters), loss = 0.0109928
I0615 19:54:53.378365 29366 solver.cpp:237]     Train net output #0: loss = 0.0109928 (* 1 = 0.0109928 loss)
I0615 19:54:53.378393 29366 sgd_solver.cpp:105] Iteration 18100, lr = 0.01
I0615 19:55:51.176877 29366 solver.cpp:218] Iteration 18150 (0.865083 iter/s, 57.798s/50 iters), loss = 0.0181103
I0615 19:55:51.177016 29366 solver.cpp:237]     Train net output #0: loss = 0.0181103 (* 1 = 0.0181103 loss)
I0615 19:55:51.177044 29366 sgd_solver.cpp:105] Iteration 18150, lr = 0.01
I0615 19:56:48.910797 29366 solver.cpp:218] Iteration 18200 (0.866053 iter/s, 57.7332s/50 iters), loss = 0.0170776
I0615 19:56:48.910936 29366 solver.cpp:237]     Train net output #0: loss = 0.0170776 (* 1 = 0.0170776 loss)
I0615 19:56:48.910964 29366 sgd_solver.cpp:105] Iteration 18200, lr = 0.01
I0615 19:57:46.642035 29366 solver.cpp:218] Iteration 18250 (0.866093 iter/s, 57.7305s/50 iters), loss = 0.00703501
I0615 19:57:46.642180 29366 solver.cpp:237]     Train net output #0: loss = 0.007035 (* 1 = 0.007035 loss)
I0615 19:57:46.642210 29366 sgd_solver.cpp:105] Iteration 18250, lr = 0.01
I0615 19:58:44.364506 29366 solver.cpp:218] Iteration 18300 (0.866224 iter/s, 57.7218s/50 iters), loss = 0.0081791
I0615 19:58:44.364653 29366 solver.cpp:237]     Train net output #0: loss = 0.00817909 (* 1 = 0.00817909 loss)
I0615 19:58:44.364681 29366 sgd_solver.cpp:105] Iteration 18300, lr = 0.01
I0615 19:59:42.095274 29366 solver.cpp:218] Iteration 18350 (0.8661 iter/s, 57.7301s/50 iters), loss = 0.00467195
I0615 19:59:42.095412 29366 solver.cpp:237]     Train net output #0: loss = 0.00467194 (* 1 = 0.00467194 loss)
I0615 19:59:42.095441 29366 sgd_solver.cpp:105] Iteration 18350, lr = 0.01
I0615 20:00:39.846446 29366 solver.cpp:218] Iteration 18400 (0.865794 iter/s, 57.7505s/50 iters), loss = 0.00938451
I0615 20:00:39.846583 29366 solver.cpp:237]     Train net output #0: loss = 0.0093845 (* 1 = 0.0093845 loss)
I0615 20:00:39.846612 29366 sgd_solver.cpp:105] Iteration 18400, lr = 0.01
I0615 20:01:37.582986 29366 solver.cpp:218] Iteration 18450 (0.866013 iter/s, 57.7358s/50 iters), loss = 0.00790789
I0615 20:01:37.583109 29366 solver.cpp:237]     Train net output #0: loss = 0.00790788 (* 1 = 0.00790788 loss)
I0615 20:01:37.583132 29366 sgd_solver.cpp:105] Iteration 18450, lr = 0.01
I0615 20:02:35.316529 29366 solver.cpp:218] Iteration 18500 (0.866058 iter/s, 57.7329s/50 iters), loss = 0.00539366
I0615 20:02:35.316720 29366 solver.cpp:237]     Train net output #0: loss = 0.00539365 (* 1 = 0.00539365 loss)
I0615 20:02:35.316750 29366 sgd_solver.cpp:105] Iteration 18500, lr = 0.01
I0615 20:03:33.041062 29366 solver.cpp:218] Iteration 18550 (0.866194 iter/s, 57.7238s/50 iters), loss = 0.00758762
I0615 20:03:33.041203 29366 solver.cpp:237]     Train net output #0: loss = 0.00758761 (* 1 = 0.00758761 loss)
I0615 20:03:33.041230 29366 sgd_solver.cpp:105] Iteration 18550, lr = 0.01
I0615 20:04:30.779003 29366 solver.cpp:218] Iteration 18600 (0.865992 iter/s, 57.7372s/50 iters), loss = 0.00588332
I0615 20:04:30.779178 29366 solver.cpp:237]     Train net output #0: loss = 0.00588331 (* 1 = 0.00588331 loss)
I0615 20:04:30.779207 29366 sgd_solver.cpp:105] Iteration 18600, lr = 0.01
I0615 20:05:28.524340 29366 solver.cpp:218] Iteration 18650 (0.865882 iter/s, 57.7446s/50 iters), loss = 0.0142433
I0615 20:05:28.524482 29366 solver.cpp:237]     Train net output #0: loss = 0.0142433 (* 1 = 0.0142433 loss)
I0615 20:05:28.524510 29366 sgd_solver.cpp:105] Iteration 18650, lr = 0.01
I0615 20:06:26.259001 29366 solver.cpp:218] Iteration 18700 (0.866042 iter/s, 57.734s/50 iters), loss = 0.0236809
I0615 20:06:26.259142 29366 solver.cpp:237]     Train net output #0: loss = 0.0236809 (* 1 = 0.0236809 loss)
I0615 20:06:26.259172 29366 sgd_solver.cpp:105] Iteration 18700, lr = 0.01
I0615 20:07:24.014761 29366 solver.cpp:218] Iteration 18750 (0.865725 iter/s, 57.7551s/50 iters), loss = 0.0168965
I0615 20:07:24.014904 29366 solver.cpp:237]     Train net output #0: loss = 0.0168965 (* 1 = 0.0168965 loss)
I0615 20:07:24.014928 29366 sgd_solver.cpp:105] Iteration 18750, lr = 0.01
I0615 20:08:21.780560 29366 solver.cpp:218] Iteration 18800 (0.865576 iter/s, 57.765s/50 iters), loss = 0.021981
I0615 20:08:21.780755 29366 solver.cpp:237]     Train net output #0: loss = 0.021981 (* 1 = 0.021981 loss)
I0615 20:08:21.780789 29366 sgd_solver.cpp:105] Iteration 18800, lr = 0.01
I0615 20:09:19.541193 29366 solver.cpp:218] Iteration 18850 (0.865653 iter/s, 57.7599s/50 iters), loss = 0.032254
I0615 20:09:19.541342 29366 solver.cpp:237]     Train net output #0: loss = 0.032254 (* 1 = 0.032254 loss)
I0615 20:09:19.541370 29366 sgd_solver.cpp:105] Iteration 18850, lr = 0.01
I0615 20:10:17.312533 29366 solver.cpp:218] Iteration 18900 (0.865492 iter/s, 57.7706s/50 iters), loss = 0.00905235
I0615 20:10:17.312700 29366 solver.cpp:237]     Train net output #0: loss = 0.00905232 (* 1 = 0.00905232 loss)
I0615 20:10:17.312727 29366 sgd_solver.cpp:105] Iteration 18900, lr = 0.01
I0615 20:11:15.252562 29366 solver.cpp:218] Iteration 18950 (0.862973 iter/s, 57.9392s/50 iters), loss = 0.042598
I0615 20:11:15.253959 29366 solver.cpp:237]     Train net output #0: loss = 0.0425979 (* 1 = 0.0425979 loss)
I0615 20:11:15.253995 29366 sgd_solver.cpp:105] Iteration 18950, lr = 0.01
I0615 20:12:13.330796 29366 solver.cpp:218] Iteration 19000 (0.860938 iter/s, 58.0762s/50 iters), loss = 0.00981142
I0615 20:12:13.331033 29366 solver.cpp:237]     Train net output #0: loss = 0.0098114 (* 1 = 0.0098114 loss)
I0615 20:12:13.331073 29366 sgd_solver.cpp:105] Iteration 19000, lr = 0.01
I0615 20:13:11.356719 29366 solver.cpp:218] Iteration 19050 (0.86175 iter/s, 58.0215s/50 iters), loss = 0.0104593
I0615 20:13:11.356904 29366 solver.cpp:237]     Train net output #0: loss = 0.0104593 (* 1 = 0.0104593 loss)
I0615 20:13:11.356932 29366 sgd_solver.cpp:105] Iteration 19050, lr = 0.01
I0615 20:14:09.639194 29366 solver.cpp:218] Iteration 19100 (0.857902 iter/s, 58.2817s/50 iters), loss = 0.0192328
I0615 20:14:09.639521 29366 solver.cpp:237]     Train net output #0: loss = 0.0192328 (* 1 = 0.0192328 loss)
I0615 20:14:09.639549 29366 sgd_solver.cpp:105] Iteration 19100, lr = 0.01
I0615 20:15:07.841645 29366 solver.cpp:218] Iteration 19150 (0.859084 iter/s, 58.2015s/50 iters), loss = 0.00688126
I0615 20:15:07.841827 29366 solver.cpp:237]     Train net output #0: loss = 0.00688124 (* 1 = 0.00688124 loss)
I0615 20:15:07.841855 29366 sgd_solver.cpp:105] Iteration 19150, lr = 0.01
I0615 20:16:06.244177 29366 solver.cpp:218] Iteration 19200 (0.856139 iter/s, 58.4018s/50 iters), loss = 0.0111982
I0615 20:16:06.247635 29366 solver.cpp:237]     Train net output #0: loss = 0.0111982 (* 1 = 0.0111982 loss)
I0615 20:16:06.247669 29366 sgd_solver.cpp:105] Iteration 19200, lr = 0.01
I0615 20:17:04.236167 29366 solver.cpp:218] Iteration 19250 (0.862249 iter/s, 57.9879s/50 iters), loss = 0.00803758
I0615 20:17:04.236368 29366 solver.cpp:237]     Train net output #0: loss = 0.00803757 (* 1 = 0.00803757 loss)
I0615 20:17:04.236395 29366 sgd_solver.cpp:105] Iteration 19250, lr = 0.01
I0615 20:18:01.975591 29366 solver.cpp:218] Iteration 19300 (0.865972 iter/s, 57.7386s/50 iters), loss = 0.0111383
I0615 20:18:01.975749 29366 solver.cpp:237]     Train net output #0: loss = 0.0111382 (* 1 = 0.0111382 loss)
I0615 20:18:01.975783 29366 sgd_solver.cpp:105] Iteration 19300, lr = 0.01
I0615 20:18:59.698411 29366 solver.cpp:218] Iteration 19350 (0.86622 iter/s, 57.7221s/50 iters), loss = 0.00656961
I0615 20:18:59.698570 29366 solver.cpp:237]     Train net output #0: loss = 0.0065696 (* 1 = 0.0065696 loss)
I0615 20:18:59.698604 29366 sgd_solver.cpp:105] Iteration 19350, lr = 0.01
I0615 20:19:57.426162 29366 solver.cpp:218] Iteration 19400 (0.866145 iter/s, 57.727s/50 iters), loss = 0.00826559
I0615 20:19:57.426288 29366 solver.cpp:237]     Train net output #0: loss = 0.00826557 (* 1 = 0.00826557 loss)
I0615 20:19:57.426316 29366 sgd_solver.cpp:105] Iteration 19400, lr = 0.01
I0615 20:20:55.168045 29366 solver.cpp:218] Iteration 19450 (0.865934 iter/s, 57.7411s/50 iters), loss = 0.0122123
I0615 20:20:55.168296 29366 solver.cpp:237]     Train net output #0: loss = 0.0122123 (* 1 = 0.0122123 loss)
I0615 20:20:55.168330 29366 sgd_solver.cpp:105] Iteration 19450, lr = 0.01
I0615 20:21:52.919858 29366 solver.cpp:218] Iteration 19500 (0.865786 iter/s, 57.751s/50 iters), loss = 0.00932604
I0615 20:21:52.920058 29366 solver.cpp:237]     Train net output #0: loss = 0.00932602 (* 1 = 0.00932602 loss)
I0615 20:21:52.920085 29366 sgd_solver.cpp:105] Iteration 19500, lr = 0.01
I0615 20:22:50.874055 29366 solver.cpp:218] Iteration 19550 (0.862762 iter/s, 57.9534s/50 iters), loss = 0.00957031
I0615 20:22:50.877604 29366 solver.cpp:237]     Train net output #0: loss = 0.0095703 (* 1 = 0.0095703 loss)
I0615 20:22:50.877631 29366 sgd_solver.cpp:105] Iteration 19550, lr = 0.01
I0615 20:23:49.557495 29366 solver.cpp:218] Iteration 19600 (0.852103 iter/s, 58.6783s/50 iters), loss = 0.00883111
I0615 20:23:49.559831 29366 solver.cpp:237]     Train net output #0: loss = 0.00883109 (* 1 = 0.00883109 loss)
I0615 20:23:49.559864 29366 sgd_solver.cpp:105] Iteration 19600, lr = 0.01
I0615 20:24:47.804153 29366 solver.cpp:218] Iteration 19650 (0.858461 iter/s, 58.2437s/50 iters), loss = 0.00655927
I0615 20:24:47.804291 29366 solver.cpp:237]     Train net output #0: loss = 0.00655925 (* 1 = 0.00655925 loss)
I0615 20:24:47.804318 29366 sgd_solver.cpp:105] Iteration 19650, lr = 0.01
I0615 20:25:45.567281 29366 solver.cpp:218] Iteration 19700 (0.865615 iter/s, 57.7624s/50 iters), loss = 0.00734513
I0615 20:25:45.567426 29366 solver.cpp:237]     Train net output #0: loss = 0.00734512 (* 1 = 0.00734512 loss)
I0615 20:25:45.567453 29366 sgd_solver.cpp:105] Iteration 19700, lr = 0.01
I0615 20:26:43.338394 29366 solver.cpp:218] Iteration 19750 (0.865496 iter/s, 57.7703s/50 iters), loss = 0.00573341
I0615 20:26:43.338528 29366 solver.cpp:237]     Train net output #0: loss = 0.00573339 (* 1 = 0.00573339 loss)
I0615 20:26:43.338557 29366 sgd_solver.cpp:105] Iteration 19750, lr = 0.01
I0615 20:27:41.105608 29366 solver.cpp:218] Iteration 19800 (0.865554 iter/s, 57.7664s/50 iters), loss = 0.00705323
I0615 20:27:41.105763 29366 solver.cpp:237]     Train net output #0: loss = 0.00705321 (* 1 = 0.00705321 loss)
I0615 20:27:41.105790 29366 sgd_solver.cpp:105] Iteration 19800, lr = 0.01
I0615 20:28:38.870744 29366 solver.cpp:218] Iteration 19850 (0.865586 iter/s, 57.7644s/50 iters), loss = 0.0106727
I0615 20:28:38.870928 29366 solver.cpp:237]     Train net output #0: loss = 0.0106726 (* 1 = 0.0106726 loss)
I0615 20:28:38.870965 29366 sgd_solver.cpp:105] Iteration 19850, lr = 0.01
I0615 20:29:36.638567 29366 solver.cpp:218] Iteration 19900 (0.865546 iter/s, 57.767s/50 iters), loss = 0.00826458
I0615 20:29:36.638698 29366 solver.cpp:237]     Train net output #0: loss = 0.00826457 (* 1 = 0.00826457 loss)
I0615 20:29:36.638725 29366 sgd_solver.cpp:105] Iteration 19900, lr = 0.01
I0615 20:30:34.400954 29366 solver.cpp:218] Iteration 19950 (0.865627 iter/s, 57.7616s/50 iters), loss = 0.00552787
I0615 20:30:34.401098 29366 solver.cpp:237]     Train net output #0: loss = 0.00552786 (* 1 = 0.00552786 loss)
I0615 20:30:34.401123 29366 sgd_solver.cpp:105] Iteration 19950, lr = 0.01
I0615 20:31:31.021168 29366 solver.cpp:447] Snapshotting to binary proto file mobilenet/mobile_2_iter_20000.caffemodel
I0615 20:31:31.101825 29366 sgd_solver.cpp:273] Snapshotting solver state to binary proto file mobilenet/mobile_2_iter_20000.solverstate
I0615 20:31:32.280094 29366 solver.cpp:218] Iteration 20000 (0.86388 iter/s, 57.8784s/50 iters), loss = 0.00654082
I0615 20:31:32.280184 29366 solver.cpp:237]     Train net output #0: loss = 0.0065408 (* 1 = 0.0065408 loss)
I0615 20:31:32.280207 29366 sgd_solver.cpp:105] Iteration 20000, lr = 0.01
I0615 20:32:30.056146 29366 solver.cpp:218] Iteration 20050 (0.865421 iter/s, 57.7753s/50 iters), loss = 0.00616225
I0615 20:32:30.056294 29366 solver.cpp:237]     Train net output #0: loss = 0.00616223 (* 1 = 0.00616223 loss)
I0615 20:32:30.056326 29366 sgd_solver.cpp:105] Iteration 20050, lr = 0.01
I0615 20:33:27.824935 29366 solver.cpp:218] Iteration 20100 (0.865531 iter/s, 57.768s/50 iters), loss = 0.0090767
I0615 20:33:27.825081 29366 solver.cpp:237]     Train net output #0: loss = 0.00907669 (* 1 = 0.00907669 loss)
I0615 20:33:27.825109 29366 sgd_solver.cpp:105] Iteration 20100, lr = 0.01
I0615 20:34:25.592124 29366 solver.cpp:218] Iteration 20150 (0.865555 iter/s, 57.7664s/50 iters), loss = 0.00433062
I0615 20:34:25.592257 29366 solver.cpp:237]     Train net output #0: loss = 0.0043306 (* 1 = 0.0043306 loss)
I0615 20:34:25.592283 29366 sgd_solver.cpp:105] Iteration 20150, lr = 0.01
I0615 20:35:23.368453 29366 solver.cpp:218] Iteration 20200 (0.865418 iter/s, 57.7756s/50 iters), loss = 0.00814974
I0615 20:35:23.368594 29366 solver.cpp:237]     Train net output #0: loss = 0.00814973 (* 1 = 0.00814973 loss)
I0615 20:35:23.368621 29366 sgd_solver.cpp:105] Iteration 20200, lr = 0.01
I0615 20:36:21.142459 29366 solver.cpp:218] Iteration 20250 (0.865453 iter/s, 57.7732s/50 iters), loss = 0.00726123
I0615 20:36:21.142617 29366 solver.cpp:237]     Train net output #0: loss = 0.00726121 (* 1 = 0.00726121 loss)
I0615 20:36:21.142652 29366 sgd_solver.cpp:105] Iteration 20250, lr = 0.01
I0615 20:37:18.908368 29366 solver.cpp:218] Iteration 20300 (0.865574 iter/s, 57.7651s/50 iters), loss = 0.00816793
I0615 20:37:18.908550 29366 solver.cpp:237]     Train net output #0: loss = 0.00816792 (* 1 = 0.00816792 loss)
I0615 20:37:18.908579 29366 sgd_solver.cpp:105] Iteration 20300, lr = 0.01
I0615 20:38:16.673751 29366 solver.cpp:218] Iteration 20350 (0.865582 iter/s, 57.7646s/50 iters), loss = 0.00709952
I0615 20:38:16.673907 29366 solver.cpp:237]     Train net output #0: loss = 0.00709951 (* 1 = 0.00709951 loss)
I0615 20:38:16.673933 29366 sgd_solver.cpp:105] Iteration 20350, lr = 0.01
I0615 20:39:14.441550 29366 solver.cpp:218] Iteration 20400 (0.865546 iter/s, 57.767s/50 iters), loss = 0.00688766
I0615 20:39:14.441645 29366 solver.cpp:237]     Train net output #0: loss = 0.00688764 (* 1 = 0.00688764 loss)
I0615 20:39:14.441670 29366 sgd_solver.cpp:105] Iteration 20400, lr = 0.01
I0615 20:40:12.208220 29366 solver.cpp:218] Iteration 20450 (0.865562 iter/s, 57.7659s/50 iters), loss = 0.00724984
I0615 20:40:12.208370 29366 solver.cpp:237]     Train net output #0: loss = 0.00724983 (* 1 = 0.00724983 loss)
I0615 20:40:12.208398 29366 sgd_solver.cpp:105] Iteration 20450, lr = 0.01
I0615 20:41:09.975379 29366 solver.cpp:218] Iteration 20500 (0.865555 iter/s, 57.7664s/50 iters), loss = 0.0119347
I0615 20:41:09.975584 29366 solver.cpp:237]     Train net output #0: loss = 0.0119347 (* 1 = 0.0119347 loss)
I0615 20:41:09.975611 29366 sgd_solver.cpp:105] Iteration 20500, lr = 0.01
I0615 20:42:07.744691 29366 solver.cpp:218] Iteration 20550 (0.865524 iter/s, 57.7685s/50 iters), loss = 0.00739114
I0615 20:42:07.744824 29366 solver.cpp:237]     Train net output #0: loss = 0.00739112 (* 1 = 0.00739112 loss)
I0615 20:42:07.744851 29366 sgd_solver.cpp:105] Iteration 20550, lr = 0.01
I0615 20:43:05.517874 29366 solver.cpp:218] Iteration 20600 (0.865465 iter/s, 57.7724s/50 iters), loss = 0.0134443
I0615 20:43:05.518009 29366 solver.cpp:237]     Train net output #0: loss = 0.0134442 (* 1 = 0.0134442 loss)
I0615 20:43:05.518036 29366 sgd_solver.cpp:105] Iteration 20600, lr = 0.01
I0615 20:44:03.297503 29366 solver.cpp:218] Iteration 20650 (0.865368 iter/s, 57.7789s/50 iters), loss = 0.00835832
I0615 20:44:03.297655 29366 solver.cpp:237]     Train net output #0: loss = 0.00835831 (* 1 = 0.00835831 loss)
I0615 20:44:03.297683 29366 sgd_solver.cpp:105] Iteration 20650, lr = 0.01
I0615 20:45:01.073981 29366 solver.cpp:218] Iteration 20700 (0.865416 iter/s, 57.7757s/50 iters), loss = 0.00617771
I0615 20:45:01.074159 29366 solver.cpp:237]     Train net output #0: loss = 0.0061777 (* 1 = 0.0061777 loss)
I0615 20:45:01.074187 29366 sgd_solver.cpp:105] Iteration 20700, lr = 0.01
I0615 20:45:58.857964 29366 solver.cpp:218] Iteration 20750 (0.865304 iter/s, 57.7832s/50 iters), loss = 0.00727858
I0615 20:45:58.858103 29366 solver.cpp:237]     Train net output #0: loss = 0.00727856 (* 1 = 0.00727856 loss)
I0615 20:45:58.858129 29366 sgd_solver.cpp:105] Iteration 20750, lr = 0.01
I0615 20:46:56.640632 29366 solver.cpp:218] Iteration 20800 (0.865323 iter/s, 57.7819s/50 iters), loss = 0.00613529
I0615 20:46:56.640774 29366 solver.cpp:237]     Train net output #0: loss = 0.00613527 (* 1 = 0.00613527 loss)
I0615 20:46:56.640802 29366 sgd_solver.cpp:105] Iteration 20800, lr = 0.01
I0615 20:47:54.422217 29366 solver.cpp:218] Iteration 20850 (0.865339 iter/s, 57.7808s/50 iters), loss = 0.0106735
I0615 20:47:54.422348 29366 solver.cpp:237]     Train net output #0: loss = 0.0106735 (* 1 = 0.0106735 loss)
I0615 20:47:54.422374 29366 sgd_solver.cpp:105] Iteration 20850, lr = 0.01
I0615 20:48:52.184854 29366 solver.cpp:218] Iteration 20900 (0.865623 iter/s, 57.7619s/50 iters), loss = 0.0122672
I0615 20:48:52.185014 29366 solver.cpp:237]     Train net output #0: loss = 0.0122672 (* 1 = 0.0122672 loss)
I0615 20:48:52.185040 29366 sgd_solver.cpp:105] Iteration 20900, lr = 0.01
I0615 20:49:49.951571 29366 solver.cpp:218] Iteration 20950 (0.865562 iter/s, 57.7659s/50 iters), loss = 0.0117661
I0615 20:49:49.951699 29366 solver.cpp:237]     Train net output #0: loss = 0.0117661 (* 1 = 0.0117661 loss)
I0615 20:49:49.951727 29366 sgd_solver.cpp:105] Iteration 20950, lr = 0.01
I0615 20:50:47.724653 29366 solver.cpp:218] Iteration 21000 (0.865466 iter/s, 57.7723s/50 iters), loss = 0.0112721
I0615 20:50:47.724784 29366 solver.cpp:237]     Train net output #0: loss = 0.011272 (* 1 = 0.011272 loss)
I0615 20:50:47.724810 29366 sgd_solver.cpp:105] Iteration 21000, lr = 0.01
I0615 20:51:45.504920 29366 solver.cpp:218] Iteration 21050 (0.865359 iter/s, 57.7795s/50 iters), loss = 0.0201385
I0615 20:51:45.505064 29366 solver.cpp:237]     Train net output #0: loss = 0.0201385 (* 1 = 0.0201385 loss)
I0615 20:51:45.505089 29366 sgd_solver.cpp:105] Iteration 21050, lr = 0.01
I0615 20:52:43.271188 29366 solver.cpp:218] Iteration 21100 (0.865569 iter/s, 57.7655s/50 iters), loss = 0.0369903
I0615 20:52:43.271332 29366 solver.cpp:237]     Train net output #0: loss = 0.0369902 (* 1 = 0.0369902 loss)
I0615 20:52:43.271358 29366 sgd_solver.cpp:105] Iteration 21100, lr = 0.01
I0615 20:53:41.038709 29366 solver.cpp:218] Iteration 21150 (0.86555 iter/s, 57.7668s/50 iters), loss = 0.025191
I0615 20:53:41.038836 29366 solver.cpp:237]     Train net output #0: loss = 0.025191 (* 1 = 0.025191 loss)
I0615 20:53:41.038862 29366 sgd_solver.cpp:105] Iteration 21150, lr = 0.01
I0615 20:54:38.813482 29366 solver.cpp:218] Iteration 21200 (0.865441 iter/s, 57.774s/50 iters), loss = 0.0351627
I0615 20:54:38.813696 29366 solver.cpp:237]     Train net output #0: loss = 0.0351626 (* 1 = 0.0351626 loss)
I0615 20:54:38.813724 29366 sgd_solver.cpp:105] Iteration 21200, lr = 0.01
I0615 20:55:36.594245 29366 solver.cpp:218] Iteration 21250 (0.865352 iter/s, 57.7799s/50 iters), loss = 0.152203
I0615 20:55:36.594379 29366 solver.cpp:237]     Train net output #0: loss = 0.152203 (* 1 = 0.152203 loss)
I0615 20:55:36.594408 29366 sgd_solver.cpp:105] Iteration 21250, lr = 0.01
I0615 20:56:34.365677 29366 solver.cpp:218] Iteration 21300 (0.865491 iter/s, 57.7707s/50 iters), loss = 0.272323
I0615 20:56:34.365799 29366 solver.cpp:237]     Train net output #0: loss = 0.272323 (* 1 = 0.272323 loss)
I0615 20:56:34.365826 29366 sgd_solver.cpp:105] Iteration 21300, lr = 0.01
I0615 20:57:32.142041 29366 solver.cpp:218] Iteration 21350 (0.865417 iter/s, 57.7756s/50 iters), loss = 0.405712
I0615 20:57:32.142190 29366 solver.cpp:237]     Train net output #0: loss = 0.405712 (* 1 = 0.405712 loss)
I0615 20:57:32.142217 29366 sgd_solver.cpp:105] Iteration 21350, lr = 0.01
I0615 20:58:29.912421 29366 solver.cpp:218] Iteration 21400 (0.865507 iter/s, 57.7696s/50 iters), loss = 0.263321
I0615 20:58:29.912559 29366 solver.cpp:237]     Train net output #0: loss = 0.263321 (* 1 = 0.263321 loss)
I0615 20:58:29.912586 29366 sgd_solver.cpp:105] Iteration 21400, lr = 0.01
I0615 20:59:27.690987 29366 solver.cpp:218] Iteration 21450 (0.865384 iter/s, 57.7778s/50 iters), loss = 0.224995
I0615 20:59:27.691114 29366 solver.cpp:237]     Train net output #0: loss = 0.224995 (* 1 = 0.224995 loss)
I0615 20:59:27.691140 29366 sgd_solver.cpp:105] Iteration 21450, lr = 0.01
I0615 21:00:25.512656 29366 solver.cpp:218] Iteration 21500 (0.864739 iter/s, 57.8209s/50 iters), loss = 0.299356
I0615 21:00:25.512806 29366 solver.cpp:237]     Train net output #0: loss = 0.299356 (* 1 = 0.299356 loss)
I0615 21:00:25.512835 29366 sgd_solver.cpp:105] Iteration 21500, lr = 0.01
I0615 21:01:23.723754 29366 solver.cpp:218] Iteration 21550 (0.858954 iter/s, 58.2103s/50 iters), loss = 0.288403
I0615 21:01:23.723894 29366 solver.cpp:237]     Train net output #0: loss = 0.288403 (* 1 = 0.288403 loss)
I0615 21:01:23.723920 29366 sgd_solver.cpp:105] Iteration 21550, lr = 0.01
I0615 21:02:21.485527 29366 solver.cpp:218] Iteration 21600 (0.865636 iter/s, 57.761s/50 iters), loss = 0.26477
I0615 21:02:21.485653 29366 solver.cpp:237]     Train net output #0: loss = 0.26477 (* 1 = 0.26477 loss)
I0615 21:02:21.485682 29366 sgd_solver.cpp:105] Iteration 21600, lr = 0.01
I0615 21:03:19.261500 29366 solver.cpp:218] Iteration 21650 (0.865423 iter/s, 57.7752s/50 iters), loss = 0.0870642
I0615 21:03:19.261662 29366 solver.cpp:237]     Train net output #0: loss = 0.0870642 (* 1 = 0.0870642 loss)
I0615 21:03:19.261695 29366 sgd_solver.cpp:105] Iteration 21650, lr = 0.01
I0615 21:04:17.040729 29366 solver.cpp:218] Iteration 21700 (0.865375 iter/s, 57.7784s/50 iters), loss = 0.0824726
I0615 21:04:17.040875 29366 solver.cpp:237]     Train net output #0: loss = 0.0824727 (* 1 = 0.0824727 loss)
I0615 21:04:17.040902 29366 sgd_solver.cpp:105] Iteration 21700, lr = 0.01
I0615 21:05:14.807170 29366 solver.cpp:218] Iteration 21750 (0.865566 iter/s, 57.7657s/50 iters), loss = 0.0764824
I0615 21:05:14.807327 29366 solver.cpp:237]     Train net output #0: loss = 0.0764824 (* 1 = 0.0764824 loss)
I0615 21:05:14.807353 29366 sgd_solver.cpp:105] Iteration 21750, lr = 0.01
I0615 21:06:12.575294 29366 solver.cpp:218] Iteration 21800 (0.865541 iter/s, 57.7673s/50 iters), loss = 0.0497193
I0615 21:06:12.575423 29366 solver.cpp:237]     Train net output #0: loss = 0.0497194 (* 1 = 0.0497194 loss)
I0615 21:06:12.575448 29366 sgd_solver.cpp:105] Iteration 21800, lr = 0.01
I0615 21:07:10.347877 29366 solver.cpp:218] Iteration 21850 (0.865474 iter/s, 57.7718s/50 iters), loss = 0.0465646
I0615 21:07:10.348076 29366 solver.cpp:237]     Train net output #0: loss = 0.0465646 (* 1 = 0.0465646 loss)
I0615 21:07:10.348104 29366 sgd_solver.cpp:105] Iteration 21850, lr = 0.01
I0615 21:08:08.113911 29366 solver.cpp:218] Iteration 21900 (0.865573 iter/s, 57.7652s/50 iters), loss = 0.0431717
I0615 21:08:08.114064 29366 solver.cpp:237]     Train net output #0: loss = 0.0431718 (* 1 = 0.0431718 loss)
I0615 21:08:08.114091 29366 sgd_solver.cpp:105] Iteration 21900, lr = 0.01
I0615 21:09:05.887472 29366 solver.cpp:218] Iteration 21950 (0.865459 iter/s, 57.7728s/50 iters), loss = 0.0420642
I0615 21:09:05.887610 29366 solver.cpp:237]     Train net output #0: loss = 0.0420642 (* 1 = 0.0420642 loss)
I0615 21:09:05.887637 29366 sgd_solver.cpp:105] Iteration 21950, lr = 0.01
I0615 21:10:03.663218 29366 solver.cpp:218] Iteration 22000 (0.865426 iter/s, 57.775s/50 iters), loss = 0.0428415
I0615 21:10:03.663362 29366 solver.cpp:237]     Train net output #0: loss = 0.0428415 (* 1 = 0.0428415 loss)
I0615 21:10:03.663389 29366 sgd_solver.cpp:105] Iteration 22000, lr = 0.01
I0615 21:11:01.428148 29366 solver.cpp:218] Iteration 22050 (0.865589 iter/s, 57.7642s/50 iters), loss = 0.0294445
I0615 21:11:01.428261 29366 solver.cpp:237]     Train net output #0: loss = 0.0294446 (* 1 = 0.0294446 loss)
I0615 21:11:01.428287 29366 sgd_solver.cpp:105] Iteration 22050, lr = 0.01
I0615 21:11:59.194082 29366 solver.cpp:218] Iteration 22100 (0.865573 iter/s, 57.7652s/50 iters), loss = 0.0286736
I0615 21:11:59.194218 29366 solver.cpp:237]     Train net output #0: loss = 0.0286736 (* 1 = 0.0286736 loss)
I0615 21:11:59.194244 29366 sgd_solver.cpp:105] Iteration 22100, lr = 0.01
I0615 21:12:56.958518 29366 solver.cpp:218] Iteration 22150 (0.865596 iter/s, 57.7637s/50 iters), loss = 0.0849024
I0615 21:12:56.958648 29366 solver.cpp:237]     Train net output #0: loss = 0.0849024 (* 1 = 0.0849024 loss)
I0615 21:12:56.958673 29366 sgd_solver.cpp:105] Iteration 22150, lr = 0.01
I0615 21:13:54.735913 29366 solver.cpp:218] Iteration 22200 (0.865402 iter/s, 57.7766s/50 iters), loss = 0.0307017
I0615 21:13:54.736054 29366 solver.cpp:237]     Train net output #0: loss = 0.0307018 (* 1 = 0.0307018 loss)
I0615 21:13:54.736083 29366 sgd_solver.cpp:105] Iteration 22200, lr = 0.01
I0615 21:14:52.515511 29366 solver.cpp:218] Iteration 22250 (0.865369 iter/s, 57.7788s/50 iters), loss = 0.0151483
I0615 21:14:52.515681 29366 solver.cpp:237]     Train net output #0: loss = 0.0151483 (* 1 = 0.0151483 loss)
I0615 21:14:52.515705 29366 sgd_solver.cpp:105] Iteration 22250, lr = 0.01
I0615 21:15:50.292650 29366 solver.cpp:218] Iteration 22300 (0.865406 iter/s, 57.7763s/50 iters), loss = 0.0174903
I0615 21:15:50.292786 29366 solver.cpp:237]     Train net output #0: loss = 0.0174903 (* 1 = 0.0174903 loss)
I0615 21:15:50.292814 29366 sgd_solver.cpp:105] Iteration 22300, lr = 0.01
I0615 21:16:48.066370 29366 solver.cpp:218] Iteration 22350 (0.865457 iter/s, 57.7729s/50 iters), loss = 0.00991884
I0615 21:16:48.066519 29366 solver.cpp:237]     Train net output #0: loss = 0.00991889 (* 1 = 0.00991889 loss)
I0615 21:16:48.066550 29366 sgd_solver.cpp:105] Iteration 22350, lr = 0.01
I0615 21:17:45.831454 29366 solver.cpp:218] Iteration 22400 (0.865587 iter/s, 57.7643s/50 iters), loss = 0.00571218
I0615 21:17:45.831609 29366 solver.cpp:237]     Train net output #0: loss = 0.00571222 (* 1 = 0.00571222 loss)
I0615 21:17:45.831637 29366 sgd_solver.cpp:105] Iteration 22400, lr = 0.01
I0615 21:18:43.604787 29366 solver.cpp:218] Iteration 22450 (0.865463 iter/s, 57.7725s/50 iters), loss = 0.00596903
I0615 21:18:43.604955 29366 solver.cpp:237]     Train net output #0: loss = 0.00596907 (* 1 = 0.00596907 loss)
I0615 21:18:43.604981 29366 sgd_solver.cpp:105] Iteration 22450, lr = 0.01
I0615 21:19:41.375953 29366 solver.cpp:218] Iteration 22500 (0.865496 iter/s, 57.7704s/50 iters), loss = 0.00629463
I0615 21:19:41.376088 29366 solver.cpp:237]     Train net output #0: loss = 0.00629467 (* 1 = 0.00629467 loss)
I0615 21:19:41.376114 29366 sgd_solver.cpp:105] Iteration 22500, lr = 0.01
I0615 21:20:39.158701 29366 solver.cpp:218] Iteration 22550 (0.865322 iter/s, 57.782s/50 iters), loss = 0.00709584
I0615 21:20:39.158900 29366 solver.cpp:237]     Train net output #0: loss = 0.00709588 (* 1 = 0.00709588 loss)
I0615 21:20:39.158946 29366 sgd_solver.cpp:105] Iteration 22550, lr = 0.01
I0615 21:21:36.939440 29366 solver.cpp:218] Iteration 22600 (0.865353 iter/s, 57.7799s/50 iters), loss = 0.00643426
I0615 21:21:36.939581 29366 solver.cpp:237]     Train net output #0: loss = 0.0064343 (* 1 = 0.0064343 loss)
I0615 21:21:36.939607 29366 sgd_solver.cpp:105] Iteration 22600, lr = 0.01
I0615 21:22:34.710708 29366 solver.cpp:218] Iteration 22650 (0.865494 iter/s, 57.7705s/50 iters), loss = 0.00667745
I0615 21:22:34.710836 29366 solver.cpp:237]     Train net output #0: loss = 0.00667749 (* 1 = 0.00667749 loss)
I0615 21:22:34.710863 29366 sgd_solver.cpp:105] Iteration 22650, lr = 0.01
I0615 21:23:32.466262 29366 solver.cpp:218] Iteration 22700 (0.865729 iter/s, 57.7548s/50 iters), loss = 0.0049236
I0615 21:23:32.466404 29366 solver.cpp:237]     Train net output #0: loss = 0.00492364 (* 1 = 0.00492364 loss)
I0615 21:23:32.466434 29366 sgd_solver.cpp:105] Iteration 22700, lr = 0.01
I0615 21:24:30.214046 29366 solver.cpp:218] Iteration 22750 (0.865847 iter/s, 57.7469s/50 iters), loss = 0.00672098
I0615 21:24:30.214262 29366 solver.cpp:237]     Train net output #0: loss = 0.00672102 (* 1 = 0.00672102 loss)
I0615 21:24:30.214298 29366 sgd_solver.cpp:105] Iteration 22750, lr = 0.01
I0615 21:25:27.948338 29366 solver.cpp:218] Iteration 22800 (0.866049 iter/s, 57.7334s/50 iters), loss = 0.00575841
I0615 21:25:27.948510 29366 solver.cpp:237]     Train net output #0: loss = 0.00575845 (* 1 = 0.00575845 loss)
I0615 21:25:27.948547 29366 sgd_solver.cpp:105] Iteration 22800, lr = 0.01
I0615 21:26:25.682111 29366 solver.cpp:218] Iteration 22850 (0.866056 iter/s, 57.733s/50 iters), loss = 0.00716178
I0615 21:26:25.682293 29366 solver.cpp:237]     Train net output #0: loss = 0.00716182 (* 1 = 0.00716182 loss)
I0615 21:26:25.682322 29366 sgd_solver.cpp:105] Iteration 22850, lr = 0.01
I0615 21:26:41.854004 29366 solver.cpp:447] Snapshotting to binary proto file mobilenet/mobile_2_iter_22865.caffemodel
I0615 21:26:41.937366 29366 sgd_solver.cpp:273] Snapshotting solver state to binary proto file mobilenet/mobile_2_iter_22865.solverstate
I0615 21:27:23.534647 29366 solver.cpp:218] Iteration 22900 (0.864279 iter/s, 57.8517s/50 iters), loss = 0.00451665
I0615 21:27:23.534780 29366 solver.cpp:237]     Train net output #0: loss = 0.00451669 (* 1 = 0.00451669 loss)
I0615 21:27:23.534806 29366 sgd_solver.cpp:105] Iteration 22900, lr = 0.01
I0615 21:28:21.273459 29366 solver.cpp:218] Iteration 22950 (0.86598 iter/s, 57.738s/50 iters), loss = 0.00740184
I0615 21:28:21.273609 29366 solver.cpp:237]     Train net output #0: loss = 0.00740188 (* 1 = 0.00740188 loss)
I0615 21:28:21.273633 29366 sgd_solver.cpp:105] Iteration 22950, lr = 0.01
I0615 21:29:19.008538 29366 solver.cpp:218] Iteration 23000 (0.866037 iter/s, 57.7343s/50 iters), loss = 0.00974891
I0615 21:29:19.008647 29366 solver.cpp:237]     Train net output #0: loss = 0.00974895 (* 1 = 0.00974895 loss)
I0615 21:29:19.008671 29366 sgd_solver.cpp:105] Iteration 23000, lr = 0.01
I0615 21:30:16.750787 29366 solver.cpp:218] Iteration 23050 (0.865928 iter/s, 57.7415s/50 iters), loss = 0.00757822
I0615 21:30:16.750916 29366 solver.cpp:237]     Train net output #0: loss = 0.00757825 (* 1 = 0.00757825 loss)
I0615 21:30:16.750941 29366 sgd_solver.cpp:105] Iteration 23050, lr = 0.01
I0615 21:31:14.480315 29366 solver.cpp:218] Iteration 23100 (0.86612 iter/s, 57.7288s/50 iters), loss = 0.00552884
I0615 21:31:14.480454 29366 solver.cpp:237]     Train net output #0: loss = 0.00552887 (* 1 = 0.00552887 loss)
I0615 21:31:14.480479 29366 sgd_solver.cpp:105] Iteration 23100, lr = 0.01
I0615 21:32:12.210477 29366 solver.cpp:218] Iteration 23150 (0.86611 iter/s, 57.7294s/50 iters), loss = 0.00613338
I0615 21:32:12.210618 29366 solver.cpp:237]     Train net output #0: loss = 0.00613342 (* 1 = 0.00613342 loss)
I0615 21:32:12.210641 29366 sgd_solver.cpp:105] Iteration 23150, lr = 0.01
I0615 21:33:09.945960 29366 solver.cpp:218] Iteration 23200 (0.86603 iter/s, 57.7347s/50 iters), loss = 0.00572912
I0615 21:33:09.946157 29366 solver.cpp:237]     Train net output #0: loss = 0.00572915 (* 1 = 0.00572915 loss)
I0615 21:33:09.946182 29366 sgd_solver.cpp:105] Iteration 23200, lr = 0.01
I0615 21:34:07.687862 29366 solver.cpp:218] Iteration 23250 (0.865935 iter/s, 57.7411s/50 iters), loss = 0.00659455
I0615 21:34:07.687999 29366 solver.cpp:237]     Train net output #0: loss = 0.00659458 (* 1 = 0.00659458 loss)
I0615 21:34:07.688024 29366 sgd_solver.cpp:105] Iteration 23250, lr = 0.01
I0615 21:35:05.427227 29366 solver.cpp:218] Iteration 23300 (0.865972 iter/s, 57.7386s/50 iters), loss = 0.0102024
I0615 21:35:05.427386 29366 solver.cpp:237]     Train net output #0: loss = 0.0102024 (* 1 = 0.0102024 loss)
I0615 21:35:05.427409 29366 sgd_solver.cpp:105] Iteration 23300, lr = 0.01
I0615 21:36:03.162030 29366 solver.cpp:218] Iteration 23350 (0.866041 iter/s, 57.734s/50 iters), loss = 0.00665612
I0615 21:36:03.162202 29366 solver.cpp:237]     Train net output #0: loss = 0.00665616 (* 1 = 0.00665616 loss)
I0615 21:36:03.162228 29366 sgd_solver.cpp:105] Iteration 23350, lr = 0.01
I0615 21:37:00.917835 29366 solver.cpp:218] Iteration 23400 (0.865726 iter/s, 57.755s/50 iters), loss = 0.00690087
I0615 21:37:00.917987 29366 solver.cpp:237]     Train net output #0: loss = 0.00690091 (* 1 = 0.00690091 loss)
I0615 21:37:00.918011 29366 sgd_solver.cpp:105] Iteration 23400, lr = 0.01
I0615 21:37:58.649236 29366 solver.cpp:218] Iteration 23450 (0.866092 iter/s, 57.7306s/50 iters), loss = 0.00769539
I0615 21:37:58.649374 29366 solver.cpp:237]     Train net output #0: loss = 0.00769543 (* 1 = 0.00769543 loss)
I0615 21:37:58.649399 29366 sgd_solver.cpp:105] Iteration 23450, lr = 0.01
I0615 21:38:56.384578 29366 solver.cpp:218] Iteration 23500 (0.866032 iter/s, 57.7346s/50 iters), loss = 0.0108854
I0615 21:38:56.384740 29366 solver.cpp:237]     Train net output #0: loss = 0.0108854 (* 1 = 0.0108854 loss)
I0615 21:38:56.384766 29366 sgd_solver.cpp:105] Iteration 23500, lr = 0.01
I0615 21:39:54.121470 29366 solver.cpp:218] Iteration 23550 (0.86601 iter/s, 57.7361s/50 iters), loss = 0.00650396
I0615 21:39:54.121625 29366 solver.cpp:237]     Train net output #0: loss = 0.006504 (* 1 = 0.006504 loss)
I0615 21:39:54.121650 29366 sgd_solver.cpp:105] Iteration 23550, lr = 0.01
I0615 21:40:51.857537 29366 solver.cpp:218] Iteration 23600 (0.866022 iter/s, 57.7353s/50 iters), loss = 0.00746715
I0615 21:40:51.857697 29366 solver.cpp:237]     Train net output #0: loss = 0.00746719 (* 1 = 0.00746719 loss)
I0615 21:40:51.857728 29366 sgd_solver.cpp:105] Iteration 23600, lr = 0.01
I0615 21:41:49.598424 29366 solver.cpp:218] Iteration 23650 (0.86595 iter/s, 57.7401s/50 iters), loss = 0.00723596
I0615 21:41:49.598597 29366 solver.cpp:237]     Train net output #0: loss = 0.007236 (* 1 = 0.007236 loss)
I0615 21:41:49.598620 29366 sgd_solver.cpp:105] Iteration 23650, lr = 0.01
I0615 21:42:47.351150 29366 solver.cpp:218] Iteration 23700 (0.865772 iter/s, 57.7519s/50 iters), loss = 0.00758741
I0615 21:42:47.351287 29366 solver.cpp:237]     Train net output #0: loss = 0.00758745 (* 1 = 0.00758745 loss)
I0615 21:42:47.351311 29366 sgd_solver.cpp:105] Iteration 23700, lr = 0.01
I0615 21:43:45.089553 29366 solver.cpp:218] Iteration 23750 (0.865987 iter/s, 57.7376s/50 iters), loss = 0.00559189
I0615 21:43:45.089718 29366 solver.cpp:237]     Train net output #0: loss = 0.00559193 (* 1 = 0.00559193 loss)
I0615 21:43:45.089742 29366 sgd_solver.cpp:105] Iteration 23750, lr = 0.01
I0615 21:44:42.833307 29366 solver.cpp:218] Iteration 23800 (0.865907 iter/s, 57.743s/50 iters), loss = 0.00883496
I0615 21:44:42.833461 29366 solver.cpp:237]     Train net output #0: loss = 0.008835 (* 1 = 0.008835 loss)
I0615 21:44:42.833487 29366 sgd_solver.cpp:105] Iteration 23800, lr = 0.01
I0615 21:45:40.565646 29366 solver.cpp:218] Iteration 23850 (0.866078 iter/s, 57.7315s/50 iters), loss = 0.00759611
I0615 21:45:40.565814 29366 solver.cpp:237]     Train net output #0: loss = 0.00759615 (* 1 = 0.00759615 loss)
I0615 21:45:40.565845 29366 sgd_solver.cpp:105] Iteration 23850, lr = 0.01
I0615 21:46:38.301141 29366 solver.cpp:218] Iteration 23900 (0.866031 iter/s, 57.7347s/50 iters), loss = 0.00610808
I0615 21:46:38.301281 29366 solver.cpp:237]     Train net output #0: loss = 0.00610812 (* 1 = 0.00610812 loss)
I0615 21:46:38.301307 29366 sgd_solver.cpp:105] Iteration 23900, lr = 0.01
I0615 21:47:36.036173 29366 solver.cpp:218] Iteration 23950 (0.866037 iter/s, 57.7342s/50 iters), loss = 0.00625588
I0615 21:47:36.036325 29366 solver.cpp:237]     Train net output #0: loss = 0.00625592 (* 1 = 0.00625592 loss)
I0615 21:47:36.036351 29366 sgd_solver.cpp:105] Iteration 23950, lr = 0.01
I0615 21:48:33.775209 29366 solver.cpp:218] Iteration 24000 (0.865977 iter/s, 57.7382s/50 iters), loss = 0.0069556
I0615 21:48:33.775357 29366 solver.cpp:237]     Train net output #0: loss = 0.00695563 (* 1 = 0.00695563 loss)
I0615 21:48:33.775380 29366 sgd_solver.cpp:105] Iteration 24000, lr = 0.01
I0615 21:49:31.531899 29366 solver.cpp:218] Iteration 24050 (0.865713 iter/s, 57.7559s/50 iters), loss = 0.00443011
I0615 21:49:31.532064 29366 solver.cpp:237]     Train net output #0: loss = 0.00443014 (* 1 = 0.00443014 loss)
I0615 21:49:31.532095 29366 sgd_solver.cpp:105] Iteration 24050, lr = 0.01
I0615 21:50:29.281685 29366 solver.cpp:218] Iteration 24100 (0.865816 iter/s, 57.749s/50 iters), loss = 0.00639229
I0615 21:50:29.281819 29366 solver.cpp:237]     Train net output #0: loss = 0.00639233 (* 1 = 0.00639233 loss)
I0615 21:50:29.281842 29366 sgd_solver.cpp:105] Iteration 24100, lr = 0.01
I0615 21:51:27.017367 29366 solver.cpp:218] Iteration 24150 (0.866025 iter/s, 57.735s/50 iters), loss = 0.00903579
I0615 21:51:27.017506 29366 solver.cpp:237]     Train net output #0: loss = 0.00903582 (* 1 = 0.00903582 loss)
I0615 21:51:27.017539 29366 sgd_solver.cpp:105] Iteration 24150, lr = 0.01
I0615 21:52:24.776695 29366 solver.cpp:218] Iteration 24200 (0.865668 iter/s, 57.7589s/50 iters), loss = 0.00643105
I0615 21:52:24.776836 29366 solver.cpp:237]     Train net output #0: loss = 0.00643109 (* 1 = 0.00643109 loss)
I0615 21:52:24.776860 29366 sgd_solver.cpp:105] Iteration 24200, lr = 0.01
I0615 21:53:22.540545 29366 solver.cpp:218] Iteration 24250 (0.865601 iter/s, 57.7633s/50 iters), loss = 0.0117935
I0615 21:53:22.540725 29366 solver.cpp:237]     Train net output #0: loss = 0.0117935 (* 1 = 0.0117935 loss)
I0615 21:53:22.540755 29366 sgd_solver.cpp:105] Iteration 24250, lr = 0.01
I0615 21:54:20.311420 29366 solver.cpp:218] Iteration 24300 (0.865496 iter/s, 57.7704s/50 iters), loss = 0.00635453
I0615 21:54:20.311553 29366 solver.cpp:237]     Train net output #0: loss = 0.00635457 (* 1 = 0.00635457 loss)
I0615 21:54:20.311578 29366 sgd_solver.cpp:105] Iteration 24300, lr = 0.01
I0615 21:55:18.075065 29366 solver.cpp:218] Iteration 24350 (0.865604 iter/s, 57.7631s/50 iters), loss = 0.00597199
I0615 21:55:18.075204 29366 solver.cpp:237]     Train net output #0: loss = 0.00597203 (* 1 = 0.00597203 loss)
I0615 21:55:18.075227 29366 sgd_solver.cpp:105] Iteration 24350, lr = 0.01
I0615 21:56:15.836813 29366 solver.cpp:218] Iteration 24400 (0.865632 iter/s, 57.7613s/50 iters), loss = 0.00908409
I0615 21:56:15.836935 29366 solver.cpp:237]     Train net output #0: loss = 0.00908413 (* 1 = 0.00908413 loss)
I0615 21:56:15.836956 29366 sgd_solver.cpp:105] Iteration 24400, lr = 0.01
I0615 21:57:13.606056 29366 solver.cpp:218] Iteration 24450 (0.865519 iter/s, 57.7688s/50 iters), loss = 0.00697993
I0615 21:57:13.606187 29366 solver.cpp:237]     Train net output #0: loss = 0.00697997 (* 1 = 0.00697997 loss)
I0615 21:57:13.606209 29366 sgd_solver.cpp:105] Iteration 24450, lr = 0.01
I0615 21:58:11.376241 29366 solver.cpp:218] Iteration 24500 (0.865506 iter/s, 57.7697s/50 iters), loss = 0.00934324
I0615 21:58:11.376435 29366 solver.cpp:237]     Train net output #0: loss = 0.00934327 (* 1 = 0.00934327 loss)
I0615 21:58:11.376458 29366 sgd_solver.cpp:105] Iteration 24500, lr = 0.01
I0615 21:59:09.144534 29366 solver.cpp:218] Iteration 24550 (0.865535 iter/s, 57.7677s/50 iters), loss = 0.00661233
I0615 21:59:09.144757 29366 solver.cpp:237]     Train net output #0: loss = 0.00661236 (* 1 = 0.00661236 loss)
I0615 21:59:09.144791 29366 sgd_solver.cpp:105] Iteration 24550, lr = 0.01
I0615 22:00:06.915920 29366 solver.cpp:218] Iteration 24600 (0.865489 iter/s, 57.7708s/50 iters), loss = 0.00853955
I0615 22:00:06.916070 29366 solver.cpp:237]     Train net output #0: loss = 0.00853958 (* 1 = 0.00853958 loss)
I0615 22:00:06.916095 29366 sgd_solver.cpp:105] Iteration 24600, lr = 0.01
I0615 22:01:04.679911 29366 solver.cpp:218] Iteration 24650 (0.865599 iter/s, 57.7635s/50 iters), loss = 0.00849849
I0615 22:01:04.680058 29366 solver.cpp:237]     Train net output #0: loss = 0.00849852 (* 1 = 0.00849852 loss)
I0615 22:01:04.680083 29366 sgd_solver.cpp:105] Iteration 24650, lr = 0.01
I0615 22:02:02.449714 29366 solver.cpp:218] Iteration 24700 (0.865512 iter/s, 57.7693s/50 iters), loss = 0.00502522
I0615 22:02:02.450654 29366 solver.cpp:237]     Train net output #0: loss = 0.00502526 (* 1 = 0.00502526 loss)
I0615 22:02:02.450687 29366 sgd_solver.cpp:105] Iteration 24700, lr = 0.01
I0615 22:03:00.217299 29366 solver.cpp:218] Iteration 24750 (0.865557 iter/s, 57.7663s/50 iters), loss = 0.00593157
I0615 22:03:00.217444 29366 solver.cpp:237]     Train net output #0: loss = 0.00593161 (* 1 = 0.00593161 loss)
I0615 22:03:00.217466 29366 sgd_solver.cpp:105] Iteration 24750, lr = 0.01
I0615 22:03:57.994782 29366 solver.cpp:218] Iteration 24800 (0.865397 iter/s, 57.7769s/50 iters), loss = 0.00570265
I0615 22:03:57.994954 29366 solver.cpp:237]     Train net output #0: loss = 0.00570268 (* 1 = 0.00570268 loss)
I0615 22:03:57.994977 29366 sgd_solver.cpp:105] Iteration 24800, lr = 0.01
I0615 22:04:55.768080 29366 solver.cpp:218] Iteration 24850 (0.86546 iter/s, 57.7728s/50 iters), loss = 0.00982473
I0615 22:04:55.768208 29366 solver.cpp:237]     Train net output #0: loss = 0.00982477 (* 1 = 0.00982477 loss)
I0615 22:04:55.768231 29366 sgd_solver.cpp:105] Iteration 24850, lr = 0.01
I0615 22:05:53.542443 29366 solver.cpp:218] Iteration 24900 (0.865443 iter/s, 57.7739s/50 iters), loss = 0.00802692
I0615 22:05:53.542574 29366 solver.cpp:237]     Train net output #0: loss = 0.00802696 (* 1 = 0.00802696 loss)
I0615 22:05:53.542598 29366 sgd_solver.cpp:105] Iteration 24900, lr = 0.01
I0615 22:06:51.308563 29366 solver.cpp:218] Iteration 24950 (0.865567 iter/s, 57.7656s/50 iters), loss = 0.00838078
I0615 22:06:51.308697 29366 solver.cpp:237]     Train net output #0: loss = 0.00838081 (* 1 = 0.00838081 loss)
I0615 22:06:51.308722 29366 sgd_solver.cpp:105] Iteration 24950, lr = 0.01
I0615 22:07:49.073599 29366 solver.cpp:218] Iteration 25000 (0.865583 iter/s, 57.7645s/50 iters), loss = 0.00470094
I0615 22:07:49.073753 29366 solver.cpp:237]     Train net output #0: loss = 0.00470097 (* 1 = 0.00470097 loss)
I0615 22:07:49.073777 29366 sgd_solver.cpp:105] Iteration 25000, lr = 0.01
I0615 22:08:46.839077 29366 solver.cpp:218] Iteration 25050 (0.865579 iter/s, 57.7648s/50 iters), loss = 0.00824144
I0615 22:08:46.839191 29366 solver.cpp:237]     Train net output #0: loss = 0.00824148 (* 1 = 0.00824148 loss)
I0615 22:08:46.839211 29366 sgd_solver.cpp:105] Iteration 25050, lr = 0.01
I0615 22:09:44.602013 29366 solver.cpp:218] Iteration 25100 (0.865618 iter/s, 57.7622s/50 iters), loss = 0.00981373
I0615 22:09:44.602138 29366 solver.cpp:237]     Train net output #0: loss = 0.00981377 (* 1 = 0.00981377 loss)
I0615 22:09:44.602161 29366 sgd_solver.cpp:105] Iteration 25100, lr = 0.01
I0615 22:10:42.372422 29366 solver.cpp:218] Iteration 25150 (0.865506 iter/s, 57.7696s/50 iters), loss = 0.0087192
I0615 22:10:42.372556 29366 solver.cpp:237]     Train net output #0: loss = 0.00871924 (* 1 = 0.00871924 loss)
I0615 22:10:42.372581 29366 sgd_solver.cpp:105] Iteration 25150, lr = 0.01
I0615 22:11:40.143270 29366 solver.cpp:218] Iteration 25200 (0.8655 iter/s, 57.7701s/50 iters), loss = 0.00784143
I0615 22:11:40.143404 29366 solver.cpp:237]     Train net output #0: loss = 0.00784146 (* 1 = 0.00784146 loss)
I0615 22:11:40.143434 29366 sgd_solver.cpp:105] Iteration 25200, lr = 0.01
I0615 22:12:37.908655 29366 solver.cpp:218] Iteration 25250 (0.865582 iter/s, 57.7646s/50 iters), loss = 0.00590534
I0615 22:12:37.908856 29366 solver.cpp:237]     Train net output #0: loss = 0.00590537 (* 1 = 0.00590537 loss)
I0615 22:12:37.908881 29366 sgd_solver.cpp:105] Iteration 25250, lr = 0.01
I0615 22:13:35.681401 29366 solver.cpp:218] Iteration 25300 (0.865472 iter/s, 57.7719s/50 iters), loss = 0.00617322
I0615 22:13:35.681526 29366 solver.cpp:237]     Train net output #0: loss = 0.00617326 (* 1 = 0.00617326 loss)
I0615 22:13:35.681551 29366 sgd_solver.cpp:105] Iteration 25300, lr = 0.01
I0615 22:14:33.470026 29366 solver.cpp:218] Iteration 25350 (0.865234 iter/s, 57.7879s/50 iters), loss = 0.00855885
I0615 22:14:33.470152 29366 solver.cpp:237]     Train net output #0: loss = 0.00855889 (* 1 = 0.00855889 loss)
I0615 22:14:33.470175 29366 sgd_solver.cpp:105] Iteration 25350, lr = 0.01
I0615 22:15:31.244159 29366 solver.cpp:218] Iteration 25400 (0.865451 iter/s, 57.7734s/50 iters), loss = 0.00650909
I0615 22:15:31.244310 29366 solver.cpp:237]     Train net output #0: loss = 0.00650913 (* 1 = 0.00650913 loss)
I0615 22:15:31.244333 29366 sgd_solver.cpp:105] Iteration 25400, lr = 0.01
I0615 22:16:29.019245 29366 solver.cpp:218] Iteration 25450 (0.865437 iter/s, 57.7743s/50 iters), loss = 0.00693421
I0615 22:16:29.020324 29366 solver.cpp:237]     Train net output #0: loss = 0.00693425 (* 1 = 0.00693425 loss)
I0615 22:16:29.020346 29366 sgd_solver.cpp:105] Iteration 25450, lr = 0.01
I0615 22:17:26.780707 29366 solver.cpp:218] Iteration 25500 (0.865655 iter/s, 57.7597s/50 iters), loss = 0.00760491
I0615 22:17:26.780860 29366 solver.cpp:237]     Train net output #0: loss = 0.00760495 (* 1 = 0.00760495 loss)
I0615 22:17:26.780884 29366 sgd_solver.cpp:105] Iteration 25500, lr = 0.01
I0615 22:18:24.543107 29366 solver.cpp:218] Iteration 25550 (0.865627 iter/s, 57.7616s/50 iters), loss = 0.00503344
I0615 22:18:24.543259 29366 solver.cpp:237]     Train net output #0: loss = 0.00503348 (* 1 = 0.00503348 loss)
I0615 22:18:24.543283 29366 sgd_solver.cpp:105] Iteration 25550, lr = 0.01
I0615 22:19:22.322369 29366 solver.cpp:218] Iteration 25600 (0.865374 iter/s, 57.7785s/50 iters), loss = 0.00788999
I0615 22:19:22.322608 29366 solver.cpp:237]     Train net output #0: loss = 0.00789003 (* 1 = 0.00789003 loss)
I0615 22:19:22.322633 29366 sgd_solver.cpp:105] Iteration 25600, lr = 0.01
I0615 22:20:20.093175 29366 solver.cpp:218] Iteration 25650 (0.865503 iter/s, 57.7699s/50 iters), loss = 0.00588568
I0615 22:20:20.093304 29366 solver.cpp:237]     Train net output #0: loss = 0.00588572 (* 1 = 0.00588572 loss)
I0615 22:20:20.093336 29366 sgd_solver.cpp:105] Iteration 25650, lr = 0.01
I0615 22:21:17.862896 29366 solver.cpp:218] Iteration 25700 (0.865517 iter/s, 57.769s/50 iters), loss = 0.00924533
I0615 22:21:17.863028 29366 solver.cpp:237]     Train net output #0: loss = 0.00924536 (* 1 = 0.00924536 loss)
I0615 22:21:17.863050 29366 sgd_solver.cpp:105] Iteration 25700, lr = 0.01
I0615 22:22:15.639691 29366 solver.cpp:218] Iteration 25750 (0.865411 iter/s, 57.776s/50 iters), loss = 0.00545925
I0615 22:22:15.639869 29366 solver.cpp:237]     Train net output #0: loss = 0.00545929 (* 1 = 0.00545929 loss)
I0615 22:22:15.639892 29366 sgd_solver.cpp:105] Iteration 25750, lr = 0.01
I0615 22:23:13.414517 29366 solver.cpp:218] Iteration 25800 (0.865441 iter/s, 57.774s/50 iters), loss = 0.0105883
I0615 22:23:13.414677 29366 solver.cpp:237]     Train net output #0: loss = 0.0105884 (* 1 = 0.0105884 loss)
I0615 22:23:13.414700 29366 sgd_solver.cpp:105] Iteration 25800, lr = 0.01
I0615 22:24:11.177707 29366 solver.cpp:218] Iteration 25850 (0.865615 iter/s, 57.7624s/50 iters), loss = 0.00762221
I0615 22:24:11.177850 29366 solver.cpp:237]     Train net output #0: loss = 0.00762225 (* 1 = 0.00762225 loss)
I0615 22:24:11.177872 29366 sgd_solver.cpp:105] Iteration 25850, lr = 0.01
I0615 22:25:08.932739 29366 solver.cpp:218] Iteration 25900 (0.865737 iter/s, 57.7542s/50 iters), loss = 0.00845751
I0615 22:25:08.932929 29366 solver.cpp:237]     Train net output #0: loss = 0.00845755 (* 1 = 0.00845755 loss)
I0615 22:25:08.932965 29366 sgd_solver.cpp:105] Iteration 25900, lr = 0.01
I0615 22:26:06.695333 29366 solver.cpp:218] Iteration 25950 (0.865625 iter/s, 57.7618s/50 iters), loss = 0.007747
I0615 22:26:06.695482 29366 solver.cpp:237]     Train net output #0: loss = 0.00774704 (* 1 = 0.00774704 loss)
I0615 22:26:06.695507 29366 sgd_solver.cpp:105] Iteration 25950, lr = 0.01
I0615 22:27:04.474617 29366 solver.cpp:218] Iteration 26000 (0.865374 iter/s, 57.7785s/50 iters), loss = 0.00971595
I0615 22:27:04.474763 29366 solver.cpp:237]     Train net output #0: loss = 0.00971599 (* 1 = 0.00971599 loss)
I0615 22:27:04.474787 29366 sgd_solver.cpp:105] Iteration 26000, lr = 0.01
I0615 22:28:02.244334 29366 solver.cpp:218] Iteration 26050 (0.865517 iter/s, 57.7689s/50 iters), loss = 0.0100613
I0615 22:28:02.244534 29366 solver.cpp:237]     Train net output #0: loss = 0.0100613 (* 1 = 0.0100613 loss)
I0615 22:28:02.244560 29366 sgd_solver.cpp:105] Iteration 26050, lr = 0.01
I0615 22:29:00.012485 29366 solver.cpp:218] Iteration 26100 (0.865541 iter/s, 57.7673s/50 iters), loss = 0.0137586
I0615 22:29:00.012596 29366 solver.cpp:237]     Train net output #0: loss = 0.0137586 (* 1 = 0.0137586 loss)
I0615 22:29:00.012619 29366 sgd_solver.cpp:105] Iteration 26100, lr = 0.01
I0615 22:29:57.780048 29366 solver.cpp:218] Iteration 26150 (0.865549 iter/s, 57.7668s/50 iters), loss = 0.00714688
I0615 22:29:57.780169 29366 solver.cpp:237]     Train net output #0: loss = 0.00714692 (* 1 = 0.00714692 loss)
I0615 22:29:57.780191 29366 sgd_solver.cpp:105] Iteration 26150, lr = 0.01
I0615 22:30:55.556002 29366 solver.cpp:218] Iteration 26200 (0.865423 iter/s, 57.7752s/50 iters), loss = 0.00546407
I0615 22:30:55.556128 29366 solver.cpp:237]     Train net output #0: loss = 0.00546411 (* 1 = 0.00546411 loss)
I0615 22:30:55.556151 29366 sgd_solver.cpp:105] Iteration 26200, lr = 0.01
I0615 22:31:53.330654 29366 solver.cpp:218] Iteration 26250 (0.865443 iter/s, 57.7739s/50 iters), loss = 0.00710133
I0615 22:31:53.330790 29366 solver.cpp:237]     Train net output #0: loss = 0.00710136 (* 1 = 0.00710136 loss)
I0615 22:31:53.330814 29366 sgd_solver.cpp:105] Iteration 26250, lr = 0.01
I0615 22:32:51.102823 29366 solver.cpp:218] Iteration 26300 (0.86548 iter/s, 57.7714s/50 iters), loss = 0.00604357
I0615 22:32:51.103010 29366 solver.cpp:237]     Train net output #0: loss = 0.0060436 (* 1 = 0.0060436 loss)
I0615 22:32:51.103035 29366 sgd_solver.cpp:105] Iteration 26300, lr = 0.01
I0615 22:33:48.869982 29366 solver.cpp:218] Iteration 26350 (0.865556 iter/s, 57.7663s/50 iters), loss = 0.00621156
I0615 22:33:48.870103 29366 solver.cpp:237]     Train net output #0: loss = 0.0062116 (* 1 = 0.0062116 loss)
I0615 22:33:48.870132 29366 sgd_solver.cpp:105] Iteration 26350, lr = 0.01
I0615 22:34:46.638772 29366 solver.cpp:218] Iteration 26400 (0.865531 iter/s, 57.768s/50 iters), loss = 0.0114239
I0615 22:34:46.638900 29366 solver.cpp:237]     Train net output #0: loss = 0.011424 (* 1 = 0.011424 loss)
I0615 22:34:46.638923 29366 sgd_solver.cpp:105] Iteration 26400, lr = 0.01
I0615 22:35:44.411085 29366 solver.cpp:218] Iteration 26450 (0.865478 iter/s, 57.7715s/50 iters), loss = 0.00824786
I0615 22:35:44.411237 29366 solver.cpp:237]     Train net output #0: loss = 0.00824789 (* 1 = 0.00824789 loss)
I0615 22:35:44.411260 29366 sgd_solver.cpp:105] Iteration 26450, lr = 0.01
I0615 22:36:42.185397 29366 solver.cpp:218] Iteration 26500 (0.865449 iter/s, 57.7735s/50 iters), loss = 0.0105233
I0615 22:36:42.185551 29366 solver.cpp:237]     Train net output #0: loss = 0.0105233 (* 1 = 0.0105233 loss)
I0615 22:36:42.185575 29366 sgd_solver.cpp:105] Iteration 26500, lr = 0.01
I0615 22:37:39.957959 29366 solver.cpp:218] Iteration 26550 (0.865475 iter/s, 57.7718s/50 iters), loss = 0.0091362
I0615 22:37:39.958093 29366 solver.cpp:237]     Train net output #0: loss = 0.00913624 (* 1 = 0.00913624 loss)
I0615 22:37:39.958117 29366 sgd_solver.cpp:105] Iteration 26550, lr = 0.01
I0615 22:38:37.736932 29366 solver.cpp:218] Iteration 26600 (0.865378 iter/s, 57.7782s/50 iters), loss = 0.00478904
I0615 22:38:37.737148 29366 solver.cpp:237]     Train net output #0: loss = 0.00478907 (* 1 = 0.00478907 loss)
I0615 22:38:37.737171 29366 sgd_solver.cpp:105] Iteration 26600, lr = 0.01
I0615 22:39:35.521575 29366 solver.cpp:218] Iteration 26650 (0.865295 iter/s, 57.7838s/50 iters), loss = 0.00447172
I0615 22:39:35.521735 29366 solver.cpp:237]     Train net output #0: loss = 0.00447176 (* 1 = 0.00447176 loss)
I0615 22:39:35.521759 29366 sgd_solver.cpp:105] Iteration 26650, lr = 0.01
I0615 22:40:33.294597 29366 solver.cpp:218] Iteration 26700 (0.865468 iter/s, 57.7722s/50 iters), loss = 0.00928912
I0615 22:40:33.294723 29366 solver.cpp:237]     Train net output #0: loss = 0.00928915 (* 1 = 0.00928915 loss)
I0615 22:40:33.294746 29366 sgd_solver.cpp:105] Iteration 26700, lr = 0.01
I0615 22:41:31.063982 29366 solver.cpp:218] Iteration 26750 (0.865522 iter/s, 57.7686s/50 iters), loss = 0.0149368
I0615 22:41:31.064121 29366 solver.cpp:237]     Train net output #0: loss = 0.0149368 (* 1 = 0.0149368 loss)
I0615 22:41:31.064146 29366 sgd_solver.cpp:105] Iteration 26750, lr = 0.01
I0615 22:42:28.838471 29366 solver.cpp:218] Iteration 26800 (0.865445 iter/s, 57.7737s/50 iters), loss = 0.00649967
I0615 22:42:28.838584 29366 solver.cpp:237]     Train net output #0: loss = 0.00649971 (* 1 = 0.00649971 loss)
I0615 22:42:28.838606 29366 sgd_solver.cpp:105] Iteration 26800, lr = 0.01
I0615 22:43:26.612606 29366 solver.cpp:218] Iteration 26850 (0.865451 iter/s, 57.7734s/50 iters), loss = 0.00684808
I0615 22:43:26.612731 29366 solver.cpp:237]     Train net output #0: loss = 0.00684812 (* 1 = 0.00684812 loss)
I0615 22:43:26.612754 29366 sgd_solver.cpp:105] Iteration 26850, lr = 0.01
I0615 22:44:24.386176 29366 solver.cpp:218] Iteration 26900 (0.865459 iter/s, 57.7728s/50 iters), loss = 0.0105355
I0615 22:44:24.386307 29366 solver.cpp:237]     Train net output #0: loss = 0.0105356 (* 1 = 0.0105356 loss)
I0615 22:44:24.386328 29366 sgd_solver.cpp:105] Iteration 26900, lr = 0.01
I0615 22:45:22.153539 29366 solver.cpp:218] Iteration 26950 (0.865552 iter/s, 57.7666s/50 iters), loss = 0.0057825
I0615 22:45:22.153664 29366 solver.cpp:237]     Train net output #0: loss = 0.00578254 (* 1 = 0.00578254 loss)
I0615 22:45:22.153687 29366 sgd_solver.cpp:105] Iteration 26950, lr = 0.01
I0615 22:46:19.926628 29366 solver.cpp:218] Iteration 27000 (0.865466 iter/s, 57.7723s/50 iters), loss = 0.00592373
I0615 22:46:19.926746 29366 solver.cpp:237]     Train net output #0: loss = 0.00592377 (* 1 = 0.00592377 loss)
I0615 22:46:19.926769 29366 sgd_solver.cpp:105] Iteration 27000, lr = 0.01
I0615 22:47:17.696638 29366 solver.cpp:218] Iteration 27050 (0.865512 iter/s, 57.7692s/50 iters), loss = 0.00643588
I0615 22:47:17.696729 29366 solver.cpp:237]     Train net output #0: loss = 0.00643593 (* 1 = 0.00643593 loss)
I0615 22:47:17.696753 29366 sgd_solver.cpp:105] Iteration 27050, lr = 0.01
I0615 22:48:15.470962 29366 solver.cpp:218] Iteration 27100 (0.865448 iter/s, 57.7736s/50 iters), loss = 0.00560939
I0615 22:48:15.471132 29366 solver.cpp:237]     Train net output #0: loss = 0.00560943 (* 1 = 0.00560943 loss)
I0615 22:48:15.471156 29366 sgd_solver.cpp:105] Iteration 27100, lr = 0.01
I0615 22:49:13.244374 29366 solver.cpp:218] Iteration 27150 (0.865462 iter/s, 57.7726s/50 iters), loss = 0.00500216
I0615 22:49:13.244504 29366 solver.cpp:237]     Train net output #0: loss = 0.0050022 (* 1 = 0.0050022 loss)
I0615 22:49:13.244536 29366 sgd_solver.cpp:105] Iteration 27150, lr = 0.01
I0615 22:50:11.015549 29366 solver.cpp:218] Iteration 27200 (0.865495 iter/s, 57.7704s/50 iters), loss = 0.007267
I0615 22:50:11.015691 29366 solver.cpp:237]     Train net output #0: loss = 0.00726704 (* 1 = 0.00726704 loss)
I0615 22:50:11.015714 29366 sgd_solver.cpp:105] Iteration 27200, lr = 0.01
I0615 22:51:08.780309 29366 solver.cpp:218] Iteration 27250 (0.865591 iter/s, 57.764s/50 iters), loss = 0.0079185
I0615 22:51:08.780510 29366 solver.cpp:237]     Train net output #0: loss = 0.00791854 (* 1 = 0.00791854 loss)
I0615 22:51:08.780542 29366 sgd_solver.cpp:105] Iteration 27250, lr = 0.01
I0615 22:52:06.553869 29366 solver.cpp:218] Iteration 27300 (0.86546 iter/s, 57.7727s/50 iters), loss = 0.00659562
I0615 22:52:06.553998 29366 solver.cpp:237]     Train net output #0: loss = 0.00659566 (* 1 = 0.00659566 loss)
I0615 22:52:06.554023 29366 sgd_solver.cpp:105] Iteration 27300, lr = 0.01
I0615 22:53:04.328475 29366 solver.cpp:218] Iteration 27350 (0.865444 iter/s, 57.7738s/50 iters), loss = 0.00799904
I0615 22:53:04.328642 29366 solver.cpp:237]     Train net output #0: loss = 0.00799908 (* 1 = 0.00799908 loss)
I0615 22:53:04.328666 29366 sgd_solver.cpp:105] Iteration 27350, lr = 0.01
I0615 22:54:02.102916 29366 solver.cpp:218] Iteration 27400 (0.865447 iter/s, 57.7736s/50 iters), loss = 0.00668568
I0615 22:54:02.103058 29366 solver.cpp:237]     Train net output #0: loss = 0.00668572 (* 1 = 0.00668572 loss)
I0615 22:54:02.103082 29366 sgd_solver.cpp:105] Iteration 27400, lr = 0.01
I0615 22:54:59.874963 29366 solver.cpp:218] Iteration 27450 (0.865482 iter/s, 57.7713s/50 iters), loss = 0.00421954
I0615 22:54:59.875090 29366 solver.cpp:237]     Train net output #0: loss = 0.00421959 (* 1 = 0.00421959 loss)
I0615 22:54:59.875114 29366 sgd_solver.cpp:105] Iteration 27450, lr = 0.01
I0615 22:55:57.645179 29366 solver.cpp:218] Iteration 27500 (0.865509 iter/s, 57.7694s/50 iters), loss = 0.00826938
I0615 22:55:57.645298 29366 solver.cpp:237]     Train net output #0: loss = 0.00826942 (* 1 = 0.00826942 loss)
I0615 22:55:57.645319 29366 sgd_solver.cpp:105] Iteration 27500, lr = 0.01
I0615 22:56:55.413018 29366 solver.cpp:218] Iteration 27550 (0.865545 iter/s, 57.7671s/50 iters), loss = 0.00772889
I0615 22:56:55.413146 29366 solver.cpp:237]     Train net output #0: loss = 0.00772894 (* 1 = 0.00772894 loss)
I0615 22:56:55.413168 29366 sgd_solver.cpp:105] Iteration 27550, lr = 0.01
I0615 22:57:53.187237 29366 solver.cpp:218] Iteration 27600 (0.865449 iter/s, 57.7735s/50 iters), loss = 0.00743457
I0615 22:57:53.187420 29366 solver.cpp:237]     Train net output #0: loss = 0.00743461 (* 1 = 0.00743461 loss)
I0615 22:57:53.187443 29366 sgd_solver.cpp:105] Iteration 27600, lr = 0.01
I0615 22:58:50.954082 29366 solver.cpp:218] Iteration 27650 (0.86556 iter/s, 57.766s/50 iters), loss = 0.00582196
I0615 22:58:50.954219 29366 solver.cpp:237]     Train net output #0: loss = 0.00582201 (* 1 = 0.00582201 loss)
I0615 22:58:50.954243 29366 sgd_solver.cpp:105] Iteration 27650, lr = 0.01
I0615 22:59:48.710243 29366 solver.cpp:218] Iteration 27700 (0.865718 iter/s, 57.7555s/50 iters), loss = 0.0122926
I0615 22:59:48.710440 29366 solver.cpp:237]     Train net output #0: loss = 0.0122926 (* 1 = 0.0122926 loss)
I0615 22:59:48.710470 29366 sgd_solver.cpp:105] Iteration 27700, lr = 0.01
I0615 23:00:46.467856 29366 solver.cpp:218] Iteration 27750 (0.865695 iter/s, 57.7571s/50 iters), loss = 0.00959928
I0615 23:00:46.467988 29366 solver.cpp:237]     Train net output #0: loss = 0.00959932 (* 1 = 0.00959932 loss)
I0615 23:00:46.468011 29366 sgd_solver.cpp:105] Iteration 27750, lr = 0.01
I0615 23:01:44.232803 29366 solver.cpp:218] Iteration 27800 (0.865584 iter/s, 57.7645s/50 iters), loss = 0.0072094
I0615 23:01:44.232935 29366 solver.cpp:237]     Train net output #0: loss = 0.00720944 (* 1 = 0.00720944 loss)
I0615 23:01:44.232959 29366 sgd_solver.cpp:105] Iteration 27800, lr = 0.01
I0615 23:02:41.998445 29366 solver.cpp:218] Iteration 27850 (0.865574 iter/s, 57.7652s/50 iters), loss = 0.00913022
I0615 23:02:41.998585 29366 solver.cpp:237]     Train net output #0: loss = 0.00913026 (* 1 = 0.00913026 loss)
I0615 23:02:41.998607 29366 sgd_solver.cpp:105] Iteration 27850, lr = 0.01
I0615 23:03:39.767963 29366 solver.cpp:218] Iteration 27900 (0.865516 iter/s, 57.769s/50 iters), loss = 0.00660287
I0615 23:03:39.768085 29366 solver.cpp:237]     Train net output #0: loss = 0.00660291 (* 1 = 0.00660291 loss)
I0615 23:03:39.768106 29366 sgd_solver.cpp:105] Iteration 27900, lr = 0.01
I0615 23:04:37.554894 29366 solver.cpp:218] Iteration 27950 (0.865255 iter/s, 57.7864s/50 iters), loss = 0.0061267
I0615 23:04:37.555083 29366 solver.cpp:237]     Train net output #0: loss = 0.00612675 (* 1 = 0.00612675 loss)
I0615 23:04:37.555116 29366 sgd_solver.cpp:105] Iteration 27950, lr = 0.01
I0615 23:05:35.325806 29366 solver.cpp:218] Iteration 28000 (0.865496 iter/s, 57.7704s/50 iters), loss = 0.00877491
I0615 23:05:35.325947 29366 solver.cpp:237]     Train net output #0: loss = 0.00877495 (* 1 = 0.00877495 loss)
I0615 23:05:35.325971 29366 sgd_solver.cpp:105] Iteration 28000, lr = 0.01
I0615 23:06:33.088073 29366 solver.cpp:218] Iteration 28050 (0.865625 iter/s, 57.7617s/50 iters), loss = 0.00721561
I0615 23:06:33.088203 29366 solver.cpp:237]     Train net output #0: loss = 0.00721566 (* 1 = 0.00721566 loss)
I0615 23:06:33.088227 29366 sgd_solver.cpp:105] Iteration 28050, lr = 0.01
I0615 23:07:30.850673 29366 solver.cpp:218] Iteration 28100 (0.86562 iter/s, 57.7621s/50 iters), loss = 0.00913098
I0615 23:07:30.850810 29366 solver.cpp:237]     Train net output #0: loss = 0.00913103 (* 1 = 0.00913103 loss)
I0615 23:07:30.850832 29366 sgd_solver.cpp:105] Iteration 28100, lr = 0.01
I0615 23:08:28.619393 29366 solver.cpp:218] Iteration 28150 (0.865528 iter/s, 57.7682s/50 iters), loss = 0.0105156
I0615 23:08:28.619505 29366 solver.cpp:237]     Train net output #0: loss = 0.0105156 (* 1 = 0.0105156 loss)
I0615 23:08:28.619539 29366 sgd_solver.cpp:105] Iteration 28150, lr = 0.01
I0615 23:09:26.389947 29366 solver.cpp:218] Iteration 28200 (0.8655 iter/s, 57.7701s/50 iters), loss = 0.00826443
I0615 23:09:26.390096 29366 solver.cpp:237]     Train net output #0: loss = 0.00826447 (* 1 = 0.00826447 loss)
I0615 23:09:26.390118 29366 sgd_solver.cpp:105] Iteration 28200, lr = 0.01
I0615 23:10:24.156100 29366 solver.cpp:218] Iteration 28250 (0.865567 iter/s, 57.7656s/50 iters), loss = 0.00989686
I0615 23:10:24.156304 29366 solver.cpp:237]     Train net output #0: loss = 0.00989691 (* 1 = 0.00989691 loss)
I0615 23:10:24.156333 29366 sgd_solver.cpp:105] Iteration 28250, lr = 0.01
I0615 23:11:21.924083 29366 solver.cpp:218] Iteration 28300 (0.86554 iter/s, 57.7674s/50 iters), loss = 0.00607977
I0615 23:11:21.924201 29366 solver.cpp:237]     Train net output #0: loss = 0.00607981 (* 1 = 0.00607981 loss)
I0615 23:11:21.924223 29366 sgd_solver.cpp:105] Iteration 28300, lr = 0.01
I0615 23:12:19.695487 29366 solver.cpp:218] Iteration 28350 (0.865488 iter/s, 57.7709s/50 iters), loss = 0.00772241
I0615 23:12:19.695672 29366 solver.cpp:237]     Train net output #0: loss = 0.00772245 (* 1 = 0.00772245 loss)
I0615 23:12:19.695696 29366 sgd_solver.cpp:105] Iteration 28350, lr = 0.01
I0615 23:13:17.467602 29366 solver.cpp:218] Iteration 28400 (0.865478 iter/s, 57.7715s/50 iters), loss = 0.00623524
I0615 23:13:17.467803 29366 solver.cpp:237]     Train net output #0: loss = 0.00623528 (* 1 = 0.00623528 loss)
I0615 23:13:17.467828 29366 sgd_solver.cpp:105] Iteration 28400, lr = 0.01
I0615 23:14:15.814631 29366 solver.cpp:218] Iteration 28450 (0.856969 iter/s, 58.3452s/50 iters), loss = 0.0111716
I0615 23:14:15.818608 29366 solver.cpp:237]     Train net output #0: loss = 0.0111716 (* 1 = 0.0111716 loss)
I0615 23:14:15.818636 29366 sgd_solver.cpp:105] Iteration 28450, lr = 0.01
I0615 23:15:14.349632 29366 solver.cpp:218] Iteration 28500 (0.854323 iter/s, 58.5259s/50 iters), loss = 0.0076719
I0615 23:15:14.353649 29366 solver.cpp:237]     Train net output #0: loss = 0.00767194 (* 1 = 0.00767194 loss)
I0615 23:15:14.353688 29366 sgd_solver.cpp:105] Iteration 28500, lr = 0.01
I0615 23:16:12.122225 29366 solver.cpp:218] Iteration 28550 (0.865529 iter/s, 57.7681s/50 iters), loss = 0.00794653
I0615 23:16:12.122403 29366 solver.cpp:237]     Train net output #0: loss = 0.00794657 (* 1 = 0.00794657 loss)
I0615 23:16:12.122434 29366 sgd_solver.cpp:105] Iteration 28550, lr = 0.01
I0615 23:17:09.855005 29366 solver.cpp:218] Iteration 28600 (0.86607 iter/s, 57.7321s/50 iters), loss = 0.00832756
I0615 23:17:09.855186 29366 solver.cpp:237]     Train net output #0: loss = 0.0083276 (* 1 = 0.0083276 loss)
I0615 23:17:09.855212 29366 sgd_solver.cpp:105] Iteration 28600, lr = 0.01
I0615 23:18:07.597846 29366 solver.cpp:218] Iteration 28650 (0.86592 iter/s, 57.7421s/50 iters), loss = 0.0117733
I0615 23:18:07.598111 29366 solver.cpp:237]     Train net output #0: loss = 0.0117734 (* 1 = 0.0117734 loss)
I0615 23:18:07.598142 29366 sgd_solver.cpp:105] Iteration 28650, lr = 0.01
I0615 23:19:05.382818 29366 solver.cpp:218] Iteration 28700 (0.865289 iter/s, 57.7841s/50 iters), loss = 0.00930884
I0615 23:19:05.382966 29366 solver.cpp:237]     Train net output #0: loss = 0.00930888 (* 1 = 0.00930888 loss)
I0615 23:19:05.382995 29366 sgd_solver.cpp:105] Iteration 28700, lr = 0.01
I0615 23:20:03.160048 29366 solver.cpp:218] Iteration 28750 (0.865405 iter/s, 57.7764s/50 iters), loss = 0.00894023
I0615 23:20:03.160244 29366 solver.cpp:237]     Train net output #0: loss = 0.00894027 (* 1 = 0.00894027 loss)
I0615 23:20:03.160276 29366 sgd_solver.cpp:105] Iteration 28750, lr = 0.01
I0615 23:21:00.946693 29366 solver.cpp:218] Iteration 28800 (0.865263 iter/s, 57.7859s/50 iters), loss = 0.00644021
I0615 23:21:00.946874 29366 solver.cpp:237]     Train net output #0: loss = 0.00644025 (* 1 = 0.00644025 loss)
I0615 23:21:00.946899 29366 sgd_solver.cpp:105] Iteration 28800, lr = 0.01
I0615 23:21:58.742409 29366 solver.cpp:218] Iteration 28850 (0.865127 iter/s, 57.795s/50 iters), loss = 0.0110941
I0615 23:21:58.742580 29366 solver.cpp:237]     Train net output #0: loss = 0.0110942 (* 1 = 0.0110942 loss)
I0615 23:21:58.742606 29366 sgd_solver.cpp:105] Iteration 28850, lr = 0.01
I0615 23:22:56.531664 29366 solver.cpp:218] Iteration 28900 (0.865224 iter/s, 57.7885s/50 iters), loss = 0.00793634
I0615 23:22:56.531882 29366 solver.cpp:237]     Train net output #0: loss = 0.00793638 (* 1 = 0.00793638 loss)
I0615 23:22:56.531904 29366 sgd_solver.cpp:105] Iteration 28900, lr = 0.01
I0615 23:23:54.331298 29366 solver.cpp:218] Iteration 28950 (0.865069 iter/s, 57.7988s/50 iters), loss = 0.00981006
I0615 23:23:54.331527 29366 solver.cpp:237]     Train net output #0: loss = 0.0098101 (* 1 = 0.0098101 loss)
I0615 23:23:54.331552 29366 sgd_solver.cpp:105] Iteration 28950, lr = 0.01
I0615 23:24:52.120115 29366 solver.cpp:218] Iteration 29000 (0.865232 iter/s, 57.788s/50 iters), loss = 0.011215
I0615 23:24:52.120318 29366 solver.cpp:237]     Train net output #0: loss = 0.011215 (* 1 = 0.011215 loss)
I0615 23:24:52.120340 29366 sgd_solver.cpp:105] Iteration 29000, lr = 0.01
I0615 23:25:49.895527 29366 solver.cpp:218] Iteration 29050 (0.865432 iter/s, 57.7746s/50 iters), loss = 0.0078433
I0615 23:25:49.895669 29366 solver.cpp:237]     Train net output #0: loss = 0.00784334 (* 1 = 0.00784334 loss)
I0615 23:25:49.895694 29366 sgd_solver.cpp:105] Iteration 29050, lr = 0.01
I0615 23:26:47.674057 29366 solver.cpp:218] Iteration 29100 (0.865384 iter/s, 57.7778s/50 iters), loss = 0.00672764
I0615 23:26:47.674204 29366 solver.cpp:237]     Train net output #0: loss = 0.00672768 (* 1 = 0.00672768 loss)
I0615 23:26:47.674228 29366 sgd_solver.cpp:105] Iteration 29100, lr = 0.01
I0615 23:27:45.430923 29366 solver.cpp:218] Iteration 29150 (0.865709 iter/s, 57.7561s/50 iters), loss = 0.0103423
I0615 23:27:45.431068 29366 solver.cpp:237]     Train net output #0: loss = 0.0103424 (* 1 = 0.0103424 loss)
I0615 23:27:45.431092 29366 sgd_solver.cpp:105] Iteration 29150, lr = 0.01
I0615 23:28:43.205775 29366 solver.cpp:218] Iteration 29200 (0.86544 iter/s, 57.7741s/50 iters), loss = 0.00698004
I0615 23:28:43.205996 29366 solver.cpp:237]     Train net output #0: loss = 0.00698007 (* 1 = 0.00698007 loss)
I0615 23:28:43.206025 29366 sgd_solver.cpp:105] Iteration 29200, lr = 0.01
I0615 23:29:40.984808 29366 solver.cpp:218] Iteration 29250 (0.865378 iter/s, 57.7782s/50 iters), loss = 0.00596479
I0615 23:29:40.984925 29366 solver.cpp:237]     Train net output #0: loss = 0.00596483 (* 1 = 0.00596483 loss)
I0615 23:29:40.984946 29366 sgd_solver.cpp:105] Iteration 29250, lr = 0.01
I0615 23:30:38.749246 29366 solver.cpp:218] Iteration 29300 (0.865595 iter/s, 57.7637s/50 iters), loss = 0.00936789
I0615 23:30:38.749413 29366 solver.cpp:237]     Train net output #0: loss = 0.00936793 (* 1 = 0.00936793 loss)
I0615 23:30:38.749446 29366 sgd_solver.cpp:105] Iteration 29300, lr = 0.01
I0615 23:31:36.509171 29366 solver.cpp:218] Iteration 29350 (0.865663 iter/s, 57.7592s/50 iters), loss = 0.00865934
I0615 23:31:36.509397 29366 solver.cpp:237]     Train net output #0: loss = 0.00865938 (* 1 = 0.00865938 loss)
I0615 23:31:36.509419 29366 sgd_solver.cpp:105] Iteration 29350, lr = 0.01
I0615 23:32:34.266927 29366 solver.cpp:218] Iteration 29400 (0.865697 iter/s, 57.757s/50 iters), loss = 0.00621126
I0615 23:32:34.267062 29366 solver.cpp:237]     Train net output #0: loss = 0.0062113 (* 1 = 0.0062113 loss)
I0615 23:32:34.267086 29366 sgd_solver.cpp:105] Iteration 29400, lr = 0.01
I0615 23:33:32.029297 29366 solver.cpp:218] Iteration 29450 (0.865626 iter/s, 57.7616s/50 iters), loss = 0.00712408
I0615 23:33:32.029438 29366 solver.cpp:237]     Train net output #0: loss = 0.00712412 (* 1 = 0.00712412 loss)
I0615 23:33:32.029461 29366 sgd_solver.cpp:105] Iteration 29450, lr = 0.01
I0615 23:34:29.795754 29366 solver.cpp:218] Iteration 29500 (0.865565 iter/s, 57.7657s/50 iters), loss = 0.00787811
I0615 23:34:29.795889 29366 solver.cpp:237]     Train net output #0: loss = 0.00787815 (* 1 = 0.00787815 loss)
I0615 23:34:29.795913 29366 sgd_solver.cpp:105] Iteration 29500, lr = 0.01
I0615 23:35:27.567899 29366 solver.cpp:218] Iteration 29550 (0.86548 iter/s, 57.7714s/50 iters), loss = 0.00551216
I0615 23:35:27.568032 29366 solver.cpp:237]     Train net output #0: loss = 0.0055122 (* 1 = 0.0055122 loss)
I0615 23:35:27.568056 29366 sgd_solver.cpp:105] Iteration 29550, lr = 0.01
I0615 23:36:25.336550 29366 solver.cpp:218] Iteration 29600 (0.865532 iter/s, 57.7679s/50 iters), loss = 0.00624725
I0615 23:36:25.336675 29366 solver.cpp:237]     Train net output #0: loss = 0.00624729 (* 1 = 0.00624729 loss)
I0615 23:36:25.336697 29366 sgd_solver.cpp:105] Iteration 29600, lr = 0.01
I0615 23:37:23.098666 29366 solver.cpp:218] Iteration 29650 (0.86563 iter/s, 57.7614s/50 iters), loss = 0.0103626
I0615 23:37:23.098850 29366 solver.cpp:237]     Train net output #0: loss = 0.0103627 (* 1 = 0.0103627 loss)
I0615 23:37:23.098872 29366 sgd_solver.cpp:105] Iteration 29650, lr = 0.01
I0615 23:38:20.860079 29366 solver.cpp:218] Iteration 29700 (0.865641 iter/s, 57.7606s/50 iters), loss = 0.00871109
I0615 23:38:20.860203 29366 solver.cpp:237]     Train net output #0: loss = 0.00871113 (* 1 = 0.00871113 loss)
I0615 23:38:20.860224 29366 sgd_solver.cpp:105] Iteration 29700, lr = 0.01
I0615 23:39:18.623234 29366 solver.cpp:218] Iteration 29750 (0.865614 iter/s, 57.7624s/50 iters), loss = 0.00735735
I0615 23:39:18.623364 29366 solver.cpp:237]     Train net output #0: loss = 0.00735739 (* 1 = 0.00735739 loss)
I0615 23:39:18.623389 29366 sgd_solver.cpp:105] Iteration 29750, lr = 0.01
I0615 23:40:16.379340 29366 solver.cpp:218] Iteration 29800 (0.86572 iter/s, 57.7554s/50 iters), loss = 0.00760547
I0615 23:40:16.379475 29366 solver.cpp:237]     Train net output #0: loss = 0.00760551 (* 1 = 0.00760551 loss)
I0615 23:40:16.379498 29366 sgd_solver.cpp:105] Iteration 29800, lr = 0.01
I0615 23:41:14.158140 29366 solver.cpp:218] Iteration 29850 (0.86538 iter/s, 57.7781s/50 iters), loss = 0.00734426
I0615 23:41:14.158303 29366 solver.cpp:237]     Train net output #0: loss = 0.00734429 (* 1 = 0.00734429 loss)
I0615 23:41:14.158326 29366 sgd_solver.cpp:105] Iteration 29850, lr = 0.01
I0615 23:42:11.932529 29366 solver.cpp:218] Iteration 29900 (0.865447 iter/s, 57.7736s/50 iters), loss = 0.00943923
I0615 23:42:11.932690 29366 solver.cpp:237]     Train net output #0: loss = 0.00943927 (* 1 = 0.00943927 loss)
I0615 23:42:11.932714 29366 sgd_solver.cpp:105] Iteration 29900, lr = 0.01
I0615 23:43:09.692598 29366 solver.cpp:218] Iteration 29950 (0.865661 iter/s, 57.7593s/50 iters), loss = 0.0102816
I0615 23:43:09.692734 29366 solver.cpp:237]     Train net output #0: loss = 0.0102816 (* 1 = 0.0102816 loss)
I0615 23:43:09.692755 29366 sgd_solver.cpp:105] Iteration 29950, lr = 0.01
I0615 23:44:06.308940 29366 solver.cpp:447] Snapshotting to binary proto file mobilenet/mobile_2_iter_30000.caffemodel
I0615 23:44:06.394196 29366 sgd_solver.cpp:273] Snapshotting solver state to binary proto file mobilenet/mobile_2_iter_30000.solverstate
I0615 23:44:07.575520 29366 solver.cpp:218] Iteration 30000 (0.863823 iter/s, 57.8822s/50 iters), loss = 0.00670719
I0615 23:44:07.575599 29366 solver.cpp:237]     Train net output #0: loss = 0.00670723 (* 1 = 0.00670723 loss)
I0615 23:44:07.575619 29366 sgd_solver.cpp:105] Iteration 30000, lr = 0.01
I0615 23:45:05.338676 29366 solver.cpp:218] Iteration 30050 (0.865614 iter/s, 57.7625s/50 iters), loss = 0.00633955
I0615 23:45:05.338806 29366 solver.cpp:237]     Train net output #0: loss = 0.00633959 (* 1 = 0.00633959 loss)
I0615 23:45:05.338829 29366 sgd_solver.cpp:105] Iteration 30050, lr = 0.01
I0615 23:46:03.109091 29366 solver.cpp:218] Iteration 30100 (0.865506 iter/s, 57.7697s/50 iters), loss = 0.0066203
I0615 23:46:03.109230 29366 solver.cpp:237]     Train net output #0: loss = 0.00662033 (* 1 = 0.00662033 loss)
I0615 23:46:03.109253 29366 sgd_solver.cpp:105] Iteration 30100, lr = 0.01
I0615 23:47:00.869606 29366 solver.cpp:218] Iteration 30150 (0.865654 iter/s, 57.7598s/50 iters), loss = 0.0095534
I0615 23:47:00.869748 29366 solver.cpp:237]     Train net output #0: loss = 0.00955344 (* 1 = 0.00955344 loss)
I0615 23:47:00.869771 29366 sgd_solver.cpp:105] Iteration 30150, lr = 0.01
I0615 23:47:58.632019 29366 solver.cpp:218] Iteration 30200 (0.865626 iter/s, 57.7617s/50 iters), loss = 0.0122177
I0615 23:47:58.632144 29366 solver.cpp:237]     Train net output #0: loss = 0.0122177 (* 1 = 0.0122177 loss)
I0615 23:47:58.632167 29366 sgd_solver.cpp:105] Iteration 30200, lr = 0.01
I0615 23:48:56.409011 29366 solver.cpp:218] Iteration 30250 (0.865407 iter/s, 57.7763s/50 iters), loss = 0.00761382
I0615 23:48:56.409168 29366 solver.cpp:237]     Train net output #0: loss = 0.00761386 (* 1 = 0.00761386 loss)
I0615 23:48:56.409191 29366 sgd_solver.cpp:105] Iteration 30250, lr = 0.01
I0615 23:49:54.174296 29366 solver.cpp:218] Iteration 30300 (0.865583 iter/s, 57.7645s/50 iters), loss = 0.0064991
I0615 23:49:54.174439 29366 solver.cpp:237]     Train net output #0: loss = 0.00649914 (* 1 = 0.00649914 loss)
I0615 23:49:54.174463 29366 sgd_solver.cpp:105] Iteration 30300, lr = 0.01
I0615 23:50:51.936348 29366 solver.cpp:218] Iteration 30350 (0.86563 iter/s, 57.7614s/50 iters), loss = 0.108827
I0615 23:50:51.936489 29366 solver.cpp:237]     Train net output #0: loss = 0.108827 (* 1 = 0.108827 loss)
I0615 23:50:51.936524 29366 sgd_solver.cpp:105] Iteration 30350, lr = 0.01
I0615 23:51:49.694841 29366 solver.cpp:218] Iteration 30400 (0.865681 iter/s, 57.758s/50 iters), loss = 1.22464
I0615 23:51:49.695266 29366 solver.cpp:237]     Train net output #0: loss = 1.22464 (* 1 = 1.22464 loss)
I0615 23:51:49.695287 29366 sgd_solver.cpp:105] Iteration 30400, lr = 0.01
I0615 23:52:47.471729 29366 solver.cpp:218] Iteration 30450 (0.86541 iter/s, 57.7761s/50 iters), loss = 1.28196
I0615 23:52:47.471854 29366 solver.cpp:237]     Train net output #0: loss = 1.28196 (* 1 = 1.28196 loss)
I0615 23:52:47.471879 29366 sgd_solver.cpp:105] Iteration 30450, lr = 0.01
I0615 23:53:45.253201 29366 solver.cpp:218] Iteration 30500 (0.865337 iter/s, 57.781s/50 iters), loss = 0.900288
I0615 23:53:45.253413 29366 solver.cpp:237]     Train net output #0: loss = 0.900289 (* 1 = 0.900289 loss)
I0615 23:53:45.253437 29366 sgd_solver.cpp:105] Iteration 30500, lr = 0.01
I0615 23:54:43.019487 29366 solver.cpp:218] Iteration 30550 (0.865566 iter/s, 57.7657s/50 iters), loss = 0.643986
I0615 23:54:43.030589 29366 solver.cpp:237]     Train net output #0: loss = 0.643987 (* 1 = 0.643987 loss)
I0615 23:54:43.030613 29366 sgd_solver.cpp:105] Iteration 30550, lr = 0.01
I0615 23:55:40.798065 29366 solver.cpp:218] Iteration 30600 (0.865545 iter/s, 57.7671s/50 iters), loss = 0.436619
I0615 23:55:40.798195 29366 solver.cpp:237]     Train net output #0: loss = 0.43662 (* 1 = 0.43662 loss)
I0615 23:55:40.798218 29366 sgd_solver.cpp:105] Iteration 30600, lr = 0.01
I0615 23:56:38.561825 29366 solver.cpp:218] Iteration 30650 (0.865602 iter/s, 57.7632s/50 iters), loss = 0.533952
I0615 23:56:38.561991 29366 solver.cpp:237]     Train net output #0: loss = 0.533952 (* 1 = 0.533952 loss)
I0615 23:56:38.562016 29366 sgd_solver.cpp:105] Iteration 30650, lr = 0.01
I0615 23:57:36.329231 29366 solver.cpp:218] Iteration 30700 (0.865548 iter/s, 57.7668s/50 iters), loss = 0.368328
I0615 23:57:36.329393 29366 solver.cpp:237]     Train net output #0: loss = 0.368328 (* 1 = 0.368328 loss)
I0615 23:57:36.329416 29366 sgd_solver.cpp:105] Iteration 30700, lr = 0.01
I0615 23:58:34.106024 29366 solver.cpp:218] Iteration 30750 (0.865408 iter/s, 57.7762s/50 iters), loss = 0.176637
I0615 23:58:34.106186 29366 solver.cpp:237]     Train net output #0: loss = 0.176637 (* 1 = 0.176637 loss)
I0615 23:58:34.106209 29366 sgd_solver.cpp:105] Iteration 30750, lr = 0.01
I0615 23:59:31.866597 29366 solver.cpp:218] Iteration 30800 (0.865651 iter/s, 57.76s/50 iters), loss = 0.342762
I0615 23:59:31.866715 29366 solver.cpp:237]     Train net output #0: loss = 0.342762 (* 1 = 0.342762 loss)
I0615 23:59:31.866739 29366 sgd_solver.cpp:105] Iteration 30800, lr = 0.01
I0616 00:00:29.635622 29366 solver.cpp:218] Iteration 30850 (0.865524 iter/s, 57.7685s/50 iters), loss = 0.238465
I0616 00:00:29.635793 29366 solver.cpp:237]     Train net output #0: loss = 0.238465 (* 1 = 0.238465 loss)
I0616 00:00:29.635817 29366 sgd_solver.cpp:105] Iteration 30850, lr = 0.01
I0616 00:01:28.946805 29366 solver.cpp:218] Iteration 30900 (0.84302 iter/s, 59.3106s/50 iters), loss = 0.202808
I0616 00:01:28.952955 29366 solver.cpp:237]     Train net output #0: loss = 0.202808 (* 1 = 0.202808 loss)
I0616 00:01:28.953011 29366 sgd_solver.cpp:105] Iteration 30900, lr = 0.01
I0616 00:02:27.561691 29366 solver.cpp:218] Iteration 30950 (0.853122 iter/s, 58.6083s/50 iters), loss = 0.331566
I0616 00:02:27.566566 29366 solver.cpp:237]     Train net output #0: loss = 0.331566 (* 1 = 0.331566 loss)
I0616 00:02:27.566614 29366 sgd_solver.cpp:105] Iteration 30950, lr = 0.01
I0616 00:03:25.579701 29366 solver.cpp:218] Iteration 31000 (0.86188 iter/s, 58.0127s/50 iters), loss = 0.116595
I0616 00:03:25.579843 29366 solver.cpp:237]     Train net output #0: loss = 0.116595 (* 1 = 0.116595 loss)
I0616 00:03:25.579867 29366 sgd_solver.cpp:105] Iteration 31000, lr = 0.01
I0616 00:04:23.935860 29366 solver.cpp:218] Iteration 31050 (0.856816 iter/s, 58.3556s/50 iters), loss = 0.11787
I0616 00:04:23.939609 29366 solver.cpp:237]     Train net output #0: loss = 0.11787 (* 1 = 0.11787 loss)
I0616 00:04:23.939636 29366 sgd_solver.cpp:105] Iteration 31050, lr = 0.01
I0616 00:05:22.902842 29366 solver.cpp:218] Iteration 31100 (0.847992 iter/s, 58.9628s/50 iters), loss = 0.177622
I0616 00:05:22.906592 29366 solver.cpp:237]     Train net output #0: loss = 0.177622 (* 1 = 0.177622 loss)
I0616 00:05:22.906617 29366 sgd_solver.cpp:105] Iteration 31100, lr = 0.01
I0616 00:06:21.200711 29366 solver.cpp:218] Iteration 31150 (0.857725 iter/s, 58.2937s/50 iters), loss = 0.0652402
I0616 00:06:21.200837 29366 solver.cpp:237]     Train net output #0: loss = 0.0652403 (* 1 = 0.0652403 loss)
I0616 00:06:21.200860 29366 sgd_solver.cpp:105] Iteration 31150, lr = 0.01
I0616 00:07:18.982985 29366 solver.cpp:218] Iteration 31200 (0.865325 iter/s, 57.7817s/50 iters), loss = 0.065948
I0616 00:07:18.983104 29366 solver.cpp:237]     Train net output #0: loss = 0.0659481 (* 1 = 0.0659481 loss)
I0616 00:07:18.983126 29366 sgd_solver.cpp:105] Iteration 31200, lr = 0.01
I0616 00:09:09.627610 29366 solver.cpp:218] Iteration 31250 (0.451965 iter/s, 110.628s/50 iters), loss = 0.110682
I0616 00:09:09.643577 29366 solver.cpp:237]     Train net output #0: loss = 0.110682 (* 1 = 0.110682 loss)
I0616 00:09:09.643631 29366 sgd_solver.cpp:105] Iteration 31250, lr = 0.01
I0616 00:11:01.911643 29366 solver.cpp:218] Iteration 31300 (0.44553 iter/s, 112.226s/50 iters), loss = 0.0638017
I0616 00:11:01.920661 29366 solver.cpp:237]     Train net output #0: loss = 0.0638018 (* 1 = 0.0638018 loss)
I0616 00:11:01.920697 29366 sgd_solver.cpp:105] Iteration 31300, lr = 0.01
I0616 00:12:09.824800 29366 solver.cpp:218] Iteration 31350 (0.736336 iter/s, 67.9038s/50 iters), loss = 0.0355814
I0616 00:12:09.824995 29366 solver.cpp:237]     Train net output #0: loss = 0.0355815 (* 1 = 0.0355815 loss)
I0616 00:12:09.825019 29366 sgd_solver.cpp:105] Iteration 31350, lr = 0.01
I0616 00:13:07.582228 29366 solver.cpp:218] Iteration 31400 (0.865698 iter/s, 57.7568s/50 iters), loss = 0.0463574
I0616 00:13:07.582361 29366 solver.cpp:237]     Train net output #0: loss = 0.0463575 (* 1 = 0.0463575 loss)
I0616 00:13:07.582391 29366 sgd_solver.cpp:105] Iteration 31400, lr = 0.01
I0616 00:14:05.362879 29366 solver.cpp:218] Iteration 31450 (0.86535 iter/s, 57.7801s/50 iters), loss = 0.0875752
I0616 00:14:05.362996 29366 solver.cpp:237]     Train net output #0: loss = 0.0875753 (* 1 = 0.0875753 loss)
I0616 00:14:05.363018 29366 sgd_solver.cpp:105] Iteration 31450, lr = 0.01
I0616 00:15:03.140811 29366 solver.cpp:218] Iteration 31500 (0.86539 iter/s, 57.7774s/50 iters), loss = 0.0303693
I0616 00:15:03.140946 29366 solver.cpp:237]     Train net output #0: loss = 0.0303694 (* 1 = 0.0303694 loss)
I0616 00:15:03.140969 29366 sgd_solver.cpp:105] Iteration 31500, lr = 0.01
I0616 00:16:00.911319 29366 solver.cpp:218] Iteration 31550 (0.865502 iter/s, 57.7699s/50 iters), loss = 0.137197
I0616 00:16:00.911510 29366 solver.cpp:237]     Train net output #0: loss = 0.137197 (* 1 = 0.137197 loss)
I0616 00:16:00.911541 29366 sgd_solver.cpp:105] Iteration 31550, lr = 0.01
I0616 00:16:58.688668 29366 solver.cpp:218] Iteration 31600 (0.8654 iter/s, 57.7767s/50 iters), loss = 0.0911762
I0616 00:16:58.688793 29366 solver.cpp:237]     Train net output #0: loss = 0.0911763 (* 1 = 0.0911763 loss)
I0616 00:16:58.688817 29366 sgd_solver.cpp:105] Iteration 31600, lr = 0.01
I0616 00:17:56.449067 29366 solver.cpp:218] Iteration 31650 (0.865653 iter/s, 57.7598s/50 iters), loss = 0.0242722
I0616 00:17:56.449185 29366 solver.cpp:237]     Train net output #0: loss = 0.0242724 (* 1 = 0.0242724 loss)
I0616 00:17:56.449208 29366 sgd_solver.cpp:105] Iteration 31650, lr = 0.01
I0616 00:18:54.635880 29366 solver.cpp:218] Iteration 31700 (0.85931 iter/s, 58.1862s/50 iters), loss = 0.0185882
I0616 00:18:54.639628 29366 solver.cpp:237]     Train net output #0: loss = 0.0185884 (* 1 = 0.0185884 loss)
I0616 00:18:54.639655 29366 sgd_solver.cpp:105] Iteration 31700, lr = 0.01
I0616 00:19:52.860507 29366 solver.cpp:218] Iteration 31750 (0.858825 iter/s, 58.2191s/50 iters), loss = 0.0675143
I0616 00:19:52.863016 29366 solver.cpp:237]     Train net output #0: loss = 0.0675144 (* 1 = 0.0675144 loss)
I0616 00:19:52.863045 29366 sgd_solver.cpp:105] Iteration 31750, lr = 0.01
I0616 00:20:51.151108 29366 solver.cpp:218] Iteration 31800 (0.857815 iter/s, 58.2876s/50 iters), loss = 0.0549781
I0616 00:20:51.154132 29366 solver.cpp:237]     Train net output #0: loss = 0.0549783 (* 1 = 0.0549783 loss)
I0616 00:20:51.154165 29366 sgd_solver.cpp:105] Iteration 31800, lr = 0.01
I0616 00:22:56.131764 29366 solver.cpp:218] Iteration 31850 (0.400074 iter/s, 124.977s/50 iters), loss = 0.0299857
I0616 00:22:56.131942 29366 solver.cpp:237]     Train net output #0: loss = 0.0299859 (* 1 = 0.0299859 loss)
I0616 00:22:56.131970 29366 sgd_solver.cpp:105] Iteration 31850, lr = 0.01
I0616 00:23:53.879977 29366 solver.cpp:218] Iteration 31900 (0.865836 iter/s, 57.7477s/50 iters), loss = 0.0315543
I0616 00:23:53.880115 29366 solver.cpp:237]     Train net output #0: loss = 0.0315544 (* 1 = 0.0315544 loss)
I0616 00:23:53.880138 29366 sgd_solver.cpp:105] Iteration 31900, lr = 0.01
I0616 00:24:51.650965 29366 solver.cpp:218] Iteration 31950 (0.865495 iter/s, 57.7704s/50 iters), loss = 0.0108099
I0616 00:24:51.651101 29366 solver.cpp:237]     Train net output #0: loss = 0.0108101 (* 1 = 0.0108101 loss)
I0616 00:24:51.651135 29366 sgd_solver.cpp:105] Iteration 31950, lr = 0.01
I0616 00:25:49.414608 29366 solver.cpp:218] Iteration 32000 (0.865605 iter/s, 57.7631s/50 iters), loss = 0.0131532
I0616 00:25:49.414791 29366 solver.cpp:237]     Train net output #0: loss = 0.0131533 (* 1 = 0.0131533 loss)
I0616 00:25:49.414827 29366 sgd_solver.cpp:105] Iteration 32000, lr = 0.01
I0616 00:26:47.171398 29366 solver.cpp:218] Iteration 32050 (0.865708 iter/s, 57.7562s/50 iters), loss = 0.0185695
I0616 00:26:47.171530 29366 solver.cpp:237]     Train net output #0: loss = 0.0185696 (* 1 = 0.0185696 loss)
I0616 00:26:47.171555 29366 sgd_solver.cpp:105] Iteration 32050, lr = 0.01
I0616 00:27:44.932555 29366 solver.cpp:218] Iteration 32100 (0.865643 iter/s, 57.7606s/50 iters), loss = 0.0232384
I0616 00:27:44.932710 29366 solver.cpp:237]     Train net output #0: loss = 0.0232385 (* 1 = 0.0232385 loss)
I0616 00:27:44.932734 29366 sgd_solver.cpp:105] Iteration 32100, lr = 0.01
I0616 00:28:42.702836 29366 solver.cpp:218] Iteration 32150 (0.865506 iter/s, 57.7697s/50 iters), loss = 0.00949414
I0616 00:28:42.702986 29366 solver.cpp:237]     Train net output #0: loss = 0.00949429 (* 1 = 0.00949429 loss)
I0616 00:28:42.703008 29366 sgd_solver.cpp:105] Iteration 32150, lr = 0.01
I0616 00:29:40.471891 29366 solver.cpp:218] Iteration 32200 (0.865524 iter/s, 57.7685s/50 iters), loss = 0.0143845
I0616 00:29:40.472018 29366 solver.cpp:237]     Train net output #0: loss = 0.0143847 (* 1 = 0.0143847 loss)
I0616 00:29:40.472043 29366 sgd_solver.cpp:105] Iteration 32200, lr = 0.01
I0616 00:30:38.240088 29366 solver.cpp:218] Iteration 32250 (0.865537 iter/s, 57.7676s/50 iters), loss = 0.00983937
I0616 00:30:38.240209 29366 solver.cpp:237]     Train net output #0: loss = 0.00983952 (* 1 = 0.00983952 loss)
I0616 00:30:38.240231 29366 sgd_solver.cpp:105] Iteration 32250, lr = 0.01
I0616 00:31:36.006834 29366 solver.cpp:218] Iteration 32300 (0.865559 iter/s, 57.7662s/50 iters), loss = 0.0129377
I0616 00:31:36.006968 29366 solver.cpp:237]     Train net output #0: loss = 0.0129379 (* 1 = 0.0129379 loss)
I0616 00:31:36.006991 29366 sgd_solver.cpp:105] Iteration 32300, lr = 0.01
I0616 00:32:33.779125 29366 solver.cpp:218] Iteration 32350 (0.865476 iter/s, 57.7717s/50 iters), loss = 0.00574907
I0616 00:32:33.779260 29366 solver.cpp:237]     Train net output #0: loss = 0.00574923 (* 1 = 0.00574923 loss)
I0616 00:32:33.779289 29366 sgd_solver.cpp:105] Iteration 32350, lr = 0.01
I0616 00:33:31.555094 29366 solver.cpp:218] Iteration 32400 (0.865421 iter/s, 57.7754s/50 iters), loss = 0.0321323
I0616 00:33:31.555214 29366 solver.cpp:237]     Train net output #0: loss = 0.0321324 (* 1 = 0.0321324 loss)
I0616 00:33:31.555238 29366 sgd_solver.cpp:105] Iteration 32400, lr = 0.01
I0616 00:34:29.319077 29366 solver.cpp:218] Iteration 32450 (0.8656 iter/s, 57.7634s/50 iters), loss = 0.0059038
I0616 00:34:29.319190 29366 solver.cpp:237]     Train net output #0: loss = 0.00590396 (* 1 = 0.00590396 loss)
I0616 00:34:29.319213 29366 sgd_solver.cpp:105] Iteration 32450, lr = 0.01
I0616 00:35:27.102602 29366 solver.cpp:218] Iteration 32500 (0.865307 iter/s, 57.7829s/50 iters), loss = 0.00901563
I0616 00:35:27.102731 29366 solver.cpp:237]     Train net output #0: loss = 0.00901579 (* 1 = 0.00901579 loss)
I0616 00:35:27.102753 29366 sgd_solver.cpp:105] Iteration 32500, lr = 0.01
I0616 00:36:24.869451 29366 solver.cpp:218] Iteration 32550 (0.865557 iter/s, 57.7663s/50 iters), loss = 0.0108684
I0616 00:36:24.869640 29366 solver.cpp:237]     Train net output #0: loss = 0.0108686 (* 1 = 0.0108686 loss)
I0616 00:36:24.869664 29366 sgd_solver.cpp:105] Iteration 32550, lr = 0.01
I0616 00:37:22.634335 29366 solver.cpp:218] Iteration 32600 (0.865588 iter/s, 57.7642s/50 iters), loss = 0.00510989
I0616 00:37:22.634454 29366 solver.cpp:237]     Train net output #0: loss = 0.00511005 (* 1 = 0.00511005 loss)
I0616 00:37:22.634476 29366 sgd_solver.cpp:105] Iteration 32600, lr = 0.01
I0616 00:38:20.410424 29366 solver.cpp:218] Iteration 32650 (0.865419 iter/s, 57.7755s/50 iters), loss = 0.00403979
I0616 00:38:20.410567 29366 solver.cpp:237]     Train net output #0: loss = 0.00403996 (* 1 = 0.00403996 loss)
I0616 00:38:20.410591 29366 sgd_solver.cpp:105] Iteration 32650, lr = 0.01
I0616 00:39:18.181419 29366 solver.cpp:218] Iteration 32700 (0.865495 iter/s, 57.7704s/50 iters), loss = 0.00494825
I0616 00:39:18.181592 29366 solver.cpp:237]     Train net output #0: loss = 0.00494841 (* 1 = 0.00494841 loss)
I0616 00:39:18.181617 29366 sgd_solver.cpp:105] Iteration 32700, lr = 0.01
I0616 00:40:15.961163 29366 solver.cpp:218] Iteration 32750 (0.865365 iter/s, 57.7791s/50 iters), loss = 0.00669392
I0616 00:40:15.961287 29366 solver.cpp:237]     Train net output #0: loss = 0.00669408 (* 1 = 0.00669408 loss)
I0616 00:40:15.961310 29366 sgd_solver.cpp:105] Iteration 32750, lr = 0.01
I0616 00:41:13.734104 29366 solver.cpp:218] Iteration 32800 (0.865466 iter/s, 57.7723s/50 iters), loss = 0.00433702
I0616 00:41:13.734889 29366 solver.cpp:237]     Train net output #0: loss = 0.00433718 (* 1 = 0.00433718 loss)
I0616 00:41:13.734913 29366 sgd_solver.cpp:105] Iteration 32800, lr = 0.01
I0616 00:42:11.510948 29366 solver.cpp:218] Iteration 32850 (0.865417 iter/s, 57.7756s/50 iters), loss = 0.0038364
I0616 00:42:11.511086 29366 solver.cpp:237]     Train net output #0: loss = 0.00383656 (* 1 = 0.00383656 loss)
I0616 00:42:11.511109 29366 sgd_solver.cpp:105] Iteration 32850, lr = 0.01
I0616 00:43:09.280622 29366 solver.cpp:218] Iteration 32900 (0.865515 iter/s, 57.7691s/50 iters), loss = 0.00783374
I0616 00:43:09.280755 29366 solver.cpp:237]     Train net output #0: loss = 0.0078339 (* 1 = 0.0078339 loss)
I0616 00:43:09.280783 29366 sgd_solver.cpp:105] Iteration 32900, lr = 0.01
I0616 00:44:07.052269 29366 solver.cpp:218] Iteration 32950 (0.865485 iter/s, 57.771s/50 iters), loss = 0.00636476
I0616 00:44:07.052392 29366 solver.cpp:237]     Train net output #0: loss = 0.00636492 (* 1 = 0.00636492 loss)
I0616 00:44:07.052414 29366 sgd_solver.cpp:105] Iteration 32950, lr = 0.01
I0616 00:45:04.828992 29366 solver.cpp:218] Iteration 33000 (0.865409 iter/s, 57.7761s/50 iters), loss = 0.00541484
I0616 00:45:04.829131 29366 solver.cpp:237]     Train net output #0: loss = 0.005415 (* 1 = 0.005415 loss)
I0616 00:45:04.829155 29366 sgd_solver.cpp:105] Iteration 33000, lr = 0.01
I0616 00:46:02.599592 29366 solver.cpp:218] Iteration 33050 (0.865501 iter/s, 57.77s/50 iters), loss = 0.00599797
I0616 00:46:02.599722 29366 solver.cpp:237]     Train net output #0: loss = 0.00599813 (* 1 = 0.00599813 loss)
I0616 00:46:02.599745 29366 sgd_solver.cpp:105] Iteration 33050, lr = 0.01
I0616 00:47:00.365175 29366 solver.cpp:218] Iteration 33100 (0.865576 iter/s, 57.765s/50 iters), loss = 0.00501734
I0616 00:47:00.365317 29366 solver.cpp:237]     Train net output #0: loss = 0.0050175 (* 1 = 0.0050175 loss)
I0616 00:47:00.365341 29366 sgd_solver.cpp:105] Iteration 33100, lr = 0.01
I0616 00:47:58.137444 29366 solver.cpp:218] Iteration 33150 (0.865476 iter/s, 57.7716s/50 iters), loss = 0.00617899
I0616 00:47:58.137574 29366 solver.cpp:237]     Train net output #0: loss = 0.00617915 (* 1 = 0.00617915 loss)
I0616 00:47:58.137598 29366 sgd_solver.cpp:105] Iteration 33150, lr = 0.01
I0616 00:48:55.902937 29366 solver.cpp:218] Iteration 33200 (0.865578 iter/s, 57.7649s/50 iters), loss = 0.00766911
I0616 00:48:55.903065 29366 solver.cpp:237]     Train net output #0: loss = 0.00766927 (* 1 = 0.00766927 loss)
I0616 00:48:55.903086 29366 sgd_solver.cpp:105] Iteration 33200, lr = 0.01
I0616 00:49:53.666887 29366 solver.cpp:218] Iteration 33250 (0.865601 iter/s, 57.7633s/50 iters), loss = 0.0089765
I0616 00:49:53.667011 29366 solver.cpp:237]     Train net output #0: loss = 0.00897666 (* 1 = 0.00897666 loss)
I0616 00:49:53.667034 29366 sgd_solver.cpp:105] Iteration 33250, lr = 0.01
I0616 00:50:51.427242 29366 solver.cpp:218] Iteration 33300 (0.865655 iter/s, 57.7598s/50 iters), loss = 0.0077414
I0616 00:50:51.427361 29366 solver.cpp:237]     Train net output #0: loss = 0.00774156 (* 1 = 0.00774156 loss)
I0616 00:50:51.427384 29366 sgd_solver.cpp:105] Iteration 33300, lr = 0.01
I0616 00:51:49.198531 29366 solver.cpp:218] Iteration 33350 (0.865491 iter/s, 57.7707s/50 iters), loss = 0.00555594
I0616 00:51:49.198850 29366 solver.cpp:237]     Train net output #0: loss = 0.00555609 (* 1 = 0.00555609 loss)
I0616 00:51:49.198874 29366 sgd_solver.cpp:105] Iteration 33350, lr = 0.01
I0616 00:52:46.968369 29366 solver.cpp:218] Iteration 33400 (0.865516 iter/s, 57.769s/50 iters), loss = 0.0168538
I0616 00:52:46.968595 29366 solver.cpp:237]     Train net output #0: loss = 0.0168539 (* 1 = 0.0168539 loss)
I0616 00:52:46.968621 29366 sgd_solver.cpp:105] Iteration 33400, lr = 0.01
I0616 00:53:44.736318 29366 solver.cpp:218] Iteration 33450 (0.865543 iter/s, 57.7672s/50 iters), loss = 0.00446095
I0616 00:53:44.736593 29366 solver.cpp:237]     Train net output #0: loss = 0.0044611 (* 1 = 0.0044611 loss)
I0616 00:53:44.736619 29366 sgd_solver.cpp:105] Iteration 33450, lr = 0.01
I0616 00:54:42.501574 29366 solver.cpp:218] Iteration 33500 (0.865583 iter/s, 57.7645s/50 iters), loss = 0.00780121
I0616 00:54:42.501715 29366 solver.cpp:237]     Train net output #0: loss = 0.00780137 (* 1 = 0.00780137 loss)
I0616 00:54:42.501739 29366 sgd_solver.cpp:105] Iteration 33500, lr = 0.01
I0616 00:55:40.280191 29366 solver.cpp:218] Iteration 33550 (0.865381 iter/s, 57.778s/50 iters), loss = 0.0070166
I0616 00:55:40.280305 29366 solver.cpp:237]     Train net output #0: loss = 0.00701676 (* 1 = 0.00701676 loss)
I0616 00:55:40.280328 29366 sgd_solver.cpp:105] Iteration 33550, lr = 0.01
I0616 00:56:38.051940 29366 solver.cpp:218] Iteration 33600 (0.865484 iter/s, 57.7712s/50 iters), loss = 0.00946589
I0616 00:56:38.052052 29366 solver.cpp:237]     Train net output #0: loss = 0.00946605 (* 1 = 0.00946605 loss)
I0616 00:56:38.052074 29366 sgd_solver.cpp:105] Iteration 33600, lr = 0.01
I0616 00:57:35.821058 29366 solver.cpp:218] Iteration 33650 (0.865523 iter/s, 57.7685s/50 iters), loss = 0.00505211
I0616 00:57:35.821197 29366 solver.cpp:237]     Train net output #0: loss = 0.00505226 (* 1 = 0.00505226 loss)
I0616 00:57:35.821219 29366 sgd_solver.cpp:105] Iteration 33650, lr = 0.01
I0616 00:58:33.590263 29366 solver.cpp:218] Iteration 33700 (0.865523 iter/s, 57.7686s/50 iters), loss = 0.00662631
I0616 00:58:33.590404 29366 solver.cpp:237]     Train net output #0: loss = 0.00662646 (* 1 = 0.00662646 loss)
I0616 00:58:33.590432 29366 sgd_solver.cpp:105] Iteration 33700, lr = 0.01
I0616 00:59:31.361851 29366 solver.cpp:218] Iteration 33750 (0.865487 iter/s, 57.7709s/50 iters), loss = 0.00657126
I0616 00:59:31.361989 29366 solver.cpp:237]     Train net output #0: loss = 0.00657141 (* 1 = 0.00657141 loss)
I0616 00:59:31.362011 29366 sgd_solver.cpp:105] Iteration 33750, lr = 0.01
I0616 01:00:29.143008 29366 solver.cpp:218] Iteration 33800 (0.865344 iter/s, 57.7805s/50 iters), loss = 0.00555458
I0616 01:00:29.143131 29366 solver.cpp:237]     Train net output #0: loss = 0.00555473 (* 1 = 0.00555473 loss)
I0616 01:00:29.143158 29366 sgd_solver.cpp:105] Iteration 33800, lr = 0.01
I0616 01:01:26.907941 29366 solver.cpp:218] Iteration 33850 (0.865587 iter/s, 57.7643s/50 iters), loss = 0.00648948
I0616 01:01:26.908068 29366 solver.cpp:237]     Train net output #0: loss = 0.00648964 (* 1 = 0.00648964 loss)
I0616 01:01:26.908092 29366 sgd_solver.cpp:105] Iteration 33850, lr = 0.01
I0616 01:02:24.671896 29366 solver.cpp:218] Iteration 33900 (0.865602 iter/s, 57.7633s/50 iters), loss = 0.00754238
I0616 01:02:24.672015 29366 solver.cpp:237]     Train net output #0: loss = 0.00754254 (* 1 = 0.00754254 loss)
I0616 01:02:24.672039 29366 sgd_solver.cpp:105] Iteration 33900, lr = 0.01
I0616 01:03:22.449124 29366 solver.cpp:218] Iteration 33950 (0.865403 iter/s, 57.7766s/50 iters), loss = 0.0115086
I0616 01:03:22.449249 29366 solver.cpp:237]     Train net output #0: loss = 0.0115088 (* 1 = 0.0115088 loss)
I0616 01:03:22.449272 29366 sgd_solver.cpp:105] Iteration 33950, lr = 0.01
I0616 01:04:20.223963 29366 solver.cpp:218] Iteration 34000 (0.865439 iter/s, 57.7742s/50 iters), loss = 0.00446078
I0616 01:04:20.224089 29366 solver.cpp:237]     Train net output #0: loss = 0.00446094 (* 1 = 0.00446094 loss)
I0616 01:04:20.224113 29366 sgd_solver.cpp:105] Iteration 34000, lr = 0.01
I0616 01:05:17.983933 29366 solver.cpp:218] Iteration 34050 (0.865661 iter/s, 57.7593s/50 iters), loss = 0.0102654
I0616 01:05:17.984138 29366 solver.cpp:237]     Train net output #0: loss = 0.0102656 (* 1 = 0.0102656 loss)
I0616 01:05:17.984175 29366 sgd_solver.cpp:105] Iteration 34050, lr = 0.01
I0616 01:06:15.758229 29366 solver.cpp:218] Iteration 34100 (0.865448 iter/s, 57.7736s/50 iters), loss = 0.00506956
I0616 01:06:15.758383 29366 solver.cpp:237]     Train net output #0: loss = 0.00506972 (* 1 = 0.00506972 loss)
I0616 01:06:15.758406 29366 sgd_solver.cpp:105] Iteration 34100, lr = 0.01
I0616 01:07:13.531154 29366 solver.cpp:218] Iteration 34150 (0.865467 iter/s, 57.7722s/50 iters), loss = 0.00351192
I0616 01:07:13.531289 29366 solver.cpp:237]     Train net output #0: loss = 0.00351208 (* 1 = 0.00351208 loss)
I0616 01:07:13.531312 29366 sgd_solver.cpp:105] Iteration 34150, lr = 0.01
I0616 01:08:11.300463 29366 solver.cpp:218] Iteration 34200 (0.865521 iter/s, 57.7686s/50 iters), loss = 0.00447768
I0616 01:08:11.300597 29366 solver.cpp:237]     Train net output #0: loss = 0.00447784 (* 1 = 0.00447784 loss)
I0616 01:08:11.300621 29366 sgd_solver.cpp:105] Iteration 34200, lr = 0.01
I0616 01:09:09.063854 29366 solver.cpp:218] Iteration 34250 (0.86561 iter/s, 57.7627s/50 iters), loss = 0.00511311
I0616 01:09:09.064019 29366 solver.cpp:237]     Train net output #0: loss = 0.00511327 (* 1 = 0.00511327 loss)
I0616 01:09:09.064043 29366 sgd_solver.cpp:105] Iteration 34250, lr = 0.01
I0616 01:10:06.834003 29366 solver.cpp:218] Iteration 34300 (0.865509 iter/s, 57.7694s/50 iters), loss = 0.00500769
I0616 01:10:06.834154 29366 solver.cpp:237]     Train net output #0: loss = 0.00500785 (* 1 = 0.00500785 loss)
I0616 01:10:06.834178 29366 sgd_solver.cpp:105] Iteration 34300, lr = 0.01
I0616 01:11:04.595608 29366 solver.cpp:218] Iteration 34350 (0.865637 iter/s, 57.7609s/50 iters), loss = 0.00454904
I0616 01:11:04.595737 29366 solver.cpp:237]     Train net output #0: loss = 0.0045492 (* 1 = 0.0045492 loss)
I0616 01:11:04.595759 29366 sgd_solver.cpp:105] Iteration 34350, lr = 0.01
I0616 01:12:02.363206 29366 solver.cpp:218] Iteration 34400 (0.865547 iter/s, 57.7669s/50 iters), loss = 0.00503658
I0616 01:12:02.363349 29366 solver.cpp:237]     Train net output #0: loss = 0.00503674 (* 1 = 0.00503674 loss)
I0616 01:12:02.363373 29366 sgd_solver.cpp:105] Iteration 34400, lr = 0.01
I0616 01:13:00.136793 29366 solver.cpp:218] Iteration 34450 (0.865458 iter/s, 57.7729s/50 iters), loss = 0.0126026
I0616 01:13:00.136970 29366 solver.cpp:237]     Train net output #0: loss = 0.0126028 (* 1 = 0.0126028 loss)
I0616 01:13:00.136993 29366 sgd_solver.cpp:105] Iteration 34450, lr = 0.01
I0616 01:13:57.908413 29366 solver.cpp:218] Iteration 34500 (0.865488 iter/s, 57.7709s/50 iters), loss = 0.00628166
I0616 01:13:57.908551 29366 solver.cpp:237]     Train net output #0: loss = 0.00628182 (* 1 = 0.00628182 loss)
I0616 01:13:57.908577 29366 sgd_solver.cpp:105] Iteration 34500, lr = 0.01
I0616 01:14:55.676033 29366 solver.cpp:218] Iteration 34550 (0.865547 iter/s, 57.7669s/50 iters), loss = 0.00522885
I0616 01:14:55.676165 29366 solver.cpp:237]     Train net output #0: loss = 0.005229 (* 1 = 0.005229 loss)
I0616 01:14:55.676189 29366 sgd_solver.cpp:105] Iteration 34550, lr = 0.01
I0616 01:15:53.458890 29366 solver.cpp:218] Iteration 34600 (0.865318 iter/s, 57.7822s/50 iters), loss = 0.0052217
I0616 01:15:53.459028 29366 solver.cpp:237]     Train net output #0: loss = 0.00522186 (* 1 = 0.00522186 loss)
I0616 01:15:53.459050 29366 sgd_solver.cpp:105] Iteration 34600, lr = 0.01
I0616 01:16:51.235393 29366 solver.cpp:218] Iteration 34650 (0.865414 iter/s, 57.7758s/50 iters), loss = 0.00459033
I0616 01:16:51.235523 29366 solver.cpp:237]     Train net output #0: loss = 0.00459049 (* 1 = 0.00459049 loss)
I0616 01:16:51.235549 29366 sgd_solver.cpp:105] Iteration 34650, lr = 0.01
I0616 01:17:48.988600 29366 solver.cpp:218] Iteration 34700 (0.865763 iter/s, 57.7525s/50 iters), loss = 0.00490863
I0616 01:17:48.988744 29366 solver.cpp:237]     Train net output #0: loss = 0.00490879 (* 1 = 0.00490879 loss)
I0616 01:17:48.988766 29366 sgd_solver.cpp:105] Iteration 34700, lr = 0.01
I0616 01:18:46.762735 29366 solver.cpp:218] Iteration 34750 (0.865449 iter/s, 57.7735s/50 iters), loss = 0.00657364
I0616 01:18:46.762971 29366 solver.cpp:237]     Train net output #0: loss = 0.0065738 (* 1 = 0.0065738 loss)
I0616 01:18:46.762996 29366 sgd_solver.cpp:105] Iteration 34750, lr = 0.01
I0616 01:19:44.535707 29366 solver.cpp:218] Iteration 34800 (0.865468 iter/s, 57.7722s/50 iters), loss = 0.00758287
I0616 01:19:44.535840 29366 solver.cpp:237]     Train net output #0: loss = 0.00758303 (* 1 = 0.00758303 loss)
I0616 01:19:44.535863 29366 sgd_solver.cpp:105] Iteration 34800, lr = 0.01
I0616 01:20:42.311553 29366 solver.cpp:218] Iteration 34850 (0.865423 iter/s, 57.7752s/50 iters), loss = 0.00520731
I0616 01:20:42.311660 29366 solver.cpp:237]     Train net output #0: loss = 0.00520747 (* 1 = 0.00520747 loss)
I0616 01:20:42.311681 29366 sgd_solver.cpp:105] Iteration 34850, lr = 0.01
I0616 01:21:40.078552 29366 solver.cpp:218] Iteration 34900 (0.865556 iter/s, 57.7664s/50 iters), loss = 0.007286
I0616 01:21:40.078661 29366 solver.cpp:237]     Train net output #0: loss = 0.00728616 (* 1 = 0.00728616 loss)
I0616 01:21:40.078685 29366 sgd_solver.cpp:105] Iteration 34900, lr = 0.01
I0616 01:22:37.844295 29366 solver.cpp:218] Iteration 34950 (0.865575 iter/s, 57.7651s/50 iters), loss = 0.00434635
I0616 01:22:37.844420 29366 solver.cpp:237]     Train net output #0: loss = 0.00434651 (* 1 = 0.00434651 loss)
I0616 01:22:37.844449 29366 sgd_solver.cpp:105] Iteration 34950, lr = 0.01
I0616 01:23:35.616292 29366 solver.cpp:218] Iteration 35000 (0.865481 iter/s, 57.7713s/50 iters), loss = 0.00524822
I0616 01:23:35.616470 29366 solver.cpp:237]     Train net output #0: loss = 0.00524838 (* 1 = 0.00524838 loss)
I0616 01:23:35.616494 29366 sgd_solver.cpp:105] Iteration 35000, lr = 0.01
I0616 01:24:33.386853 29366 solver.cpp:218] Iteration 35050 (0.865503 iter/s, 57.7698s/50 iters), loss = 0.00386096
I0616 01:24:33.386988 29366 solver.cpp:237]     Train net output #0: loss = 0.00386112 (* 1 = 0.00386112 loss)
I0616 01:24:33.387011 29366 sgd_solver.cpp:105] Iteration 35050, lr = 0.01
I0616 01:25:31.172579 29366 solver.cpp:218] Iteration 35100 (0.865276 iter/s, 57.7851s/50 iters), loss = 0.00492595
I0616 01:25:31.172698 29366 solver.cpp:237]     Train net output #0: loss = 0.00492611 (* 1 = 0.00492611 loss)
I0616 01:25:31.172721 29366 sgd_solver.cpp:105] Iteration 35100, lr = 0.01
I0616 01:26:28.941563 29366 solver.cpp:218] Iteration 35150 (0.865526 iter/s, 57.7683s/50 iters), loss = 0.00600767
I0616 01:26:28.941691 29366 solver.cpp:237]     Train net output #0: loss = 0.00600783 (* 1 = 0.00600783 loss)
I0616 01:26:28.941715 29366 sgd_solver.cpp:105] Iteration 35150, lr = 0.01
I0616 01:27:26.706512 29366 solver.cpp:218] Iteration 35200 (0.865587 iter/s, 57.7643s/50 iters), loss = 0.00557384
I0616 01:27:26.706660 29366 solver.cpp:237]     Train net output #0: loss = 0.005574 (* 1 = 0.005574 loss)
I0616 01:27:26.706684 29366 sgd_solver.cpp:105] Iteration 35200, lr = 0.01
I0616 01:28:24.484447 29366 solver.cpp:218] Iteration 35250 (0.865392 iter/s, 57.7773s/50 iters), loss = 0.00381491
I0616 01:28:24.484936 29366 solver.cpp:237]     Train net output #0: loss = 0.00381507 (* 1 = 0.00381507 loss)
I0616 01:28:24.484959 29366 sgd_solver.cpp:105] Iteration 35250, lr = 0.01
I0616 01:29:22.241367 29366 solver.cpp:218] Iteration 35300 (0.865713 iter/s, 57.7559s/50 iters), loss = 0.00370577
I0616 01:29:22.241503 29366 solver.cpp:237]     Train net output #0: loss = 0.00370593 (* 1 = 0.00370593 loss)
I0616 01:29:22.241539 29366 sgd_solver.cpp:105] Iteration 35300, lr = 0.01
I0616 01:30:20.018692 29366 solver.cpp:218] Iteration 35350 (0.865401 iter/s, 57.7767s/50 iters), loss = 0.00396437
I0616 01:30:20.019345 29366 solver.cpp:237]     Train net output #0: loss = 0.00396453 (* 1 = 0.00396453 loss)
I0616 01:30:20.019369 29366 sgd_solver.cpp:105] Iteration 35350, lr = 0.01
I0616 01:31:17.783859 29366 solver.cpp:218] Iteration 35400 (0.865591 iter/s, 57.764s/50 iters), loss = 0.00421383
I0616 01:31:17.784072 29366 solver.cpp:237]     Train net output #0: loss = 0.00421399 (* 1 = 0.00421399 loss)
I0616 01:31:17.784096 29366 sgd_solver.cpp:105] Iteration 35400, lr = 0.01
I0616 01:32:15.544648 29366 solver.cpp:218] Iteration 35450 (0.86565 iter/s, 57.76s/50 iters), loss = 0.00644131
I0616 01:32:15.544781 29366 solver.cpp:237]     Train net output #0: loss = 0.00644147 (* 1 = 0.00644147 loss)
I0616 01:32:15.544805 29366 sgd_solver.cpp:105] Iteration 35450, lr = 0.01
I0616 01:33:13.313961 29366 solver.cpp:218] Iteration 35500 (0.865522 iter/s, 57.7686s/50 iters), loss = 0.00513733
I0616 01:33:13.314110 29366 solver.cpp:237]     Train net output #0: loss = 0.00513749 (* 1 = 0.00513749 loss)
I0616 01:33:13.314132 29366 sgd_solver.cpp:105] Iteration 35500, lr = 0.01
I0616 01:34:11.076903 29366 solver.cpp:218] Iteration 35550 (0.865618 iter/s, 57.7622s/50 iters), loss = 0.00692675
I0616 01:34:11.077025 29366 solver.cpp:237]     Train net output #0: loss = 0.00692691 (* 1 = 0.00692691 loss)
I0616 01:34:11.077049 29366 sgd_solver.cpp:105] Iteration 35550, lr = 0.01
I0616 01:35:08.846293 29366 solver.cpp:218] Iteration 35600 (0.865521 iter/s, 57.7687s/50 iters), loss = 0.00600588
I0616 01:35:08.846441 29366 solver.cpp:237]     Train net output #0: loss = 0.00600603 (* 1 = 0.00600603 loss)
I0616 01:35:08.846464 29366 sgd_solver.cpp:105] Iteration 35600, lr = 0.01
I0616 01:36:06.628021 29366 solver.cpp:218] Iteration 35650 (0.865337 iter/s, 57.781s/50 iters), loss = 0.00425696
I0616 01:36:06.628134 29366 solver.cpp:237]     Train net output #0: loss = 0.00425712 (* 1 = 0.00425712 loss)
I0616 01:36:06.628155 29366 sgd_solver.cpp:105] Iteration 35650, lr = 0.01
I0616 01:37:04.404659 29366 solver.cpp:218] Iteration 35700 (0.865413 iter/s, 57.7759s/50 iters), loss = 0.00536894
I0616 01:37:04.404788 29366 solver.cpp:237]     Train net output #0: loss = 0.0053691 (* 1 = 0.0053691 loss)
I0616 01:37:04.404811 29366 sgd_solver.cpp:105] Iteration 35700, lr = 0.01
I0616 01:38:02.170588 29366 solver.cpp:218] Iteration 35750 (0.865573 iter/s, 57.7652s/50 iters), loss = 0.0068779
I0616 01:38:02.170703 29366 solver.cpp:237]     Train net output #0: loss = 0.00687805 (* 1 = 0.00687805 loss)
I0616 01:38:02.170727 29366 sgd_solver.cpp:105] Iteration 35750, lr = 0.01
I0616 01:38:59.935662 29366 solver.cpp:218] Iteration 35800 (0.865586 iter/s, 57.7643s/50 iters), loss = 0.00544656
I0616 01:38:59.935792 29366 solver.cpp:237]     Train net output #0: loss = 0.00544672 (* 1 = 0.00544672 loss)
I0616 01:38:59.935817 29366 sgd_solver.cpp:105] Iteration 35800, lr = 0.01
I0616 01:39:57.714790 29366 solver.cpp:218] Iteration 35850 (0.865376 iter/s, 57.7784s/50 iters), loss = 0.00590153
I0616 01:39:57.714938 29366 solver.cpp:237]     Train net output #0: loss = 0.00590169 (* 1 = 0.00590169 loss)
I0616 01:39:57.714960 29366 sgd_solver.cpp:105] Iteration 35850, lr = 0.01
I0616 01:40:55.487681 29366 solver.cpp:218] Iteration 35900 (0.865469 iter/s, 57.7721s/50 iters), loss = 0.0064048
I0616 01:40:55.487803 29366 solver.cpp:237]     Train net output #0: loss = 0.00640496 (* 1 = 0.00640496 loss)
I0616 01:40:55.487828 29366 sgd_solver.cpp:105] Iteration 35900, lr = 0.01
I0616 01:41:53.250402 29366 solver.cpp:218] Iteration 35950 (0.865621 iter/s, 57.762s/50 iters), loss = 0.00472977
I0616 01:41:53.250535 29366 solver.cpp:237]     Train net output #0: loss = 0.00472993 (* 1 = 0.00472993 loss)
I0616 01:41:53.250561 29366 sgd_solver.cpp:105] Iteration 35950, lr = 0.01
I0616 01:42:51.023643 29366 solver.cpp:218] Iteration 36000 (0.865464 iter/s, 57.7725s/50 iters), loss = 0.00781852
I0616 01:42:51.023779 29366 solver.cpp:237]     Train net output #0: loss = 0.00781868 (* 1 = 0.00781868 loss)
I0616 01:42:51.023802 29366 sgd_solver.cpp:105] Iteration 36000, lr = 0.01
I0616 01:43:48.798501 29366 solver.cpp:218] Iteration 36050 (0.86544 iter/s, 57.7741s/50 iters), loss = 0.00803129
I0616 01:43:48.798629 29366 solver.cpp:237]     Train net output #0: loss = 0.00803145 (* 1 = 0.00803145 loss)
I0616 01:43:48.798653 29366 sgd_solver.cpp:105] Iteration 36050, lr = 0.01
I0616 01:44:46.568572 29366 solver.cpp:218] Iteration 36100 (0.865511 iter/s, 57.7693s/50 iters), loss = 0.0117289
I0616 01:44:46.568737 29366 solver.cpp:237]     Train net output #0: loss = 0.0117291 (* 1 = 0.0117291 loss)
I0616 01:44:46.568768 29366 sgd_solver.cpp:105] Iteration 36100, lr = 0.01
I0616 01:45:44.334269 29366 solver.cpp:218] Iteration 36150 (0.865577 iter/s, 57.7649s/50 iters), loss = 0.00583313
I0616 01:45:44.334403 29366 solver.cpp:237]     Train net output #0: loss = 0.00583329 (* 1 = 0.00583329 loss)
I0616 01:45:44.334427 29366 sgd_solver.cpp:105] Iteration 36150, lr = 0.01
I0616 01:46:42.098759 29366 solver.cpp:218] Iteration 36200 (0.865595 iter/s, 57.7637s/50 iters), loss = 0.00469005
I0616 01:46:42.098891 29366 solver.cpp:237]     Train net output #0: loss = 0.00469021 (* 1 = 0.00469021 loss)
I0616 01:46:42.098913 29366 sgd_solver.cpp:105] Iteration 36200, lr = 0.01
I0616 01:47:39.874505 29366 solver.cpp:218] Iteration 36250 (0.865426 iter/s, 57.775s/50 iters), loss = 0.00346816
I0616 01:47:39.874656 29366 solver.cpp:237]     Train net output #0: loss = 0.00346831 (* 1 = 0.00346831 loss)
I0616 01:47:39.874680 29366 sgd_solver.cpp:105] Iteration 36250, lr = 0.01
I0616 01:48:37.641436 29366 solver.cpp:218] Iteration 36300 (0.865558 iter/s, 57.7662s/50 iters), loss = 0.00746754
I0616 01:48:37.641574 29366 solver.cpp:237]     Train net output #0: loss = 0.0074677 (* 1 = 0.0074677 loss)
I0616 01:48:37.641598 29366 sgd_solver.cpp:105] Iteration 36300, lr = 0.01
I0616 01:49:35.406533 29366 solver.cpp:218] Iteration 36350 (0.865586 iter/s, 57.7643s/50 iters), loss = 0.00627661
I0616 01:49:35.406663 29366 solver.cpp:237]     Train net output #0: loss = 0.00627677 (* 1 = 0.00627677 loss)
I0616 01:49:35.406685 29366 sgd_solver.cpp:105] Iteration 36350, lr = 0.01
I0616 01:50:33.177306 29366 solver.cpp:218] Iteration 36400 (0.865501 iter/s, 57.77s/50 iters), loss = 0.00396386
I0616 01:50:33.177445 29366 solver.cpp:237]     Train net output #0: loss = 0.00396402 (* 1 = 0.00396402 loss)
I0616 01:50:33.177469 29366 sgd_solver.cpp:105] Iteration 36400, lr = 0.01
I0616 01:51:30.946054 29366 solver.cpp:218] Iteration 36450 (0.865531 iter/s, 57.768s/50 iters), loss = 0.00442936
I0616 01:51:30.946202 29366 solver.cpp:237]     Train net output #0: loss = 0.00442951 (* 1 = 0.00442951 loss)
I0616 01:51:30.946224 29366 sgd_solver.cpp:105] Iteration 36450, lr = 0.01
I0616 01:52:28.703140 29366 solver.cpp:218] Iteration 36500 (0.865706 iter/s, 57.7563s/50 iters), loss = 0.00502479
I0616 01:52:28.703295 29366 solver.cpp:237]     Train net output #0: loss = 0.00502494 (* 1 = 0.00502494 loss)
I0616 01:52:28.703325 29366 sgd_solver.cpp:105] Iteration 36500, lr = 0.01
I0616 01:53:26.479521 29366 solver.cpp:218] Iteration 36550 (0.865417 iter/s, 57.7756s/50 iters), loss = 0.00394617
I0616 01:53:26.479663 29366 solver.cpp:237]     Train net output #0: loss = 0.00394633 (* 1 = 0.00394633 loss)
I0616 01:53:26.479686 29366 sgd_solver.cpp:105] Iteration 36550, lr = 0.01
I0616 01:54:24.257915 29366 solver.cpp:218] Iteration 36600 (0.865386 iter/s, 57.7777s/50 iters), loss = 0.00592245
I0616 01:54:24.258075 29366 solver.cpp:237]     Train net output #0: loss = 0.00592261 (* 1 = 0.00592261 loss)
I0616 01:54:24.258100 29366 sgd_solver.cpp:105] Iteration 36600, lr = 0.01
I0616 01:55:22.030194 29366 solver.cpp:218] Iteration 36650 (0.865478 iter/s, 57.7715s/50 iters), loss = 0.00648218
I0616 01:55:22.030324 29366 solver.cpp:237]     Train net output #0: loss = 0.00648234 (* 1 = 0.00648234 loss)
I0616 01:55:22.030349 29366 sgd_solver.cpp:105] Iteration 36650, lr = 0.01
I0616 01:56:19.795601 29366 solver.cpp:218] Iteration 36700 (0.865581 iter/s, 57.7646s/50 iters), loss = 0.00673008
I0616 01:56:19.795750 29366 solver.cpp:237]     Train net output #0: loss = 0.00673024 (* 1 = 0.00673024 loss)
I0616 01:56:19.795780 29366 sgd_solver.cpp:105] Iteration 36700, lr = 0.01
I0616 01:57:17.564568 29366 solver.cpp:218] Iteration 36750 (0.865528 iter/s, 57.7682s/50 iters), loss = 0.00458475
I0616 01:57:17.564689 29366 solver.cpp:237]     Train net output #0: loss = 0.0045849 (* 1 = 0.0045849 loss)
I0616 01:57:17.564713 29366 sgd_solver.cpp:105] Iteration 36750, lr = 0.01
I0616 01:58:15.331413 29366 solver.cpp:218] Iteration 36800 (0.865559 iter/s, 57.7661s/50 iters), loss = 0.00583592
I0616 01:58:15.331578 29366 solver.cpp:237]     Train net output #0: loss = 0.00583608 (* 1 = 0.00583608 loss)
I0616 01:58:15.331601 29366 sgd_solver.cpp:105] Iteration 36800, lr = 0.01
I0616 01:59:13.093631 29366 solver.cpp:218] Iteration 36850 (0.865629 iter/s, 57.7615s/50 iters), loss = 0.00949651
I0616 01:59:13.093758 29366 solver.cpp:237]     Train net output #0: loss = 0.00949667 (* 1 = 0.00949667 loss)
I0616 01:59:13.093782 29366 sgd_solver.cpp:105] Iteration 36850, lr = 0.01
I0616 02:00:10.858033 29366 solver.cpp:218] Iteration 36900 (0.865596 iter/s, 57.7637s/50 iters), loss = 0.00501262
I0616 02:00:10.858230 29366 solver.cpp:237]     Train net output #0: loss = 0.00501278 (* 1 = 0.00501278 loss)
I0616 02:00:10.858254 29366 sgd_solver.cpp:105] Iteration 36900, lr = 0.01
I0616 02:01:08.623947 29366 solver.cpp:218] Iteration 36950 (0.865574 iter/s, 57.7651s/50 iters), loss = 0.00628774
I0616 02:01:08.624071 29366 solver.cpp:237]     Train net output #0: loss = 0.0062879 (* 1 = 0.0062879 loss)
I0616 02:01:08.624095 29366 sgd_solver.cpp:105] Iteration 36950, lr = 0.01
I0616 02:02:06.396661 29366 solver.cpp:218] Iteration 37000 (0.865471 iter/s, 57.772s/50 iters), loss = 0.00577363
I0616 02:02:06.396788 29366 solver.cpp:237]     Train net output #0: loss = 0.00577379 (* 1 = 0.00577379 loss)
I0616 02:02:06.396813 29366 sgd_solver.cpp:105] Iteration 37000, lr = 0.01
I0616 02:03:04.162796 29366 solver.cpp:218] Iteration 37050 (0.86557 iter/s, 57.7654s/50 iters), loss = 0.00603527
I0616 02:03:04.162905 29366 solver.cpp:237]     Train net output #0: loss = 0.00603543 (* 1 = 0.00603543 loss)
I0616 02:03:04.162927 29366 sgd_solver.cpp:105] Iteration 37050, lr = 0.01
I0616 02:04:01.938544 29366 solver.cpp:218] Iteration 37100 (0.865426 iter/s, 57.775s/50 iters), loss = 0.00592311
I0616 02:04:01.938668 29366 solver.cpp:237]     Train net output #0: loss = 0.00592327 (* 1 = 0.00592327 loss)
I0616 02:04:01.938691 29366 sgd_solver.cpp:105] Iteration 37100, lr = 0.01
I0616 02:04:59.709534 29366 solver.cpp:218] Iteration 37150 (0.865497 iter/s, 57.7703s/50 iters), loss = 0.00448643
I0616 02:04:59.709739 29366 solver.cpp:237]     Train net output #0: loss = 0.00448659 (* 1 = 0.00448659 loss)
I0616 02:04:59.709763 29366 sgd_solver.cpp:105] Iteration 37150, lr = 0.01
I0616 02:05:57.483659 29366 solver.cpp:218] Iteration 37200 (0.865451 iter/s, 57.7733s/50 iters), loss = 0.00480976
I0616 02:05:57.483772 29366 solver.cpp:237]     Train net output #0: loss = 0.00480992 (* 1 = 0.00480992 loss)
I0616 02:05:57.483794 29366 sgd_solver.cpp:105] Iteration 37200, lr = 0.01
I0616 02:06:55.245682 29366 solver.cpp:218] Iteration 37250 (0.865631 iter/s, 57.7613s/50 iters), loss = 0.00759699
I0616 02:06:55.245806 29366 solver.cpp:237]     Train net output #0: loss = 0.00759715 (* 1 = 0.00759715 loss)
I0616 02:06:55.245829 29366 sgd_solver.cpp:105] Iteration 37250, lr = 0.01
I0616 02:07:53.012461 29366 solver.cpp:218] Iteration 37300 (0.86556 iter/s, 57.766s/50 iters), loss = 0.0147607
I0616 02:07:53.012599 29366 solver.cpp:237]     Train net output #0: loss = 0.0147609 (* 1 = 0.0147609 loss)
I0616 02:07:53.012622 29366 sgd_solver.cpp:105] Iteration 37300, lr = 0.01
I0616 02:08:50.789016 29366 solver.cpp:218] Iteration 37350 (0.865415 iter/s, 57.7758s/50 iters), loss = 0.00965819
I0616 02:08:50.789160 29366 solver.cpp:237]     Train net output #0: loss = 0.00965835 (* 1 = 0.00965835 loss)
I0616 02:08:50.789183 29366 sgd_solver.cpp:105] Iteration 37350, lr = 0.01
I0616 02:09:48.552711 29366 solver.cpp:218] Iteration 37400 (0.865607 iter/s, 57.7629s/50 iters), loss = 0.00395681
I0616 02:09:48.552836 29366 solver.cpp:237]     Train net output #0: loss = 0.00395696 (* 1 = 0.00395696 loss)
I0616 02:09:48.552858 29366 sgd_solver.cpp:105] Iteration 37400, lr = 0.01
I0616 02:10:46.324828 29366 solver.cpp:218] Iteration 37450 (0.86548 iter/s, 57.7714s/50 iters), loss = 0.0112725
I0616 02:10:46.325024 29366 solver.cpp:237]     Train net output #0: loss = 0.0112727 (* 1 = 0.0112727 loss)
I0616 02:10:46.325059 29366 sgd_solver.cpp:105] Iteration 37450, lr = 0.01
I0616 02:11:44.081825 29366 solver.cpp:218] Iteration 37500 (0.865708 iter/s, 57.7562s/50 iters), loss = 0.00941068
I0616 02:11:44.081961 29366 solver.cpp:237]     Train net output #0: loss = 0.00941084 (* 1 = 0.00941084 loss)
I0616 02:11:44.081984 29366 sgd_solver.cpp:105] Iteration 37500, lr = 0.01
I0616 02:12:41.853027 29366 solver.cpp:218] Iteration 37550 (0.865495 iter/s, 57.7704s/50 iters), loss = 0.0112013
I0616 02:12:41.853171 29366 solver.cpp:237]     Train net output #0: loss = 0.0112014 (* 1 = 0.0112014 loss)
I0616 02:12:41.853201 29366 sgd_solver.cpp:105] Iteration 37550, lr = 0.01
I0616 02:13:39.639209 29366 solver.cpp:218] Iteration 37600 (0.86527 iter/s, 57.7854s/50 iters), loss = 0.0072055
I0616 02:13:39.639328 29366 solver.cpp:237]     Train net output #0: loss = 0.00720566 (* 1 = 0.00720566 loss)
I0616 02:13:39.639350 29366 sgd_solver.cpp:105] Iteration 37600, lr = 0.01
I0616 02:14:37.427275 29366 solver.cpp:218] Iteration 37650 (0.865242 iter/s, 57.7873s/50 iters), loss = 0.00463695
I0616 02:14:37.427438 29366 solver.cpp:237]     Train net output #0: loss = 0.0046371 (* 1 = 0.0046371 loss)
I0616 02:14:37.427461 29366 sgd_solver.cpp:105] Iteration 37650, lr = 0.01
I0616 02:15:35.188352 29366 solver.cpp:218] Iteration 37700 (0.865646 iter/s, 57.7603s/50 iters), loss = 0.00660244
I0616 02:15:35.188483 29366 solver.cpp:237]     Train net output #0: loss = 0.0066026 (* 1 = 0.0066026 loss)
I0616 02:15:35.188506 29366 sgd_solver.cpp:105] Iteration 37700, lr = 0.01
I0616 02:16:32.957053 29366 solver.cpp:218] Iteration 37750 (0.865532 iter/s, 57.768s/50 iters), loss = 0.00843666
I0616 02:16:32.957193 29366 solver.cpp:237]     Train net output #0: loss = 0.00843681 (* 1 = 0.00843681 loss)
I0616 02:16:32.957216 29366 sgd_solver.cpp:105] Iteration 37750, lr = 0.01
I0616 02:17:30.717327 29366 solver.cpp:218] Iteration 37800 (0.865658 iter/s, 57.7595s/50 iters), loss = 0.00530776
I0616 02:17:30.717555 29366 solver.cpp:237]     Train net output #0: loss = 0.00530792 (* 1 = 0.00530792 loss)
I0616 02:17:30.717581 29366 sgd_solver.cpp:105] Iteration 37800, lr = 0.01
I0616 02:18:28.470324 29366 solver.cpp:218] Iteration 37850 (0.865768 iter/s, 57.7522s/50 iters), loss = 0.00515498
I0616 02:18:28.470454 29366 solver.cpp:237]     Train net output #0: loss = 0.00515514 (* 1 = 0.00515514 loss)
I0616 02:18:28.470476 29366 sgd_solver.cpp:105] Iteration 37850, lr = 0.01
I0616 02:19:26.227684 29366 solver.cpp:218] Iteration 37900 (0.865702 iter/s, 57.7566s/50 iters), loss = 0.0051594
I0616 02:19:26.227809 29366 solver.cpp:237]     Train net output #0: loss = 0.00515956 (* 1 = 0.00515956 loss)
I0616 02:19:26.227833 29366 sgd_solver.cpp:105] Iteration 37900, lr = 0.01
I0616 02:20:24.000638 29366 solver.cpp:218] Iteration 37950 (0.865468 iter/s, 57.7722s/50 iters), loss = 0.00955492
I0616 02:20:24.000787 29366 solver.cpp:237]     Train net output #0: loss = 0.00955508 (* 1 = 0.00955508 loss)
I0616 02:20:24.000809 29366 sgd_solver.cpp:105] Iteration 37950, lr = 0.01
I0616 02:21:21.772114 29366 solver.cpp:218] Iteration 38000 (0.865491 iter/s, 57.7707s/50 iters), loss = 0.00591387
I0616 02:21:21.772261 29366 solver.cpp:237]     Train net output #0: loss = 0.00591403 (* 1 = 0.00591403 loss)
I0616 02:21:21.772289 29366 sgd_solver.cpp:105] Iteration 38000, lr = 0.01
I0616 02:22:19.544203 29366 solver.cpp:218] Iteration 38050 (0.865481 iter/s, 57.7713s/50 iters), loss = 0.0046284
I0616 02:22:19.544328 29366 solver.cpp:237]     Train net output #0: loss = 0.00462855 (* 1 = 0.00462855 loss)
I0616 02:22:19.544353 29366 sgd_solver.cpp:105] Iteration 38050, lr = 0.01
I0616 02:23:17.327004 29366 solver.cpp:218] Iteration 38100 (0.86532 iter/s, 57.7821s/50 iters), loss = 0.00568656
I0616 02:23:17.327152 29366 solver.cpp:237]     Train net output #0: loss = 0.00568671 (* 1 = 0.00568671 loss)
I0616 02:23:17.327174 29366 sgd_solver.cpp:105] Iteration 38100, lr = 0.01
I0616 02:24:15.096271 29366 solver.cpp:218] Iteration 38150 (0.865523 iter/s, 57.7685s/50 iters), loss = 0.00579946
I0616 02:24:15.096436 29366 solver.cpp:237]     Train net output #0: loss = 0.00579961 (* 1 = 0.00579961 loss)
I0616 02:24:15.096459 29366 sgd_solver.cpp:105] Iteration 38150, lr = 0.01
I0616 02:25:12.852571 29366 solver.cpp:218] Iteration 38200 (0.865717 iter/s, 57.7556s/50 iters), loss = 0.00949496
I0616 02:25:12.852707 29366 solver.cpp:237]     Train net output #0: loss = 0.00949511 (* 1 = 0.00949511 loss)
I0616 02:25:12.852730 29366 sgd_solver.cpp:105] Iteration 38200, lr = 0.01
I0616 02:26:10.615639 29366 solver.cpp:218] Iteration 38250 (0.865616 iter/s, 57.7624s/50 iters), loss = 0.00720584
I0616 02:26:10.615767 29366 solver.cpp:237]     Train net output #0: loss = 0.007206 (* 1 = 0.007206 loss)
I0616 02:26:10.615789 29366 sgd_solver.cpp:105] Iteration 38250, lr = 0.01
I0616 02:27:08.389749 29366 solver.cpp:218] Iteration 38300 (0.86545 iter/s, 57.7734s/50 iters), loss = 0.0057449
I0616 02:27:08.389865 29366 solver.cpp:237]     Train net output #0: loss = 0.00574506 (* 1 = 0.00574506 loss)
I0616 02:27:08.389888 29366 sgd_solver.cpp:105] Iteration 38300, lr = 0.01
I0616 02:28:06.160449 29366 solver.cpp:218] Iteration 38350 (0.865501 iter/s, 57.77s/50 iters), loss = 0.00522956
I0616 02:28:06.160571 29366 solver.cpp:237]     Train net output #0: loss = 0.00522971 (* 1 = 0.00522971 loss)
I0616 02:28:06.160595 29366 sgd_solver.cpp:105] Iteration 38350, lr = 0.01
I0616 02:29:03.925206 29366 solver.cpp:218] Iteration 38400 (0.86559 iter/s, 57.764s/50 iters), loss = 0.00385163
I0616 02:29:03.925341 29366 solver.cpp:237]     Train net output #0: loss = 0.00385179 (* 1 = 0.00385179 loss)
I0616 02:29:03.925370 29366 sgd_solver.cpp:105] Iteration 38400, lr = 0.01
I0616 02:30:01.683473 29366 solver.cpp:218] Iteration 38450 (0.865688 iter/s, 57.7576s/50 iters), loss = 0.00690696
I0616 02:30:01.683615 29366 solver.cpp:237]     Train net output #0: loss = 0.00690712 (* 1 = 0.00690712 loss)
I0616 02:30:01.683639 29366 sgd_solver.cpp:105] Iteration 38450, lr = 0.01
I0616 02:30:59.451421 29366 solver.cpp:218] Iteration 38500 (0.865542 iter/s, 57.7672s/50 iters), loss = 0.0105855
I0616 02:30:59.451561 29366 solver.cpp:237]     Train net output #0: loss = 0.0105857 (* 1 = 0.0105857 loss)
I0616 02:30:59.451586 29366 sgd_solver.cpp:105] Iteration 38500, lr = 0.01
I0616 02:31:57.221776 29366 solver.cpp:218] Iteration 38550 (0.865506 iter/s, 57.7696s/50 iters), loss = 0.00667791
I0616 02:31:57.221902 29366 solver.cpp:237]     Train net output #0: loss = 0.00667807 (* 1 = 0.00667807 loss)
I0616 02:31:57.221925 29366 sgd_solver.cpp:105] Iteration 38550, lr = 0.01
I0616 02:32:54.989078 29366 solver.cpp:218] Iteration 38600 (0.865552 iter/s, 57.7666s/50 iters), loss = 0.00756018
I0616 02:32:54.989212 29366 solver.cpp:237]     Train net output #0: loss = 0.00756034 (* 1 = 0.00756034 loss)
I0616 02:32:54.989234 29366 sgd_solver.cpp:105] Iteration 38600, lr = 0.01
I0616 02:33:52.756701 29366 solver.cpp:218] Iteration 38650 (0.865547 iter/s, 57.7669s/50 iters), loss = 0.00483616
I0616 02:33:52.756834 29366 solver.cpp:237]     Train net output #0: loss = 0.00483632 (* 1 = 0.00483632 loss)
I0616 02:33:52.756857 29366 sgd_solver.cpp:105] Iteration 38650, lr = 0.01
I0616 02:34:50.527189 29366 solver.cpp:218] Iteration 38700 (0.865504 iter/s, 57.7698s/50 iters), loss = 0.00503477
I0616 02:34:50.527318 29366 solver.cpp:237]     Train net output #0: loss = 0.00503493 (* 1 = 0.00503493 loss)
I0616 02:34:50.527340 29366 sgd_solver.cpp:105] Iteration 38700, lr = 0.01
I0616 02:35:48.282717 29366 solver.cpp:218] Iteration 38750 (0.865728 iter/s, 57.7548s/50 iters), loss = 0.00924754
I0616 02:35:48.282856 29366 solver.cpp:237]     Train net output #0: loss = 0.0092477 (* 1 = 0.0092477 loss)
I0616 02:35:48.282881 29366 sgd_solver.cpp:105] Iteration 38750, lr = 0.01
I0616 02:36:46.054428 29366 solver.cpp:218] Iteration 38800 (0.865486 iter/s, 57.771s/50 iters), loss = 0.00664437
I0616 02:36:46.054607 29366 solver.cpp:237]     Train net output #0: loss = 0.00664453 (* 1 = 0.00664453 loss)
I0616 02:36:46.054637 29366 sgd_solver.cpp:105] Iteration 38800, lr = 0.01
I0616 02:37:43.829124 29366 solver.cpp:218] Iteration 38850 (0.865442 iter/s, 57.7739s/50 iters), loss = 0.00488614
I0616 02:37:43.829257 29366 solver.cpp:237]     Train net output #0: loss = 0.00488629 (* 1 = 0.00488629 loss)
I0616 02:37:43.829286 29366 sgd_solver.cpp:105] Iteration 38850, lr = 0.01
I0616 02:38:41.607595 29366 solver.cpp:218] Iteration 38900 (0.865385 iter/s, 57.7778s/50 iters), loss = 0.00637214
I0616 02:38:41.607727 29366 solver.cpp:237]     Train net output #0: loss = 0.00637229 (* 1 = 0.00637229 loss)
I0616 02:38:41.607748 29366 sgd_solver.cpp:105] Iteration 38900, lr = 0.01
I0616 02:39:39.383976 29366 solver.cpp:218] Iteration 38950 (0.865416 iter/s, 57.7757s/50 iters), loss = 0.00661609
I0616 02:39:39.384102 29366 solver.cpp:237]     Train net output #0: loss = 0.00661625 (* 1 = 0.00661625 loss)
I0616 02:39:39.384126 29366 sgd_solver.cpp:105] Iteration 38950, lr = 0.01
I0616 02:40:37.141172 29366 solver.cpp:218] Iteration 39000 (0.865703 iter/s, 57.7565s/50 iters), loss = 0.00814784
I0616 02:40:37.141291 29366 solver.cpp:237]     Train net output #0: loss = 0.008148 (* 1 = 0.008148 loss)
I0616 02:40:37.141314 29366 sgd_solver.cpp:105] Iteration 39000, lr = 0.01
I0616 02:41:34.903616 29366 solver.cpp:218] Iteration 39050 (0.865624 iter/s, 57.7618s/50 iters), loss = 0.00956334
I0616 02:41:34.903787 29366 solver.cpp:237]     Train net output #0: loss = 0.0095635 (* 1 = 0.0095635 loss)
I0616 02:41:34.903811 29366 sgd_solver.cpp:105] Iteration 39050, lr = 0.01
I0616 02:42:32.666132 29366 solver.cpp:218] Iteration 39100 (0.865623 iter/s, 57.7618s/50 iters), loss = 0.00536728
I0616 02:42:32.666271 29366 solver.cpp:237]     Train net output #0: loss = 0.00536744 (* 1 = 0.00536744 loss)
I0616 02:42:32.666299 29366 sgd_solver.cpp:105] Iteration 39100, lr = 0.01
I0616 02:43:30.440564 29366 solver.cpp:218] Iteration 39150 (0.865444 iter/s, 57.7738s/50 iters), loss = 0.00706906
I0616 02:43:30.440661 29366 solver.cpp:237]     Train net output #0: loss = 0.00706922 (* 1 = 0.00706922 loss)
I0616 02:43:30.440682 29366 sgd_solver.cpp:105] Iteration 39150, lr = 0.01
I0616 02:44:28.206261 29366 solver.cpp:218] Iteration 39200 (0.865574 iter/s, 57.7651s/50 iters), loss = 0.00610965
I0616 02:44:28.206429 29366 solver.cpp:237]     Train net output #0: loss = 0.0061098 (* 1 = 0.0061098 loss)
I0616 02:44:28.206452 29366 sgd_solver.cpp:105] Iteration 39200, lr = 0.01
I0616 02:45:25.967494 29366 solver.cpp:218] Iteration 39250 (0.865642 iter/s, 57.7606s/50 iters), loss = 0.00739658
I0616 02:45:25.967684 29366 solver.cpp:237]     Train net output #0: loss = 0.00739674 (* 1 = 0.00739674 loss)
I0616 02:45:25.967706 29366 sgd_solver.cpp:105] Iteration 39250, lr = 0.01
I0616 02:46:23.732101 29366 solver.cpp:218] Iteration 39300 (0.865592 iter/s, 57.7639s/50 iters), loss = 0.00658359
I0616 02:46:23.732255 29366 solver.cpp:237]     Train net output #0: loss = 0.00658375 (* 1 = 0.00658375 loss)
I0616 02:46:23.732280 29366 sgd_solver.cpp:105] Iteration 39300, lr = 0.01
I0616 02:47:21.484063 29366 solver.cpp:218] Iteration 39350 (0.865781 iter/s, 57.7513s/50 iters), loss = 0.00499834
I0616 02:47:21.484177 29366 solver.cpp:237]     Train net output #0: loss = 0.0049985 (* 1 = 0.0049985 loss)
I0616 02:47:21.484205 29366 sgd_solver.cpp:105] Iteration 39350, lr = 0.01
I0616 02:48:19.250277 29366 solver.cpp:218] Iteration 39400 (0.865567 iter/s, 57.7656s/50 iters), loss = 0.00790545
I0616 02:48:19.250411 29366 solver.cpp:237]     Train net output #0: loss = 0.00790561 (* 1 = 0.00790561 loss)
I0616 02:48:19.250435 29366 sgd_solver.cpp:105] Iteration 39400, lr = 0.01
I0616 02:49:17.011901 29366 solver.cpp:218] Iteration 39450 (0.865636 iter/s, 57.761s/50 iters), loss = 0.00749028
I0616 02:49:17.012099 29366 solver.cpp:237]     Train net output #0: loss = 0.00749044 (* 1 = 0.00749044 loss)
I0616 02:49:17.012126 29366 sgd_solver.cpp:105] Iteration 39450, lr = 0.01
I0616 02:50:14.776244 29366 solver.cpp:218] Iteration 39500 (0.865596 iter/s, 57.7636s/50 iters), loss = 0.00800124
I0616 02:50:14.776453 29366 solver.cpp:237]     Train net output #0: loss = 0.0080014 (* 1 = 0.0080014 loss)
I0616 02:50:14.776485 29366 sgd_solver.cpp:105] Iteration 39500, lr = 0.01
I0616 02:51:12.548974 29366 solver.cpp:218] Iteration 39550 (0.865471 iter/s, 57.772s/50 iters), loss = 0.00744153
I0616 02:51:12.549114 29366 solver.cpp:237]     Train net output #0: loss = 0.00744169 (* 1 = 0.00744169 loss)
I0616 02:51:12.549139 29366 sgd_solver.cpp:105] Iteration 39550, lr = 0.01
I0616 02:52:10.314298 29366 solver.cpp:218] Iteration 39600 (0.865581 iter/s, 57.7647s/50 iters), loss = 0.00654932
I0616 02:52:10.314476 29366 solver.cpp:237]     Train net output #0: loss = 0.00654948 (* 1 = 0.00654948 loss)
I0616 02:52:10.314497 29366 sgd_solver.cpp:105] Iteration 39600, lr = 0.01
I0616 02:53:08.088035 29366 solver.cpp:218] Iteration 39650 (0.865455 iter/s, 57.7731s/50 iters), loss = 0.00781053
I0616 02:53:08.088165 29366 solver.cpp:237]     Train net output #0: loss = 0.00781068 (* 1 = 0.00781068 loss)
I0616 02:53:08.088189 29366 sgd_solver.cpp:105] Iteration 39650, lr = 0.01
I0616 02:54:05.870333 29366 solver.cpp:218] Iteration 39700 (0.865326 iter/s, 57.7817s/50 iters), loss = 0.0061803
I0616 02:54:05.870466 29366 solver.cpp:237]     Train net output #0: loss = 0.00618045 (* 1 = 0.00618045 loss)
I0616 02:54:05.870489 29366 sgd_solver.cpp:105] Iteration 39700, lr = 0.01
I0616 02:55:03.630547 29366 solver.cpp:218] Iteration 39750 (0.865657 iter/s, 57.7596s/50 iters), loss = 0.00828578
I0616 02:55:03.630671 29366 solver.cpp:237]     Train net output #0: loss = 0.00828594 (* 1 = 0.00828594 loss)
I0616 02:55:03.630693 29366 sgd_solver.cpp:105] Iteration 39750, lr = 0.01
I0616 02:56:01.396024 29366 solver.cpp:218] Iteration 39800 (0.865578 iter/s, 57.7649s/50 iters), loss = 0.00493469
I0616 02:56:01.396143 29366 solver.cpp:237]     Train net output #0: loss = 0.00493485 (* 1 = 0.00493485 loss)
I0616 02:56:01.396167 29366 sgd_solver.cpp:105] Iteration 39800, lr = 0.01
I0616 02:56:59.163427 29366 solver.cpp:218] Iteration 39850 (0.865549 iter/s, 57.7668s/50 iters), loss = 0.00742517
I0616 02:56:59.163558 29366 solver.cpp:237]     Train net output #0: loss = 0.00742533 (* 1 = 0.00742533 loss)
I0616 02:56:59.163581 29366 sgd_solver.cpp:105] Iteration 39850, lr = 0.01
I0616 02:57:56.938470 29366 solver.cpp:218] Iteration 39900 (0.865435 iter/s, 57.7744s/50 iters), loss = 0.00557075
I0616 02:57:56.938624 29366 solver.cpp:237]     Train net output #0: loss = 0.0055709 (* 1 = 0.0055709 loss)
I0616 02:57:56.938648 29366 sgd_solver.cpp:105] Iteration 39900, lr = 0.01
I0616 02:58:54.706511 29366 solver.cpp:218] Iteration 39950 (0.86554 iter/s, 57.7674s/50 iters), loss = 0.00644529
I0616 02:58:54.706665 29366 solver.cpp:237]     Train net output #0: loss = 0.00644544 (* 1 = 0.00644544 loss)
I0616 02:58:54.706687 29366 sgd_solver.cpp:105] Iteration 39950, lr = 0.01
I0616 02:59:51.298131 29366 solver.cpp:447] Snapshotting to binary proto file mobilenet/mobile_2_iter_40000.caffemodel
I0616 02:59:51.379714 29366 sgd_solver.cpp:273] Snapshotting solver state to binary proto file mobilenet/mobile_2_iter_40000.solverstate
I0616 02:59:52.561873 29366 solver.cpp:218] Iteration 40000 (0.864234 iter/s, 57.8547s/50 iters), loss = 0.0062079
I0616 02:59:52.561959 29366 solver.cpp:237]     Train net output #0: loss = 0.00620806 (* 1 = 0.00620806 loss)
I0616 02:59:52.561982 29366 sgd_solver.cpp:105] Iteration 40000, lr = 0.01
I0616 03:00:50.313350 29366 solver.cpp:218] Iteration 40050 (0.865788 iter/s, 57.7509s/50 iters), loss = 0.00893485
I0616 03:00:50.313479 29366 solver.cpp:237]     Train net output #0: loss = 0.008935 (* 1 = 0.008935 loss)
I0616 03:00:50.313501 29366 sgd_solver.cpp:105] Iteration 40050, lr = 0.01
I0616 03:01:48.066447 29366 solver.cpp:218] Iteration 40100 (0.865764 iter/s, 57.7525s/50 iters), loss = 0.00823326
I0616 03:01:48.066568 29366 solver.cpp:237]     Train net output #0: loss = 0.00823342 (* 1 = 0.00823342 loss)
I0616 03:01:48.066592 29366 sgd_solver.cpp:105] Iteration 40100, lr = 0.01
I0616 03:02:45.832669 29366 solver.cpp:218] Iteration 40150 (0.865567 iter/s, 57.7656s/50 iters), loss = 0.00748437
I0616 03:02:45.832890 29366 solver.cpp:237]     Train net output #0: loss = 0.00748452 (* 1 = 0.00748452 loss)
I0616 03:02:45.832914 29366 sgd_solver.cpp:105] Iteration 40150, lr = 0.01
I0616 03:03:43.603572 29366 solver.cpp:218] Iteration 40200 (0.865498 iter/s, 57.7702s/50 iters), loss = 0.00577369
I0616 03:03:43.603701 29366 solver.cpp:237]     Train net output #0: loss = 0.00577385 (* 1 = 0.00577385 loss)
I0616 03:03:43.603725 29366 sgd_solver.cpp:105] Iteration 40200, lr = 0.01
I0616 03:04:41.373767 29366 solver.cpp:218] Iteration 40250 (0.865508 iter/s, 57.7696s/50 iters), loss = 0.004505
I0616 03:04:41.373909 29366 solver.cpp:237]     Train net output #0: loss = 0.00450516 (* 1 = 0.00450516 loss)
I0616 03:04:41.373932 29366 sgd_solver.cpp:105] Iteration 40250, lr = 0.01
I0616 03:05:39.142302 29366 solver.cpp:218] Iteration 40300 (0.865533 iter/s, 57.7679s/50 iters), loss = 0.00700063
I0616 03:05:39.142422 29366 solver.cpp:237]     Train net output #0: loss = 0.00700078 (* 1 = 0.00700078 loss)
I0616 03:05:39.142446 29366 sgd_solver.cpp:105] Iteration 40300, lr = 0.01
I0616 03:06:36.904557 29366 solver.cpp:218] Iteration 40350 (0.865627 iter/s, 57.7616s/50 iters), loss = 0.00667356
I0616 03:06:36.904693 29366 solver.cpp:237]     Train net output #0: loss = 0.00667372 (* 1 = 0.00667372 loss)
I0616 03:06:36.904716 29366 sgd_solver.cpp:105] Iteration 40350, lr = 0.01
I0616 03:07:34.677275 29366 solver.cpp:218] Iteration 40400 (0.86547 iter/s, 57.7721s/50 iters), loss = 0.00984279
I0616 03:07:34.677502 29366 solver.cpp:237]     Train net output #0: loss = 0.00984295 (* 1 = 0.00984295 loss)
I0616 03:07:34.677534 29366 sgd_solver.cpp:105] Iteration 40400, lr = 0.01
I0616 03:08:32.454926 29366 solver.cpp:218] Iteration 40450 (0.865398 iter/s, 57.7769s/50 iters), loss = 0.00686608
I0616 03:08:32.455065 29366 solver.cpp:237]     Train net output #0: loss = 0.00686624 (* 1 = 0.00686624 loss)
I0616 03:08:32.455087 29366 sgd_solver.cpp:105] Iteration 40450, lr = 0.01
I0616 03:09:30.228265 29366 solver.cpp:218] Iteration 40500 (0.865461 iter/s, 57.7727s/50 iters), loss = 0.00635974
I0616 03:09:30.228404 29366 solver.cpp:237]     Train net output #0: loss = 0.0063599 (* 1 = 0.0063599 loss)
I0616 03:09:30.228427 29366 sgd_solver.cpp:105] Iteration 40500, lr = 0.01
I0616 03:10:27.999428 29366 solver.cpp:218] Iteration 40550 (0.865493 iter/s, 57.7705s/50 iters), loss = 0.00601238
I0616 03:10:27.999569 29366 solver.cpp:237]     Train net output #0: loss = 0.00601254 (* 1 = 0.00601254 loss)
I0616 03:10:27.999594 29366 sgd_solver.cpp:105] Iteration 40550, lr = 0.01
I0616 03:11:25.761916 29366 solver.cpp:218] Iteration 40600 (0.865623 iter/s, 57.7618s/50 iters), loss = 0.0103386
I0616 03:11:25.762049 29366 solver.cpp:237]     Train net output #0: loss = 0.0103388 (* 1 = 0.0103388 loss)
I0616 03:11:25.762073 29366 sgd_solver.cpp:105] Iteration 40600, lr = 0.01
I0616 03:12:23.541584 29366 solver.cpp:218] Iteration 40650 (0.865366 iter/s, 57.779s/50 iters), loss = 0.00781956
I0616 03:12:23.541771 29366 solver.cpp:237]     Train net output #0: loss = 0.00781972 (* 1 = 0.00781972 loss)
I0616 03:12:23.541795 29366 sgd_solver.cpp:105] Iteration 40650, lr = 0.01
I0616 03:13:21.317970 29366 solver.cpp:218] Iteration 40700 (0.865416 iter/s, 57.7757s/50 iters), loss = 0.00804349
I0616 03:13:21.318099 29366 solver.cpp:237]     Train net output #0: loss = 0.00804364 (* 1 = 0.00804364 loss)
I0616 03:13:21.318120 29366 sgd_solver.cpp:105] Iteration 40700, lr = 0.01
I0616 03:14:19.096359 29366 solver.cpp:218] Iteration 40750 (0.865385 iter/s, 57.7778s/50 iters), loss = 0.00962167
I0616 03:14:19.096480 29366 solver.cpp:237]     Train net output #0: loss = 0.00962183 (* 1 = 0.00962183 loss)
I0616 03:14:19.096503 29366 sgd_solver.cpp:105] Iteration 40750, lr = 0.01
I0616 03:15:16.867491 29366 solver.cpp:218] Iteration 40800 (0.865494 iter/s, 57.7705s/50 iters), loss = 0.00656309
I0616 03:15:16.867686 29366 solver.cpp:237]     Train net output #0: loss = 0.00656325 (* 1 = 0.00656325 loss)
I0616 03:15:16.867712 29366 sgd_solver.cpp:105] Iteration 40800, lr = 0.01
I0616 03:16:14.639073 29366 solver.cpp:218] Iteration 40850 (0.865488 iter/s, 57.7709s/50 iters), loss = 0.00971089
I0616 03:16:14.639219 29366 solver.cpp:237]     Train net output #0: loss = 0.00971105 (* 1 = 0.00971105 loss)
I0616 03:16:14.639241 29366 sgd_solver.cpp:105] Iteration 40850, lr = 0.01
I0616 03:17:12.413350 29366 solver.cpp:218] Iteration 40900 (0.865447 iter/s, 57.7736s/50 iters), loss = 0.00753918
I0616 03:17:12.413564 29366 solver.cpp:237]     Train net output #0: loss = 0.00753933 (* 1 = 0.00753933 loss)
I0616 03:17:12.413589 29366 sgd_solver.cpp:105] Iteration 40900, lr = 0.01
I0616 03:18:10.182647 29366 solver.cpp:218] Iteration 40950 (0.865523 iter/s, 57.7686s/50 iters), loss = 0.00429264
I0616 03:18:10.182808 29366 solver.cpp:237]     Train net output #0: loss = 0.0042928 (* 1 = 0.0042928 loss)
I0616 03:18:10.182833 29366 sgd_solver.cpp:105] Iteration 40950, lr = 0.01
I0616 03:19:07.961586 29366 solver.cpp:218] Iteration 41000 (0.865377 iter/s, 57.7783s/50 iters), loss = 0.00552117
I0616 03:19:07.961714 29366 solver.cpp:237]     Train net output #0: loss = 0.00552133 (* 1 = 0.00552133 loss)
I0616 03:19:07.961737 29366 sgd_solver.cpp:105] Iteration 41000, lr = 0.01
I0616 03:20:05.734340 29366 solver.cpp:218] Iteration 41050 (0.86547 iter/s, 57.7721s/50 iters), loss = 0.00657095
I0616 03:20:05.734484 29366 solver.cpp:237]     Train net output #0: loss = 0.00657111 (* 1 = 0.00657111 loss)
I0616 03:20:05.734508 29366 sgd_solver.cpp:105] Iteration 41050, lr = 0.01
I0616 03:21:03.497423 29366 solver.cpp:218] Iteration 41100 (0.865615 iter/s, 57.7624s/50 iters), loss = 0.00510933
I0616 03:21:03.497560 29366 solver.cpp:237]     Train net output #0: loss = 0.00510949 (* 1 = 0.00510949 loss)
I0616 03:21:03.497582 29366 sgd_solver.cpp:105] Iteration 41100, lr = 0.01
I0616 03:22:01.265434 29366 solver.cpp:218] Iteration 41150 (0.865541 iter/s, 57.7674s/50 iters), loss = 0.00780476
I0616 03:22:01.265576 29366 solver.cpp:237]     Train net output #0: loss = 0.00780491 (* 1 = 0.00780491 loss)
I0616 03:22:01.265601 29366 sgd_solver.cpp:105] Iteration 41150, lr = 0.01
I0616 03:22:59.045440 29366 solver.cpp:218] Iteration 41200 (0.865361 iter/s, 57.7794s/50 iters), loss = 0.00867792
I0616 03:22:59.045567 29366 solver.cpp:237]     Train net output #0: loss = 0.00867808 (* 1 = 0.00867808 loss)
I0616 03:22:59.045590 29366 sgd_solver.cpp:105] Iteration 41200, lr = 0.01
I0616 03:23:56.820894 29366 solver.cpp:218] Iteration 41250 (0.865429 iter/s, 57.7748s/50 iters), loss = 0.00758196
I0616 03:23:56.821036 29366 solver.cpp:237]     Train net output #0: loss = 0.00758212 (* 1 = 0.00758212 loss)
I0616 03:23:56.821059 29366 sgd_solver.cpp:105] Iteration 41250, lr = 0.01
I0616 03:24:54.592280 29366 solver.cpp:218] Iteration 41300 (0.86549 iter/s, 57.7707s/50 iters), loss = 0.00577219
I0616 03:24:54.592407 29366 solver.cpp:237]     Train net output #0: loss = 0.00577235 (* 1 = 0.00577235 loss)
I0616 03:24:54.592432 29366 sgd_solver.cpp:105] Iteration 41300, lr = 0.01
I0616 03:25:52.364289 29366 solver.cpp:218] Iteration 41350 (0.865481 iter/s, 57.7714s/50 iters), loss = 0.00571809
I0616 03:25:52.364406 29366 solver.cpp:237]     Train net output #0: loss = 0.00571825 (* 1 = 0.00571825 loss)
I0616 03:25:52.364429 29366 sgd_solver.cpp:105] Iteration 41350, lr = 0.01
I0616 03:26:50.129573 29366 solver.cpp:218] Iteration 41400 (0.865582 iter/s, 57.7646s/50 iters), loss = 0.00745774
I0616 03:26:50.129720 29366 solver.cpp:237]     Train net output #0: loss = 0.0074579 (* 1 = 0.0074579 loss)
I0616 03:26:50.129745 29366 sgd_solver.cpp:105] Iteration 41400, lr = 0.01
I0616 03:27:47.895081 29366 solver.cpp:218] Iteration 41450 (0.865578 iter/s, 57.7648s/50 iters), loss = 0.00593982
I0616 03:27:47.895207 29366 solver.cpp:237]     Train net output #0: loss = 0.00593998 (* 1 = 0.00593998 loss)
I0616 03:27:47.895231 29366 sgd_solver.cpp:105] Iteration 41450, lr = 0.01
I0616 03:28:45.677644 29366 solver.cpp:218] Iteration 41500 (0.865323 iter/s, 57.7819s/50 iters), loss = 0.00843922
I0616 03:28:45.677901 29366 solver.cpp:237]     Train net output #0: loss = 0.00843938 (* 1 = 0.00843938 loss)
I0616 03:28:45.677925 29366 sgd_solver.cpp:105] Iteration 41500, lr = 0.01
I0616 03:29:43.442824 29366 solver.cpp:218] Iteration 41550 (0.865585 iter/s, 57.7644s/50 iters), loss = 0.00587858
I0616 03:29:43.442960 29366 solver.cpp:237]     Train net output #0: loss = 0.00587874 (* 1 = 0.00587874 loss)
I0616 03:29:43.442982 29366 sgd_solver.cpp:105] Iteration 41550, lr = 0.01
I0616 03:30:41.198544 29366 solver.cpp:218] Iteration 41600 (0.865725 iter/s, 57.7551s/50 iters), loss = 0.00546818
I0616 03:30:41.198673 29366 solver.cpp:237]     Train net output #0: loss = 0.00546834 (* 1 = 0.00546834 loss)
I0616 03:30:41.198696 29366 sgd_solver.cpp:105] Iteration 41600, lr = 0.01
I0616 03:31:38.973248 29366 solver.cpp:218] Iteration 41650 (0.86544 iter/s, 57.7741s/50 iters), loss = 0.00808655
I0616 03:31:38.973435 29366 solver.cpp:237]     Train net output #0: loss = 0.00808671 (* 1 = 0.00808671 loss)
I0616 03:31:38.973459 29366 sgd_solver.cpp:105] Iteration 41650, lr = 0.01
I0616 03:32:36.742153 29366 solver.cpp:218] Iteration 41700 (0.865528 iter/s, 57.7682s/50 iters), loss = 0.00618322
I0616 03:32:36.742343 29366 solver.cpp:237]     Train net output #0: loss = 0.00618338 (* 1 = 0.00618338 loss)
I0616 03:32:36.742368 29366 sgd_solver.cpp:105] Iteration 41700, lr = 0.01
I0616 03:33:34.509186 29366 solver.cpp:218] Iteration 41750 (0.865557 iter/s, 57.7662s/50 iters), loss = 0.00574448
I0616 03:33:34.509328 29366 solver.cpp:237]     Train net output #0: loss = 0.00574464 (* 1 = 0.00574464 loss)
I0616 03:33:34.509351 29366 sgd_solver.cpp:105] Iteration 41750, lr = 0.01
I0616 03:34:32.293114 29366 solver.cpp:218] Iteration 41800 (0.865303 iter/s, 57.7832s/50 iters), loss = 0.00805084
I0616 03:34:32.293236 29366 solver.cpp:237]     Train net output #0: loss = 0.008051 (* 1 = 0.008051 loss)
I0616 03:34:32.293259 29366 sgd_solver.cpp:105] Iteration 41800, lr = 0.01
I0616 03:35:30.066757 29366 solver.cpp:218] Iteration 41850 (0.865457 iter/s, 57.7729s/50 iters), loss = 0.00920876
I0616 03:35:30.066884 29366 solver.cpp:237]     Train net output #0: loss = 0.00920892 (* 1 = 0.00920892 loss)
I0616 03:35:30.066908 29366 sgd_solver.cpp:105] Iteration 41850, lr = 0.01
I0616 03:36:27.825623 29366 solver.cpp:218] Iteration 41900 (0.865679 iter/s, 57.7581s/50 iters), loss = 0.00757902
I0616 03:36:27.825770 29366 solver.cpp:237]     Train net output #0: loss = 0.00757918 (* 1 = 0.00757918 loss)
I0616 03:36:27.825794 29366 sgd_solver.cpp:105] Iteration 41900, lr = 0.01
I0616 03:37:25.587523 29366 solver.cpp:218] Iteration 41950 (0.865634 iter/s, 57.7612s/50 iters), loss = 0.00944083
I0616 03:37:25.587707 29366 solver.cpp:237]     Train net output #0: loss = 0.00944099 (* 1 = 0.00944099 loss)
I0616 03:37:25.587731 29366 sgd_solver.cpp:105] Iteration 41950, lr = 0.01
I0616 03:38:23.351001 29366 solver.cpp:218] Iteration 42000 (0.86561 iter/s, 57.7627s/50 iters), loss = 0.0136954
I0616 03:38:23.351110 29366 solver.cpp:237]     Train net output #0: loss = 0.0136955 (* 1 = 0.0136955 loss)
I0616 03:38:23.351135 29366 sgd_solver.cpp:105] Iteration 42000, lr = 0.01
I0616 03:39:21.110577 29366 solver.cpp:218] Iteration 42050 (0.865668 iter/s, 57.7589s/50 iters), loss = 0.0104366
I0616 03:39:21.110728 29366 solver.cpp:237]     Train net output #0: loss = 0.0104368 (* 1 = 0.0104368 loss)
I0616 03:39:21.110752 29366 sgd_solver.cpp:105] Iteration 42050, lr = 0.01
I0616 03:40:18.839712 29366 solver.cpp:218] Iteration 42100 (0.866126 iter/s, 57.7284s/50 iters), loss = 0.00553222
I0616 03:40:18.839867 29366 solver.cpp:237]     Train net output #0: loss = 0.00553237 (* 1 = 0.00553237 loss)
I0616 03:40:18.839891 29366 sgd_solver.cpp:105] Iteration 42100, lr = 0.01
I0616 03:41:16.573467 29366 solver.cpp:218] Iteration 42150 (0.866056 iter/s, 57.733s/50 iters), loss = 0.00655672
I0616 03:41:16.573635 29366 solver.cpp:237]     Train net output #0: loss = 0.00655688 (* 1 = 0.00655688 loss)
I0616 03:41:16.573667 29366 sgd_solver.cpp:105] Iteration 42150, lr = 0.01
I0616 03:42:14.298732 29366 solver.cpp:218] Iteration 42200 (0.866183 iter/s, 57.7245s/50 iters), loss = 0.00487225
I0616 03:42:14.298940 29366 solver.cpp:237]     Train net output #0: loss = 0.00487241 (* 1 = 0.00487241 loss)
I0616 03:42:14.298967 29366 sgd_solver.cpp:105] Iteration 42200, lr = 0.01
I0616 03:43:12.026420 29366 solver.cpp:218] Iteration 42250 (0.866147 iter/s, 57.7269s/50 iters), loss = 0.00475044
I0616 03:43:12.026572 29366 solver.cpp:237]     Train net output #0: loss = 0.0047506 (* 1 = 0.0047506 loss)
I0616 03:43:12.026597 29366 sgd_solver.cpp:105] Iteration 42250, lr = 0.01
I0616 03:44:09.753211 29366 solver.cpp:218] Iteration 42300 (0.86616 iter/s, 57.7261s/50 iters), loss = 0.00610411
I0616 03:44:09.753355 29366 solver.cpp:237]     Train net output #0: loss = 0.00610427 (* 1 = 0.00610427 loss)
I0616 03:44:09.753378 29366 sgd_solver.cpp:105] Iteration 42300, lr = 0.01
I0616 03:45:07.467180 29366 solver.cpp:218] Iteration 42350 (0.866352 iter/s, 57.7133s/50 iters), loss = 0.00599654
I0616 03:45:07.467303 29366 solver.cpp:237]     Train net output #0: loss = 0.0059967 (* 1 = 0.0059967 loss)
I0616 03:45:07.467329 29366 sgd_solver.cpp:105] Iteration 42350, lr = 0.01
I0616 03:46:05.194141 29366 solver.cpp:218] Iteration 42400 (0.866157 iter/s, 57.7263s/50 iters), loss = 0.00481202
I0616 03:46:05.194285 29366 solver.cpp:237]     Train net output #0: loss = 0.00481218 (* 1 = 0.00481218 loss)
I0616 03:46:05.194310 29366 sgd_solver.cpp:105] Iteration 42400, lr = 0.01
I0616 03:47:02.921963 29366 solver.cpp:218] Iteration 42450 (0.866144 iter/s, 57.7271s/50 iters), loss = 0.00860159
I0616 03:47:02.922094 29366 solver.cpp:237]     Train net output #0: loss = 0.00860175 (* 1 = 0.00860175 loss)
I0616 03:47:02.922117 29366 sgd_solver.cpp:105] Iteration 42450, lr = 0.01
I0616 03:48:00.640738 29366 solver.cpp:218] Iteration 42500 (0.86628 iter/s, 57.7181s/50 iters), loss = 0.0101341
I0616 03:48:00.640883 29366 solver.cpp:237]     Train net output #0: loss = 0.0101342 (* 1 = 0.0101342 loss)
I0616 03:48:00.640907 29366 sgd_solver.cpp:105] Iteration 42500, lr = 0.01
I0616 03:48:58.361860 29366 solver.cpp:218] Iteration 42550 (0.866245 iter/s, 57.7204s/50 iters), loss = 0.0088724
I0616 03:48:58.361989 29366 solver.cpp:237]     Train net output #0: loss = 0.00887256 (* 1 = 0.00887256 loss)
I0616 03:48:58.362012 29366 sgd_solver.cpp:105] Iteration 42550, lr = 0.01
I0616 03:49:56.082238 29366 solver.cpp:218] Iteration 42600 (0.866256 iter/s, 57.7197s/50 iters), loss = 0.00633452
I0616 03:49:56.082361 29366 solver.cpp:237]     Train net output #0: loss = 0.00633468 (* 1 = 0.00633468 loss)
I0616 03:49:56.082384 29366 sgd_solver.cpp:105] Iteration 42600, lr = 0.01
I0616 03:50:53.807869 29366 solver.cpp:218] Iteration 42650 (0.866177 iter/s, 57.7249s/50 iters), loss = 0.00923578
I0616 03:50:53.808004 29366 solver.cpp:237]     Train net output #0: loss = 0.00923594 (* 1 = 0.00923594 loss)
I0616 03:50:53.808028 29366 sgd_solver.cpp:105] Iteration 42650, lr = 0.01
I0616 03:51:51.534255 29366 solver.cpp:218] Iteration 42700 (0.866166 iter/s, 57.7257s/50 iters), loss = 0.00480762
I0616 03:51:51.534385 29366 solver.cpp:237]     Train net output #0: loss = 0.00480778 (* 1 = 0.00480778 loss)
I0616 03:51:51.534410 29366 sgd_solver.cpp:105] Iteration 42700, lr = 0.01
I0616 03:52:49.267073 29366 solver.cpp:218] Iteration 42750 (0.86607 iter/s, 57.7321s/50 iters), loss = 0.00840214
I0616 03:52:49.267225 29366 solver.cpp:237]     Train net output #0: loss = 0.0084023 (* 1 = 0.0084023 loss)
I0616 03:52:49.267251 29366 sgd_solver.cpp:105] Iteration 42750, lr = 0.01
I0616 03:53:47.001436 29366 solver.cpp:218] Iteration 42800 (0.866046 iter/s, 57.7336s/50 iters), loss = 0.00671328
I0616 03:53:47.001579 29366 solver.cpp:237]     Train net output #0: loss = 0.00671344 (* 1 = 0.00671344 loss)
I0616 03:53:47.001603 29366 sgd_solver.cpp:105] Iteration 42800, lr = 0.01
I0616 03:54:44.721735 29366 solver.cpp:218] Iteration 42850 (0.866257 iter/s, 57.7196s/50 iters), loss = 0.00478121
I0616 03:54:44.721926 29366 solver.cpp:237]     Train net output #0: loss = 0.00478137 (* 1 = 0.00478137 loss)
I0616 03:54:44.721961 29366 sgd_solver.cpp:105] Iteration 42850, lr = 0.01
I0616 03:55:42.447484 29366 solver.cpp:218] Iteration 42900 (0.866176 iter/s, 57.725s/50 iters), loss = 0.0055456
I0616 03:55:42.447631 29366 solver.cpp:237]     Train net output #0: loss = 0.00554576 (* 1 = 0.00554576 loss)
I0616 03:55:42.447656 29366 sgd_solver.cpp:105] Iteration 42900, lr = 0.01
I0616 03:56:40.169517 29366 solver.cpp:218] Iteration 42950 (0.866232 iter/s, 57.7213s/50 iters), loss = 0.0067124
I0616 03:56:40.169651 29366 solver.cpp:237]     Train net output #0: loss = 0.00671256 (* 1 = 0.00671256 loss)
I0616 03:56:40.169674 29366 sgd_solver.cpp:105] Iteration 42950, lr = 0.01
I0616 03:57:37.914077 29366 solver.cpp:218] Iteration 43000 (0.865893 iter/s, 57.7438s/50 iters), loss = 0.00646048
I0616 03:57:37.914243 29366 solver.cpp:237]     Train net output #0: loss = 0.00646064 (* 1 = 0.00646064 loss)
I0616 03:57:37.914268 29366 sgd_solver.cpp:105] Iteration 43000, lr = 0.01
I0616 03:58:35.680961 29366 solver.cpp:218] Iteration 43050 (0.86556 iter/s, 57.7661s/50 iters), loss = 0.00703446
I0616 03:58:35.681141 29366 solver.cpp:237]     Train net output #0: loss = 0.00703462 (* 1 = 0.00703462 loss)
I0616 03:58:35.681174 29366 sgd_solver.cpp:105] Iteration 43050, lr = 0.01
I0616 03:59:33.431810 29366 solver.cpp:218] Iteration 43100 (0.8658 iter/s, 57.7501s/50 iters), loss = 0.00513248
I0616 03:59:33.431980 29366 solver.cpp:237]     Train net output #0: loss = 0.00513264 (* 1 = 0.00513264 loss)
I0616 03:59:33.432006 29366 sgd_solver.cpp:105] Iteration 43100, lr = 0.01
I0616 04:00:31.182657 29366 solver.cpp:218] Iteration 43150 (0.8658 iter/s, 57.7501s/50 iters), loss = 0.00690141
I0616 04:00:31.182811 29366 solver.cpp:237]     Train net output #0: loss = 0.00690156 (* 1 = 0.00690156 loss)
I0616 04:00:31.182835 29366 sgd_solver.cpp:105] Iteration 43150, lr = 0.01
I0616 04:01:28.929394 29366 solver.cpp:218] Iteration 43200 (0.865861 iter/s, 57.746s/50 iters), loss = 0.00768808
I0616 04:01:28.929579 29366 solver.cpp:237]     Train net output #0: loss = 0.00768824 (* 1 = 0.00768824 loss)
I0616 04:01:28.929605 29366 sgd_solver.cpp:105] Iteration 43200, lr = 0.01
I0616 04:02:26.682438 29366 solver.cpp:218] Iteration 43250 (0.865767 iter/s, 57.7523s/50 iters), loss = 0.00535412
I0616 04:02:26.682612 29366 solver.cpp:237]     Train net output #0: loss = 0.00535427 (* 1 = 0.00535427 loss)
I0616 04:02:26.682637 29366 sgd_solver.cpp:105] Iteration 43250, lr = 0.01
I0616 04:03:24.437839 29366 solver.cpp:218] Iteration 43300 (0.865731 iter/s, 57.7546s/50 iters), loss = 0.0142589
I0616 04:03:24.437978 29366 solver.cpp:237]     Train net output #0: loss = 0.014259 (* 1 = 0.014259 loss)
I0616 04:03:24.438001 29366 sgd_solver.cpp:105] Iteration 43300, lr = 0.01
I0616 04:04:22.189685 29366 solver.cpp:218] Iteration 43350 (0.865784 iter/s, 57.7511s/50 iters), loss = 0.00759949
I0616 04:04:22.189860 29366 solver.cpp:237]     Train net output #0: loss = 0.00759965 (* 1 = 0.00759965 loss)
I0616 04:04:22.189885 29366 sgd_solver.cpp:105] Iteration 43350, lr = 0.01
I0616 04:05:19.933253 29366 solver.cpp:218] Iteration 43400 (0.865909 iter/s, 57.7428s/50 iters), loss = 0.00643042
I0616 04:05:19.933403 29366 solver.cpp:237]     Train net output #0: loss = 0.00643058 (* 1 = 0.00643058 loss)
I0616 04:05:19.933429 29366 sgd_solver.cpp:105] Iteration 43400, lr = 0.01
I0616 04:06:17.698477 29366 solver.cpp:218] Iteration 43450 (0.865584 iter/s, 57.7645s/50 iters), loss = 0.00966778
I0616 04:06:17.699559 29366 solver.cpp:237]     Train net output #0: loss = 0.00966793 (* 1 = 0.00966793 loss)
I0616 04:06:17.699587 29366 sgd_solver.cpp:105] Iteration 43450, lr = 0.01
I0616 04:07:15.448896 29366 solver.cpp:218] Iteration 43500 (0.865819 iter/s, 57.7488s/50 iters), loss = 0.00622476
I0616 04:07:15.449025 29366 solver.cpp:237]     Train net output #0: loss = 0.00622491 (* 1 = 0.00622491 loss)
I0616 04:07:15.449048 29366 sgd_solver.cpp:105] Iteration 43500, lr = 0.01
I0616 04:08:13.167768 29366 solver.cpp:218] Iteration 43550 (0.866278 iter/s, 57.7182s/50 iters), loss = 0.00802845
I0616 04:08:13.167963 29366 solver.cpp:237]     Train net output #0: loss = 0.00802861 (* 1 = 0.00802861 loss)
I0616 04:08:13.167987 29366 sgd_solver.cpp:105] Iteration 43550, lr = 0.01
I0616 04:09:10.901347 29366 solver.cpp:218] Iteration 43600 (0.866058 iter/s, 57.7328s/50 iters), loss = 0.00801968
I0616 04:09:10.901501 29366 solver.cpp:237]     Train net output #0: loss = 0.00801984 (* 1 = 0.00801984 loss)
I0616 04:09:10.901536 29366 sgd_solver.cpp:105] Iteration 43600, lr = 0.01
I0616 04:10:08.621273 29366 solver.cpp:218] Iteration 43650 (0.866262 iter/s, 57.7192s/50 iters), loss = 0.00566268
I0616 04:10:08.621402 29366 solver.cpp:237]     Train net output #0: loss = 0.00566284 (* 1 = 0.00566284 loss)
I0616 04:10:08.621425 29366 sgd_solver.cpp:105] Iteration 43650, lr = 0.01
I0616 04:11:06.338632 29366 solver.cpp:218] Iteration 43700 (0.8663 iter/s, 57.7167s/50 iters), loss = 0.0063894
I0616 04:11:06.338747 29366 solver.cpp:237]     Train net output #0: loss = 0.00638956 (* 1 = 0.00638956 loss)
I0616 04:11:06.338771 29366 sgd_solver.cpp:105] Iteration 43700, lr = 0.01
I0616 04:12:04.065161 29366 solver.cpp:218] Iteration 43750 (0.866163 iter/s, 57.7259s/50 iters), loss = 0.00655125
I0616 04:12:04.065292 29366 solver.cpp:237]     Train net output #0: loss = 0.0065514 (* 1 = 0.0065514 loss)
I0616 04:12:04.065315 29366 sgd_solver.cpp:105] Iteration 43750, lr = 0.01
I0616 04:13:01.792346 29366 solver.cpp:218] Iteration 43800 (0.866153 iter/s, 57.7265s/50 iters), loss = 0.00875694
I0616 04:13:01.792484 29366 solver.cpp:237]     Train net output #0: loss = 0.0087571 (* 1 = 0.0087571 loss)
I0616 04:13:01.792518 29366 sgd_solver.cpp:105] Iteration 43800, lr = 0.01
I0616 04:13:59.518987 29366 solver.cpp:218] Iteration 43850 (0.866161 iter/s, 57.726s/50 iters), loss = 0.00652295
I0616 04:13:59.519148 29366 solver.cpp:237]     Train net output #0: loss = 0.00652311 (* 1 = 0.00652311 loss)
I0616 04:13:59.519172 29366 sgd_solver.cpp:105] Iteration 43850, lr = 0.01
I0616 04:14:57.251013 29366 solver.cpp:218] Iteration 43900 (0.866081 iter/s, 57.7313s/50 iters), loss = 0.00748545
I0616 04:14:57.251139 29366 solver.cpp:237]     Train net output #0: loss = 0.0074856 (* 1 = 0.0074856 loss)
I0616 04:14:57.251163 29366 sgd_solver.cpp:105] Iteration 43900, lr = 0.01
I0616 04:15:54.967578 29366 solver.cpp:218] Iteration 43950 (0.866312 iter/s, 57.7159s/50 iters), loss = 0.00716186
I0616 04:15:54.967708 29366 solver.cpp:237]     Train net output #0: loss = 0.00716202 (* 1 = 0.00716202 loss)
I0616 04:15:54.967733 29366 sgd_solver.cpp:105] Iteration 43950, lr = 0.01
I0616 04:16:52.692311 29366 solver.cpp:218] Iteration 44000 (0.86619 iter/s, 57.7241s/50 iters), loss = 0.00759022
I0616 04:16:52.692442 29366 solver.cpp:237]     Train net output #0: loss = 0.00759038 (* 1 = 0.00759038 loss)
I0616 04:16:52.692466 29366 sgd_solver.cpp:105] Iteration 44000, lr = 0.01
I0616 04:17:50.419541 29366 solver.cpp:218] Iteration 44050 (0.866152 iter/s, 57.7266s/50 iters), loss = 0.00557213
I0616 04:17:50.419678 29366 solver.cpp:237]     Train net output #0: loss = 0.00557229 (* 1 = 0.00557229 loss)
I0616 04:17:50.419703 29366 sgd_solver.cpp:105] Iteration 44050, lr = 0.01
I0616 04:18:48.139930 29366 solver.cpp:218] Iteration 44100 (0.866255 iter/s, 57.7197s/50 iters), loss = 0.00719278
I0616 04:18:48.140053 29366 solver.cpp:237]     Train net output #0: loss = 0.00719293 (* 1 = 0.00719293 loss)
I0616 04:18:48.140077 29366 sgd_solver.cpp:105] Iteration 44100, lr = 0.01
I0616 04:19:45.865530 29366 solver.cpp:218] Iteration 44150 (0.866177 iter/s, 57.7249s/50 iters), loss = 0.00671459
I0616 04:19:45.865660 29366 solver.cpp:237]     Train net output #0: loss = 0.00671475 (* 1 = 0.00671475 loss)
I0616 04:19:45.865685 29366 sgd_solver.cpp:105] Iteration 44150, lr = 0.01
I0616 04:20:43.589018 29366 solver.cpp:218] Iteration 44200 (0.866208 iter/s, 57.7228s/50 iters), loss = 0.00844244
I0616 04:20:43.589190 29366 solver.cpp:237]     Train net output #0: loss = 0.0084426 (* 1 = 0.0084426 loss)
I0616 04:20:43.589215 29366 sgd_solver.cpp:105] Iteration 44200, lr = 0.01
I0616 04:21:41.325686 29366 solver.cpp:218] Iteration 44250 (0.866011 iter/s, 57.736s/50 iters), loss = 0.00602284
I0616 04:21:41.325812 29366 solver.cpp:237]     Train net output #0: loss = 0.006023 (* 1 = 0.006023 loss)
I0616 04:21:41.325835 29366 sgd_solver.cpp:105] Iteration 44250, lr = 0.01
I0616 04:22:39.045837 29366 solver.cpp:218] Iteration 44300 (0.866259 iter/s, 57.7195s/50 iters), loss = 0.00567221
I0616 04:22:39.045984 29366 solver.cpp:237]     Train net output #0: loss = 0.00567237 (* 1 = 0.00567237 loss)
I0616 04:22:39.046011 29366 sgd_solver.cpp:105] Iteration 44300, lr = 0.01
I0616 04:23:36.765233 29366 solver.cpp:218] Iteration 44350 (0.86627 iter/s, 57.7187s/50 iters), loss = 0.00499796
I0616 04:23:36.765357 29366 solver.cpp:237]     Train net output #0: loss = 0.00499812 (* 1 = 0.00499812 loss)
I0616 04:23:36.765386 29366 sgd_solver.cpp:105] Iteration 44350, lr = 0.01
I0616 04:24:34.501067 29366 solver.cpp:218] Iteration 44400 (0.866021 iter/s, 57.7353s/50 iters), loss = 0.00575589
I0616 04:24:34.501217 29366 solver.cpp:237]     Train net output #0: loss = 0.00575605 (* 1 = 0.00575605 loss)
I0616 04:24:34.501242 29366 sgd_solver.cpp:105] Iteration 44400, lr = 0.01
I0616 04:25:32.218024 29366 solver.cpp:218] Iteration 44450 (0.866305 iter/s, 57.7164s/50 iters), loss = 0.00677985
I0616 04:25:32.218169 29366 solver.cpp:237]     Train net output #0: loss = 0.00678001 (* 1 = 0.00678001 loss)
I0616 04:25:32.218194 29366 sgd_solver.cpp:105] Iteration 44450, lr = 0.01
I0616 04:26:29.952668 29366 solver.cpp:218] Iteration 44500 (0.866039 iter/s, 57.7341s/50 iters), loss = 0.00621638
I0616 04:26:29.952797 29366 solver.cpp:237]     Train net output #0: loss = 0.00621654 (* 1 = 0.00621654 loss)
I0616 04:26:29.952821 29366 sgd_solver.cpp:105] Iteration 44500, lr = 0.01
I0616 04:27:27.666960 29366 solver.cpp:218] Iteration 44550 (0.866345 iter/s, 57.7138s/50 iters), loss = 0.00684584
I0616 04:27:27.667150 29366 solver.cpp:237]     Train net output #0: loss = 0.00684599 (* 1 = 0.00684599 loss)
I0616 04:27:27.667172 29366 sgd_solver.cpp:105] Iteration 44550, lr = 0.01
I0616 04:28:25.387023 29366 solver.cpp:218] Iteration 44600 (0.866259 iter/s, 57.7195s/50 iters), loss = 0.00865607
I0616 04:28:25.387150 29366 solver.cpp:237]     Train net output #0: loss = 0.00865623 (* 1 = 0.00865623 loss)
I0616 04:28:25.387171 29366 sgd_solver.cpp:105] Iteration 44600, lr = 0.01
I0616 04:29:23.119695 29366 solver.cpp:218] Iteration 44650 (0.866069 iter/s, 57.7321s/50 iters), loss = 0.00648843
I0616 04:29:23.119827 29366 solver.cpp:237]     Train net output #0: loss = 0.00648859 (* 1 = 0.00648859 loss)
I0616 04:29:23.119850 29366 sgd_solver.cpp:105] Iteration 44650, lr = 0.01
I0616 04:30:20.840356 29366 solver.cpp:218] Iteration 44700 (0.866249 iter/s, 57.7201s/50 iters), loss = 0.00607822
I0616 04:30:20.840494 29366 solver.cpp:237]     Train net output #0: loss = 0.00607838 (* 1 = 0.00607838 loss)
I0616 04:30:20.840524 29366 sgd_solver.cpp:105] Iteration 44700, lr = 0.01
I0616 04:31:18.566915 29366 solver.cpp:218] Iteration 44750 (0.866161 iter/s, 57.726s/50 iters), loss = 0.0103592
I0616 04:31:18.567045 29366 solver.cpp:237]     Train net output #0: loss = 0.0103594 (* 1 = 0.0103594 loss)
I0616 04:31:18.567070 29366 sgd_solver.cpp:105] Iteration 44750, lr = 0.01
I0616 04:32:16.295029 29366 solver.cpp:218] Iteration 44800 (0.866137 iter/s, 57.7276s/50 iters), loss = 1.73971
I0616 04:32:16.295153 29366 solver.cpp:237]     Train net output #0: loss = 1.73971 (* 1 = 1.73971 loss)
I0616 04:32:16.295183 29366 sgd_solver.cpp:105] Iteration 44800, lr = 0.01
I0616 04:33:14.018399 29366 solver.cpp:218] Iteration 44850 (0.866208 iter/s, 57.7228s/50 iters), loss = 1.37929
I0616 04:33:14.018532 29366 solver.cpp:237]     Train net output #0: loss = 1.37929 (* 1 = 1.37929 loss)
I0616 04:33:14.018556 29366 sgd_solver.cpp:105] Iteration 44850, lr = 0.01
I0616 04:34:11.739251 29366 solver.cpp:218] Iteration 44900 (0.866247 iter/s, 57.7203s/50 iters), loss = 0.965676
I0616 04:34:11.739480 29366 solver.cpp:237]     Train net output #0: loss = 0.965676 (* 1 = 0.965676 loss)
I0616 04:34:11.739521 29366 sgd_solver.cpp:105] Iteration 44900, lr = 0.01
I0616 04:35:09.464447 29366 solver.cpp:218] Iteration 44950 (0.866183 iter/s, 57.7245s/50 iters), loss = 1.31554
I0616 04:35:09.464644 29366 solver.cpp:237]     Train net output #0: loss = 1.31554 (* 1 = 1.31554 loss)
I0616 04:35:09.464668 29366 sgd_solver.cpp:105] Iteration 44950, lr = 0.01
I0616 04:36:07.189723 29366 solver.cpp:218] Iteration 45000 (0.866181 iter/s, 57.7247s/50 iters), loss = 0.879964
I0616 04:36:07.189846 29366 solver.cpp:237]     Train net output #0: loss = 0.879964 (* 1 = 0.879964 loss)
I0616 04:36:07.189870 29366 sgd_solver.cpp:105] Iteration 45000, lr = 0.01
I0616 04:37:04.910269 29366 solver.cpp:218] Iteration 45050 (0.866251 iter/s, 57.72s/50 iters), loss = 0.637156
I0616 04:37:04.910403 29366 solver.cpp:237]     Train net output #0: loss = 0.637156 (* 1 = 0.637156 loss)
I0616 04:37:04.910426 29366 sgd_solver.cpp:105] Iteration 45050, lr = 0.01
I0616 04:38:02.670032 29366 solver.cpp:218] Iteration 45100 (0.865663 iter/s, 57.7592s/50 iters), loss = 0.769442
I0616 04:38:02.670207 29366 solver.cpp:237]     Train net output #0: loss = 0.769442 (* 1 = 0.769442 loss)
I0616 04:38:02.670233 29366 sgd_solver.cpp:105] Iteration 45100, lr = 0.01
I0616 04:39:00.430492 29366 solver.cpp:218] Iteration 45150 (0.865653 iter/s, 57.7598s/50 iters), loss = 0.312602
I0616 04:39:00.430665 29366 solver.cpp:237]     Train net output #0: loss = 0.312602 (* 1 = 0.312602 loss)
I0616 04:39:00.430691 29366 sgd_solver.cpp:105] Iteration 45150, lr = 0.01
I0616 04:39:58.193202 29366 solver.cpp:218] Iteration 45200 (0.86562 iter/s, 57.7621s/50 iters), loss = 0.557574
I0616 04:39:58.193362 29366 solver.cpp:237]     Train net output #0: loss = 0.557574 (* 1 = 0.557574 loss)
I0616 04:39:58.193387 29366 sgd_solver.cpp:105] Iteration 45200, lr = 0.01
I0616 04:40:55.959578 29366 solver.cpp:218] Iteration 45250 (0.865565 iter/s, 57.7658s/50 iters), loss = 0.319303
I0616 04:40:55.959745 29366 solver.cpp:237]     Train net output #0: loss = 0.319303 (* 1 = 0.319303 loss)
I0616 04:40:55.959769 29366 sgd_solver.cpp:105] Iteration 45250, lr = 0.01
I0616 04:41:53.724675 29366 solver.cpp:218] Iteration 45300 (0.865584 iter/s, 57.7645s/50 iters), loss = 0.520822
I0616 04:41:53.724869 29366 solver.cpp:237]     Train net output #0: loss = 0.520822 (* 1 = 0.520822 loss)
I0616 04:41:53.724901 29366 sgd_solver.cpp:105] Iteration 45300, lr = 0.01
I0616 04:42:51.487803 29366 solver.cpp:218] Iteration 45350 (0.865614 iter/s, 57.7625s/50 iters), loss = 0.263315
I0616 04:42:51.487972 29366 solver.cpp:237]     Train net output #0: loss = 0.263315 (* 1 = 0.263315 loss)
I0616 04:42:51.487996 29366 sgd_solver.cpp:105] Iteration 45350, lr = 0.01
I0616 04:43:49.257532 29366 solver.cpp:218] Iteration 45400 (0.865515 iter/s, 57.7691s/50 iters), loss = 0.368603
I0616 04:43:49.257699 29366 solver.cpp:237]     Train net output #0: loss = 0.368603 (* 1 = 0.368603 loss)
I0616 04:43:49.257722 29366 sgd_solver.cpp:105] Iteration 45400, lr = 0.01
I0616 04:44:47.019749 29366 solver.cpp:218] Iteration 45450 (0.865627 iter/s, 57.7616s/50 iters), loss = 0.161827
I0616 04:44:47.019917 29366 solver.cpp:237]     Train net output #0: loss = 0.161827 (* 1 = 0.161827 loss)
I0616 04:44:47.019940 29366 sgd_solver.cpp:105] Iteration 45450, lr = 0.01
I0616 04:45:44.785527 29366 solver.cpp:218] Iteration 45500 (0.865574 iter/s, 57.7652s/50 iters), loss = 0.300749
I0616 04:45:44.785693 29366 solver.cpp:237]     Train net output #0: loss = 0.30075 (* 1 = 0.30075 loss)
I0616 04:45:44.785717 29366 sgd_solver.cpp:105] Iteration 45500, lr = 0.01
I0616 04:46:42.549324 29366 solver.cpp:218] Iteration 45550 (0.865603 iter/s, 57.7632s/50 iters), loss = 0.148452
I0616 04:46:42.549489 29366 solver.cpp:237]     Train net output #0: loss = 0.148452 (* 1 = 0.148452 loss)
I0616 04:46:42.549520 29366 sgd_solver.cpp:105] Iteration 45550, lr = 0.01
I0616 04:47:40.308153 29366 solver.cpp:218] Iteration 45600 (0.865678 iter/s, 57.7582s/50 iters), loss = 0.220875
I0616 04:47:40.308341 29366 solver.cpp:237]     Train net output #0: loss = 0.220875 (* 1 = 0.220875 loss)
I0616 04:47:40.308364 29366 sgd_solver.cpp:105] Iteration 45600, lr = 0.01
I0616 04:48:38.061605 29366 solver.cpp:218] Iteration 45650 (0.865759 iter/s, 57.7528s/50 iters), loss = 0.182887
I0616 04:48:38.062616 29366 solver.cpp:237]     Train net output #0: loss = 0.182887 (* 1 = 0.182887 loss)
I0616 04:48:38.062640 29366 sgd_solver.cpp:105] Iteration 45650, lr = 0.01
I0616 04:49:35.801156 29366 solver.cpp:218] Iteration 45700 (0.865979 iter/s, 57.7381s/50 iters), loss = 0.149363
I0616 04:49:35.801301 29366 solver.cpp:237]     Train net output #0: loss = 0.149363 (* 1 = 0.149363 loss)
I0616 04:49:35.801332 29366 sgd_solver.cpp:105] Iteration 45700, lr = 0.01
I0616 04:50:33.557332 29366 solver.cpp:218] Iteration 45750 (0.865717 iter/s, 57.7556s/50 iters), loss = 0.17211
I0616 04:50:33.557521 29366 solver.cpp:237]     Train net output #0: loss = 0.17211 (* 1 = 0.17211 loss)
I0616 04:50:33.557548 29366 sgd_solver.cpp:105] Iteration 45750, lr = 0.01
I0616 04:51:31.318963 29366 solver.cpp:218] Iteration 45800 (0.865636 iter/s, 57.761s/50 iters), loss = 0.139435
I0616 04:51:31.319087 29366 solver.cpp:237]     Train net output #0: loss = 0.139435 (* 1 = 0.139435 loss)
I0616 04:51:31.319111 29366 sgd_solver.cpp:105] Iteration 45800, lr = 0.01
I0616 04:52:29.068670 29366 solver.cpp:218] Iteration 45850 (0.865814 iter/s, 57.7491s/50 iters), loss = 0.164465
I0616 04:52:29.068821 29366 solver.cpp:237]     Train net output #0: loss = 0.164465 (* 1 = 0.164465 loss)
I0616 04:52:29.068847 29366 sgd_solver.cpp:105] Iteration 45850, lr = 0.01
I0616 04:53:26.832484 29366 solver.cpp:218] Iteration 45900 (0.865603 iter/s, 57.7632s/50 iters), loss = 0.203074
I0616 04:53:26.832626 29366 solver.cpp:237]     Train net output #0: loss = 0.203074 (* 1 = 0.203074 loss)
I0616 04:53:26.832656 29366 sgd_solver.cpp:105] Iteration 45900, lr = 0.01
I0616 04:54:24.583017 29366 solver.cpp:218] Iteration 45950 (0.865802 iter/s, 57.7499s/50 iters), loss = 0.0965074
I0616 04:54:24.583175 29366 solver.cpp:237]     Train net output #0: loss = 0.0965075 (* 1 = 0.0965075 loss)
I0616 04:54:24.583204 29366 sgd_solver.cpp:105] Iteration 45950, lr = 0.01
I0616 04:55:22.360200 29366 solver.cpp:218] Iteration 46000 (0.865403 iter/s, 57.7766s/50 iters), loss = 0.139349
I0616 04:55:22.360329 29366 solver.cpp:237]     Train net output #0: loss = 0.139349 (* 1 = 0.139349 loss)
I0616 04:55:22.360352 29366 sgd_solver.cpp:105] Iteration 46000, lr = 0.01
I0616 04:56:20.116041 29366 solver.cpp:218] Iteration 46050 (0.865722 iter/s, 57.7553s/50 iters), loss = 0.134254
I0616 04:56:20.116554 29366 solver.cpp:237]     Train net output #0: loss = 0.134254 (* 1 = 0.134254 loss)
I0616 04:56:20.116580 29366 sgd_solver.cpp:105] Iteration 46050, lr = 0.01
I0616 04:57:17.874102 29366 solver.cpp:218] Iteration 46100 (0.865694 iter/s, 57.7571s/50 iters), loss = 0.0879154
I0616 04:57:17.874241 29366 solver.cpp:237]     Train net output #0: loss = 0.0879155 (* 1 = 0.0879155 loss)
I0616 04:57:17.874264 29366 sgd_solver.cpp:105] Iteration 46100, lr = 0.01
I0616 04:58:15.620574 29366 solver.cpp:218] Iteration 46150 (0.865864 iter/s, 57.7458s/50 iters), loss = 0.112125
I0616 04:58:15.620702 29366 solver.cpp:237]     Train net output #0: loss = 0.112125 (* 1 = 0.112125 loss)
I0616 04:58:15.620725 29366 sgd_solver.cpp:105] Iteration 46150, lr = 0.01
I0616 04:59:13.369619 29366 solver.cpp:218] Iteration 46200 (0.865826 iter/s, 57.7483s/50 iters), loss = 0.0455491
I0616 04:59:13.369750 29366 solver.cpp:237]     Train net output #0: loss = 0.0455492 (* 1 = 0.0455492 loss)
I0616 04:59:13.369773 29366 sgd_solver.cpp:105] Iteration 46200, lr = 0.01
I0616 05:00:11.127887 29366 solver.cpp:218] Iteration 46250 (0.865688 iter/s, 57.7575s/50 iters), loss = 0.0432628
I0616 05:00:11.128044 29366 solver.cpp:237]     Train net output #0: loss = 0.0432629 (* 1 = 0.0432629 loss)
I0616 05:00:11.128067 29366 sgd_solver.cpp:105] Iteration 46250, lr = 0.01
I0616 05:01:08.879669 29366 solver.cpp:218] Iteration 46300 (0.865785 iter/s, 57.751s/50 iters), loss = 0.0821263
I0616 05:01:08.879873 29366 solver.cpp:237]     Train net output #0: loss = 0.0821263 (* 1 = 0.0821263 loss)
I0616 05:01:08.879895 29366 sgd_solver.cpp:105] Iteration 46300, lr = 0.01
I0616 05:02:06.634601 29366 solver.cpp:218] Iteration 46350 (0.865739 iter/s, 57.7541s/50 iters), loss = 0.0960342
I0616 05:02:06.634739 29366 solver.cpp:237]     Train net output #0: loss = 0.0960343 (* 1 = 0.0960343 loss)
I0616 05:02:06.634766 29366 sgd_solver.cpp:105] Iteration 46350, lr = 0.01
I0616 05:03:04.396991 29366 solver.cpp:218] Iteration 46400 (0.865626 iter/s, 57.7617s/50 iters), loss = 0.0332893
I0616 05:03:04.397121 29366 solver.cpp:237]     Train net output #0: loss = 0.0332893 (* 1 = 0.0332893 loss)
I0616 05:03:04.397145 29366 sgd_solver.cpp:105] Iteration 46400, lr = 0.01
I0616 05:04:02.154507 29366 solver.cpp:218] Iteration 46450 (0.865699 iter/s, 57.7568s/50 iters), loss = 0.0160633
I0616 05:04:02.154644 29366 solver.cpp:237]     Train net output #0: loss = 0.0160634 (* 1 = 0.0160634 loss)
I0616 05:04:02.154667 29366 sgd_solver.cpp:105] Iteration 46450, lr = 0.01
I0616 05:04:59.909831 29366 solver.cpp:218] Iteration 46500 (0.865732 iter/s, 57.7546s/50 iters), loss = 0.0481982
I0616 05:04:59.909961 29366 solver.cpp:237]     Train net output #0: loss = 0.0481983 (* 1 = 0.0481983 loss)
I0616 05:04:59.909986 29366 sgd_solver.cpp:105] Iteration 46500, lr = 0.01
I0616 05:05:57.675295 29366 solver.cpp:218] Iteration 46550 (0.86558 iter/s, 57.7647s/50 iters), loss = 0.0776736
I0616 05:05:57.675436 29366 solver.cpp:237]     Train net output #0: loss = 0.0776737 (* 1 = 0.0776737 loss)
I0616 05:05:57.675459 29366 sgd_solver.cpp:105] Iteration 46550, lr = 0.01
I0616 05:06:55.441865 29366 solver.cpp:218] Iteration 46600 (0.865563 iter/s, 57.7658s/50 iters), loss = 0.0214193
I0616 05:06:55.442654 29366 solver.cpp:237]     Train net output #0: loss = 0.0214194 (* 1 = 0.0214194 loss)
I0616 05:06:55.442678 29366 sgd_solver.cpp:105] Iteration 46600, lr = 0.01
I0616 05:07:53.193395 29366 solver.cpp:218] Iteration 46650 (0.865799 iter/s, 57.7502s/50 iters), loss = 0.0157057
I0616 05:07:53.193518 29366 solver.cpp:237]     Train net output #0: loss = 0.0157057 (* 1 = 0.0157057 loss)
I0616 05:07:53.193542 29366 sgd_solver.cpp:105] Iteration 46650, lr = 0.01
I0616 05:08:50.948731 29366 solver.cpp:218] Iteration 46700 (0.865731 iter/s, 57.7546s/50 iters), loss = 0.0137441
I0616 05:08:50.948890 29366 solver.cpp:237]     Train net output #0: loss = 0.0137442 (* 1 = 0.0137442 loss)
I0616 05:08:50.948912 29366 sgd_solver.cpp:105] Iteration 46700, lr = 0.01
I0616 05:09:48.679224 29366 solver.cpp:218] Iteration 46750 (0.866105 iter/s, 57.7297s/50 iters), loss = 0.00410778
I0616 05:09:48.679363 29366 solver.cpp:237]     Train net output #0: loss = 0.00410787 (* 1 = 0.00410787 loss)
I0616 05:09:48.679394 29366 sgd_solver.cpp:105] Iteration 46750, lr = 0.01
I0616 05:10:46.425608 29366 solver.cpp:218] Iteration 46800 (0.865867 iter/s, 57.7456s/50 iters), loss = 0.00629121
I0616 05:10:46.425770 29366 solver.cpp:237]     Train net output #0: loss = 0.0062913 (* 1 = 0.0062913 loss)
I0616 05:10:46.425794 29366 sgd_solver.cpp:105] Iteration 46800, lr = 0.01
I0616 05:11:44.152528 29366 solver.cpp:218] Iteration 46850 (0.866158 iter/s, 57.7262s/50 iters), loss = 0.0175052
I0616 05:11:44.152681 29366 solver.cpp:237]     Train net output #0: loss = 0.0175053 (* 1 = 0.0175053 loss)
I0616 05:11:44.152707 29366 sgd_solver.cpp:105] Iteration 46850, lr = 0.01
I0616 05:12:41.890813 29366 solver.cpp:218] Iteration 46900 (0.865987 iter/s, 57.7376s/50 iters), loss = 0.00383143
I0616 05:12:41.890950 29366 solver.cpp:237]     Train net output #0: loss = 0.00383152 (* 1 = 0.00383152 loss)
I0616 05:12:41.890975 29366 sgd_solver.cpp:105] Iteration 46900, lr = 0.01
I0616 05:13:39.614555 29366 solver.cpp:218] Iteration 46950 (0.866206 iter/s, 57.723s/50 iters), loss = 0.0103716
I0616 05:13:39.614753 29366 solver.cpp:237]     Train net output #0: loss = 0.0103717 (* 1 = 0.0103717 loss)
I0616 05:13:39.614778 29366 sgd_solver.cpp:105] Iteration 46950, lr = 0.01
I0616 05:14:37.336616 29366 solver.cpp:218] Iteration 47000 (0.866232 iter/s, 57.7213s/50 iters), loss = 0.00707846
I0616 05:14:37.336755 29366 solver.cpp:237]     Train net output #0: loss = 0.00707855 (* 1 = 0.00707855 loss)
I0616 05:14:37.336778 29366 sgd_solver.cpp:105] Iteration 47000, lr = 0.01
I0616 05:15:35.059696 29366 solver.cpp:218] Iteration 47050 (0.866215 iter/s, 57.7224s/50 iters), loss = 0.00623619
I0616 05:15:35.059814 29366 solver.cpp:237]     Train net output #0: loss = 0.00623628 (* 1 = 0.00623628 loss)
I0616 05:15:35.059842 29366 sgd_solver.cpp:105] Iteration 47050, lr = 0.01
I0616 05:16:32.785061 29366 solver.cpp:218] Iteration 47100 (0.866181 iter/s, 57.7247s/50 iters), loss = 0.00967838
I0616 05:16:32.785189 29366 solver.cpp:237]     Train net output #0: loss = 0.00967847 (* 1 = 0.00967847 loss)
I0616 05:16:32.785214 29366 sgd_solver.cpp:105] Iteration 47100, lr = 0.01
I0616 05:17:30.517853 29366 solver.cpp:218] Iteration 47150 (0.86607 iter/s, 57.7321s/50 iters), loss = 0.00472965
I0616 05:17:30.517977 29366 solver.cpp:237]     Train net output #0: loss = 0.00472974 (* 1 = 0.00472974 loss)
I0616 05:17:30.518002 29366 sgd_solver.cpp:105] Iteration 47150, lr = 0.01
I0616 05:18:28.279449 29366 solver.cpp:218] Iteration 47200 (0.865638 iter/s, 57.7609s/50 iters), loss = 0.00510122
I0616 05:18:28.279652 29366 solver.cpp:237]     Train net output #0: loss = 0.00510131 (* 1 = 0.00510131 loss)
I0616 05:18:28.279680 29366 sgd_solver.cpp:105] Iteration 47200, lr = 0.01
I0616 05:19:26.023948 29366 solver.cpp:218] Iteration 47250 (0.865896 iter/s, 57.7437s/50 iters), loss = 0.00467435
I0616 05:19:26.024113 29366 solver.cpp:237]     Train net output #0: loss = 0.00467444 (* 1 = 0.00467444 loss)
I0616 05:19:26.024144 29366 sgd_solver.cpp:105] Iteration 47250, lr = 0.01
I0616 05:20:23.786743 29366 solver.cpp:218] Iteration 47300 (0.86562 iter/s, 57.762s/50 iters), loss = 0.00725681
I0616 05:20:23.786906 29366 solver.cpp:237]     Train net output #0: loss = 0.0072569 (* 1 = 0.0072569 loss)
I0616 05:20:23.786931 29366 sgd_solver.cpp:105] Iteration 47300, lr = 0.01
I0616 05:21:21.540163 29366 solver.cpp:218] Iteration 47350 (0.865761 iter/s, 57.7527s/50 iters), loss = 0.0118701
I0616 05:21:21.540323 29366 solver.cpp:237]     Train net output #0: loss = 0.0118702 (* 1 = 0.0118702 loss)
I0616 05:21:21.540347 29366 sgd_solver.cpp:105] Iteration 47350, lr = 0.01
I0616 05:22:19.281303 29366 solver.cpp:218] Iteration 47400 (0.865946 iter/s, 57.7403s/50 iters), loss = 0.00643833
I0616 05:22:19.281507 29366 solver.cpp:237]     Train net output #0: loss = 0.00643842 (* 1 = 0.00643842 loss)
I0616 05:22:19.281545 29366 sgd_solver.cpp:105] Iteration 47400, lr = 0.01
I0616 05:23:17.030760 29366 solver.cpp:218] Iteration 47450 (0.865821 iter/s, 57.7487s/50 iters), loss = 0.00489741
I0616 05:23:17.030915 29366 solver.cpp:237]     Train net output #0: loss = 0.0048975 (* 1 = 0.0048975 loss)
I0616 05:23:17.030941 29366 sgd_solver.cpp:105] Iteration 47450, lr = 0.01
I0616 05:24:14.772173 29366 solver.cpp:218] Iteration 47500 (0.865941 iter/s, 57.7407s/50 iters), loss = 0.00371131
I0616 05:24:14.772359 29366 solver.cpp:237]     Train net output #0: loss = 0.0037114 (* 1 = 0.0037114 loss)
I0616 05:24:14.772383 29366 sgd_solver.cpp:105] Iteration 47500, lr = 0.01
I0616 05:25:12.530807 29366 solver.cpp:218] Iteration 47550 (0.865683 iter/s, 57.7579s/50 iters), loss = 0.00829719
I0616 05:25:12.530972 29366 solver.cpp:237]     Train net output #0: loss = 0.00829728 (* 1 = 0.00829728 loss)
I0616 05:25:12.530997 29366 sgd_solver.cpp:105] Iteration 47550, lr = 0.01
I0616 05:26:10.262833 29366 solver.cpp:218] Iteration 47600 (0.866082 iter/s, 57.7313s/50 iters), loss = 0.0282562
I0616 05:26:10.263003 29366 solver.cpp:237]     Train net output #0: loss = 0.0282562 (* 1 = 0.0282562 loss)
I0616 05:26:10.263036 29366 sgd_solver.cpp:105] Iteration 47600, lr = 0.01
I0616 05:27:08.020081 29366 solver.cpp:218] Iteration 47650 (0.865703 iter/s, 57.7565s/50 iters), loss = 0.0159977
I0616 05:27:08.020258 29366 solver.cpp:237]     Train net output #0: loss = 0.0159977 (* 1 = 0.0159977 loss)
I0616 05:27:08.020294 29366 sgd_solver.cpp:105] Iteration 47650, lr = 0.01
I0616 05:28:05.731447 29366 solver.cpp:218] Iteration 47700 (0.866392 iter/s, 57.7106s/50 iters), loss = 0.0919007
I0616 05:28:05.731601 29366 solver.cpp:237]     Train net output #0: loss = 0.0919008 (* 1 = 0.0919008 loss)
I0616 05:28:05.731624 29366 sgd_solver.cpp:105] Iteration 47700, lr = 0.01
I0616 05:29:03.454078 29366 solver.cpp:218] Iteration 47750 (0.866222 iter/s, 57.7219s/50 iters), loss = 0.0183982
I0616 05:29:03.454212 29366 solver.cpp:237]     Train net output #0: loss = 0.0183983 (* 1 = 0.0183983 loss)
I0616 05:29:03.454236 29366 sgd_solver.cpp:105] Iteration 47750, lr = 0.01
I0616 05:30:01.190403 29366 solver.cpp:218] Iteration 47800 (0.866016 iter/s, 57.7356s/50 iters), loss = 0.0176705
I0616 05:30:01.190537 29366 solver.cpp:237]     Train net output #0: loss = 0.0176706 (* 1 = 0.0176706 loss)
I0616 05:30:01.190564 29366 sgd_solver.cpp:105] Iteration 47800, lr = 0.01
I0616 05:30:58.910116 29366 solver.cpp:218] Iteration 47850 (0.866266 iter/s, 57.719s/50 iters), loss = 0.0212027
I0616 05:30:58.910249 29366 solver.cpp:237]     Train net output #0: loss = 0.0212028 (* 1 = 0.0212028 loss)
I0616 05:30:58.910279 29366 sgd_solver.cpp:105] Iteration 47850, lr = 0.01
I0616 05:31:56.641826 29366 solver.cpp:218] Iteration 47900 (0.866086 iter/s, 57.731s/50 iters), loss = 0.00683742
I0616 05:31:56.641974 29366 solver.cpp:237]     Train net output #0: loss = 0.00683748 (* 1 = 0.00683748 loss)
I0616 05:31:56.641999 29366 sgd_solver.cpp:105] Iteration 47900, lr = 0.01
I0616 05:32:54.364490 29366 solver.cpp:218] Iteration 47950 (0.866222 iter/s, 57.7219s/50 iters), loss = 0.00723369
I0616 05:32:54.364634 29366 solver.cpp:237]     Train net output #0: loss = 0.00723375 (* 1 = 0.00723375 loss)
I0616 05:32:54.364660 29366 sgd_solver.cpp:105] Iteration 47950, lr = 0.01
I0616 05:33:52.086881 29366 solver.cpp:218] Iteration 48000 (0.866226 iter/s, 57.7216s/50 iters), loss = 0.00842457
I0616 05:33:52.087007 29366 solver.cpp:237]     Train net output #0: loss = 0.00842462 (* 1 = 0.00842462 loss)
I0616 05:33:52.087035 29366 sgd_solver.cpp:105] Iteration 48000, lr = 0.01
I0616 05:34:49.805284 29366 solver.cpp:218] Iteration 48050 (0.866286 iter/s, 57.7177s/50 iters), loss = 0.00543134
I0616 05:34:49.805444 29366 solver.cpp:237]     Train net output #0: loss = 0.0054314 (* 1 = 0.0054314 loss)
I0616 05:34:49.805467 29366 sgd_solver.cpp:105] Iteration 48050, lr = 0.01
I0616 05:35:47.525895 29366 solver.cpp:218] Iteration 48100 (0.866253 iter/s, 57.7199s/50 iters), loss = 0.00623229
I0616 05:35:47.526027 29366 solver.cpp:237]     Train net output #0: loss = 0.00623235 (* 1 = 0.00623235 loss)
I0616 05:35:47.526051 29366 sgd_solver.cpp:105] Iteration 48100, lr = 0.01
I0616 05:36:45.243978 29366 solver.cpp:218] Iteration 48150 (0.86629 iter/s, 57.7174s/50 iters), loss = 0.0137927
I0616 05:36:45.244097 29366 solver.cpp:237]     Train net output #0: loss = 0.0137927 (* 1 = 0.0137927 loss)
I0616 05:36:45.244122 29366 sgd_solver.cpp:105] Iteration 48150, lr = 0.01
I0616 05:37:42.965543 29366 solver.cpp:218] Iteration 48200 (0.866238 iter/s, 57.7208s/50 iters), loss = 0.0210317
I0616 05:37:42.965704 29366 solver.cpp:237]     Train net output #0: loss = 0.0210317 (* 1 = 0.0210317 loss)
I0616 05:37:42.965729 29366 sgd_solver.cpp:105] Iteration 48200, lr = 0.01
I0616 05:38:40.696796 29366 solver.cpp:218] Iteration 48250 (0.866093 iter/s, 57.7305s/50 iters), loss = 0.00923092
I0616 05:38:40.696936 29366 solver.cpp:237]     Train net output #0: loss = 0.00923097 (* 1 = 0.00923097 loss)
I0616 05:38:40.696961 29366 sgd_solver.cpp:105] Iteration 48250, lr = 0.01
I0616 05:39:38.430580 29366 solver.cpp:218] Iteration 48300 (0.866055 iter/s, 57.7331s/50 iters), loss = 0.00540296
I0616 05:39:38.430732 29366 solver.cpp:237]     Train net output #0: loss = 0.00540301 (* 1 = 0.00540301 loss)
I0616 05:39:38.430757 29366 sgd_solver.cpp:105] Iteration 48300, lr = 0.01
I0616 05:40:36.168402 29366 solver.cpp:218] Iteration 48350 (0.865995 iter/s, 57.7371s/50 iters), loss = 0.00776852
I0616 05:40:36.168634 29366 solver.cpp:237]     Train net output #0: loss = 0.00776857 (* 1 = 0.00776857 loss)
I0616 05:40:36.168660 29366 sgd_solver.cpp:105] Iteration 48350, lr = 0.01
I0616 05:41:33.910223 29366 solver.cpp:218] Iteration 48400 (0.865936 iter/s, 57.741s/50 iters), loss = 0.00325875
I0616 05:41:33.910370 29366 solver.cpp:237]     Train net output #0: loss = 0.00325879 (* 1 = 0.00325879 loss)
I0616 05:41:33.910393 29366 sgd_solver.cpp:105] Iteration 48400, lr = 0.01
I0616 05:42:31.644479 29366 solver.cpp:218] Iteration 48450 (0.866048 iter/s, 57.7335s/50 iters), loss = 0.00372252
I0616 05:42:31.644634 29366 solver.cpp:237]     Train net output #0: loss = 0.00372257 (* 1 = 0.00372257 loss)
I0616 05:42:31.644657 29366 sgd_solver.cpp:105] Iteration 48450, lr = 0.01
I0616 05:43:29.373497 29366 solver.cpp:218] Iteration 48500 (0.866127 iter/s, 57.7283s/50 iters), loss = 0.00638125
I0616 05:43:29.373628 29366 solver.cpp:237]     Train net output #0: loss = 0.00638131 (* 1 = 0.00638131 loss)
I0616 05:43:29.373652 29366 sgd_solver.cpp:105] Iteration 48500, lr = 0.01
I0616 05:44:27.122532 29366 solver.cpp:218] Iteration 48550 (0.865826 iter/s, 57.7483s/50 iters), loss = 0.00583822
I0616 05:44:27.122670 29366 solver.cpp:237]     Train net output #0: loss = 0.00583827 (* 1 = 0.00583827 loss)
I0616 05:44:27.122694 29366 sgd_solver.cpp:105] Iteration 48550, lr = 0.01
I0616 05:45:24.855720 29366 solver.cpp:218] Iteration 48600 (0.866064 iter/s, 57.7325s/50 iters), loss = 0.00497565
I0616 05:45:24.855891 29366 solver.cpp:237]     Train net output #0: loss = 0.0049757 (* 1 = 0.0049757 loss)
I0616 05:45:24.855916 29366 sgd_solver.cpp:105] Iteration 48600, lr = 0.01
I0616 05:46:22.592003 29366 solver.cpp:218] Iteration 48650 (0.866018 iter/s, 57.7355s/50 iters), loss = 0.00991555
I0616 05:46:22.592165 29366 solver.cpp:237]     Train net output #0: loss = 0.00991561 (* 1 = 0.00991561 loss)
I0616 05:46:22.592203 29366 sgd_solver.cpp:105] Iteration 48650, lr = 0.01
I0616 05:47:20.335687 29366 solver.cpp:218] Iteration 48700 (0.865907 iter/s, 57.7429s/50 iters), loss = 0.00322385
I0616 05:47:20.335856 29366 solver.cpp:237]     Train net output #0: loss = 0.00322391 (* 1 = 0.00322391 loss)
I0616 05:47:20.335881 29366 sgd_solver.cpp:105] Iteration 48700, lr = 0.01
I0616 05:48:18.085583 29366 solver.cpp:218] Iteration 48750 (0.865814 iter/s, 57.7491s/50 iters), loss = 0.0046146
I0616 05:48:18.085752 29366 solver.cpp:237]     Train net output #0: loss = 0.00461465 (* 1 = 0.00461465 loss)
I0616 05:48:18.085777 29366 sgd_solver.cpp:105] Iteration 48750, lr = 0.01
I0616 05:49:15.846701 29366 solver.cpp:218] Iteration 48800 (0.865645 iter/s, 57.7604s/50 iters), loss = 0.00419981
I0616 05:49:15.846887 29366 solver.cpp:237]     Train net output #0: loss = 0.00419986 (* 1 = 0.00419986 loss)
I0616 05:49:15.846911 29366 sgd_solver.cpp:105] Iteration 48800, lr = 0.01
I0616 05:50:13.615674 29366 solver.cpp:218] Iteration 48850 (0.865527 iter/s, 57.7683s/50 iters), loss = 0.00450324
I0616 05:50:13.615849 29366 solver.cpp:237]     Train net output #0: loss = 0.00450329 (* 1 = 0.00450329 loss)
I0616 05:50:13.615875 29366 sgd_solver.cpp:105] Iteration 48850, lr = 0.01
I0616 05:51:11.380833 29366 solver.cpp:218] Iteration 48900 (0.865584 iter/s, 57.7645s/50 iters), loss = 0.00423534
I0616 05:51:11.380987 29366 solver.cpp:237]     Train net output #0: loss = 0.00423539 (* 1 = 0.00423539 loss)
I0616 05:51:11.381011 29366 sgd_solver.cpp:105] Iteration 48900, lr = 0.01
I0616 05:52:09.146397 29366 solver.cpp:218] Iteration 48950 (0.865578 iter/s, 57.7649s/50 iters), loss = 0.00517792
I0616 05:52:09.146538 29366 solver.cpp:237]     Train net output #0: loss = 0.00517798 (* 1 = 0.00517798 loss)
I0616 05:52:09.146565 29366 sgd_solver.cpp:105] Iteration 48950, lr = 0.01
I0616 05:53:06.892643 29366 solver.cpp:218] Iteration 49000 (0.865867 iter/s, 57.7456s/50 iters), loss = 0.00421925
I0616 05:53:06.892894 29366 solver.cpp:237]     Train net output #0: loss = 0.00421931 (* 1 = 0.00421931 loss)
I0616 05:53:06.892938 29366 sgd_solver.cpp:105] Iteration 49000, lr = 0.01
I0616 05:54:04.661092 29366 solver.cpp:218] Iteration 49050 (0.865536 iter/s, 57.7677s/50 iters), loss = 0.00432608
I0616 05:54:04.661269 29366 solver.cpp:237]     Train net output #0: loss = 0.00432614 (* 1 = 0.00432614 loss)
I0616 05:54:04.661294 29366 sgd_solver.cpp:105] Iteration 49050, lr = 0.01
I0616 05:55:02.426393 29366 solver.cpp:218] Iteration 49100 (0.865582 iter/s, 57.7646s/50 iters), loss = 0.00809502
I0616 05:55:02.426607 29366 solver.cpp:237]     Train net output #0: loss = 0.00809508 (* 1 = 0.00809508 loss)
I0616 05:55:02.426633 29366 sgd_solver.cpp:105] Iteration 49100, lr = 0.01
I0616 05:56:00.188877 29366 solver.cpp:218] Iteration 49150 (0.865625 iter/s, 57.7617s/50 iters), loss = 0.00364068
I0616 05:56:00.189029 29366 solver.cpp:237]     Train net output #0: loss = 0.00364074 (* 1 = 0.00364074 loss)
I0616 05:56:00.189057 29366 sgd_solver.cpp:105] Iteration 49150, lr = 0.01
I0616 05:56:57.958796 29366 solver.cpp:218] Iteration 49200 (0.865513 iter/s, 57.7692s/50 iters), loss = 0.00868729
I0616 05:56:57.958974 29366 solver.cpp:237]     Train net output #0: loss = 0.00868734 (* 1 = 0.00868734 loss)
I0616 05:56:57.958999 29366 sgd_solver.cpp:105] Iteration 49200, lr = 0.01
I0616 05:57:55.679884 29366 solver.cpp:218] Iteration 49250 (0.866245 iter/s, 57.7204s/50 iters), loss = 0.00504941
I0616 05:57:55.680057 29366 solver.cpp:237]     Train net output #0: loss = 0.00504947 (* 1 = 0.00504947 loss)
I0616 05:57:55.680079 29366 sgd_solver.cpp:105] Iteration 49250, lr = 0.01
I0616 05:58:53.394047 29366 solver.cpp:218] Iteration 49300 (0.866349 iter/s, 57.7135s/50 iters), loss = 0.00350894
I0616 05:58:53.394182 29366 solver.cpp:237]     Train net output #0: loss = 0.003509 (* 1 = 0.003509 loss)
I0616 05:58:53.394207 29366 sgd_solver.cpp:105] Iteration 49300, lr = 0.01
I0616 05:59:51.113961 29366 solver.cpp:218] Iteration 49350 (0.866262 iter/s, 57.7193s/50 iters), loss = 0.00343036
I0616 05:59:51.114082 29366 solver.cpp:237]     Train net output #0: loss = 0.00343042 (* 1 = 0.00343042 loss)
I0616 05:59:51.114107 29366 sgd_solver.cpp:105] Iteration 49350, lr = 0.01
I0616 06:00:48.840854 29366 solver.cpp:218] Iteration 49400 (0.866157 iter/s, 57.7263s/50 iters), loss = 0.00397363
I0616 06:00:48.840983 29366 solver.cpp:237]     Train net output #0: loss = 0.00397369 (* 1 = 0.00397369 loss)
I0616 06:00:48.841008 29366 sgd_solver.cpp:105] Iteration 49400, lr = 0.01
I0616 06:01:46.565798 29366 solver.cpp:218] Iteration 49450 (0.866186 iter/s, 57.7243s/50 iters), loss = 0.00603749
I0616 06:01:46.568580 29366 solver.cpp:237]     Train net output #0: loss = 0.00603754 (* 1 = 0.00603754 loss)
I0616 06:01:46.568604 29366 sgd_solver.cpp:105] Iteration 49450, lr = 0.01
I0616 06:02:44.294047 29366 solver.cpp:218] Iteration 49500 (0.866177 iter/s, 57.7249s/50 iters), loss = 0.00529632
I0616 06:02:44.294145 29366 solver.cpp:237]     Train net output #0: loss = 0.00529638 (* 1 = 0.00529638 loss)
I0616 06:02:44.294167 29366 sgd_solver.cpp:105] Iteration 49500, lr = 0.01
I0616 06:03:42.017748 29366 solver.cpp:218] Iteration 49550 (0.866205 iter/s, 57.7231s/50 iters), loss = 0.00517646
I0616 06:03:42.017894 29366 solver.cpp:237]     Train net output #0: loss = 0.00517651 (* 1 = 0.00517651 loss)
I0616 06:03:42.017925 29366 sgd_solver.cpp:105] Iteration 49550, lr = 0.01
I0616 06:04:39.741351 29366 solver.cpp:218] Iteration 49600 (0.866207 iter/s, 57.7229s/50 iters), loss = 0.00357146
I0616 06:04:39.741500 29366 solver.cpp:237]     Train net output #0: loss = 0.00357151 (* 1 = 0.00357151 loss)
I0616 06:04:39.741533 29366 sgd_solver.cpp:105] Iteration 49600, lr = 0.01
I0616 06:05:37.463119 29366 solver.cpp:218] Iteration 49650 (0.866234 iter/s, 57.7211s/50 iters), loss = 0.00379389
I0616 06:05:37.463254 29366 solver.cpp:237]     Train net output #0: loss = 0.00379395 (* 1 = 0.00379395 loss)
I0616 06:05:37.463279 29366 sgd_solver.cpp:105] Iteration 49650, lr = 0.01
I0616 06:06:35.194371 29366 solver.cpp:218] Iteration 49700 (0.866092 iter/s, 57.7306s/50 iters), loss = 0.0122504
I0616 06:06:35.194555 29366 solver.cpp:237]     Train net output #0: loss = 0.0122505 (* 1 = 0.0122505 loss)
I0616 06:06:35.194581 29366 sgd_solver.cpp:105] Iteration 49700, lr = 0.01
I0616 06:07:32.929280 29366 solver.cpp:218] Iteration 49750 (0.866038 iter/s, 57.7342s/50 iters), loss = 0.00600071
I0616 06:07:32.929440 29366 solver.cpp:237]     Train net output #0: loss = 0.00600076 (* 1 = 0.00600076 loss)
I0616 06:07:32.929471 29366 sgd_solver.cpp:105] Iteration 49750, lr = 0.01
I0616 06:08:30.675459 29366 solver.cpp:218] Iteration 49800 (0.865869 iter/s, 57.7455s/50 iters), loss = 0.00339591
I0616 06:08:30.675629 29366 solver.cpp:237]     Train net output #0: loss = 0.00339597 (* 1 = 0.00339597 loss)
I0616 06:08:30.675654 29366 sgd_solver.cpp:105] Iteration 49800, lr = 0.01
I0616 06:09:28.419123 29366 solver.cpp:218] Iteration 49850 (0.865906 iter/s, 57.743s/50 iters), loss = 0.00518709
I0616 06:09:28.419275 29366 solver.cpp:237]     Train net output #0: loss = 0.00518714 (* 1 = 0.00518714 loss)
I0616 06:09:28.419298 29366 sgd_solver.cpp:105] Iteration 49850, lr = 0.01
I0616 06:10:26.157281 29366 solver.cpp:218] Iteration 49900 (0.865989 iter/s, 57.7375s/50 iters), loss = 0.00290414
I0616 06:10:26.157426 29366 solver.cpp:237]     Train net output #0: loss = 0.00290419 (* 1 = 0.00290419 loss)
I0616 06:10:26.157456 29366 sgd_solver.cpp:105] Iteration 49900, lr = 0.01
I0616 06:11:23.909525 29366 solver.cpp:218] Iteration 49950 (0.865777 iter/s, 57.7516s/50 iters), loss = 0.0101839
I0616 06:11:23.909667 29366 solver.cpp:237]     Train net output #0: loss = 0.0101839 (* 1 = 0.0101839 loss)
I0616 06:11:23.909688 29366 sgd_solver.cpp:105] Iteration 49950, lr = 0.01
I0616 06:12:20.504920 29366 solver.cpp:447] Snapshotting to binary proto file mobilenet/mobile_2_iter_50000.caffemodel
I0616 06:12:20.589273 29366 sgd_solver.cpp:273] Snapshotting solver state to binary proto file mobilenet/mobile_2_iter_50000.solverstate
I0616 06:12:21.770336 29366 solver.cpp:218] Iteration 50000 (0.864153 iter/s, 57.8601s/50 iters), loss = 0.0268194
I0616 06:12:21.770438 29366 solver.cpp:237]     Train net output #0: loss = 0.0268194 (* 1 = 0.0268194 loss)
I0616 06:12:21.770459 29366 sgd_solver.cpp:105] Iteration 50000, lr = 0.001
I0616 06:13:19.504498 29366 solver.cpp:218] Iteration 50050 (0.866048 iter/s, 57.7335s/50 iters), loss = 0.0192707
I0616 06:13:19.504765 29366 solver.cpp:237]     Train net output #0: loss = 0.0192708 (* 1 = 0.0192708 loss)
I0616 06:13:19.504788 29366 sgd_solver.cpp:105] Iteration 50050, lr = 0.001
I0616 06:14:17.237185 29366 solver.cpp:218] Iteration 50100 (0.866073 iter/s, 57.7319s/50 iters), loss = 0.00706846
I0616 06:14:17.237336 29366 solver.cpp:237]     Train net output #0: loss = 0.00706852 (* 1 = 0.00706852 loss)
I0616 06:14:17.237367 29366 sgd_solver.cpp:105] Iteration 50100, lr = 0.001
I0616 06:15:14.977927 29366 solver.cpp:218] Iteration 50150 (0.86595 iter/s, 57.7401s/50 iters), loss = 0.0100166
I0616 06:15:14.978063 29366 solver.cpp:237]     Train net output #0: loss = 0.0100166 (* 1 = 0.0100166 loss)
I0616 06:15:14.978088 29366 sgd_solver.cpp:105] Iteration 50150, lr = 0.001
I0616 06:16:12.729228 29366 solver.cpp:218] Iteration 50200 (0.865791 iter/s, 57.7506s/50 iters), loss = 0.00613767
I0616 06:16:12.729621 29366 solver.cpp:237]     Train net output #0: loss = 0.00613773 (* 1 = 0.00613773 loss)
I0616 06:16:12.729646 29366 sgd_solver.cpp:105] Iteration 50200, lr = 0.001
I0616 06:17:10.461194 29366 solver.cpp:218] Iteration 50250 (0.866085 iter/s, 57.731s/50 iters), loss = 0.0114768
I0616 06:17:10.461330 29366 solver.cpp:237]     Train net output #0: loss = 0.0114768 (* 1 = 0.0114768 loss)
I0616 06:17:10.461354 29366 sgd_solver.cpp:105] Iteration 50250, lr = 0.001
I0616 06:18:08.189497 29366 solver.cpp:218] Iteration 50300 (0.866136 iter/s, 57.7276s/50 iters), loss = 0.00541912
I0616 06:18:08.189635 29366 solver.cpp:237]     Train net output #0: loss = 0.00541917 (* 1 = 0.00541917 loss)
I0616 06:18:08.189658 29366 sgd_solver.cpp:105] Iteration 50300, lr = 0.001
I0616 06:19:05.918761 29366 solver.cpp:218] Iteration 50350 (0.866122 iter/s, 57.7286s/50 iters), loss = 0.00604828
I0616 06:19:05.918980 29366 solver.cpp:237]     Train net output #0: loss = 0.00604834 (* 1 = 0.00604834 loss)
I0616 06:19:05.919004 29366 sgd_solver.cpp:105] Iteration 50350, lr = 0.001
I0616 06:20:03.641705 29366 solver.cpp:218] Iteration 50400 (0.866218 iter/s, 57.7222s/50 iters), loss = 0.00743347
I0616 06:20:03.650588 29366 solver.cpp:237]     Train net output #0: loss = 0.00743353 (* 1 = 0.00743353 loss)
I0616 06:20:03.650612 29366 sgd_solver.cpp:105] Iteration 50400, lr = 0.001
I0616 06:21:01.365183 29366 solver.cpp:218] Iteration 50450 (0.86634 iter/s, 57.7141s/50 iters), loss = 0.00981561
I0616 06:21:01.365331 29366 solver.cpp:237]     Train net output #0: loss = 0.00981566 (* 1 = 0.00981566 loss)
I0616 06:21:01.365362 29366 sgd_solver.cpp:105] Iteration 50450, lr = 0.001
I0616 06:21:59.087893 29366 solver.cpp:218] Iteration 50500 (0.86622 iter/s, 57.722s/50 iters), loss = 0.00981917
I0616 06:21:59.088037 29366 solver.cpp:237]     Train net output #0: loss = 0.00981923 (* 1 = 0.00981923 loss)
I0616 06:21:59.088062 29366 sgd_solver.cpp:105] Iteration 50500, lr = 0.001
I0616 06:22:56.817951 29366 solver.cpp:218] Iteration 50550 (0.86611 iter/s, 57.7294s/50 iters), loss = 0.00583209
I0616 06:22:56.818114 29366 solver.cpp:237]     Train net output #0: loss = 0.00583214 (* 1 = 0.00583214 loss)
I0616 06:22:56.818138 29366 sgd_solver.cpp:105] Iteration 50550, lr = 0.001
I0616 06:23:54.540101 29366 solver.cpp:218] Iteration 50600 (0.86623 iter/s, 57.7214s/50 iters), loss = 0.00530162
I0616 06:23:54.540230 29366 solver.cpp:237]     Train net output #0: loss = 0.00530167 (* 1 = 0.00530167 loss)
I0616 06:23:54.540256 29366 sgd_solver.cpp:105] Iteration 50600, lr = 0.001
I0616 06:24:52.265601 29366 solver.cpp:218] Iteration 50650 (0.866179 iter/s, 57.7248s/50 iters), loss = 0.00401071
I0616 06:24:52.265735 29366 solver.cpp:237]     Train net output #0: loss = 0.00401076 (* 1 = 0.00401076 loss)
I0616 06:24:52.265763 29366 sgd_solver.cpp:105] Iteration 50650, lr = 0.001
I0616 06:25:49.996642 29366 solver.cpp:218] Iteration 50700 (0.866096 iter/s, 57.7303s/50 iters), loss = 0.00484219
I0616 06:25:49.996799 29366 solver.cpp:237]     Train net output #0: loss = 0.00484224 (* 1 = 0.00484224 loss)
I0616 06:25:49.996824 29366 sgd_solver.cpp:105] Iteration 50700, lr = 0.001
I0616 06:26:47.714926 29366 solver.cpp:218] Iteration 50750 (0.866288 iter/s, 57.7175s/50 iters), loss = 0.00566639
I0616 06:26:47.715095 29366 solver.cpp:237]     Train net output #0: loss = 0.00566644 (* 1 = 0.00566644 loss)
I0616 06:26:47.715117 29366 sgd_solver.cpp:105] Iteration 50750, lr = 0.001
I0616 06:27:45.447458 29366 solver.cpp:218] Iteration 50800 (0.866074 iter/s, 57.7318s/50 iters), loss = 0.0091004
I0616 06:27:45.447600 29366 solver.cpp:237]     Train net output #0: loss = 0.00910045 (* 1 = 0.00910045 loss)
I0616 06:27:45.447625 29366 sgd_solver.cpp:105] Iteration 50800, lr = 0.001
I0616 06:28:43.181666 29366 solver.cpp:218] Iteration 50850 (0.866049 iter/s, 57.7335s/50 iters), loss = 0.00930892
I0616 06:28:43.181798 29366 solver.cpp:237]     Train net output #0: loss = 0.00930898 (* 1 = 0.00930898 loss)
I0616 06:28:43.181823 29366 sgd_solver.cpp:105] Iteration 50850, lr = 0.001
I0616 06:29:40.913967 29366 solver.cpp:218] Iteration 50900 (0.866077 iter/s, 57.7316s/50 iters), loss = 0.00487199
I0616 06:29:40.914117 29366 solver.cpp:237]     Train net output #0: loss = 0.00487205 (* 1 = 0.00487205 loss)
I0616 06:29:40.914147 29366 sgd_solver.cpp:105] Iteration 50900, lr = 0.001
I0616 06:30:38.653692 29366 solver.cpp:218] Iteration 50950 (0.865966 iter/s, 57.739s/50 iters), loss = 0.0037559
I0616 06:30:38.653836 29366 solver.cpp:237]     Train net output #0: loss = 0.00375596 (* 1 = 0.00375596 loss)
I0616 06:30:38.653861 29366 sgd_solver.cpp:105] Iteration 50950, lr = 0.001
I0616 06:31:36.381287 29366 solver.cpp:218] Iteration 51000 (0.866148 iter/s, 57.7269s/50 iters), loss = 0.00502998
I0616 06:31:36.381474 29366 solver.cpp:237]     Train net output #0: loss = 0.00503003 (* 1 = 0.00503003 loss)
I0616 06:31:36.381510 29366 sgd_solver.cpp:105] Iteration 51000, lr = 0.001
I0616 06:32:34.097451 29366 solver.cpp:218] Iteration 51050 (0.86632 iter/s, 57.7154s/50 iters), loss = 0.00607166
I0616 06:32:34.097592 29366 solver.cpp:237]     Train net output #0: loss = 0.00607172 (* 1 = 0.00607172 loss)
I0616 06:32:34.097621 29366 sgd_solver.cpp:105] Iteration 51050, lr = 0.001
I0616 06:33:31.830399 29366 solver.cpp:218] Iteration 51100 (0.866068 iter/s, 57.7322s/50 iters), loss = 0.00903454
I0616 06:33:31.830550 29366 solver.cpp:237]     Train net output #0: loss = 0.0090346 (* 1 = 0.0090346 loss)
I0616 06:33:31.830576 29366 sgd_solver.cpp:105] Iteration 51100, lr = 0.001
I0616 06:34:29.559042 29366 solver.cpp:218] Iteration 51150 (0.866132 iter/s, 57.7279s/50 iters), loss = 0.00549444
I0616 06:34:29.559171 29366 solver.cpp:237]     Train net output #0: loss = 0.0054945 (* 1 = 0.0054945 loss)
I0616 06:34:29.559196 29366 sgd_solver.cpp:105] Iteration 51150, lr = 0.001
I0616 06:35:27.287992 29366 solver.cpp:218] Iteration 51200 (0.866127 iter/s, 57.7282s/50 iters), loss = 0.00560143
I0616 06:35:27.288128 29366 solver.cpp:237]     Train net output #0: loss = 0.00560148 (* 1 = 0.00560148 loss)
I0616 06:35:27.288153 29366 sgd_solver.cpp:105] Iteration 51200, lr = 0.001
I0616 06:36:25.016829 29366 solver.cpp:218] Iteration 51250 (0.866129 iter/s, 57.7281s/50 iters), loss = 0.00761885
I0616 06:36:25.016970 29366 solver.cpp:237]     Train net output #0: loss = 0.0076189 (* 1 = 0.0076189 loss)
I0616 06:36:25.016995 29366 sgd_solver.cpp:105] Iteration 51250, lr = 0.001
I0616 06:37:22.755962 29366 solver.cpp:218] Iteration 51300 (0.865975 iter/s, 57.7384s/50 iters), loss = 0.005344
I0616 06:37:22.756108 29366 solver.cpp:237]     Train net output #0: loss = 0.00534406 (* 1 = 0.00534406 loss)
I0616 06:37:22.756132 29366 sgd_solver.cpp:105] Iteration 51300, lr = 0.001
I0616 06:38:20.505581 29366 solver.cpp:218] Iteration 51350 (0.865818 iter/s, 57.7489s/50 iters), loss = 0.0068512
I0616 06:38:20.505725 29366 solver.cpp:237]     Train net output #0: loss = 0.00685125 (* 1 = 0.00685125 loss)
I0616 06:38:20.505750 29366 sgd_solver.cpp:105] Iteration 51350, lr = 0.001
I0616 06:39:18.241785 29366 solver.cpp:218] Iteration 51400 (0.866019 iter/s, 57.7355s/50 iters), loss = 0.00494143
I0616 06:39:18.241930 29366 solver.cpp:237]     Train net output #0: loss = 0.00494149 (* 1 = 0.00494149 loss)
I0616 06:39:18.241953 29366 sgd_solver.cpp:105] Iteration 51400, lr = 0.001
I0616 06:40:15.974967 29366 solver.cpp:218] Iteration 51450 (0.866064 iter/s, 57.7324s/50 iters), loss = 0.00271127
I0616 06:40:15.976347 29366 solver.cpp:237]     Train net output #0: loss = 0.00271132 (* 1 = 0.00271132 loss)
I0616 06:40:15.976372 29366 sgd_solver.cpp:105] Iteration 51450, lr = 0.001
I0616 06:41:13.735133 29366 solver.cpp:218] Iteration 51500 (0.865679 iter/s, 57.7581s/50 iters), loss = 0.00406661
I0616 06:41:13.735306 29366 solver.cpp:237]     Train net output #0: loss = 0.00406667 (* 1 = 0.00406667 loss)
I0616 06:41:13.735337 29366 sgd_solver.cpp:105] Iteration 51500, lr = 0.001
I0616 06:42:11.475195 29366 solver.cpp:218] Iteration 51550 (0.865961 iter/s, 57.7393s/50 iters), loss = 0.00494635
I0616 06:42:11.475347 29366 solver.cpp:237]     Train net output #0: loss = 0.0049464 (* 1 = 0.0049464 loss)
I0616 06:42:11.475371 29366 sgd_solver.cpp:105] Iteration 51550, lr = 0.001
I0616 06:43:09.206411 29366 solver.cpp:218] Iteration 51600 (0.866094 iter/s, 57.7305s/50 iters), loss = 0.00647682
I0616 06:43:09.206531 29366 solver.cpp:237]     Train net output #0: loss = 0.00647687 (* 1 = 0.00647687 loss)
I0616 06:43:09.206555 29366 sgd_solver.cpp:105] Iteration 51600, lr = 0.001
I0616 06:44:06.951843 29366 solver.cpp:218] Iteration 51650 (0.86588 iter/s, 57.7447s/50 iters), loss = 0.00604265
I0616 06:44:06.951964 29366 solver.cpp:237]     Train net output #0: loss = 0.00604271 (* 1 = 0.00604271 loss)
I0616 06:44:06.951995 29366 sgd_solver.cpp:105] Iteration 51650, lr = 0.001
I0616 06:45:04.700510 29366 solver.cpp:218] Iteration 51700 (0.865832 iter/s, 57.7479s/50 iters), loss = 0.00795928
I0616 06:45:04.700938 29366 solver.cpp:237]     Train net output #0: loss = 0.00795933 (* 1 = 0.00795933 loss)
I0616 06:45:04.700963 29366 sgd_solver.cpp:105] Iteration 51700, lr = 0.001
I0616 06:46:02.446447 29366 solver.cpp:218] Iteration 51750 (0.865878 iter/s, 57.7449s/50 iters), loss = 0.00449356
I0616 06:46:02.446614 29366 solver.cpp:237]     Train net output #0: loss = 0.00449361 (* 1 = 0.00449361 loss)
I0616 06:46:02.446640 29366 sgd_solver.cpp:105] Iteration 51750, lr = 0.001
I0616 06:47:00.189568 29366 solver.cpp:218] Iteration 51800 (0.865915 iter/s, 57.7424s/50 iters), loss = 0.0047784
I0616 06:47:00.189703 29366 solver.cpp:237]     Train net output #0: loss = 0.00477846 (* 1 = 0.00477846 loss)
I0616 06:47:00.189726 29366 sgd_solver.cpp:105] Iteration 51800, lr = 0.001
I0616 06:47:57.917316 29366 solver.cpp:218] Iteration 51850 (0.866145 iter/s, 57.727s/50 iters), loss = 0.00409617
I0616 06:47:57.917469 29366 solver.cpp:237]     Train net output #0: loss = 0.00409622 (* 1 = 0.00409622 loss)
I0616 06:47:57.917496 29366 sgd_solver.cpp:105] Iteration 51850, lr = 0.001
I0616 06:48:55.648636 29366 solver.cpp:218] Iteration 51900 (0.866092 iter/s, 57.7306s/50 iters), loss = 0.00651809
I0616 06:48:55.648825 29366 solver.cpp:237]     Train net output #0: loss = 0.00651814 (* 1 = 0.00651814 loss)
I0616 06:48:55.648859 29366 sgd_solver.cpp:105] Iteration 51900, lr = 0.001
I0616 06:49:53.380491 29366 solver.cpp:218] Iteration 51950 (0.866085 iter/s, 57.7311s/50 iters), loss = 0.00412513
I0616 06:49:53.380636 29366 solver.cpp:237]     Train net output #0: loss = 0.00412518 (* 1 = 0.00412518 loss)
I0616 06:49:53.380661 29366 sgd_solver.cpp:105] Iteration 51950, lr = 0.001
I0616 06:50:51.108330 29366 solver.cpp:218] Iteration 52000 (0.866144 iter/s, 57.7271s/50 iters), loss = 0.00332802
I0616 06:50:51.108464 29366 solver.cpp:237]     Train net output #0: loss = 0.00332807 (* 1 = 0.00332807 loss)
I0616 06:50:51.108489 29366 sgd_solver.cpp:105] Iteration 52000, lr = 0.001
I0616 06:51:48.833869 29366 solver.cpp:218] Iteration 52050 (0.866179 iter/s, 57.7248s/50 iters), loss = 0.00444905
I0616 06:51:48.833966 29366 solver.cpp:237]     Train net output #0: loss = 0.0044491 (* 1 = 0.0044491 loss)
I0616 06:51:48.833987 29366 sgd_solver.cpp:105] Iteration 52050, lr = 0.001
I0616 06:52:46.561075 29366 solver.cpp:218] Iteration 52100 (0.866153 iter/s, 57.7265s/50 iters), loss = 0.00833519
I0616 06:52:46.561215 29366 solver.cpp:237]     Train net output #0: loss = 0.00833524 (* 1 = 0.00833524 loss)
I0616 06:52:46.561239 29366 sgd_solver.cpp:105] Iteration 52100, lr = 0.001
I0616 06:53:44.292644 29366 solver.cpp:218] Iteration 52150 (0.866088 iter/s, 57.7308s/50 iters), loss = 0.00544886
I0616 06:53:44.292778 29366 solver.cpp:237]     Train net output #0: loss = 0.00544891 (* 1 = 0.00544891 loss)
I0616 06:53:44.292801 29366 sgd_solver.cpp:105] Iteration 52150, lr = 0.001
I0616 06:54:42.024821 29366 solver.cpp:218] Iteration 52200 (0.866079 iter/s, 57.7315s/50 iters), loss = 0.00468937
I0616 06:54:42.024950 29366 solver.cpp:237]     Train net output #0: loss = 0.00468943 (* 1 = 0.00468943 loss)
I0616 06:54:42.024974 29366 sgd_solver.cpp:105] Iteration 52200, lr = 0.001
I0616 06:55:39.749804 29366 solver.cpp:218] Iteration 52250 (0.866187 iter/s, 57.7243s/50 iters), loss = 0.00597236
I0616 06:55:39.749938 29366 solver.cpp:237]     Train net output #0: loss = 0.00597242 (* 1 = 0.00597242 loss)
I0616 06:55:39.749963 29366 sgd_solver.cpp:105] Iteration 52250, lr = 0.001
I0616 06:56:37.458618 29366 solver.cpp:218] Iteration 52300 (0.86643 iter/s, 57.7081s/50 iters), loss = 0.00478218
I0616 06:56:37.458737 29366 solver.cpp:237]     Train net output #0: loss = 0.00478223 (* 1 = 0.00478223 loss)
I0616 06:56:37.458762 29366 sgd_solver.cpp:105] Iteration 52300, lr = 0.001
I0616 06:57:35.192145 29366 solver.cpp:218] Iteration 52350 (0.866058 iter/s, 57.7328s/50 iters), loss = 0.00705509
I0616 06:57:35.192348 29366 solver.cpp:237]     Train net output #0: loss = 0.00705515 (* 1 = 0.00705515 loss)
I0616 06:57:35.192383 29366 sgd_solver.cpp:105] Iteration 52350, lr = 0.001
I0616 06:58:32.920100 29366 solver.cpp:218] Iteration 52400 (0.866143 iter/s, 57.7272s/50 iters), loss = 0.00547362
I0616 06:58:32.920245 29366 solver.cpp:237]     Train net output #0: loss = 0.00547367 (* 1 = 0.00547367 loss)
I0616 06:58:32.920276 29366 sgd_solver.cpp:105] Iteration 52400, lr = 0.001
I0616 06:59:30.647929 29366 solver.cpp:218] Iteration 52450 (0.866144 iter/s, 57.7271s/50 iters), loss = 0.00684079
I0616 06:59:30.648080 29366 solver.cpp:237]     Train net output #0: loss = 0.00684084 (* 1 = 0.00684084 loss)
I0616 06:59:30.648105 29366 sgd_solver.cpp:105] Iteration 52450, lr = 0.001
I0616 07:00:28.373745 29366 solver.cpp:218] Iteration 52500 (0.866174 iter/s, 57.7251s/50 iters), loss = 0.00512407
I0616 07:00:28.373883 29366 solver.cpp:237]     Train net output #0: loss = 0.00512413 (* 1 = 0.00512413 loss)
I0616 07:00:28.373905 29366 sgd_solver.cpp:105] Iteration 52500, lr = 0.001
I0616 07:01:26.099265 29366 solver.cpp:218] Iteration 52550 (0.866179 iter/s, 57.7248s/50 iters), loss = 0.00557505
I0616 07:01:26.099383 29366 solver.cpp:237]     Train net output #0: loss = 0.00557511 (* 1 = 0.00557511 loss)
I0616 07:01:26.099407 29366 sgd_solver.cpp:105] Iteration 52550, lr = 0.001
I0616 07:02:23.851676 29366 solver.cpp:218] Iteration 52600 (0.865776 iter/s, 57.7517s/50 iters), loss = 0.00499367
I0616 07:02:23.851853 29366 solver.cpp:237]     Train net output #0: loss = 0.00499373 (* 1 = 0.00499373 loss)
I0616 07:02:23.851881 29366 sgd_solver.cpp:105] Iteration 52600, lr = 0.001
I0616 07:03:21.598954 29366 solver.cpp:218] Iteration 52650 (0.865853 iter/s, 57.7465s/50 iters), loss = 0.00405726
I0616 07:03:21.599092 29366 solver.cpp:237]     Train net output #0: loss = 0.00405731 (* 1 = 0.00405731 loss)
I0616 07:03:21.599117 29366 sgd_solver.cpp:105] Iteration 52650, lr = 0.001
I0616 07:04:19.344630 29366 solver.cpp:218] Iteration 52700 (0.865877 iter/s, 57.7449s/50 iters), loss = 0.0042351
I0616 07:04:19.344805 29366 solver.cpp:237]     Train net output #0: loss = 0.00423516 (* 1 = 0.00423516 loss)
I0616 07:04:19.344830 29366 sgd_solver.cpp:105] Iteration 52700, lr = 0.001
I0616 07:05:17.092427 29366 solver.cpp:218] Iteration 52750 (0.865845 iter/s, 57.747s/50 iters), loss = 0.00665877
I0616 07:05:17.092566 29366 solver.cpp:237]     Train net output #0: loss = 0.00665883 (* 1 = 0.00665883 loss)
I0616 07:05:17.092592 29366 sgd_solver.cpp:105] Iteration 52750, lr = 0.001
I0616 07:06:14.837815 29366 solver.cpp:218] Iteration 52800 (0.865881 iter/s, 57.7447s/50 iters), loss = 0.00851359
I0616 07:06:14.837957 29366 solver.cpp:237]     Train net output #0: loss = 0.00851365 (* 1 = 0.00851365 loss)
I0616 07:06:14.837981 29366 sgd_solver.cpp:105] Iteration 52800, lr = 0.001
I0616 07:07:12.589439 29366 solver.cpp:218] Iteration 52850 (0.865787 iter/s, 57.7509s/50 iters), loss = 0.00472309
I0616 07:07:12.589570 29366 solver.cpp:237]     Train net output #0: loss = 0.00472314 (* 1 = 0.00472314 loss)
I0616 07:07:12.589592 29366 sgd_solver.cpp:105] Iteration 52850, lr = 0.001
I0616 07:08:10.306133 29366 solver.cpp:218] Iteration 52900 (0.866311 iter/s, 57.716s/50 iters), loss = 0.0070741
I0616 07:08:10.306257 29366 solver.cpp:237]     Train net output #0: loss = 0.00707415 (* 1 = 0.00707415 loss)
I0616 07:08:10.306282 29366 sgd_solver.cpp:105] Iteration 52900, lr = 0.001
I0616 07:09:08.028676 29366 solver.cpp:218] Iteration 52950 (0.866223 iter/s, 57.7218s/50 iters), loss = 0.00523835
I0616 07:09:08.028805 29366 solver.cpp:237]     Train net output #0: loss = 0.00523841 (* 1 = 0.00523841 loss)
I0616 07:09:08.028830 29366 sgd_solver.cpp:105] Iteration 52950, lr = 0.001
I0616 07:10:05.743221 29366 solver.cpp:218] Iteration 53000 (0.866343 iter/s, 57.7138s/50 iters), loss = 0.00551364
I0616 07:10:05.743358 29366 solver.cpp:237]     Train net output #0: loss = 0.0055137 (* 1 = 0.0055137 loss)
I0616 07:10:05.743384 29366 sgd_solver.cpp:105] Iteration 53000, lr = 0.001
I0616 07:11:03.477164 29366 solver.cpp:218] Iteration 53050 (0.866052 iter/s, 57.7332s/50 iters), loss = 0.0055081
I0616 07:11:03.477358 29366 solver.cpp:237]     Train net output #0: loss = 0.00550815 (* 1 = 0.00550815 loss)
I0616 07:11:03.477382 29366 sgd_solver.cpp:105] Iteration 53050, lr = 0.001
I0616 07:12:01.199328 29366 solver.cpp:218] Iteration 53100 (0.86623 iter/s, 57.7214s/50 iters), loss = 0.00857362
I0616 07:12:01.199470 29366 solver.cpp:237]     Train net output #0: loss = 0.00857367 (* 1 = 0.00857367 loss)
I0616 07:12:01.199492 29366 sgd_solver.cpp:105] Iteration 53100, lr = 0.001
I0616 07:12:58.914299 29366 solver.cpp:218] Iteration 53150 (0.866337 iter/s, 57.7143s/50 iters), loss = 0.00382335
I0616 07:12:58.914428 29366 solver.cpp:237]     Train net output #0: loss = 0.0038234 (* 1 = 0.0038234 loss)
I0616 07:12:58.914451 29366 sgd_solver.cpp:105] Iteration 53150, lr = 0.001
I0616 07:13:56.642091 29366 solver.cpp:218] Iteration 53200 (0.866145 iter/s, 57.7271s/50 iters), loss = 0.0061843
I0616 07:13:56.642233 29366 solver.cpp:237]     Train net output #0: loss = 0.00618435 (* 1 = 0.00618435 loss)
I0616 07:13:56.642258 29366 sgd_solver.cpp:105] Iteration 53200, lr = 0.001
I0616 07:14:54.367306 29366 solver.cpp:218] Iteration 53250 (0.866183 iter/s, 57.7245s/50 iters), loss = 0.00452607
I0616 07:14:54.367449 29366 solver.cpp:237]     Train net output #0: loss = 0.00452613 (* 1 = 0.00452613 loss)
I0616 07:14:54.367473 29366 sgd_solver.cpp:105] Iteration 53250, lr = 0.001
I0616 07:15:52.099496 29366 solver.cpp:218] Iteration 53300 (0.866077 iter/s, 57.7316s/50 iters), loss = 0.00571462
I0616 07:15:52.099629 29366 solver.cpp:237]     Train net output #0: loss = 0.00571467 (* 1 = 0.00571467 loss)
I0616 07:15:52.099654 29366 sgd_solver.cpp:105] Iteration 53300, lr = 0.001
I0616 07:16:49.821925 29366 solver.cpp:218] Iteration 53350 (0.866224 iter/s, 57.7218s/50 iters), loss = 0.00732292
I0616 07:16:49.822095 29366 solver.cpp:237]     Train net output #0: loss = 0.00732298 (* 1 = 0.00732298 loss)
I0616 07:16:49.822127 29366 sgd_solver.cpp:105] Iteration 53350, lr = 0.001
I0616 07:17:47.539502 29366 solver.cpp:218] Iteration 53400 (0.866297 iter/s, 57.7169s/50 iters), loss = 0.00607898
I0616 07:17:47.539619 29366 solver.cpp:237]     Train net output #0: loss = 0.00607903 (* 1 = 0.00607903 loss)
I0616 07:17:47.539644 29366 sgd_solver.cpp:105] Iteration 53400, lr = 0.001
I0616 07:18:45.272164 29366 solver.cpp:218] Iteration 53450 (0.86607 iter/s, 57.7321s/50 iters), loss = 0.00528794
I0616 07:18:45.272295 29366 solver.cpp:237]     Train net output #0: loss = 0.00528799 (* 1 = 0.00528799 loss)
I0616 07:18:45.272318 29366 sgd_solver.cpp:105] Iteration 53450, lr = 0.001
I0616 07:19:42.992602 29366 solver.cpp:218] Iteration 53500 (0.866254 iter/s, 57.7198s/50 iters), loss = 0.00890976
I0616 07:19:42.992748 29366 solver.cpp:237]     Train net output #0: loss = 0.00890982 (* 1 = 0.00890982 loss)
I0616 07:19:42.992771 29366 sgd_solver.cpp:105] Iteration 53500, lr = 0.001
I0616 07:20:40.713549 29366 solver.cpp:218] Iteration 53550 (0.866246 iter/s, 57.7203s/50 iters), loss = 0.00452269
I0616 07:20:40.713783 29366 solver.cpp:237]     Train net output #0: loss = 0.00452274 (* 1 = 0.00452274 loss)
I0616 07:20:40.713807 29366 sgd_solver.cpp:105] Iteration 53550, lr = 0.001
I0616 07:21:38.442478 29366 solver.cpp:218] Iteration 53600 (0.866128 iter/s, 57.7282s/50 iters), loss = 0.00283841
I0616 07:21:38.442615 29366 solver.cpp:237]     Train net output #0: loss = 0.00283847 (* 1 = 0.00283847 loss)
I0616 07:21:38.442639 29366 sgd_solver.cpp:105] Iteration 53600, lr = 0.001
I0616 07:22:36.173822 29366 solver.cpp:218] Iteration 53650 (0.86609 iter/s, 57.7307s/50 iters), loss = 0.00493086
I0616 07:22:36.173965 29366 solver.cpp:237]     Train net output #0: loss = 0.00493091 (* 1 = 0.00493091 loss)
I0616 07:22:36.173995 29366 sgd_solver.cpp:105] Iteration 53650, lr = 0.001
I0616 07:23:33.894948 29366 solver.cpp:218] Iteration 53700 (0.866244 iter/s, 57.7205s/50 iters), loss = 0.00734157
I0616 07:23:33.895139 29366 solver.cpp:237]     Train net output #0: loss = 0.00734162 (* 1 = 0.00734162 loss)
I0616 07:23:33.895176 29366 sgd_solver.cpp:105] Iteration 53700, lr = 0.001
I0616 07:24:31.614879 29366 solver.cpp:218] Iteration 53750 (0.866262 iter/s, 57.7192s/50 iters), loss = 0.00431056
I0616 07:24:31.615015 29366 solver.cpp:237]     Train net output #0: loss = 0.00431061 (* 1 = 0.00431061 loss)
I0616 07:24:31.615039 29366 sgd_solver.cpp:105] Iteration 53750, lr = 0.001
I0616 07:25:29.354676 29366 solver.cpp:218] Iteration 53800 (0.865963 iter/s, 57.7392s/50 iters), loss = 0.00425039
I0616 07:25:29.354818 29366 solver.cpp:237]     Train net output #0: loss = 0.00425044 (* 1 = 0.00425044 loss)
I0616 07:25:29.354841 29366 sgd_solver.cpp:105] Iteration 53800, lr = 0.001
I0616 07:26:27.075991 29366 solver.cpp:218] Iteration 53850 (0.866241 iter/s, 57.7207s/50 iters), loss = 0.00432294
I0616 07:26:27.076112 29366 solver.cpp:237]     Train net output #0: loss = 0.004323 (* 1 = 0.004323 loss)
I0616 07:26:27.076136 29366 sgd_solver.cpp:105] Iteration 53850, lr = 0.001
I0616 07:27:24.792387 29366 solver.cpp:218] Iteration 53900 (0.866314 iter/s, 57.7158s/50 iters), loss = 0.00411362
I0616 07:27:24.792536 29366 solver.cpp:237]     Train net output #0: loss = 0.00411368 (* 1 = 0.00411368 loss)
I0616 07:27:24.792562 29366 sgd_solver.cpp:105] Iteration 53900, lr = 0.001
I0616 07:28:22.515561 29366 solver.cpp:218] Iteration 53950 (0.866213 iter/s, 57.7225s/50 iters), loss = 0.00377603
I0616 07:28:22.515691 29366 solver.cpp:237]     Train net output #0: loss = 0.00377608 (* 1 = 0.00377608 loss)
I0616 07:28:22.515717 29366 sgd_solver.cpp:105] Iteration 53950, lr = 0.001
I0616 07:29:20.238060 29366 solver.cpp:218] Iteration 54000 (0.866223 iter/s, 57.7219s/50 iters), loss = 0.00522644
I0616 07:29:20.238186 29366 solver.cpp:237]     Train net output #0: loss = 0.00522649 (* 1 = 0.00522649 loss)
I0616 07:29:20.238210 29366 sgd_solver.cpp:105] Iteration 54000, lr = 0.001
I0616 07:30:17.966760 29366 solver.cpp:218] Iteration 54050 (0.86613 iter/s, 57.7281s/50 iters), loss = 0.00353087
I0616 07:30:17.966883 29366 solver.cpp:237]     Train net output #0: loss = 0.00353092 (* 1 = 0.00353092 loss)
I0616 07:30:17.966907 29366 sgd_solver.cpp:105] Iteration 54050, lr = 0.001
I0616 07:31:15.691359 29366 solver.cpp:218] Iteration 54100 (0.866191 iter/s, 57.724s/50 iters), loss = 0.00363172
I0616 07:31:15.691503 29366 solver.cpp:237]     Train net output #0: loss = 0.00363177 (* 1 = 0.00363177 loss)
I0616 07:31:15.691532 29366 sgd_solver.cpp:105] Iteration 54100, lr = 0.001
I0616 07:32:13.426038 29366 solver.cpp:218] Iteration 54150 (0.86604 iter/s, 57.7341s/50 iters), loss = 0.00363111
I0616 07:32:13.426184 29366 solver.cpp:237]     Train net output #0: loss = 0.00363116 (* 1 = 0.00363116 loss)
I0616 07:32:13.426208 29366 sgd_solver.cpp:105] Iteration 54150, lr = 0.001
I0616 07:33:11.140949 29366 solver.cpp:218] Iteration 54200 (0.866336 iter/s, 57.7143s/50 iters), loss = 0.00466783
I0616 07:33:11.141077 29366 solver.cpp:237]     Train net output #0: loss = 0.00466789 (* 1 = 0.00466789 loss)
I0616 07:33:11.141101 29366 sgd_solver.cpp:105] Iteration 54200, lr = 0.001
I0616 07:34:08.859992 29366 solver.cpp:218] Iteration 54250 (0.866274 iter/s, 57.7185s/50 iters), loss = 0.00834671
I0616 07:34:08.860134 29366 solver.cpp:237]     Train net output #0: loss = 0.00834677 (* 1 = 0.00834677 loss)
I0616 07:34:08.860157 29366 sgd_solver.cpp:105] Iteration 54250, lr = 0.001
I0616 07:35:06.591048 29366 solver.cpp:218] Iteration 54300 (0.866094 iter/s, 57.7305s/50 iters), loss = 0.00667897
I0616 07:35:06.591193 29366 solver.cpp:237]     Train net output #0: loss = 0.00667903 (* 1 = 0.00667903 loss)
I0616 07:35:06.591218 29366 sgd_solver.cpp:105] Iteration 54300, lr = 0.001
I0616 07:36:04.324010 29366 solver.cpp:218] Iteration 54350 (0.866065 iter/s, 57.7324s/50 iters), loss = 0.00355898
I0616 07:36:04.324147 29366 solver.cpp:237]     Train net output #0: loss = 0.00355903 (* 1 = 0.00355903 loss)
I0616 07:36:04.324172 29366 sgd_solver.cpp:105] Iteration 54350, lr = 0.001
I0616 07:37:02.035477 29366 solver.cpp:218] Iteration 54400 (0.866388 iter/s, 57.7109s/50 iters), loss = 0.00457891
I0616 07:37:02.035665 29366 solver.cpp:237]     Train net output #0: loss = 0.00457896 (* 1 = 0.00457896 loss)
I0616 07:37:02.035689 29366 sgd_solver.cpp:105] Iteration 54400, lr = 0.001
I0616 07:37:59.805357 29366 solver.cpp:218] Iteration 54450 (0.865513 iter/s, 57.7692s/50 iters), loss = 0.00394955
I0616 07:37:59.805562 29366 solver.cpp:237]     Train net output #0: loss = 0.0039496 (* 1 = 0.0039496 loss)
I0616 07:37:59.805589 29366 sgd_solver.cpp:105] Iteration 54450, lr = 0.001
I0616 07:38:57.571107 29366 solver.cpp:218] Iteration 54500 (0.865575 iter/s, 57.7651s/50 iters), loss = 0.00523138
I0616 07:38:57.571313 29366 solver.cpp:237]     Train net output #0: loss = 0.00523143 (* 1 = 0.00523143 loss)
I0616 07:38:57.571337 29366 sgd_solver.cpp:105] Iteration 54500, lr = 0.001
I0616 07:39:55.338474 29366 solver.cpp:218] Iteration 54550 (0.865551 iter/s, 57.7667s/50 iters), loss = 0.00787288
I0616 07:39:55.338666 29366 solver.cpp:237]     Train net output #0: loss = 0.00787293 (* 1 = 0.00787293 loss)
I0616 07:39:55.338690 29366 sgd_solver.cpp:105] Iteration 54550, lr = 0.001
I0616 07:40:53.099637 29366 solver.cpp:218] Iteration 54600 (0.865644 iter/s, 57.7605s/50 iters), loss = 0.00518381
I0616 07:40:53.099803 29366 solver.cpp:237]     Train net output #0: loss = 0.00518386 (* 1 = 0.00518386 loss)
I0616 07:40:53.099835 29366 sgd_solver.cpp:105] Iteration 54600, lr = 0.001
I0616 07:41:50.861738 29366 solver.cpp:218] Iteration 54650 (0.865629 iter/s, 57.7615s/50 iters), loss = 0.00443949
I0616 07:41:50.861903 29366 solver.cpp:237]     Train net output #0: loss = 0.00443954 (* 1 = 0.00443954 loss)
I0616 07:41:50.861928 29366 sgd_solver.cpp:105] Iteration 54650, lr = 0.001
I0616 07:42:48.619755 29366 solver.cpp:218] Iteration 54700 (0.86569 iter/s, 57.7574s/50 iters), loss = 0.00597948
I0616 07:42:48.619920 29366 solver.cpp:237]     Train net output #0: loss = 0.00597953 (* 1 = 0.00597953 loss)
I0616 07:42:48.619946 29366 sgd_solver.cpp:105] Iteration 54700, lr = 0.001
I0616 07:43:46.381139 29366 solver.cpp:218] Iteration 54750 (0.86564 iter/s, 57.7607s/50 iters), loss = 0.00490652
I0616 07:43:46.381356 29366 solver.cpp:237]     Train net output #0: loss = 0.00490657 (* 1 = 0.00490657 loss)
I0616 07:43:46.381386 29366 sgd_solver.cpp:105] Iteration 54750, lr = 0.001
I0616 07:44:44.137054 29366 solver.cpp:218] Iteration 54800 (0.865723 iter/s, 57.7552s/50 iters), loss = 0.00522874
I0616 07:44:44.137217 29366 solver.cpp:237]     Train net output #0: loss = 0.00522879 (* 1 = 0.00522879 loss)
I0616 07:44:44.137243 29366 sgd_solver.cpp:105] Iteration 54800, lr = 0.001
I0616 07:45:41.901382 29366 solver.cpp:218] Iteration 54850 (0.865596 iter/s, 57.7637s/50 iters), loss = 0.0063895
I0616 07:45:41.901556 29366 solver.cpp:237]     Train net output #0: loss = 0.00638956 (* 1 = 0.00638956 loss)
I0616 07:45:41.901582 29366 sgd_solver.cpp:105] Iteration 54850, lr = 0.001
I0616 07:46:39.663244 29366 solver.cpp:218] Iteration 54900 (0.865633 iter/s, 57.7612s/50 iters), loss = 0.00701982
I0616 07:46:39.663518 29366 solver.cpp:237]     Train net output #0: loss = 0.00701987 (* 1 = 0.00701987 loss)
I0616 07:46:39.663544 29366 sgd_solver.cpp:105] Iteration 54900, lr = 0.001
I0616 07:47:37.411268 29366 solver.cpp:218] Iteration 54950 (0.865842 iter/s, 57.7473s/50 iters), loss = 0.00624705
I0616 07:47:37.411402 29366 solver.cpp:237]     Train net output #0: loss = 0.0062471 (* 1 = 0.0062471 loss)
I0616 07:47:37.411427 29366 sgd_solver.cpp:105] Iteration 54950, lr = 0.001
I0616 07:48:35.134100 29366 solver.cpp:218] Iteration 55000 (0.866217 iter/s, 57.7222s/50 iters), loss = 0.00495319
I0616 07:48:35.134227 29366 solver.cpp:237]     Train net output #0: loss = 0.00495325 (* 1 = 0.00495325 loss)
I0616 07:48:35.134251 29366 sgd_solver.cpp:105] Iteration 55000, lr = 0.001
I0616 07:49:32.863661 29366 solver.cpp:218] Iteration 55050 (0.866117 iter/s, 57.7289s/50 iters), loss = 0.00388023
I0616 07:49:32.863854 29366 solver.cpp:237]     Train net output #0: loss = 0.00388029 (* 1 = 0.00388029 loss)
I0616 07:49:32.863886 29366 sgd_solver.cpp:105] Iteration 55050, lr = 0.001
I0616 07:50:30.579704 29366 solver.cpp:218] Iteration 55100 (0.86632 iter/s, 57.7154s/50 iters), loss = 0.00456139
I0616 07:50:30.579840 29366 solver.cpp:237]     Train net output #0: loss = 0.00456144 (* 1 = 0.00456144 loss)
I0616 07:50:30.579865 29366 sgd_solver.cpp:105] Iteration 55100, lr = 0.001
I0616 07:51:28.297448 29366 solver.cpp:218] Iteration 55150 (0.866294 iter/s, 57.7171s/50 iters), loss = 0.00445148
I0616 07:51:28.297572 29366 solver.cpp:237]     Train net output #0: loss = 0.00445153 (* 1 = 0.00445153 loss)
I0616 07:51:28.297597 29366 sgd_solver.cpp:105] Iteration 55150, lr = 0.001
I0616 07:52:26.022120 29366 solver.cpp:218] Iteration 55200 (0.86619 iter/s, 57.7241s/50 iters), loss = 0.00580955
I0616 07:52:26.022256 29366 solver.cpp:237]     Train net output #0: loss = 0.0058096 (* 1 = 0.0058096 loss)
I0616 07:52:26.022279 29366 sgd_solver.cpp:105] Iteration 55200, lr = 0.001
I0616 07:53:23.734360 29366 solver.cpp:218] Iteration 55250 (0.866377 iter/s, 57.7116s/50 iters), loss = 0.00448778
I0616 07:53:23.744590 29366 solver.cpp:237]     Train net output #0: loss = 0.00448783 (* 1 = 0.00448783 loss)
I0616 07:53:23.744614 29366 sgd_solver.cpp:105] Iteration 55250, lr = 0.001
I0616 07:54:21.462589 29366 solver.cpp:218] Iteration 55300 (0.866288 iter/s, 57.7175s/50 iters), loss = 0.0058106
I0616 07:54:21.462738 29366 solver.cpp:237]     Train net output #0: loss = 0.00581065 (* 1 = 0.00581065 loss)
I0616 07:54:21.462762 29366 sgd_solver.cpp:105] Iteration 55300, lr = 0.001
I0616 07:55:19.193153 29366 solver.cpp:218] Iteration 55350 (0.866102 iter/s, 57.7299s/50 iters), loss = 0.00690571
I0616 07:55:19.193297 29366 solver.cpp:237]     Train net output #0: loss = 0.00690577 (* 1 = 0.00690577 loss)
I0616 07:55:19.193322 29366 sgd_solver.cpp:105] Iteration 55350, lr = 0.001
I0616 07:56:16.911821 29366 solver.cpp:218] Iteration 55400 (0.86628 iter/s, 57.718s/50 iters), loss = 0.00556404
I0616 07:56:16.911963 29366 solver.cpp:237]     Train net output #0: loss = 0.0055641 (* 1 = 0.0055641 loss)
I0616 07:56:16.911988 29366 sgd_solver.cpp:105] Iteration 55400, lr = 0.001
I0616 07:57:14.632499 29366 solver.cpp:218] Iteration 55450 (0.86625 iter/s, 57.7201s/50 iters), loss = 0.00368277
I0616 07:57:14.632637 29366 solver.cpp:237]     Train net output #0: loss = 0.00368282 (* 1 = 0.00368282 loss)
I0616 07:57:14.632663 29366 sgd_solver.cpp:105] Iteration 55450, lr = 0.001
I0616 07:58:12.351904 29366 solver.cpp:218] Iteration 55500 (0.866269 iter/s, 57.7188s/50 iters), loss = 0.00358403
I0616 07:58:12.352044 29366 solver.cpp:237]     Train net output #0: loss = 0.00358408 (* 1 = 0.00358408 loss)
I0616 07:58:12.352075 29366 sgd_solver.cpp:105] Iteration 55500, lr = 0.001
I0616 07:59:10.090221 29366 solver.cpp:218] Iteration 55550 (0.865985 iter/s, 57.7377s/50 iters), loss = 0.00391346
I0616 07:59:10.090353 29366 solver.cpp:237]     Train net output #0: loss = 0.00391351 (* 1 = 0.00391351 loss)
I0616 07:59:10.090376 29366 sgd_solver.cpp:105] Iteration 55550, lr = 0.001
I0616 08:00:07.811880 29366 solver.cpp:218] Iteration 55600 (0.866235 iter/s, 57.721s/50 iters), loss = 0.00467386
I0616 08:00:07.812022 29366 solver.cpp:237]     Train net output #0: loss = 0.00467391 (* 1 = 0.00467391 loss)
I0616 08:00:07.812046 29366 sgd_solver.cpp:105] Iteration 55600, lr = 0.001
I0616 08:01:05.533372 29366 solver.cpp:218] Iteration 55650 (0.866238 iter/s, 57.7209s/50 iters), loss = 0.00562569
I0616 08:01:05.533494 29366 solver.cpp:237]     Train net output #0: loss = 0.00562574 (* 1 = 0.00562574 loss)
I0616 08:01:05.533522 29366 sgd_solver.cpp:105] Iteration 55650, lr = 0.001
I0616 08:02:03.257105 29366 solver.cpp:218] Iteration 55700 (0.866204 iter/s, 57.7231s/50 iters), loss = 0.00532171
I0616 08:02:03.257246 29366 solver.cpp:237]     Train net output #0: loss = 0.00532176 (* 1 = 0.00532176 loss)
I0616 08:02:03.257275 29366 sgd_solver.cpp:105] Iteration 55700, lr = 0.001
I0616 08:03:01.004868 29366 solver.cpp:218] Iteration 55750 (0.865844 iter/s, 57.7471s/50 iters), loss = 0.00359076
I0616 08:03:01.005116 29366 solver.cpp:237]     Train net output #0: loss = 0.00359082 (* 1 = 0.00359082 loss)
I0616 08:03:01.005142 29366 sgd_solver.cpp:105] Iteration 55750, lr = 0.001
I0616 08:03:58.748168 29366 solver.cpp:218] Iteration 55800 (0.865912 iter/s, 57.7426s/50 iters), loss = 0.00729965
I0616 08:03:58.748297 29366 solver.cpp:237]     Train net output #0: loss = 0.0072997 (* 1 = 0.0072997 loss)
I0616 08:03:58.748322 29366 sgd_solver.cpp:105] Iteration 55800, lr = 0.001
I0616 08:04:56.499172 29366 solver.cpp:218] Iteration 55850 (0.865795 iter/s, 57.7504s/50 iters), loss = 0.00624515
I0616 08:04:56.499341 29366 solver.cpp:237]     Train net output #0: loss = 0.00624521 (* 1 = 0.00624521 loss)
I0616 08:04:56.499367 29366 sgd_solver.cpp:105] Iteration 55850, lr = 0.001
I0616 08:05:54.253820 29366 solver.cpp:218] Iteration 55900 (0.865741 iter/s, 57.754s/50 iters), loss = 0.00597602
I0616 08:05:54.253942 29366 solver.cpp:237]     Train net output #0: loss = 0.00597608 (* 1 = 0.00597608 loss)
I0616 08:05:54.253965 29366 sgd_solver.cpp:105] Iteration 55900, lr = 0.001
I0616 08:06:52.006088 29366 solver.cpp:218] Iteration 55950 (0.865777 iter/s, 57.7516s/50 iters), loss = 0.00435676
I0616 08:06:52.006254 29366 solver.cpp:237]     Train net output #0: loss = 0.00435681 (* 1 = 0.00435681 loss)
I0616 08:06:52.006284 29366 sgd_solver.cpp:105] Iteration 55950, lr = 0.001
I0616 08:07:49.741559 29366 solver.cpp:218] Iteration 56000 (0.86603 iter/s, 57.7347s/50 iters), loss = 0.0038712
I0616 08:07:49.741717 29366 solver.cpp:237]     Train net output #0: loss = 0.00387125 (* 1 = 0.00387125 loss)
I0616 08:07:49.741742 29366 sgd_solver.cpp:105] Iteration 56000, lr = 0.001
I0616 08:08:47.475247 29366 solver.cpp:218] Iteration 56050 (0.866056 iter/s, 57.733s/50 iters), loss = 0.00299065
I0616 08:08:47.475388 29366 solver.cpp:237]     Train net output #0: loss = 0.0029907 (* 1 = 0.0029907 loss)
I0616 08:08:47.475412 29366 sgd_solver.cpp:105] Iteration 56050, lr = 0.001
I0616 08:09:45.205816 29366 solver.cpp:218] Iteration 56100 (0.866103 iter/s, 57.7299s/50 iters), loss = 0.00565192
I0616 08:09:45.205953 29366 solver.cpp:237]     Train net output #0: loss = 0.00565198 (* 1 = 0.00565198 loss)
I0616 08:09:45.205989 29366 sgd_solver.cpp:105] Iteration 56100, lr = 0.001
I0616 08:10:42.932819 29366 solver.cpp:218] Iteration 56150 (0.866156 iter/s, 57.7263s/50 iters), loss = 0.00429322
I0616 08:10:42.932996 29366 solver.cpp:237]     Train net output #0: loss = 0.00429327 (* 1 = 0.00429327 loss)
I0616 08:10:42.933020 29366 sgd_solver.cpp:105] Iteration 56150, lr = 0.001
I0616 08:11:40.654659 29366 solver.cpp:218] Iteration 56200 (0.866234 iter/s, 57.7211s/50 iters), loss = 0.00484493
I0616 08:11:40.654788 29366 solver.cpp:237]     Train net output #0: loss = 0.00484499 (* 1 = 0.00484499 loss)
I0616 08:11:40.654813 29366 sgd_solver.cpp:105] Iteration 56200, lr = 0.001
I0616 08:12:38.381296 29366 solver.cpp:218] Iteration 56250 (0.866161 iter/s, 57.726s/50 iters), loss = 0.00550028
I0616 08:12:38.381433 29366 solver.cpp:237]     Train net output #0: loss = 0.00550033 (* 1 = 0.00550033 loss)
I0616 08:12:38.381456 29366 sgd_solver.cpp:105] Iteration 56250, lr = 0.001
I0616 08:13:36.110087 29366 solver.cpp:218] Iteration 56300 (0.866129 iter/s, 57.7281s/50 iters), loss = 0.00583082
I0616 08:13:36.110213 29366 solver.cpp:237]     Train net output #0: loss = 0.00583087 (* 1 = 0.00583087 loss)
I0616 08:13:36.110235 29366 sgd_solver.cpp:105] Iteration 56300, lr = 0.001
I0616 08:14:33.840113 29366 solver.cpp:218] Iteration 56350 (0.866111 iter/s, 57.7294s/50 iters), loss = 0.00483847
I0616 08:14:33.840266 29366 solver.cpp:237]     Train net output #0: loss = 0.00483853 (* 1 = 0.00483853 loss)
I0616 08:14:33.840289 29366 sgd_solver.cpp:105] Iteration 56350, lr = 0.001
I0616 08:15:31.561470 29366 solver.cpp:218] Iteration 56400 (0.866241 iter/s, 57.7207s/50 iters), loss = 0.00350349
I0616 08:15:31.561684 29366 solver.cpp:237]     Train net output #0: loss = 0.00350355 (* 1 = 0.00350355 loss)
I0616 08:15:31.561710 29366 sgd_solver.cpp:105] Iteration 56400, lr = 0.001
I0616 08:16:29.283478 29366 solver.cpp:218] Iteration 56450 (0.866232 iter/s, 57.7213s/50 iters), loss = 0.00421712
I0616 08:16:29.283632 29366 solver.cpp:237]     Train net output #0: loss = 0.00421717 (* 1 = 0.00421717 loss)
I0616 08:16:29.283658 29366 sgd_solver.cpp:105] Iteration 56450, lr = 0.001
I0616 08:17:26.998293 29366 solver.cpp:218] Iteration 56500 (0.866339 iter/s, 57.7141s/50 iters), loss = 0.00406862
I0616 08:17:26.998441 29366 solver.cpp:237]     Train net output #0: loss = 0.00406867 (* 1 = 0.00406867 loss)
I0616 08:17:26.998467 29366 sgd_solver.cpp:105] Iteration 56500, lr = 0.001
I0616 08:18:24.729707 29366 solver.cpp:218] Iteration 56550 (0.86609 iter/s, 57.7307s/50 iters), loss = 0.00390544
I0616 08:18:24.729853 29366 solver.cpp:237]     Train net output #0: loss = 0.00390549 (* 1 = 0.00390549 loss)
I0616 08:18:24.729878 29366 sgd_solver.cpp:105] Iteration 56550, lr = 0.001
I0616 08:19:22.454965 29366 solver.cpp:218] Iteration 56600 (0.866182 iter/s, 57.7246s/50 iters), loss = 0.00474595
I0616 08:19:22.455106 29366 solver.cpp:237]     Train net output #0: loss = 0.004746 (* 1 = 0.004746 loss)
I0616 08:19:22.455130 29366 sgd_solver.cpp:105] Iteration 56600, lr = 0.001
I0616 08:20:20.170655 29366 solver.cpp:218] Iteration 56650 (0.866326 iter/s, 57.715s/50 iters), loss = 0.00805387
I0616 08:20:20.170799 29366 solver.cpp:237]     Train net output #0: loss = 0.00805392 (* 1 = 0.00805392 loss)
I0616 08:20:20.170821 29366 sgd_solver.cpp:105] Iteration 56650, lr = 0.001
I0616 08:21:17.893918 29366 solver.cpp:218] Iteration 56700 (0.866212 iter/s, 57.7226s/50 iters), loss = 0.00436651
I0616 08:21:17.894047 29366 solver.cpp:237]     Train net output #0: loss = 0.00436656 (* 1 = 0.00436656 loss)
I0616 08:21:17.894069 29366 sgd_solver.cpp:105] Iteration 56700, lr = 0.001
I0616 08:22:15.619549 29366 solver.cpp:218] Iteration 56750 (0.866176 iter/s, 57.725s/50 iters), loss = 0.00464125
I0616 08:22:15.619680 29366 solver.cpp:237]     Train net output #0: loss = 0.00464131 (* 1 = 0.00464131 loss)
I0616 08:22:15.619704 29366 sgd_solver.cpp:105] Iteration 56750, lr = 0.001
I0616 08:23:13.347021 29366 solver.cpp:218] Iteration 56800 (0.866149 iter/s, 57.7268s/50 iters), loss = 0.00400579
I0616 08:23:13.347146 29366 solver.cpp:237]     Train net output #0: loss = 0.00400584 (* 1 = 0.00400584 loss)
I0616 08:23:13.347170 29366 sgd_solver.cpp:105] Iteration 56800, lr = 0.001
I0616 08:24:11.066485 29366 solver.cpp:218] Iteration 56850 (0.866269 iter/s, 57.7188s/50 iters), loss = 0.00418316
I0616 08:24:11.066628 29366 solver.cpp:237]     Train net output #0: loss = 0.00418322 (* 1 = 0.00418322 loss)
I0616 08:24:11.066653 29366 sgd_solver.cpp:105] Iteration 56850, lr = 0.001
I0616 08:25:08.793143 29366 solver.cpp:218] Iteration 56900 (0.866161 iter/s, 57.726s/50 iters), loss = 0.00465713
I0616 08:25:08.793292 29366 solver.cpp:237]     Train net output #0: loss = 0.00465719 (* 1 = 0.00465719 loss)
I0616 08:25:08.793318 29366 sgd_solver.cpp:105] Iteration 56900, lr = 0.001
I0616 08:26:06.518103 29366 solver.cpp:218] Iteration 56950 (0.866187 iter/s, 57.7243s/50 iters), loss = 0.00424249
I0616 08:26:06.518244 29366 solver.cpp:237]     Train net output #0: loss = 0.00424254 (* 1 = 0.00424254 loss)
I0616 08:26:06.518267 29366 sgd_solver.cpp:105] Iteration 56950, lr = 0.001
I0616 08:27:04.237383 29366 solver.cpp:218] Iteration 57000 (0.866272 iter/s, 57.7186s/50 iters), loss = 0.0030835
I0616 08:27:04.237524 29366 solver.cpp:237]     Train net output #0: loss = 0.00308356 (* 1 = 0.00308356 loss)
I0616 08:27:04.237550 29366 sgd_solver.cpp:105] Iteration 57000, lr = 0.001
I0616 08:28:01.962569 29366 solver.cpp:218] Iteration 57050 (0.866183 iter/s, 57.7245s/50 iters), loss = 0.00803257
I0616 08:28:01.962694 29366 solver.cpp:237]     Train net output #0: loss = 0.00803262 (* 1 = 0.00803262 loss)
I0616 08:28:01.962718 29366 sgd_solver.cpp:105] Iteration 57050, lr = 0.001
I0616 08:28:59.682646 29366 solver.cpp:218] Iteration 57100 (0.86626 iter/s, 57.7194s/50 iters), loss = 0.00544463
I0616 08:28:59.682852 29366 solver.cpp:237]     Train net output #0: loss = 0.00544468 (* 1 = 0.00544468 loss)
I0616 08:28:59.682891 29366 sgd_solver.cpp:105] Iteration 57100, lr = 0.001
I0616 08:29:57.399212 29366 solver.cpp:218] Iteration 57150 (0.866314 iter/s, 57.7158s/50 iters), loss = 0.00344834
I0616 08:29:57.399348 29366 solver.cpp:237]     Train net output #0: loss = 0.0034484 (* 1 = 0.0034484 loss)
I0616 08:29:57.399372 29366 sgd_solver.cpp:105] Iteration 57150, lr = 0.001
I0616 08:30:55.117220 29366 solver.cpp:218] Iteration 57200 (0.866291 iter/s, 57.7173s/50 iters), loss = 0.00298901
I0616 08:30:55.117339 29366 solver.cpp:237]     Train net output #0: loss = 0.00298907 (* 1 = 0.00298907 loss)
I0616 08:30:55.117363 29366 sgd_solver.cpp:105] Iteration 57200, lr = 0.001
I0616 08:31:52.838165 29366 solver.cpp:218] Iteration 57250 (0.866247 iter/s, 57.7203s/50 iters), loss = 0.00659543
I0616 08:31:52.838296 29366 solver.cpp:237]     Train net output #0: loss = 0.00659548 (* 1 = 0.00659548 loss)
I0616 08:31:52.838325 29366 sgd_solver.cpp:105] Iteration 57250, lr = 0.001
I0616 08:32:50.551931 29366 solver.cpp:218] Iteration 57300 (0.866355 iter/s, 57.7131s/50 iters), loss = 0.00624234
I0616 08:32:50.552332 29366 solver.cpp:237]     Train net output #0: loss = 0.0062424 (* 1 = 0.0062424 loss)
I0616 08:32:50.552356 29366 sgd_solver.cpp:105] Iteration 57300, lr = 0.001
I0616 08:33:48.275682 29366 solver.cpp:218] Iteration 57350 (0.866209 iter/s, 57.7228s/50 iters), loss = 0.00626411
I0616 08:33:48.276239 29366 solver.cpp:237]     Train net output #0: loss = 0.00626416 (* 1 = 0.00626416 loss)
I0616 08:33:48.276263 29366 sgd_solver.cpp:105] Iteration 57350, lr = 0.001
I0616 08:34:45.988545 29366 solver.cpp:218] Iteration 57400 (0.866374 iter/s, 57.7118s/50 iters), loss = 0.0071817
I0616 08:34:45.988689 29366 solver.cpp:237]     Train net output #0: loss = 0.00718176 (* 1 = 0.00718176 loss)
I0616 08:34:45.988713 29366 sgd_solver.cpp:105] Iteration 57400, lr = 0.001
I0616 08:35:43.707746 29366 solver.cpp:218] Iteration 57450 (0.866273 iter/s, 57.7185s/50 iters), loss = 0.00642881
I0616 08:35:43.707880 29366 solver.cpp:237]     Train net output #0: loss = 0.00642886 (* 1 = 0.00642886 loss)
I0616 08:35:43.707903 29366 sgd_solver.cpp:105] Iteration 57450, lr = 0.001
I0616 08:36:41.425534 29366 solver.cpp:218] Iteration 57500 (0.866294 iter/s, 57.7171s/50 iters), loss = 0.00603098
I0616 08:36:41.425662 29366 solver.cpp:237]     Train net output #0: loss = 0.00603104 (* 1 = 0.00603104 loss)
I0616 08:36:41.425688 29366 sgd_solver.cpp:105] Iteration 57500, lr = 0.001
I0616 08:37:39.166263 29366 solver.cpp:218] Iteration 57550 (0.86595 iter/s, 57.74s/50 iters), loss = 0.00656496
I0616 08:37:39.166422 29366 solver.cpp:237]     Train net output #0: loss = 0.00656501 (* 1 = 0.00656501 loss)
I0616 08:37:39.166455 29366 sgd_solver.cpp:105] Iteration 57550, lr = 0.001
I0616 08:38:36.910507 29366 solver.cpp:218] Iteration 57600 (0.865898 iter/s, 57.7435s/50 iters), loss = 0.00430369
I0616 08:38:36.910657 29366 solver.cpp:237]     Train net output #0: loss = 0.00430374 (* 1 = 0.00430374 loss)
I0616 08:38:36.910682 29366 sgd_solver.cpp:105] Iteration 57600, lr = 0.001
I0616 08:39:34.643466 29366 solver.cpp:218] Iteration 57650 (0.866067 iter/s, 57.7323s/50 iters), loss = 0.00441486
I0616 08:39:34.643599 29366 solver.cpp:237]     Train net output #0: loss = 0.00441491 (* 1 = 0.00441491 loss)
I0616 08:39:34.643622 29366 sgd_solver.cpp:105] Iteration 57650, lr = 0.001
I0616 08:40:32.388640 29366 solver.cpp:218] Iteration 57700 (0.865883 iter/s, 57.7445s/50 iters), loss = 0.00458946
I0616 08:40:32.388769 29366 solver.cpp:237]     Train net output #0: loss = 0.00458951 (* 1 = 0.00458951 loss)
I0616 08:40:32.388793 29366 sgd_solver.cpp:105] Iteration 57700, lr = 0.001
I0616 08:41:30.127676 29366 solver.cpp:218] Iteration 57750 (0.865975 iter/s, 57.7384s/50 iters), loss = 0.00673814
I0616 08:41:30.127843 29366 solver.cpp:237]     Train net output #0: loss = 0.0067382 (* 1 = 0.0067382 loss)
I0616 08:41:30.127868 29366 sgd_solver.cpp:105] Iteration 57750, lr = 0.001
I0616 08:42:27.873543 29366 solver.cpp:218] Iteration 57800 (0.865873 iter/s, 57.7452s/50 iters), loss = 0.00371023
I0616 08:42:27.873746 29366 solver.cpp:237]     Train net output #0: loss = 0.00371029 (* 1 = 0.00371029 loss)
I0616 08:42:27.873772 29366 sgd_solver.cpp:105] Iteration 57800, lr = 0.001
I0616 08:43:25.614408 29366 solver.cpp:218] Iteration 57850 (0.865949 iter/s, 57.7401s/50 iters), loss = 0.0041516
I0616 08:43:25.614567 29366 solver.cpp:237]     Train net output #0: loss = 0.00415166 (* 1 = 0.00415166 loss)
I0616 08:43:25.614593 29366 sgd_solver.cpp:105] Iteration 57850, lr = 0.001
I0616 08:44:23.351768 29366 solver.cpp:218] Iteration 57900 (0.866001 iter/s, 57.7367s/50 iters), loss = 0.00547633
I0616 08:44:23.351914 29366 solver.cpp:237]     Train net output #0: loss = 0.00547639 (* 1 = 0.00547639 loss)
I0616 08:44:23.351939 29366 sgd_solver.cpp:105] Iteration 57900, lr = 0.001
I0616 08:45:21.099506 29366 solver.cpp:218] Iteration 57950 (0.865845 iter/s, 57.7471s/50 iters), loss = 0.00577478
I0616 08:45:21.099639 29366 solver.cpp:237]     Train net output #0: loss = 0.00577484 (* 1 = 0.00577484 loss)
I0616 08:45:21.099664 29366 sgd_solver.cpp:105] Iteration 57950, lr = 0.001
I0616 08:46:18.837061 29366 solver.cpp:218] Iteration 58000 (0.865997 iter/s, 57.7369s/50 iters), loss = 0.00478229
I0616 08:46:18.837198 29366 solver.cpp:237]     Train net output #0: loss = 0.00478234 (* 1 = 0.00478234 loss)
I0616 08:46:18.837221 29366 sgd_solver.cpp:105] Iteration 58000, lr = 0.001
I0616 08:47:16.573078 29366 solver.cpp:218] Iteration 58050 (0.866021 iter/s, 57.7353s/50 iters), loss = 0.00723546
I0616 08:47:16.573227 29366 solver.cpp:237]     Train net output #0: loss = 0.00723551 (* 1 = 0.00723551 loss)
I0616 08:47:16.573258 29366 sgd_solver.cpp:105] Iteration 58050, lr = 0.001
I0616 08:48:14.302166 29366 solver.cpp:218] Iteration 58100 (0.866124 iter/s, 57.7284s/50 iters), loss = 0.00540347
I0616 08:48:14.302310 29366 solver.cpp:237]     Train net output #0: loss = 0.00540352 (* 1 = 0.00540352 loss)
I0616 08:48:14.302335 29366 sgd_solver.cpp:105] Iteration 58100, lr = 0.001
I0616 08:49:12.030694 29366 solver.cpp:218] Iteration 58150 (0.866133 iter/s, 57.7279s/50 iters), loss = 0.00404788
I0616 08:49:12.030836 29366 solver.cpp:237]     Train net output #0: loss = 0.00404793 (* 1 = 0.00404793 loss)
I0616 08:49:12.030863 29366 sgd_solver.cpp:105] Iteration 58150, lr = 0.001
I0616 08:50:09.761484 29366 solver.cpp:218] Iteration 58200 (0.866099 iter/s, 57.7301s/50 iters), loss = 0.00637344
I0616 08:50:09.761633 29366 solver.cpp:237]     Train net output #0: loss = 0.0063735 (* 1 = 0.0063735 loss)
I0616 08:50:09.761658 29366 sgd_solver.cpp:105] Iteration 58200, lr = 0.001
I0616 08:51:07.484174 29366 solver.cpp:218] Iteration 58250 (0.866221 iter/s, 57.722s/50 iters), loss = 0.00705776
I0616 08:51:07.484300 29366 solver.cpp:237]     Train net output #0: loss = 0.00705781 (* 1 = 0.00705781 loss)
I0616 08:51:07.484325 29366 sgd_solver.cpp:105] Iteration 58250, lr = 0.001
I0616 08:52:05.205912 29366 solver.cpp:218] Iteration 58300 (0.866234 iter/s, 57.7211s/50 iters), loss = 0.0080113
I0616 08:52:05.206040 29366 solver.cpp:237]     Train net output #0: loss = 0.00801136 (* 1 = 0.00801136 loss)
I0616 08:52:05.206064 29366 sgd_solver.cpp:105] Iteration 58300, lr = 0.001
I0616 08:53:02.927224 29366 solver.cpp:218] Iteration 58350 (0.866241 iter/s, 57.7207s/50 iters), loss = 0.00398607
I0616 08:53:02.927350 29366 solver.cpp:237]     Train net output #0: loss = 0.00398613 (* 1 = 0.00398613 loss)
I0616 08:53:02.927372 29366 sgd_solver.cpp:105] Iteration 58350, lr = 0.001
I0616 08:54:00.651562 29366 solver.cpp:218] Iteration 58400 (0.866195 iter/s, 57.7237s/50 iters), loss = 0.00894986
I0616 08:54:00.651711 29366 solver.cpp:237]     Train net output #0: loss = 0.00894992 (* 1 = 0.00894992 loss)
I0616 08:54:00.651736 29366 sgd_solver.cpp:105] Iteration 58400, lr = 0.001
I0616 08:54:58.363898 29366 solver.cpp:218] Iteration 58450 (0.866376 iter/s, 57.7117s/50 iters), loss = 0.00331702
I0616 08:54:58.364061 29366 solver.cpp:237]     Train net output #0: loss = 0.00331708 (* 1 = 0.00331708 loss)
I0616 08:54:58.364102 29366 sgd_solver.cpp:105] Iteration 58450, lr = 0.001
I0616 08:55:56.087733 29366 solver.cpp:218] Iteration 58500 (0.866204 iter/s, 57.7232s/50 iters), loss = 0.00318
I0616 08:55:56.087879 29366 solver.cpp:237]     Train net output #0: loss = 0.00318005 (* 1 = 0.00318005 loss)
I0616 08:55:56.087905 29366 sgd_solver.cpp:105] Iteration 58500, lr = 0.001
I0616 08:56:53.808893 29366 solver.cpp:218] Iteration 58550 (0.866244 iter/s, 57.7205s/50 iters), loss = 0.00369305
I0616 08:56:53.809067 29366 solver.cpp:237]     Train net output #0: loss = 0.0036931 (* 1 = 0.0036931 loss)
I0616 08:56:53.809093 29366 sgd_solver.cpp:105] Iteration 58550, lr = 0.001
I0616 08:57:51.534070 29366 solver.cpp:218] Iteration 58600 (0.866184 iter/s, 57.7244s/50 iters), loss = 0.00399626
I0616 08:57:51.534199 29366 solver.cpp:237]     Train net output #0: loss = 0.00399631 (* 1 = 0.00399631 loss)
I0616 08:57:51.534224 29366 sgd_solver.cpp:105] Iteration 58600, lr = 0.001
I0616 08:58:49.260367 29366 solver.cpp:218] Iteration 58650 (0.866167 iter/s, 57.7256s/50 iters), loss = 0.00298584
I0616 08:58:49.260495 29366 solver.cpp:237]     Train net output #0: loss = 0.00298589 (* 1 = 0.00298589 loss)
I0616 08:58:49.260525 29366 sgd_solver.cpp:105] Iteration 58650, lr = 0.001
I0616 08:59:46.983685 29366 solver.cpp:218] Iteration 58700 (0.866212 iter/s, 57.7226s/50 iters), loss = 0.00329195
I0616 08:59:46.983813 29366 solver.cpp:237]     Train net output #0: loss = 0.003292 (* 1 = 0.003292 loss)
I0616 08:59:46.983834 29366 sgd_solver.cpp:105] Iteration 58700, lr = 0.001
I0616 09:00:44.711437 29366 solver.cpp:218] Iteration 58750 (0.866145 iter/s, 57.7271s/50 iters), loss = 0.00408869
I0616 09:00:44.711578 29366 solver.cpp:237]     Train net output #0: loss = 0.00408874 (* 1 = 0.00408874 loss)
I0616 09:00:44.711602 29366 sgd_solver.cpp:105] Iteration 58750, lr = 0.001
I0616 09:01:42.430562 29366 solver.cpp:218] Iteration 58800 (0.866275 iter/s, 57.7184s/50 iters), loss = 0.00526961
I0616 09:01:42.430709 29366 solver.cpp:237]     Train net output #0: loss = 0.00526966 (* 1 = 0.00526966 loss)
I0616 09:01:42.430733 29366 sgd_solver.cpp:105] Iteration 58800, lr = 0.001
I0616 09:02:40.159598 29366 solver.cpp:218] Iteration 58850 (0.866126 iter/s, 57.7283s/50 iters), loss = 0.00577437
I0616 09:02:40.159735 29366 solver.cpp:237]     Train net output #0: loss = 0.00577442 (* 1 = 0.00577442 loss)
I0616 09:02:40.159760 29366 sgd_solver.cpp:105] Iteration 58850, lr = 0.001
I0616 09:03:37.885601 29366 solver.cpp:218] Iteration 58900 (0.866171 iter/s, 57.7253s/50 iters), loss = 0.00371462
I0616 09:03:37.885743 29366 solver.cpp:237]     Train net output #0: loss = 0.00371467 (* 1 = 0.00371467 loss)
I0616 09:03:37.885768 29366 sgd_solver.cpp:105] Iteration 58900, lr = 0.001
I0616 09:04:35.599937 29366 solver.cpp:218] Iteration 58950 (0.866347 iter/s, 57.7136s/50 iters), loss = 0.00471047
I0616 09:04:35.600075 29366 solver.cpp:237]     Train net output #0: loss = 0.00471052 (* 1 = 0.00471052 loss)
I0616 09:04:35.600100 29366 sgd_solver.cpp:105] Iteration 58950, lr = 0.001
I0616 09:05:33.328994 29366 solver.cpp:218] Iteration 59000 (0.866126 iter/s, 57.7283s/50 iters), loss = 0.00444964
I0616 09:05:33.329126 29366 solver.cpp:237]     Train net output #0: loss = 0.00444969 (* 1 = 0.00444969 loss)
I0616 09:05:33.329151 29366 sgd_solver.cpp:105] Iteration 59000, lr = 0.001
I0616 09:06:31.053653 29366 solver.cpp:218] Iteration 59050 (0.866192 iter/s, 57.724s/50 iters), loss = 0.00351881
I0616 09:06:31.053789 29366 solver.cpp:237]     Train net output #0: loss = 0.00351886 (* 1 = 0.00351886 loss)
I0616 09:06:31.053812 29366 sgd_solver.cpp:105] Iteration 59050, lr = 0.001
I0616 09:07:28.772495 29366 solver.cpp:218] Iteration 59100 (0.866279 iter/s, 57.7181s/50 iters), loss = 0.00537774
I0616 09:07:28.772630 29366 solver.cpp:237]     Train net output #0: loss = 0.00537779 (* 1 = 0.00537779 loss)
I0616 09:07:28.772655 29366 sgd_solver.cpp:105] Iteration 59100, lr = 0.001
I0616 09:08:26.496476 29366 solver.cpp:218] Iteration 59150 (0.866202 iter/s, 57.7233s/50 iters), loss = 0.00406697
I0616 09:08:26.496646 29366 solver.cpp:237]     Train net output #0: loss = 0.00406702 (* 1 = 0.00406702 loss)
I0616 09:08:26.496671 29366 sgd_solver.cpp:105] Iteration 59150, lr = 0.001
I0616 09:09:24.225424 29366 solver.cpp:218] Iteration 59200 (0.866128 iter/s, 57.7282s/50 iters), loss = 0.0048547
I0616 09:09:24.225563 29366 solver.cpp:237]     Train net output #0: loss = 0.00485475 (* 1 = 0.00485475 loss)
I0616 09:09:24.225589 29366 sgd_solver.cpp:105] Iteration 59200, lr = 0.001
I0616 09:10:21.950527 29366 solver.cpp:218] Iteration 59250 (0.866185 iter/s, 57.7244s/50 iters), loss = 0.00653537
I0616 09:10:21.950662 29366 solver.cpp:237]     Train net output #0: loss = 0.00653543 (* 1 = 0.00653543 loss)
I0616 09:10:21.950687 29366 sgd_solver.cpp:105] Iteration 59250, lr = 0.001
I0616 09:11:19.668815 29366 solver.cpp:218] Iteration 59300 (0.866287 iter/s, 57.7176s/50 iters), loss = 0.00452457
I0616 09:11:19.668958 29366 solver.cpp:237]     Train net output #0: loss = 0.00452462 (* 1 = 0.00452462 loss)
I0616 09:11:19.668983 29366 sgd_solver.cpp:105] Iteration 59300, lr = 0.001
I0616 09:12:17.394943 29366 solver.cpp:218] Iteration 59350 (0.866169 iter/s, 57.7254s/50 iters), loss = 0.00487138
I0616 09:12:17.395072 29366 solver.cpp:237]     Train net output #0: loss = 0.00487143 (* 1 = 0.00487143 loss)
I0616 09:12:17.395097 29366 sgd_solver.cpp:105] Iteration 59350, lr = 0.001
I0616 09:13:15.126816 29366 solver.cpp:218] Iteration 59400 (0.866083 iter/s, 57.7312s/50 iters), loss = 0.0050828
I0616 09:13:15.126946 29366 solver.cpp:237]     Train net output #0: loss = 0.00508285 (* 1 = 0.00508285 loss)
I0616 09:13:15.126971 29366 sgd_solver.cpp:105] Iteration 59400, lr = 0.001
I0616 09:14:12.859241 29366 solver.cpp:218] Iteration 59450 (0.866075 iter/s, 57.7317s/50 iters), loss = 0.00450961
I0616 09:14:12.859385 29366 solver.cpp:237]     Train net output #0: loss = 0.00450966 (* 1 = 0.00450966 loss)
I0616 09:14:12.859408 29366 sgd_solver.cpp:105] Iteration 59450, lr = 0.001
I0616 09:15:10.588572 29366 solver.cpp:218] Iteration 59500 (0.866121 iter/s, 57.7287s/50 iters), loss = 0.00760396
I0616 09:15:10.588692 29366 solver.cpp:237]     Train net output #0: loss = 0.00760401 (* 1 = 0.00760401 loss)
I0616 09:15:10.588716 29366 sgd_solver.cpp:105] Iteration 59500, lr = 0.001
I0616 09:16:08.313259 29366 solver.cpp:218] Iteration 59550 (0.86619 iter/s, 57.7241s/50 iters), loss = 0.00561948
I0616 09:16:08.313390 29366 solver.cpp:237]     Train net output #0: loss = 0.00561953 (* 1 = 0.00561953 loss)
I0616 09:16:08.313419 29366 sgd_solver.cpp:105] Iteration 59550, lr = 0.001
I0616 09:17:06.031821 29366 solver.cpp:218] Iteration 59600 (0.866282 iter/s, 57.7179s/50 iters), loss = 0.00412011
I0616 09:17:06.031966 29366 solver.cpp:237]     Train net output #0: loss = 0.00412016 (* 1 = 0.00412016 loss)
I0616 09:17:06.031993 29366 sgd_solver.cpp:105] Iteration 59600, lr = 0.001
I0616 09:18:03.753597 29366 solver.cpp:218] Iteration 59650 (0.866234 iter/s, 57.7211s/50 iters), loss = 0.00357345
I0616 09:18:03.753742 29366 solver.cpp:237]     Train net output #0: loss = 0.0035735 (* 1 = 0.0035735 loss)
I0616 09:18:03.753767 29366 sgd_solver.cpp:105] Iteration 59650, lr = 0.001
I0616 09:19:01.479861 29366 solver.cpp:218] Iteration 59700 (0.866167 iter/s, 57.7256s/50 iters), loss = 0.00491397
I0616 09:19:01.480000 29366 solver.cpp:237]     Train net output #0: loss = 0.00491402 (* 1 = 0.00491402 loss)
I0616 09:19:01.480026 29366 sgd_solver.cpp:105] Iteration 59700, lr = 0.001
I0616 09:19:59.202035 29366 solver.cpp:218] Iteration 59750 (0.866228 iter/s, 57.7215s/50 iters), loss = 0.00448613
I0616 09:19:59.202172 29366 solver.cpp:237]     Train net output #0: loss = 0.00448618 (* 1 = 0.00448618 loss)
I0616 09:19:59.202204 29366 sgd_solver.cpp:105] Iteration 59750, lr = 0.001
I0616 09:20:56.924233 29366 solver.cpp:218] Iteration 59800 (0.866228 iter/s, 57.7216s/50 iters), loss = 0.00666819
I0616 09:20:56.924422 29366 solver.cpp:237]     Train net output #0: loss = 0.00666824 (* 1 = 0.00666824 loss)
I0616 09:20:56.924455 29366 sgd_solver.cpp:105] Iteration 59800, lr = 0.001
I0616 09:21:54.653699 29366 solver.cpp:218] Iteration 59850 (0.86612 iter/s, 57.7288s/50 iters), loss = 0.00421625
I0616 09:21:54.653880 29366 solver.cpp:237]     Train net output #0: loss = 0.0042163 (* 1 = 0.0042163 loss)
I0616 09:21:54.653904 29366 sgd_solver.cpp:105] Iteration 59850, lr = 0.001
I0616 09:22:52.369191 29366 solver.cpp:218] Iteration 59900 (0.866329 iter/s, 57.7148s/50 iters), loss = 0.00619171
I0616 09:22:52.369313 29366 solver.cpp:237]     Train net output #0: loss = 0.00619176 (* 1 = 0.00619176 loss)
I0616 09:22:52.369338 29366 sgd_solver.cpp:105] Iteration 59900, lr = 0.001
I0616 09:23:50.100118 29366 solver.cpp:218] Iteration 59950 (0.866096 iter/s, 57.7303s/50 iters), loss = 0.00417949
I0616 09:23:50.100241 29366 solver.cpp:237]     Train net output #0: loss = 0.00417954 (* 1 = 0.00417954 loss)
I0616 09:23:50.100265 29366 sgd_solver.cpp:105] Iteration 59950, lr = 0.001
I0616 09:24:46.674298 29366 solver.cpp:447] Snapshotting to binary proto file mobilenet/mobile_2_iter_60000.caffemodel
I0616 09:24:46.755352 29366 sgd_solver.cpp:273] Snapshotting solver state to binary proto file mobilenet/mobile_2_iter_60000.solverstate
I0616 09:24:47.936580 29366 solver.cpp:218] Iteration 60000 (0.864516 iter/s, 57.8358s/50 iters), loss = 0.00449195
I0616 09:24:47.936663 29366 solver.cpp:237]     Train net output #0: loss = 0.004492 (* 1 = 0.004492 loss)
I0616 09:24:47.936686 29366 sgd_solver.cpp:105] Iteration 60000, lr = 0.001
I0616 09:25:45.646598 29366 solver.cpp:218] Iteration 60050 (0.86641 iter/s, 57.7094s/50 iters), loss = 0.00342877
I0616 09:25:45.646730 29366 solver.cpp:237]     Train net output #0: loss = 0.00342882 (* 1 = 0.00342882 loss)
I0616 09:25:45.646754 29366 sgd_solver.cpp:105] Iteration 60050, lr = 0.001
I0616 09:26:43.374188 29366 solver.cpp:218] Iteration 60100 (0.866147 iter/s, 57.7269s/50 iters), loss = 0.00394085
I0616 09:26:43.375696 29366 solver.cpp:237]     Train net output #0: loss = 0.0039409 (* 1 = 0.0039409 loss)
I0616 09:26:43.375722 29366 sgd_solver.cpp:105] Iteration 60100, lr = 0.001
I0616 09:27:41.107012 29366 solver.cpp:218] Iteration 60150 (0.866089 iter/s, 57.7308s/50 iters), loss = 0.00475143
I0616 09:27:41.107153 29366 solver.cpp:237]     Train net output #0: loss = 0.00475149 (* 1 = 0.00475149 loss)
I0616 09:27:41.107178 29366 sgd_solver.cpp:105] Iteration 60150, lr = 0.001
I0616 09:28:38.827505 29366 solver.cpp:218] Iteration 60200 (0.866253 iter/s, 57.7198s/50 iters), loss = 0.0073119
I0616 09:28:38.827651 29366 solver.cpp:237]     Train net output #0: loss = 0.00731195 (* 1 = 0.00731195 loss)
I0616 09:28:38.827673 29366 sgd_solver.cpp:105] Iteration 60200, lr = 0.001
I0616 09:29:36.549998 29366 solver.cpp:218] Iteration 60250 (0.866223 iter/s, 57.7218s/50 iters), loss = 0.00389664
I0616 09:29:36.550130 29366 solver.cpp:237]     Train net output #0: loss = 0.00389669 (* 1 = 0.00389669 loss)
I0616 09:29:36.550155 29366 sgd_solver.cpp:105] Iteration 60250, lr = 0.001
I0616 09:30:34.283871 29366 solver.cpp:218] Iteration 60300 (0.866052 iter/s, 57.7332s/50 iters), loss = 0.00443535
I0616 09:30:34.284013 29366 solver.cpp:237]     Train net output #0: loss = 0.0044354 (* 1 = 0.0044354 loss)
I0616 09:30:34.284036 29366 sgd_solver.cpp:105] Iteration 60300, lr = 0.001
I0616 09:31:32.007231 29366 solver.cpp:218] Iteration 60350 (0.86621 iter/s, 57.7227s/50 iters), loss = 0.0077055
I0616 09:31:32.007364 29366 solver.cpp:237]     Train net output #0: loss = 0.00770555 (* 1 = 0.00770555 loss)
I0616 09:31:32.007387 29366 sgd_solver.cpp:105] Iteration 60350, lr = 0.001
I0616 09:32:29.737627 29366 solver.cpp:218] Iteration 60400 (0.866105 iter/s, 57.7298s/50 iters), loss = 0.00653477
I0616 09:32:29.737776 29366 solver.cpp:237]     Train net output #0: loss = 0.00653482 (* 1 = 0.00653482 loss)
I0616 09:32:29.737800 29366 sgd_solver.cpp:105] Iteration 60400, lr = 0.001
I0616 09:33:27.484985 29366 solver.cpp:218] Iteration 60450 (0.86585 iter/s, 57.7467s/50 iters), loss = 0.00619175
I0616 09:33:27.485177 29366 solver.cpp:237]     Train net output #0: loss = 0.00619181 (* 1 = 0.00619181 loss)
I0616 09:33:27.485200 29366 sgd_solver.cpp:105] Iteration 60450, lr = 0.001
I0616 09:34:25.211267 29366 solver.cpp:218] Iteration 60500 (0.866167 iter/s, 57.7256s/50 iters), loss = 0.00454805
I0616 09:34:25.211400 29366 solver.cpp:237]     Train net output #0: loss = 0.0045481 (* 1 = 0.0045481 loss)
I0616 09:34:25.211424 29366 sgd_solver.cpp:105] Iteration 60500, lr = 0.001
I0616 09:35:22.934468 29366 solver.cpp:218] Iteration 60550 (0.866213 iter/s, 57.7225s/50 iters), loss = 0.00346363
I0616 09:35:22.934610 29366 solver.cpp:237]     Train net output #0: loss = 0.00346368 (* 1 = 0.00346368 loss)
I0616 09:35:22.934634 29366 sgd_solver.cpp:105] Iteration 60550, lr = 0.001
I0616 09:36:20.655043 29366 solver.cpp:218] Iteration 60600 (0.866252 iter/s, 57.7199s/50 iters), loss = 0.00375655
I0616 09:36:20.655169 29366 solver.cpp:237]     Train net output #0: loss = 0.00375661 (* 1 = 0.00375661 loss)
I0616 09:36:20.655194 29366 sgd_solver.cpp:105] Iteration 60600, lr = 0.001
I0616 09:37:18.374922 29366 solver.cpp:218] Iteration 60650 (0.866262 iter/s, 57.7192s/50 iters), loss = 0.00766684
I0616 09:37:18.375048 29366 solver.cpp:237]     Train net output #0: loss = 0.0076669 (* 1 = 0.0076669 loss)
I0616 09:37:18.375072 29366 sgd_solver.cpp:105] Iteration 60650, lr = 0.001
I0616 09:38:16.106600 29366 solver.cpp:218] Iteration 60700 (0.866085 iter/s, 57.731s/50 iters), loss = 0.00587629
I0616 09:38:16.106734 29366 solver.cpp:237]     Train net output #0: loss = 0.00587634 (* 1 = 0.00587634 loss)
I0616 09:38:16.106763 29366 sgd_solver.cpp:105] Iteration 60700, lr = 0.001
I0616 09:39:15.703618 29366 solver.cpp:218] Iteration 60750 (0.839001 iter/s, 59.5947s/50 iters), loss = 0.0038113
I0616 09:39:15.708793 29366 solver.cpp:237]     Train net output #0: loss = 0.00381135 (* 1 = 0.00381135 loss)
I0616 09:39:15.708827 29366 sgd_solver.cpp:105] Iteration 60750, lr = 0.001
I0616 09:41:16.403501 29366 solver.cpp:218] Iteration 60800 (0.414272 iter/s, 120.694s/50 iters), loss = 0.00327121
I0616 09:41:16.403657 29366 solver.cpp:237]     Train net output #0: loss = 0.00327126 (* 1 = 0.00327126 loss)
I0616 09:41:16.403683 29366 sgd_solver.cpp:105] Iteration 60800, lr = 0.001
I0616 09:42:14.122601 29366 solver.cpp:218] Iteration 60850 (0.866274 iter/s, 57.7185s/50 iters), loss = 0.00567844
I0616 09:42:14.122735 29366 solver.cpp:237]     Train net output #0: loss = 0.00567849 (* 1 = 0.00567849 loss)
I0616 09:42:14.122761 29366 sgd_solver.cpp:105] Iteration 60850, lr = 0.001
I0616 09:43:11.846052 29366 solver.cpp:218] Iteration 60900 (0.866209 iter/s, 57.7228s/50 iters), loss = 0.00343793
I0616 09:43:11.846194 29366 solver.cpp:237]     Train net output #0: loss = 0.00343798 (* 1 = 0.00343798 loss)
I0616 09:43:11.846217 29366 sgd_solver.cpp:105] Iteration 60900, lr = 0.001
I0616 09:44:09.978631 29366 solver.cpp:218] Iteration 60950 (0.86023 iter/s, 58.124s/50 iters), loss = 0.00661239
I0616 09:44:09.982616 29366 solver.cpp:237]     Train net output #0: loss = 0.00661245 (* 1 = 0.00661245 loss)
I0616 09:44:09.982655 29366 sgd_solver.cpp:105] Iteration 60950, lr = 0.001
I0616 09:46:03.221758 29366 solver.cpp:218] Iteration 61000 (0.441547 iter/s, 113.238s/50 iters), loss = 0.00465573
I0616 09:46:03.222075 29366 solver.cpp:237]     Train net output #0: loss = 0.00465578 (* 1 = 0.00465578 loss)
I0616 09:46:03.222100 29366 sgd_solver.cpp:105] Iteration 61000, lr = 0.001
I0616 09:47:00.922288 29366 solver.cpp:218] Iteration 61050 (0.866555 iter/s, 57.6997s/50 iters), loss = 0.00668493
I0616 09:47:00.922438 29366 solver.cpp:237]     Train net output #0: loss = 0.00668498 (* 1 = 0.00668498 loss)
I0616 09:47:00.922462 29366 sgd_solver.cpp:105] Iteration 61050, lr = 0.001
I0616 09:47:58.635530 29366 solver.cpp:218] Iteration 61100 (0.866362 iter/s, 57.7126s/50 iters), loss = 0.00438387
I0616 09:47:58.635727 29366 solver.cpp:237]     Train net output #0: loss = 0.00438393 (* 1 = 0.00438393 loss)
I0616 09:47:58.635752 29366 sgd_solver.cpp:105] Iteration 61100, lr = 0.001
I0616 09:50:00.052625 29366 solver.cpp:218] Iteration 61150 (0.411808 iter/s, 121.416s/50 iters), loss = 0.00559871
I0616 09:50:00.052769 29366 solver.cpp:237]     Train net output #0: loss = 0.00559876 (* 1 = 0.00559876 loss)
I0616 09:50:00.052800 29366 sgd_solver.cpp:105] Iteration 61150, lr = 0.001
I0616 09:50:57.792899 29366 solver.cpp:218] Iteration 61200 (0.865956 iter/s, 57.7396s/50 iters), loss = 0.00696121
I0616 09:50:57.793033 29366 solver.cpp:237]     Train net output #0: loss = 0.00696126 (* 1 = 0.00696126 loss)
I0616 09:50:57.793058 29366 sgd_solver.cpp:105] Iteration 61200, lr = 0.001
I0616 09:51:55.529881 29366 solver.cpp:218] Iteration 61250 (0.866006 iter/s, 57.7363s/50 iters), loss = 0.00401059
I0616 09:51:55.530019 29366 solver.cpp:237]     Train net output #0: loss = 0.00401064 (* 1 = 0.00401064 loss)
I0616 09:51:55.530043 29366 sgd_solver.cpp:105] Iteration 61250, lr = 0.001
I0616 09:52:53.256289 29366 solver.cpp:218] Iteration 61300 (0.866165 iter/s, 57.7257s/50 iters), loss = 0.00503707
I0616 09:52:53.256408 29366 solver.cpp:237]     Train net output #0: loss = 0.00503712 (* 1 = 0.00503712 loss)
I0616 09:52:53.256434 29366 sgd_solver.cpp:105] Iteration 61300, lr = 0.001
I0616 09:53:50.983713 29366 solver.cpp:218] Iteration 61350 (0.866149 iter/s, 57.7268s/50 iters), loss = 0.00455341
I0616 09:53:50.983880 29366 solver.cpp:237]     Train net output #0: loss = 0.00455346 (* 1 = 0.00455346 loss)
I0616 09:53:50.983903 29366 sgd_solver.cpp:105] Iteration 61350, lr = 0.001
I0616 09:54:48.719861 29366 solver.cpp:218] Iteration 61400 (0.866019 iter/s, 57.7354s/50 iters), loss = 0.00451475
I0616 09:54:48.719990 29366 solver.cpp:237]     Train net output #0: loss = 0.00451481 (* 1 = 0.00451481 loss)
I0616 09:54:48.720013 29366 sgd_solver.cpp:105] Iteration 61400, lr = 0.001
I0616 09:55:46.447969 29366 solver.cpp:218] Iteration 61450 (0.866139 iter/s, 57.7274s/50 iters), loss = 0.00424345
I0616 09:55:46.448118 29366 solver.cpp:237]     Train net output #0: loss = 0.00424351 (* 1 = 0.00424351 loss)
I0616 09:55:46.448143 29366 sgd_solver.cpp:105] Iteration 61450, lr = 0.001
I0616 09:56:44.196045 29366 solver.cpp:218] Iteration 61500 (0.86584 iter/s, 57.7474s/50 iters), loss = 0.00335933
I0616 09:56:44.196285 29366 solver.cpp:237]     Train net output #0: loss = 0.00335938 (* 1 = 0.00335938 loss)
I0616 09:56:44.196310 29366 sgd_solver.cpp:105] Iteration 61500, lr = 0.001
I0616 09:57:41.949352 29366 solver.cpp:218] Iteration 61550 (0.865763 iter/s, 57.7525s/50 iters), loss = 0.00365992
I0616 09:57:41.949533 29366 solver.cpp:237]     Train net output #0: loss = 0.00365997 (* 1 = 0.00365997 loss)
I0616 09:57:41.949560 29366 sgd_solver.cpp:105] Iteration 61550, lr = 0.001
I0616 09:58:39.730311 29366 solver.cpp:218] Iteration 61600 (0.865348 iter/s, 57.7802s/50 iters), loss = 0.00647881
I0616 09:58:39.730497 29366 solver.cpp:237]     Train net output #0: loss = 0.00647886 (* 1 = 0.00647886 loss)
I0616 09:58:39.730527 29366 sgd_solver.cpp:105] Iteration 61600, lr = 0.001
I0616 09:59:37.502806 29366 solver.cpp:218] Iteration 61650 (0.865475 iter/s, 57.7717s/50 iters), loss = 0.00713581
I0616 09:59:37.506846 29366 solver.cpp:237]     Train net output #0: loss = 0.00713586 (* 1 = 0.00713586 loss)
I0616 09:59:37.506878 29366 sgd_solver.cpp:105] Iteration 61650, lr = 0.001
I0616 10:01:07.834612 29366 solver.cpp:218] Iteration 61700 (0.553848 iter/s, 90.2774s/50 iters), loss = 0.00512093
I0616 10:01:07.838630 29366 solver.cpp:237]     Train net output #0: loss = 0.00512098 (* 1 = 0.00512098 loss)
I0616 10:01:07.838661 29366 sgd_solver.cpp:105] Iteration 61700, lr = 0.001
I0616 10:02:22.622848 29366 solver.cpp:218] Iteration 61750 (0.668596 iter/s, 74.7836s/50 iters), loss = 0.00469863
I0616 10:02:22.623031 29366 solver.cpp:237]     Train net output #0: loss = 0.00469868 (* 1 = 0.00469868 loss)
I0616 10:02:22.623054 29366 sgd_solver.cpp:105] Iteration 61750, lr = 0.001
I0616 10:03:20.400521 29366 solver.cpp:218] Iteration 61800 (0.865397 iter/s, 57.777s/50 iters), loss = 0.0083462
I0616 10:03:20.400712 29366 solver.cpp:237]     Train net output #0: loss = 0.00834625 (* 1 = 0.00834625 loss)
I0616 10:03:20.400748 29366 sgd_solver.cpp:105] Iteration 61800, lr = 0.001
I0616 10:04:18.160815 29366 solver.cpp:218] Iteration 61850 (0.865658 iter/s, 57.7595s/50 iters), loss = 0.00747287
I0616 10:04:18.160971 29366 solver.cpp:237]     Train net output #0: loss = 0.00747292 (* 1 = 0.00747292 loss)
I0616 10:04:18.160996 29366 sgd_solver.cpp:105] Iteration 61850, lr = 0.001
I0616 10:05:16.246384 29366 solver.cpp:218] Iteration 61900 (0.86081 iter/s, 58.0848s/50 iters), loss = 0.00452335
I0616 10:05:16.254575 29366 solver.cpp:237]     Train net output #0: loss = 0.00452341 (* 1 = 0.00452341 loss)
I0616 10:05:16.254631 29366 sgd_solver.cpp:105] Iteration 61900, lr = 0.001
I0616 10:06:14.543978 29366 solver.cpp:218] Iteration 61950 (0.857797 iter/s, 58.2889s/50 iters), loss = 0.00668393
I0616 10:06:14.544175 29366 solver.cpp:237]     Train net output #0: loss = 0.00668398 (* 1 = 0.00668398 loss)
I0616 10:06:14.544198 29366 sgd_solver.cpp:105] Iteration 61950, lr = 0.001
I0616 10:07:12.577484 29366 solver.cpp:218] Iteration 62000 (0.861583 iter/s, 58.0327s/50 iters), loss = 0.00403447
I0616 10:07:12.577709 29366 solver.cpp:237]     Train net output #0: loss = 0.00403452 (* 1 = 0.00403452 loss)
I0616 10:07:12.577739 29366 sgd_solver.cpp:105] Iteration 62000, lr = 0.001
I0616 10:08:10.604018 29366 solver.cpp:218] Iteration 62050 (0.861687 iter/s, 58.0257s/50 iters), loss = 0.005535
I0616 10:08:10.608605 29366 solver.cpp:237]     Train net output #0: loss = 0.00553506 (* 1 = 0.00553506 loss)
I0616 10:08:10.608634 29366 sgd_solver.cpp:105] Iteration 62050, lr = 0.001
I0616 10:09:09.099082 29366 solver.cpp:218] Iteration 62100 (0.854848 iter/s, 58.4899s/50 iters), loss = 0.00548351
I0616 10:09:09.102558 29366 solver.cpp:237]     Train net output #0: loss = 0.00548356 (* 1 = 0.00548356 loss)
I0616 10:09:09.102598 29366 sgd_solver.cpp:105] Iteration 62100, lr = 0.001
I0616 10:10:07.736956 29366 solver.cpp:218] Iteration 62150 (0.85275 iter/s, 58.6338s/50 iters), loss = 0.0042197
I0616 10:10:07.741605 29366 solver.cpp:237]     Train net output #0: loss = 0.00421976 (* 1 = 0.00421976 loss)
I0616 10:10:07.741670 29366 sgd_solver.cpp:105] Iteration 62150, lr = 0.001
I0616 10:11:05.950556 29366 solver.cpp:218] Iteration 62200 (0.858983 iter/s, 58.2084s/50 iters), loss = 0.0039446
I0616 10:11:05.950759 29366 solver.cpp:237]     Train net output #0: loss = 0.00394465 (* 1 = 0.00394465 loss)
I0616 10:11:05.950793 29366 sgd_solver.cpp:105] Iteration 62200, lr = 0.001
I0616 10:12:03.678655 29366 solver.cpp:218] Iteration 62250 (0.86614 iter/s, 57.7274s/50 iters), loss = 0.00391341
I0616 10:12:03.678783 29366 solver.cpp:237]     Train net output #0: loss = 0.00391346 (* 1 = 0.00391346 loss)
I0616 10:12:03.678812 29366 sgd_solver.cpp:105] Iteration 62250, lr = 0.001
I0616 10:13:01.498543 29366 solver.cpp:218] Iteration 62300 (0.864765 iter/s, 57.8192s/50 iters), loss = 0.00610376
I0616 10:13:01.498687 29366 solver.cpp:237]     Train net output #0: loss = 0.00610382 (* 1 = 0.00610382 loss)
I0616 10:13:01.498713 29366 sgd_solver.cpp:105] Iteration 62300, lr = 0.001
I0616 10:13:59.222641 29366 solver.cpp:218] Iteration 62350 (0.8662 iter/s, 57.7234s/50 iters), loss = 0.00682892
I0616 10:13:59.222777 29366 solver.cpp:237]     Train net output #0: loss = 0.00682898 (* 1 = 0.00682898 loss)
I0616 10:13:59.222806 29366 sgd_solver.cpp:105] Iteration 62350, lr = 0.001
I0616 10:14:57.029348 29366 solver.cpp:218] Iteration 62400 (0.864962 iter/s, 57.806s/50 iters), loss = 0.00313803
I0616 10:14:57.029502 29366 solver.cpp:237]     Train net output #0: loss = 0.00313809 (* 1 = 0.00313809 loss)
I0616 10:14:57.029543 29366 sgd_solver.cpp:105] Iteration 62400, lr = 0.001
I0616 10:15:54.752461 29366 solver.cpp:218] Iteration 62450 (0.866215 iter/s, 57.7224s/50 iters), loss = 0.00575679
I0616 10:15:54.752586 29366 solver.cpp:237]     Train net output #0: loss = 0.00575685 (* 1 = 0.00575685 loss)
I0616 10:15:54.752614 29366 sgd_solver.cpp:105] Iteration 62450, lr = 0.001
I0616 10:16:52.476598 29366 solver.cpp:218] Iteration 62500 (0.866199 iter/s, 57.7235s/50 iters), loss = 0.00454475
I0616 10:16:52.476814 29366 solver.cpp:237]     Train net output #0: loss = 0.0045448 (* 1 = 0.0045448 loss)
I0616 10:16:52.476843 29366 sgd_solver.cpp:105] Iteration 62500, lr = 0.001
I0616 10:17:50.199823 29366 solver.cpp:218] Iteration 62550 (0.866214 iter/s, 57.7225s/50 iters), loss = 0.00495487
I0616 10:17:50.199985 29366 solver.cpp:237]     Train net output #0: loss = 0.00495492 (* 1 = 0.00495492 loss)
I0616 10:17:50.200014 29366 sgd_solver.cpp:105] Iteration 62550, lr = 0.001
I0616 10:18:47.923485 29366 solver.cpp:218] Iteration 62600 (0.866207 iter/s, 57.723s/50 iters), loss = 0.00483455
I0616 10:18:47.923642 29366 solver.cpp:237]     Train net output #0: loss = 0.0048346 (* 1 = 0.0048346 loss)
I0616 10:18:47.923671 29366 sgd_solver.cpp:105] Iteration 62600, lr = 0.001
I0616 10:19:45.655342 29366 solver.cpp:218] Iteration 62650 (0.866084 iter/s, 57.7311s/50 iters), loss = 0.00525896
I0616 10:19:45.655495 29366 solver.cpp:237]     Train net output #0: loss = 0.00525902 (* 1 = 0.00525902 loss)
I0616 10:19:45.655526 29366 sgd_solver.cpp:105] Iteration 62650, lr = 0.001
I0616 10:20:43.449049 29366 solver.cpp:218] Iteration 62700 (0.865157 iter/s, 57.793s/50 iters), loss = 0.00321838
I0616 10:20:43.449195 29366 solver.cpp:237]     Train net output #0: loss = 0.00321843 (* 1 = 0.00321843 loss)
I0616 10:20:43.449223 29366 sgd_solver.cpp:105] Iteration 62700, lr = 0.001
I0616 10:21:41.305609 29366 solver.cpp:218] Iteration 62750 (0.864274 iter/s, 57.852s/50 iters), loss = 0.00307857
I0616 10:21:41.309604 29366 solver.cpp:237]     Train net output #0: loss = 0.00307862 (* 1 = 0.00307862 loss)
I0616 10:21:41.309631 29366 sgd_solver.cpp:105] Iteration 62750, lr = 0.001
I0616 10:22:40.826851 29366 solver.cpp:218] Iteration 62800 (0.840101 iter/s, 59.5166s/50 iters), loss = 0.00565636
I0616 10:22:40.827083 29366 solver.cpp:237]     Train net output #0: loss = 0.00565642 (* 1 = 0.00565642 loss)
I0616 10:22:40.827111 29366 sgd_solver.cpp:105] Iteration 62800, lr = 0.001
I0616 10:23:38.875000 29366 solver.cpp:218] Iteration 62850 (0.861366 iter/s, 58.0473s/50 iters), loss = 0.00405218
I0616 10:23:38.875155 29366 solver.cpp:237]     Train net output #0: loss = 0.00405224 (* 1 = 0.00405224 loss)
I0616 10:23:38.875185 29366 sgd_solver.cpp:105] Iteration 62850, lr = 0.001
I0616 10:24:36.894237 29366 solver.cpp:218] Iteration 62900 (0.861795 iter/s, 58.0184s/50 iters), loss = 0.00455023
I0616 10:24:36.898635 29366 solver.cpp:237]     Train net output #0: loss = 0.00455028 (* 1 = 0.00455028 loss)
I0616 10:24:36.898668 29366 sgd_solver.cpp:105] Iteration 62900, lr = 0.001
I0616 10:25:35.112607 29366 solver.cpp:218] Iteration 62950 (0.858951 iter/s, 58.2105s/50 iters), loss = 0.0047243
I0616 10:25:35.116612 29366 solver.cpp:237]     Train net output #0: loss = 0.00472436 (* 1 = 0.00472436 loss)
I0616 10:25:35.116644 29366 sgd_solver.cpp:105] Iteration 62950, lr = 0.001
I0616 10:26:33.430053 29366 solver.cpp:218] Iteration 63000 (0.857445 iter/s, 58.3128s/50 iters), loss = 0.00342589
I0616 10:26:33.433655 29366 solver.cpp:237]     Train net output #0: loss = 0.00342594 (* 1 = 0.00342594 loss)
I0616 10:26:33.433703 29366 sgd_solver.cpp:105] Iteration 63000, lr = 0.001
I0616 10:27:31.579639 29366 solver.cpp:218] Iteration 63050 (0.859915 iter/s, 58.1453s/50 iters), loss = 0.00266219
I0616 10:27:31.583662 29366 solver.cpp:237]     Train net output #0: loss = 0.00266224 (* 1 = 0.00266224 loss)
I0616 10:27:31.583715 29366 sgd_solver.cpp:105] Iteration 63050, lr = 0.001
I0616 10:28:29.372031 29366 solver.cpp:218] Iteration 63100 (0.865235 iter/s, 57.7877s/50 iters), loss = 0.00625047
I0616 10:28:29.372225 29366 solver.cpp:237]     Train net output #0: loss = 0.00625052 (* 1 = 0.00625052 loss)
I0616 10:28:29.372251 29366 sgd_solver.cpp:105] Iteration 63100, lr = 0.001
I0616 10:29:27.124737 29366 solver.cpp:218] Iteration 63150 (0.865772 iter/s, 57.7519s/50 iters), loss = 0.00495447
I0616 10:29:27.124938 29366 solver.cpp:237]     Train net output #0: loss = 0.00495452 (* 1 = 0.00495452 loss)
I0616 10:29:27.124977 29366 sgd_solver.cpp:105] Iteration 63150, lr = 0.001
I0616 10:30:24.886380 29366 solver.cpp:218] Iteration 63200 (0.865638 iter/s, 57.7609s/50 iters), loss = 0.00293386
I0616 10:30:24.886529 29366 solver.cpp:237]     Train net output #0: loss = 0.00293391 (* 1 = 0.00293391 loss)
I0616 10:30:24.886559 29366 sgd_solver.cpp:105] Iteration 63200, lr = 0.001
I0616 10:31:22.646026 29366 solver.cpp:218] Iteration 63250 (0.865667 iter/s, 57.7589s/50 iters), loss = 0.0044535
I0616 10:31:22.646158 29366 solver.cpp:237]     Train net output #0: loss = 0.00445356 (* 1 = 0.00445356 loss)
I0616 10:31:22.646185 29366 sgd_solver.cpp:105] Iteration 63250, lr = 0.001
I0616 10:32:20.397887 29366 solver.cpp:218] Iteration 63300 (0.865784 iter/s, 57.7511s/50 iters), loss = 0.00566528
I0616 10:32:20.398020 29366 solver.cpp:237]     Train net output #0: loss = 0.00566534 (* 1 = 0.00566534 loss)
I0616 10:32:20.398046 29366 sgd_solver.cpp:105] Iteration 63300, lr = 0.001
I0616 10:33:18.153554 29366 solver.cpp:218] Iteration 63350 (0.865727 iter/s, 57.7549s/50 iters), loss = 0.00390605
I0616 10:33:18.153687 29366 solver.cpp:237]     Train net output #0: loss = 0.00390611 (* 1 = 0.00390611 loss)
I0616 10:33:18.153718 29366 sgd_solver.cpp:105] Iteration 63350, lr = 0.001
I0616 10:34:15.909590 29366 solver.cpp:218] Iteration 63400 (0.865721 iter/s, 57.7553s/50 iters), loss = 0.00658567
I0616 10:34:15.909732 29366 solver.cpp:237]     Train net output #0: loss = 0.00658573 (* 1 = 0.00658573 loss)
I0616 10:34:15.909759 29366 sgd_solver.cpp:105] Iteration 63400, lr = 0.001
I0616 10:35:13.660116 29366 solver.cpp:218] Iteration 63450 (0.865804 iter/s, 57.7498s/50 iters), loss = 0.00462583
I0616 10:35:13.660245 29366 solver.cpp:237]     Train net output #0: loss = 0.00462588 (* 1 = 0.00462588 loss)
I0616 10:35:13.660271 29366 sgd_solver.cpp:105] Iteration 63450, lr = 0.001
I0616 10:36:11.420815 29366 solver.cpp:218] Iteration 63500 (0.865652 iter/s, 57.7599s/50 iters), loss = 0.00420844
I0616 10:36:11.420948 29366 solver.cpp:237]     Train net output #0: loss = 0.00420849 (* 1 = 0.00420849 loss)
I0616 10:36:11.420981 29366 sgd_solver.cpp:105] Iteration 63500, lr = 0.001
I0616 10:37:09.178210 29366 solver.cpp:218] Iteration 63550 (0.865701 iter/s, 57.7567s/50 iters), loss = 0.00352339
I0616 10:37:09.178333 29366 solver.cpp:237]     Train net output #0: loss = 0.00352345 (* 1 = 0.00352345 loss)
I0616 10:37:09.178359 29366 sgd_solver.cpp:105] Iteration 63550, lr = 0.001
I0616 10:38:06.944375 29366 solver.cpp:218] Iteration 63600 (0.865569 iter/s, 57.7654s/50 iters), loss = 0.00500615
I0616 10:38:06.944509 29366 solver.cpp:237]     Train net output #0: loss = 0.00500621 (* 1 = 0.00500621 loss)
I0616 10:38:06.944542 29366 sgd_solver.cpp:105] Iteration 63600, lr = 0.001
I0616 10:39:04.701333 29366 solver.cpp:218] Iteration 63650 (0.865707 iter/s, 57.7562s/50 iters), loss = 0.00421675
I0616 10:39:04.701454 29366 solver.cpp:237]     Train net output #0: loss = 0.00421681 (* 1 = 0.00421681 loss)
I0616 10:39:04.701481 29366 sgd_solver.cpp:105] Iteration 63650, lr = 0.001
I0616 10:40:02.466274 29366 solver.cpp:218] Iteration 63700 (0.865587 iter/s, 57.7643s/50 iters), loss = 0.00422632
I0616 10:40:02.466404 29366 solver.cpp:237]     Train net output #0: loss = 0.00422637 (* 1 = 0.00422637 loss)
I0616 10:40:02.466430 29366 sgd_solver.cpp:105] Iteration 63700, lr = 0.001
I0616 10:41:00.232892 29366 solver.cpp:218] Iteration 63750 (0.865561 iter/s, 57.766s/50 iters), loss = 0.00494592
I0616 10:41:00.233026 29366 solver.cpp:237]     Train net output #0: loss = 0.00494598 (* 1 = 0.00494598 loss)
I0616 10:41:00.233053 29366 sgd_solver.cpp:105] Iteration 63750, lr = 0.001
I0616 10:41:57.993986 29366 solver.cpp:218] Iteration 63800 (0.865644 iter/s, 57.7605s/50 iters), loss = 0.0050112
I0616 10:41:57.994123 29366 solver.cpp:237]     Train net output #0: loss = 0.00501126 (* 1 = 0.00501126 loss)
I0616 10:41:57.994149 29366 sgd_solver.cpp:105] Iteration 63800, lr = 0.001
I0616 10:42:55.760334 29366 solver.cpp:218] Iteration 63850 (0.865565 iter/s, 57.7657s/50 iters), loss = 0.00516431
I0616 10:42:55.760509 29366 solver.cpp:237]     Train net output #0: loss = 0.00516437 (* 1 = 0.00516437 loss)
I0616 10:42:55.760542 29366 sgd_solver.cpp:105] Iteration 63850, lr = 0.001
I0616 10:43:53.517320 29366 solver.cpp:218] Iteration 63900 (0.865706 iter/s, 57.7563s/50 iters), loss = 0.0056887
I0616 10:43:53.517454 29366 solver.cpp:237]     Train net output #0: loss = 0.00568875 (* 1 = 0.00568875 loss)
I0616 10:43:53.517482 29366 sgd_solver.cpp:105] Iteration 63900, lr = 0.001
I0616 10:44:51.275480 29366 solver.cpp:218] Iteration 63950 (0.865688 iter/s, 57.7575s/50 iters), loss = 0.00549446
I0616 10:44:51.275768 29366 solver.cpp:237]     Train net output #0: loss = 0.00549451 (* 1 = 0.00549451 loss)
I0616 10:44:51.275796 29366 sgd_solver.cpp:105] Iteration 63950, lr = 0.001
I0616 10:45:49.024899 29366 solver.cpp:218] Iteration 64000 (0.865821 iter/s, 57.7486s/50 iters), loss = 0.00651985
I0616 10:45:49.025090 29366 solver.cpp:237]     Train net output #0: loss = 0.00651991 (* 1 = 0.00651991 loss)
I0616 10:45:49.025117 29366 sgd_solver.cpp:105] Iteration 64000, lr = 0.001
I0616 10:46:46.784129 29366 solver.cpp:218] Iteration 64050 (0.865673 iter/s, 57.7585s/50 iters), loss = 0.00428464
I0616 10:46:46.784286 29366 solver.cpp:237]     Train net output #0: loss = 0.00428469 (* 1 = 0.00428469 loss)
I0616 10:46:46.784312 29366 sgd_solver.cpp:105] Iteration 64050, lr = 0.001
I0616 10:47:44.541733 29366 solver.cpp:218] Iteration 64100 (0.865697 iter/s, 57.757s/50 iters), loss = 0.00475016
I0616 10:47:44.541877 29366 solver.cpp:237]     Train net output #0: loss = 0.00475021 (* 1 = 0.00475021 loss)
I0616 10:47:44.541909 29366 sgd_solver.cpp:105] Iteration 64100, lr = 0.001
I0616 10:48:42.291091 29366 solver.cpp:218] Iteration 64150 (0.86582 iter/s, 57.7487s/50 iters), loss = 0.00400569
I0616 10:48:42.291216 29366 solver.cpp:237]     Train net output #0: loss = 0.00400575 (* 1 = 0.00400575 loss)
I0616 10:48:42.291242 29366 sgd_solver.cpp:105] Iteration 64150, lr = 0.001
I0616 10:49:40.038105 29366 solver.cpp:218] Iteration 64200 (0.865855 iter/s, 57.7464s/50 iters), loss = 0.00657006
I0616 10:49:40.038242 29366 solver.cpp:237]     Train net output #0: loss = 0.00657011 (* 1 = 0.00657011 loss)
I0616 10:49:40.038269 29366 sgd_solver.cpp:105] Iteration 64200, lr = 0.001
I0616 10:50:37.803987 29366 solver.cpp:218] Iteration 64250 (0.865572 iter/s, 57.7653s/50 iters), loss = 0.00537193
I0616 10:50:37.804131 29366 solver.cpp:237]     Train net output #0: loss = 0.00537199 (* 1 = 0.00537199 loss)
I0616 10:50:37.804158 29366 sgd_solver.cpp:105] Iteration 64250, lr = 0.001
I0616 10:51:35.574231 29366 solver.cpp:218] Iteration 64300 (0.865507 iter/s, 57.7696s/50 iters), loss = 0.00324353
I0616 10:51:35.574367 29366 solver.cpp:237]     Train net output #0: loss = 0.00324358 (* 1 = 0.00324358 loss)
I0616 10:51:35.574393 29366 sgd_solver.cpp:105] Iteration 64300, lr = 0.001
I0616 10:52:33.326705 29366 solver.cpp:218] Iteration 64350 (0.865773 iter/s, 57.7518s/50 iters), loss = 0.00438386
I0616 10:52:33.326853 29366 solver.cpp:237]     Train net output #0: loss = 0.00438391 (* 1 = 0.00438391 loss)
I0616 10:52:33.326879 29366 sgd_solver.cpp:105] Iteration 64350, lr = 0.001
I0616 10:53:31.089828 29366 solver.cpp:218] Iteration 64400 (0.865614 iter/s, 57.7625s/50 iters), loss = 0.00512739
I0616 10:53:31.089949 29366 solver.cpp:237]     Train net output #0: loss = 0.00512745 (* 1 = 0.00512745 loss)
I0616 10:53:31.089974 29366 sgd_solver.cpp:105] Iteration 64400, lr = 0.001
I0616 10:54:28.846029 29366 solver.cpp:218] Iteration 64450 (0.865718 iter/s, 57.7556s/50 iters), loss = 0.00502044
I0616 10:54:28.846144 29366 solver.cpp:237]     Train net output #0: loss = 0.00502049 (* 1 = 0.00502049 loss)
I0616 10:54:28.846176 29366 sgd_solver.cpp:105] Iteration 64450, lr = 0.001
I0616 10:55:26.607964 29366 solver.cpp:218] Iteration 64500 (0.865631 iter/s, 57.7613s/50 iters), loss = 0.00629774
I0616 10:55:26.608247 29366 solver.cpp:237]     Train net output #0: loss = 0.00629779 (* 1 = 0.00629779 loss)
I0616 10:55:26.608283 29366 sgd_solver.cpp:105] Iteration 64500, lr = 0.001
I0616 10:56:24.364521 29366 solver.cpp:218] Iteration 64550 (0.865714 iter/s, 57.7558s/50 iters), loss = 0.00489985
I0616 10:56:24.364694 29366 solver.cpp:237]     Train net output #0: loss = 0.00489991 (* 1 = 0.00489991 loss)
I0616 10:56:24.364719 29366 sgd_solver.cpp:105] Iteration 64550, lr = 0.001
I0616 10:57:22.113256 29366 solver.cpp:218] Iteration 64600 (0.86583 iter/s, 57.7481s/50 iters), loss = 0.00282716
I0616 10:57:22.113382 29366 solver.cpp:237]     Train net output #0: loss = 0.00282721 (* 1 = 0.00282721 loss)
I0616 10:57:22.113409 29366 sgd_solver.cpp:105] Iteration 64600, lr = 0.001
I0616 10:58:19.860920 29366 solver.cpp:218] Iteration 64650 (0.865845 iter/s, 57.747s/50 iters), loss = 0.00511435
I0616 10:58:19.861050 29366 solver.cpp:237]     Train net output #0: loss = 0.0051144 (* 1 = 0.0051144 loss)
I0616 10:58:19.861080 29366 sgd_solver.cpp:105] Iteration 64650, lr = 0.001
I0616 10:59:17.613708 29366 solver.cpp:218] Iteration 64700 (0.865769 iter/s, 57.7522s/50 iters), loss = 0.00552448
I0616 10:59:17.613847 29366 solver.cpp:237]     Train net output #0: loss = 0.00552453 (* 1 = 0.00552453 loss)
I0616 10:59:17.613873 29366 sgd_solver.cpp:105] Iteration 64700, lr = 0.001
I0616 11:00:15.360698 29366 solver.cpp:218] Iteration 64750 (0.865856 iter/s, 57.7463s/50 iters), loss = 0.00612844
I0616 11:00:15.360832 29366 solver.cpp:237]     Train net output #0: loss = 0.0061285 (* 1 = 0.0061285 loss)
I0616 11:00:15.360858 29366 sgd_solver.cpp:105] Iteration 64750, lr = 0.001
I0616 11:01:13.114998 29366 solver.cpp:218] Iteration 64800 (0.865746 iter/s, 57.7536s/50 iters), loss = 0.00472517
I0616 11:01:13.115131 29366 solver.cpp:237]     Train net output #0: loss = 0.00472522 (* 1 = 0.00472522 loss)
I0616 11:01:13.115164 29366 sgd_solver.cpp:105] Iteration 64800, lr = 0.001
I0616 11:02:10.874475 29366 solver.cpp:218] Iteration 64850 (0.865668 iter/s, 57.7588s/50 iters), loss = 0.00493663
I0616 11:02:10.874617 29366 solver.cpp:237]     Train net output #0: loss = 0.00493668 (* 1 = 0.00493668 loss)
I0616 11:02:10.874642 29366 sgd_solver.cpp:105] Iteration 64850, lr = 0.001
I0616 11:03:08.641566 29366 solver.cpp:218] Iteration 64900 (0.865554 iter/s, 57.7664s/50 iters), loss = 0.00668003
I0616 11:03:08.641681 29366 solver.cpp:237]     Train net output #0: loss = 0.00668009 (* 1 = 0.00668009 loss)
I0616 11:03:08.641706 29366 sgd_solver.cpp:105] Iteration 64900, lr = 0.001
I0616 11:04:06.392820 29366 solver.cpp:218] Iteration 64950 (0.865791 iter/s, 57.7506s/50 iters), loss = 0.0054958
I0616 11:04:06.392966 29366 solver.cpp:237]     Train net output #0: loss = 0.00549585 (* 1 = 0.00549585 loss)
I0616 11:04:06.392993 29366 sgd_solver.cpp:105] Iteration 64950, lr = 0.001
I0616 11:05:04.155777 29366 solver.cpp:218] Iteration 65000 (0.865616 iter/s, 57.7623s/50 iters), loss = 0.00559473
I0616 11:05:04.155912 29366 solver.cpp:237]     Train net output #0: loss = 0.00559479 (* 1 = 0.00559479 loss)
I0616 11:05:04.155939 29366 sgd_solver.cpp:105] Iteration 65000, lr = 0.001
I0616 11:06:01.919886 29366 solver.cpp:218] Iteration 65050 (0.865599 iter/s, 57.7635s/50 iters), loss = 0.00639364
I0616 11:06:01.920014 29366 solver.cpp:237]     Train net output #0: loss = 0.0063937 (* 1 = 0.0063937 loss)
I0616 11:06:01.920047 29366 sgd_solver.cpp:105] Iteration 65050, lr = 0.001
I0616 11:06:59.669709 29366 solver.cpp:218] Iteration 65100 (0.865813 iter/s, 57.7492s/50 iters), loss = 0.0065642
I0616 11:06:59.669836 29366 solver.cpp:237]     Train net output #0: loss = 0.00656426 (* 1 = 0.00656426 loss)
I0616 11:06:59.669862 29366 sgd_solver.cpp:105] Iteration 65100, lr = 0.001
I0616 11:07:57.429101 29366 solver.cpp:218] Iteration 65150 (0.86567 iter/s, 57.7588s/50 iters), loss = 0.00436188
I0616 11:07:57.429224 29366 solver.cpp:237]     Train net output #0: loss = 0.00436193 (* 1 = 0.00436193 loss)
I0616 11:07:57.429252 29366 sgd_solver.cpp:105] Iteration 65150, lr = 0.001
I0616 11:08:55.187227 29366 solver.cpp:218] Iteration 65200 (0.865689 iter/s, 57.7575s/50 iters), loss = 0.00738182
I0616 11:08:55.187403 29366 solver.cpp:237]     Train net output #0: loss = 0.00738188 (* 1 = 0.00738188 loss)
I0616 11:08:55.187435 29366 sgd_solver.cpp:105] Iteration 65200, lr = 0.001
I0616 11:09:52.951608 29366 solver.cpp:218] Iteration 65250 (0.865595 iter/s, 57.7637s/50 iters), loss = 0.00545106
I0616 11:09:52.951741 29366 solver.cpp:237]     Train net output #0: loss = 0.00545112 (* 1 = 0.00545112 loss)
I0616 11:09:52.951767 29366 sgd_solver.cpp:105] Iteration 65250, lr = 0.001
I0616 11:10:50.712220 29366 solver.cpp:218] Iteration 65300 (0.865651 iter/s, 57.76s/50 iters), loss = 0.0027322
I0616 11:10:50.712350 29366 solver.cpp:237]     Train net output #0: loss = 0.00273226 (* 1 = 0.00273226 loss)
I0616 11:10:50.712378 29366 sgd_solver.cpp:105] Iteration 65300, lr = 0.001
I0616 11:11:48.479802 29366 solver.cpp:218] Iteration 65350 (0.865547 iter/s, 57.7669s/50 iters), loss = 0.00460177
I0616 11:11:48.479926 29366 solver.cpp:237]     Train net output #0: loss = 0.00460182 (* 1 = 0.00460182 loss)
I0616 11:11:48.479954 29366 sgd_solver.cpp:105] Iteration 65350, lr = 0.001
I0616 11:12:46.236253 29366 solver.cpp:218] Iteration 65400 (0.865714 iter/s, 57.7558s/50 iters), loss = 0.0058451
I0616 11:12:46.236383 29366 solver.cpp:237]     Train net output #0: loss = 0.00584515 (* 1 = 0.00584515 loss)
I0616 11:12:46.236410 29366 sgd_solver.cpp:105] Iteration 65400, lr = 0.001
I0616 11:13:43.986233 29366 solver.cpp:218] Iteration 65450 (0.86581 iter/s, 57.7494s/50 iters), loss = 0.00493562
I0616 11:13:43.986371 29366 solver.cpp:237]     Train net output #0: loss = 0.00493568 (* 1 = 0.00493568 loss)
I0616 11:13:43.986395 29366 sgd_solver.cpp:105] Iteration 65450, lr = 0.001
I0616 11:14:41.753268 29366 solver.cpp:218] Iteration 65500 (0.865552 iter/s, 57.7666s/50 iters), loss = 0.00660627
I0616 11:14:41.753409 29366 solver.cpp:237]     Train net output #0: loss = 0.00660633 (* 1 = 0.00660633 loss)
I0616 11:14:41.753437 29366 sgd_solver.cpp:105] Iteration 65500, lr = 0.001
I0616 11:15:39.508949 29366 solver.cpp:218] Iteration 65550 (0.865722 iter/s, 57.7552s/50 iters), loss = 0.00583989
I0616 11:15:39.509074 29366 solver.cpp:237]     Train net output #0: loss = 0.00583994 (* 1 = 0.00583994 loss)
I0616 11:15:39.509100 29366 sgd_solver.cpp:105] Iteration 65550, lr = 0.001
I0616 11:16:37.272008 29366 solver.cpp:218] Iteration 65600 (0.865611 iter/s, 57.7626s/50 iters), loss = 0.00724297
I0616 11:16:37.272159 29366 solver.cpp:237]     Train net output #0: loss = 0.00724303 (* 1 = 0.00724303 loss)
I0616 11:16:37.272187 29366 sgd_solver.cpp:105] Iteration 65600, lr = 0.001
I0616 11:17:35.031311 29366 solver.cpp:218] Iteration 65650 (0.865668 iter/s, 57.7589s/50 iters), loss = 0.00446951
I0616 11:17:35.031445 29366 solver.cpp:237]     Train net output #0: loss = 0.00446956 (* 1 = 0.00446956 loss)
I0616 11:17:35.031471 29366 sgd_solver.cpp:105] Iteration 65650, lr = 0.001
I0616 11:18:32.781087 29366 solver.cpp:218] Iteration 65700 (0.865811 iter/s, 57.7493s/50 iters), loss = 0.00355072
I0616 11:18:32.781250 29366 solver.cpp:237]     Train net output #0: loss = 0.00355077 (* 1 = 0.00355077 loss)
I0616 11:18:32.781278 29366 sgd_solver.cpp:105] Iteration 65700, lr = 0.001
I0616 11:19:30.542737 29366 solver.cpp:218] Iteration 65750 (0.865633 iter/s, 57.7612s/50 iters), loss = 0.00610465
I0616 11:19:30.542876 29366 solver.cpp:237]     Train net output #0: loss = 0.00610471 (* 1 = 0.00610471 loss)
I0616 11:19:30.542904 29366 sgd_solver.cpp:105] Iteration 65750, lr = 0.001
I0616 11:20:28.298971 29366 solver.cpp:218] Iteration 65800 (0.865714 iter/s, 57.7558s/50 iters), loss = 0.00372125
I0616 11:20:28.299108 29366 solver.cpp:237]     Train net output #0: loss = 0.00372131 (* 1 = 0.00372131 loss)
I0616 11:20:28.299134 29366 sgd_solver.cpp:105] Iteration 65800, lr = 0.001
I0616 11:21:26.047783 29366 solver.cpp:218] Iteration 65850 (0.865825 iter/s, 57.7484s/50 iters), loss = 0.00695565
I0616 11:21:26.047945 29366 solver.cpp:237]     Train net output #0: loss = 0.00695571 (* 1 = 0.00695571 loss)
I0616 11:21:26.047984 29366 sgd_solver.cpp:105] Iteration 65850, lr = 0.001
I0616 11:22:23.802958 29366 solver.cpp:218] Iteration 65900 (0.86573 iter/s, 57.7547s/50 iters), loss = 0.00524487
I0616 11:22:23.803091 29366 solver.cpp:237]     Train net output #0: loss = 0.00524492 (* 1 = 0.00524492 loss)
I0616 11:22:23.803117 29366 sgd_solver.cpp:105] Iteration 65900, lr = 0.001
I0616 11:23:21.557410 29366 solver.cpp:218] Iteration 65950 (0.865741 iter/s, 57.754s/50 iters), loss = 0.00370127
I0616 11:23:21.557543 29366 solver.cpp:237]     Train net output #0: loss = 0.00370132 (* 1 = 0.00370132 loss)
I0616 11:23:21.557569 29366 sgd_solver.cpp:105] Iteration 65950, lr = 0.001
I0616 11:24:19.318543 29366 solver.cpp:218] Iteration 66000 (0.865641 iter/s, 57.7607s/50 iters), loss = 0.00566102
I0616 11:24:19.318667 29366 solver.cpp:237]     Train net output #0: loss = 0.00566107 (* 1 = 0.00566107 loss)
I0616 11:24:19.318693 29366 sgd_solver.cpp:105] Iteration 66000, lr = 0.001
I0616 11:25:17.062399 29366 solver.cpp:218] Iteration 66050 (0.8659 iter/s, 57.7434s/50 iters), loss = 0.0042955
I0616 11:25:17.062543 29366 solver.cpp:237]     Train net output #0: loss = 0.00429555 (* 1 = 0.00429555 loss)
I0616 11:25:17.062572 29366 sgd_solver.cpp:105] Iteration 66050, lr = 0.001
I0616 11:26:14.822454 29366 solver.cpp:218] Iteration 66100 (0.865657 iter/s, 57.7596s/50 iters), loss = 0.00590209
I0616 11:26:14.822583 29366 solver.cpp:237]     Train net output #0: loss = 0.00590214 (* 1 = 0.00590214 loss)
I0616 11:26:14.822609 29366 sgd_solver.cpp:105] Iteration 66100, lr = 0.001
I0616 11:27:12.575729 29366 solver.cpp:218] Iteration 66150 (0.865759 iter/s, 57.7528s/50 iters), loss = 0.00576276
I0616 11:27:12.575821 29366 solver.cpp:237]     Train net output #0: loss = 0.00576281 (* 1 = 0.00576281 loss)
I0616 11:27:12.575846 29366 sgd_solver.cpp:105] Iteration 66150, lr = 0.001
I0616 11:28:10.321244 29366 solver.cpp:218] Iteration 66200 (0.865874 iter/s, 57.7451s/50 iters), loss = 0.00608414
I0616 11:28:10.321385 29366 solver.cpp:237]     Train net output #0: loss = 0.00608419 (* 1 = 0.00608419 loss)
I0616 11:28:10.321413 29366 sgd_solver.cpp:105] Iteration 66200, lr = 0.001
I0616 11:29:08.085950 29366 solver.cpp:218] Iteration 66250 (0.865588 iter/s, 57.7642s/50 iters), loss = 0.00649691
I0616 11:29:08.086154 29366 solver.cpp:237]     Train net output #0: loss = 0.00649696 (* 1 = 0.00649696 loss)
I0616 11:29:08.086194 29366 sgd_solver.cpp:105] Iteration 66250, lr = 0.001
I0616 11:30:05.831018 29366 solver.cpp:218] Iteration 66300 (0.865882 iter/s, 57.7446s/50 iters), loss = 0.00774275
I0616 11:30:05.831244 29366 solver.cpp:237]     Train net output #0: loss = 0.00774281 (* 1 = 0.00774281 loss)
I0616 11:30:05.831272 29366 sgd_solver.cpp:105] Iteration 66300, lr = 0.001
I0616 11:31:03.588682 29366 solver.cpp:218] Iteration 66350 (0.865694 iter/s, 57.7571s/50 iters), loss = 0.0108592
I0616 11:31:03.588799 29366 solver.cpp:237]     Train net output #0: loss = 0.0108593 (* 1 = 0.0108593 loss)
I0616 11:31:03.588826 29366 sgd_solver.cpp:105] Iteration 66350, lr = 0.001
I0616 11:32:01.350255 29366 solver.cpp:218] Iteration 66400 (0.865634 iter/s, 57.7611s/50 iters), loss = 0.00797721
I0616 11:32:01.350391 29366 solver.cpp:237]     Train net output #0: loss = 0.00797726 (* 1 = 0.00797726 loss)
I0616 11:32:01.350419 29366 sgd_solver.cpp:105] Iteration 66400, lr = 0.001
I0616 11:32:59.111758 29366 solver.cpp:218] Iteration 66450 (0.865636 iter/s, 57.761s/50 iters), loss = 0.00452419
I0616 11:32:59.111886 29366 solver.cpp:237]     Train net output #0: loss = 0.00452424 (* 1 = 0.00452424 loss)
I0616 11:32:59.111917 29366 sgd_solver.cpp:105] Iteration 66450, lr = 0.001
I0616 11:33:56.858232 29366 solver.cpp:218] Iteration 66500 (0.865861 iter/s, 57.746s/50 iters), loss = 0.00519274
I0616 11:33:56.858361 29366 solver.cpp:237]     Train net output #0: loss = 0.0051928 (* 1 = 0.0051928 loss)
I0616 11:33:56.858387 29366 sgd_solver.cpp:105] Iteration 66500, lr = 0.001
I0616 11:34:54.603794 29366 solver.cpp:218] Iteration 66550 (0.865874 iter/s, 57.7451s/50 iters), loss = 0.00414259
I0616 11:34:54.603967 29366 solver.cpp:237]     Train net output #0: loss = 0.00414265 (* 1 = 0.00414265 loss)
I0616 11:34:54.603994 29366 sgd_solver.cpp:105] Iteration 66550, lr = 0.001
I0616 11:35:52.356809 29366 solver.cpp:218] Iteration 66600 (0.865764 iter/s, 57.7525s/50 iters), loss = 0.00371915
I0616 11:35:52.356962 29366 solver.cpp:237]     Train net output #0: loss = 0.0037192 (* 1 = 0.0037192 loss)
I0616 11:35:52.356997 29366 sgd_solver.cpp:105] Iteration 66600, lr = 0.001
I0616 11:36:50.118407 29366 solver.cpp:218] Iteration 66650 (0.865635 iter/s, 57.7611s/50 iters), loss = 0.00519081
I0616 11:36:50.118561 29366 solver.cpp:237]     Train net output #0: loss = 0.00519087 (* 1 = 0.00519087 loss)
I0616 11:36:50.118588 29366 sgd_solver.cpp:105] Iteration 66650, lr = 0.001
I0616 11:37:47.874970 29366 solver.cpp:218] Iteration 66700 (0.86571 iter/s, 57.7561s/50 iters), loss = 0.00507608
I0616 11:37:47.875105 29366 solver.cpp:237]     Train net output #0: loss = 0.00507614 (* 1 = 0.00507614 loss)
I0616 11:37:47.875133 29366 sgd_solver.cpp:105] Iteration 66700, lr = 0.001
I0616 11:38:45.647147 29366 solver.cpp:218] Iteration 66750 (0.865476 iter/s, 57.7717s/50 iters), loss = 0.00443988
I0616 11:38:45.647300 29366 solver.cpp:237]     Train net output #0: loss = 0.00443994 (* 1 = 0.00443994 loss)
I0616 11:38:45.647327 29366 sgd_solver.cpp:105] Iteration 66750, lr = 0.001
I0616 11:39:43.402369 29366 solver.cpp:218] Iteration 66800 (0.86573 iter/s, 57.7547s/50 iters), loss = 0.00491577
I0616 11:39:43.402501 29366 solver.cpp:237]     Train net output #0: loss = 0.00491583 (* 1 = 0.00491583 loss)
I0616 11:39:43.402536 29366 sgd_solver.cpp:105] Iteration 66800, lr = 0.001
I0616 11:40:41.157089 29366 solver.cpp:218] Iteration 66850 (0.865738 iter/s, 57.7542s/50 iters), loss = 0.00667395
I0616 11:40:41.157219 29366 solver.cpp:237]     Train net output #0: loss = 0.006674 (* 1 = 0.006674 loss)
I0616 11:40:41.157253 29366 sgd_solver.cpp:105] Iteration 66850, lr = 0.001
I0616 11:41:38.919157 29366 solver.cpp:218] Iteration 66900 (0.865627 iter/s, 57.7616s/50 iters), loss = 0.00607529
I0616 11:41:38.919332 29366 solver.cpp:237]     Train net output #0: loss = 0.00607534 (* 1 = 0.00607534 loss)
I0616 11:41:38.919359 29366 sgd_solver.cpp:105] Iteration 66900, lr = 0.001
I0616 11:42:36.672469 29366 solver.cpp:218] Iteration 66950 (0.865759 iter/s, 57.7528s/50 iters), loss = 0.00570246
I0616 11:42:36.672623 29366 solver.cpp:237]     Train net output #0: loss = 0.00570252 (* 1 = 0.00570252 loss)
I0616 11:42:36.672650 29366 sgd_solver.cpp:105] Iteration 66950, lr = 0.001
I0616 11:43:34.430944 29366 solver.cpp:218] Iteration 67000 (0.865681 iter/s, 57.758s/50 iters), loss = 0.00822657
I0616 11:43:34.431078 29366 solver.cpp:237]     Train net output #0: loss = 0.00822662 (* 1 = 0.00822662 loss)
I0616 11:43:34.431103 29366 sgd_solver.cpp:105] Iteration 67000, lr = 0.001
I0616 11:44:32.184284 29366 solver.cpp:218] Iteration 67050 (0.865758 iter/s, 57.7529s/50 iters), loss = 0.00478113
I0616 11:44:32.184401 29366 solver.cpp:237]     Train net output #0: loss = 0.00478119 (* 1 = 0.00478119 loss)
I0616 11:44:32.184427 29366 sgd_solver.cpp:105] Iteration 67050, lr = 0.001
I0616 11:45:29.930747 29366 solver.cpp:218] Iteration 67100 (0.865861 iter/s, 57.746s/50 iters), loss = 0.0070996
I0616 11:45:29.930902 29366 solver.cpp:237]     Train net output #0: loss = 0.00709965 (* 1 = 0.00709965 loss)
I0616 11:45:29.930936 29366 sgd_solver.cpp:105] Iteration 67100, lr = 0.001
I0616 11:46:27.698812 29366 solver.cpp:218] Iteration 67150 (0.865538 iter/s, 57.7676s/50 iters), loss = 0.00792811
I0616 11:46:27.698940 29366 solver.cpp:237]     Train net output #0: loss = 0.00792817 (* 1 = 0.00792817 loss)
I0616 11:46:27.698966 29366 sgd_solver.cpp:105] Iteration 67150, lr = 0.001
I0616 11:47:25.445121 29366 solver.cpp:218] Iteration 67200 (0.865864 iter/s, 57.7458s/50 iters), loss = 0.00466641
I0616 11:47:25.445302 29366 solver.cpp:237]     Train net output #0: loss = 0.00466646 (* 1 = 0.00466646 loss)
I0616 11:47:25.445329 29366 sgd_solver.cpp:105] Iteration 67200, lr = 0.001
I0616 11:48:23.202880 29366 solver.cpp:218] Iteration 67250 (0.865696 iter/s, 57.757s/50 iters), loss = 0.00577773
I0616 11:48:23.203016 29366 solver.cpp:237]     Train net output #0: loss = 0.00577779 (* 1 = 0.00577779 loss)
I0616 11:48:23.203044 29366 sgd_solver.cpp:105] Iteration 67250, lr = 0.001
I0616 11:49:20.954072 29366 solver.cpp:218] Iteration 67300 (0.865794 iter/s, 57.7505s/50 iters), loss = 0.00546827
I0616 11:49:20.954205 29366 solver.cpp:237]     Train net output #0: loss = 0.00546832 (* 1 = 0.00546832 loss)
I0616 11:49:20.954231 29366 sgd_solver.cpp:105] Iteration 67300, lr = 0.001
I0616 11:50:18.720208 29366 solver.cpp:218] Iteration 67350 (0.865569 iter/s, 57.7654s/50 iters), loss = 0.00484634
I0616 11:50:18.720336 29366 solver.cpp:237]     Train net output #0: loss = 0.0048464 (* 1 = 0.0048464 loss)
I0616 11:50:18.720361 29366 sgd_solver.cpp:105] Iteration 67350, lr = 0.001
I0616 11:51:16.478263 29366 solver.cpp:218] Iteration 67400 (0.86569 iter/s, 57.7574s/50 iters), loss = 0.00547533
I0616 11:51:16.478402 29366 solver.cpp:237]     Train net output #0: loss = 0.00547539 (* 1 = 0.00547539 loss)
I0616 11:51:16.478430 29366 sgd_solver.cpp:105] Iteration 67400, lr = 0.001
I0616 11:52:14.234849 29366 solver.cpp:218] Iteration 67450 (0.865713 iter/s, 57.7559s/50 iters), loss = 0.0047342
I0616 11:52:14.234992 29366 solver.cpp:237]     Train net output #0: loss = 0.00473426 (* 1 = 0.00473426 loss)
I0616 11:52:14.235018 29366 sgd_solver.cpp:105] Iteration 67450, lr = 0.001
I0616 11:53:11.997046 29366 solver.cpp:218] Iteration 67500 (0.865629 iter/s, 57.7615s/50 iters), loss = 0.00529783
I0616 11:53:11.997226 29366 solver.cpp:237]     Train net output #0: loss = 0.00529788 (* 1 = 0.00529788 loss)
I0616 11:53:11.997261 29366 sgd_solver.cpp:105] Iteration 67500, lr = 0.001
I0616 11:54:09.758062 29366 solver.cpp:218] Iteration 67550 (0.865647 iter/s, 57.7603s/50 iters), loss = 0.00451199
I0616 11:54:09.758177 29366 solver.cpp:237]     Train net output #0: loss = 0.00451205 (* 1 = 0.00451205 loss)
I0616 11:54:09.758201 29366 sgd_solver.cpp:105] Iteration 67550, lr = 0.001
I0616 11:55:07.497556 29366 solver.cpp:218] Iteration 67600 (0.865969 iter/s, 57.7388s/50 iters), loss = 0.00423793
I0616 11:55:07.499013 29366 solver.cpp:237]     Train net output #0: loss = 0.00423798 (* 1 = 0.00423798 loss)
I0616 11:55:07.499042 29366 sgd_solver.cpp:105] Iteration 67600, lr = 0.001
I0616 11:56:05.214320 29366 solver.cpp:218] Iteration 67650 (0.86633 iter/s, 57.7147s/50 iters), loss = 0.00769706
I0616 11:56:05.214493 29366 solver.cpp:237]     Train net output #0: loss = 0.00769712 (* 1 = 0.00769712 loss)
I0616 11:56:05.214527 29366 sgd_solver.cpp:105] Iteration 67650, lr = 0.001
I0616 11:57:02.923259 29366 solver.cpp:218] Iteration 67700 (0.866428 iter/s, 57.7082s/50 iters), loss = 0.00540551
I0616 11:57:02.923441 29366 solver.cpp:237]     Train net output #0: loss = 0.00540557 (* 1 = 0.00540557 loss)
I0616 11:57:02.923470 29366 sgd_solver.cpp:105] Iteration 67700, lr = 0.001
I0616 11:58:00.637899 29366 solver.cpp:218] Iteration 67750 (0.866342 iter/s, 57.7139s/50 iters), loss = 0.004533
I0616 11:58:00.638061 29366 solver.cpp:237]     Train net output #0: loss = 0.00453305 (* 1 = 0.00453305 loss)
I0616 11:58:00.638090 29366 sgd_solver.cpp:105] Iteration 67750, lr = 0.001
I0616 11:58:58.348567 29366 solver.cpp:218] Iteration 67800 (0.866402 iter/s, 57.7099s/50 iters), loss = 0.00673111
I0616 11:58:58.348702 29366 solver.cpp:237]     Train net output #0: loss = 0.00673116 (* 1 = 0.00673116 loss)
I0616 11:58:58.348736 29366 sgd_solver.cpp:105] Iteration 67800, lr = 0.001
I0616 11:59:56.073546 29366 solver.cpp:218] Iteration 67850 (0.866186 iter/s, 57.7243s/50 iters), loss = 0.00558161
I0616 11:59:56.073693 29366 solver.cpp:237]     Train net output #0: loss = 0.00558167 (* 1 = 0.00558167 loss)
I0616 11:59:56.073721 29366 sgd_solver.cpp:105] Iteration 67850, lr = 0.001
I0616 12:00:53.788292 29366 solver.cpp:218] Iteration 67900 (0.86634 iter/s, 57.7141s/50 iters), loss = 0.00571426
I0616 12:00:53.788491 29366 solver.cpp:237]     Train net output #0: loss = 0.00571431 (* 1 = 0.00571431 loss)
I0616 12:00:53.788525 29366 sgd_solver.cpp:105] Iteration 67900, lr = 0.001
I0616 12:01:51.505698 29366 solver.cpp:218] Iteration 67950 (0.866301 iter/s, 57.7167s/50 iters), loss = 0.00476636
I0616 12:01:51.506191 29366 solver.cpp:237]     Train net output #0: loss = 0.00476641 (* 1 = 0.00476641 loss)
I0616 12:01:51.506219 29366 sgd_solver.cpp:105] Iteration 67950, lr = 0.001
I0616 12:02:49.219756 29366 solver.cpp:218] Iteration 68000 (0.866356 iter/s, 57.713s/50 iters), loss = 0.00461762
I0616 12:02:49.219905 29366 solver.cpp:237]     Train net output #0: loss = 0.00461767 (* 1 = 0.00461767 loss)
I0616 12:02:49.219933 29366 sgd_solver.cpp:105] Iteration 68000, lr = 0.001
I0616 12:03:46.941386 29366 solver.cpp:218] Iteration 68050 (0.866237 iter/s, 57.7209s/50 iters), loss = 0.00749256
I0616 12:03:46.941537 29366 solver.cpp:237]     Train net output #0: loss = 0.00749262 (* 1 = 0.00749262 loss)
I0616 12:03:46.941567 29366 sgd_solver.cpp:105] Iteration 68050, lr = 0.001
I0616 12:04:44.672998 29366 solver.cpp:218] Iteration 68100 (0.866087 iter/s, 57.7309s/50 iters), loss = 0.00536766
I0616 12:04:44.673144 29366 solver.cpp:237]     Train net output #0: loss = 0.00536772 (* 1 = 0.00536772 loss)
I0616 12:04:44.673174 29366 sgd_solver.cpp:105] Iteration 68100, lr = 0.001
I0616 12:05:42.401614 29366 solver.cpp:218] Iteration 68150 (0.866132 iter/s, 57.7279s/50 iters), loss = 0.0055474
I0616 12:05:42.401773 29366 solver.cpp:237]     Train net output #0: loss = 0.00554745 (* 1 = 0.00554745 loss)
I0616 12:05:42.401803 29366 sgd_solver.cpp:105] Iteration 68150, lr = 0.001
I0616 12:06:40.120800 29366 solver.cpp:218] Iteration 68200 (0.866274 iter/s, 57.7185s/50 iters), loss = 0.00601439
I0616 12:06:40.121150 29366 solver.cpp:237]     Train net output #0: loss = 0.00601444 (* 1 = 0.00601444 loss)
I0616 12:06:40.121178 29366 sgd_solver.cpp:105] Iteration 68200, lr = 0.001
I0616 12:07:37.845840 29366 solver.cpp:218] Iteration 68250 (0.866189 iter/s, 57.7241s/50 iters), loss = 0.00697753
I0616 12:07:37.846041 29366 solver.cpp:237]     Train net output #0: loss = 0.00697759 (* 1 = 0.00697759 loss)
I0616 12:07:37.846071 29366 sgd_solver.cpp:105] Iteration 68250, lr = 0.001
I0616 12:08:35.597755 29366 solver.cpp:218] Iteration 68300 (0.865783 iter/s, 57.7512s/50 iters), loss = 0.00538849
I0616 12:08:35.597935 29366 solver.cpp:237]     Train net output #0: loss = 0.00538855 (* 1 = 0.00538855 loss)
I0616 12:08:35.597965 29366 sgd_solver.cpp:105] Iteration 68300, lr = 0.001
I0616 12:09:33.349226 29366 solver.cpp:218] Iteration 68350 (0.86579 iter/s, 57.7507s/50 iters), loss = 0.00629922
I0616 12:09:33.349408 29366 solver.cpp:237]     Train net output #0: loss = 0.00629927 (* 1 = 0.00629927 loss)
I0616 12:09:33.349436 29366 sgd_solver.cpp:105] Iteration 68350, lr = 0.001
I0616 12:10:31.101693 29366 solver.cpp:218] Iteration 68400 (0.865775 iter/s, 57.7517s/50 iters), loss = 0.00591504
I0616 12:10:31.101881 29366 solver.cpp:237]     Train net output #0: loss = 0.0059151 (* 1 = 0.0059151 loss)
I0616 12:10:31.101909 29366 sgd_solver.cpp:105] Iteration 68400, lr = 0.001
I0616 12:11:28.854354 29366 solver.cpp:218] Iteration 68450 (0.865772 iter/s, 57.7519s/50 iters), loss = 0.00549548
I0616 12:11:28.854535 29366 solver.cpp:237]     Train net output #0: loss = 0.00549553 (* 1 = 0.00549553 loss)
I0616 12:11:28.854565 29366 sgd_solver.cpp:105] Iteration 68450, lr = 0.001
I0616 12:12:26.614559 29366 solver.cpp:218] Iteration 68500 (0.865659 iter/s, 57.7595s/50 iters), loss = 0.0050535
I0616 12:12:26.614734 29366 solver.cpp:237]     Train net output #0: loss = 0.00505355 (* 1 = 0.00505355 loss)
I0616 12:12:26.614763 29366 sgd_solver.cpp:105] Iteration 68500, lr = 0.001
I0616 12:13:24.364919 29366 solver.cpp:218] Iteration 68550 (0.865806 iter/s, 57.7496s/50 iters), loss = 0.00627645
I0616 12:13:24.365172 29366 solver.cpp:237]     Train net output #0: loss = 0.00627651 (* 1 = 0.00627651 loss)
I0616 12:13:24.365201 29366 sgd_solver.cpp:105] Iteration 68550, lr = 0.001
I0616 12:14:22.121664 29366 solver.cpp:218] Iteration 68600 (0.865712 iter/s, 57.7559s/50 iters), loss = 0.00529721
I0616 12:14:22.121857 29366 solver.cpp:237]     Train net output #0: loss = 0.00529727 (* 1 = 0.00529727 loss)
I0616 12:14:22.121884 29366 sgd_solver.cpp:105] Iteration 68600, lr = 0.001
I0616 12:15:19.880306 29366 solver.cpp:218] Iteration 68650 (0.865682 iter/s, 57.7579s/50 iters), loss = 0.00564814
I0616 12:15:19.880486 29366 solver.cpp:237]     Train net output #0: loss = 0.0056482 (* 1 = 0.0056482 loss)
I0616 12:15:19.880520 29366 sgd_solver.cpp:105] Iteration 68650, lr = 0.001
I0616 12:16:17.628607 29366 solver.cpp:218] Iteration 68700 (0.865837 iter/s, 57.7476s/50 iters), loss = 0.00437179
I0616 12:16:17.628778 29366 solver.cpp:237]     Train net output #0: loss = 0.00437185 (* 1 = 0.00437185 loss)
I0616 12:16:17.628806 29366 sgd_solver.cpp:105] Iteration 68700, lr = 0.001
I0616 12:17:15.397073 29366 solver.cpp:218] Iteration 68750 (0.865535 iter/s, 57.7677s/50 iters), loss = 0.00329387
I0616 12:17:15.397230 29366 solver.cpp:237]     Train net output #0: loss = 0.00329393 (* 1 = 0.00329393 loss)
I0616 12:17:15.397264 29366 sgd_solver.cpp:105] Iteration 68750, lr = 0.001
I0616 12:18:13.156751 29366 solver.cpp:218] Iteration 68800 (0.865666 iter/s, 57.759s/50 iters), loss = 0.00534729
I0616 12:18:13.156945 29366 solver.cpp:237]     Train net output #0: loss = 0.00534735 (* 1 = 0.00534735 loss)
I0616 12:18:13.156975 29366 sgd_solver.cpp:105] Iteration 68800, lr = 0.001
I0616 12:19:10.916529 29366 solver.cpp:218] Iteration 68850 (0.865665 iter/s, 57.759s/50 iters), loss = 0.00368826
I0616 12:19:10.916714 29366 solver.cpp:237]     Train net output #0: loss = 0.00368832 (* 1 = 0.00368832 loss)
I0616 12:19:10.916743 29366 sgd_solver.cpp:105] Iteration 68850, lr = 0.001
I0616 12:20:08.667667 29366 solver.cpp:218] Iteration 68900 (0.865794 iter/s, 57.7504s/50 iters), loss = 0.00611456
I0616 12:20:08.667834 29366 solver.cpp:237]     Train net output #0: loss = 0.00611462 (* 1 = 0.00611462 loss)
I0616 12:20:08.667863 29366 sgd_solver.cpp:105] Iteration 68900, lr = 0.001
I0616 12:21:06.419921 29366 solver.cpp:218] Iteration 68950 (0.865778 iter/s, 57.7515s/50 iters), loss = 0.00601356
I0616 12:21:06.420116 29366 solver.cpp:237]     Train net output #0: loss = 0.00601362 (* 1 = 0.00601362 loss)
I0616 12:21:06.420143 29366 sgd_solver.cpp:105] Iteration 68950, lr = 0.001
I0616 12:22:04.188500 29366 solver.cpp:218] Iteration 69000 (0.865534 iter/s, 57.7678s/50 iters), loss = 0.00433673
I0616 12:22:04.188701 29366 solver.cpp:237]     Train net output #0: loss = 0.00433679 (* 1 = 0.00433679 loss)
I0616 12:22:04.188731 29366 sgd_solver.cpp:105] Iteration 69000, lr = 0.001
I0616 12:23:01.950963 29366 solver.cpp:218] Iteration 69050 (0.865626 iter/s, 57.7617s/50 iters), loss = 0.00508953
I0616 12:23:01.951166 29366 solver.cpp:237]     Train net output #0: loss = 0.00508958 (* 1 = 0.00508958 loss)
I0616 12:23:01.951195 29366 sgd_solver.cpp:105] Iteration 69050, lr = 0.001
I0616 12:23:59.709830 29366 solver.cpp:218] Iteration 69100 (0.86568 iter/s, 57.7581s/50 iters), loss = 0.00766559
I0616 12:23:59.710098 29366 solver.cpp:237]     Train net output #0: loss = 0.00766564 (* 1 = 0.00766564 loss)
I0616 12:23:59.710134 29366 sgd_solver.cpp:105] Iteration 69100, lr = 0.001
I0616 12:24:57.464272 29366 solver.cpp:218] Iteration 69150 (0.865747 iter/s, 57.7536s/50 iters), loss = 0.00484559
I0616 12:24:57.464476 29366 solver.cpp:237]     Train net output #0: loss = 0.00484565 (* 1 = 0.00484565 loss)
I0616 12:24:57.464511 29366 sgd_solver.cpp:105] Iteration 69150, lr = 0.001
I0616 12:25:55.214182 29366 solver.cpp:218] Iteration 69200 (0.865814 iter/s, 57.7491s/50 iters), loss = 0.00577588
I0616 12:25:55.214383 29366 solver.cpp:237]     Train net output #0: loss = 0.00577594 (* 1 = 0.00577594 loss)
I0616 12:25:55.214412 29366 sgd_solver.cpp:105] Iteration 69200, lr = 0.001
I0616 12:26:52.980033 29366 solver.cpp:218] Iteration 69250 (0.865575 iter/s, 57.765s/50 iters), loss = 0.00604893
I0616 12:26:52.980300 29366 solver.cpp:237]     Train net output #0: loss = 0.00604898 (* 1 = 0.00604898 loss)
I0616 12:26:52.980336 29366 sgd_solver.cpp:105] Iteration 69250, lr = 0.001
I0616 12:27:50.742656 29366 solver.cpp:218] Iteration 69300 (0.865624 iter/s, 57.7618s/50 iters), loss = 0.00685736
I0616 12:27:50.742843 29366 solver.cpp:237]     Train net output #0: loss = 0.00685742 (* 1 = 0.00685742 loss)
I0616 12:27:50.742871 29366 sgd_solver.cpp:105] Iteration 69300, lr = 0.001
I0616 12:28:48.505013 29366 solver.cpp:218] Iteration 69350 (0.865627 iter/s, 57.7616s/50 iters), loss = 0.00545074
I0616 12:28:48.505199 29366 solver.cpp:237]     Train net output #0: loss = 0.00545079 (* 1 = 0.00545079 loss)
I0616 12:28:48.505229 29366 sgd_solver.cpp:105] Iteration 69350, lr = 0.001
I0616 12:29:46.275207 29366 solver.cpp:218] Iteration 69400 (0.86551 iter/s, 57.7694s/50 iters), loss = 0.00415269
I0616 12:29:46.275384 29366 solver.cpp:237]     Train net output #0: loss = 0.00415275 (* 1 = 0.00415275 loss)
I0616 12:29:46.275413 29366 sgd_solver.cpp:105] Iteration 69400, lr = 0.001
I0616 12:30:44.041357 29366 solver.cpp:218] Iteration 69450 (0.86557 iter/s, 57.7654s/50 iters), loss = 0.00433093
I0616 12:30:44.041566 29366 solver.cpp:237]     Train net output #0: loss = 0.00433098 (* 1 = 0.00433098 loss)
I0616 12:30:44.041604 29366 sgd_solver.cpp:105] Iteration 69450, lr = 0.001
I0616 12:31:41.797785 29366 solver.cpp:218] Iteration 69500 (0.865716 iter/s, 57.7557s/50 iters), loss = 0.0062464
I0616 12:31:41.798038 29366 solver.cpp:237]     Train net output #0: loss = 0.00624645 (* 1 = 0.00624645 loss)
I0616 12:31:41.798064 29366 sgd_solver.cpp:105] Iteration 69500, lr = 0.001
I0616 12:32:39.559263 29366 solver.cpp:218] Iteration 69550 (0.865641 iter/s, 57.7606s/50 iters), loss = 0.00529247
I0616 12:32:39.559437 29366 solver.cpp:237]     Train net output #0: loss = 0.00529252 (* 1 = 0.00529252 loss)
I0616 12:32:39.559463 29366 sgd_solver.cpp:105] Iteration 69550, lr = 0.001
I0616 12:33:37.328131 29366 solver.cpp:218] Iteration 69600 (0.865529 iter/s, 57.7681s/50 iters), loss = 0.00390683
I0616 12:33:37.328332 29366 solver.cpp:237]     Train net output #0: loss = 0.00390689 (* 1 = 0.00390689 loss)
I0616 12:33:37.328359 29366 sgd_solver.cpp:105] Iteration 69600, lr = 0.001
I0616 12:34:35.086031 29366 solver.cpp:218] Iteration 69650 (0.865694 iter/s, 57.7571s/50 iters), loss = 0.00460051
I0616 12:34:35.086272 29366 solver.cpp:237]     Train net output #0: loss = 0.00460057 (* 1 = 0.00460057 loss)
I0616 12:34:35.086295 29366 sgd_solver.cpp:105] Iteration 69650, lr = 0.001
I0616 12:35:32.846319 29366 solver.cpp:218] Iteration 69700 (0.865659 iter/s, 57.7595s/50 iters), loss = 0.0048012
I0616 12:35:32.846482 29366 solver.cpp:237]     Train net output #0: loss = 0.00480126 (* 1 = 0.00480126 loss)
I0616 12:35:32.846508 29366 sgd_solver.cpp:105] Iteration 69700, lr = 0.001
I0616 12:36:30.609586 29366 solver.cpp:218] Iteration 69750 (0.865613 iter/s, 57.7625s/50 iters), loss = 0.00648965
I0616 12:36:30.609758 29366 solver.cpp:237]     Train net output #0: loss = 0.0064897 (* 1 = 0.0064897 loss)
I0616 12:36:30.609782 29366 sgd_solver.cpp:105] Iteration 69750, lr = 0.001
I0616 12:37:28.369339 29366 solver.cpp:218] Iteration 69800 (0.865666 iter/s, 57.759s/50 iters), loss = 0.00653643
I0616 12:37:28.369520 29366 solver.cpp:237]     Train net output #0: loss = 0.00653649 (* 1 = 0.00653649 loss)
I0616 12:37:28.369547 29366 sgd_solver.cpp:105] Iteration 69800, lr = 0.001
I0616 12:38:26.125963 29366 solver.cpp:218] Iteration 69850 (0.865713 iter/s, 57.7559s/50 iters), loss = 0.00480736
I0616 12:38:26.126121 29366 solver.cpp:237]     Train net output #0: loss = 0.00480741 (* 1 = 0.00480741 loss)
I0616 12:38:26.126145 29366 sgd_solver.cpp:105] Iteration 69850, lr = 0.001
I0616 12:39:23.884615 29366 solver.cpp:218] Iteration 69900 (0.865682 iter/s, 57.7579s/50 iters), loss = 0.00378028
I0616 12:39:23.884894 29366 solver.cpp:237]     Train net output #0: loss = 0.00378033 (* 1 = 0.00378033 loss)
I0616 12:39:23.884920 29366 sgd_solver.cpp:105] Iteration 69900, lr = 0.001
I0616 12:40:21.636353 29366 solver.cpp:218] Iteration 69950 (0.865787 iter/s, 57.7509s/50 iters), loss = 0.00490661
I0616 12:40:21.636531 29366 solver.cpp:237]     Train net output #0: loss = 0.00490666 (* 1 = 0.00490666 loss)
I0616 12:40:21.636559 29366 sgd_solver.cpp:105] Iteration 69950, lr = 0.001
I0616 12:41:18.242331 29366 solver.cpp:447] Snapshotting to binary proto file mobilenet/mobile_2_iter_70000.caffemodel
I0616 12:41:18.321593 29366 sgd_solver.cpp:273] Snapshotting solver state to binary proto file mobilenet/mobile_2_iter_70000.solverstate
I0616 12:41:19.502755 29366 solver.cpp:218] Iteration 70000 (0.86407 iter/s, 57.8657s/50 iters), loss = 0.00443937
I0616 12:41:19.502843 29366 solver.cpp:237]     Train net output #0: loss = 0.00443942 (* 1 = 0.00443942 loss)
I0616 12:41:19.502866 29366 sgd_solver.cpp:105] Iteration 70000, lr = 0.001
I0616 12:42:17.259531 29366 solver.cpp:218] Iteration 70050 (0.865709 iter/s, 57.7561s/50 iters), loss = 0.0107043
I0616 12:42:17.259728 29366 solver.cpp:237]     Train net output #0: loss = 0.0107044 (* 1 = 0.0107044 loss)
I0616 12:42:17.259754 29366 sgd_solver.cpp:105] Iteration 70050, lr = 0.001
I0616 12:43:15.011871 29366 solver.cpp:218] Iteration 70100 (0.865777 iter/s, 57.7516s/50 iters), loss = 0.00624901
I0616 12:43:15.012028 29366 solver.cpp:237]     Train net output #0: loss = 0.00624907 (* 1 = 0.00624907 loss)
I0616 12:43:15.012054 29366 sgd_solver.cpp:105] Iteration 70100, lr = 0.001
I0616 12:44:12.762483 29366 solver.cpp:218] Iteration 70150 (0.865802 iter/s, 57.7499s/50 iters), loss = 0.00705359
I0616 12:44:12.762758 29366 solver.cpp:237]     Train net output #0: loss = 0.00705364 (* 1 = 0.00705364 loss)
I0616 12:44:12.762784 29366 sgd_solver.cpp:105] Iteration 70150, lr = 0.001
I0616 12:45:10.523622 29366 solver.cpp:218] Iteration 70200 (0.865646 iter/s, 57.7603s/50 iters), loss = 0.00608019
I0616 12:45:10.523810 29366 solver.cpp:237]     Train net output #0: loss = 0.00608025 (* 1 = 0.00608025 loss)
I0616 12:45:10.523835 29366 sgd_solver.cpp:105] Iteration 70200, lr = 0.001
I0616 12:46:08.275460 29366 solver.cpp:218] Iteration 70250 (0.865784 iter/s, 57.7511s/50 iters), loss = 0.00576031
I0616 12:46:08.275640 29366 solver.cpp:237]     Train net output #0: loss = 0.00576036 (* 1 = 0.00576036 loss)
I0616 12:46:08.275665 29366 sgd_solver.cpp:105] Iteration 70250, lr = 0.001
I0616 12:47:06.024483 29366 solver.cpp:218] Iteration 70300 (0.865826 iter/s, 57.7483s/50 iters), loss = 0.00436542
I0616 12:47:06.024643 29366 solver.cpp:237]     Train net output #0: loss = 0.00436547 (* 1 = 0.00436547 loss)
I0616 12:47:06.024669 29366 sgd_solver.cpp:105] Iteration 70300, lr = 0.001
I0616 12:48:03.764325 29366 solver.cpp:218] Iteration 70350 (0.865964 iter/s, 57.7391s/50 iters), loss = 0.00503826
I0616 12:48:03.764564 29366 solver.cpp:237]     Train net output #0: loss = 0.00503831 (* 1 = 0.00503831 loss)
I0616 12:48:03.764590 29366 sgd_solver.cpp:105] Iteration 70350, lr = 0.001
I0616 12:49:01.506402 29366 solver.cpp:218] Iteration 70400 (0.865932 iter/s, 57.7413s/50 iters), loss = 0.00557628
I0616 12:49:01.506561 29366 solver.cpp:237]     Train net output #0: loss = 0.00557633 (* 1 = 0.00557633 loss)
I0616 12:49:01.506593 29366 sgd_solver.cpp:105] Iteration 70400, lr = 0.001
I0616 12:49:59.245903 29366 solver.cpp:218] Iteration 70450 (0.865969 iter/s, 57.7388s/50 iters), loss = 0.00528641
I0616 12:49:59.246034 29366 solver.cpp:237]     Train net output #0: loss = 0.00528646 (* 1 = 0.00528646 loss)
I0616 12:49:59.246059 29366 sgd_solver.cpp:105] Iteration 70450, lr = 0.001
I0616 12:50:56.979729 29366 solver.cpp:218] Iteration 70500 (0.866054 iter/s, 57.7332s/50 iters), loss = 0.00425725
I0616 12:50:56.979912 29366 solver.cpp:237]     Train net output #0: loss = 0.00425731 (* 1 = 0.00425731 loss)
I0616 12:50:56.979938 29366 sgd_solver.cpp:105] Iteration 70500, lr = 0.001
I0616 12:51:54.722877 29366 solver.cpp:218] Iteration 70550 (0.865914 iter/s, 57.7424s/50 iters), loss = 0.00560657
I0616 12:51:54.723135 29366 solver.cpp:237]     Train net output #0: loss = 0.00560662 (* 1 = 0.00560662 loss)
I0616 12:51:54.723171 29366 sgd_solver.cpp:105] Iteration 70550, lr = 0.001
I0616 12:52:52.458832 29366 solver.cpp:218] Iteration 70600 (0.866023 iter/s, 57.7352s/50 iters), loss = 0.00593182
I0616 12:52:52.458979 29366 solver.cpp:237]     Train net output #0: loss = 0.00593188 (* 1 = 0.00593188 loss)
I0616 12:52:52.459003 29366 sgd_solver.cpp:105] Iteration 70600, lr = 0.001
I0616 12:53:50.193212 29366 solver.cpp:218] Iteration 70650 (0.866045 iter/s, 57.7337s/50 iters), loss = 0.00611785
I0616 12:53:50.193356 29366 solver.cpp:237]     Train net output #0: loss = 0.0061179 (* 1 = 0.0061179 loss)
I0616 12:53:50.193380 29366 sgd_solver.cpp:105] Iteration 70650, lr = 0.001
I0616 12:54:47.919855 29366 solver.cpp:218] Iteration 70700 (0.866161 iter/s, 57.726s/50 iters), loss = 0.00721224
I0616 12:54:47.920008 29366 solver.cpp:237]     Train net output #0: loss = 0.0072123 (* 1 = 0.0072123 loss)
I0616 12:54:47.920034 29366 sgd_solver.cpp:105] Iteration 70700, lr = 0.001
I0616 12:55:45.649039 29366 solver.cpp:218] Iteration 70750 (0.866123 iter/s, 57.7285s/50 iters), loss = 0.00566145
I0616 12:55:45.649188 29366 solver.cpp:237]     Train net output #0: loss = 0.0056615 (* 1 = 0.0056615 loss)
I0616 12:55:45.649214 29366 sgd_solver.cpp:105] Iteration 70750, lr = 0.001
I0616 12:56:43.373004 29366 solver.cpp:218] Iteration 70800 (0.866202 iter/s, 57.7233s/50 iters), loss = 0.00508051
I0616 12:56:43.373143 29366 solver.cpp:237]     Train net output #0: loss = 0.00508057 (* 1 = 0.00508057 loss)
I0616 12:56:43.373168 29366 sgd_solver.cpp:105] Iteration 70800, lr = 0.001
I0616 12:57:41.098685 29366 solver.cpp:218] Iteration 70850 (0.866176 iter/s, 57.725s/50 iters), loss = 0.0063292
I0616 12:57:41.098836 29366 solver.cpp:237]     Train net output #0: loss = 0.00632926 (* 1 = 0.00632926 loss)
I0616 12:57:41.098862 29366 sgd_solver.cpp:105] Iteration 70850, lr = 0.001
I0616 12:58:38.830495 29366 solver.cpp:218] Iteration 70900 (0.866084 iter/s, 57.7311s/50 iters), loss = 0.0123809
I0616 12:58:38.830638 29366 solver.cpp:237]     Train net output #0: loss = 0.0123809 (* 1 = 0.0123809 loss)
I0616 12:58:38.830662 29366 sgd_solver.cpp:105] Iteration 70900, lr = 0.001
I0616 12:59:36.654635 29366 solver.cpp:218] Iteration 70950 (0.864701 iter/s, 57.8234s/50 iters), loss = 0.00597554
I0616 12:59:36.654777 29366 solver.cpp:237]     Train net output #0: loss = 0.00597559 (* 1 = 0.00597559 loss)
I0616 12:59:36.654800 29366 sgd_solver.cpp:105] Iteration 70950, lr = 0.001
I0616 13:00:34.384614 29366 solver.cpp:218] Iteration 71000 (0.866112 iter/s, 57.7293s/50 iters), loss = 0.0046856
I0616 13:00:34.384755 29366 solver.cpp:237]     Train net output #0: loss = 0.00468565 (* 1 = 0.00468565 loss)
I0616 13:00:34.384779 29366 sgd_solver.cpp:105] Iteration 71000, lr = 0.001
I0616 13:01:32.112120 29366 solver.cpp:218] Iteration 71050 (0.866149 iter/s, 57.7268s/50 iters), loss = 0.00782413
I0616 13:01:32.112287 29366 solver.cpp:237]     Train net output #0: loss = 0.00782419 (* 1 = 0.00782419 loss)
I0616 13:01:32.112311 29366 sgd_solver.cpp:105] Iteration 71050, lr = 0.001
I0616 13:02:29.830698 29366 solver.cpp:218] Iteration 71100 (0.866283 iter/s, 57.7179s/50 iters), loss = 0.00467478
I0616 13:02:29.830847 29366 solver.cpp:237]     Train net output #0: loss = 0.00467483 (* 1 = 0.00467483 loss)
I0616 13:02:29.830873 29366 sgd_solver.cpp:105] Iteration 71100, lr = 0.001
I0616 13:03:27.781611 29366 solver.cpp:218] Iteration 71150 (0.862911 iter/s, 57.9434s/50 iters), loss = 0.0035699
I0616 13:03:27.785589 29366 solver.cpp:237]     Train net output #0: loss = 0.00356996 (* 1 = 0.00356996 loss)
I0616 13:03:27.785615 29366 sgd_solver.cpp:105] Iteration 71150, lr = 0.001
I0616 13:04:27.722677 29366 solver.cpp:218] Iteration 71200 (0.834243 iter/s, 59.9346s/50 iters), loss = 0.00475392
I0616 13:04:27.726603 29366 solver.cpp:237]     Train net output #0: loss = 0.00475398 (* 1 = 0.00475398 loss)
I0616 13:04:27.726639 29366 sgd_solver.cpp:105] Iteration 71200, lr = 0.001
I0616 13:05:25.880666 29366 solver.cpp:218] Iteration 71250 (0.859794 iter/s, 58.1535s/50 iters), loss = 0.0035808
I0616 13:05:25.880944 29366 solver.cpp:237]     Train net output #0: loss = 0.00358085 (* 1 = 0.00358085 loss)
I0616 13:05:25.880970 29366 sgd_solver.cpp:105] Iteration 71250, lr = 0.001
I0616 13:06:24.106825 29366 solver.cpp:218] Iteration 71300 (0.858734 iter/s, 58.2252s/50 iters), loss = 0.00555603
I0616 13:06:24.108675 29366 solver.cpp:237]     Train net output #0: loss = 0.00555608 (* 1 = 0.00555608 loss)
I0616 13:06:24.108701 29366 sgd_solver.cpp:105] Iteration 71300, lr = 0.001
I0616 13:07:22.611644 29366 solver.cpp:218] Iteration 71350 (0.854722 iter/s, 58.4985s/50 iters), loss = 0.00390814
I0616 13:07:22.617678 29366 solver.cpp:237]     Train net output #0: loss = 0.00390819 (* 1 = 0.00390819 loss)
I0616 13:07:22.617719 29366 sgd_solver.cpp:105] Iteration 71350, lr = 0.001
I0616 13:08:21.320485 29366 solver.cpp:218] Iteration 71400 (0.851756 iter/s, 58.7023s/50 iters), loss = 0.00706603
I0616 13:08:21.324610 29366 solver.cpp:237]     Train net output #0: loss = 0.00706608 (* 1 = 0.00706608 loss)
I0616 13:08:21.328536 29366 sgd_solver.cpp:105] Iteration 71400, lr = 0.001
I0616 13:09:19.840819 29366 solver.cpp:218] Iteration 71450 (0.854473 iter/s, 58.5156s/50 iters), loss = 0.00600824
I0616 13:09:19.841076 29366 solver.cpp:237]     Train net output #0: loss = 0.0060083 (* 1 = 0.0060083 loss)
I0616 13:09:19.841107 29366 sgd_solver.cpp:105] Iteration 71450, lr = 0.001
I0616 13:10:18.746193 29366 solver.cpp:218] Iteration 71500 (0.848863 iter/s, 58.9023s/50 iters), loss = 0.00578497
I0616 13:10:18.758572 29366 solver.cpp:237]     Train net output #0: loss = 0.00578503 (* 1 = 0.00578503 loss)
I0616 13:10:18.758640 29366 sgd_solver.cpp:105] Iteration 71500, lr = 0.001
I0616 13:11:18.013931 29366 solver.cpp:218] Iteration 71550 (0.843745 iter/s, 59.2596s/50 iters), loss = 0.00599248
I0616 13:11:18.014124 29366 solver.cpp:237]     Train net output #0: loss = 0.00599254 (* 1 = 0.00599254 loss)
I0616 13:11:18.014152 29366 sgd_solver.cpp:105] Iteration 71550, lr = 0.001
I0616 13:12:15.755616 29366 solver.cpp:218] Iteration 71600 (0.865937 iter/s, 57.7409s/50 iters), loss = 0.00511444
I0616 13:12:15.755810 29366 solver.cpp:237]     Train net output #0: loss = 0.00511449 (* 1 = 0.00511449 loss)
I0616 13:12:15.755833 29366 sgd_solver.cpp:105] Iteration 71600, lr = 0.001
I0616 13:13:13.524078 29366 solver.cpp:218] Iteration 71650 (0.865535 iter/s, 57.7677s/50 iters), loss = 0.00666516
I0616 13:13:13.524222 29366 solver.cpp:237]     Train net output #0: loss = 0.00666521 (* 1 = 0.00666521 loss)
I0616 13:13:13.524247 29366 sgd_solver.cpp:105] Iteration 71650, lr = 0.001
I0616 13:14:11.670408 29366 solver.cpp:218] Iteration 71700 (0.85991 iter/s, 58.1456s/50 iters), loss = 0.00599468
I0616 13:14:11.670826 29366 solver.cpp:237]     Train net output #0: loss = 0.00599473 (* 1 = 0.00599473 loss)
I0616 13:14:11.670858 29366 sgd_solver.cpp:105] Iteration 71700, lr = 0.001
I0616 13:15:09.580937 29366 solver.cpp:218] Iteration 71750 (0.863416 iter/s, 57.9095s/50 iters), loss = 0.00576512
I0616 13:15:09.581142 29366 solver.cpp:237]     Train net output #0: loss = 0.00576517 (* 1 = 0.00576517 loss)
I0616 13:15:09.581173 29366 sgd_solver.cpp:105] Iteration 71750, lr = 0.001
I0616 13:16:07.422965 29366 solver.cpp:218] Iteration 71800 (0.864436 iter/s, 57.8412s/50 iters), loss = 0.00422183
I0616 13:16:07.423238 29366 solver.cpp:237]     Train net output #0: loss = 0.00422189 (* 1 = 0.00422189 loss)
I0616 13:16:07.423270 29366 sgd_solver.cpp:105] Iteration 71800, lr = 0.001
I0616 13:17:05.250928 29366 solver.cpp:218] Iteration 71850 (0.864646 iter/s, 57.8272s/50 iters), loss = 0.00609377
I0616 13:17:05.251096 29366 solver.cpp:237]     Train net output #0: loss = 0.00609383 (* 1 = 0.00609383 loss)
I0616 13:17:05.251121 29366 sgd_solver.cpp:105] Iteration 71850, lr = 0.001
I0616 13:18:03.087769 29366 solver.cpp:218] Iteration 71900 (0.864512 iter/s, 57.8361s/50 iters), loss = 0.00755009
I0616 13:18:03.088098 29366 solver.cpp:237]     Train net output #0: loss = 0.00755015 (* 1 = 0.00755015 loss)
I0616 13:18:03.088140 29366 sgd_solver.cpp:105] Iteration 71900, lr = 0.001
I0616 13:19:01.045081 29366 solver.cpp:218] Iteration 71950 (0.862717 iter/s, 57.9564s/50 iters), loss = 0.00468003
I0616 13:19:01.045362 29366 solver.cpp:237]     Train net output #0: loss = 0.00468008 (* 1 = 0.00468008 loss)
I0616 13:19:01.045387 29366 sgd_solver.cpp:105] Iteration 71950, lr = 0.001
I0616 13:19:59.031195 29366 solver.cpp:218] Iteration 72000 (0.862288 iter/s, 57.9853s/50 iters), loss = 0.00670656
I0616 13:19:59.034441 29366 solver.cpp:237]     Train net output #0: loss = 0.00670661 (* 1 = 0.00670661 loss)
I0616 13:19:59.034471 29366 sgd_solver.cpp:105] Iteration 72000, lr = 0.001
I0616 13:20:57.018254 29366 solver.cpp:218] Iteration 72050 (0.862318 iter/s, 57.9833s/50 iters), loss = 0.00523281
I0616 13:20:57.018556 29366 solver.cpp:237]     Train net output #0: loss = 0.00523287 (* 1 = 0.00523287 loss)
I0616 13:20:57.018582 29366 sgd_solver.cpp:105] Iteration 72050, lr = 0.001
I0616 13:21:54.975613 29366 solver.cpp:218] Iteration 72100 (0.862716 iter/s, 57.9565s/50 iters), loss = 0.00548466
I0616 13:21:54.975833 29366 solver.cpp:237]     Train net output #0: loss = 0.00548472 (* 1 = 0.00548472 loss)
I0616 13:21:54.975857 29366 sgd_solver.cpp:105] Iteration 72100, lr = 0.001
I0616 13:22:52.896235 29366 solver.cpp:218] Iteration 72150 (0.863262 iter/s, 57.9199s/50 iters), loss = 0.00752119
I0616 13:22:52.896374 29366 solver.cpp:237]     Train net output #0: loss = 0.00752124 (* 1 = 0.00752124 loss)
I0616 13:22:52.896402 29366 sgd_solver.cpp:105] Iteration 72150, lr = 0.001
I0616 13:23:50.655678 29366 solver.cpp:218] Iteration 72200 (0.86567 iter/s, 57.7588s/50 iters), loss = 0.00695535
I0616 13:23:50.655838 29366 solver.cpp:237]     Train net output #0: loss = 0.00695541 (* 1 = 0.00695541 loss)
I0616 13:23:50.655861 29366 sgd_solver.cpp:105] Iteration 72200, lr = 0.001
I0616 13:24:48.417923 29366 solver.cpp:218] Iteration 72250 (0.865628 iter/s, 57.7615s/50 iters), loss = 0.00619938
I0616 13:24:48.418068 29366 solver.cpp:237]     Train net output #0: loss = 0.00619944 (* 1 = 0.00619944 loss)
I0616 13:24:48.418092 29366 sgd_solver.cpp:105] Iteration 72250, lr = 0.001
I0616 13:25:46.172497 29366 solver.cpp:218] Iteration 72300 (0.865743 iter/s, 57.7539s/50 iters), loss = 0.00570133
I0616 13:25:46.172654 29366 solver.cpp:237]     Train net output #0: loss = 0.00570138 (* 1 = 0.00570138 loss)
I0616 13:25:46.172677 29366 sgd_solver.cpp:105] Iteration 72300, lr = 0.001
I0616 13:26:43.977571 29366 solver.cpp:218] Iteration 72350 (0.864986 iter/s, 57.8044s/50 iters), loss = 0.00730037
I0616 13:26:43.977782 29366 solver.cpp:237]     Train net output #0: loss = 0.00730043 (* 1 = 0.00730043 loss)
I0616 13:26:43.977805 29366 sgd_solver.cpp:105] Iteration 72350, lr = 0.001
I0616 13:27:41.854778 29366 solver.cpp:218] Iteration 72400 (0.863909 iter/s, 57.8764s/50 iters), loss = 0.00458768
I0616 13:27:41.857640 29366 solver.cpp:237]     Train net output #0: loss = 0.00458773 (* 1 = 0.00458773 loss)
I0616 13:27:41.857664 29366 sgd_solver.cpp:105] Iteration 72400, lr = 0.001
I0616 13:28:39.833022 29366 solver.cpp:218] Iteration 72450 (0.862443 iter/s, 57.9748s/50 iters), loss = 0.00509971
I0616 13:28:39.836621 29366 solver.cpp:237]     Train net output #0: loss = 0.00509976 (* 1 = 0.00509976 loss)
I0616 13:28:39.836654 29366 sgd_solver.cpp:105] Iteration 72450, lr = 0.001
I0616 13:29:37.754060 29366 solver.cpp:218] Iteration 72500 (0.863306 iter/s, 57.9169s/50 iters), loss = 0.0109763
I0616 13:29:37.754215 29366 solver.cpp:237]     Train net output #0: loss = 0.0109763 (* 1 = 0.0109763 loss)
I0616 13:29:37.754240 29366 sgd_solver.cpp:105] Iteration 72500, lr = 0.001
I0616 13:30:35.577787 29366 solver.cpp:218] Iteration 72550 (0.864707 iter/s, 57.823s/50 iters), loss = 0.00582716
I0616 13:30:35.577992 29366 solver.cpp:237]     Train net output #0: loss = 0.00582721 (* 1 = 0.00582721 loss)
I0616 13:30:35.578019 29366 sgd_solver.cpp:105] Iteration 72550, lr = 0.001
I0616 13:31:33.378785 29366 solver.cpp:218] Iteration 72600 (0.865048 iter/s, 57.8002s/50 iters), loss = 0.00955454
I0616 13:31:33.379030 29366 solver.cpp:237]     Train net output #0: loss = 0.00955459 (* 1 = 0.00955459 loss)
I0616 13:31:33.379055 29366 sgd_solver.cpp:105] Iteration 72600, lr = 0.001
I0616 13:32:31.164872 29366 solver.cpp:218] Iteration 72650 (0.865272 iter/s, 57.7853s/50 iters), loss = 0.0058664
I0616 13:32:31.165027 29366 solver.cpp:237]     Train net output #0: loss = 0.00586646 (* 1 = 0.00586646 loss)
I0616 13:32:31.165050 29366 sgd_solver.cpp:105] Iteration 72650, lr = 0.001
I0616 13:33:28.916229 29366 solver.cpp:218] Iteration 72700 (0.865792 iter/s, 57.7506s/50 iters), loss = 0.00677917
I0616 13:33:28.916404 29366 solver.cpp:237]     Train net output #0: loss = 0.00677923 (* 1 = 0.00677923 loss)
I0616 13:33:28.916435 29366 sgd_solver.cpp:105] Iteration 72700, lr = 0.001
I0616 13:34:26.680840 29366 solver.cpp:218] Iteration 72750 (0.865593 iter/s, 57.7639s/50 iters), loss = 0.00437246
I0616 13:34:26.680989 29366 solver.cpp:237]     Train net output #0: loss = 0.00437251 (* 1 = 0.00437251 loss)
I0616 13:34:26.681012 29366 sgd_solver.cpp:105] Iteration 72750, lr = 0.001
I0616 13:35:24.453052 29366 solver.cpp:218] Iteration 72800 (0.865479 iter/s, 57.7715s/50 iters), loss = 0.00467588
I0616 13:35:24.453202 29366 solver.cpp:237]     Train net output #0: loss = 0.00467593 (* 1 = 0.00467593 loss)
I0616 13:35:24.453225 29366 sgd_solver.cpp:105] Iteration 72800, lr = 0.001
I0616 13:36:22.212313 29366 solver.cpp:218] Iteration 72850 (0.865673 iter/s, 57.7586s/50 iters), loss = 0.00595007
I0616 13:36:22.212448 29366 solver.cpp:237]     Train net output #0: loss = 0.00595012 (* 1 = 0.00595012 loss)
I0616 13:36:22.212471 29366 sgd_solver.cpp:105] Iteration 72850, lr = 0.001
I0616 13:37:20.060976 29366 solver.cpp:218] Iteration 72900 (0.864335 iter/s, 57.848s/50 iters), loss = 0.00478091
I0616 13:37:20.061105 29366 solver.cpp:237]     Train net output #0: loss = 0.00478097 (* 1 = 0.00478097 loss)
I0616 13:37:20.061130 29366 sgd_solver.cpp:105] Iteration 72900, lr = 0.001
I0616 13:38:17.879209 29366 solver.cpp:218] Iteration 72950 (0.86479 iter/s, 57.8175s/50 iters), loss = 0.00467227
I0616 13:38:17.879480 29366 solver.cpp:237]     Train net output #0: loss = 0.00467232 (* 1 = 0.00467232 loss)
I0616 13:38:17.879505 29366 sgd_solver.cpp:105] Iteration 72950, lr = 0.001
I0616 13:39:16.222404 29366 solver.cpp:218] Iteration 73000 (0.857011 iter/s, 58.3423s/50 iters), loss = 0.0088991
I0616 13:39:16.222636 29366 solver.cpp:237]     Train net output #0: loss = 0.00889915 (* 1 = 0.00889915 loss)
I0616 13:39:16.222666 29366 sgd_solver.cpp:105] Iteration 73000, lr = 0.001
I0616 13:40:14.199816 29366 solver.cpp:218] Iteration 73050 (0.862417 iter/s, 57.9766s/50 iters), loss = 0.00570327
I0616 13:40:14.200108 29366 solver.cpp:237]     Train net output #0: loss = 0.00570332 (* 1 = 0.00570332 loss)
I0616 13:40:14.200131 29366 sgd_solver.cpp:105] Iteration 73050, lr = 0.001
I0616 13:41:12.178813 29366 solver.cpp:218] Iteration 73100 (0.862395 iter/s, 57.9781s/50 iters), loss = 0.00644018
I0616 13:41:12.179142 29366 solver.cpp:237]     Train net output #0: loss = 0.00644024 (* 1 = 0.00644024 loss)
I0616 13:41:12.179168 29366 sgd_solver.cpp:105] Iteration 73100, lr = 0.001
I0616 13:42:10.404578 29366 solver.cpp:218] Iteration 73150 (0.858787 iter/s, 58.2216s/50 iters), loss = 0.00578586
I0616 13:42:10.408608 29366 solver.cpp:237]     Train net output #0: loss = 0.00578591 (* 1 = 0.00578591 loss)
I0616 13:42:10.408639 29366 sgd_solver.cpp:105] Iteration 73150, lr = 0.001
I0616 13:43:08.795972 29366 solver.cpp:218] Iteration 73200 (0.856358 iter/s, 58.3868s/50 iters), loss = 0.00505357
I0616 13:43:08.797853 29366 solver.cpp:237]     Train net output #0: loss = 0.00505363 (* 1 = 0.00505363 loss)
I0616 13:43:08.797884 29366 sgd_solver.cpp:105] Iteration 73200, lr = 0.001
I0616 13:44:06.980321 29366 solver.cpp:218] Iteration 73250 (0.859374 iter/s, 58.1819s/50 iters), loss = 0.00623657
I0616 13:44:06.983325 29366 solver.cpp:237]     Train net output #0: loss = 0.00623663 (* 1 = 0.00623663 loss)
I0616 13:44:06.983391 29366 sgd_solver.cpp:105] Iteration 73250, lr = 0.001
I0616 13:45:04.725291 29366 solver.cpp:218] Iteration 73300 (0.86593 iter/s, 57.7414s/50 iters), loss = 0.00702406
I0616 13:45:04.725450 29366 solver.cpp:237]     Train net output #0: loss = 0.00702411 (* 1 = 0.00702411 loss)
I0616 13:45:04.725482 29366 sgd_solver.cpp:105] Iteration 73300, lr = 0.001
I0616 13:46:02.457742 29366 solver.cpp:218] Iteration 73350 (0.866075 iter/s, 57.7317s/50 iters), loss = 0.00583699
I0616 13:46:02.457881 29366 solver.cpp:237]     Train net output #0: loss = 0.00583705 (* 1 = 0.00583705 loss)
I0616 13:46:02.457909 29366 sgd_solver.cpp:105] Iteration 73350, lr = 0.001
I0616 13:47:00.204138 29366 solver.cpp:218] Iteration 73400 (0.865866 iter/s, 57.7456s/50 iters), loss = 0.00381603
I0616 13:47:00.204306 29366 solver.cpp:237]     Train net output #0: loss = 0.00381608 (* 1 = 0.00381608 loss)
I0616 13:47:00.204330 29366 sgd_solver.cpp:105] Iteration 73400, lr = 0.001
I0616 13:47:58.278520 29366 solver.cpp:218] Iteration 73450 (0.860976 iter/s, 58.0736s/50 iters), loss = 0.00589011
I0616 13:47:58.282177 29366 solver.cpp:237]     Train net output #0: loss = 0.00589016 (* 1 = 0.00589016 loss)
I0616 13:47:58.282212 29366 sgd_solver.cpp:105] Iteration 73450, lr = 0.001
I0616 13:48:57.089128 29366 solver.cpp:218] Iteration 73500 (0.850248 iter/s, 58.8064s/50 iters), loss = 0.00636353
I0616 13:48:57.094576 29366 solver.cpp:237]     Train net output #0: loss = 0.00636358 (* 1 = 0.00636358 loss)
I0616 13:48:57.094622 29366 sgd_solver.cpp:105] Iteration 73500, lr = 0.001
I0616 13:49:55.102674 29366 solver.cpp:218] Iteration 73550 (0.861956 iter/s, 58.0076s/50 iters), loss = 0.00585849
I0616 13:49:55.102807 29366 solver.cpp:237]     Train net output #0: loss = 0.00585854 (* 1 = 0.00585854 loss)
I0616 13:49:55.102831 29366 sgd_solver.cpp:105] Iteration 73550, lr = 0.001
I0616 13:50:52.862812 29366 solver.cpp:218] Iteration 73600 (0.865659 iter/s, 57.7595s/50 iters), loss = 0.00630214
I0616 13:50:52.862951 29366 solver.cpp:237]     Train net output #0: loss = 0.00630219 (* 1 = 0.00630219 loss)
I0616 13:50:52.862983 29366 sgd_solver.cpp:105] Iteration 73600, lr = 0.001
I0616 13:51:50.616891 29366 solver.cpp:218] Iteration 73650 (0.86575 iter/s, 57.7534s/50 iters), loss = 0.00654
I0616 13:51:50.617044 29366 solver.cpp:237]     Train net output #0: loss = 0.00654006 (* 1 = 0.00654006 loss)
I0616 13:51:50.617069 29366 sgd_solver.cpp:105] Iteration 73650, lr = 0.001
I0616 13:52:48.369786 29366 solver.cpp:218] Iteration 73700 (0.865768 iter/s, 57.7522s/50 iters), loss = 0.00427606
I0616 13:52:48.369920 29366 solver.cpp:237]     Train net output #0: loss = 0.00427612 (* 1 = 0.00427612 loss)
I0616 13:52:48.369941 29366 sgd_solver.cpp:105] Iteration 73700, lr = 0.001
I0616 13:53:46.123352 29366 solver.cpp:218] Iteration 73750 (0.865758 iter/s, 57.7529s/50 iters), loss = 0.00486898
I0616 13:53:46.123479 29366 solver.cpp:237]     Train net output #0: loss = 0.00486903 (* 1 = 0.00486903 loss)
I0616 13:53:46.123502 29366 sgd_solver.cpp:105] Iteration 73750, lr = 0.001
I0616 13:54:43.875524 29366 solver.cpp:218] Iteration 73800 (0.865778 iter/s, 57.7515s/50 iters), loss = 0.00675872
I0616 13:54:43.875659 29366 solver.cpp:237]     Train net output #0: loss = 0.00675877 (* 1 = 0.00675877 loss)
I0616 13:54:43.875681 29366 sgd_solver.cpp:105] Iteration 73800, lr = 0.001
I0616 13:55:41.630297 29366 solver.cpp:218] Iteration 73850 (0.86574 iter/s, 57.7541s/50 iters), loss = 0.00725458
I0616 13:55:41.630434 29366 solver.cpp:237]     Train net output #0: loss = 0.00725464 (* 1 = 0.00725464 loss)
I0616 13:55:41.630458 29366 sgd_solver.cpp:105] Iteration 73850, lr = 0.001
I0616 13:56:39.382719 29366 solver.cpp:218] Iteration 73900 (0.865775 iter/s, 57.7517s/50 iters), loss = 0.00473587
I0616 13:56:39.382838 29366 solver.cpp:237]     Train net output #0: loss = 0.00473593 (* 1 = 0.00473593 loss)
I0616 13:56:39.382860 29366 sgd_solver.cpp:105] Iteration 73900, lr = 0.001
I0616 13:57:37.131950 29366 solver.cpp:218] Iteration 73950 (0.865822 iter/s, 57.7486s/50 iters), loss = 0.00466206
I0616 13:57:37.132118 29366 solver.cpp:237]     Train net output #0: loss = 0.00466212 (* 1 = 0.00466212 loss)
I0616 13:57:37.132141 29366 sgd_solver.cpp:105] Iteration 73950, lr = 0.001
I0616 13:58:34.893241 29366 solver.cpp:218] Iteration 74000 (0.865643 iter/s, 57.7606s/50 iters), loss = 0.00508761
I0616 13:58:34.893399 29366 solver.cpp:237]     Train net output #0: loss = 0.00508767 (* 1 = 0.00508767 loss)
I0616 13:58:34.893429 29366 sgd_solver.cpp:105] Iteration 74000, lr = 0.001
I0616 13:59:32.652727 29366 solver.cpp:218] Iteration 74050 (0.865669 iter/s, 57.7588s/50 iters), loss = 0.00606875
I0616 13:59:32.652849 29366 solver.cpp:237]     Train net output #0: loss = 0.0060688 (* 1 = 0.0060688 loss)
I0616 13:59:32.652871 29366 sgd_solver.cpp:105] Iteration 74050, lr = 0.001
I0616 14:00:30.402925 29366 solver.cpp:218] Iteration 74100 (0.865808 iter/s, 57.7495s/50 iters), loss = 0.00749596
I0616 14:00:30.403036 29366 solver.cpp:237]     Train net output #0: loss = 0.00749602 (* 1 = 0.00749602 loss)
I0616 14:00:30.403059 29366 sgd_solver.cpp:105] Iteration 74100, lr = 0.001
I0616 14:01:28.148538 29366 solver.cpp:218] Iteration 74150 (0.865876 iter/s, 57.745s/50 iters), loss = 0.00375303
I0616 14:01:28.148664 29366 solver.cpp:237]     Train net output #0: loss = 0.00375309 (* 1 = 0.00375309 loss)
I0616 14:01:28.148686 29366 sgd_solver.cpp:105] Iteration 74150, lr = 0.001
I0616 14:02:25.906528 29366 solver.cpp:218] Iteration 74200 (0.865691 iter/s, 57.7573s/50 iters), loss = 0.00604683
I0616 14:02:25.906698 29366 solver.cpp:237]     Train net output #0: loss = 0.00604689 (* 1 = 0.00604689 loss)
I0616 14:02:25.906721 29366 sgd_solver.cpp:105] Iteration 74200, lr = 0.001
I0616 14:03:23.662294 29366 solver.cpp:218] Iteration 74250 (0.865725 iter/s, 57.7551s/50 iters), loss = 0.00444909
I0616 14:03:23.662420 29366 solver.cpp:237]     Train net output #0: loss = 0.00444914 (* 1 = 0.00444914 loss)
I0616 14:03:23.662442 29366 sgd_solver.cpp:105] Iteration 74250, lr = 0.001
I0616 14:04:21.418869 29366 solver.cpp:218] Iteration 74300 (0.865712 iter/s, 57.7559s/50 iters), loss = 0.00951572
I0616 14:04:21.419009 29366 solver.cpp:237]     Train net output #0: loss = 0.00951578 (* 1 = 0.00951578 loss)
I0616 14:04:21.419034 29366 sgd_solver.cpp:105] Iteration 74300, lr = 0.001
I0616 14:05:19.185276 29366 solver.cpp:218] Iteration 74350 (0.865563 iter/s, 57.7659s/50 iters), loss = 0.00804582
I0616 14:05:19.185385 29366 solver.cpp:237]     Train net output #0: loss = 0.00804588 (* 1 = 0.00804588 loss)
I0616 14:05:19.185410 29366 sgd_solver.cpp:105] Iteration 74350, lr = 0.001
I0616 14:06:17.104450 29366 solver.cpp:218] Iteration 74400 (0.86328 iter/s, 57.9186s/50 iters), loss = 0.00471794
I0616 14:06:17.108610 29366 solver.cpp:237]     Train net output #0: loss = 0.004718 (* 1 = 0.004718 loss)
I0616 14:06:17.108636 29366 sgd_solver.cpp:105] Iteration 74400, lr = 0.001
I0616 14:07:15.319211 29366 solver.cpp:218] Iteration 74450 (0.858956 iter/s, 58.2102s/50 iters), loss = 0.00493483
I0616 14:07:15.319402 29366 solver.cpp:237]     Train net output #0: loss = 0.00493488 (* 1 = 0.00493488 loss)
I0616 14:07:15.319425 29366 sgd_solver.cpp:105] Iteration 74450, lr = 0.001
I0616 14:08:13.290253 29366 solver.cpp:218] Iteration 74500 (0.862509 iter/s, 57.9704s/50 iters), loss = 0.00476879
I0616 14:08:13.290552 29366 solver.cpp:237]     Train net output #0: loss = 0.00476885 (* 1 = 0.00476885 loss)
I0616 14:08:13.290576 29366 sgd_solver.cpp:105] Iteration 74500, lr = 0.001
I0616 14:09:11.381618 29366 solver.cpp:218] Iteration 74550 (0.860773 iter/s, 58.0873s/50 iters), loss = 0.00729915
I0616 14:09:11.385668 29366 solver.cpp:237]     Train net output #0: loss = 0.00729921 (* 1 = 0.00729921 loss)
I0616 14:09:11.385705 29366 sgd_solver.cpp:105] Iteration 74550, lr = 0.001
I0616 14:10:10.151005 29366 solver.cpp:218] Iteration 74600 (0.85085 iter/s, 58.7648s/50 iters), loss = 0.00960923
I0616 14:10:10.154659 29366 solver.cpp:237]     Train net output #0: loss = 0.00960929 (* 1 = 0.00960929 loss)
I0616 14:10:10.154701 29366 sgd_solver.cpp:105] Iteration 74600, lr = 0.001
I0616 14:11:08.268389 29366 solver.cpp:218] Iteration 74650 (0.860388 iter/s, 58.1133s/50 iters), loss = 0.00484167
I0616 14:11:08.268681 29366 solver.cpp:237]     Train net output #0: loss = 0.00484172 (* 1 = 0.00484172 loss)
I0616 14:11:08.268704 29366 sgd_solver.cpp:105] Iteration 74650, lr = 0.001
I0616 14:12:06.620810 29366 solver.cpp:218] Iteration 74700 (0.856874 iter/s, 58.3517s/50 iters), loss = 0.0056859
I0616 14:12:06.621094 29366 solver.cpp:237]     Train net output #0: loss = 0.00568595 (* 1 = 0.00568595 loss)
I0616 14:12:06.621121 29366 sgd_solver.cpp:105] Iteration 74700, lr = 0.001
I0616 14:13:04.701987 29366 solver.cpp:218] Iteration 74750 (0.860875 iter/s, 58.0804s/50 iters), loss = 0.0068338
I0616 14:13:04.702147 29366 solver.cpp:237]     Train net output #0: loss = 0.00683386 (* 1 = 0.00683386 loss)
I0616 14:13:04.702169 29366 sgd_solver.cpp:105] Iteration 74750, lr = 0.001
I0616 14:14:02.457218 29366 solver.cpp:218] Iteration 74800 (0.865732 iter/s, 57.7546s/50 iters), loss = 0.00898439
I0616 14:14:02.457386 29366 solver.cpp:237]     Train net output #0: loss = 0.00898444 (* 1 = 0.00898444 loss)
I0616 14:14:02.457411 29366 sgd_solver.cpp:105] Iteration 74800, lr = 0.001
I0616 14:15:00.228140 29366 solver.cpp:218] Iteration 74850 (0.865496 iter/s, 57.7703s/50 iters), loss = 0.00551797
I0616 14:15:00.228302 29366 solver.cpp:237]     Train net output #0: loss = 0.00551803 (* 1 = 0.00551803 loss)
I0616 14:15:00.228325 29366 sgd_solver.cpp:105] Iteration 74850, lr = 0.001
I0616 14:15:58.001930 29366 solver.cpp:218] Iteration 74900 (0.865453 iter/s, 57.7732s/50 iters), loss = 0.00549129
I0616 14:15:58.002082 29366 solver.cpp:237]     Train net output #0: loss = 0.00549135 (* 1 = 0.00549135 loss)
I0616 14:15:58.002107 29366 sgd_solver.cpp:105] Iteration 74900, lr = 0.001
I0616 14:16:55.761997 29366 solver.cpp:218] Iteration 74950 (0.865658 iter/s, 57.7595s/50 iters), loss = 0.00427279
I0616 14:16:55.762140 29366 solver.cpp:237]     Train net output #0: loss = 0.00427285 (* 1 = 0.00427285 loss)
I0616 14:16:55.762163 29366 sgd_solver.cpp:105] Iteration 74950, lr = 0.001
I0616 14:17:53.531548 29366 solver.cpp:218] Iteration 75000 (0.865517 iter/s, 57.769s/50 iters), loss = 0.00409774
I0616 14:17:53.531711 29366 solver.cpp:237]     Train net output #0: loss = 0.00409779 (* 1 = 0.00409779 loss)
I0616 14:17:53.531735 29366 sgd_solver.cpp:105] Iteration 75000, lr = 0.001
I0616 14:18:51.295857 29366 solver.cpp:218] Iteration 75050 (0.865596 iter/s, 57.7637s/50 iters), loss = 0.00593593
I0616 14:18:51.296025 29366 solver.cpp:237]     Train net output #0: loss = 0.00593599 (* 1 = 0.00593599 loss)
I0616 14:18:51.296049 29366 sgd_solver.cpp:105] Iteration 75050, lr = 0.001
I0616 14:19:49.045356 29366 solver.cpp:218] Iteration 75100 (0.865817 iter/s, 57.7489s/50 iters), loss = 0.00618399
I0616 14:19:49.045481 29366 solver.cpp:237]     Train net output #0: loss = 0.00618404 (* 1 = 0.00618404 loss)
I0616 14:19:49.045503 29366 sgd_solver.cpp:105] Iteration 75100, lr = 0.001
I0616 14:20:46.806001 29366 solver.cpp:218] Iteration 75150 (0.86565 iter/s, 57.7601s/50 iters), loss = 0.00773927
I0616 14:20:46.806135 29366 solver.cpp:237]     Train net output #0: loss = 0.00773932 (* 1 = 0.00773932 loss)
I0616 14:20:46.806164 29366 sgd_solver.cpp:105] Iteration 75150, lr = 0.001
I0616 14:21:44.553838 29366 solver.cpp:218] Iteration 75200 (0.865843 iter/s, 57.7472s/50 iters), loss = 0.00938493
I0616 14:21:44.553967 29366 solver.cpp:237]     Train net output #0: loss = 0.00938499 (* 1 = 0.00938499 loss)
I0616 14:21:44.553989 29366 sgd_solver.cpp:105] Iteration 75200, lr = 0.001
I0616 14:22:42.382855 29366 solver.cpp:218] Iteration 75250 (0.864629 iter/s, 57.8283s/50 iters), loss = 0.00429173
I0616 14:22:42.383127 29366 solver.cpp:237]     Train net output #0: loss = 0.00429178 (* 1 = 0.00429178 loss)
I0616 14:22:42.383155 29366 sgd_solver.cpp:105] Iteration 75250, lr = 0.001
I0616 14:23:40.159317 29366 solver.cpp:218] Iteration 75300 (0.865417 iter/s, 57.7756s/50 iters), loss = 0.00452383
I0616 14:23:40.159567 29366 solver.cpp:237]     Train net output #0: loss = 0.00452388 (* 1 = 0.00452388 loss)
I0616 14:23:40.159592 29366 sgd_solver.cpp:105] Iteration 75300, lr = 0.001
I0616 14:24:37.929431 29366 solver.cpp:218] Iteration 75350 (0.865512 iter/s, 57.7693s/50 iters), loss = 0.00395218
I0616 14:24:37.929666 29366 solver.cpp:237]     Train net output #0: loss = 0.00395223 (* 1 = 0.00395223 loss)
I0616 14:24:37.929695 29366 sgd_solver.cpp:105] Iteration 75350, lr = 0.001
I0616 14:25:35.710796 29366 solver.cpp:218] Iteration 75400 (0.865343 iter/s, 57.7805s/50 iters), loss = 0.00737124
I0616 14:25:35.710944 29366 solver.cpp:237]     Train net output #0: loss = 0.00737129 (* 1 = 0.00737129 loss)
I0616 14:25:35.710968 29366 sgd_solver.cpp:105] Iteration 75400, lr = 0.001
I0616 14:26:33.473906 29366 solver.cpp:218] Iteration 75450 (0.865616 iter/s, 57.7624s/50 iters), loss = 0.0116342
I0616 14:26:33.474052 29366 solver.cpp:237]     Train net output #0: loss = 0.0116342 (* 1 = 0.0116342 loss)
I0616 14:26:33.474081 29366 sgd_solver.cpp:105] Iteration 75450, lr = 0.001
I0616 14:27:31.244410 29366 solver.cpp:218] Iteration 75500 (0.865505 iter/s, 57.7698s/50 iters), loss = 0.00477587
I0616 14:27:31.244585 29366 solver.cpp:237]     Train net output #0: loss = 0.00477592 (* 1 = 0.00477592 loss)
I0616 14:27:31.244607 29366 sgd_solver.cpp:105] Iteration 75500, lr = 0.001
I0616 14:28:29.056666 29366 solver.cpp:218] Iteration 75550 (0.86488 iter/s, 57.8115s/50 iters), loss = 0.00583319
I0616 14:28:29.056922 29366 solver.cpp:237]     Train net output #0: loss = 0.00583324 (* 1 = 0.00583324 loss)
I0616 14:28:29.056946 29366 sgd_solver.cpp:105] Iteration 75550, lr = 0.001
I0616 14:29:26.860927 29366 solver.cpp:218] Iteration 75600 (0.865001 iter/s, 57.8034s/50 iters), loss = 0.00708886
I0616 14:29:26.861084 29366 solver.cpp:237]     Train net output #0: loss = 0.00708892 (* 1 = 0.00708892 loss)
I0616 14:29:26.861109 29366 sgd_solver.cpp:105] Iteration 75600, lr = 0.001
I0616 14:30:24.627406 29366 solver.cpp:218] Iteration 75650 (0.865565 iter/s, 57.7657s/50 iters), loss = 0.0060985
I0616 14:30:24.627632 29366 solver.cpp:237]     Train net output #0: loss = 0.00609856 (* 1 = 0.00609856 loss)
I0616 14:30:24.627656 29366 sgd_solver.cpp:105] Iteration 75650, lr = 0.001
I0616 14:31:22.418352 29366 solver.cpp:218] Iteration 75700 (0.8652 iter/s, 57.7901s/50 iters), loss = 0.00442489
I0616 14:31:22.418543 29366 solver.cpp:237]     Train net output #0: loss = 0.00442494 (* 1 = 0.00442494 loss)
I0616 14:31:22.418572 29366 sgd_solver.cpp:105] Iteration 75700, lr = 0.001
I0616 14:32:20.203673 29366 solver.cpp:218] Iteration 75750 (0.865283 iter/s, 57.7845s/50 iters), loss = 0.00499517
I0616 14:32:20.203919 29366 solver.cpp:237]     Train net output #0: loss = 0.00499522 (* 1 = 0.00499522 loss)
I0616 14:32:20.203944 29366 sgd_solver.cpp:105] Iteration 75750, lr = 0.001
I0616 14:33:17.972496 29366 solver.cpp:218] Iteration 75800 (0.865531 iter/s, 57.768s/50 iters), loss = 0.00274356
I0616 14:33:17.972640 29366 solver.cpp:237]     Train net output #0: loss = 0.00274362 (* 1 = 0.00274362 loss)
I0616 14:33:17.972661 29366 sgd_solver.cpp:105] Iteration 75800, lr = 0.001
I0616 14:34:15.749269 29366 solver.cpp:218] Iteration 75850 (0.865411 iter/s, 57.776s/50 iters), loss = 0.00375313
I0616 14:34:15.749444 29366 solver.cpp:237]     Train net output #0: loss = 0.00375319 (* 1 = 0.00375319 loss)
I0616 14:34:15.749465 29366 sgd_solver.cpp:105] Iteration 75850, lr = 0.001
I0616 14:35:13.529307 29366 solver.cpp:218] Iteration 75900 (0.865362 iter/s, 57.7793s/50 iters), loss = 0.00566504
I0616 14:35:13.529455 29366 solver.cpp:237]     Train net output #0: loss = 0.0056651 (* 1 = 0.0056651 loss)
I0616 14:35:13.529477 29366 sgd_solver.cpp:105] Iteration 75900, lr = 0.001
I0616 14:36:11.302851 29366 solver.cpp:218] Iteration 75950 (0.865459 iter/s, 57.7728s/50 iters), loss = 0.00545566
I0616 14:36:11.303048 29366 solver.cpp:237]     Train net output #0: loss = 0.00545572 (* 1 = 0.00545572 loss)
I0616 14:36:11.303073 29366 sgd_solver.cpp:105] Iteration 75950, lr = 0.001
I0616 14:37:09.088138 29366 solver.cpp:218] Iteration 76000 (0.865284 iter/s, 57.7845s/50 iters), loss = 0.0060821
I0616 14:37:09.088310 29366 solver.cpp:237]     Train net output #0: loss = 0.00608215 (* 1 = 0.00608215 loss)
I0616 14:37:09.088333 29366 sgd_solver.cpp:105] Iteration 76000, lr = 0.001
I0616 14:38:06.907902 29366 solver.cpp:218] Iteration 76050 (0.864768 iter/s, 57.819s/50 iters), loss = 0.00566111
I0616 14:38:06.908113 29366 solver.cpp:237]     Train net output #0: loss = 0.00566116 (* 1 = 0.00566116 loss)
I0616 14:38:06.908143 29366 sgd_solver.cpp:105] Iteration 76050, lr = 0.001
I0616 14:39:04.776614 29366 solver.cpp:218] Iteration 76100 (0.864037 iter/s, 57.8679s/50 iters), loss = 0.00611211
I0616 14:39:04.776749 29366 solver.cpp:237]     Train net output #0: loss = 0.00611216 (* 1 = 0.00611216 loss)
I0616 14:39:04.776773 29366 sgd_solver.cpp:105] Iteration 76100, lr = 0.001
I0616 14:40:02.551342 29366 solver.cpp:218] Iteration 76150 (0.865442 iter/s, 57.7739s/50 iters), loss = 0.00502979
I0616 14:40:02.551502 29366 solver.cpp:237]     Train net output #0: loss = 0.00502984 (* 1 = 0.00502984 loss)
I0616 14:40:02.551539 29366 sgd_solver.cpp:105] Iteration 76150, lr = 0.001
I0616 14:41:00.334200 29366 solver.cpp:218] Iteration 76200 (0.86532 iter/s, 57.7821s/50 iters), loss = 0.00501533
I0616 14:41:00.334347 29366 solver.cpp:237]     Train net output #0: loss = 0.00501539 (* 1 = 0.00501539 loss)
I0616 14:41:00.334370 29366 sgd_solver.cpp:105] Iteration 76200, lr = 0.001
I0616 14:41:58.133759 29366 solver.cpp:218] Iteration 76250 (0.86507 iter/s, 57.7988s/50 iters), loss = 0.00468761
I0616 14:41:58.133888 29366 solver.cpp:237]     Train net output #0: loss = 0.00468766 (* 1 = 0.00468766 loss)
I0616 14:41:58.133910 29366 sgd_solver.cpp:105] Iteration 76250, lr = 0.001
I0616 14:42:55.902055 29366 solver.cpp:218] Iteration 76300 (0.865538 iter/s, 57.7676s/50 iters), loss = 0.00533723
I0616 14:42:55.902192 29366 solver.cpp:237]     Train net output #0: loss = 0.00533729 (* 1 = 0.00533729 loss)
I0616 14:42:55.902215 29366 sgd_solver.cpp:105] Iteration 76300, lr = 0.001
I0616 14:43:53.674649 29366 solver.cpp:218] Iteration 76350 (0.865474 iter/s, 57.7718s/50 iters), loss = 0.00567652
I0616 14:43:53.674813 29366 solver.cpp:237]     Train net output #0: loss = 0.00567658 (* 1 = 0.00567658 loss)
I0616 14:43:53.674837 29366 sgd_solver.cpp:105] Iteration 76350, lr = 0.001
I0616 14:44:51.448050 29366 solver.cpp:218] Iteration 76400 (0.865462 iter/s, 57.7726s/50 iters), loss = 0.00513148
I0616 14:44:51.448180 29366 solver.cpp:237]     Train net output #0: loss = 0.00513153 (* 1 = 0.00513153 loss)
I0616 14:44:51.448204 29366 sgd_solver.cpp:105] Iteration 76400, lr = 0.001
I0616 14:45:49.257227 29366 solver.cpp:218] Iteration 76450 (0.864926 iter/s, 57.8084s/50 iters), loss = 0.00833565
I0616 14:45:49.257526 29366 solver.cpp:237]     Train net output #0: loss = 0.00833571 (* 1 = 0.00833571 loss)
I0616 14:45:49.257552 29366 sgd_solver.cpp:105] Iteration 76450, lr = 0.001
I0616 14:46:47.117969 29366 solver.cpp:218] Iteration 76500 (0.864157 iter/s, 57.8599s/50 iters), loss = 0.00456876
I0616 14:46:47.118094 29366 solver.cpp:237]     Train net output #0: loss = 0.00456881 (* 1 = 0.00456881 loss)
I0616 14:46:47.118116 29366 sgd_solver.cpp:105] Iteration 76500, lr = 0.001
I0616 14:47:44.936240 29366 solver.cpp:218] Iteration 76550 (0.864789 iter/s, 57.8176s/50 iters), loss = 0.00658578
I0616 14:47:44.936375 29366 solver.cpp:237]     Train net output #0: loss = 0.00658583 (* 1 = 0.00658583 loss)
I0616 14:47:44.936398 29366 sgd_solver.cpp:105] Iteration 76550, lr = 0.001
I0616 14:48:42.702884 29366 solver.cpp:218] Iteration 76600 (0.865562 iter/s, 57.7659s/50 iters), loss = 0.00469754
I0616 14:48:42.703017 29366 solver.cpp:237]     Train net output #0: loss = 0.0046976 (* 1 = 0.0046976 loss)
I0616 14:48:42.703040 29366 sgd_solver.cpp:105] Iteration 76600, lr = 0.001
I0616 14:49:40.453861 29366 solver.cpp:218] Iteration 76650 (0.865797 iter/s, 57.7503s/50 iters), loss = 0.00459146
I0616 14:49:40.454056 29366 solver.cpp:237]     Train net output #0: loss = 0.00459152 (* 1 = 0.00459152 loss)
I0616 14:49:40.454092 29366 sgd_solver.cpp:105] Iteration 76650, lr = 0.001
I0616 14:50:38.207689 29366 solver.cpp:218] Iteration 76700 (0.865755 iter/s, 57.753s/50 iters), loss = 0.00659457
I0616 14:50:38.207859 29366 solver.cpp:237]     Train net output #0: loss = 0.00659462 (* 1 = 0.00659462 loss)
I0616 14:50:38.207881 29366 sgd_solver.cpp:105] Iteration 76700, lr = 0.001
I0616 14:51:36.024739 29366 solver.cpp:218] Iteration 76750 (0.864808 iter/s, 57.8163s/50 iters), loss = 0.00513565
I0616 14:51:36.024854 29366 solver.cpp:237]     Train net output #0: loss = 0.0051357 (* 1 = 0.0051357 loss)
I0616 14:51:36.024878 29366 sgd_solver.cpp:105] Iteration 76750, lr = 0.001
I0616 14:52:33.834722 29366 solver.cpp:218] Iteration 76800 (0.864913 iter/s, 57.8093s/50 iters), loss = 0.00547773
I0616 14:52:33.834852 29366 solver.cpp:237]     Train net output #0: loss = 0.00547778 (* 1 = 0.00547778 loss)
I0616 14:52:33.834877 29366 sgd_solver.cpp:105] Iteration 76800, lr = 0.001
I0616 14:53:31.595810 29366 solver.cpp:218] Iteration 76850 (0.865645 iter/s, 57.7604s/50 iters), loss = 0.00687163
I0616 14:53:31.595940 29366 solver.cpp:237]     Train net output #0: loss = 0.00687168 (* 1 = 0.00687168 loss)
I0616 14:53:31.595963 29366 sgd_solver.cpp:105] Iteration 76850, lr = 0.001
I0616 14:54:29.396018 29366 solver.cpp:218] Iteration 76900 (0.86506 iter/s, 57.7995s/50 iters), loss = 0.00675807
I0616 14:54:29.396162 29366 solver.cpp:237]     Train net output #0: loss = 0.00675813 (* 1 = 0.00675813 loss)
I0616 14:54:29.396184 29366 sgd_solver.cpp:105] Iteration 76900, lr = 0.001
I0616 14:55:27.148217 29366 solver.cpp:218] Iteration 76950 (0.865779 iter/s, 57.7515s/50 iters), loss = 0.00786287
I0616 14:55:27.148334 29366 solver.cpp:237]     Train net output #0: loss = 0.00786293 (* 1 = 0.00786293 loss)
I0616 14:55:27.148355 29366 sgd_solver.cpp:105] Iteration 76950, lr = 0.001
I0616 14:56:24.890825 29366 solver.cpp:218] Iteration 77000 (0.865922 iter/s, 57.7419s/50 iters), loss = 0.00412741
I0616 14:56:24.890955 29366 solver.cpp:237]     Train net output #0: loss = 0.00412747 (* 1 = 0.00412747 loss)
I0616 14:56:24.890978 29366 sgd_solver.cpp:105] Iteration 77000, lr = 0.001
I0616 14:57:22.646657 29366 solver.cpp:218] Iteration 77050 (0.865724 iter/s, 57.7551s/50 iters), loss = 0.00698953
I0616 14:57:22.646788 29366 solver.cpp:237]     Train net output #0: loss = 0.00698958 (* 1 = 0.00698958 loss)
I0616 14:57:22.646811 29366 sgd_solver.cpp:105] Iteration 77050, lr = 0.001
I0616 14:58:20.399415 29366 solver.cpp:218] Iteration 77100 (0.86577 iter/s, 57.752s/50 iters), loss = 0.00517771
I0616 14:58:20.399523 29366 solver.cpp:237]     Train net output #0: loss = 0.00517776 (* 1 = 0.00517776 loss)
I0616 14:58:20.399547 29366 sgd_solver.cpp:105] Iteration 77100, lr = 0.001
I0616 14:59:18.159098 29366 solver.cpp:218] Iteration 77150 (0.865666 iter/s, 57.759s/50 iters), loss = 0.00838222
I0616 14:59:18.159243 29366 solver.cpp:237]     Train net output #0: loss = 0.00838228 (* 1 = 0.00838228 loss)
I0616 14:59:18.159267 29366 sgd_solver.cpp:105] Iteration 77150, lr = 0.001
I0616 15:00:15.999579 29366 solver.cpp:218] Iteration 77200 (0.864458 iter/s, 57.8397s/50 iters), loss = 0.00620363
I0616 15:00:15.999743 29366 solver.cpp:237]     Train net output #0: loss = 0.00620368 (* 1 = 0.00620368 loss)
I0616 15:00:15.999766 29366 sgd_solver.cpp:105] Iteration 77200, lr = 0.001
I0616 15:01:13.786312 29366 solver.cpp:218] Iteration 77250 (0.865263 iter/s, 57.7859s/50 iters), loss = 0.00668129
I0616 15:01:13.786453 29366 solver.cpp:237]     Train net output #0: loss = 0.00668135 (* 1 = 0.00668135 loss)
I0616 15:01:13.786483 29366 sgd_solver.cpp:105] Iteration 77250, lr = 0.001
I0616 15:02:11.622901 29366 solver.cpp:218] Iteration 77300 (0.864516 iter/s, 57.8358s/50 iters), loss = 0.00590436
I0616 15:02:11.623067 29366 solver.cpp:237]     Train net output #0: loss = 0.00590441 (* 1 = 0.00590441 loss)
I0616 15:02:11.623090 29366 sgd_solver.cpp:105] Iteration 77300, lr = 0.001
I0616 15:03:09.405499 29366 solver.cpp:218] Iteration 77350 (0.865324 iter/s, 57.7818s/50 iters), loss = 0.00624312
I0616 15:03:09.405720 29366 solver.cpp:237]     Train net output #0: loss = 0.00624317 (* 1 = 0.00624317 loss)
I0616 15:03:09.405745 29366 sgd_solver.cpp:105] Iteration 77350, lr = 0.001
I0616 15:04:07.172266 29366 solver.cpp:218] Iteration 77400 (0.865562 iter/s, 57.766s/50 iters), loss = 0.00605792
I0616 15:04:07.172412 29366 solver.cpp:237]     Train net output #0: loss = 0.00605798 (* 1 = 0.00605798 loss)
I0616 15:04:07.172436 29366 sgd_solver.cpp:105] Iteration 77400, lr = 0.001
I0616 15:05:05.013795 29366 solver.cpp:218] Iteration 77450 (0.864442 iter/s, 57.8408s/50 iters), loss = 0.00411025
I0616 15:05:05.013938 29366 solver.cpp:237]     Train net output #0: loss = 0.00411031 (* 1 = 0.00411031 loss)
I0616 15:05:05.013963 29366 sgd_solver.cpp:105] Iteration 77450, lr = 0.001
I0616 15:06:02.782199 29366 solver.cpp:218] Iteration 77500 (0.865536 iter/s, 57.7677s/50 iters), loss = 0.0049473
I0616 15:06:02.782335 29366 solver.cpp:237]     Train net output #0: loss = 0.00494736 (* 1 = 0.00494736 loss)
I0616 15:06:02.782358 29366 sgd_solver.cpp:105] Iteration 77500, lr = 0.001
I0616 15:07:00.556349 29366 solver.cpp:218] Iteration 77550 (0.86545 iter/s, 57.7734s/50 iters), loss = 0.00834191
I0616 15:07:00.556485 29366 solver.cpp:237]     Train net output #0: loss = 0.00834196 (* 1 = 0.00834196 loss)
I0616 15:07:00.556509 29366 sgd_solver.cpp:105] Iteration 77550, lr = 0.001
I0616 15:07:58.389411 29366 solver.cpp:218] Iteration 77600 (0.864568 iter/s, 57.8323s/50 iters), loss = 0.00396602
I0616 15:07:58.389570 29366 solver.cpp:237]     Train net output #0: loss = 0.00396608 (* 1 = 0.00396608 loss)
I0616 15:07:58.389595 29366 sgd_solver.cpp:105] Iteration 77600, lr = 0.001
I0616 15:08:56.269870 29366 solver.cpp:218] Iteration 77650 (0.863861 iter/s, 57.8797s/50 iters), loss = 0.00628536
I0616 15:08:56.270068 29366 solver.cpp:237]     Train net output #0: loss = 0.00628541 (* 1 = 0.00628541 loss)
I0616 15:08:56.270092 29366 sgd_solver.cpp:105] Iteration 77650, lr = 0.001
I0616 15:09:54.065610 29366 solver.cpp:218] Iteration 77700 (0.865127 iter/s, 57.795s/50 iters), loss = 0.00769239
I0616 15:09:54.065788 29366 solver.cpp:237]     Train net output #0: loss = 0.00769245 (* 1 = 0.00769245 loss)
I0616 15:09:54.065812 29366 sgd_solver.cpp:105] Iteration 77700, lr = 0.001
I0616 15:10:51.945770 29366 solver.cpp:218] Iteration 77750 (0.863865 iter/s, 57.8794s/50 iters), loss = 0.00825048
I0616 15:10:51.945986 29366 solver.cpp:237]     Train net output #0: loss = 0.00825054 (* 1 = 0.00825054 loss)
I0616 15:10:51.946010 29366 sgd_solver.cpp:105] Iteration 77750, lr = 0.001
I0616 15:11:49.888466 29366 solver.cpp:218] Iteration 77800 (0.862934 iter/s, 57.9419s/50 iters), loss = 0.00410283
I0616 15:11:49.888633 29366 solver.cpp:237]     Train net output #0: loss = 0.00410289 (* 1 = 0.00410289 loss)
I0616 15:11:49.888658 29366 sgd_solver.cpp:105] Iteration 77800, lr = 0.001
I0616 15:12:47.655791 29366 solver.cpp:218] Iteration 77850 (0.865553 iter/s, 57.7666s/50 iters), loss = 0.0106939
I0616 15:12:47.655941 29366 solver.cpp:237]     Train net output #0: loss = 0.010694 (* 1 = 0.010694 loss)
I0616 15:12:47.655964 29366 sgd_solver.cpp:105] Iteration 77850, lr = 0.001
I0616 15:13:45.436406 29366 solver.cpp:218] Iteration 77900 (0.865353 iter/s, 57.7799s/50 iters), loss = 0.00682902
I0616 15:13:45.436671 29366 solver.cpp:237]     Train net output #0: loss = 0.00682908 (* 1 = 0.00682908 loss)
I0616 15:13:45.436692 29366 sgd_solver.cpp:105] Iteration 77900, lr = 0.001
I0616 15:14:43.220335 29366 solver.cpp:218] Iteration 77950 (0.865305 iter/s, 57.7831s/50 iters), loss = 0.00399227
I0616 15:14:43.220535 29366 solver.cpp:237]     Train net output #0: loss = 0.00399232 (* 1 = 0.00399232 loss)
I0616 15:14:43.220559 29366 sgd_solver.cpp:105] Iteration 77950, lr = 0.001
I0616 15:15:41.033156 29366 solver.cpp:218] Iteration 78000 (0.864872 iter/s, 57.812s/50 iters), loss = 0.00713129
I0616 15:15:41.033326 29366 solver.cpp:237]     Train net output #0: loss = 0.00713135 (* 1 = 0.00713135 loss)
I0616 15:15:41.033371 29366 sgd_solver.cpp:105] Iteration 78000, lr = 0.001
I0616 15:16:38.819301 29366 solver.cpp:218] Iteration 78050 (0.865271 iter/s, 57.7854s/50 iters), loss = 0.00866149
I0616 15:16:38.819480 29366 solver.cpp:237]     Train net output #0: loss = 0.00866154 (* 1 = 0.00866154 loss)
I0616 15:16:38.819504 29366 sgd_solver.cpp:105] Iteration 78050, lr = 0.001
I0616 15:17:36.725318 29366 solver.cpp:218] Iteration 78100 (0.86348 iter/s, 57.9052s/50 iters), loss = 0.00449405
I0616 15:17:36.725491 29366 solver.cpp:237]     Train net output #0: loss = 0.00449411 (* 1 = 0.00449411 loss)
I0616 15:17:36.725522 29366 sgd_solver.cpp:105] Iteration 78100, lr = 0.001
I0616 15:18:34.521317 29366 solver.cpp:218] Iteration 78150 (0.865124 iter/s, 57.7952s/50 iters), loss = 0.00439696
I0616 15:18:34.521493 29366 solver.cpp:237]     Train net output #0: loss = 0.00439701 (* 1 = 0.00439701 loss)
I0616 15:18:34.521529 29366 sgd_solver.cpp:105] Iteration 78150, lr = 0.001
I0616 15:19:32.283658 29366 solver.cpp:218] Iteration 78200 (0.865628 iter/s, 57.7615s/50 iters), loss = 0.00671368
I0616 15:19:32.283831 29366 solver.cpp:237]     Train net output #0: loss = 0.00671373 (* 1 = 0.00671373 loss)
I0616 15:19:32.283864 29366 sgd_solver.cpp:105] Iteration 78200, lr = 0.001
I0616 15:20:30.080492 29366 solver.cpp:218] Iteration 78250 (0.865111 iter/s, 57.7961s/50 iters), loss = 0.00465121
I0616 15:20:30.080655 29366 solver.cpp:237]     Train net output #0: loss = 0.00465126 (* 1 = 0.00465126 loss)
I0616 15:20:30.080679 29366 sgd_solver.cpp:105] Iteration 78250, lr = 0.001
I0616 15:21:27.826921 29366 solver.cpp:218] Iteration 78300 (0.865866 iter/s, 57.7457s/50 iters), loss = 0.00404357
I0616 15:21:27.827107 29366 solver.cpp:237]     Train net output #0: loss = 0.00404363 (* 1 = 0.00404363 loss)
I0616 15:21:27.827133 29366 sgd_solver.cpp:105] Iteration 78300, lr = 0.001
I0616 15:22:25.579886 29366 solver.cpp:218] Iteration 78350 (0.865768 iter/s, 57.7522s/50 iters), loss = 0.00670967
I0616 15:22:25.580029 29366 solver.cpp:237]     Train net output #0: loss = 0.00670972 (* 1 = 0.00670972 loss)
I0616 15:22:25.580054 29366 sgd_solver.cpp:105] Iteration 78350, lr = 0.001
I0616 15:23:23.330368 29366 solver.cpp:218] Iteration 78400 (0.865804 iter/s, 57.7498s/50 iters), loss = 0.00557253
I0616 15:23:23.330489 29366 solver.cpp:237]     Train net output #0: loss = 0.00557259 (* 1 = 0.00557259 loss)
I0616 15:23:23.330518 29366 sgd_solver.cpp:105] Iteration 78400, lr = 0.001
I0616 15:24:21.060506 29366 solver.cpp:218] Iteration 78450 (0.86611 iter/s, 57.7294s/50 iters), loss = 0.00479409
I0616 15:24:21.060696 29366 solver.cpp:237]     Train net output #0: loss = 0.00479414 (* 1 = 0.00479414 loss)
I0616 15:24:21.060729 29366 sgd_solver.cpp:105] Iteration 78450, lr = 0.001
I0616 15:25:18.818034 29366 solver.cpp:218] Iteration 78500 (0.865699 iter/s, 57.7568s/50 iters), loss = 0.00496043
I0616 15:25:18.818189 29366 solver.cpp:237]     Train net output #0: loss = 0.00496048 (* 1 = 0.00496048 loss)
I0616 15:25:18.818215 29366 sgd_solver.cpp:105] Iteration 78500, lr = 0.001
I0616 15:26:16.554282 29366 solver.cpp:218] Iteration 78550 (0.866018 iter/s, 57.7355s/50 iters), loss = 0.00530443
I0616 15:26:16.554420 29366 solver.cpp:237]     Train net output #0: loss = 0.00530449 (* 1 = 0.00530449 loss)
I0616 15:26:16.554445 29366 sgd_solver.cpp:105] Iteration 78550, lr = 0.001
I0616 15:27:14.273319 29366 solver.cpp:218] Iteration 78600 (0.866276 iter/s, 57.7183s/50 iters), loss = 0.00619397
I0616 15:27:14.273437 29366 solver.cpp:237]     Train net output #0: loss = 0.00619402 (* 1 = 0.00619402 loss)
I0616 15:27:14.273459 29366 sgd_solver.cpp:105] Iteration 78600, lr = 0.001
I0616 15:28:11.995708 29366 solver.cpp:218] Iteration 78650 (0.866225 iter/s, 57.7217s/50 iters), loss = 0.00772118
I0616 15:28:11.995843 29366 solver.cpp:237]     Train net output #0: loss = 0.00772123 (* 1 = 0.00772123 loss)
I0616 15:28:11.995867 29366 sgd_solver.cpp:105] Iteration 78650, lr = 0.001
I0616 15:29:09.747115 29366 solver.cpp:218] Iteration 78700 (0.86579 iter/s, 57.7507s/50 iters), loss = 0.00532999
I0616 15:29:09.747347 29366 solver.cpp:237]     Train net output #0: loss = 0.00533004 (* 1 = 0.00533004 loss)
I0616 15:29:09.747371 29366 sgd_solver.cpp:105] Iteration 78700, lr = 0.001
I0616 15:30:07.535109 29366 solver.cpp:218] Iteration 78750 (0.865243 iter/s, 57.7872s/50 iters), loss = 0.00485017
I0616 15:30:07.535326 29366 solver.cpp:237]     Train net output #0: loss = 0.00485023 (* 1 = 0.00485023 loss)
I0616 15:30:07.535352 29366 sgd_solver.cpp:105] Iteration 78750, lr = 0.001
I0616 15:31:05.276728 29366 solver.cpp:218] Iteration 78800 (0.865937 iter/s, 57.7409s/50 iters), loss = 0.00411495
I0616 15:31:05.276885 29366 solver.cpp:237]     Train net output #0: loss = 0.004115 (* 1 = 0.004115 loss)
I0616 15:31:05.276911 29366 sgd_solver.cpp:105] Iteration 78800, lr = 0.001
I0616 15:32:03.011483 29366 solver.cpp:218] Iteration 78850 (0.866039 iter/s, 57.7341s/50 iters), loss = 0.0088384
I0616 15:32:03.011631 29366 solver.cpp:237]     Train net output #0: loss = 0.00883846 (* 1 = 0.00883846 loss)
I0616 15:32:03.011656 29366 sgd_solver.cpp:105] Iteration 78850, lr = 0.001
I0616 15:33:00.752426 29366 solver.cpp:218] Iteration 78900 (0.865946 iter/s, 57.7403s/50 iters), loss = 0.00763979
I0616 15:33:00.752583 29366 solver.cpp:237]     Train net output #0: loss = 0.00763984 (* 1 = 0.00763984 loss)
I0616 15:33:00.752610 29366 sgd_solver.cpp:105] Iteration 78900, lr = 0.001
I0616 15:33:58.479635 29366 solver.cpp:218] Iteration 78950 (0.866153 iter/s, 57.7265s/50 iters), loss = 0.00516282
I0616 15:33:58.479780 29366 solver.cpp:237]     Train net output #0: loss = 0.00516287 (* 1 = 0.00516287 loss)
I0616 15:33:58.479809 29366 sgd_solver.cpp:105] Iteration 78950, lr = 0.001
I0616 15:34:56.203794 29366 solver.cpp:218] Iteration 79000 (0.866198 iter/s, 57.7235s/50 iters), loss = 0.00572206
I0616 15:34:56.203935 29366 solver.cpp:237]     Train net output #0: loss = 0.00572211 (* 1 = 0.00572211 loss)
I0616 15:34:56.203965 29366 sgd_solver.cpp:105] Iteration 79000, lr = 0.001
I0616 15:35:53.935619 29366 solver.cpp:218] Iteration 79050 (0.866083 iter/s, 57.7312s/50 iters), loss = 0.00776365
I0616 15:35:53.935775 29366 solver.cpp:237]     Train net output #0: loss = 0.0077637 (* 1 = 0.0077637 loss)
I0616 15:35:53.935797 29366 sgd_solver.cpp:105] Iteration 79050, lr = 0.001
I0616 15:36:51.654584 29366 solver.cpp:218] Iteration 79100 (0.866276 iter/s, 57.7183s/50 iters), loss = 0.00553429
I0616 15:36:51.654721 29366 solver.cpp:237]     Train net output #0: loss = 0.00553434 (* 1 = 0.00553434 loss)
I0616 15:36:51.654747 29366 sgd_solver.cpp:105] Iteration 79100, lr = 0.001
I0616 15:37:49.376165 29366 solver.cpp:218] Iteration 79150 (0.866237 iter/s, 57.721s/50 iters), loss = 0.00836785
I0616 15:37:49.376297 29366 solver.cpp:237]     Train net output #0: loss = 0.00836791 (* 1 = 0.00836791 loss)
I0616 15:37:49.376322 29366 sgd_solver.cpp:105] Iteration 79150, lr = 0.001
I0616 15:38:47.093433 29366 solver.cpp:218] Iteration 79200 (0.866302 iter/s, 57.7166s/50 iters), loss = 0.00466967
I0616 15:38:47.093591 29366 solver.cpp:237]     Train net output #0: loss = 0.00466972 (* 1 = 0.00466972 loss)
I0616 15:38:47.093622 29366 sgd_solver.cpp:105] Iteration 79200, lr = 0.001
I0616 15:39:44.816458 29366 solver.cpp:218] Iteration 79250 (0.866215 iter/s, 57.7224s/50 iters), loss = 0.0060857
I0616 15:39:44.816587 29366 solver.cpp:237]     Train net output #0: loss = 0.00608575 (* 1 = 0.00608575 loss)
I0616 15:39:44.816612 29366 sgd_solver.cpp:105] Iteration 79250, lr = 0.001
I0616 15:40:42.540201 29366 solver.cpp:218] Iteration 79300 (0.866204 iter/s, 57.7231s/50 iters), loss = 0.00706665
I0616 15:40:42.540343 29366 solver.cpp:237]     Train net output #0: loss = 0.0070667 (* 1 = 0.0070667 loss)
I0616 15:40:42.540365 29366 sgd_solver.cpp:105] Iteration 79300, lr = 0.001
I0616 15:41:40.256783 29366 solver.cpp:218] Iteration 79350 (0.866312 iter/s, 57.7159s/50 iters), loss = 0.00819106
I0616 15:41:40.256958 29366 solver.cpp:237]     Train net output #0: loss = 0.00819111 (* 1 = 0.00819111 loss)
I0616 15:41:40.256992 29366 sgd_solver.cpp:105] Iteration 79350, lr = 0.001
I0616 15:42:37.974686 29366 solver.cpp:218] Iteration 79400 (0.866292 iter/s, 57.7172s/50 iters), loss = 0.0048156
I0616 15:42:37.974822 29366 solver.cpp:237]     Train net output #0: loss = 0.00481566 (* 1 = 0.00481566 loss)
I0616 15:42:37.974845 29366 sgd_solver.cpp:105] Iteration 79400, lr = 0.001
I0616 15:43:35.755497 29366 solver.cpp:218] Iteration 79450 (0.865349 iter/s, 57.7802s/50 iters), loss = 0.00590076
I0616 15:43:35.755640 29366 solver.cpp:237]     Train net output #0: loss = 0.00590082 (* 1 = 0.00590082 loss)
I0616 15:43:35.755663 29366 sgd_solver.cpp:105] Iteration 79450, lr = 0.001
I0616 15:44:33.478932 29366 solver.cpp:218] Iteration 79500 (0.866209 iter/s, 57.7228s/50 iters), loss = 0.00456906
I0616 15:44:33.479086 29366 solver.cpp:237]     Train net output #0: loss = 0.00456911 (* 1 = 0.00456911 loss)
I0616 15:44:33.479112 29366 sgd_solver.cpp:105] Iteration 79500, lr = 0.001
I0616 15:45:31.213759 29366 solver.cpp:218] Iteration 79550 (0.866038 iter/s, 57.7342s/50 iters), loss = 0.00627255
I0616 15:45:31.213882 29366 solver.cpp:237]     Train net output #0: loss = 0.0062726 (* 1 = 0.0062726 loss)
I0616 15:45:31.213907 29366 sgd_solver.cpp:105] Iteration 79550, lr = 0.001
I0616 15:46:28.944612 29366 solver.cpp:218] Iteration 79600 (0.866098 iter/s, 57.7302s/50 iters), loss = 0.00631809
I0616 15:46:28.944735 29366 solver.cpp:237]     Train net output #0: loss = 0.00631815 (* 1 = 0.00631815 loss)
I0616 15:46:28.944758 29366 sgd_solver.cpp:105] Iteration 79600, lr = 0.001
I0616 15:47:26.672070 29366 solver.cpp:218] Iteration 79650 (0.866148 iter/s, 57.7268s/50 iters), loss = 0.00597518
I0616 15:47:26.672216 29366 solver.cpp:237]     Train net output #0: loss = 0.00597523 (* 1 = 0.00597523 loss)
I0616 15:47:26.672240 29366 sgd_solver.cpp:105] Iteration 79650, lr = 0.001
I0616 15:48:24.445286 29366 solver.cpp:218] Iteration 79700 (0.865463 iter/s, 57.7725s/50 iters), loss = 0.00767853
I0616 15:48:24.445469 29366 solver.cpp:237]     Train net output #0: loss = 0.00767859 (* 1 = 0.00767859 loss)
I0616 15:48:24.445494 29366 sgd_solver.cpp:105] Iteration 79700, lr = 0.001
I0616 15:49:22.294338 29366 solver.cpp:218] Iteration 79750 (0.864329 iter/s, 57.8483s/50 iters), loss = 0.00518706
I0616 15:49:22.294564 29366 solver.cpp:237]     Train net output #0: loss = 0.00518711 (* 1 = 0.00518711 loss)
I0616 15:49:22.294590 29366 sgd_solver.cpp:105] Iteration 79750, lr = 0.001
I0616 15:50:20.068987 29366 solver.cpp:218] Iteration 79800 (0.865443 iter/s, 57.7739s/50 iters), loss = 0.00476442
I0616 15:50:20.069161 29366 solver.cpp:237]     Train net output #0: loss = 0.00476447 (* 1 = 0.00476447 loss)
I0616 15:50:20.069186 29366 sgd_solver.cpp:105] Iteration 79800, lr = 0.001
I0616 15:51:18.302301 29366 solver.cpp:218] Iteration 79850 (0.858626 iter/s, 58.2326s/50 iters), loss = 0.0048305
I0616 15:51:18.306555 29366 solver.cpp:237]     Train net output #0: loss = 0.00483055 (* 1 = 0.00483055 loss)
I0616 15:51:18.306591 29366 sgd_solver.cpp:105] Iteration 79850, lr = 0.001
I0616 15:52:16.601861 29366 solver.cpp:218] Iteration 79900 (0.85771 iter/s, 58.2948s/50 iters), loss = 0.00494
I0616 15:52:16.611662 29366 solver.cpp:237]     Train net output #0: loss = 0.00494005 (* 1 = 0.00494005 loss)
I0616 15:52:16.611702 29366 sgd_solver.cpp:105] Iteration 79900, lr = 0.001
I0616 15:53:14.957041 29366 solver.cpp:218] Iteration 79950 (0.856973 iter/s, 58.3449s/50 iters), loss = 0.00681434
I0616 15:53:14.964903 29366 solver.cpp:237]     Train net output #0: loss = 0.00681439 (* 1 = 0.00681439 loss)
I0616 15:53:14.964943 29366 sgd_solver.cpp:105] Iteration 79950, lr = 0.001
I0616 15:54:11.963071 29366 solver.cpp:447] Snapshotting to binary proto file mobilenet/mobile_2_iter_80000.caffemodel
I0616 15:54:12.041255 29366 sgd_solver.cpp:273] Snapshotting solver state to binary proto file mobilenet/mobile_2_iter_80000.solverstate
I0616 15:54:13.222391 29366 solver.cpp:218] Iteration 80000 (0.858266 iter/s, 58.257s/50 iters), loss = 0.00725439
I0616 15:54:13.222530 29366 solver.cpp:237]     Train net output #0: loss = 0.00725444 (* 1 = 0.00725444 loss)
I0616 15:54:13.222555 29366 sgd_solver.cpp:105] Iteration 80000, lr = 0.001
I0616 15:55:10.982816 29366 solver.cpp:218] Iteration 80050 (0.865655 iter/s, 57.7598s/50 iters), loss = 0.00555567
I0616 15:55:10.983036 29366 solver.cpp:237]     Train net output #0: loss = 0.00555572 (* 1 = 0.00555572 loss)
I0616 15:55:10.983062 29366 sgd_solver.cpp:105] Iteration 80050, lr = 0.001
I0616 15:56:08.814049 29366 solver.cpp:218] Iteration 80100 (0.864596 iter/s, 57.8305s/50 iters), loss = 0.00617666
I0616 15:56:08.814232 29366 solver.cpp:237]     Train net output #0: loss = 0.00617671 (* 1 = 0.00617671 loss)
I0616 15:56:08.814257 29366 sgd_solver.cpp:105] Iteration 80100, lr = 0.001
I0616 15:57:06.601321 29366 solver.cpp:218] Iteration 80150 (0.865253 iter/s, 57.7866s/50 iters), loss = 0.00661806
I0616 15:57:06.601624 29366 solver.cpp:237]     Train net output #0: loss = 0.00661811 (* 1 = 0.00661811 loss)
I0616 15:57:06.601647 29366 sgd_solver.cpp:105] Iteration 80150, lr = 0.001
I0616 15:58:04.365649 29366 solver.cpp:218] Iteration 80200 (0.865598 iter/s, 57.7635s/50 iters), loss = 0.0077704
I0616 15:58:04.365815 29366 solver.cpp:237]     Train net output #0: loss = 0.00777045 (* 1 = 0.00777045 loss)
I0616 15:58:04.365839 29366 sgd_solver.cpp:105] Iteration 80200, lr = 0.001
I0616 15:59:02.187911 29366 solver.cpp:218] Iteration 80250 (0.864729 iter/s, 57.8216s/50 iters), loss = 0.00711946
I0616 15:59:02.188060 29366 solver.cpp:237]     Train net output #0: loss = 0.00711952 (* 1 = 0.00711952 loss)
I0616 15:59:02.188083 29366 sgd_solver.cpp:105] Iteration 80250, lr = 0.001
I0616 16:00:00.027307 29366 solver.cpp:218] Iteration 80300 (0.864473 iter/s, 57.8387s/50 iters), loss = 0.00502568
I0616 16:00:00.027634 29366 solver.cpp:237]     Train net output #0: loss = 0.00502573 (* 1 = 0.00502573 loss)
I0616 16:00:00.027660 29366 sgd_solver.cpp:105] Iteration 80300, lr = 0.001
I0616 16:00:57.807409 29366 solver.cpp:218] Iteration 80350 (0.865363 iter/s, 57.7792s/50 iters), loss = 0.00508304
I0616 16:00:57.807590 29366 solver.cpp:237]     Train net output #0: loss = 0.0050831 (* 1 = 0.0050831 loss)
I0616 16:00:57.807621 29366 sgd_solver.cpp:105] Iteration 80350, lr = 0.001
I0616 16:01:55.611747 29366 solver.cpp:218] Iteration 80400 (0.864997 iter/s, 57.8036s/50 iters), loss = 0.00436623
I0616 16:01:55.611932 29366 solver.cpp:237]     Train net output #0: loss = 0.00436629 (* 1 = 0.00436629 loss)
I0616 16:01:55.611956 29366 sgd_solver.cpp:105] Iteration 80400, lr = 0.001
I0616 16:02:53.378437 29366 solver.cpp:218] Iteration 80450 (0.865561 iter/s, 57.766s/50 iters), loss = 0.00759067
I0616 16:02:53.378684 29366 solver.cpp:237]     Train net output #0: loss = 0.00759072 (* 1 = 0.00759072 loss)
I0616 16:02:53.378708 29366 sgd_solver.cpp:105] Iteration 80450, lr = 0.001
I0616 16:03:51.151137 29366 solver.cpp:218] Iteration 80500 (0.865472 iter/s, 57.7719s/50 iters), loss = 0.00501199
I0616 16:03:51.151363 29366 solver.cpp:237]     Train net output #0: loss = 0.00501204 (* 1 = 0.00501204 loss)
I0616 16:03:51.151387 29366 sgd_solver.cpp:105] Iteration 80500, lr = 0.001
I0616 16:04:48.923923 29366 solver.cpp:218] Iteration 80550 (0.865471 iter/s, 57.772s/50 iters), loss = 0.00594879
I0616 16:04:48.924114 29366 solver.cpp:237]     Train net output #0: loss = 0.00594885 (* 1 = 0.00594885 loss)
I0616 16:04:48.924139 29366 sgd_solver.cpp:105] Iteration 80550, lr = 0.001
I0616 16:05:46.679471 29366 solver.cpp:218] Iteration 80600 (0.865728 iter/s, 57.7548s/50 iters), loss = 0.0063192
I0616 16:05:46.679636 29366 solver.cpp:237]     Train net output #0: loss = 0.00631925 (* 1 = 0.00631925 loss)
I0616 16:05:46.679664 29366 sgd_solver.cpp:105] Iteration 80600, lr = 0.001
I0616 16:06:44.421303 29366 solver.cpp:218] Iteration 80650 (0.865934 iter/s, 57.7411s/50 iters), loss = 0.00690986
I0616 16:06:44.421506 29366 solver.cpp:237]     Train net output #0: loss = 0.00690991 (* 1 = 0.00690991 loss)
I0616 16:06:44.421542 29366 sgd_solver.cpp:105] Iteration 80650, lr = 0.001
I0616 16:07:42.182374 29366 solver.cpp:218] Iteration 80700 (0.865646 iter/s, 57.7604s/50 iters), loss = 0.00480633
I0616 16:07:42.182510 29366 solver.cpp:237]     Train net output #0: loss = 0.00480638 (* 1 = 0.00480638 loss)
I0616 16:07:42.182541 29366 sgd_solver.cpp:105] Iteration 80700, lr = 0.001
I0616 16:08:39.922454 29366 solver.cpp:218] Iteration 80750 (0.86596 iter/s, 57.7394s/50 iters), loss = 0.00510049
I0616 16:08:39.922593 29366 solver.cpp:237]     Train net output #0: loss = 0.00510055 (* 1 = 0.00510055 loss)
I0616 16:08:39.922618 29366 sgd_solver.cpp:105] Iteration 80750, lr = 0.001
I0616 16:09:37.655370 29366 solver.cpp:218] Iteration 80800 (0.866067 iter/s, 57.7323s/50 iters), loss = 0.00588126
I0616 16:09:37.655549 29366 solver.cpp:237]     Train net output #0: loss = 0.00588132 (* 1 = 0.00588132 loss)
I0616 16:09:37.655573 29366 sgd_solver.cpp:105] Iteration 80800, lr = 0.001
I0616 16:10:35.400480 29366 solver.cpp:218] Iteration 80850 (0.865885 iter/s, 57.7444s/50 iters), loss = 0.00848024
I0616 16:10:35.400641 29366 solver.cpp:237]     Train net output #0: loss = 0.00848029 (* 1 = 0.00848029 loss)
I0616 16:10:35.400665 29366 sgd_solver.cpp:105] Iteration 80850, lr = 0.001
I0616 16:11:33.144991 29366 solver.cpp:218] Iteration 80900 (0.865893 iter/s, 57.7438s/50 iters), loss = 0.00501814
I0616 16:11:33.145123 29366 solver.cpp:237]     Train net output #0: loss = 0.0050182 (* 1 = 0.0050182 loss)
I0616 16:11:33.145146 29366 sgd_solver.cpp:105] Iteration 80900, lr = 0.001
I0616 16:12:30.880491 29366 solver.cpp:218] Iteration 80950 (0.866028 iter/s, 57.7348s/50 iters), loss = 0.00598962
I0616 16:12:30.880638 29366 solver.cpp:237]     Train net output #0: loss = 0.00598967 (* 1 = 0.00598967 loss)
I0616 16:12:30.880661 29366 sgd_solver.cpp:105] Iteration 80950, lr = 0.001
I0616 16:13:28.614694 29366 solver.cpp:218] Iteration 81000 (0.866048 iter/s, 57.7335s/50 iters), loss = 0.00917902
I0616 16:13:28.614843 29366 solver.cpp:237]     Train net output #0: loss = 0.00917908 (* 1 = 0.00917908 loss)
I0616 16:13:28.614867 29366 sgd_solver.cpp:105] Iteration 81000, lr = 0.001
I0616 16:14:26.356292 29366 solver.cpp:218] Iteration 81050 (0.865937 iter/s, 57.7409s/50 iters), loss = 0.00526035
I0616 16:14:26.356426 29366 solver.cpp:237]     Train net output #0: loss = 0.0052604 (* 1 = 0.0052604 loss)
I0616 16:14:26.356449 29366 sgd_solver.cpp:105] Iteration 81050, lr = 0.001
I0616 16:15:24.090380 29366 solver.cpp:218] Iteration 81100 (0.866049 iter/s, 57.7334s/50 iters), loss = 0.00690627
I0616 16:15:24.090528 29366 solver.cpp:237]     Train net output #0: loss = 0.00690632 (* 1 = 0.00690632 loss)
I0616 16:15:24.090553 29366 sgd_solver.cpp:105] Iteration 81100, lr = 0.001
I0616 16:16:21.829094 29366 solver.cpp:218] Iteration 81150 (0.86598 iter/s, 57.7381s/50 iters), loss = 0.0047611
I0616 16:16:21.829228 29366 solver.cpp:237]     Train net output #0: loss = 0.00476115 (* 1 = 0.00476115 loss)
I0616 16:16:21.829252 29366 sgd_solver.cpp:105] Iteration 81150, lr = 0.001
I0616 16:17:19.570334 29366 solver.cpp:218] Iteration 81200 (0.865942 iter/s, 57.7406s/50 iters), loss = 0.00553952
I0616 16:17:19.570482 29366 solver.cpp:237]     Train net output #0: loss = 0.00553957 (* 1 = 0.00553957 loss)
I0616 16:17:19.570523 29366 sgd_solver.cpp:105] Iteration 81200, lr = 0.001
I0616 16:18:17.314142 29366 solver.cpp:218] Iteration 81250 (0.865904 iter/s, 57.7431s/50 iters), loss = 0.0057712
I0616 16:18:17.314282 29366 solver.cpp:237]     Train net output #0: loss = 0.00577126 (* 1 = 0.00577126 loss)
I0616 16:18:17.314304 29366 sgd_solver.cpp:105] Iteration 81250, lr = 0.001
I0616 16:19:15.054150 29366 solver.cpp:218] Iteration 81300 (0.865961 iter/s, 57.7393s/50 iters), loss = 0.00510979
I0616 16:19:15.054294 29366 solver.cpp:237]     Train net output #0: loss = 0.00510985 (* 1 = 0.00510985 loss)
I0616 16:19:15.054318 29366 sgd_solver.cpp:105] Iteration 81300, lr = 0.001
I0616 16:20:12.788784 29366 solver.cpp:218] Iteration 81350 (0.866041 iter/s, 57.734s/50 iters), loss = 0.00363786
I0616 16:20:12.788964 29366 solver.cpp:237]     Train net output #0: loss = 0.00363791 (* 1 = 0.00363791 loss)
I0616 16:20:12.788997 29366 sgd_solver.cpp:105] Iteration 81350, lr = 0.001
I0616 16:21:10.559530 29366 solver.cpp:218] Iteration 81400 (0.865501 iter/s, 57.77s/50 iters), loss = 0.00696488
I0616 16:21:10.559671 29366 solver.cpp:237]     Train net output #0: loss = 0.00696493 (* 1 = 0.00696493 loss)
I0616 16:21:10.559696 29366 sgd_solver.cpp:105] Iteration 81400, lr = 0.001
I0616 16:22:08.378471 29366 solver.cpp:218] Iteration 81450 (0.864786 iter/s, 57.8177s/50 iters), loss = 0.00812335
I0616 16:22:08.378763 29366 solver.cpp:237]     Train net output #0: loss = 0.0081234 (* 1 = 0.0081234 loss)
I0616 16:22:08.378795 29366 sgd_solver.cpp:105] Iteration 81450, lr = 0.001
I0616 16:23:06.215798 29366 solver.cpp:218] Iteration 81500 (0.864507 iter/s, 57.8364s/50 iters), loss = 0.00542435
I0616 16:23:06.215978 29366 solver.cpp:237]     Train net output #0: loss = 0.0054244 (* 1 = 0.0054244 loss)
I0616 16:23:06.216003 29366 sgd_solver.cpp:105] Iteration 81500, lr = 0.001
I0616 16:24:03.958849 29366 solver.cpp:218] Iteration 81550 (0.865917 iter/s, 57.7423s/50 iters), loss = 0.00485766
I0616 16:24:03.959030 29366 solver.cpp:237]     Train net output #0: loss = 0.00485772 (* 1 = 0.00485772 loss)
I0616 16:24:03.959054 29366 sgd_solver.cpp:105] Iteration 81550, lr = 0.001
I0616 16:25:01.697620 29366 solver.cpp:218] Iteration 81600 (0.865981 iter/s, 57.738s/50 iters), loss = 0.00727823
I0616 16:25:01.698355 29366 solver.cpp:237]     Train net output #0: loss = 0.00727828 (* 1 = 0.00727828 loss)
I0616 16:25:01.698379 29366 sgd_solver.cpp:105] Iteration 81600, lr = 0.001
I0616 16:25:59.438640 29366 solver.cpp:218] Iteration 81650 (0.865955 iter/s, 57.7397s/50 iters), loss = 0.0103409
I0616 16:25:59.438863 29366 solver.cpp:237]     Train net output #0: loss = 0.010341 (* 1 = 0.010341 loss)
I0616 16:25:59.438885 29366 sgd_solver.cpp:105] Iteration 81650, lr = 0.001
I0616 16:26:57.185542 29366 solver.cpp:218] Iteration 81700 (0.865859 iter/s, 57.7461s/50 iters), loss = 0.00857763
I0616 16:26:57.185719 29366 solver.cpp:237]     Train net output #0: loss = 0.00857768 (* 1 = 0.00857768 loss)
I0616 16:26:57.185742 29366 sgd_solver.cpp:105] Iteration 81700, lr = 0.001
I0616 16:27:54.929836 29366 solver.cpp:218] Iteration 81750 (0.865898 iter/s, 57.7435s/50 iters), loss = 0.00844357
I0616 16:27:54.930007 29366 solver.cpp:237]     Train net output #0: loss = 0.00844362 (* 1 = 0.00844362 loss)
I0616 16:27:54.930032 29366 sgd_solver.cpp:105] Iteration 81750, lr = 0.001
I0616 16:28:52.673461 29366 solver.cpp:218] Iteration 81800 (0.865908 iter/s, 57.7429s/50 iters), loss = 0.0054828
I0616 16:28:52.673629 29366 solver.cpp:237]     Train net output #0: loss = 0.00548285 (* 1 = 0.00548285 loss)
I0616 16:28:52.673655 29366 sgd_solver.cpp:105] Iteration 81800, lr = 0.001
I0616 16:29:50.416757 29366 solver.cpp:218] Iteration 81850 (0.865913 iter/s, 57.7425s/50 iters), loss = 0.00697729
I0616 16:29:50.416930 29366 solver.cpp:237]     Train net output #0: loss = 0.00697734 (* 1 = 0.00697734 loss)
I0616 16:29:50.416954 29366 sgd_solver.cpp:105] Iteration 81850, lr = 0.001
I0616 16:30:48.155406 29366 solver.cpp:218] Iteration 81900 (0.865982 iter/s, 57.7379s/50 iters), loss = 0.006492
I0616 16:30:48.155560 29366 solver.cpp:237]     Train net output #0: loss = 0.00649205 (* 1 = 0.00649205 loss)
I0616 16:30:48.155586 29366 sgd_solver.cpp:105] Iteration 81900, lr = 0.001
I0616 16:31:45.897501 29366 solver.cpp:218] Iteration 81950 (0.86593 iter/s, 57.7414s/50 iters), loss = 0.00644217
I0616 16:31:45.897655 29366 solver.cpp:237]     Train net output #0: loss = 0.00644223 (* 1 = 0.00644223 loss)
I0616 16:31:45.897680 29366 sgd_solver.cpp:105] Iteration 81950, lr = 0.001
I0616 16:32:43.693239 29366 solver.cpp:218] Iteration 82000 (0.865126 iter/s, 57.795s/50 iters), loss = 0.0049455
I0616 16:32:43.693410 29366 solver.cpp:237]     Train net output #0: loss = 0.00494555 (* 1 = 0.00494555 loss)
I0616 16:32:43.693434 29366 sgd_solver.cpp:105] Iteration 82000, lr = 0.001
I0616 16:33:41.434584 29366 solver.cpp:218] Iteration 82050 (0.865942 iter/s, 57.7406s/50 iters), loss = 0.00567605
I0616 16:33:41.434870 29366 solver.cpp:237]     Train net output #0: loss = 0.00567611 (* 1 = 0.00567611 loss)
I0616 16:33:41.434895 29366 sgd_solver.cpp:105] Iteration 82050, lr = 0.001
I0616 16:34:39.187698 29366 solver.cpp:218] Iteration 82100 (0.865767 iter/s, 57.7523s/50 iters), loss = 0.00798988
I0616 16:34:39.187839 29366 solver.cpp:237]     Train net output #0: loss = 0.00798993 (* 1 = 0.00798993 loss)
I0616 16:34:39.187863 29366 sgd_solver.cpp:105] Iteration 82100, lr = 0.001
I0616 16:35:36.947795 29366 solver.cpp:218] Iteration 82150 (0.86566 iter/s, 57.7594s/50 iters), loss = 0.0047357
I0616 16:35:36.947949 29366 solver.cpp:237]     Train net output #0: loss = 0.00473575 (* 1 = 0.00473575 loss)
I0616 16:35:36.947975 29366 sgd_solver.cpp:105] Iteration 82150, lr = 0.001
I0616 16:36:34.691431 29366 solver.cpp:218] Iteration 82200 (0.865907 iter/s, 57.7429s/50 iters), loss = 0.00450324
I0616 16:36:34.691545 29366 solver.cpp:237]     Train net output #0: loss = 0.00450329 (* 1 = 0.00450329 loss)
I0616 16:36:34.691570 29366 sgd_solver.cpp:105] Iteration 82200, lr = 0.001
I0616 16:37:32.440253 29366 solver.cpp:218] Iteration 82250 (0.865829 iter/s, 57.7482s/50 iters), loss = 0.00589433
I0616 16:37:32.440393 29366 solver.cpp:237]     Train net output #0: loss = 0.00589438 (* 1 = 0.00589438 loss)
I0616 16:37:32.440417 29366 sgd_solver.cpp:105] Iteration 82250, lr = 0.001
I0616 16:38:30.173249 29366 solver.cpp:218] Iteration 82300 (0.866066 iter/s, 57.7323s/50 iters), loss = 0.00816743
I0616 16:38:30.173418 29366 solver.cpp:237]     Train net output #0: loss = 0.00816748 (* 1 = 0.00816748 loss)
I0616 16:38:30.173441 29366 sgd_solver.cpp:105] Iteration 82300, lr = 0.001
I0616 16:39:27.902837 29366 solver.cpp:218] Iteration 82350 (0.866118 iter/s, 57.7289s/50 iters), loss = 0.00818763
I0616 16:39:27.902981 29366 solver.cpp:237]     Train net output #0: loss = 0.00818768 (* 1 = 0.00818768 loss)
I0616 16:39:27.903003 29366 sgd_solver.cpp:105] Iteration 82350, lr = 0.001
I0616 16:40:25.638949 29366 solver.cpp:218] Iteration 82400 (0.86602 iter/s, 57.7354s/50 iters), loss = 0.00702651
I0616 16:40:25.639087 29366 solver.cpp:237]     Train net output #0: loss = 0.00702656 (* 1 = 0.00702656 loss)
I0616 16:40:25.639109 29366 sgd_solver.cpp:105] Iteration 82400, lr = 0.001
I0616 16:41:23.372918 29366 solver.cpp:218] Iteration 82450 (0.866052 iter/s, 57.7333s/50 iters), loss = 0.00547137
I0616 16:41:23.373057 29366 solver.cpp:237]     Train net output #0: loss = 0.00547142 (* 1 = 0.00547142 loss)
I0616 16:41:23.373080 29366 sgd_solver.cpp:105] Iteration 82450, lr = 0.001
I0616 16:42:21.114897 29366 solver.cpp:218] Iteration 82500 (0.865932 iter/s, 57.7413s/50 iters), loss = 0.00575037
I0616 16:42:21.115036 29366 solver.cpp:237]     Train net output #0: loss = 0.00575042 (* 1 = 0.00575042 loss)
I0616 16:42:21.115062 29366 sgd_solver.cpp:105] Iteration 82500, lr = 0.001
I0616 16:43:18.851680 29366 solver.cpp:218] Iteration 82550 (0.866009 iter/s, 57.7361s/50 iters), loss = 0.00644718
I0616 16:43:18.851810 29366 solver.cpp:237]     Train net output #0: loss = 0.00644723 (* 1 = 0.00644723 loss)
I0616 16:43:18.851835 29366 sgd_solver.cpp:105] Iteration 82550, lr = 0.001
I0616 16:44:16.577457 29366 solver.cpp:218] Iteration 82600 (0.866174 iter/s, 57.7251s/50 iters), loss = 0.00932484
I0616 16:44:16.577658 29366 solver.cpp:237]     Train net output #0: loss = 0.00932489 (* 1 = 0.00932489 loss)
I0616 16:44:16.577682 29366 sgd_solver.cpp:105] Iteration 82600, lr = 0.001
I0616 16:45:14.319174 29366 solver.cpp:218] Iteration 82650 (0.865936 iter/s, 57.741s/50 iters), loss = 0.00845456
I0616 16:45:14.319315 29366 solver.cpp:237]     Train net output #0: loss = 0.00845461 (* 1 = 0.00845461 loss)
I0616 16:45:14.319339 29366 sgd_solver.cpp:105] Iteration 82650, lr = 0.001
I0616 16:46:12.054430 29366 solver.cpp:218] Iteration 82700 (0.866032 iter/s, 57.7346s/50 iters), loss = 0.00483383
I0616 16:46:12.054592 29366 solver.cpp:237]     Train net output #0: loss = 0.00483388 (* 1 = 0.00483388 loss)
I0616 16:46:12.054628 29366 sgd_solver.cpp:105] Iteration 82700, lr = 0.001
I0616 16:47:09.792889 29366 solver.cpp:218] Iteration 82750 (0.865985 iter/s, 57.7377s/50 iters), loss = 0.00679703
I0616 16:47:09.793035 29366 solver.cpp:237]     Train net output #0: loss = 0.00679708 (* 1 = 0.00679708 loss)
I0616 16:47:09.793059 29366 sgd_solver.cpp:105] Iteration 82750, lr = 0.001
I0616 16:48:07.530418 29366 solver.cpp:218] Iteration 82800 (0.865998 iter/s, 57.7368s/50 iters), loss = 0.00452957
I0616 16:48:07.530597 29366 solver.cpp:237]     Train net output #0: loss = 0.00452962 (* 1 = 0.00452962 loss)
I0616 16:48:07.530622 29366 sgd_solver.cpp:105] Iteration 82800, lr = 0.001
I0616 16:49:05.260128 29366 solver.cpp:218] Iteration 82850 (0.866116 iter/s, 57.729s/50 iters), loss = 0.00374579
I0616 16:49:05.260279 29366 solver.cpp:237]     Train net output #0: loss = 0.00374584 (* 1 = 0.00374584 loss)
I0616 16:49:05.260304 29366 sgd_solver.cpp:105] Iteration 82850, lr = 0.001
I0616 16:50:02.988494 29366 solver.cpp:218] Iteration 82900 (0.866136 iter/s, 57.7277s/50 iters), loss = 0.00537553
I0616 16:50:02.988653 29366 solver.cpp:237]     Train net output #0: loss = 0.00537559 (* 1 = 0.00537559 loss)
I0616 16:50:02.988677 29366 sgd_solver.cpp:105] Iteration 82900, lr = 0.001
I0616 16:51:00.710976 29366 solver.cpp:218] Iteration 82950 (0.866224 iter/s, 57.7218s/50 iters), loss = 0.00522028
I0616 16:51:00.711100 29366 solver.cpp:237]     Train net output #0: loss = 0.00522033 (* 1 = 0.00522033 loss)
I0616 16:51:00.711123 29366 sgd_solver.cpp:105] Iteration 82950, lr = 0.001
I0616 16:51:58.432237 29366 solver.cpp:218] Iteration 83000 (0.866242 iter/s, 57.7206s/50 iters), loss = 0.0035138
I0616 16:51:58.432379 29366 solver.cpp:237]     Train net output #0: loss = 0.00351385 (* 1 = 0.00351385 loss)
I0616 16:51:58.432402 29366 sgd_solver.cpp:105] Iteration 83000, lr = 0.001
I0616 16:52:56.153859 29366 solver.cpp:218] Iteration 83050 (0.866237 iter/s, 57.7209s/50 iters), loss = 0.00371802
I0616 16:52:56.153990 29366 solver.cpp:237]     Train net output #0: loss = 0.00371807 (* 1 = 0.00371807 loss)
I0616 16:52:56.154013 29366 sgd_solver.cpp:105] Iteration 83050, lr = 0.001
I0616 16:53:53.876843 29366 solver.cpp:218] Iteration 83100 (0.866216 iter/s, 57.7223s/50 iters), loss = 0.00444701
I0616 16:53:53.876982 29366 solver.cpp:237]     Train net output #0: loss = 0.00444706 (* 1 = 0.00444706 loss)
I0616 16:53:53.877012 29366 sgd_solver.cpp:105] Iteration 83100, lr = 0.001
I0616 16:54:51.590786 29366 solver.cpp:218] Iteration 83150 (0.866352 iter/s, 57.7132s/50 iters), loss = 0.00599696
I0616 16:54:51.590934 29366 solver.cpp:237]     Train net output #0: loss = 0.00599701 (* 1 = 0.00599701 loss)
I0616 16:54:51.590957 29366 sgd_solver.cpp:105] Iteration 83150, lr = 0.001
I0616 16:55:49.320587 29366 solver.cpp:218] Iteration 83200 (0.866114 iter/s, 57.7291s/50 iters), loss = 0.00856451
I0616 16:55:49.320732 29366 solver.cpp:237]     Train net output #0: loss = 0.00856456 (* 1 = 0.00856456 loss)
I0616 16:55:49.320762 29366 sgd_solver.cpp:105] Iteration 83200, lr = 0.001
I0616 16:56:47.045974 29366 solver.cpp:218] Iteration 83250 (0.86618 iter/s, 57.7247s/50 iters), loss = 0.00592588
I0616 16:56:47.046098 29366 solver.cpp:237]     Train net output #0: loss = 0.00592593 (* 1 = 0.00592593 loss)
I0616 16:56:47.046123 29366 sgd_solver.cpp:105] Iteration 83250, lr = 0.001
I0616 16:57:44.780706 29366 solver.cpp:218] Iteration 83300 (0.86604 iter/s, 57.7341s/50 iters), loss = 0.0058684
I0616 16:57:44.780854 29366 solver.cpp:237]     Train net output #0: loss = 0.00586846 (* 1 = 0.00586846 loss)
I0616 16:57:44.780877 29366 sgd_solver.cpp:105] Iteration 83300, lr = 0.001
I0616 16:58:42.523936 29366 solver.cpp:218] Iteration 83350 (0.865913 iter/s, 57.7425s/50 iters), loss = 0.00392434
I0616 16:58:42.524091 29366 solver.cpp:237]     Train net output #0: loss = 0.0039244 (* 1 = 0.0039244 loss)
I0616 16:58:42.524119 29366 sgd_solver.cpp:105] Iteration 83350, lr = 0.001
I0616 16:59:40.271623 29366 solver.cpp:218] Iteration 83400 (0.865846 iter/s, 57.747s/50 iters), loss = 0.00455057
I0616 16:59:40.271847 29366 solver.cpp:237]     Train net output #0: loss = 0.00455063 (* 1 = 0.00455063 loss)
I0616 16:59:40.271874 29366 sgd_solver.cpp:105] Iteration 83400, lr = 0.001
I0616 17:00:38.026011 29366 solver.cpp:218] Iteration 83450 (0.865746 iter/s, 57.7536s/50 iters), loss = 0.00693701
I0616 17:00:38.026172 29366 solver.cpp:237]     Train net output #0: loss = 0.00693706 (* 1 = 0.00693706 loss)
I0616 17:00:38.026203 29366 sgd_solver.cpp:105] Iteration 83450, lr = 0.001
I0616 17:01:35.768103 29366 solver.cpp:218] Iteration 83500 (0.86593 iter/s, 57.7414s/50 iters), loss = 0.0048208
I0616 17:01:35.768246 29366 solver.cpp:237]     Train net output #0: loss = 0.00482086 (* 1 = 0.00482086 loss)
I0616 17:01:35.768275 29366 sgd_solver.cpp:105] Iteration 83500, lr = 0.001
I0616 17:02:33.502409 29366 solver.cpp:218] Iteration 83550 (0.866046 iter/s, 57.7336s/50 iters), loss = 0.00653697
I0616 17:02:33.502564 29366 solver.cpp:237]     Train net output #0: loss = 0.00653703 (* 1 = 0.00653703 loss)
I0616 17:02:33.502594 29366 sgd_solver.cpp:105] Iteration 83550, lr = 0.001
I0616 17:03:31.255024 29366 solver.cpp:218] Iteration 83600 (0.865772 iter/s, 57.7519s/50 iters), loss = 0.00599796
I0616 17:03:31.255162 29366 solver.cpp:237]     Train net output #0: loss = 0.00599801 (* 1 = 0.00599801 loss)
I0616 17:03:31.255190 29366 sgd_solver.cpp:105] Iteration 83600, lr = 0.001
I0616 17:04:29.004925 29366 solver.cpp:218] Iteration 83650 (0.865812 iter/s, 57.7492s/50 iters), loss = 0.0050633
I0616 17:04:29.005074 29366 solver.cpp:237]     Train net output #0: loss = 0.00506335 (* 1 = 0.00506335 loss)
I0616 17:04:29.005101 29366 sgd_solver.cpp:105] Iteration 83650, lr = 0.001
I0616 17:05:26.754056 29366 solver.cpp:218] Iteration 83700 (0.865825 iter/s, 57.7484s/50 iters), loss = 0.00698612
I0616 17:05:26.754214 29366 solver.cpp:237]     Train net output #0: loss = 0.00698618 (* 1 = 0.00698618 loss)
I0616 17:05:26.754247 29366 sgd_solver.cpp:105] Iteration 83700, lr = 0.001
I0616 17:06:24.554960 29366 solver.cpp:218] Iteration 83750 (0.865049 iter/s, 57.8002s/50 iters), loss = 0.00537527
I0616 17:06:24.555127 29366 solver.cpp:237]     Train net output #0: loss = 0.00537533 (* 1 = 0.00537533 loss)
I0616 17:06:24.555155 29366 sgd_solver.cpp:105] Iteration 83750, lr = 0.001
I0616 17:07:22.308013 29366 solver.cpp:218] Iteration 83800 (0.865766 iter/s, 57.7523s/50 iters), loss = 0.00797334
I0616 17:07:22.308696 29366 solver.cpp:237]     Train net output #0: loss = 0.0079734 (* 1 = 0.0079734 loss)
I0616 17:07:22.308725 29366 sgd_solver.cpp:105] Iteration 83800, lr = 0.001
I0616 17:08:20.084686 29366 solver.cpp:218] Iteration 83850 (0.86542 iter/s, 57.7754s/50 iters), loss = 0.00618637
I0616 17:08:20.084836 29366 solver.cpp:237]     Train net output #0: loss = 0.00618642 (* 1 = 0.00618642 loss)
I0616 17:08:20.084872 29366 sgd_solver.cpp:105] Iteration 83850, lr = 0.001
I0616 17:09:17.845628 29366 solver.cpp:218] Iteration 83900 (0.865647 iter/s, 57.7602s/50 iters), loss = 0.00854847
I0616 17:09:17.845805 29366 solver.cpp:237]     Train net output #0: loss = 0.00854853 (* 1 = 0.00854853 loss)
I0616 17:09:17.845834 29366 sgd_solver.cpp:105] Iteration 83900, lr = 0.001
I0616 17:10:15.655455 29366 solver.cpp:218] Iteration 83950 (0.864916 iter/s, 57.8091s/50 iters), loss = 0.00564713
I0616 17:10:15.655634 29366 solver.cpp:237]     Train net output #0: loss = 0.00564718 (* 1 = 0.00564718 loss)
I0616 17:10:15.655663 29366 sgd_solver.cpp:105] Iteration 83950, lr = 0.001
I0616 17:11:13.404029 29366 solver.cpp:218] Iteration 84000 (0.865833 iter/s, 57.7479s/50 iters), loss = 0.00555493
I0616 17:11:13.404199 29366 solver.cpp:237]     Train net output #0: loss = 0.00555498 (* 1 = 0.00555498 loss)
I0616 17:11:13.404227 29366 sgd_solver.cpp:105] Iteration 84000, lr = 0.001
I0616 17:12:11.152076 29366 solver.cpp:218] Iteration 84050 (0.86584 iter/s, 57.7474s/50 iters), loss = 0.00588422
I0616 17:12:11.152307 29366 solver.cpp:237]     Train net output #0: loss = 0.00588428 (* 1 = 0.00588428 loss)
I0616 17:12:11.152345 29366 sgd_solver.cpp:105] Iteration 84050, lr = 0.001
I0616 17:13:08.919093 29366 solver.cpp:218] Iteration 84100 (0.865554 iter/s, 57.7665s/50 iters), loss = 0.00447344
I0616 17:13:08.919273 29366 solver.cpp:237]     Train net output #0: loss = 0.0044735 (* 1 = 0.0044735 loss)
I0616 17:13:08.919301 29366 sgd_solver.cpp:105] Iteration 84100, lr = 0.001
I0616 17:14:06.673142 29366 solver.cpp:218] Iteration 84150 (0.865748 iter/s, 57.7536s/50 iters), loss = 0.00679471
I0616 17:14:06.673316 29366 solver.cpp:237]     Train net output #0: loss = 0.00679477 (* 1 = 0.00679477 loss)
I0616 17:14:06.673346 29366 sgd_solver.cpp:105] Iteration 84150, lr = 0.001
I0616 17:15:04.431304 29366 solver.cpp:218] Iteration 84200 (0.865686 iter/s, 57.7577s/50 iters), loss = 0.00634595
I0616 17:15:04.431493 29366 solver.cpp:237]     Train net output #0: loss = 0.00634601 (* 1 = 0.00634601 loss)
I0616 17:15:04.431526 29366 sgd_solver.cpp:105] Iteration 84200, lr = 0.001
I0616 17:16:02.180629 29366 solver.cpp:218] Iteration 84250 (0.865818 iter/s, 57.7488s/50 iters), loss = 0.00703926
I0616 17:16:02.180758 29366 solver.cpp:237]     Train net output #0: loss = 0.00703932 (* 1 = 0.00703932 loss)
I0616 17:16:02.180783 29366 sgd_solver.cpp:105] Iteration 84250, lr = 0.001
I0616 17:16:59.943583 29366 solver.cpp:218] Iteration 84300 (0.865613 iter/s, 57.7625s/50 iters), loss = 0.00598841
I0616 17:16:59.943719 29366 solver.cpp:237]     Train net output #0: loss = 0.00598847 (* 1 = 0.00598847 loss)
I0616 17:16:59.943745 29366 sgd_solver.cpp:105] Iteration 84300, lr = 0.001
I0616 17:17:57.684020 29366 solver.cpp:218] Iteration 84350 (0.865951 iter/s, 57.74s/50 iters), loss = 0.00445618
I0616 17:17:57.684154 29366 solver.cpp:237]     Train net output #0: loss = 0.00445624 (* 1 = 0.00445624 loss)
I0616 17:17:57.684176 29366 sgd_solver.cpp:105] Iteration 84350, lr = 0.001
I0616 17:18:55.409598 29366 solver.cpp:218] Iteration 84400 (0.866174 iter/s, 57.7251s/50 iters), loss = 0.00424367
I0616 17:18:55.409751 29366 solver.cpp:237]     Train net output #0: loss = 0.00424373 (* 1 = 0.00424373 loss)
I0616 17:18:55.409775 29366 sgd_solver.cpp:105] Iteration 84400, lr = 0.001
I0616 17:19:53.133751 29366 solver.cpp:218] Iteration 84450 (0.866196 iter/s, 57.7237s/50 iters), loss = 0.0058343
I0616 17:19:53.133885 29366 solver.cpp:237]     Train net output #0: loss = 0.00583435 (* 1 = 0.00583435 loss)
I0616 17:19:53.133915 29366 sgd_solver.cpp:105] Iteration 84450, lr = 0.001
I0616 17:20:50.858248 29366 solver.cpp:218] Iteration 84500 (0.86619 iter/s, 57.7241s/50 iters), loss = 0.0053571
I0616 17:20:50.858374 29366 solver.cpp:237]     Train net output #0: loss = 0.00535715 (* 1 = 0.00535715 loss)
I0616 17:20:50.858399 29366 sgd_solver.cpp:105] Iteration 84500, lr = 0.001
I0616 17:21:48.582980 29366 solver.cpp:218] Iteration 84550 (0.866187 iter/s, 57.7243s/50 iters), loss = 0.00656234
I0616 17:21:48.583134 29366 solver.cpp:237]     Train net output #0: loss = 0.0065624 (* 1 = 0.0065624 loss)
I0616 17:21:48.583165 29366 sgd_solver.cpp:105] Iteration 84550, lr = 0.001
I0616 17:22:46.291255 29366 solver.cpp:218] Iteration 84600 (0.866434 iter/s, 57.7078s/50 iters), loss = 0.00662563
I0616 17:22:46.291378 29366 solver.cpp:237]     Train net output #0: loss = 0.00662569 (* 1 = 0.00662569 loss)
I0616 17:22:46.291406 29366 sgd_solver.cpp:105] Iteration 84600, lr = 0.001
I0616 17:23:44.006804 29366 solver.cpp:218] Iteration 84650 (0.866324 iter/s, 57.7151s/50 iters), loss = 0.00456217
I0616 17:23:44.006930 29366 solver.cpp:237]     Train net output #0: loss = 0.00456223 (* 1 = 0.00456223 loss)
I0616 17:23:44.006955 29366 sgd_solver.cpp:105] Iteration 84650, lr = 0.001
I0616 17:24:41.723985 29366 solver.cpp:218] Iteration 84700 (0.8663 iter/s, 57.7167s/50 iters), loss = 0.00660606
I0616 17:24:41.724123 29366 solver.cpp:237]     Train net output #0: loss = 0.00660611 (* 1 = 0.00660611 loss)
I0616 17:24:41.724146 29366 sgd_solver.cpp:105] Iteration 84700, lr = 0.001
I0616 17:25:39.450027 29366 solver.cpp:218] Iteration 84750 (0.866167 iter/s, 57.7256s/50 iters), loss = 0.00814219
I0616 17:25:39.450204 29366 solver.cpp:237]     Train net output #0: loss = 0.00814224 (* 1 = 0.00814224 loss)
I0616 17:25:39.450227 29366 sgd_solver.cpp:105] Iteration 84750, lr = 0.001
I0616 17:26:37.171574 29366 solver.cpp:218] Iteration 84800 (0.866235 iter/s, 57.721s/50 iters), loss = 0.0082554
I0616 17:26:37.171702 29366 solver.cpp:237]     Train net output #0: loss = 0.00825546 (* 1 = 0.00825546 loss)
I0616 17:26:37.171725 29366 sgd_solver.cpp:105] Iteration 84800, lr = 0.001
I0616 17:27:34.944109 29366 solver.cpp:218] Iteration 84850 (0.86547 iter/s, 57.7721s/50 iters), loss = 0.00663987
I0616 17:27:34.944264 29366 solver.cpp:237]     Train net output #0: loss = 0.00663993 (* 1 = 0.00663993 loss)
I0616 17:27:34.944289 29366 sgd_solver.cpp:105] Iteration 84850, lr = 0.001
I0616 17:28:32.676084 29366 solver.cpp:218] Iteration 84900 (0.866079 iter/s, 57.7315s/50 iters), loss = 0.00413565
I0616 17:28:32.676244 29366 solver.cpp:237]     Train net output #0: loss = 0.00413571 (* 1 = 0.00413571 loss)
I0616 17:28:32.676278 29366 sgd_solver.cpp:105] Iteration 84900, lr = 0.001
I0616 17:29:30.394424 29366 solver.cpp:218] Iteration 84950 (0.866283 iter/s, 57.7178s/50 iters), loss = 0.00466075
I0616 17:29:30.394567 29366 solver.cpp:237]     Train net output #0: loss = 0.0046608 (* 1 = 0.0046608 loss)
I0616 17:29:30.394593 29366 sgd_solver.cpp:105] Iteration 84950, lr = 0.001
I0616 17:30:28.108844 29366 solver.cpp:218] Iteration 85000 (0.866342 iter/s, 57.7139s/50 iters), loss = 0.00827171
I0616 17:30:28.108973 29366 solver.cpp:237]     Train net output #0: loss = 0.00827176 (* 1 = 0.00827176 loss)
I0616 17:30:28.108997 29366 sgd_solver.cpp:105] Iteration 85000, lr = 0.001
I0616 17:31:25.830122 29366 solver.cpp:218] Iteration 85050 (0.866239 iter/s, 57.7208s/50 iters), loss = 0.00593084
I0616 17:31:25.830247 29366 solver.cpp:237]     Train net output #0: loss = 0.0059309 (* 1 = 0.0059309 loss)
I0616 17:31:25.830277 29366 sgd_solver.cpp:105] Iteration 85050, lr = 0.001
I0616 17:32:23.552122 29366 solver.cpp:218] Iteration 85100 (0.866228 iter/s, 57.7215s/50 iters), loss = 0.00362998
I0616 17:32:23.552326 29366 solver.cpp:237]     Train net output #0: loss = 0.00363004 (* 1 = 0.00363004 loss)
I0616 17:32:23.552350 29366 sgd_solver.cpp:105] Iteration 85100, lr = 0.001
I0616 17:33:21.274837 29366 solver.cpp:218] Iteration 85150 (0.866218 iter/s, 57.7222s/50 iters), loss = 0.00535219
I0616 17:33:21.274966 29366 solver.cpp:237]     Train net output #0: loss = 0.00535224 (* 1 = 0.00535224 loss)
I0616 17:33:21.274989 29366 sgd_solver.cpp:105] Iteration 85150, lr = 0.001
I0616 17:34:19.014461 29366 solver.cpp:218] Iteration 85200 (0.865964 iter/s, 57.7392s/50 iters), loss = 0.00677061
I0616 17:34:19.014603 29366 solver.cpp:237]     Train net output #0: loss = 0.00677067 (* 1 = 0.00677067 loss)
I0616 17:34:19.014628 29366 sgd_solver.cpp:105] Iteration 85200, lr = 0.001
I0616 17:35:16.752946 29366 solver.cpp:218] Iteration 85250 (0.865981 iter/s, 57.738s/50 iters), loss = 0.00430719
I0616 17:35:16.753084 29366 solver.cpp:237]     Train net output #0: loss = 0.00430725 (* 1 = 0.00430725 loss)
I0616 17:35:16.753109 29366 sgd_solver.cpp:105] Iteration 85250, lr = 0.001
I0616 17:36:14.575935 29366 solver.cpp:218] Iteration 85300 (0.864716 iter/s, 57.8225s/50 iters), loss = 0.00749778
I0616 17:36:14.576334 29366 solver.cpp:237]     Train net output #0: loss = 0.00749784 (* 1 = 0.00749784 loss)
I0616 17:36:14.576359 29366 sgd_solver.cpp:105] Iteration 85300, lr = 0.001
I0616 17:37:12.453919 29366 solver.cpp:218] Iteration 85350 (0.863898 iter/s, 57.8772s/50 iters), loss = 0.00622541
I0616 17:37:12.454095 29366 solver.cpp:237]     Train net output #0: loss = 0.00622547 (* 1 = 0.00622547 loss)
I0616 17:37:12.454120 29366 sgd_solver.cpp:105] Iteration 85350, lr = 0.001
I0616 17:38:10.281987 29366 solver.cpp:218] Iteration 85400 (0.86464 iter/s, 57.8275s/50 iters), loss = 0.00817748
I0616 17:38:10.282161 29366 solver.cpp:237]     Train net output #0: loss = 0.00817754 (* 1 = 0.00817754 loss)
I0616 17:38:10.282194 29366 sgd_solver.cpp:105] Iteration 85400, lr = 0.001
I0616 17:39:08.015096 29366 solver.cpp:218] Iteration 85450 (0.866062 iter/s, 57.7326s/50 iters), loss = 0.00631388
I0616 17:39:08.015238 29366 solver.cpp:237]     Train net output #0: loss = 0.00631394 (* 1 = 0.00631394 loss)
I0616 17:39:08.015260 29366 sgd_solver.cpp:105] Iteration 85450, lr = 0.001
I0616 17:40:05.740563 29366 solver.cpp:218] Iteration 85500 (0.866176 iter/s, 57.725s/50 iters), loss = 0.00690397
I0616 17:40:05.740711 29366 solver.cpp:237]     Train net output #0: loss = 0.00690403 (* 1 = 0.00690403 loss)
I0616 17:40:05.740734 29366 sgd_solver.cpp:105] Iteration 85500, lr = 0.001
I0616 17:41:03.479588 29366 solver.cpp:218] Iteration 85550 (0.865973 iter/s, 57.7385s/50 iters), loss = 0.00957081
I0616 17:41:03.479733 29366 solver.cpp:237]     Train net output #0: loss = 0.00957086 (* 1 = 0.00957086 loss)
I0616 17:41:03.479759 29366 sgd_solver.cpp:105] Iteration 85550, lr = 0.001
I0616 17:42:01.217686 29366 solver.cpp:218] Iteration 85600 (0.865987 iter/s, 57.7376s/50 iters), loss = 0.00466012
I0616 17:42:01.217869 29366 solver.cpp:237]     Train net output #0: loss = 0.00466017 (* 1 = 0.00466017 loss)
I0616 17:42:01.217893 29366 sgd_solver.cpp:105] Iteration 85600, lr = 0.001
I0616 17:42:58.944732 29366 solver.cpp:218] Iteration 85650 (0.866154 iter/s, 57.7265s/50 iters), loss = 0.00792048
I0616 17:42:58.944921 29366 solver.cpp:237]     Train net output #0: loss = 0.00792054 (* 1 = 0.00792054 loss)
I0616 17:42:58.944952 29366 sgd_solver.cpp:105] Iteration 85650, lr = 0.001
I0616 17:43:56.683315 29366 solver.cpp:218] Iteration 85700 (0.865981 iter/s, 57.738s/50 iters), loss = 0.00577055
I0616 17:43:56.683452 29366 solver.cpp:237]     Train net output #0: loss = 0.00577061 (* 1 = 0.00577061 loss)
I0616 17:43:56.683477 29366 sgd_solver.cpp:105] Iteration 85700, lr = 0.001
I0616 17:44:54.426268 29366 solver.cpp:218] Iteration 85750 (0.865914 iter/s, 57.7424s/50 iters), loss = 0.00527476
I0616 17:44:54.426410 29366 solver.cpp:237]     Train net output #0: loss = 0.00527482 (* 1 = 0.00527482 loss)
I0616 17:44:54.426434 29366 sgd_solver.cpp:105] Iteration 85750, lr = 0.001
I0616 17:45:52.165868 29366 solver.cpp:218] Iteration 85800 (0.865965 iter/s, 57.7391s/50 iters), loss = 0.00602395
I0616 17:45:52.168305 29366 solver.cpp:237]     Train net output #0: loss = 0.006024 (* 1 = 0.006024 loss)
I0616 17:45:52.168329 29366 sgd_solver.cpp:105] Iteration 85800, lr = 0.001
I0616 17:46:49.909734 29366 solver.cpp:218] Iteration 85850 (0.865935 iter/s, 57.741s/50 iters), loss = 0.00397513
I0616 17:46:49.909937 29366 solver.cpp:237]     Train net output #0: loss = 0.00397519 (* 1 = 0.00397519 loss)
I0616 17:46:49.909962 29366 sgd_solver.cpp:105] Iteration 85850, lr = 0.001
I0616 17:47:47.643373 29366 solver.cpp:218] Iteration 85900 (0.866055 iter/s, 57.733s/50 iters), loss = 0.00617101
I0616 17:47:47.643497 29366 solver.cpp:237]     Train net output #0: loss = 0.00617107 (* 1 = 0.00617107 loss)
I0616 17:47:47.643532 29366 sgd_solver.cpp:105] Iteration 85900, lr = 0.001
I0616 17:48:45.382242 29366 solver.cpp:218] Iteration 85950 (0.865976 iter/s, 57.7383s/50 iters), loss = 0.0082918
I0616 17:48:45.382383 29366 solver.cpp:237]     Train net output #0: loss = 0.00829185 (* 1 = 0.00829185 loss)
I0616 17:48:45.382412 29366 sgd_solver.cpp:105] Iteration 85950, lr = 0.001
I0616 17:49:43.121338 29366 solver.cpp:218] Iteration 86000 (0.865973 iter/s, 57.7385s/50 iters), loss = 0.00819754
I0616 17:49:43.121474 29366 solver.cpp:237]     Train net output #0: loss = 0.0081976 (* 1 = 0.0081976 loss)
I0616 17:49:43.121502 29366 sgd_solver.cpp:105] Iteration 86000, lr = 0.001
I0616 17:50:40.865432 29366 solver.cpp:218] Iteration 86050 (0.865898 iter/s, 57.7436s/50 iters), loss = 0.00712634
I0616 17:50:40.865640 29366 solver.cpp:237]     Train net output #0: loss = 0.00712639 (* 1 = 0.00712639 loss)
I0616 17:50:40.865666 29366 sgd_solver.cpp:105] Iteration 86050, lr = 0.001
I0616 17:51:38.602965 29366 solver.cpp:218] Iteration 86100 (0.865997 iter/s, 57.7369s/50 iters), loss = 0.00638355
I0616 17:51:38.603281 29366 solver.cpp:237]     Train net output #0: loss = 0.00638361 (* 1 = 0.00638361 loss)
I0616 17:51:38.603305 29366 sgd_solver.cpp:105] Iteration 86100, lr = 0.001
I0616 17:52:36.332273 29366 solver.cpp:218] Iteration 86150 (0.866122 iter/s, 57.7286s/50 iters), loss = 0.0122748
I0616 17:52:36.332475 29366 solver.cpp:237]     Train net output #0: loss = 0.0122749 (* 1 = 0.0122749 loss)
I0616 17:52:36.332499 29366 sgd_solver.cpp:105] Iteration 86150, lr = 0.001
I0616 17:53:34.065037 29366 solver.cpp:218] Iteration 86200 (0.866068 iter/s, 57.7322s/50 iters), loss = 0.00793675
I0616 17:53:34.065187 29366 solver.cpp:237]     Train net output #0: loss = 0.00793681 (* 1 = 0.00793681 loss)
I0616 17:53:34.065212 29366 sgd_solver.cpp:105] Iteration 86200, lr = 0.001
I0616 17:54:31.804769 29366 solver.cpp:218] Iteration 86250 (0.865963 iter/s, 57.7392s/50 iters), loss = 0.00571146
I0616 17:54:31.804929 29366 solver.cpp:237]     Train net output #0: loss = 0.00571151 (* 1 = 0.00571151 loss)
I0616 17:54:31.804953 29366 sgd_solver.cpp:105] Iteration 86250, lr = 0.001
I0616 17:55:29.537519 29366 solver.cpp:218] Iteration 86300 (0.866069 iter/s, 57.7322s/50 iters), loss = 0.00656079
I0616 17:55:29.537709 29366 solver.cpp:237]     Train net output #0: loss = 0.00656084 (* 1 = 0.00656084 loss)
I0616 17:55:29.537742 29366 sgd_solver.cpp:105] Iteration 86300, lr = 0.001
I0616 17:56:27.331401 29366 solver.cpp:218] Iteration 86350 (0.865152 iter/s, 57.7933s/50 iters), loss = 0.00486083
I0616 17:56:27.331614 29366 solver.cpp:237]     Train net output #0: loss = 0.00486089 (* 1 = 0.00486089 loss)
I0616 17:56:27.331637 29366 sgd_solver.cpp:105] Iteration 86350, lr = 0.001
I0616 17:57:25.073156 29366 solver.cpp:218] Iteration 86400 (0.865934 iter/s, 57.7411s/50 iters), loss = 0.00535058
I0616 17:57:25.073312 29366 solver.cpp:237]     Train net output #0: loss = 0.00535063 (* 1 = 0.00535063 loss)
I0616 17:57:25.073339 29366 sgd_solver.cpp:105] Iteration 86400, lr = 0.001
I0616 17:58:22.809741 29366 solver.cpp:218] Iteration 86450 (0.86601 iter/s, 57.736s/50 iters), loss = 0.00648918
I0616 17:58:22.809870 29366 solver.cpp:237]     Train net output #0: loss = 0.00648924 (* 1 = 0.00648924 loss)
I0616 17:58:22.809893 29366 sgd_solver.cpp:105] Iteration 86450, lr = 0.001
I0616 17:59:20.543705 29366 solver.cpp:218] Iteration 86500 (0.866049 iter/s, 57.7334s/50 iters), loss = 0.00571397
I0616 17:59:20.543854 29366 solver.cpp:237]     Train net output #0: loss = 0.00571402 (* 1 = 0.00571402 loss)
I0616 17:59:20.543877 29366 sgd_solver.cpp:105] Iteration 86500, lr = 0.001
I0616 18:00:18.277472 29366 solver.cpp:218] Iteration 86550 (0.866053 iter/s, 57.7332s/50 iters), loss = 0.00496452
I0616 18:00:18.277623 29366 solver.cpp:237]     Train net output #0: loss = 0.00496458 (* 1 = 0.00496458 loss)
I0616 18:00:18.277653 29366 sgd_solver.cpp:105] Iteration 86550, lr = 0.001
I0616 18:01:16.014793 29366 solver.cpp:218] Iteration 86600 (0.865999 iter/s, 57.7368s/50 iters), loss = 0.00618263
I0616 18:01:16.014957 29366 solver.cpp:237]     Train net output #0: loss = 0.00618268 (* 1 = 0.00618268 loss)
I0616 18:01:16.014983 29366 sgd_solver.cpp:105] Iteration 86600, lr = 0.001
I0616 18:02:13.748291 29366 solver.cpp:218] Iteration 86650 (0.866057 iter/s, 57.7329s/50 iters), loss = 0.00687011
I0616 18:02:13.748596 29366 solver.cpp:237]     Train net output #0: loss = 0.00687017 (* 1 = 0.00687017 loss)
I0616 18:02:13.748623 29366 sgd_solver.cpp:105] Iteration 86650, lr = 0.001
I0616 18:03:11.475571 29366 solver.cpp:218] Iteration 86700 (0.866152 iter/s, 57.7266s/50 iters), loss = 0.00623768
I0616 18:03:11.475734 29366 solver.cpp:237]     Train net output #0: loss = 0.00623773 (* 1 = 0.00623773 loss)
I0616 18:03:11.475759 29366 sgd_solver.cpp:105] Iteration 86700, lr = 0.001
I0616 18:04:09.215534 29366 solver.cpp:218] Iteration 86750 (0.865963 iter/s, 57.7392s/50 iters), loss = 0.00493594
I0616 18:04:09.215752 29366 solver.cpp:237]     Train net output #0: loss = 0.00493599 (* 1 = 0.00493599 loss)
I0616 18:04:09.215791 29366 sgd_solver.cpp:105] Iteration 86750, lr = 0.001
I0616 18:05:06.966158 29366 solver.cpp:218] Iteration 86800 (0.865804 iter/s, 57.7498s/50 iters), loss = 0.00700417
I0616 18:05:06.966372 29366 solver.cpp:237]     Train net output #0: loss = 0.00700423 (* 1 = 0.00700423 loss)
I0616 18:05:06.966397 29366 sgd_solver.cpp:105] Iteration 86800, lr = 0.001
I0616 18:06:04.708498 29366 solver.cpp:218] Iteration 86850 (0.865928 iter/s, 57.7415s/50 iters), loss = 0.00641731
I0616 18:06:04.708684 29366 solver.cpp:237]     Train net output #0: loss = 0.00641736 (* 1 = 0.00641736 loss)
I0616 18:06:04.708709 29366 sgd_solver.cpp:105] Iteration 86850, lr = 0.001
I0616 18:07:02.442111 29366 solver.cpp:218] Iteration 86900 (0.866059 iter/s, 57.7328s/50 iters), loss = 0.00713037
I0616 18:07:02.442271 29366 solver.cpp:237]     Train net output #0: loss = 0.00713043 (* 1 = 0.00713043 loss)
I0616 18:07:02.442296 29366 sgd_solver.cpp:105] Iteration 86900, lr = 0.001
I0616 18:08:00.178225 29366 solver.cpp:218] Iteration 86950 (0.86602 iter/s, 57.7354s/50 iters), loss = 0.00544089
I0616 18:08:00.178376 29366 solver.cpp:237]     Train net output #0: loss = 0.00544094 (* 1 = 0.00544094 loss)
I0616 18:08:00.178402 29366 sgd_solver.cpp:105] Iteration 86950, lr = 0.001
I0616 18:08:57.915333 29366 solver.cpp:218] Iteration 87000 (0.866005 iter/s, 57.7364s/50 iters), loss = 0.00665424
I0616 18:08:57.915482 29366 solver.cpp:237]     Train net output #0: loss = 0.00665429 (* 1 = 0.00665429 loss)
I0616 18:08:57.915508 29366 sgd_solver.cpp:105] Iteration 87000, lr = 0.001
I0616 18:09:55.639293 29366 solver.cpp:218] Iteration 87050 (0.866202 iter/s, 57.7233s/50 iters), loss = 0.00421918
I0616 18:09:55.639408 29366 solver.cpp:237]     Train net output #0: loss = 0.00421923 (* 1 = 0.00421923 loss)
I0616 18:09:55.639432 29366 sgd_solver.cpp:105] Iteration 87050, lr = 0.001
I0616 18:10:53.371505 29366 solver.cpp:218] Iteration 87100 (0.866078 iter/s, 57.7315s/50 iters), loss = 0.00483226
I0616 18:10:53.371671 29366 solver.cpp:237]     Train net output #0: loss = 0.00483231 (* 1 = 0.00483231 loss)
I0616 18:10:53.371697 29366 sgd_solver.cpp:105] Iteration 87100, lr = 0.001
I0616 18:11:51.108886 29366 solver.cpp:218] Iteration 87150 (0.866001 iter/s, 57.7367s/50 iters), loss = 0.0060767
I0616 18:11:51.109006 29366 solver.cpp:237]     Train net output #0: loss = 0.00607676 (* 1 = 0.00607676 loss)
I0616 18:11:51.109030 29366 sgd_solver.cpp:105] Iteration 87150, lr = 0.001
I0616 18:12:48.841320 29366 solver.cpp:218] Iteration 87200 (0.866075 iter/s, 57.7318s/50 iters), loss = 0.00524145
I0616 18:12:48.841447 29366 solver.cpp:237]     Train net output #0: loss = 0.00524151 (* 1 = 0.00524151 loss)
I0616 18:12:48.841471 29366 sgd_solver.cpp:105] Iteration 87200, lr = 0.001
I0616 18:13:46.568874 29366 solver.cpp:218] Iteration 87250 (0.866148 iter/s, 57.7269s/50 iters), loss = 0.0053402
I0616 18:13:46.569042 29366 solver.cpp:237]     Train net output #0: loss = 0.00534026 (* 1 = 0.00534026 loss)
I0616 18:13:46.569067 29366 sgd_solver.cpp:105] Iteration 87250, lr = 0.001
I0616 18:14:44.302810 29366 solver.cpp:218] Iteration 87300 (0.866053 iter/s, 57.7332s/50 iters), loss = 0.00602704
I0616 18:14:44.302960 29366 solver.cpp:237]     Train net output #0: loss = 0.0060271 (* 1 = 0.0060271 loss)
I0616 18:14:44.302984 29366 sgd_solver.cpp:105] Iteration 87300, lr = 0.001
I0616 18:15:42.042029 29366 solver.cpp:218] Iteration 87350 (0.865973 iter/s, 57.7385s/50 iters), loss = 0.00523419
I0616 18:15:42.042172 29366 solver.cpp:237]     Train net output #0: loss = 0.00523424 (* 1 = 0.00523424 loss)
I0616 18:15:42.042197 29366 sgd_solver.cpp:105] Iteration 87350, lr = 0.001
I0616 18:16:39.764744 29366 solver.cpp:218] Iteration 87400 (0.866221 iter/s, 57.722s/50 iters), loss = 0.00446918
I0616 18:16:39.764878 29366 solver.cpp:237]     Train net output #0: loss = 0.00446923 (* 1 = 0.00446923 loss)
I0616 18:16:39.764904 29366 sgd_solver.cpp:105] Iteration 87400, lr = 0.001
I0616 18:17:37.504628 29366 solver.cpp:218] Iteration 87450 (0.865963 iter/s, 57.7392s/50 iters), loss = 0.00744338
I0616 18:17:37.504817 29366 solver.cpp:237]     Train net output #0: loss = 0.00744344 (* 1 = 0.00744344 loss)
I0616 18:17:37.504842 29366 sgd_solver.cpp:105] Iteration 87450, lr = 0.001
I0616 18:18:35.238319 29366 solver.cpp:218] Iteration 87500 (0.866056 iter/s, 57.733s/50 iters), loss = 0.00763613
I0616 18:18:35.238451 29366 solver.cpp:237]     Train net output #0: loss = 0.00763619 (* 1 = 0.00763619 loss)
I0616 18:18:35.238473 29366 sgd_solver.cpp:105] Iteration 87500, lr = 0.001
I0616 18:19:32.968689 29366 solver.cpp:218] Iteration 87550 (0.866106 iter/s, 57.7297s/50 iters), loss = 0.00368505
I0616 18:19:32.968845 29366 solver.cpp:237]     Train net output #0: loss = 0.00368511 (* 1 = 0.00368511 loss)
I0616 18:19:32.968869 29366 sgd_solver.cpp:105] Iteration 87550, lr = 0.001
I0616 18:20:30.707218 29366 solver.cpp:218] Iteration 87600 (0.865984 iter/s, 57.7378s/50 iters), loss = 0.00619229
I0616 18:20:30.707336 29366 solver.cpp:237]     Train net output #0: loss = 0.00619235 (* 1 = 0.00619235 loss)
I0616 18:20:30.707360 29366 sgd_solver.cpp:105] Iteration 87600, lr = 0.001
I0616 18:21:28.439338 29366 solver.cpp:218] Iteration 87650 (0.86608 iter/s, 57.7314s/50 iters), loss = 0.00476372
I0616 18:21:28.439478 29366 solver.cpp:237]     Train net output #0: loss = 0.00476378 (* 1 = 0.00476378 loss)
I0616 18:21:28.439502 29366 sgd_solver.cpp:105] Iteration 87650, lr = 0.001
I0616 18:22:26.171345 29366 solver.cpp:218] Iteration 87700 (0.866082 iter/s, 57.7313s/50 iters), loss = 0.00627139
I0616 18:22:26.171479 29366 solver.cpp:237]     Train net output #0: loss = 0.00627144 (* 1 = 0.00627144 loss)
I0616 18:22:26.171504 29366 sgd_solver.cpp:105] Iteration 87700, lr = 0.001
I0616 18:23:23.899173 29366 solver.cpp:218] Iteration 87750 (0.866145 iter/s, 57.7271s/50 iters), loss = 0.00931579
I0616 18:23:23.899307 29366 solver.cpp:237]     Train net output #0: loss = 0.00931585 (* 1 = 0.00931585 loss)
I0616 18:23:23.899330 29366 sgd_solver.cpp:105] Iteration 87750, lr = 0.001
I0616 18:24:21.633296 29366 solver.cpp:218] Iteration 87800 (0.86605 iter/s, 57.7334s/50 iters), loss = 0.00580145
I0616 18:24:21.633435 29366 solver.cpp:237]     Train net output #0: loss = 0.0058015 (* 1 = 0.0058015 loss)
I0616 18:24:21.633460 29366 sgd_solver.cpp:105] Iteration 87800, lr = 0.001
I0616 18:25:19.367156 29366 solver.cpp:218] Iteration 87850 (0.866055 iter/s, 57.7331s/50 iters), loss = 0.00631086
I0616 18:25:19.367341 29366 solver.cpp:237]     Train net output #0: loss = 0.00631091 (* 1 = 0.00631091 loss)
I0616 18:25:19.367365 29366 sgd_solver.cpp:105] Iteration 87850, lr = 0.001
I0616 18:26:17.102466 29366 solver.cpp:218] Iteration 87900 (0.866033 iter/s, 57.7345s/50 iters), loss = 0.00419419
I0616 18:26:17.102619 29366 solver.cpp:237]     Train net output #0: loss = 0.00419425 (* 1 = 0.00419425 loss)
I0616 18:26:17.102644 29366 sgd_solver.cpp:105] Iteration 87900, lr = 0.001
I0616 18:27:14.892061 29366 solver.cpp:218] Iteration 87950 (0.865219 iter/s, 57.7888s/50 iters), loss = 0.00633588
I0616 18:27:14.892215 29366 solver.cpp:237]     Train net output #0: loss = 0.00633593 (* 1 = 0.00633593 loss)
I0616 18:27:14.892238 29366 sgd_solver.cpp:105] Iteration 87950, lr = 0.001
I0616 18:28:12.645529 29366 solver.cpp:218] Iteration 88000 (0.865761 iter/s, 57.7527s/50 iters), loss = 0.00569287
I0616 18:28:12.645798 29366 solver.cpp:237]     Train net output #0: loss = 0.00569292 (* 1 = 0.00569292 loss)
I0616 18:28:12.645823 29366 sgd_solver.cpp:105] Iteration 88000, lr = 0.001
I0616 18:29:10.376431 29366 solver.cpp:218] Iteration 88050 (0.8661 iter/s, 57.73s/50 iters), loss = 0.00444486
I0616 18:29:10.376615 29366 solver.cpp:237]     Train net output #0: loss = 0.00444492 (* 1 = 0.00444492 loss)
I0616 18:29:10.376638 29366 sgd_solver.cpp:105] Iteration 88050, lr = 0.001
I0616 18:30:08.125306 29366 solver.cpp:218] Iteration 88100 (0.86583 iter/s, 57.7481s/50 iters), loss = 0.00616238
I0616 18:30:08.125504 29366 solver.cpp:237]     Train net output #0: loss = 0.00616244 (* 1 = 0.00616244 loss)
I0616 18:30:08.125541 29366 sgd_solver.cpp:105] Iteration 88100, lr = 0.001
I0616 18:31:05.862238 29366 solver.cpp:218] Iteration 88150 (0.866009 iter/s, 57.7361s/50 iters), loss = 0.00496277
I0616 18:31:05.862370 29366 solver.cpp:237]     Train net output #0: loss = 0.00496282 (* 1 = 0.00496282 loss)
I0616 18:31:05.862396 29366 sgd_solver.cpp:105] Iteration 88150, lr = 0.001
I0616 18:32:03.595533 29366 solver.cpp:218] Iteration 88200 (0.866063 iter/s, 57.7325s/50 iters), loss = 0.00628118
I0616 18:32:03.595772 29366 solver.cpp:237]     Train net output #0: loss = 0.00628124 (* 1 = 0.00628124 loss)
I0616 18:32:03.595794 29366 sgd_solver.cpp:105] Iteration 88200, lr = 0.001
I0616 18:33:01.387586 29366 solver.cpp:218] Iteration 88250 (0.865184 iter/s, 57.7912s/50 iters), loss = 0.00857684
I0616 18:33:01.387922 29366 solver.cpp:237]     Train net output #0: loss = 0.0085769 (* 1 = 0.0085769 loss)
I0616 18:33:01.387946 29366 sgd_solver.cpp:105] Iteration 88250, lr = 0.001
I0616 18:33:59.139384 29366 solver.cpp:218] Iteration 88300 (0.865789 iter/s, 57.7508s/50 iters), loss = 0.00607034
I0616 18:33:59.139525 29366 solver.cpp:237]     Train net output #0: loss = 0.00607039 (* 1 = 0.00607039 loss)
I0616 18:33:59.139556 29366 sgd_solver.cpp:105] Iteration 88300, lr = 0.001
I0616 18:34:56.876991 29366 solver.cpp:218] Iteration 88350 (0.865998 iter/s, 57.7369s/50 iters), loss = 0.00724969
I0616 18:34:56.877121 29366 solver.cpp:237]     Train net output #0: loss = 0.00724975 (* 1 = 0.00724975 loss)
I0616 18:34:56.877146 29366 sgd_solver.cpp:105] Iteration 88350, lr = 0.001
I0616 18:35:54.614621 29366 solver.cpp:218] Iteration 88400 (0.865998 iter/s, 57.7369s/50 iters), loss = 0.00578351
I0616 18:35:54.614861 29366 solver.cpp:237]     Train net output #0: loss = 0.00578357 (* 1 = 0.00578357 loss)
I0616 18:35:54.614886 29366 sgd_solver.cpp:105] Iteration 88400, lr = 0.001
I0616 18:36:52.359416 29366 solver.cpp:218] Iteration 88450 (0.865892 iter/s, 57.7439s/50 iters), loss = 0.00578044
I0616 18:36:52.362979 29366 solver.cpp:237]     Train net output #0: loss = 0.00578049 (* 1 = 0.00578049 loss)
I0616 18:36:52.363008 29366 sgd_solver.cpp:105] Iteration 88450, lr = 0.001
I0616 18:37:50.105384 29366 solver.cpp:218] Iteration 88500 (0.865924 iter/s, 57.7418s/50 iters), loss = 0.00377522
I0616 18:37:50.105532 29366 solver.cpp:237]     Train net output #0: loss = 0.00377527 (* 1 = 0.00377527 loss)
I0616 18:37:50.105558 29366 sgd_solver.cpp:105] Iteration 88500, lr = 0.001
I0616 18:38:47.843088 29366 solver.cpp:218] Iteration 88550 (0.865997 iter/s, 57.7369s/50 iters), loss = 0.00527694
I0616 18:38:47.843238 29366 solver.cpp:237]     Train net output #0: loss = 0.00527699 (* 1 = 0.00527699 loss)
I0616 18:38:47.843262 29366 sgd_solver.cpp:105] Iteration 88550, lr = 0.001
I0616 18:39:45.595974 29366 solver.cpp:218] Iteration 88600 (0.865769 iter/s, 57.7521s/50 iters), loss = 0.00513444
I0616 18:39:45.596154 29366 solver.cpp:237]     Train net output #0: loss = 0.00513449 (* 1 = 0.00513449 loss)
I0616 18:39:45.596179 29366 sgd_solver.cpp:105] Iteration 88600, lr = 0.001
I0616 18:40:43.332835 29366 solver.cpp:218] Iteration 88650 (0.86601 iter/s, 57.736s/50 iters), loss = 0.00571103
I0616 18:40:43.333036 29366 solver.cpp:237]     Train net output #0: loss = 0.00571109 (* 1 = 0.00571109 loss)
I0616 18:40:43.333061 29366 sgd_solver.cpp:105] Iteration 88650, lr = 0.001
I0616 18:41:41.067598 29366 solver.cpp:218] Iteration 88700 (0.866042 iter/s, 57.734s/50 iters), loss = 0.00508342
I0616 18:41:41.067726 29366 solver.cpp:237]     Train net output #0: loss = 0.00508348 (* 1 = 0.00508348 loss)
I0616 18:41:41.067750 29366 sgd_solver.cpp:105] Iteration 88700, lr = 0.001
I0616 18:42:38.792160 29366 solver.cpp:218] Iteration 88750 (0.866193 iter/s, 57.7238s/50 iters), loss = 0.00651945
I0616 18:42:38.792309 29366 solver.cpp:237]     Train net output #0: loss = 0.0065195 (* 1 = 0.0065195 loss)
I0616 18:42:38.792333 29366 sgd_solver.cpp:105] Iteration 88750, lr = 0.001
I0616 18:43:36.524683 29366 solver.cpp:218] Iteration 88800 (0.866075 iter/s, 57.7317s/50 iters), loss = 0.00589906
I0616 18:43:36.524955 29366 solver.cpp:237]     Train net output #0: loss = 0.00589912 (* 1 = 0.00589912 loss)
I0616 18:43:36.524996 29366 sgd_solver.cpp:105] Iteration 88800, lr = 0.001
I0616 18:44:34.268884 29366 solver.cpp:218] Iteration 88850 (0.865901 iter/s, 57.7433s/50 iters), loss = 0.00652379
I0616 18:44:34.269062 29366 solver.cpp:237]     Train net output #0: loss = 0.00652385 (* 1 = 0.00652385 loss)
I0616 18:44:34.269088 29366 sgd_solver.cpp:105] Iteration 88850, lr = 0.001
I0616 18:45:32.018601 29366 solver.cpp:218] Iteration 88900 (0.865817 iter/s, 57.7489s/50 iters), loss = 0.00557423
I0616 18:45:32.018766 29366 solver.cpp:237]     Train net output #0: loss = 0.00557429 (* 1 = 0.00557429 loss)
I0616 18:45:32.018791 29366 sgd_solver.cpp:105] Iteration 88900, lr = 0.001
I0616 18:46:29.755532 29366 solver.cpp:218] Iteration 88950 (0.866009 iter/s, 57.7361s/50 iters), loss = 0.00325457
I0616 18:46:29.755674 29366 solver.cpp:237]     Train net output #0: loss = 0.00325463 (* 1 = 0.00325463 loss)
I0616 18:46:29.755703 29366 sgd_solver.cpp:105] Iteration 88950, lr = 0.001
I0616 18:47:27.494294 29366 solver.cpp:218] Iteration 89000 (0.865981 iter/s, 57.738s/50 iters), loss = 0.00547857
I0616 18:47:27.494585 29366 solver.cpp:237]     Train net output #0: loss = 0.00547862 (* 1 = 0.00547862 loss)
I0616 18:47:27.494611 29366 sgd_solver.cpp:105] Iteration 89000, lr = 0.001
I0616 18:48:25.229416 29366 solver.cpp:218] Iteration 89050 (0.866037 iter/s, 57.7342s/50 iters), loss = 0.00846824
I0616 18:48:25.229599 29366 solver.cpp:237]     Train net output #0: loss = 0.00846829 (* 1 = 0.00846829 loss)
I0616 18:48:25.229624 29366 sgd_solver.cpp:105] Iteration 89050, lr = 0.001
I0616 18:49:22.956234 29366 solver.cpp:218] Iteration 89100 (0.86616 iter/s, 57.726s/50 iters), loss = 0.00746607
I0616 18:49:22.956408 29366 solver.cpp:237]     Train net output #0: loss = 0.00746612 (* 1 = 0.00746612 loss)
I0616 18:49:22.956434 29366 sgd_solver.cpp:105] Iteration 89100, lr = 0.001
I0616 18:50:20.690114 29366 solver.cpp:218] Iteration 89150 (0.866054 iter/s, 57.7331s/50 iters), loss = 0.00680599
I0616 18:50:20.690243 29366 solver.cpp:237]     Train net output #0: loss = 0.00680605 (* 1 = 0.00680605 loss)
I0616 18:50:20.690268 29366 sgd_solver.cpp:105] Iteration 89150, lr = 0.001
I0616 18:51:18.431677 29366 solver.cpp:218] Iteration 89200 (0.865939 iter/s, 57.7408s/50 iters), loss = 0.00500335
I0616 18:51:18.431852 29366 solver.cpp:237]     Train net output #0: loss = 0.00500341 (* 1 = 0.00500341 loss)
I0616 18:51:18.431884 29366 sgd_solver.cpp:105] Iteration 89200, lr = 0.001
I0616 18:52:16.173830 29366 solver.cpp:218] Iteration 89250 (0.86593 iter/s, 57.7414s/50 iters), loss = 0.00718594
I0616 18:52:16.173970 29366 solver.cpp:237]     Train net output #0: loss = 0.00718599 (* 1 = 0.00718599 loss)
I0616 18:52:16.173995 29366 sgd_solver.cpp:105] Iteration 89250, lr = 0.001
I0616 18:53:13.902125 29366 solver.cpp:218] Iteration 89300 (0.866138 iter/s, 57.7276s/50 iters), loss = 0.00615306
I0616 18:53:13.902281 29366 solver.cpp:237]     Train net output #0: loss = 0.00615311 (* 1 = 0.00615311 loss)
I0616 18:53:13.902304 29366 sgd_solver.cpp:105] Iteration 89300, lr = 0.001
I0616 18:54:11.636231 29366 solver.cpp:218] Iteration 89350 (0.866051 iter/s, 57.7333s/50 iters), loss = 0.00633794
I0616 18:54:11.636368 29366 solver.cpp:237]     Train net output #0: loss = 0.006338 (* 1 = 0.006338 loss)
I0616 18:54:11.636391 29366 sgd_solver.cpp:105] Iteration 89350, lr = 0.001
I0616 18:55:09.369344 29366 solver.cpp:218] Iteration 89400 (0.866066 iter/s, 57.7323s/50 iters), loss = 0.00742663
I0616 18:55:09.369541 29366 solver.cpp:237]     Train net output #0: loss = 0.00742668 (* 1 = 0.00742668 loss)
I0616 18:55:09.369575 29366 sgd_solver.cpp:105] Iteration 89400, lr = 0.001
I0616 18:56:07.103868 29366 solver.cpp:218] Iteration 89450 (0.866045 iter/s, 57.7337s/50 iters), loss = 0.00569046
I0616 18:56:07.104068 29366 solver.cpp:237]     Train net output #0: loss = 0.00569052 (* 1 = 0.00569052 loss)
I0616 18:56:07.104094 29366 sgd_solver.cpp:105] Iteration 89450, lr = 0.001
I0616 18:57:04.840538 29366 solver.cpp:218] Iteration 89500 (0.866013 iter/s, 57.7359s/50 iters), loss = 0.00615045
I0616 18:57:04.840759 29366 solver.cpp:237]     Train net output #0: loss = 0.0061505 (* 1 = 0.0061505 loss)
I0616 18:57:04.840783 29366 sgd_solver.cpp:105] Iteration 89500, lr = 0.001
I0616 18:58:02.585582 29366 solver.cpp:218] Iteration 89550 (0.865887 iter/s, 57.7442s/50 iters), loss = 0.00814059
I0616 18:58:02.585757 29366 solver.cpp:237]     Train net output #0: loss = 0.00814064 (* 1 = 0.00814064 loss)
I0616 18:58:02.585782 29366 sgd_solver.cpp:105] Iteration 89550, lr = 0.001
I0616 18:59:00.323918 29366 solver.cpp:218] Iteration 89600 (0.865987 iter/s, 57.7376s/50 iters), loss = 0.00595081
I0616 18:59:00.324057 29366 solver.cpp:237]     Train net output #0: loss = 0.00595087 (* 1 = 0.00595087 loss)
I0616 18:59:00.324080 29366 sgd_solver.cpp:105] Iteration 89600, lr = 0.001
I0616 18:59:58.060734 29366 solver.cpp:218] Iteration 89650 (0.86601 iter/s, 57.7361s/50 iters), loss = 0.00400206
I0616 18:59:58.060886 29366 solver.cpp:237]     Train net output #0: loss = 0.00400211 (* 1 = 0.00400211 loss)
I0616 18:59:58.060917 29366 sgd_solver.cpp:105] Iteration 89650, lr = 0.001
I0616 19:00:55.783253 29366 solver.cpp:218] Iteration 89700 (0.866224 iter/s, 57.7218s/50 iters), loss = 0.00463357
I0616 19:00:55.783413 29366 solver.cpp:237]     Train net output #0: loss = 0.00463362 (* 1 = 0.00463362 loss)
I0616 19:00:55.783437 29366 sgd_solver.cpp:105] Iteration 89700, lr = 0.001
I0616 19:01:53.520016 29366 solver.cpp:218] Iteration 89750 (0.86601 iter/s, 57.736s/50 iters), loss = 0.00543963
I0616 19:01:53.520205 29366 solver.cpp:237]     Train net output #0: loss = 0.00543969 (* 1 = 0.00543969 loss)
I0616 19:01:53.520229 29366 sgd_solver.cpp:105] Iteration 89750, lr = 0.001
I0616 19:02:51.261123 29366 solver.cpp:218] Iteration 89800 (0.865946 iter/s, 57.7403s/50 iters), loss = 0.00686906
I0616 19:02:51.261279 29366 solver.cpp:237]     Train net output #0: loss = 0.00686911 (* 1 = 0.00686911 loss)
I0616 19:02:51.261303 29366 sgd_solver.cpp:105] Iteration 89800, lr = 0.001
I0616 19:03:49.020726 29366 solver.cpp:218] Iteration 89850 (0.865668 iter/s, 57.7589s/50 iters), loss = 0.00768975
I0616 19:03:49.020892 29366 solver.cpp:237]     Train net output #0: loss = 0.0076898 (* 1 = 0.0076898 loss)
I0616 19:03:49.020917 29366 sgd_solver.cpp:105] Iteration 89850, lr = 0.001
I0616 19:04:46.762217 29366 solver.cpp:218] Iteration 89900 (0.86594 iter/s, 57.7407s/50 iters), loss = 0.00653692
I0616 19:04:46.762413 29366 solver.cpp:237]     Train net output #0: loss = 0.00653698 (* 1 = 0.00653698 loss)
I0616 19:04:46.762437 29366 sgd_solver.cpp:105] Iteration 89900, lr = 0.001
I0616 19:05:44.501868 29366 solver.cpp:218] Iteration 89950 (0.865968 iter/s, 57.7389s/50 iters), loss = 0.009208
I0616 19:05:44.502038 29366 solver.cpp:237]     Train net output #0: loss = 0.00920806 (* 1 = 0.00920806 loss)
I0616 19:05:44.502063 29366 sgd_solver.cpp:105] Iteration 89950, lr = 0.001
I0616 19:06:41.084650 29366 solver.cpp:447] Snapshotting to binary proto file mobilenet/mobile_2_iter_90000.caffemodel
I0616 19:06:41.161725 29366 sgd_solver.cpp:273] Snapshotting solver state to binary proto file mobilenet/mobile_2_iter_90000.solverstate
I0616 19:06:42.340962 29366 solver.cpp:218] Iteration 90000 (0.864478 iter/s, 57.8384s/50 iters), loss = 0.00560176
I0616 19:06:42.341040 29366 solver.cpp:237]     Train net output #0: loss = 0.00560182 (* 1 = 0.00560182 loss)
I0616 19:06:42.341063 29366 sgd_solver.cpp:105] Iteration 90000, lr = 0.001
I0616 19:07:40.076922 29366 solver.cpp:218] Iteration 90050 (0.866021 iter/s, 57.7353s/50 iters), loss = 0.00506392
I0616 19:07:40.077054 29366 solver.cpp:237]     Train net output #0: loss = 0.00506397 (* 1 = 0.00506397 loss)
I0616 19:07:40.077077 29366 sgd_solver.cpp:105] Iteration 90050, lr = 0.001
I0616 19:08:37.819900 29366 solver.cpp:218] Iteration 90100 (0.865917 iter/s, 57.7423s/50 iters), loss = 0.0068134
I0616 19:08:37.820257 29366 solver.cpp:237]     Train net output #0: loss = 0.00681346 (* 1 = 0.00681346 loss)
I0616 19:08:37.820294 29366 sgd_solver.cpp:105] Iteration 90100, lr = 0.001
I0616 19:09:35.577356 29366 solver.cpp:218] Iteration 90150 (0.865703 iter/s, 57.7565s/50 iters), loss = 0.00466142
I0616 19:09:35.577520 29366 solver.cpp:237]     Train net output #0: loss = 0.00466147 (* 1 = 0.00466147 loss)
I0616 19:09:35.577545 29366 sgd_solver.cpp:105] Iteration 90150, lr = 0.001
I0616 19:10:33.344243 29366 solver.cpp:218] Iteration 90200 (0.865559 iter/s, 57.7661s/50 iters), loss = 0.00735131
I0616 19:10:33.344427 29366 solver.cpp:237]     Train net output #0: loss = 0.00735137 (* 1 = 0.00735137 loss)
I0616 19:10:33.344454 29366 sgd_solver.cpp:105] Iteration 90200, lr = 0.001
I0616 19:11:31.091419 29366 solver.cpp:218] Iteration 90250 (0.865855 iter/s, 57.7464s/50 iters), loss = 0.00683446
I0616 19:11:31.091567 29366 solver.cpp:237]     Train net output #0: loss = 0.00683452 (* 1 = 0.00683452 loss)
I0616 19:11:31.091598 29366 sgd_solver.cpp:105] Iteration 90250, lr = 0.001
I0616 19:12:28.832106 29366 solver.cpp:218] Iteration 90300 (0.865951 iter/s, 57.74s/50 iters), loss = 0.00527269
I0616 19:12:28.832300 29366 solver.cpp:237]     Train net output #0: loss = 0.00527275 (* 1 = 0.00527275 loss)
I0616 19:12:28.832325 29366 sgd_solver.cpp:105] Iteration 90300, lr = 0.001
I0616 19:13:26.593421 29366 solver.cpp:218] Iteration 90350 (0.865643 iter/s, 57.7605s/50 iters), loss = 0.0060456
I0616 19:13:26.593582 29366 solver.cpp:237]     Train net output #0: loss = 0.00604565 (* 1 = 0.00604565 loss)
I0616 19:13:26.593607 29366 sgd_solver.cpp:105] Iteration 90350, lr = 0.001
I0616 19:14:24.349875 29366 solver.cpp:218] Iteration 90400 (0.865715 iter/s, 57.7557s/50 iters), loss = 0.00549323
I0616 19:14:24.350020 29366 solver.cpp:237]     Train net output #0: loss = 0.00549329 (* 1 = 0.00549329 loss)
I0616 19:14:24.350042 29366 sgd_solver.cpp:105] Iteration 90400, lr = 0.001
I0616 19:15:22.098889 29366 solver.cpp:218] Iteration 90450 (0.865827 iter/s, 57.7483s/50 iters), loss = 0.00761307
I0616 19:15:22.099079 29366 solver.cpp:237]     Train net output #0: loss = 0.00761313 (* 1 = 0.00761313 loss)
I0616 19:15:22.099105 29366 sgd_solver.cpp:105] Iteration 90450, lr = 0.001
I0616 19:16:19.861929 29366 solver.cpp:218] Iteration 90500 (0.865617 iter/s, 57.7623s/50 iters), loss = 0.00754653
I0616 19:16:19.862110 29366 solver.cpp:237]     Train net output #0: loss = 0.00754658 (* 1 = 0.00754658 loss)
I0616 19:16:19.862135 29366 sgd_solver.cpp:105] Iteration 90500, lr = 0.001
I0616 19:17:17.615924 29366 solver.cpp:218] Iteration 90550 (0.865752 iter/s, 57.7532s/50 iters), loss = 0.00679123
I0616 19:17:17.616094 29366 solver.cpp:237]     Train net output #0: loss = 0.00679128 (* 1 = 0.00679128 loss)
I0616 19:17:17.616119 29366 sgd_solver.cpp:105] Iteration 90550, lr = 0.001
I0616 19:18:15.352656 29366 solver.cpp:218] Iteration 90600 (0.866011 iter/s, 57.736s/50 iters), loss = 0.00832231
I0616 19:18:15.352784 29366 solver.cpp:237]     Train net output #0: loss = 0.00832236 (* 1 = 0.00832236 loss)
I0616 19:18:15.352807 29366 sgd_solver.cpp:105] Iteration 90600, lr = 0.001
I0616 19:19:13.085582 29366 solver.cpp:218] Iteration 90650 (0.866067 iter/s, 57.7322s/50 iters), loss = 0.00894616
I0616 19:19:13.085719 29366 solver.cpp:237]     Train net output #0: loss = 0.00894621 (* 1 = 0.00894621 loss)
I0616 19:19:13.085743 29366 sgd_solver.cpp:105] Iteration 90650, lr = 0.001
I0616 19:20:10.837333 29366 solver.cpp:218] Iteration 90700 (0.865785 iter/s, 57.751s/50 iters), loss = 0.0140434
I0616 19:20:10.837484 29366 solver.cpp:237]     Train net output #0: loss = 0.0140435 (* 1 = 0.0140435 loss)
I0616 19:20:10.837509 29366 sgd_solver.cpp:105] Iteration 90700, lr = 0.001
I0616 19:21:08.578814 29366 solver.cpp:218] Iteration 90750 (0.865939 iter/s, 57.7408s/50 iters), loss = 0.00948019
I0616 19:21:08.578955 29366 solver.cpp:237]     Train net output #0: loss = 0.00948025 (* 1 = 0.00948025 loss)
I0616 19:21:08.578979 29366 sgd_solver.cpp:105] Iteration 90750, lr = 0.001
I0616 19:22:06.327780 29366 solver.cpp:218] Iteration 90800 (0.865827 iter/s, 57.7482s/50 iters), loss = 0.00560894
I0616 19:22:06.328016 29366 solver.cpp:237]     Train net output #0: loss = 0.00560899 (* 1 = 0.00560899 loss)
I0616 19:22:06.328047 29366 sgd_solver.cpp:105] Iteration 90800, lr = 0.001
I0616 19:23:04.063143 29366 solver.cpp:218] Iteration 90850 (0.866032 iter/s, 57.7346s/50 iters), loss = 0.00711194
I0616 19:23:04.063316 29366 solver.cpp:237]     Train net output #0: loss = 0.007112 (* 1 = 0.007112 loss)
I0616 19:23:04.063340 29366 sgd_solver.cpp:105] Iteration 90850, lr = 0.001
I0616 19:24:01.801434 29366 solver.cpp:218] Iteration 90900 (0.865988 iter/s, 57.7375s/50 iters), loss = 0.0061496
I0616 19:24:01.801602 29366 solver.cpp:237]     Train net output #0: loss = 0.00614965 (* 1 = 0.00614965 loss)
I0616 19:24:01.801627 29366 sgd_solver.cpp:105] Iteration 90900, lr = 0.001
I0616 19:24:59.542538 29366 solver.cpp:218] Iteration 90950 (0.865945 iter/s, 57.7404s/50 iters), loss = 0.00404561
I0616 19:24:59.542681 29366 solver.cpp:237]     Train net output #0: loss = 0.00404566 (* 1 = 0.00404566 loss)
I0616 19:24:59.542704 29366 sgd_solver.cpp:105] Iteration 90950, lr = 0.001
I0616 19:25:57.280540 29366 solver.cpp:218] Iteration 91000 (0.865992 iter/s, 57.7373s/50 iters), loss = 0.00674832
I0616 19:25:57.280725 29366 solver.cpp:237]     Train net output #0: loss = 0.00674837 (* 1 = 0.00674837 loss)
I0616 19:25:57.280750 29366 sgd_solver.cpp:105] Iteration 91000, lr = 0.001
I0616 19:26:55.031222 29366 solver.cpp:218] Iteration 91050 (0.865802 iter/s, 57.7499s/50 iters), loss = 0.00450847
I0616 19:26:55.031400 29366 solver.cpp:237]     Train net output #0: loss = 0.00450852 (* 1 = 0.00450852 loss)
I0616 19:26:55.031426 29366 sgd_solver.cpp:105] Iteration 91050, lr = 0.001
I0616 19:27:52.775898 29366 solver.cpp:218] Iteration 91100 (0.865892 iter/s, 57.7439s/50 iters), loss = 0.0055274
I0616 19:27:52.776875 29366 solver.cpp:237]     Train net output #0: loss = 0.00552745 (* 1 = 0.00552745 loss)
I0616 19:27:52.776899 29366 sgd_solver.cpp:105] Iteration 91100, lr = 0.001
I0616 19:28:50.529592 29366 solver.cpp:218] Iteration 91150 (0.865769 iter/s, 57.7521s/50 iters), loss = 0.00654787
I0616 19:28:50.530344 29366 solver.cpp:237]     Train net output #0: loss = 0.00654793 (* 1 = 0.00654793 loss)
I0616 19:28:50.530375 29366 sgd_solver.cpp:105] Iteration 91150, lr = 0.001
I0616 19:29:48.279647 29366 solver.cpp:218] Iteration 91200 (0.865819 iter/s, 57.7488s/50 iters), loss = 0.00923656
I0616 19:29:48.279788 29366 solver.cpp:237]     Train net output #0: loss = 0.00923661 (* 1 = 0.00923661 loss)
I0616 19:29:48.279811 29366 sgd_solver.cpp:105] Iteration 91200, lr = 0.001
I0616 19:30:46.038208 29366 solver.cpp:218] Iteration 91250 (0.865682 iter/s, 57.7579s/50 iters), loss = 0.00783983
I0616 19:30:46.038359 29366 solver.cpp:237]     Train net output #0: loss = 0.00783988 (* 1 = 0.00783988 loss)
I0616 19:30:46.038383 29366 sgd_solver.cpp:105] Iteration 91250, lr = 0.001
I0616 19:31:43.784380 29366 solver.cpp:218] Iteration 91300 (0.865868 iter/s, 57.7455s/50 iters), loss = 0.00638597
I0616 19:31:43.784618 29366 solver.cpp:237]     Train net output #0: loss = 0.00638602 (* 1 = 0.00638602 loss)
I0616 19:31:43.784641 29366 sgd_solver.cpp:105] Iteration 91300, lr = 0.001
I0616 19:32:41.540897 29366 solver.cpp:218] Iteration 91350 (0.865714 iter/s, 57.7558s/50 iters), loss = 0.00759442
I0616 19:32:41.541055 29366 solver.cpp:237]     Train net output #0: loss = 0.00759448 (* 1 = 0.00759448 loss)
I0616 19:32:41.541081 29366 sgd_solver.cpp:105] Iteration 91350, lr = 0.001
I0616 19:33:39.287093 29366 solver.cpp:218] Iteration 91400 (0.865868 iter/s, 57.7455s/50 iters), loss = 0.00596416
I0616 19:33:39.287240 29366 solver.cpp:237]     Train net output #0: loss = 0.00596421 (* 1 = 0.00596421 loss)
I0616 19:33:39.287264 29366 sgd_solver.cpp:105] Iteration 91400, lr = 0.001
I0616 19:34:37.051483 29366 solver.cpp:218] Iteration 91450 (0.865595 iter/s, 57.7637s/50 iters), loss = 0.00982236
I0616 19:34:37.051667 29366 solver.cpp:237]     Train net output #0: loss = 0.00982242 (* 1 = 0.00982242 loss)
I0616 19:34:37.051692 29366 sgd_solver.cpp:105] Iteration 91450, lr = 0.001
I0616 19:35:34.802217 29366 solver.cpp:218] Iteration 91500 (0.8658 iter/s, 57.7501s/50 iters), loss = 0.00755036
I0616 19:35:34.802475 29366 solver.cpp:237]     Train net output #0: loss = 0.00755041 (* 1 = 0.00755041 loss)
I0616 19:35:34.802501 29366 sgd_solver.cpp:105] Iteration 91500, lr = 0.001
I0616 19:36:32.552194 29366 solver.cpp:218] Iteration 91550 (0.865812 iter/s, 57.7492s/50 iters), loss = 0.0057358
I0616 19:36:32.552356 29366 solver.cpp:237]     Train net output #0: loss = 0.00573586 (* 1 = 0.00573586 loss)
I0616 19:36:32.552378 29366 sgd_solver.cpp:105] Iteration 91550, lr = 0.001
I0616 19:37:30.304134 29366 solver.cpp:218] Iteration 91600 (0.865782 iter/s, 57.7513s/50 iters), loss = 0.00485847
I0616 19:37:30.304307 29366 solver.cpp:237]     Train net output #0: loss = 0.00485853 (* 1 = 0.00485853 loss)
I0616 19:37:30.304337 29366 sgd_solver.cpp:105] Iteration 91600, lr = 0.001
I0616 19:38:28.063635 29366 solver.cpp:218] Iteration 91650 (0.865668 iter/s, 57.7588s/50 iters), loss = 0.00693952
I0616 19:38:28.063781 29366 solver.cpp:237]     Train net output #0: loss = 0.00693957 (* 1 = 0.00693957 loss)
I0616 19:38:28.063804 29366 sgd_solver.cpp:105] Iteration 91650, lr = 0.001
I0616 19:39:25.825381 29366 solver.cpp:218] Iteration 91700 (0.865635 iter/s, 57.7611s/50 iters), loss = 0.00524933
I0616 19:39:25.825551 29366 solver.cpp:237]     Train net output #0: loss = 0.00524938 (* 1 = 0.00524938 loss)
I0616 19:39:25.825578 29366 sgd_solver.cpp:105] Iteration 91700, lr = 0.001
I0616 19:40:23.588768 29366 solver.cpp:218] Iteration 91750 (0.865611 iter/s, 57.7627s/50 iters), loss = 0.00627435
I0616 19:40:23.588973 29366 solver.cpp:237]     Train net output #0: loss = 0.00627441 (* 1 = 0.00627441 loss)
I0616 19:40:23.588999 29366 sgd_solver.cpp:105] Iteration 91750, lr = 0.001
I0616 19:41:21.348292 29366 solver.cpp:218] Iteration 91800 (0.865669 iter/s, 57.7588s/50 iters), loss = 0.00468436
I0616 19:41:21.348475 29366 solver.cpp:237]     Train net output #0: loss = 0.00468441 (* 1 = 0.00468441 loss)
I0616 19:41:21.348500 29366 sgd_solver.cpp:105] Iteration 91800, lr = 0.001
I0616 19:42:19.111271 29366 solver.cpp:218] Iteration 91850 (0.865617 iter/s, 57.7623s/50 iters), loss = 0.00572444
I0616 19:42:19.111491 29366 solver.cpp:237]     Train net output #0: loss = 0.0057245 (* 1 = 0.0057245 loss)
I0616 19:42:19.111523 29366 sgd_solver.cpp:105] Iteration 91850, lr = 0.001
I0616 19:43:16.875484 29366 solver.cpp:218] Iteration 91900 (0.865599 iter/s, 57.7635s/50 iters), loss = 0.00490609
I0616 19:43:16.875663 29366 solver.cpp:237]     Train net output #0: loss = 0.00490614 (* 1 = 0.00490614 loss)
I0616 19:43:16.875694 29366 sgd_solver.cpp:105] Iteration 91900, lr = 0.001
I0616 19:44:14.644027 29366 solver.cpp:218] Iteration 91950 (0.865533 iter/s, 57.7679s/50 iters), loss = 0.00534316
I0616 19:44:14.644206 29366 solver.cpp:237]     Train net output #0: loss = 0.00534321 (* 1 = 0.00534321 loss)
I0616 19:44:14.644232 29366 sgd_solver.cpp:105] Iteration 91950, lr = 0.001
I0616 19:45:12.411823 29366 solver.cpp:218] Iteration 92000 (0.865544 iter/s, 57.7671s/50 iters), loss = 0.0084547
I0616 19:45:12.411995 29366 solver.cpp:237]     Train net output #0: loss = 0.00845475 (* 1 = 0.00845475 loss)
I0616 19:45:12.412019 29366 sgd_solver.cpp:105] Iteration 92000, lr = 0.001
I0616 19:46:10.174499 29366 solver.cpp:218] Iteration 92050 (0.865621 iter/s, 57.762s/50 iters), loss = 0.00793933
I0616 19:46:10.174674 29366 solver.cpp:237]     Train net output #0: loss = 0.00793939 (* 1 = 0.00793939 loss)
I0616 19:46:10.174700 29366 sgd_solver.cpp:105] Iteration 92050, lr = 0.001
I0616 19:47:07.941088 29366 solver.cpp:218] Iteration 92100 (0.865563 iter/s, 57.7659s/50 iters), loss = 0.00626078
I0616 19:47:07.941269 29366 solver.cpp:237]     Train net output #0: loss = 0.00626084 (* 1 = 0.00626084 loss)
I0616 19:47:07.941303 29366 sgd_solver.cpp:105] Iteration 92100, lr = 0.001
I0616 19:48:05.685822 29366 solver.cpp:218] Iteration 92150 (0.86589 iter/s, 57.744s/50 iters), loss = 0.00698271
I0616 19:48:05.686061 29366 solver.cpp:237]     Train net output #0: loss = 0.00698276 (* 1 = 0.00698276 loss)
I0616 19:48:05.686084 29366 sgd_solver.cpp:105] Iteration 92150, lr = 0.001
I0616 19:49:03.434834 29366 solver.cpp:218] Iteration 92200 (0.865827 iter/s, 57.7483s/50 iters), loss = 0.00632767
I0616 19:49:03.434945 29366 solver.cpp:237]     Train net output #0: loss = 0.00632773 (* 1 = 0.00632773 loss)
I0616 19:49:03.434970 29366 sgd_solver.cpp:105] Iteration 92200, lr = 0.001
I0616 19:50:01.182498 29366 solver.cpp:218] Iteration 92250 (0.865845 iter/s, 57.747s/50 iters), loss = 0.00638398
I0616 19:50:01.182639 29366 solver.cpp:237]     Train net output #0: loss = 0.00638403 (* 1 = 0.00638403 loss)
I0616 19:50:01.182663 29366 sgd_solver.cpp:105] Iteration 92250, lr = 0.001
I0616 19:50:58.923301 29366 solver.cpp:218] Iteration 92300 (0.865948 iter/s, 57.7402s/50 iters), loss = 0.00669944
I0616 19:50:58.923430 29366 solver.cpp:237]     Train net output #0: loss = 0.00669949 (* 1 = 0.00669949 loss)
I0616 19:50:58.923455 29366 sgd_solver.cpp:105] Iteration 92300, lr = 0.001
I0616 19:51:56.671710 29366 solver.cpp:218] Iteration 92350 (0.865834 iter/s, 57.7478s/50 iters), loss = 0.00633609
I0616 19:51:56.671844 29366 solver.cpp:237]     Train net output #0: loss = 0.00633615 (* 1 = 0.00633615 loss)
I0616 19:51:56.671869 29366 sgd_solver.cpp:105] Iteration 92350, lr = 0.001
I0616 19:52:54.418980 29366 solver.cpp:218] Iteration 92400 (0.865851 iter/s, 57.7466s/50 iters), loss = 0.00697712
I0616 19:52:54.419108 29366 solver.cpp:237]     Train net output #0: loss = 0.00697717 (* 1 = 0.00697717 loss)
I0616 19:52:54.419134 29366 sgd_solver.cpp:105] Iteration 92400, lr = 0.001
I0616 19:53:52.154067 29366 solver.cpp:218] Iteration 92450 (0.866034 iter/s, 57.7344s/50 iters), loss = 0.00791514
I0616 19:53:52.154206 29366 solver.cpp:237]     Train net output #0: loss = 0.00791519 (* 1 = 0.00791519 loss)
I0616 19:53:52.154232 29366 sgd_solver.cpp:105] Iteration 92450, lr = 0.001
I0616 19:54:49.907837 29366 solver.cpp:218] Iteration 92500 (0.865754 iter/s, 57.7531s/50 iters), loss = 0.0069844
I0616 19:54:49.908001 29366 solver.cpp:237]     Train net output #0: loss = 0.00698446 (* 1 = 0.00698446 loss)
I0616 19:54:49.908025 29366 sgd_solver.cpp:105] Iteration 92500, lr = 0.001
I0616 19:55:47.664278 29366 solver.cpp:218] Iteration 92550 (0.865714 iter/s, 57.7558s/50 iters), loss = 0.00562083
I0616 19:55:47.664439 29366 solver.cpp:237]     Train net output #0: loss = 0.00562089 (* 1 = 0.00562089 loss)
I0616 19:55:47.664464 29366 sgd_solver.cpp:105] Iteration 92550, lr = 0.001
I0616 19:56:45.403370 29366 solver.cpp:218] Iteration 92600 (0.865975 iter/s, 57.7384s/50 iters), loss = 0.00657314
I0616 19:56:45.403507 29366 solver.cpp:237]     Train net output #0: loss = 0.00657319 (* 1 = 0.00657319 loss)
I0616 19:56:45.403544 29366 sgd_solver.cpp:105] Iteration 92600, lr = 0.001
I0616 19:57:43.153836 29366 solver.cpp:218] Iteration 92650 (0.865804 iter/s, 57.7498s/50 iters), loss = 0.00654624
I0616 19:57:43.154019 29366 solver.cpp:237]     Train net output #0: loss = 0.00654629 (* 1 = 0.00654629 loss)
I0616 19:57:43.154045 29366 sgd_solver.cpp:105] Iteration 92650, lr = 0.001
I0616 19:58:40.906304 29366 solver.cpp:218] Iteration 92700 (0.865774 iter/s, 57.7518s/50 iters), loss = 0.00553151
I0616 19:58:40.906445 29366 solver.cpp:237]     Train net output #0: loss = 0.00553157 (* 1 = 0.00553157 loss)
I0616 19:58:40.906468 29366 sgd_solver.cpp:105] Iteration 92700, lr = 0.001
I0616 19:59:38.655544 29366 solver.cpp:218] Iteration 92750 (0.865822 iter/s, 57.7486s/50 iters), loss = 0.00677738
I0616 19:59:38.655730 29366 solver.cpp:237]     Train net output #0: loss = 0.00677744 (* 1 = 0.00677744 loss)
I0616 19:59:38.655755 29366 sgd_solver.cpp:105] Iteration 92750, lr = 0.001
I0616 20:00:36.408524 29366 solver.cpp:218] Iteration 92800 (0.865767 iter/s, 57.7523s/50 iters), loss = 0.00696784
I0616 20:00:36.408746 29366 solver.cpp:237]     Train net output #0: loss = 0.00696789 (* 1 = 0.00696789 loss)
I0616 20:00:36.408771 29366 sgd_solver.cpp:105] Iteration 92800, lr = 0.001
I0616 20:01:34.150863 29366 solver.cpp:218] Iteration 92850 (0.865927 iter/s, 57.7416s/50 iters), loss = 0.00426097
I0616 20:01:34.150992 29366 solver.cpp:237]     Train net output #0: loss = 0.00426102 (* 1 = 0.00426102 loss)
I0616 20:01:34.151015 29366 sgd_solver.cpp:105] Iteration 92850, lr = 0.001
I0616 20:02:31.898183 29366 solver.cpp:218] Iteration 92900 (0.865851 iter/s, 57.7467s/50 iters), loss = 0.00721814
I0616 20:02:31.898316 29366 solver.cpp:237]     Train net output #0: loss = 0.0072182 (* 1 = 0.0072182 loss)
I0616 20:02:31.898340 29366 sgd_solver.cpp:105] Iteration 92900, lr = 0.001
I0616 20:03:29.646873 29366 solver.cpp:218] Iteration 92950 (0.86583 iter/s, 57.7481s/50 iters), loss = 0.00579245
I0616 20:03:29.647011 29366 solver.cpp:237]     Train net output #0: loss = 0.0057925 (* 1 = 0.0057925 loss)
I0616 20:03:29.647035 29366 sgd_solver.cpp:105] Iteration 92950, lr = 0.001
I0616 20:04:27.398087 29366 solver.cpp:218] Iteration 93000 (0.865792 iter/s, 57.7506s/50 iters), loss = 0.00692867
I0616 20:04:27.398237 29366 solver.cpp:237]     Train net output #0: loss = 0.00692873 (* 1 = 0.00692873 loss)
I0616 20:04:27.398262 29366 sgd_solver.cpp:105] Iteration 93000, lr = 0.001
I0616 20:05:25.147372 29366 solver.cpp:218] Iteration 93050 (0.865821 iter/s, 57.7487s/50 iters), loss = 0.00548171
I0616 20:05:25.147505 29366 solver.cpp:237]     Train net output #0: loss = 0.00548176 (* 1 = 0.00548176 loss)
I0616 20:05:25.147536 29366 sgd_solver.cpp:105] Iteration 93050, lr = 0.001
I0616 20:06:22.894631 29366 solver.cpp:218] Iteration 93100 (0.865851 iter/s, 57.7467s/50 iters), loss = 0.0046762
I0616 20:06:22.894804 29366 solver.cpp:237]     Train net output #0: loss = 0.00467625 (* 1 = 0.00467625 loss)
I0616 20:06:22.894829 29366 sgd_solver.cpp:105] Iteration 93100, lr = 0.001
I0616 20:07:20.643759 29366 solver.cpp:218] Iteration 93150 (0.865824 iter/s, 57.7485s/50 iters), loss = 0.00657313
I0616 20:07:20.643937 29366 solver.cpp:237]     Train net output #0: loss = 0.00657319 (* 1 = 0.00657319 loss)
I0616 20:07:20.643963 29366 sgd_solver.cpp:105] Iteration 93150, lr = 0.001
I0616 20:08:18.398651 29366 solver.cpp:218] Iteration 93200 (0.865738 iter/s, 57.7542s/50 iters), loss = 0.00403726
I0616 20:08:18.398820 29366 solver.cpp:237]     Train net output #0: loss = 0.00403731 (* 1 = 0.00403731 loss)
I0616 20:08:18.398852 29366 sgd_solver.cpp:105] Iteration 93200, lr = 0.001
I0616 20:09:16.141237 29366 solver.cpp:218] Iteration 93250 (0.865921 iter/s, 57.742s/50 iters), loss = 0.00706721
I0616 20:09:16.141382 29366 solver.cpp:237]     Train net output #0: loss = 0.00706726 (* 1 = 0.00706726 loss)
I0616 20:09:16.141408 29366 sgd_solver.cpp:105] Iteration 93250, lr = 0.001
I0616 20:10:13.891639 29366 solver.cpp:218] Iteration 93300 (0.865804 iter/s, 57.7498s/50 iters), loss = 0.00564112
I0616 20:10:13.891780 29366 solver.cpp:237]     Train net output #0: loss = 0.00564117 (* 1 = 0.00564117 loss)
I0616 20:10:13.891804 29366 sgd_solver.cpp:105] Iteration 93300, lr = 0.001
I0616 20:11:11.638392 29366 solver.cpp:218] Iteration 93350 (0.865859 iter/s, 57.7461s/50 iters), loss = 0.00631139
I0616 20:11:11.638579 29366 solver.cpp:237]     Train net output #0: loss = 0.00631145 (* 1 = 0.00631145 loss)
I0616 20:11:11.638607 29366 sgd_solver.cpp:105] Iteration 93350, lr = 0.001
I0616 20:12:09.379101 29366 solver.cpp:218] Iteration 93400 (0.86595 iter/s, 57.74s/50 iters), loss = 0.0057171
I0616 20:12:09.379356 29366 solver.cpp:237]     Train net output #0: loss = 0.00571715 (* 1 = 0.00571715 loss)
I0616 20:12:09.379381 29366 sgd_solver.cpp:105] Iteration 93400, lr = 0.001
I0616 20:13:07.130041 29366 solver.cpp:218] Iteration 93450 (0.865798 iter/s, 57.7502s/50 iters), loss = 0.00509814
I0616 20:13:07.130179 29366 solver.cpp:237]     Train net output #0: loss = 0.0050982 (* 1 = 0.0050982 loss)
I0616 20:13:07.130204 29366 sgd_solver.cpp:105] Iteration 93450, lr = 0.001
I0616 20:14:04.872095 29366 solver.cpp:218] Iteration 93500 (0.865929 iter/s, 57.7415s/50 iters), loss = 0.00482097
I0616 20:14:04.872303 29366 solver.cpp:237]     Train net output #0: loss = 0.00482102 (* 1 = 0.00482102 loss)
I0616 20:14:04.872340 29366 sgd_solver.cpp:105] Iteration 93500, lr = 0.001
I0616 20:15:02.617702 29366 solver.cpp:218] Iteration 93550 (0.865877 iter/s, 57.7449s/50 iters), loss = 0.00621974
I0616 20:15:02.617857 29366 solver.cpp:237]     Train net output #0: loss = 0.00621979 (* 1 = 0.00621979 loss)
I0616 20:15:02.617882 29366 sgd_solver.cpp:105] Iteration 93550, lr = 0.001
I0616 20:16:00.354756 29366 solver.cpp:218] Iteration 93600 (0.866004 iter/s, 57.7364s/50 iters), loss = 0.00726913
I0616 20:16:00.354864 29366 solver.cpp:237]     Train net output #0: loss = 0.00726918 (* 1 = 0.00726918 loss)
I0616 20:16:00.354889 29366 sgd_solver.cpp:105] Iteration 93600, lr = 0.001
I0616 20:16:58.097512 29366 solver.cpp:218] Iteration 93650 (0.865918 iter/s, 57.7422s/50 iters), loss = 0.00766258
I0616 20:16:58.097640 29366 solver.cpp:237]     Train net output #0: loss = 0.00766263 (* 1 = 0.00766263 loss)
I0616 20:16:58.097663 29366 sgd_solver.cpp:105] Iteration 93650, lr = 0.001
I0616 20:17:55.837596 29366 solver.cpp:218] Iteration 93700 (0.865959 iter/s, 57.7395s/50 iters), loss = 0.00615347
I0616 20:17:55.837788 29366 solver.cpp:237]     Train net output #0: loss = 0.00615352 (* 1 = 0.00615352 loss)
I0616 20:17:55.837813 29366 sgd_solver.cpp:105] Iteration 93700, lr = 0.001
I0616 20:18:53.592690 29366 solver.cpp:218] Iteration 93750 (0.865735 iter/s, 57.7544s/50 iters), loss = 0.00426625
I0616 20:18:53.592870 29366 solver.cpp:237]     Train net output #0: loss = 0.00426631 (* 1 = 0.00426631 loss)
I0616 20:18:53.592910 29366 sgd_solver.cpp:105] Iteration 93750, lr = 0.001
I0616 20:19:51.339449 29366 solver.cpp:218] Iteration 93800 (0.865859 iter/s, 57.7461s/50 iters), loss = 0.00507709
I0616 20:19:51.339603 29366 solver.cpp:237]     Train net output #0: loss = 0.00507714 (* 1 = 0.00507714 loss)
I0616 20:19:51.339628 29366 sgd_solver.cpp:105] Iteration 93800, lr = 0.001
I0616 20:20:49.098841 29366 solver.cpp:218] Iteration 93850 (0.86567 iter/s, 57.7587s/50 iters), loss = 0.00834384
I0616 20:20:49.098975 29366 solver.cpp:237]     Train net output #0: loss = 0.00834389 (* 1 = 0.00834389 loss)
I0616 20:20:49.099006 29366 sgd_solver.cpp:105] Iteration 93850, lr = 0.001
I0616 20:21:46.842859 29366 solver.cpp:218] Iteration 93900 (0.8659 iter/s, 57.7434s/50 iters), loss = 0.00758862
I0616 20:21:46.842993 29366 solver.cpp:237]     Train net output #0: loss = 0.00758867 (* 1 = 0.00758867 loss)
I0616 20:21:46.843016 29366 sgd_solver.cpp:105] Iteration 93900, lr = 0.001
I0616 20:22:44.594876 29366 solver.cpp:218] Iteration 93950 (0.86578 iter/s, 57.7514s/50 iters), loss = 0.00516839
I0616 20:22:44.595067 29366 solver.cpp:237]     Train net output #0: loss = 0.00516844 (* 1 = 0.00516844 loss)
I0616 20:22:44.595093 29366 sgd_solver.cpp:105] Iteration 93950, lr = 0.001
I0616 20:23:42.337821 29366 solver.cpp:218] Iteration 94000 (0.865917 iter/s, 57.7423s/50 iters), loss = 0.00551116
I0616 20:23:42.338008 29366 solver.cpp:237]     Train net output #0: loss = 0.00551122 (* 1 = 0.00551122 loss)
I0616 20:23:42.338032 29366 sgd_solver.cpp:105] Iteration 94000, lr = 0.001
I0616 20:24:40.084426 29366 solver.cpp:218] Iteration 94050 (0.865862 iter/s, 57.7459s/50 iters), loss = 0.00462779
I0616 20:24:40.084584 29366 solver.cpp:237]     Train net output #0: loss = 0.00462784 (* 1 = 0.00462784 loss)
I0616 20:24:40.084610 29366 sgd_solver.cpp:105] Iteration 94050, lr = 0.001
I0616 20:25:37.829377 29366 solver.cpp:218] Iteration 94100 (0.865886 iter/s, 57.7443s/50 iters), loss = 0.00797673
I0616 20:25:37.829537 29366 solver.cpp:237]     Train net output #0: loss = 0.00797678 (* 1 = 0.00797678 loss)
I0616 20:25:37.829562 29366 sgd_solver.cpp:105] Iteration 94100, lr = 0.001
I0616 20:26:35.587849 29366 solver.cpp:218] Iteration 94150 (0.865684 iter/s, 57.7578s/50 iters), loss = 0.00696607
I0616 20:26:35.588055 29366 solver.cpp:237]     Train net output #0: loss = 0.00696612 (* 1 = 0.00696612 loss)
I0616 20:26:35.588081 29366 sgd_solver.cpp:105] Iteration 94150, lr = 0.001
I0616 20:27:33.335712 29366 solver.cpp:218] Iteration 94200 (0.865843 iter/s, 57.7472s/50 iters), loss = 0.00524819
I0616 20:27:33.335909 29366 solver.cpp:237]     Train net output #0: loss = 0.00524824 (* 1 = 0.00524824 loss)
I0616 20:27:33.335934 29366 sgd_solver.cpp:105] Iteration 94200, lr = 0.001
I0616 20:28:31.089817 29366 solver.cpp:218] Iteration 94250 (0.865749 iter/s, 57.7534s/50 iters), loss = 0.00422493
I0616 20:28:31.089967 29366 solver.cpp:237]     Train net output #0: loss = 0.00422498 (* 1 = 0.00422498 loss)
I0616 20:28:31.089989 29366 sgd_solver.cpp:105] Iteration 94250, lr = 0.001
I0616 20:29:28.826288 29366 solver.cpp:218] Iteration 94300 (0.866013 iter/s, 57.7358s/50 iters), loss = 0.00658051
I0616 20:29:28.826439 29366 solver.cpp:237]     Train net output #0: loss = 0.00658056 (* 1 = 0.00658056 loss)
I0616 20:29:28.826464 29366 sgd_solver.cpp:105] Iteration 94300, lr = 0.001
I0616 20:30:26.569526 29366 solver.cpp:218] Iteration 94350 (0.865912 iter/s, 57.7426s/50 iters), loss = 0.00489252
I0616 20:30:26.569674 29366 solver.cpp:237]     Train net output #0: loss = 0.00489258 (* 1 = 0.00489258 loss)
I0616 20:30:26.569697 29366 sgd_solver.cpp:105] Iteration 94350, lr = 0.001
I0616 20:31:24.317844 29366 solver.cpp:218] Iteration 94400 (0.865835 iter/s, 57.7477s/50 iters), loss = 0.0102022
I0616 20:31:24.318011 29366 solver.cpp:237]     Train net output #0: loss = 0.0102023 (* 1 = 0.0102023 loss)
I0616 20:31:24.318037 29366 sgd_solver.cpp:105] Iteration 94400, lr = 0.001
I0616 20:32:22.069424 29366 solver.cpp:218] Iteration 94450 (0.865787 iter/s, 57.7509s/50 iters), loss = 0.00843179
I0616 20:32:22.069607 29366 solver.cpp:237]     Train net output #0: loss = 0.00843184 (* 1 = 0.00843184 loss)
I0616 20:32:22.069631 29366 sgd_solver.cpp:105] Iteration 94450, lr = 0.001
I0616 20:33:19.825654 29366 solver.cpp:218] Iteration 94500 (0.865718 iter/s, 57.7556s/50 iters), loss = 0.00665981
I0616 20:33:19.825850 29366 solver.cpp:237]     Train net output #0: loss = 0.00665987 (* 1 = 0.00665987 loss)
I0616 20:33:19.825876 29366 sgd_solver.cpp:105] Iteration 94500, lr = 0.001
I0616 20:34:17.572679 29366 solver.cpp:218] Iteration 94550 (0.865856 iter/s, 57.7463s/50 iters), loss = 0.00623608
I0616 20:34:17.572877 29366 solver.cpp:237]     Train net output #0: loss = 0.00623613 (* 1 = 0.00623613 loss)
I0616 20:34:17.572903 29366 sgd_solver.cpp:105] Iteration 94550, lr = 0.001
I0616 20:35:15.323282 29366 solver.cpp:218] Iteration 94600 (0.865802 iter/s, 57.7499s/50 iters), loss = 0.00603049
I0616 20:35:15.323424 29366 solver.cpp:237]     Train net output #0: loss = 0.00603055 (* 1 = 0.00603055 loss)
I0616 20:35:15.323447 29366 sgd_solver.cpp:105] Iteration 94600, lr = 0.001
I0616 20:36:13.066045 29366 solver.cpp:218] Iteration 94650 (0.865919 iter/s, 57.7421s/50 iters), loss = 0.00606794
I0616 20:36:13.066234 29366 solver.cpp:237]     Train net output #0: loss = 0.006068 (* 1 = 0.006068 loss)
I0616 20:36:13.066262 29366 sgd_solver.cpp:105] Iteration 94650, lr = 0.001
I0616 20:37:10.812881 29366 solver.cpp:218] Iteration 94700 (0.865858 iter/s, 57.7462s/50 iters), loss = 0.00616871
I0616 20:37:10.813017 29366 solver.cpp:237]     Train net output #0: loss = 0.00616877 (* 1 = 0.00616877 loss)
I0616 20:37:10.813040 29366 sgd_solver.cpp:105] Iteration 94700, lr = 0.001
I0616 20:38:08.556617 29366 solver.cpp:218] Iteration 94750 (0.865904 iter/s, 57.7431s/50 iters), loss = 0.00665035
I0616 20:38:08.556747 29366 solver.cpp:237]     Train net output #0: loss = 0.0066504 (* 1 = 0.0066504 loss)
I0616 20:38:08.556772 29366 sgd_solver.cpp:105] Iteration 94750, lr = 0.001
I0616 20:39:06.298071 29366 solver.cpp:218] Iteration 94800 (0.865938 iter/s, 57.7408s/50 iters), loss = 0.00720674
I0616 20:39:06.298260 29366 solver.cpp:237]     Train net output #0: loss = 0.00720679 (* 1 = 0.00720679 loss)
I0616 20:39:06.298285 29366 sgd_solver.cpp:105] Iteration 94800, lr = 0.001
I0616 20:40:04.047639 29366 solver.cpp:218] Iteration 94850 (0.865817 iter/s, 57.7489s/50 iters), loss = 0.00559459
I0616 20:40:04.047878 29366 solver.cpp:237]     Train net output #0: loss = 0.00559465 (* 1 = 0.00559465 loss)
I0616 20:40:04.047919 29366 sgd_solver.cpp:105] Iteration 94850, lr = 0.001
I0616 20:41:01.786072 29366 solver.cpp:218] Iteration 94900 (0.865985 iter/s, 57.7377s/50 iters), loss = 0.00673739
I0616 20:41:01.786258 29366 solver.cpp:237]     Train net output #0: loss = 0.00673745 (* 1 = 0.00673745 loss)
I0616 20:41:01.786283 29366 sgd_solver.cpp:105] Iteration 94900, lr = 0.001
I0616 20:41:59.525898 29366 solver.cpp:218] Iteration 94950 (0.865964 iter/s, 57.7391s/50 iters), loss = 0.00687564
I0616 20:41:59.526161 29366 solver.cpp:237]     Train net output #0: loss = 0.00687569 (* 1 = 0.00687569 loss)
I0616 20:41:59.526185 29366 sgd_solver.cpp:105] Iteration 94950, lr = 0.001
I0616 20:42:57.279557 29366 solver.cpp:218] Iteration 95000 (0.865757 iter/s, 57.7529s/50 iters), loss = 0.00728665
I0616 20:42:57.279660 29366 solver.cpp:237]     Train net output #0: loss = 0.0072867 (* 1 = 0.0072867 loss)
I0616 20:42:57.279685 29366 sgd_solver.cpp:105] Iteration 95000, lr = 0.001
I0616 20:43:55.027442 29366 solver.cpp:218] Iteration 95050 (0.865842 iter/s, 57.7473s/50 iters), loss = 0.0068146
I0616 20:43:55.027643 29366 solver.cpp:237]     Train net output #0: loss = 0.00681466 (* 1 = 0.00681466 loss)
I0616 20:43:55.027668 29366 sgd_solver.cpp:105] Iteration 95050, lr = 0.001
I0616 20:44:52.776193 29366 solver.cpp:218] Iteration 95100 (0.86583 iter/s, 57.7481s/50 iters), loss = 0.00429616
I0616 20:44:52.776342 29366 solver.cpp:237]     Train net output #0: loss = 0.00429622 (* 1 = 0.00429622 loss)
I0616 20:44:52.776367 29366 sgd_solver.cpp:105] Iteration 95100, lr = 0.001
I0616 20:45:50.527164 29366 solver.cpp:218] Iteration 95150 (0.865796 iter/s, 57.7503s/50 iters), loss = 0.00562113
I0616 20:45:50.527359 29366 solver.cpp:237]     Train net output #0: loss = 0.00562119 (* 1 = 0.00562119 loss)
I0616 20:45:50.527384 29366 sgd_solver.cpp:105] Iteration 95150, lr = 0.001
I0616 20:46:48.276588 29366 solver.cpp:218] Iteration 95200 (0.86582 iter/s, 57.7487s/50 iters), loss = 0.00814431
I0616 20:46:48.276782 29366 solver.cpp:237]     Train net output #0: loss = 0.00814437 (* 1 = 0.00814437 loss)
I0616 20:46:48.276808 29366 sgd_solver.cpp:105] Iteration 95200, lr = 0.001
I0616 20:47:46.020686 29366 solver.cpp:218] Iteration 95250 (0.8659 iter/s, 57.7434s/50 iters), loss = 0.0137167
I0616 20:47:46.020822 29366 solver.cpp:237]     Train net output #0: loss = 0.0137168 (* 1 = 0.0137168 loss)
I0616 20:47:46.020848 29366 sgd_solver.cpp:105] Iteration 95250, lr = 0.001
I0616 20:48:43.757829 29366 solver.cpp:218] Iteration 95300 (0.866003 iter/s, 57.7365s/50 iters), loss = 0.0064745
I0616 20:48:43.757963 29366 solver.cpp:237]     Train net output #0: loss = 0.00647455 (* 1 = 0.00647455 loss)
I0616 20:48:43.757987 29366 sgd_solver.cpp:105] Iteration 95300, lr = 0.001
I0616 20:49:41.496987 29366 solver.cpp:218] Iteration 95350 (0.865973 iter/s, 57.7385s/50 iters), loss = 0.00546652
I0616 20:49:41.497153 29366 solver.cpp:237]     Train net output #0: loss = 0.00546658 (* 1 = 0.00546658 loss)
I0616 20:49:41.497176 29366 sgd_solver.cpp:105] Iteration 95350, lr = 0.001
I0616 20:50:39.232019 29366 solver.cpp:218] Iteration 95400 (0.866035 iter/s, 57.7344s/50 iters), loss = 0.0077454
I0616 20:50:39.232147 29366 solver.cpp:237]     Train net output #0: loss = 0.00774545 (* 1 = 0.00774545 loss)
I0616 20:50:39.232170 29366 sgd_solver.cpp:105] Iteration 95400, lr = 0.001
I0616 20:51:36.965355 29366 solver.cpp:218] Iteration 95450 (0.866061 iter/s, 57.7327s/50 iters), loss = 0.00593434
I0616 20:51:36.965544 29366 solver.cpp:237]     Train net output #0: loss = 0.00593439 (* 1 = 0.00593439 loss)
I0616 20:51:36.965580 29366 sgd_solver.cpp:105] Iteration 95450, lr = 0.001
I0616 20:52:34.711906 29366 solver.cpp:218] Iteration 95500 (0.865863 iter/s, 57.7459s/50 iters), loss = 0.00521055
I0616 20:52:34.712093 29366 solver.cpp:237]     Train net output #0: loss = 0.0052106 (* 1 = 0.0052106 loss)
I0616 20:52:34.712118 29366 sgd_solver.cpp:105] Iteration 95500, lr = 0.001
I0616 20:53:32.456727 29366 solver.cpp:218] Iteration 95550 (0.865889 iter/s, 57.7441s/50 iters), loss = 0.0054969
I0616 20:53:32.456954 29366 solver.cpp:237]     Train net output #0: loss = 0.00549696 (* 1 = 0.00549696 loss)
I0616 20:53:32.456986 29366 sgd_solver.cpp:105] Iteration 95550, lr = 0.001
I0616 20:54:30.200520 29366 solver.cpp:218] Iteration 95600 (0.865905 iter/s, 57.743s/50 iters), loss = 0.00291888
I0616 20:54:30.200781 29366 solver.cpp:237]     Train net output #0: loss = 0.00291893 (* 1 = 0.00291893 loss)
I0616 20:54:30.200810 29366 sgd_solver.cpp:105] Iteration 95600, lr = 0.001
I0616 20:55:27.939692 29366 solver.cpp:218] Iteration 95650 (0.865975 iter/s, 57.7384s/50 iters), loss = 0.00530627
I0616 20:55:27.939831 29366 solver.cpp:237]     Train net output #0: loss = 0.00530633 (* 1 = 0.00530633 loss)
I0616 20:55:27.939854 29366 sgd_solver.cpp:105] Iteration 95650, lr = 0.001
I0616 20:56:25.679006 29366 solver.cpp:218] Iteration 95700 (0.865972 iter/s, 57.7386s/50 iters), loss = 0.00546009
I0616 20:56:25.679211 29366 solver.cpp:237]     Train net output #0: loss = 0.00546015 (* 1 = 0.00546015 loss)
I0616 20:56:25.679237 29366 sgd_solver.cpp:105] Iteration 95700, lr = 0.001
I0616 20:57:23.418396 29366 solver.cpp:218] Iteration 95750 (0.865971 iter/s, 57.7386s/50 iters), loss = 0.00748353
I0616 20:57:23.418532 29366 solver.cpp:237]     Train net output #0: loss = 0.00748358 (* 1 = 0.00748358 loss)
I0616 20:57:23.418557 29366 sgd_solver.cpp:105] Iteration 95750, lr = 0.001
I0616 20:58:21.171133 29366 solver.cpp:218] Iteration 95800 (0.86577 iter/s, 57.7521s/50 iters), loss = 0.00612646
I0616 20:58:21.171295 29366 solver.cpp:237]     Train net output #0: loss = 0.00612652 (* 1 = 0.00612652 loss)
I0616 20:58:21.171321 29366 sgd_solver.cpp:105] Iteration 95800, lr = 0.001
I0616 20:59:18.930294 29366 solver.cpp:218] Iteration 95850 (0.865674 iter/s, 57.7584s/50 iters), loss = 0.00752294
I0616 20:59:18.930444 29366 solver.cpp:237]     Train net output #0: loss = 0.00752299 (* 1 = 0.00752299 loss)
I0616 20:59:18.930469 29366 sgd_solver.cpp:105] Iteration 95850, lr = 0.001
I0616 21:00:16.679313 29366 solver.cpp:218] Iteration 95900 (0.865826 iter/s, 57.7483s/50 iters), loss = 0.00612281
I0616 21:00:16.679539 29366 solver.cpp:237]     Train net output #0: loss = 0.00612287 (* 1 = 0.00612287 loss)
I0616 21:00:16.679567 29366 sgd_solver.cpp:105] Iteration 95900, lr = 0.001
I0616 21:01:14.426947 29366 solver.cpp:218] Iteration 95950 (0.865848 iter/s, 57.7469s/50 iters), loss = 0.00450258
I0616 21:01:14.427101 29366 solver.cpp:237]     Train net output #0: loss = 0.00450264 (* 1 = 0.00450264 loss)
I0616 21:01:14.427125 29366 sgd_solver.cpp:105] Iteration 95950, lr = 0.001
I0616 21:02:12.172657 29366 solver.cpp:218] Iteration 96000 (0.865876 iter/s, 57.745s/50 iters), loss = 0.00820437
I0616 21:02:12.172796 29366 solver.cpp:237]     Train net output #0: loss = 0.00820442 (* 1 = 0.00820442 loss)
I0616 21:02:12.172819 29366 sgd_solver.cpp:105] Iteration 96000, lr = 0.001
I0616 21:03:09.922327 29366 solver.cpp:218] Iteration 96050 (0.865816 iter/s, 57.749s/50 iters), loss = 0.00592265
I0616 21:03:09.922467 29366 solver.cpp:237]     Train net output #0: loss = 0.00592271 (* 1 = 0.00592271 loss)
I0616 21:03:09.922492 29366 sgd_solver.cpp:105] Iteration 96050, lr = 0.001
I0616 21:04:07.671820 29366 solver.cpp:218] Iteration 96100 (0.865819 iter/s, 57.7488s/50 iters), loss = 0.00548049
I0616 21:04:07.672013 29366 solver.cpp:237]     Train net output #0: loss = 0.00548055 (* 1 = 0.00548055 loss)
I0616 21:04:07.672037 29366 sgd_solver.cpp:105] Iteration 96100, lr = 0.001
I0616 21:05:05.429067 29366 solver.cpp:218] Iteration 96150 (0.865703 iter/s, 57.7565s/50 iters), loss = 0.0050275
I0616 21:05:05.429255 29366 solver.cpp:237]     Train net output #0: loss = 0.00502756 (* 1 = 0.00502756 loss)
I0616 21:05:05.429280 29366 sgd_solver.cpp:105] Iteration 96150, lr = 0.001
I0616 21:06:03.173926 29366 solver.cpp:218] Iteration 96200 (0.865889 iter/s, 57.7441s/50 iters), loss = 0.00787878
I0616 21:06:03.174129 29366 solver.cpp:237]     Train net output #0: loss = 0.00787884 (* 1 = 0.00787884 loss)
I0616 21:06:03.174166 29366 sgd_solver.cpp:105] Iteration 96200, lr = 0.001
I0616 21:07:00.927158 29366 solver.cpp:218] Iteration 96250 (0.865764 iter/s, 57.7525s/50 iters), loss = 0.00825257
I0616 21:07:00.927353 29366 solver.cpp:237]     Train net output #0: loss = 0.00825263 (* 1 = 0.00825263 loss)
I0616 21:07:00.927381 29366 sgd_solver.cpp:105] Iteration 96250, lr = 0.001
I0616 21:07:58.680109 29366 solver.cpp:218] Iteration 96300 (0.865768 iter/s, 57.7522s/50 iters), loss = 0.00557993
I0616 21:07:58.680317 29366 solver.cpp:237]     Train net output #0: loss = 0.00557999 (* 1 = 0.00557999 loss)
I0616 21:07:58.680343 29366 sgd_solver.cpp:105] Iteration 96300, lr = 0.001
I0616 21:08:56.420920 29366 solver.cpp:218] Iteration 96350 (0.86595 iter/s, 57.7401s/50 iters), loss = 0.00673897
I0616 21:08:56.421087 29366 solver.cpp:237]     Train net output #0: loss = 0.00673903 (* 1 = 0.00673903 loss)
I0616 21:08:56.421110 29366 sgd_solver.cpp:105] Iteration 96350, lr = 0.001
I0616 21:09:54.170244 29366 solver.cpp:218] Iteration 96400 (0.865822 iter/s, 57.7486s/50 iters), loss = 0.00636628
I0616 21:09:54.170507 29366 solver.cpp:237]     Train net output #0: loss = 0.00636634 (* 1 = 0.00636634 loss)
I0616 21:09:54.170539 29366 sgd_solver.cpp:105] Iteration 96400, lr = 0.001
I0616 21:10:51.925529 29366 solver.cpp:218] Iteration 96450 (0.865734 iter/s, 57.7545s/50 iters), loss = 0.00452916
I0616 21:10:51.925691 29366 solver.cpp:237]     Train net output #0: loss = 0.00452922 (* 1 = 0.00452922 loss)
I0616 21:10:51.925715 29366 sgd_solver.cpp:105] Iteration 96450, lr = 0.001
I0616 21:11:49.663851 29366 solver.cpp:218] Iteration 96500 (0.865987 iter/s, 57.7376s/50 iters), loss = 0.00777073
I0616 21:11:49.663986 29366 solver.cpp:237]     Train net output #0: loss = 0.00777079 (* 1 = 0.00777079 loss)
I0616 21:11:49.664011 29366 sgd_solver.cpp:105] Iteration 96500, lr = 0.001
I0616 21:12:47.417852 29366 solver.cpp:218] Iteration 96550 (0.865751 iter/s, 57.7533s/50 iters), loss = 0.00782242
I0616 21:12:47.418066 29366 solver.cpp:237]     Train net output #0: loss = 0.00782248 (* 1 = 0.00782248 loss)
I0616 21:12:47.418092 29366 sgd_solver.cpp:105] Iteration 96550, lr = 0.001
I0616 21:13:45.165426 29366 solver.cpp:218] Iteration 96600 (0.865848 iter/s, 57.7468s/50 iters), loss = 0.00632727
I0616 21:13:45.165563 29366 solver.cpp:237]     Train net output #0: loss = 0.00632733 (* 1 = 0.00632733 loss)
I0616 21:13:45.165590 29366 sgd_solver.cpp:105] Iteration 96600, lr = 0.001
I0616 21:14:42.910109 29366 solver.cpp:218] Iteration 96650 (0.865891 iter/s, 57.744s/50 iters), loss = 0.0062901
I0616 21:14:42.910238 29366 solver.cpp:237]     Train net output #0: loss = 0.00629016 (* 1 = 0.00629016 loss)
I0616 21:14:42.910262 29366 sgd_solver.cpp:105] Iteration 96650, lr = 0.001
I0616 21:15:40.656129 29366 solver.cpp:218] Iteration 96700 (0.865871 iter/s, 57.7453s/50 iters), loss = 0.00825302
I0616 21:15:40.656265 29366 solver.cpp:237]     Train net output #0: loss = 0.00825308 (* 1 = 0.00825308 loss)
I0616 21:15:40.656288 29366 sgd_solver.cpp:105] Iteration 96700, lr = 0.001
I0616 21:16:38.398006 29366 solver.cpp:218] Iteration 96750 (0.865933 iter/s, 57.7412s/50 iters), loss = 0.00479974
I0616 21:16:38.398140 29366 solver.cpp:237]     Train net output #0: loss = 0.00479981 (* 1 = 0.00479981 loss)
I0616 21:16:38.398164 29366 sgd_solver.cpp:105] Iteration 96750, lr = 0.001
I0616 21:17:36.142276 29366 solver.cpp:218] Iteration 96800 (0.865897 iter/s, 57.7436s/50 iters), loss = 0.00552527
I0616 21:17:36.142424 29366 solver.cpp:237]     Train net output #0: loss = 0.00552533 (* 1 = 0.00552533 loss)
I0616 21:17:36.142448 29366 sgd_solver.cpp:105] Iteration 96800, lr = 0.001
I0616 21:18:33.907133 29366 solver.cpp:218] Iteration 96850 (0.865588 iter/s, 57.7642s/50 iters), loss = 0.00802464
I0616 21:18:33.907279 29366 solver.cpp:237]     Train net output #0: loss = 0.0080247 (* 1 = 0.0080247 loss)
I0616 21:18:33.907304 29366 sgd_solver.cpp:105] Iteration 96850, lr = 0.001
I0616 21:19:31.662259 29366 solver.cpp:218] Iteration 96900 (0.865735 iter/s, 57.7544s/50 iters), loss = 0.0055341
I0616 21:19:31.662544 29366 solver.cpp:237]     Train net output #0: loss = 0.00553416 (* 1 = 0.00553416 loss)
I0616 21:19:31.662578 29366 sgd_solver.cpp:105] Iteration 96900, lr = 0.001
I0616 21:20:29.418361 29366 solver.cpp:218] Iteration 96950 (0.865722 iter/s, 57.7553s/50 iters), loss = 0.00828026
I0616 21:20:29.418527 29366 solver.cpp:237]     Train net output #0: loss = 0.00828032 (* 1 = 0.00828032 loss)
I0616 21:20:29.418555 29366 sgd_solver.cpp:105] Iteration 96950, lr = 0.001
I0616 21:21:27.172825 29366 solver.cpp:218] Iteration 97000 (0.865744 iter/s, 57.7538s/50 iters), loss = 0.00834492
I0616 21:21:27.172957 29366 solver.cpp:237]     Train net output #0: loss = 0.00834498 (* 1 = 0.00834498 loss)
I0616 21:21:27.172982 29366 sgd_solver.cpp:105] Iteration 97000, lr = 0.001
I0616 21:22:24.935899 29366 solver.cpp:218] Iteration 97050 (0.865615 iter/s, 57.7624s/50 iters), loss = 0.00845
I0616 21:22:24.936061 29366 solver.cpp:237]     Train net output #0: loss = 0.00845006 (* 1 = 0.00845006 loss)
I0616 21:22:24.936085 29366 sgd_solver.cpp:105] Iteration 97050, lr = 0.001
I0616 21:23:22.693528 29366 solver.cpp:218] Iteration 97100 (0.865697 iter/s, 57.7569s/50 iters), loss = 0.00552383
I0616 21:23:22.693691 29366 solver.cpp:237]     Train net output #0: loss = 0.0055239 (* 1 = 0.0055239 loss)
I0616 21:23:22.693716 29366 sgd_solver.cpp:105] Iteration 97100, lr = 0.001
I0616 21:24:20.448766 29366 solver.cpp:218] Iteration 97150 (0.865733 iter/s, 57.7545s/50 iters), loss = 0.00597582
I0616 21:24:20.448925 29366 solver.cpp:237]     Train net output #0: loss = 0.00597588 (* 1 = 0.00597588 loss)
I0616 21:24:20.448948 29366 sgd_solver.cpp:105] Iteration 97150, lr = 0.001
I0616 21:25:18.215268 29366 solver.cpp:218] Iteration 97200 (0.865564 iter/s, 57.7658s/50 iters), loss = 0.00681718
I0616 21:25:18.215443 29366 solver.cpp:237]     Train net output #0: loss = 0.00681724 (* 1 = 0.00681724 loss)
I0616 21:25:18.215469 29366 sgd_solver.cpp:105] Iteration 97200, lr = 0.001
I0616 21:26:15.967082 29366 solver.cpp:218] Iteration 97250 (0.865785 iter/s, 57.7511s/50 iters), loss = 0.00715135
I0616 21:26:15.967272 29366 solver.cpp:237]     Train net output #0: loss = 0.00715141 (* 1 = 0.00715141 loss)
I0616 21:26:15.967296 29366 sgd_solver.cpp:105] Iteration 97250, lr = 0.001
I0616 21:27:13.728358 29366 solver.cpp:218] Iteration 97300 (0.865643 iter/s, 57.7605s/50 iters), loss = 0.00580175
I0616 21:27:13.728551 29366 solver.cpp:237]     Train net output #0: loss = 0.00580182 (* 1 = 0.00580182 loss)
I0616 21:27:13.728577 29366 sgd_solver.cpp:105] Iteration 97300, lr = 0.001
I0616 21:28:11.479849 29366 solver.cpp:218] Iteration 97350 (0.86579 iter/s, 57.7507s/50 iters), loss = 0.0070904
I0616 21:28:11.480031 29366 solver.cpp:237]     Train net output #0: loss = 0.00709046 (* 1 = 0.00709046 loss)
I0616 21:28:11.480057 29366 sgd_solver.cpp:105] Iteration 97350, lr = 0.001
I0616 21:29:09.230222 29366 solver.cpp:218] Iteration 97400 (0.865807 iter/s, 57.7496s/50 iters), loss = 0.00620737
I0616 21:29:09.230365 29366 solver.cpp:237]     Train net output #0: loss = 0.00620743 (* 1 = 0.00620743 loss)
I0616 21:29:09.230388 29366 sgd_solver.cpp:105] Iteration 97400, lr = 0.001
I0616 21:30:06.974226 29366 solver.cpp:218] Iteration 97450 (0.865903 iter/s, 57.7432s/50 iters), loss = 0.00840322
I0616 21:30:06.974403 29366 solver.cpp:237]     Train net output #0: loss = 0.00840328 (* 1 = 0.00840328 loss)
I0616 21:30:06.974429 29366 sgd_solver.cpp:105] Iteration 97450, lr = 0.001
I0616 21:31:04.717883 29366 solver.cpp:218] Iteration 97500 (0.865908 iter/s, 57.7429s/50 iters), loss = 0.00723363
I0616 21:31:04.718006 29366 solver.cpp:237]     Train net output #0: loss = 0.00723369 (* 1 = 0.00723369 loss)
I0616 21:31:04.718029 29366 sgd_solver.cpp:105] Iteration 97500, lr = 0.001
I0616 21:32:02.459003 29366 solver.cpp:218] Iteration 97550 (0.865945 iter/s, 57.7404s/50 iters), loss = 0.00686856
I0616 21:32:02.459187 29366 solver.cpp:237]     Train net output #0: loss = 0.00686862 (* 1 = 0.00686862 loss)
I0616 21:32:02.459223 29366 sgd_solver.cpp:105] Iteration 97550, lr = 0.001
I0616 21:33:00.204707 29366 solver.cpp:218] Iteration 97600 (0.865878 iter/s, 57.7449s/50 iters), loss = 0.004929
I0616 21:33:00.204869 29366 solver.cpp:237]     Train net output #0: loss = 0.00492906 (* 1 = 0.00492906 loss)
I0616 21:33:00.204901 29366 sgd_solver.cpp:105] Iteration 97600, lr = 0.001
I0616 21:33:57.949805 29366 solver.cpp:218] Iteration 97650 (0.865886 iter/s, 57.7443s/50 iters), loss = 0.00831026
I0616 21:33:57.949959 29366 solver.cpp:237]     Train net output #0: loss = 0.00831032 (* 1 = 0.00831032 loss)
I0616 21:33:57.949983 29366 sgd_solver.cpp:105] Iteration 97650, lr = 0.001
I0616 21:34:55.704895 29366 solver.cpp:218] Iteration 97700 (0.865737 iter/s, 57.7543s/50 iters), loss = 0.00644907
I0616 21:34:55.705067 29366 solver.cpp:237]     Train net output #0: loss = 0.00644913 (* 1 = 0.00644913 loss)
I0616 21:34:55.705099 29366 sgd_solver.cpp:105] Iteration 97700, lr = 0.001
I0616 21:35:53.456281 29366 solver.cpp:218] Iteration 97750 (0.865792 iter/s, 57.7506s/50 iters), loss = 0.00499642
I0616 21:35:53.456426 29366 solver.cpp:237]     Train net output #0: loss = 0.00499648 (* 1 = 0.00499648 loss)
I0616 21:35:53.456450 29366 sgd_solver.cpp:105] Iteration 97750, lr = 0.001
I0616 21:36:51.200146 29366 solver.cpp:218] Iteration 97800 (0.865905 iter/s, 57.7431s/50 iters), loss = 0.00607391
I0616 21:36:51.200934 29366 solver.cpp:237]     Train net output #0: loss = 0.00607397 (* 1 = 0.00607397 loss)
I0616 21:36:51.200961 29366 sgd_solver.cpp:105] Iteration 97800, lr = 0.001
I0616 21:37:48.947932 29366 solver.cpp:218] Iteration 97850 (0.865855 iter/s, 57.7464s/50 iters), loss = 0.00716417
I0616 21:37:48.948060 29366 solver.cpp:237]     Train net output #0: loss = 0.00716423 (* 1 = 0.00716423 loss)
I0616 21:37:48.948083 29366 sgd_solver.cpp:105] Iteration 97850, lr = 0.001
I0616 21:38:46.690807 29366 solver.cpp:218] Iteration 97900 (0.865919 iter/s, 57.7421s/50 iters), loss = 0.00717241
I0616 21:38:46.690950 29366 solver.cpp:237]     Train net output #0: loss = 0.00717247 (* 1 = 0.00717247 loss)
I0616 21:38:46.690974 29366 sgd_solver.cpp:105] Iteration 97900, lr = 0.001
I0616 21:39:44.432873 29366 solver.cpp:218] Iteration 97950 (0.865932 iter/s, 57.7413s/50 iters), loss = 0.00672756
I0616 21:39:44.433050 29366 solver.cpp:237]     Train net output #0: loss = 0.00672762 (* 1 = 0.00672762 loss)
I0616 21:39:44.433075 29366 sgd_solver.cpp:105] Iteration 97950, lr = 0.001
I0616 21:40:42.177650 29366 solver.cpp:218] Iteration 98000 (0.865891 iter/s, 57.744s/50 iters), loss = 0.00798538
I0616 21:40:42.177850 29366 solver.cpp:237]     Train net output #0: loss = 0.00798544 (* 1 = 0.00798544 loss)
I0616 21:40:42.177876 29366 sgd_solver.cpp:105] Iteration 98000, lr = 0.001
I0616 21:41:39.924813 29366 solver.cpp:218] Iteration 98050 (0.865856 iter/s, 57.7463s/50 iters), loss = 0.00387987
I0616 21:41:39.924988 29366 solver.cpp:237]     Train net output #0: loss = 0.00387993 (* 1 = 0.00387993 loss)
I0616 21:41:39.925015 29366 sgd_solver.cpp:105] Iteration 98050, lr = 0.001
I0616 21:42:37.671830 29366 solver.cpp:218] Iteration 98100 (0.865858 iter/s, 57.7462s/50 iters), loss = 0.00505427
I0616 21:42:37.672019 29366 solver.cpp:237]     Train net output #0: loss = 0.00505433 (* 1 = 0.00505433 loss)
I0616 21:42:37.672044 29366 sgd_solver.cpp:105] Iteration 98100, lr = 0.001
I0616 21:43:35.421960 29366 solver.cpp:218] Iteration 98150 (0.865811 iter/s, 57.7493s/50 iters), loss = 0.00781201
I0616 21:43:35.422152 29366 solver.cpp:237]     Train net output #0: loss = 0.00781207 (* 1 = 0.00781207 loss)
I0616 21:43:35.422176 29366 sgd_solver.cpp:105] Iteration 98150, lr = 0.001
I0616 21:44:33.164572 29366 solver.cpp:218] Iteration 98200 (0.865924 iter/s, 57.7418s/50 iters), loss = 0.00824799
I0616 21:44:33.164703 29366 solver.cpp:237]     Train net output #0: loss = 0.00824805 (* 1 = 0.00824805 loss)
I0616 21:44:33.164727 29366 sgd_solver.cpp:105] Iteration 98200, lr = 0.001
I0616 21:45:30.922858 29366 solver.cpp:218] Iteration 98250 (0.865688 iter/s, 57.7575s/50 iters), loss = 0.00547006
I0616 21:45:30.923063 29366 solver.cpp:237]     Train net output #0: loss = 0.00547012 (* 1 = 0.00547012 loss)
I0616 21:45:30.923089 29366 sgd_solver.cpp:105] Iteration 98250, lr = 0.001
I0616 21:46:28.667762 29366 solver.cpp:218] Iteration 98300 (0.86589 iter/s, 57.7441s/50 iters), loss = 0.00611466
I0616 21:46:28.667912 29366 solver.cpp:237]     Train net output #0: loss = 0.00611472 (* 1 = 0.00611472 loss)
I0616 21:46:28.667937 29366 sgd_solver.cpp:105] Iteration 98300, lr = 0.001
I0616 21:47:26.422677 29366 solver.cpp:218] Iteration 98350 (0.865739 iter/s, 57.7541s/50 iters), loss = 0.00628091
I0616 21:47:26.422858 29366 solver.cpp:237]     Train net output #0: loss = 0.00628097 (* 1 = 0.00628097 loss)
I0616 21:47:26.422884 29366 sgd_solver.cpp:105] Iteration 98350, lr = 0.001
I0616 21:48:24.176745 29366 solver.cpp:218] Iteration 98400 (0.865752 iter/s, 57.7533s/50 iters), loss = 0.0070619
I0616 21:48:24.176928 29366 solver.cpp:237]     Train net output #0: loss = 0.00706196 (* 1 = 0.00706196 loss)
I0616 21:48:24.176954 29366 sgd_solver.cpp:105] Iteration 98400, lr = 0.001
I0616 21:49:21.929335 29366 solver.cpp:218] Iteration 98450 (0.865774 iter/s, 57.7518s/50 iters), loss = 0.00806061
I0616 21:49:21.929482 29366 solver.cpp:237]     Train net output #0: loss = 0.00806067 (* 1 = 0.00806067 loss)
I0616 21:49:21.929505 29366 sgd_solver.cpp:105] Iteration 98450, lr = 0.001
I0616 21:50:19.661311 29366 solver.cpp:218] Iteration 98500 (0.866083 iter/s, 57.7312s/50 iters), loss = 0.00434236
I0616 21:50:19.661479 29366 solver.cpp:237]     Train net output #0: loss = 0.00434243 (* 1 = 0.00434243 loss)
I0616 21:50:19.661504 29366 sgd_solver.cpp:105] Iteration 98500, lr = 0.001
I0616 21:51:17.404971 29366 solver.cpp:218] Iteration 98550 (0.865908 iter/s, 57.7429s/50 iters), loss = 0.00522593
I0616 21:51:17.405135 29366 solver.cpp:237]     Train net output #0: loss = 0.00522599 (* 1 = 0.00522599 loss)
I0616 21:51:17.405160 29366 sgd_solver.cpp:105] Iteration 98550, lr = 0.001
I0616 21:52:15.148973 29366 solver.cpp:218] Iteration 98600 (0.865902 iter/s, 57.7432s/50 iters), loss = 0.00503371
I0616 21:52:15.149147 29366 solver.cpp:237]     Train net output #0: loss = 0.00503377 (* 1 = 0.00503377 loss)
I0616 21:52:15.149173 29366 sgd_solver.cpp:105] Iteration 98600, lr = 0.001
I0616 21:53:12.897732 29366 solver.cpp:218] Iteration 98650 (0.865831 iter/s, 57.748s/50 iters), loss = 0.0107614
I0616 21:53:12.897835 29366 solver.cpp:237]     Train net output #0: loss = 0.0107615 (* 1 = 0.0107615 loss)
I0616 21:53:12.897856 29366 sgd_solver.cpp:105] Iteration 98650, lr = 0.001
I0616 21:54:10.639246 29366 solver.cpp:218] Iteration 98700 (0.865939 iter/s, 57.7408s/50 iters), loss = 0.00807539
I0616 21:54:10.639436 29366 solver.cpp:237]     Train net output #0: loss = 0.00807545 (* 1 = 0.00807545 loss)
I0616 21:54:10.639461 29366 sgd_solver.cpp:105] Iteration 98700, lr = 0.001
I0616 21:55:08.376616 29366 solver.cpp:218] Iteration 98750 (0.866002 iter/s, 57.7366s/50 iters), loss = 0.00601542
I0616 21:55:08.376750 29366 solver.cpp:237]     Train net output #0: loss = 0.00601548 (* 1 = 0.00601548 loss)
I0616 21:55:08.376775 29366 sgd_solver.cpp:105] Iteration 98750, lr = 0.001
I0616 21:56:06.117656 29366 solver.cpp:218] Iteration 98800 (0.865946 iter/s, 57.7403s/50 iters), loss = 0.00578962
I0616 21:56:06.117794 29366 solver.cpp:237]     Train net output #0: loss = 0.00578968 (* 1 = 0.00578968 loss)
I0616 21:56:06.117817 29366 sgd_solver.cpp:105] Iteration 98800, lr = 0.001
I0616 21:57:03.856086 29366 solver.cpp:218] Iteration 98850 (0.865985 iter/s, 57.7377s/50 iters), loss = 0.00520139
I0616 21:57:03.856215 29366 solver.cpp:237]     Train net output #0: loss = 0.00520145 (* 1 = 0.00520145 loss)
I0616 21:57:03.856240 29366 sgd_solver.cpp:105] Iteration 98850, lr = 0.001
I0616 21:58:01.602406 29366 solver.cpp:218] Iteration 98900 (0.865867 iter/s, 57.7456s/50 iters), loss = 0.0056933
I0616 21:58:01.602628 29366 solver.cpp:237]     Train net output #0: loss = 0.00569337 (* 1 = 0.00569337 loss)
I0616 21:58:01.602653 29366 sgd_solver.cpp:105] Iteration 98900, lr = 0.001
I0616 21:58:59.342849 29366 solver.cpp:218] Iteration 98950 (0.865957 iter/s, 57.7396s/50 iters), loss = 0.0104732
I0616 21:58:59.343019 29366 solver.cpp:237]     Train net output #0: loss = 0.0104733 (* 1 = 0.0104733 loss)
I0616 21:58:59.343050 29366 sgd_solver.cpp:105] Iteration 98950, lr = 0.001
I0616 21:59:57.089025 29366 solver.cpp:218] Iteration 99000 (0.86587 iter/s, 57.7454s/50 iters), loss = 0.0060191
I0616 21:59:57.089170 29366 solver.cpp:237]     Train net output #0: loss = 0.00601916 (* 1 = 0.00601916 loss)
I0616 21:59:57.089193 29366 sgd_solver.cpp:105] Iteration 99000, lr = 0.001
I0616 22:00:54.844637 29366 solver.cpp:218] Iteration 99050 (0.865728 iter/s, 57.7549s/50 iters), loss = 0.00671763
I0616 22:00:54.844785 29366 solver.cpp:237]     Train net output #0: loss = 0.00671769 (* 1 = 0.00671769 loss)
I0616 22:00:54.844810 29366 sgd_solver.cpp:105] Iteration 99050, lr = 0.001
I0616 22:01:52.595870 29366 solver.cpp:218] Iteration 99100 (0.865794 iter/s, 57.7505s/50 iters), loss = 0.00928116
I0616 22:01:52.596046 29366 solver.cpp:237]     Train net output #0: loss = 0.00928122 (* 1 = 0.00928122 loss)
I0616 22:01:52.596072 29366 sgd_solver.cpp:105] Iteration 99100, lr = 0.001
I0616 22:02:50.351899 29366 solver.cpp:218] Iteration 99150 (0.865721 iter/s, 57.7553s/50 iters), loss = 0.00716303
I0616 22:02:50.352082 29366 solver.cpp:237]     Train net output #0: loss = 0.00716309 (* 1 = 0.00716309 loss)
I0616 22:02:50.352107 29366 sgd_solver.cpp:105] Iteration 99150, lr = 0.001
I0616 22:03:48.091797 29366 solver.cpp:218] Iteration 99200 (0.865963 iter/s, 57.7392s/50 iters), loss = 0.0051921
I0616 22:03:48.091987 29366 solver.cpp:237]     Train net output #0: loss = 0.00519216 (* 1 = 0.00519216 loss)
I0616 22:03:48.092013 29366 sgd_solver.cpp:105] Iteration 99200, lr = 0.001
I0616 22:04:45.841794 29366 solver.cpp:218] Iteration 99250 (0.865812 iter/s, 57.7493s/50 iters), loss = 0.00724655
I0616 22:04:45.841989 29366 solver.cpp:237]     Train net output #0: loss = 0.00724661 (* 1 = 0.00724661 loss)
I0616 22:04:45.842015 29366 sgd_solver.cpp:105] Iteration 99250, lr = 0.001
I0616 22:05:43.588111 29366 solver.cpp:218] Iteration 99300 (0.865866 iter/s, 57.7456s/50 iters), loss = 0.00478282
I0616 22:05:43.588335 29366 solver.cpp:237]     Train net output #0: loss = 0.00478288 (* 1 = 0.00478288 loss)
I0616 22:05:43.588361 29366 sgd_solver.cpp:105] Iteration 99300, lr = 0.001
I0616 22:06:41.330598 29366 solver.cpp:218] Iteration 99350 (0.865924 iter/s, 57.7418s/50 iters), loss = 0.00508567
I0616 22:06:41.330834 29366 solver.cpp:237]     Train net output #0: loss = 0.00508574 (* 1 = 0.00508574 loss)
I0616 22:06:41.330859 29366 sgd_solver.cpp:105] Iteration 99350, lr = 0.001
I0616 22:07:39.079233 29366 solver.cpp:218] Iteration 99400 (0.865832 iter/s, 57.7479s/50 iters), loss = 0.00651072
I0616 22:07:39.079381 29366 solver.cpp:237]     Train net output #0: loss = 0.00651078 (* 1 = 0.00651078 loss)
I0616 22:07:39.079406 29366 sgd_solver.cpp:105] Iteration 99400, lr = 0.001
I0616 22:08:36.824285 29366 solver.cpp:218] Iteration 99450 (0.865885 iter/s, 57.7444s/50 iters), loss = 0.00709677
I0616 22:08:36.824470 29366 solver.cpp:237]     Train net output #0: loss = 0.00709684 (* 1 = 0.00709684 loss)
I0616 22:08:36.824496 29366 sgd_solver.cpp:105] Iteration 99450, lr = 0.001
I0616 22:09:34.565111 29366 solver.cpp:218] Iteration 99500 (0.865949 iter/s, 57.7401s/50 iters), loss = 0.00750288
I0616 22:09:34.565310 29366 solver.cpp:237]     Train net output #0: loss = 0.00750294 (* 1 = 0.00750294 loss)
I0616 22:09:34.565335 29366 sgd_solver.cpp:105] Iteration 99500, lr = 0.001
I0616 22:10:32.308040 29366 solver.cpp:218] Iteration 99550 (0.865918 iter/s, 57.7422s/50 iters), loss = 0.0113061
I0616 22:10:32.308226 29366 solver.cpp:237]     Train net output #0: loss = 0.0113062 (* 1 = 0.0113062 loss)
I0616 22:10:32.308251 29366 sgd_solver.cpp:105] Iteration 99550, lr = 0.001
I0616 22:11:30.059432 29366 solver.cpp:218] Iteration 99600 (0.86579 iter/s, 57.7507s/50 iters), loss = 0.00573549
I0616 22:11:30.059634 29366 solver.cpp:237]     Train net output #0: loss = 0.00573555 (* 1 = 0.00573555 loss)
I0616 22:11:30.059659 29366 sgd_solver.cpp:105] Iteration 99600, lr = 0.001
I0616 22:12:27.806367 29366 solver.cpp:218] Iteration 99650 (0.865857 iter/s, 57.7462s/50 iters), loss = 0.00447291
I0616 22:12:27.815295 29366 solver.cpp:237]     Train net output #0: loss = 0.00447297 (* 1 = 0.00447297 loss)
I0616 22:12:27.815320 29366 sgd_solver.cpp:105] Iteration 99650, lr = 0.001
I0616 22:13:25.556969 29366 solver.cpp:218] Iteration 99700 (0.865933 iter/s, 57.7412s/50 iters), loss = 0.00634278
I0616 22:13:25.557109 29366 solver.cpp:237]     Train net output #0: loss = 0.00634284 (* 1 = 0.00634284 loss)
I0616 22:13:25.557132 29366 sgd_solver.cpp:105] Iteration 99700, lr = 0.001
I0616 22:14:23.298990 29366 solver.cpp:218] Iteration 99750 (0.86593 iter/s, 57.7414s/50 iters), loss = 0.00800235
I0616 22:14:23.299134 29366 solver.cpp:237]     Train net output #0: loss = 0.00800241 (* 1 = 0.00800241 loss)
I0616 22:14:23.299159 29366 sgd_solver.cpp:105] Iteration 99750, lr = 0.001
I0616 22:15:21.045179 29366 solver.cpp:218] Iteration 99800 (0.865868 iter/s, 57.7455s/50 iters), loss = 0.00976778
I0616 22:15:21.045315 29366 solver.cpp:237]     Train net output #0: loss = 0.00976784 (* 1 = 0.00976784 loss)
I0616 22:15:21.045339 29366 sgd_solver.cpp:105] Iteration 99800, lr = 0.001
I0616 22:16:18.786633 29366 solver.cpp:218] Iteration 99850 (0.865939 iter/s, 57.7408s/50 iters), loss = 0.00580802
I0616 22:16:18.786780 29366 solver.cpp:237]     Train net output #0: loss = 0.00580808 (* 1 = 0.00580808 loss)
I0616 22:16:18.786803 29366 sgd_solver.cpp:105] Iteration 99850, lr = 0.001
I0616 22:17:16.529201 29366 solver.cpp:218] Iteration 99900 (0.865922 iter/s, 57.7419s/50 iters), loss = 0.00667555
I0616 22:17:16.529331 29366 solver.cpp:237]     Train net output #0: loss = 0.00667561 (* 1 = 0.00667561 loss)
I0616 22:17:16.529356 29366 sgd_solver.cpp:105] Iteration 99900, lr = 0.001
I0616 22:18:14.292084 29366 solver.cpp:218] Iteration 99950 (0.865618 iter/s, 57.7622s/50 iters), loss = 0.00736411
I0616 22:18:14.292244 29366 solver.cpp:237]     Train net output #0: loss = 0.00736417 (* 1 = 0.00736417 loss)
I0616 22:18:14.292268 29366 sgd_solver.cpp:105] Iteration 99950, lr = 0.001
I0616 22:19:10.903805 29366 solver.cpp:447] Snapshotting to binary proto file mobilenet/mobile_2_iter_100000.caffemodel
I0616 22:19:10.984163 29366 sgd_solver.cpp:273] Snapshotting solver state to binary proto file mobilenet/mobile_2_iter_100000.solverstate
I0616 22:19:12.167235 29366 solver.cpp:218] Iteration 100000 (0.863939 iter/s, 57.8745s/50 iters), loss = 0.00597891
I0616 22:19:12.167335 29366 solver.cpp:237]     Train net output #0: loss = 0.00597897 (* 1 = 0.00597897 loss)
I0616 22:19:12.167357 29366 sgd_solver.cpp:105] Iteration 100000, lr = 0.0001
I0616 22:20:09.936728 29366 solver.cpp:218] Iteration 100050 (0.865518 iter/s, 57.7689s/50 iters), loss = 0.00586996
I0616 22:20:09.936935 29366 solver.cpp:237]     Train net output #0: loss = 0.00587002 (* 1 = 0.00587002 loss)
I0616 22:20:09.936960 29366 sgd_solver.cpp:105] Iteration 100050, lr = 0.0001
I0616 22:21:07.705341 29366 solver.cpp:218] Iteration 100100 (0.865533 iter/s, 57.7679s/50 iters), loss = 0.00499361
I0616 22:21:07.705528 29366 solver.cpp:237]     Train net output #0: loss = 0.00499367 (* 1 = 0.00499367 loss)
I0616 22:21:07.705555 29366 sgd_solver.cpp:105] Iteration 100100, lr = 0.0001
I0616 22:22:05.474512 29366 solver.cpp:218] Iteration 100150 (0.865524 iter/s, 57.7685s/50 iters), loss = 0.00304656
I0616 22:22:05.474702 29366 solver.cpp:237]     Train net output #0: loss = 0.00304662 (* 1 = 0.00304662 loss)
I0616 22:22:05.474727 29366 sgd_solver.cpp:105] Iteration 100150, lr = 0.0001
I0616 22:23:03.251888 29366 solver.cpp:218] Iteration 100200 (0.865402 iter/s, 57.7766s/50 iters), loss = 0.00494062
I0616 22:23:03.252146 29366 solver.cpp:237]     Train net output #0: loss = 0.00494068 (* 1 = 0.00494068 loss)
I0616 22:23:03.252177 29366 sgd_solver.cpp:105] Iteration 100200, lr = 0.0001
I0616 22:24:01.027137 29366 solver.cpp:218] Iteration 100250 (0.865434 iter/s, 57.7745s/50 iters), loss = 0.00586868
I0616 22:24:01.027312 29366 solver.cpp:237]     Train net output #0: loss = 0.00586874 (* 1 = 0.00586874 loss)
I0616 22:24:01.027338 29366 sgd_solver.cpp:105] Iteration 100250, lr = 0.0001
I0616 22:24:58.799495 29366 solver.cpp:218] Iteration 100300 (0.865476 iter/s, 57.7717s/50 iters), loss = 0.0057249
I0616 22:24:58.799965 29366 solver.cpp:237]     Train net output #0: loss = 0.00572496 (* 1 = 0.00572496 loss)
I0616 22:24:58.799993 29366 sgd_solver.cpp:105] Iteration 100300, lr = 0.0001
I0616 22:25:56.574633 29366 solver.cpp:218] Iteration 100350 (0.865439 iter/s, 57.7741s/50 iters), loss = 0.00635581
I0616 22:25:56.574831 29366 solver.cpp:237]     Train net output #0: loss = 0.00635587 (* 1 = 0.00635587 loss)
I0616 22:25:56.574863 29366 sgd_solver.cpp:105] Iteration 100350, lr = 0.0001
I0616 22:26:54.342959 29366 solver.cpp:218] Iteration 100400 (0.865537 iter/s, 57.7676s/50 iters), loss = 0.00696673
I0616 22:26:54.343158 29366 solver.cpp:237]     Train net output #0: loss = 0.00696679 (* 1 = 0.00696679 loss)
I0616 22:26:54.343183 29366 sgd_solver.cpp:105] Iteration 100400, lr = 0.0001
I0616 22:27:52.108809 29366 solver.cpp:218] Iteration 100450 (0.865574 iter/s, 57.7651s/50 iters), loss = 0.00749959
I0616 22:27:52.108948 29366 solver.cpp:237]     Train net output #0: loss = 0.00749965 (* 1 = 0.00749965 loss)
I0616 22:27:52.108973 29366 sgd_solver.cpp:105] Iteration 100450, lr = 0.0001
I0616 22:28:49.871294 29366 solver.cpp:218] Iteration 100500 (0.865624 iter/s, 57.7618s/50 iters), loss = 0.00443221
I0616 22:28:49.871472 29366 solver.cpp:237]     Train net output #0: loss = 0.00443227 (* 1 = 0.00443227 loss)
I0616 22:28:49.871506 29366 sgd_solver.cpp:105] Iteration 100500, lr = 0.0001
I0616 22:29:47.643426 29366 solver.cpp:218] Iteration 100550 (0.86548 iter/s, 57.7714s/50 iters), loss = 0.00537422
I0616 22:29:47.643615 29366 solver.cpp:237]     Train net output #0: loss = 0.00537428 (* 1 = 0.00537428 loss)
I0616 22:29:47.643640 29366 sgd_solver.cpp:105] Iteration 100550, lr = 0.0001
I0616 22:30:45.397364 29366 solver.cpp:218] Iteration 100600 (0.865753 iter/s, 57.7532s/50 iters), loss = 0.00499121
I0616 22:30:45.397532 29366 solver.cpp:237]     Train net output #0: loss = 0.00499127 (* 1 = 0.00499127 loss)
I0616 22:30:45.397564 29366 sgd_solver.cpp:105] Iteration 100600, lr = 0.0001
I0616 22:31:43.172215 29366 solver.cpp:218] Iteration 100650 (0.865439 iter/s, 57.7742s/50 iters), loss = 0.00656453
I0616 22:31:43.172369 29366 solver.cpp:237]     Train net output #0: loss = 0.00656459 (* 1 = 0.00656459 loss)
I0616 22:31:43.172394 29366 sgd_solver.cpp:105] Iteration 100650, lr = 0.0001
I0616 22:32:40.926862 29366 solver.cpp:218] Iteration 100700 (0.865742 iter/s, 57.754s/50 iters), loss = 0.00755451
I0616 22:32:40.927044 29366 solver.cpp:237]     Train net output #0: loss = 0.00755457 (* 1 = 0.00755457 loss)
I0616 22:32:40.927068 29366 sgd_solver.cpp:105] Iteration 100700, lr = 0.0001
I0616 22:33:38.696691 29366 solver.cpp:218] Iteration 100750 (0.865514 iter/s, 57.7691s/50 iters), loss = 0.00669971
I0616 22:33:38.696859 29366 solver.cpp:237]     Train net output #0: loss = 0.00669977 (* 1 = 0.00669977 loss)
I0616 22:33:38.696883 29366 sgd_solver.cpp:105] Iteration 100750, lr = 0.0001
I0616 22:34:36.450927 29366 solver.cpp:218] Iteration 100800 (0.865748 iter/s, 57.7536s/50 iters), loss = 0.0101668
I0616 22:34:36.451077 29366 solver.cpp:237]     Train net output #0: loss = 0.0101668 (* 1 = 0.0101668 loss)
I0616 22:34:36.451102 29366 sgd_solver.cpp:105] Iteration 100800, lr = 0.0001
I0616 22:35:34.223316 29366 solver.cpp:218] Iteration 100850 (0.865475 iter/s, 57.7717s/50 iters), loss = 0.00432598
I0616 22:35:34.223501 29366 solver.cpp:237]     Train net output #0: loss = 0.00432604 (* 1 = 0.00432604 loss)
I0616 22:35:34.223531 29366 sgd_solver.cpp:105] Iteration 100850, lr = 0.0001
I0616 22:36:31.982915 29366 solver.cpp:218] Iteration 100900 (0.865667 iter/s, 57.7589s/50 iters), loss = 0.00719652
I0616 22:36:31.983101 29366 solver.cpp:237]     Train net output #0: loss = 0.00719658 (* 1 = 0.00719658 loss)
I0616 22:36:31.983126 29366 sgd_solver.cpp:105] Iteration 100900, lr = 0.0001
I0616 22:37:29.746577 29366 solver.cpp:218] Iteration 100950 (0.865607 iter/s, 57.7629s/50 iters), loss = 0.0056439
I0616 22:37:29.746783 29366 solver.cpp:237]     Train net output #0: loss = 0.00564396 (* 1 = 0.00564396 loss)
I0616 22:37:29.746809 29366 sgd_solver.cpp:105] Iteration 100950, lr = 0.0001
I0616 22:38:27.498466 29366 solver.cpp:218] Iteration 101000 (0.865784 iter/s, 57.7512s/50 iters), loss = 0.00503614
I0616 22:38:27.498754 29366 solver.cpp:237]     Train net output #0: loss = 0.00503621 (* 1 = 0.00503621 loss)
I0616 22:38:27.498780 29366 sgd_solver.cpp:105] Iteration 101000, lr = 0.0001
I0616 22:39:25.236662 29366 solver.cpp:218] Iteration 101050 (0.86599 iter/s, 57.7374s/50 iters), loss = 0.00834634
I0616 22:39:25.236804 29366 solver.cpp:237]     Train net output #0: loss = 0.0083464 (* 1 = 0.0083464 loss)
I0616 22:39:25.236827 29366 sgd_solver.cpp:105] Iteration 101050, lr = 0.0001
I0616 22:40:22.994698 29366 solver.cpp:218] Iteration 101100 (0.86569 iter/s, 57.7574s/50 iters), loss = 0.0058877
I0616 22:40:22.994879 29366 solver.cpp:237]     Train net output #0: loss = 0.00588777 (* 1 = 0.00588777 loss)
I0616 22:40:22.994904 29366 sgd_solver.cpp:105] Iteration 101100, lr = 0.0001
I0616 22:41:20.748340 29366 solver.cpp:218] Iteration 101150 (0.865757 iter/s, 57.7529s/50 iters), loss = 0.00598141
I0616 22:41:20.748495 29366 solver.cpp:237]     Train net output #0: loss = 0.00598147 (* 1 = 0.00598147 loss)
I0616 22:41:20.748525 29366 sgd_solver.cpp:105] Iteration 101150, lr = 0.0001
I0616 22:42:18.504554 29366 solver.cpp:218] Iteration 101200 (0.865718 iter/s, 57.7555s/50 iters), loss = 0.00850319
I0616 22:42:18.504693 29366 solver.cpp:237]     Train net output #0: loss = 0.00850325 (* 1 = 0.00850325 loss)
I0616 22:42:18.504717 29366 sgd_solver.cpp:105] Iteration 101200, lr = 0.0001
I0616 22:43:16.245023 29366 solver.cpp:218] Iteration 101250 (0.865954 iter/s, 57.7398s/50 iters), loss = 0.00701446
I0616 22:43:16.245174 29366 solver.cpp:237]     Train net output #0: loss = 0.00701452 (* 1 = 0.00701452 loss)
I0616 22:43:16.245199 29366 sgd_solver.cpp:105] Iteration 101250, lr = 0.0001
I0616 22:44:13.987154 29366 solver.cpp:218] Iteration 101300 (0.865929 iter/s, 57.7415s/50 iters), loss = 0.00989812
I0616 22:44:13.987303 29366 solver.cpp:237]     Train net output #0: loss = 0.00989818 (* 1 = 0.00989818 loss)
I0616 22:44:13.987327 29366 sgd_solver.cpp:105] Iteration 101300, lr = 0.0001
I0616 22:45:11.730082 29366 solver.cpp:218] Iteration 101350 (0.865917 iter/s, 57.7423s/50 iters), loss = 0.00510903
I0616 22:45:11.730239 29366 solver.cpp:237]     Train net output #0: loss = 0.00510909 (* 1 = 0.00510909 loss)
I0616 22:45:11.730265 29366 sgd_solver.cpp:105] Iteration 101350, lr = 0.0001
I0616 22:46:09.470062 29366 solver.cpp:218] Iteration 101400 (0.865961 iter/s, 57.7393s/50 iters), loss = 0.00699443
I0616 22:46:09.470253 29366 solver.cpp:237]     Train net output #0: loss = 0.00699449 (* 1 = 0.00699449 loss)
I0616 22:46:09.470278 29366 sgd_solver.cpp:105] Iteration 101400, lr = 0.0001
I0616 22:47:07.213860 29366 solver.cpp:218] Iteration 101450 (0.865904 iter/s, 57.7431s/50 iters), loss = 0.00556603
I0616 22:47:07.213981 29366 solver.cpp:237]     Train net output #0: loss = 0.0055661 (* 1 = 0.0055661 loss)
I0616 22:47:07.214004 29366 sgd_solver.cpp:105] Iteration 101450, lr = 0.0001
I0616 22:48:04.956511 29366 solver.cpp:218] Iteration 101500 (0.865921 iter/s, 57.742s/50 iters), loss = 0.0102418
I0616 22:48:04.956708 29366 solver.cpp:237]     Train net output #0: loss = 0.0102419 (* 1 = 0.0102419 loss)
I0616 22:48:04.956734 29366 sgd_solver.cpp:105] Iteration 101500, lr = 0.0001
I0616 22:49:02.706861 29366 solver.cpp:218] Iteration 101550 (0.865807 iter/s, 57.7496s/50 iters), loss = 0.00804283
I0616 22:49:02.707142 29366 solver.cpp:237]     Train net output #0: loss = 0.00804289 (* 1 = 0.00804289 loss)
I0616 22:49:02.707168 29366 sgd_solver.cpp:105] Iteration 101550, lr = 0.0001
I0616 22:50:00.459977 29366 solver.cpp:218] Iteration 101600 (0.865766 iter/s, 57.7523s/50 iters), loss = 0.00704607
I0616 22:50:00.460144 29366 solver.cpp:237]     Train net output #0: loss = 0.00704613 (* 1 = 0.00704613 loss)
I0616 22:50:00.460170 29366 sgd_solver.cpp:105] Iteration 101600, lr = 0.0001
I0616 22:50:58.213642 29366 solver.cpp:218] Iteration 101650 (0.865756 iter/s, 57.753s/50 iters), loss = 0.00678957
I0616 22:50:58.213830 29366 solver.cpp:237]     Train net output #0: loss = 0.00678963 (* 1 = 0.00678963 loss)
I0616 22:50:58.213857 29366 sgd_solver.cpp:105] Iteration 101650, lr = 0.0001
I0616 22:51:55.971860 29366 solver.cpp:218] Iteration 101700 (0.865689 iter/s, 57.7575s/50 iters), loss = 0.00674645
I0616 22:51:55.972024 29366 solver.cpp:237]     Train net output #0: loss = 0.00674651 (* 1 = 0.00674651 loss)
I0616 22:51:55.972050 29366 sgd_solver.cpp:105] Iteration 101700, lr = 0.0001
I0616 22:52:53.718511 29366 solver.cpp:218] Iteration 101750 (0.865861 iter/s, 57.746s/50 iters), loss = 0.00822264
I0616 22:52:53.718684 29366 solver.cpp:237]     Train net output #0: loss = 0.0082227 (* 1 = 0.0082227 loss)
I0616 22:52:53.718715 29366 sgd_solver.cpp:105] Iteration 101750, lr = 0.0001
I0616 22:53:51.492218 29366 solver.cpp:218] Iteration 101800 (0.865456 iter/s, 57.773s/50 iters), loss = 0.00504746
I0616 22:53:51.492401 29366 solver.cpp:237]     Train net output #0: loss = 0.00504752 (* 1 = 0.00504752 loss)
I0616 22:53:51.492425 29366 sgd_solver.cpp:105] Iteration 101800, lr = 0.0001
I0616 22:54:49.243230 29366 solver.cpp:218] Iteration 101850 (0.865796 iter/s, 57.7503s/50 iters), loss = 0.00521689
I0616 22:54:49.243376 29366 solver.cpp:237]     Train net output #0: loss = 0.00521695 (* 1 = 0.00521695 loss)
I0616 22:54:49.243402 29366 sgd_solver.cpp:105] Iteration 101850, lr = 0.0001
I0616 22:55:46.994213 29366 solver.cpp:218] Iteration 101900 (0.865796 iter/s, 57.7503s/50 iters), loss = 0.0104144
I0616 22:55:46.994377 29366 solver.cpp:237]     Train net output #0: loss = 0.0104145 (* 1 = 0.0104145 loss)
I0616 22:55:46.994405 29366 sgd_solver.cpp:105] Iteration 101900, lr = 0.0001
I0616 22:56:44.745877 29366 solver.cpp:218] Iteration 101950 (0.865786 iter/s, 57.751s/50 iters), loss = 0.00505122
I0616 22:56:44.746026 29366 solver.cpp:237]     Train net output #0: loss = 0.00505129 (* 1 = 0.00505129 loss)
I0616 22:56:44.746052 29366 sgd_solver.cpp:105] Iteration 101950, lr = 0.0001
I0616 22:57:42.495633 29366 solver.cpp:218] Iteration 102000 (0.865815 iter/s, 57.7491s/50 iters), loss = 0.00547027
I0616 22:57:42.495779 29366 solver.cpp:237]     Train net output #0: loss = 0.00547033 (* 1 = 0.00547033 loss)
I0616 22:57:42.495810 29366 sgd_solver.cpp:105] Iteration 102000, lr = 0.0001
I0616 22:58:40.237069 29366 solver.cpp:218] Iteration 102050 (0.865939 iter/s, 57.7408s/50 iters), loss = 0.0100085
I0616 22:58:40.237200 29366 solver.cpp:237]     Train net output #0: loss = 0.0100086 (* 1 = 0.0100086 loss)
I0616 22:58:40.237226 29366 sgd_solver.cpp:105] Iteration 102050, lr = 0.0001
I0616 22:59:37.978080 29366 solver.cpp:218] Iteration 102100 (0.865945 iter/s, 57.7404s/50 iters), loss = 0.00857645
I0616 22:59:37.978212 29366 solver.cpp:237]     Train net output #0: loss = 0.00857651 (* 1 = 0.00857651 loss)
I0616 22:59:37.978236 29366 sgd_solver.cpp:105] Iteration 102100, lr = 0.0001
I0616 23:00:35.721257 29366 solver.cpp:218] Iteration 102150 (0.865913 iter/s, 57.7425s/50 iters), loss = 0.00422299
I0616 23:00:35.721400 29366 solver.cpp:237]     Train net output #0: loss = 0.00422305 (* 1 = 0.00422305 loss)
I0616 23:00:35.721422 29366 sgd_solver.cpp:105] Iteration 102150, lr = 0.0001
I0616 23:01:33.452967 29366 solver.cpp:218] Iteration 102200 (0.866085 iter/s, 57.7311s/50 iters), loss = 0.01078
I0616 23:01:33.453142 29366 solver.cpp:237]     Train net output #0: loss = 0.0107801 (* 1 = 0.0107801 loss)
I0616 23:01:33.453167 29366 sgd_solver.cpp:105] Iteration 102200, lr = 0.0001
I0616 23:02:31.197006 29366 solver.cpp:218] Iteration 102250 (0.8659 iter/s, 57.7434s/50 iters), loss = 0.00858888
I0616 23:02:31.197214 29366 solver.cpp:237]     Train net output #0: loss = 0.00858894 (* 1 = 0.00858894 loss)
I0616 23:02:31.197238 29366 sgd_solver.cpp:105] Iteration 102250, lr = 0.0001
I0616 23:03:28.935703 29366 solver.cpp:218] Iteration 102300 (0.865981 iter/s, 57.738s/50 iters), loss = 0.00584519
I0616 23:03:28.935847 29366 solver.cpp:237]     Train net output #0: loss = 0.00584525 (* 1 = 0.00584525 loss)
I0616 23:03:28.935871 29366 sgd_solver.cpp:105] Iteration 102300, lr = 0.0001
I0616 23:04:26.666579 29366 solver.cpp:218] Iteration 102350 (0.866098 iter/s, 57.7302s/50 iters), loss = 0.00541961
I0616 23:04:26.666754 29366 solver.cpp:237]     Train net output #0: loss = 0.00541967 (* 1 = 0.00541967 loss)
I0616 23:04:26.666779 29366 sgd_solver.cpp:105] Iteration 102350, lr = 0.0001
I0616 23:05:24.407121 29366 solver.cpp:218] Iteration 102400 (0.865953 iter/s, 57.7399s/50 iters), loss = 0.00603529
I0616 23:05:24.407258 29366 solver.cpp:237]     Train net output #0: loss = 0.00603535 (* 1 = 0.00603535 loss)
I0616 23:05:24.407284 29366 sgd_solver.cpp:105] Iteration 102400, lr = 0.0001
I0616 23:06:22.154223 29366 solver.cpp:218] Iteration 102450 (0.865854 iter/s, 57.7464s/50 iters), loss = 0.00618946
I0616 23:06:22.154400 29366 solver.cpp:237]     Train net output #0: loss = 0.00618953 (* 1 = 0.00618953 loss)
I0616 23:06:22.154424 29366 sgd_solver.cpp:105] Iteration 102450, lr = 0.0001
I0616 23:07:19.900101 29366 solver.cpp:218] Iteration 102500 (0.865873 iter/s, 57.7452s/50 iters), loss = 0.00540227
I0616 23:07:19.900226 29366 solver.cpp:237]     Train net output #0: loss = 0.00540234 (* 1 = 0.00540234 loss)
I0616 23:07:19.900249 29366 sgd_solver.cpp:105] Iteration 102500, lr = 0.0001
I0616 23:08:17.653304 29366 solver.cpp:218] Iteration 102550 (0.865762 iter/s, 57.7526s/50 iters), loss = 0.00860583
I0616 23:08:17.653491 29366 solver.cpp:237]     Train net output #0: loss = 0.00860589 (* 1 = 0.00860589 loss)
I0616 23:08:17.653523 29366 sgd_solver.cpp:105] Iteration 102550, lr = 0.0001
I0616 23:09:15.389358 29366 solver.cpp:218] Iteration 102600 (0.86602 iter/s, 57.7354s/50 iters), loss = 0.00685799
I0616 23:09:15.389488 29366 solver.cpp:237]     Train net output #0: loss = 0.00685806 (* 1 = 0.00685806 loss)
I0616 23:09:15.389513 29366 sgd_solver.cpp:105] Iteration 102600, lr = 0.0001
I0616 23:10:13.133918 29366 solver.cpp:218] Iteration 102650 (0.865892 iter/s, 57.7439s/50 iters), loss = 0.00409339
I0616 23:10:13.134060 29366 solver.cpp:237]     Train net output #0: loss = 0.00409345 (* 1 = 0.00409345 loss)
I0616 23:10:13.134085 29366 sgd_solver.cpp:105] Iteration 102650, lr = 0.0001
I0616 23:11:10.873348 29366 solver.cpp:218] Iteration 102700 (0.865968 iter/s, 57.7388s/50 iters), loss = 0.00765763
I0616 23:11:10.873510 29366 solver.cpp:237]     Train net output #0: loss = 0.0076577 (* 1 = 0.0076577 loss)
I0616 23:11:10.873543 29366 sgd_solver.cpp:105] Iteration 102700, lr = 0.0001
I0616 23:12:08.625680 29366 solver.cpp:218] Iteration 102750 (0.865775 iter/s, 57.7518s/50 iters), loss = 0.00573958
I0616 23:12:08.625844 29366 solver.cpp:237]     Train net output #0: loss = 0.00573964 (* 1 = 0.00573964 loss)
I0616 23:12:08.625869 29366 sgd_solver.cpp:105] Iteration 102750, lr = 0.0001
I0616 23:13:06.372231 29366 solver.cpp:218] Iteration 102800 (0.865862 iter/s, 57.746s/50 iters), loss = 0.00468425
I0616 23:13:06.372381 29366 solver.cpp:237]     Train net output #0: loss = 0.00468432 (* 1 = 0.00468432 loss)
I0616 23:13:06.372412 29366 sgd_solver.cpp:105] Iteration 102800, lr = 0.0001
I0616 23:14:04.118885 29366 solver.cpp:218] Iteration 102850 (0.86586 iter/s, 57.7461s/50 iters), loss = 0.00448763
I0616 23:14:04.119052 29366 solver.cpp:237]     Train net output #0: loss = 0.0044877 (* 1 = 0.0044877 loss)
I0616 23:14:04.119076 29366 sgd_solver.cpp:105] Iteration 102850, lr = 0.0001
I0616 23:15:01.861865 29366 solver.cpp:218] Iteration 102900 (0.865915 iter/s, 57.7424s/50 iters), loss = 0.00520116
I0616 23:15:01.862109 29366 solver.cpp:237]     Train net output #0: loss = 0.00520123 (* 1 = 0.00520123 loss)
I0616 23:15:01.862149 29366 sgd_solver.cpp:105] Iteration 102900, lr = 0.0001
I0616 23:15:59.601383 29366 solver.cpp:218] Iteration 102950 (0.865968 iter/s, 57.7388s/50 iters), loss = 0.00798631
I0616 23:15:59.601543 29366 solver.cpp:237]     Train net output #0: loss = 0.00798637 (* 1 = 0.00798637 loss)
I0616 23:15:59.601569 29366 sgd_solver.cpp:105] Iteration 102950, lr = 0.0001
I0616 23:16:57.351256 29366 solver.cpp:218] Iteration 103000 (0.865811 iter/s, 57.7493s/50 iters), loss = 0.00799709
I0616 23:16:57.351415 29366 solver.cpp:237]     Train net output #0: loss = 0.00799716 (* 1 = 0.00799716 loss)
I0616 23:16:57.351440 29366 sgd_solver.cpp:105] Iteration 103000, lr = 0.0001
I0616 23:17:55.098011 29366 solver.cpp:218] Iteration 103050 (0.865859 iter/s, 57.7462s/50 iters), loss = 0.00597729
I0616 23:17:55.098222 29366 solver.cpp:237]     Train net output #0: loss = 0.00597735 (* 1 = 0.00597735 loss)
I0616 23:17:55.098248 29366 sgd_solver.cpp:105] Iteration 103050, lr = 0.0001
I0616 23:18:52.848135 29366 solver.cpp:218] Iteration 103100 (0.865808 iter/s, 57.7495s/50 iters), loss = 0.00561807
I0616 23:18:52.848280 29366 solver.cpp:237]     Train net output #0: loss = 0.00561814 (* 1 = 0.00561814 loss)
I0616 23:18:52.848305 29366 sgd_solver.cpp:105] Iteration 103100, lr = 0.0001
I0616 23:19:50.593813 29366 solver.cpp:218] Iteration 103150 (0.865875 iter/s, 57.7451s/50 iters), loss = 0.00440889
I0616 23:19:50.593981 29366 solver.cpp:237]     Train net output #0: loss = 0.00440895 (* 1 = 0.00440895 loss)
I0616 23:19:50.594007 29366 sgd_solver.cpp:105] Iteration 103150, lr = 0.0001
I0616 23:20:48.335662 29366 solver.cpp:218] Iteration 103200 (0.865932 iter/s, 57.7413s/50 iters), loss = 0.00635359
I0616 23:20:48.335798 29366 solver.cpp:237]     Train net output #0: loss = 0.00635365 (* 1 = 0.00635365 loss)
I0616 23:20:48.335821 29366 sgd_solver.cpp:105] Iteration 103200, lr = 0.0001
I0616 23:21:46.077896 29366 solver.cpp:218] Iteration 103250 (0.865926 iter/s, 57.7417s/50 iters), loss = 0.00808075
I0616 23:21:46.078018 29366 solver.cpp:237]     Train net output #0: loss = 0.00808081 (* 1 = 0.00808081 loss)
I0616 23:21:46.078044 29366 sgd_solver.cpp:105] Iteration 103250, lr = 0.0001
I0616 23:22:43.817682 29366 solver.cpp:218] Iteration 103300 (0.865963 iter/s, 57.7392s/50 iters), loss = 0.00532828
I0616 23:22:43.817863 29366 solver.cpp:237]     Train net output #0: loss = 0.00532835 (* 1 = 0.00532835 loss)
I0616 23:22:43.817888 29366 sgd_solver.cpp:105] Iteration 103300, lr = 0.0001
I0616 23:23:41.558854 29366 solver.cpp:218] Iteration 103350 (0.865942 iter/s, 57.7406s/50 iters), loss = 0.00678383
I0616 23:23:41.558984 29366 solver.cpp:237]     Train net output #0: loss = 0.0067839 (* 1 = 0.0067839 loss)
I0616 23:23:41.559008 29366 sgd_solver.cpp:105] Iteration 103350, lr = 0.0001
I0616 23:24:39.317140 29366 solver.cpp:218] Iteration 103400 (0.865685 iter/s, 57.7577s/50 iters), loss = 0.00798247
I0616 23:24:39.317279 29366 solver.cpp:237]     Train net output #0: loss = 0.00798253 (* 1 = 0.00798253 loss)
I0616 23:24:39.317304 29366 sgd_solver.cpp:105] Iteration 103400, lr = 0.0001
I0616 23:25:37.061990 29366 solver.cpp:218] Iteration 103450 (0.865887 iter/s, 57.7443s/50 iters), loss = 0.00499757
I0616 23:25:37.062155 29366 solver.cpp:237]     Train net output #0: loss = 0.00499764 (* 1 = 0.00499764 loss)
I0616 23:25:37.062180 29366 sgd_solver.cpp:105] Iteration 103450, lr = 0.0001
I0616 23:26:34.811487 29366 solver.cpp:218] Iteration 103500 (0.865817 iter/s, 57.7489s/50 iters), loss = 0.00861547
I0616 23:26:34.811631 29366 solver.cpp:237]     Train net output #0: loss = 0.00861553 (* 1 = 0.00861553 loss)
I0616 23:26:34.811655 29366 sgd_solver.cpp:105] Iteration 103500, lr = 0.0001
I0616 23:27:32.558025 29366 solver.cpp:218] Iteration 103550 (0.865861 iter/s, 57.746s/50 iters), loss = 0.00552088
I0616 23:27:32.558178 29366 solver.cpp:237]     Train net output #0: loss = 0.00552095 (* 1 = 0.00552095 loss)
I0616 23:27:32.558202 29366 sgd_solver.cpp:105] Iteration 103550, lr = 0.0001
I0616 23:28:30.331470 29366 solver.cpp:218] Iteration 103600 (0.865459 iter/s, 57.7728s/50 iters), loss = 0.00598554
I0616 23:28:30.331727 29366 solver.cpp:237]     Train net output #0: loss = 0.00598561 (* 1 = 0.00598561 loss)
I0616 23:28:30.331753 29366 sgd_solver.cpp:105] Iteration 103600, lr = 0.0001
I0616 23:29:28.105886 29366 solver.cpp:218] Iteration 103650 (0.865446 iter/s, 57.7737s/50 iters), loss = 0.00804181
I0616 23:29:28.106071 29366 solver.cpp:237]     Train net output #0: loss = 0.00804188 (* 1 = 0.00804188 loss)
I0616 23:29:28.106096 29366 sgd_solver.cpp:105] Iteration 103650, lr = 0.0001
I0616 23:30:25.887647 29366 solver.cpp:218] Iteration 103700 (0.865335 iter/s, 57.7811s/50 iters), loss = 0.00824816
I0616 23:30:25.887831 29366 solver.cpp:237]     Train net output #0: loss = 0.00824822 (* 1 = 0.00824822 loss)
I0616 23:30:25.887856 29366 sgd_solver.cpp:105] Iteration 103700, lr = 0.0001
I0616 23:31:23.662600 29366 solver.cpp:218] Iteration 103750 (0.865437 iter/s, 57.7743s/50 iters), loss = 0.00536908
I0616 23:31:23.662755 29366 solver.cpp:237]     Train net output #0: loss = 0.00536915 (* 1 = 0.00536915 loss)
I0616 23:31:23.662781 29366 sgd_solver.cpp:105] Iteration 103750, lr = 0.0001
I0616 23:32:21.429816 29366 solver.cpp:218] Iteration 103800 (0.865553 iter/s, 57.7666s/50 iters), loss = 0.00564895
I0616 23:32:21.430014 29366 solver.cpp:237]     Train net output #0: loss = 0.00564901 (* 1 = 0.00564901 loss)
I0616 23:32:21.430045 29366 sgd_solver.cpp:105] Iteration 103800, lr = 0.0001
I0616 23:33:19.193651 29366 solver.cpp:218] Iteration 103850 (0.865603 iter/s, 57.7632s/50 iters), loss = 0.00586523
I0616 23:33:19.193836 29366 solver.cpp:237]     Train net output #0: loss = 0.0058653 (* 1 = 0.0058653 loss)
I0616 23:33:19.193861 29366 sgd_solver.cpp:105] Iteration 103850, lr = 0.0001
I0616 23:34:16.963982 29366 solver.cpp:218] Iteration 103900 (0.865506 iter/s, 57.7697s/50 iters), loss = 0.00705908
I0616 23:34:16.964169 29366 solver.cpp:237]     Train net output #0: loss = 0.00705914 (* 1 = 0.00705914 loss)
I0616 23:34:16.964193 29366 sgd_solver.cpp:105] Iteration 103900, lr = 0.0001
I0616 23:35:14.735200 29366 solver.cpp:218] Iteration 103950 (0.865492 iter/s, 57.7706s/50 iters), loss = 0.0068306
I0616 23:35:14.735363 29366 solver.cpp:237]     Train net output #0: loss = 0.00683067 (* 1 = 0.00683067 loss)
I0616 23:35:14.735389 29366 sgd_solver.cpp:105] Iteration 103950, lr = 0.0001
I0616 23:36:12.498404 29366 solver.cpp:218] Iteration 104000 (0.865612 iter/s, 57.7626s/50 iters), loss = 0.00624815
I0616 23:36:12.498569 29366 solver.cpp:237]     Train net output #0: loss = 0.00624821 (* 1 = 0.00624821 loss)
I0616 23:36:12.498594 29366 sgd_solver.cpp:105] Iteration 104000, lr = 0.0001
I0616 23:37:10.277313 29366 solver.cpp:218] Iteration 104050 (0.865377 iter/s, 57.7783s/50 iters), loss = 0.00649301
I0616 23:37:10.277523 29366 solver.cpp:237]     Train net output #0: loss = 0.00649308 (* 1 = 0.00649308 loss)
I0616 23:37:10.277551 29366 sgd_solver.cpp:105] Iteration 104050, lr = 0.0001
I0616 23:38:08.025076 29366 solver.cpp:218] Iteration 104100 (0.865844 iter/s, 57.7471s/50 iters), loss = 0.00596105
I0616 23:38:08.025257 29366 solver.cpp:237]     Train net output #0: loss = 0.00596111 (* 1 = 0.00596111 loss)
I0616 23:38:08.025285 29366 sgd_solver.cpp:105] Iteration 104100, lr = 0.0001
I0616 23:39:05.771055 29366 solver.cpp:218] Iteration 104150 (0.865871 iter/s, 57.7453s/50 iters), loss = 0.00465093
I0616 23:39:05.771200 29366 solver.cpp:237]     Train net output #0: loss = 0.00465099 (* 1 = 0.00465099 loss)
I0616 23:39:05.771225 29366 sgd_solver.cpp:105] Iteration 104150, lr = 0.0001
I0616 23:40:03.514899 29366 solver.cpp:218] Iteration 104200 (0.865902 iter/s, 57.7432s/50 iters), loss = 0.00522364
I0616 23:40:03.515050 29366 solver.cpp:237]     Train net output #0: loss = 0.00522371 (* 1 = 0.00522371 loss)
I0616 23:40:03.515074 29366 sgd_solver.cpp:105] Iteration 104200, lr = 0.0001
I0616 23:41:01.254480 29366 solver.cpp:218] Iteration 104250 (0.865966 iter/s, 57.739s/50 iters), loss = 0.0057968
I0616 23:41:01.254750 29366 solver.cpp:237]     Train net output #0: loss = 0.00579686 (* 1 = 0.00579686 loss)
I0616 23:41:01.254787 29366 sgd_solver.cpp:105] Iteration 104250, lr = 0.0001
I0616 23:41:59.010934 29366 solver.cpp:218] Iteration 104300 (0.865715 iter/s, 57.7557s/50 iters), loss = 0.00708863
I0616 23:41:59.011036 29366 solver.cpp:237]     Train net output #0: loss = 0.0070887 (* 1 = 0.0070887 loss)
I0616 23:41:59.011061 29366 sgd_solver.cpp:105] Iteration 104300, lr = 0.0001
I0616 23:42:56.764910 29366 solver.cpp:218] Iteration 104350 (0.86575 iter/s, 57.7534s/50 iters), loss = 0.00686919
I0616 23:42:56.765102 29366 solver.cpp:237]     Train net output #0: loss = 0.00686926 (* 1 = 0.00686926 loss)
I0616 23:42:56.765127 29366 sgd_solver.cpp:105] Iteration 104350, lr = 0.0001
I0616 23:43:54.512818 29366 solver.cpp:218] Iteration 104400 (0.865842 iter/s, 57.7473s/50 iters), loss = 0.00680889
I0616 23:43:54.512970 29366 solver.cpp:237]     Train net output #0: loss = 0.00680896 (* 1 = 0.00680896 loss)
I0616 23:43:54.512995 29366 sgd_solver.cpp:105] Iteration 104400, lr = 0.0001
I0616 23:44:52.256633 29366 solver.cpp:218] Iteration 104450 (0.865903 iter/s, 57.7432s/50 iters), loss = 0.00549908
I0616 23:44:52.256814 29366 solver.cpp:237]     Train net output #0: loss = 0.00549914 (* 1 = 0.00549914 loss)
I0616 23:44:52.256841 29366 sgd_solver.cpp:105] Iteration 104450, lr = 0.0001
I0616 23:45:49.999178 29366 solver.cpp:218] Iteration 104500 (0.865921 iter/s, 57.742s/50 iters), loss = 0.00617602
I0616 23:45:49.999361 29366 solver.cpp:237]     Train net output #0: loss = 0.00617608 (* 1 = 0.00617608 loss)
I0616 23:45:49.999387 29366 sgd_solver.cpp:105] Iteration 104500, lr = 0.0001
I0616 23:46:47.747179 29366 solver.cpp:218] Iteration 104550 (0.86584 iter/s, 57.7474s/50 iters), loss = 0.0101433
I0616 23:46:47.747341 29366 solver.cpp:237]     Train net output #0: loss = 0.0101433 (* 1 = 0.0101433 loss)
I0616 23:46:47.747372 29366 sgd_solver.cpp:105] Iteration 104550, lr = 0.0001
I0616 23:47:45.491978 29366 solver.cpp:218] Iteration 104600 (0.865887 iter/s, 57.7443s/50 iters), loss = 0.00946287
I0616 23:47:45.492159 29366 solver.cpp:237]     Train net output #0: loss = 0.00946294 (* 1 = 0.00946294 loss)
I0616 23:47:45.492183 29366 sgd_solver.cpp:105] Iteration 104600, lr = 0.0001
I0616 23:48:43.254272 29366 solver.cpp:218] Iteration 104650 (0.865625 iter/s, 57.7617s/50 iters), loss = 0.00612619
I0616 23:48:43.254627 29366 solver.cpp:237]     Train net output #0: loss = 0.00612626 (* 1 = 0.00612626 loss)
I0616 23:48:43.254654 29366 sgd_solver.cpp:105] Iteration 104650, lr = 0.0001
I0616 23:49:41.007848 29366 solver.cpp:218] Iteration 104700 (0.865758 iter/s, 57.7528s/50 iters), loss = 0.00732144
I0616 23:49:41.008008 29366 solver.cpp:237]     Train net output #0: loss = 0.00732151 (* 1 = 0.00732151 loss)
I0616 23:49:41.008033 29366 sgd_solver.cpp:105] Iteration 104700, lr = 0.0001
I0616 23:50:38.762419 29366 solver.cpp:218] Iteration 104750 (0.86574 iter/s, 57.754s/50 iters), loss = 0.00378747
I0616 23:50:38.762590 29366 solver.cpp:237]     Train net output #0: loss = 0.00378753 (* 1 = 0.00378753 loss)
I0616 23:50:38.762615 29366 sgd_solver.cpp:105] Iteration 104750, lr = 0.0001
I0616 23:51:36.514322 29366 solver.cpp:218] Iteration 104800 (0.865781 iter/s, 57.7513s/50 iters), loss = 0.00740273
I0616 23:51:36.514508 29366 solver.cpp:237]     Train net output #0: loss = 0.00740279 (* 1 = 0.00740279 loss)
I0616 23:51:36.514549 29366 sgd_solver.cpp:105] Iteration 104800, lr = 0.0001
I0616 23:52:34.265735 29366 solver.cpp:218] Iteration 104850 (0.865788 iter/s, 57.7509s/50 iters), loss = 0.0057958
I0616 23:52:34.265872 29366 solver.cpp:237]     Train net output #0: loss = 0.00579587 (* 1 = 0.00579587 loss)
I0616 23:52:34.265897 29366 sgd_solver.cpp:105] Iteration 104850, lr = 0.0001
I0616 23:53:32.027868 29366 solver.cpp:218] Iteration 104900 (0.865627 iter/s, 57.7616s/50 iters), loss = 0.00511178
I0616 23:53:32.028229 29366 solver.cpp:237]     Train net output #0: loss = 0.00511185 (* 1 = 0.00511185 loss)
I0616 23:53:32.028254 29366 sgd_solver.cpp:105] Iteration 104900, lr = 0.0001
I0616 23:54:29.791162 29366 solver.cpp:218] Iteration 104950 (0.865613 iter/s, 57.7625s/50 iters), loss = 0.00710568
I0616 23:54:29.791376 29366 solver.cpp:237]     Train net output #0: loss = 0.00710574 (* 1 = 0.00710574 loss)
I0616 23:54:29.791401 29366 sgd_solver.cpp:105] Iteration 104950, lr = 0.0001
I0616 23:55:27.555115 29366 solver.cpp:218] Iteration 105000 (0.865601 iter/s, 57.7634s/50 iters), loss = 0.00701582
I0616 23:55:27.555277 29366 solver.cpp:237]     Train net output #0: loss = 0.00701588 (* 1 = 0.00701588 loss)
I0616 23:55:27.555302 29366 sgd_solver.cpp:105] Iteration 105000, lr = 0.0001
I0616 23:56:25.312731 29366 solver.cpp:218] Iteration 105050 (0.865695 iter/s, 57.7571s/50 iters), loss = 0.00549941
I0616 23:56:25.312873 29366 solver.cpp:237]     Train net output #0: loss = 0.00549948 (* 1 = 0.00549948 loss)
I0616 23:56:25.312896 29366 sgd_solver.cpp:105] Iteration 105050, lr = 0.0001
I0616 23:57:23.075249 29366 solver.cpp:218] Iteration 105100 (0.865621 iter/s, 57.762s/50 iters), loss = 0.00551736
I0616 23:57:23.075374 29366 solver.cpp:237]     Train net output #0: loss = 0.00551743 (* 1 = 0.00551743 loss)
I0616 23:57:23.075399 29366 sgd_solver.cpp:105] Iteration 105100, lr = 0.0001
I0616 23:58:20.840776 29366 solver.cpp:218] Iteration 105150 (0.865576 iter/s, 57.765s/50 iters), loss = 0.0071685
I0616 23:58:20.840940 29366 solver.cpp:237]     Train net output #0: loss = 0.00716856 (* 1 = 0.00716856 loss)
I0616 23:58:20.840972 29366 sgd_solver.cpp:105] Iteration 105150, lr = 0.0001
I0616 23:59:18.614866 29366 solver.cpp:218] Iteration 105200 (0.865448 iter/s, 57.7735s/50 iters), loss = 0.00614563
I0616 23:59:18.615038 29366 solver.cpp:237]     Train net output #0: loss = 0.00614569 (* 1 = 0.00614569 loss)
I0616 23:59:18.615063 29366 sgd_solver.cpp:105] Iteration 105200, lr = 0.0001
I0617 00:00:16.393699 29366 solver.cpp:218] Iteration 105250 (0.865377 iter/s, 57.7783s/50 iters), loss = 0.00707657
I0617 00:00:16.393895 29366 solver.cpp:237]     Train net output #0: loss = 0.00707663 (* 1 = 0.00707663 loss)
I0617 00:00:16.393920 29366 sgd_solver.cpp:105] Iteration 105250, lr = 0.0001
I0617 00:01:14.171298 29366 solver.cpp:218] Iteration 105300 (0.865396 iter/s, 57.777s/50 iters), loss = 0.0058305
I0617 00:01:14.171603 29366 solver.cpp:237]     Train net output #0: loss = 0.00583057 (* 1 = 0.00583057 loss)
I0617 00:01:14.171628 29366 sgd_solver.cpp:105] Iteration 105300, lr = 0.0001
I0617 00:02:11.935149 29366 solver.cpp:218] Iteration 105350 (0.865604 iter/s, 57.7631s/50 iters), loss = 0.00912158
I0617 00:02:11.935336 29366 solver.cpp:237]     Train net output #0: loss = 0.00912164 (* 1 = 0.00912164 loss)
I0617 00:02:11.935361 29366 sgd_solver.cpp:105] Iteration 105350, lr = 0.0001
I0617 00:03:09.701431 29366 solver.cpp:218] Iteration 105400 (0.865566 iter/s, 57.7657s/50 iters), loss = 0.00619408
I0617 00:03:09.701596 29366 solver.cpp:237]     Train net output #0: loss = 0.00619415 (* 1 = 0.00619415 loss)
I0617 00:03:09.701622 29366 sgd_solver.cpp:105] Iteration 105400, lr = 0.0001
I0617 00:04:07.463660 29366 solver.cpp:218] Iteration 105450 (0.865626 iter/s, 57.7617s/50 iters), loss = 0.0069822
I0617 00:04:07.463845 29366 solver.cpp:237]     Train net output #0: loss = 0.00698227 (* 1 = 0.00698227 loss)
I0617 00:04:07.463871 29366 sgd_solver.cpp:105] Iteration 105450, lr = 0.0001
I0617 00:05:05.231572 29366 solver.cpp:218] Iteration 105500 (0.865541 iter/s, 57.7673s/50 iters), loss = 0.00498691
I0617 00:05:05.231750 29366 solver.cpp:237]     Train net output #0: loss = 0.00498697 (* 1 = 0.00498697 loss)
I0617 00:05:05.231775 29366 sgd_solver.cpp:105] Iteration 105500, lr = 0.0001
I0617 00:06:02.999608 29366 solver.cpp:218] Iteration 105550 (0.865539 iter/s, 57.7674s/50 iters), loss = 0.00571585
I0617 00:06:02.999891 29366 solver.cpp:237]     Train net output #0: loss = 0.00571592 (* 1 = 0.00571592 loss)
I0617 00:06:02.999917 29366 sgd_solver.cpp:105] Iteration 105550, lr = 0.0001
I0617 00:07:00.774826 29366 solver.cpp:218] Iteration 105600 (0.865433 iter/s, 57.7745s/50 iters), loss = 0.00760081
I0617 00:07:00.775084 29366 solver.cpp:237]     Train net output #0: loss = 0.00760088 (* 1 = 0.00760088 loss)
I0617 00:07:00.775110 29366 sgd_solver.cpp:105] Iteration 105600, lr = 0.0001
I0617 00:07:58.548775 29366 solver.cpp:218] Iteration 105650 (0.865452 iter/s, 57.7733s/50 iters), loss = 0.00497316
I0617 00:07:58.548980 29366 solver.cpp:237]     Train net output #0: loss = 0.00497322 (* 1 = 0.00497322 loss)
I0617 00:07:58.549005 29366 sgd_solver.cpp:105] Iteration 105650, lr = 0.0001
I0617 00:08:56.326926 29366 solver.cpp:218] Iteration 105700 (0.865388 iter/s, 57.7775s/50 iters), loss = 0.00419132
I0617 00:08:56.327222 29366 solver.cpp:237]     Train net output #0: loss = 0.00419138 (* 1 = 0.00419138 loss)
I0617 00:08:56.327250 29366 sgd_solver.cpp:105] Iteration 105700, lr = 0.0001
I0617 00:09:54.106765 29366 solver.cpp:218] Iteration 105750 (0.865364 iter/s, 57.7791s/50 iters), loss = 0.00755353
I0617 00:09:54.106956 29366 solver.cpp:237]     Train net output #0: loss = 0.0075536 (* 1 = 0.0075536 loss)
I0617 00:09:54.106981 29366 sgd_solver.cpp:105] Iteration 105750, lr = 0.0001
I0617 00:10:51.883317 29366 solver.cpp:218] Iteration 105800 (0.865412 iter/s, 57.776s/50 iters), loss = 0.00857615
I0617 00:10:51.883505 29366 solver.cpp:237]     Train net output #0: loss = 0.00857621 (* 1 = 0.00857621 loss)
I0617 00:10:51.883538 29366 sgd_solver.cpp:105] Iteration 105800, lr = 0.0001
I0617 00:11:49.657878 29366 solver.cpp:218] Iteration 105850 (0.865442 iter/s, 57.774s/50 iters), loss = 0.00525233
I0617 00:11:49.658076 29366 solver.cpp:237]     Train net output #0: loss = 0.0052524 (* 1 = 0.0052524 loss)
I0617 00:11:49.658100 29366 sgd_solver.cpp:105] Iteration 105850, lr = 0.0001
I0617 00:12:47.442355 29366 solver.cpp:218] Iteration 105900 (0.865294 iter/s, 57.7839s/50 iters), loss = 0.00557904
I0617 00:12:47.442543 29366 solver.cpp:237]     Train net output #0: loss = 0.0055791 (* 1 = 0.0055791 loss)
I0617 00:12:47.442570 29366 sgd_solver.cpp:105] Iteration 105900, lr = 0.0001
I0617 00:13:45.223971 29366 solver.cpp:218] Iteration 105950 (0.865336 iter/s, 57.781s/50 iters), loss = 0.00793651
I0617 00:13:45.224159 29366 solver.cpp:237]     Train net output #0: loss = 0.00793657 (* 1 = 0.00793657 loss)
I0617 00:13:45.224182 29366 sgd_solver.cpp:105] Iteration 105950, lr = 0.0001
I0617 00:14:43.001054 29366 solver.cpp:218] Iteration 106000 (0.865404 iter/s, 57.7765s/50 iters), loss = 0.0108294
I0617 00:14:43.001237 29366 solver.cpp:237]     Train net output #0: loss = 0.0108295 (* 1 = 0.0108295 loss)
I0617 00:14:43.001271 29366 sgd_solver.cpp:105] Iteration 106000, lr = 0.0001
I0617 00:15:40.776763 29366 solver.cpp:218] Iteration 106050 (0.865425 iter/s, 57.7751s/50 iters), loss = 0.00916352
I0617 00:15:40.776933 29366 solver.cpp:237]     Train net output #0: loss = 0.00916359 (* 1 = 0.00916359 loss)
I0617 00:15:40.776958 29366 sgd_solver.cpp:105] Iteration 106050, lr = 0.0001
I0617 00:16:38.551615 29366 solver.cpp:218] Iteration 106100 (0.865437 iter/s, 57.7743s/50 iters), loss = 0.00684262
I0617 00:16:38.551800 29366 solver.cpp:237]     Train net output #0: loss = 0.00684269 (* 1 = 0.00684269 loss)
I0617 00:16:38.551823 29366 sgd_solver.cpp:105] Iteration 106100, lr = 0.0001
I0617 00:17:36.323173 29366 solver.cpp:218] Iteration 106150 (0.865487 iter/s, 57.771s/50 iters), loss = 0.00578262
I0617 00:17:36.323369 29366 solver.cpp:237]     Train net output #0: loss = 0.00578268 (* 1 = 0.00578268 loss)
I0617 00:17:36.323395 29366 sgd_solver.cpp:105] Iteration 106150, lr = 0.0001
I0617 00:18:34.081135 29366 solver.cpp:218] Iteration 106200 (0.865691 iter/s, 57.7573s/50 iters), loss = 0.00735737
I0617 00:18:34.081431 29366 solver.cpp:237]     Train net output #0: loss = 0.00735743 (* 1 = 0.00735743 loss)
I0617 00:18:34.081459 29366 sgd_solver.cpp:105] Iteration 106200, lr = 0.0001
I0617 00:19:31.840978 29366 solver.cpp:218] Iteration 106250 (0.865664 iter/s, 57.7591s/50 iters), loss = 0.00909447
I0617 00:19:31.841251 29366 solver.cpp:237]     Train net output #0: loss = 0.00909453 (* 1 = 0.00909453 loss)
I0617 00:19:31.841292 29366 sgd_solver.cpp:105] Iteration 106250, lr = 0.0001
I0617 00:20:29.597977 29366 solver.cpp:218] Iteration 106300 (0.865706 iter/s, 57.7563s/50 iters), loss = 0.00634674
I0617 00:20:29.598162 29366 solver.cpp:237]     Train net output #0: loss = 0.00634681 (* 1 = 0.00634681 loss)
I0617 00:20:29.598187 29366 sgd_solver.cpp:105] Iteration 106300, lr = 0.0001
I0617 00:21:27.355271 29366 solver.cpp:218] Iteration 106350 (0.8657 iter/s, 57.7567s/50 iters), loss = 0.0073446
I0617 00:21:27.355442 29366 solver.cpp:237]     Train net output #0: loss = 0.00734466 (* 1 = 0.00734466 loss)
I0617 00:21:27.355466 29366 sgd_solver.cpp:105] Iteration 106350, lr = 0.0001
I0617 00:22:25.108222 29366 solver.cpp:218] Iteration 106400 (0.865765 iter/s, 57.7524s/50 iters), loss = 0.00529687
I0617 00:22:25.108361 29366 solver.cpp:237]     Train net output #0: loss = 0.00529693 (* 1 = 0.00529693 loss)
I0617 00:22:25.108387 29366 sgd_solver.cpp:105] Iteration 106400, lr = 0.0001
I0617 00:23:22.869827 29366 solver.cpp:218] Iteration 106450 (0.865635 iter/s, 57.7611s/50 iters), loss = 0.0106176
I0617 00:23:22.870004 29366 solver.cpp:237]     Train net output #0: loss = 0.0106177 (* 1 = 0.0106177 loss)
I0617 00:23:22.870029 29366 sgd_solver.cpp:105] Iteration 106450, lr = 0.0001
I0617 00:24:20.625313 29366 solver.cpp:218] Iteration 106500 (0.865727 iter/s, 57.7549s/50 iters), loss = 0.00663541
I0617 00:24:20.625572 29366 solver.cpp:237]     Train net output #0: loss = 0.00663547 (* 1 = 0.00663547 loss)
I0617 00:24:20.625599 29366 sgd_solver.cpp:105] Iteration 106500, lr = 0.0001
I0617 00:25:18.385128 29366 solver.cpp:218] Iteration 106550 (0.865664 iter/s, 57.7591s/50 iters), loss = 0.00416938
I0617 00:25:18.385321 29366 solver.cpp:237]     Train net output #0: loss = 0.00416944 (* 1 = 0.00416944 loss)
I0617 00:25:18.385347 29366 sgd_solver.cpp:105] Iteration 106550, lr = 0.0001
I0617 00:26:16.140954 29366 solver.cpp:218] Iteration 106600 (0.865722 iter/s, 57.7552s/50 iters), loss = 0.00727254
I0617 00:26:16.141082 29366 solver.cpp:237]     Train net output #0: loss = 0.00727261 (* 1 = 0.00727261 loss)
I0617 00:26:16.141106 29366 sgd_solver.cpp:105] Iteration 106600, lr = 0.0001
I0617 00:27:13.890012 29366 solver.cpp:218] Iteration 106650 (0.865823 iter/s, 57.7485s/50 iters), loss = 0.00663361
I0617 00:27:13.890168 29366 solver.cpp:237]     Train net output #0: loss = 0.00663368 (* 1 = 0.00663368 loss)
I0617 00:27:13.890192 29366 sgd_solver.cpp:105] Iteration 106650, lr = 0.0001
I0617 00:28:11.653458 29366 solver.cpp:218] Iteration 106700 (0.865608 iter/s, 57.7629s/50 iters), loss = 0.00749645
I0617 00:28:11.653626 29366 solver.cpp:237]     Train net output #0: loss = 0.00749651 (* 1 = 0.00749651 loss)
I0617 00:28:11.653650 29366 sgd_solver.cpp:105] Iteration 106700, lr = 0.0001
I0617 00:29:09.426786 29366 solver.cpp:218] Iteration 106750 (0.86546 iter/s, 57.7728s/50 iters), loss = 0.00714305
I0617 00:29:09.426975 29366 solver.cpp:237]     Train net output #0: loss = 0.00714311 (* 1 = 0.00714311 loss)
I0617 00:29:09.427001 29366 sgd_solver.cpp:105] Iteration 106750, lr = 0.0001
I0617 00:30:07.196300 29366 solver.cpp:218] Iteration 106800 (0.865517 iter/s, 57.7689s/50 iters), loss = 0.00744232
I0617 00:30:07.196473 29366 solver.cpp:237]     Train net output #0: loss = 0.00744238 (* 1 = 0.00744238 loss)
I0617 00:30:07.196498 29366 sgd_solver.cpp:105] Iteration 106800, lr = 0.0001
I0617 00:31:04.969646 29366 solver.cpp:218] Iteration 106850 (0.86546 iter/s, 57.7728s/50 iters), loss = 0.00617449
I0617 00:31:04.969815 29366 solver.cpp:237]     Train net output #0: loss = 0.00617456 (* 1 = 0.00617456 loss)
I0617 00:31:04.969847 29366 sgd_solver.cpp:105] Iteration 106850, lr = 0.0001
I0617 00:32:02.744293 29366 solver.cpp:218] Iteration 106900 (0.86544 iter/s, 57.7741s/50 iters), loss = 0.00572948
I0617 00:32:02.744495 29366 solver.cpp:237]     Train net output #0: loss = 0.00572954 (* 1 = 0.00572954 loss)
I0617 00:32:02.744531 29366 sgd_solver.cpp:105] Iteration 106900, lr = 0.0001
I0617 00:33:00.515331 29366 solver.cpp:218] Iteration 106950 (0.865495 iter/s, 57.7704s/50 iters), loss = 0.00775217
I0617 00:33:00.515625 29366 solver.cpp:237]     Train net output #0: loss = 0.00775223 (* 1 = 0.00775223 loss)
I0617 00:33:00.515652 29366 sgd_solver.cpp:105] Iteration 106950, lr = 0.0001
I0617 00:33:58.287317 29366 solver.cpp:218] Iteration 107000 (0.865482 iter/s, 57.7713s/50 iters), loss = 0.00817438
I0617 00:33:58.287485 29366 solver.cpp:237]     Train net output #0: loss = 0.00817445 (* 1 = 0.00817445 loss)
I0617 00:33:58.287509 29366 sgd_solver.cpp:105] Iteration 107000, lr = 0.0001
I0617 00:34:56.060452 29366 solver.cpp:218] Iteration 107050 (0.865463 iter/s, 57.7726s/50 iters), loss = 0.00453612
I0617 00:34:56.060708 29366 solver.cpp:237]     Train net output #0: loss = 0.00453618 (* 1 = 0.00453618 loss)
I0617 00:34:56.060732 29366 sgd_solver.cpp:105] Iteration 107050, lr = 0.0001
I0617 00:35:53.829963 29366 solver.cpp:218] Iteration 107100 (0.865518 iter/s, 57.7689s/50 iters), loss = 0.00688576
I0617 00:35:53.830235 29366 solver.cpp:237]     Train net output #0: loss = 0.00688583 (* 1 = 0.00688583 loss)
I0617 00:35:53.830261 29366 sgd_solver.cpp:105] Iteration 107100, lr = 0.0001
I0617 00:36:51.621132 29366 solver.cpp:218] Iteration 107150 (0.865195 iter/s, 57.7904s/50 iters), loss = 0.00491056
I0617 00:36:51.621417 29366 solver.cpp:237]     Train net output #0: loss = 0.00491062 (* 1 = 0.00491062 loss)
I0617 00:36:51.621450 29366 sgd_solver.cpp:105] Iteration 107150, lr = 0.0001
I0617 00:37:49.382593 29366 solver.cpp:218] Iteration 107200 (0.86564 iter/s, 57.7607s/50 iters), loss = 0.00364701
I0617 00:37:49.383263 29366 solver.cpp:237]     Train net output #0: loss = 0.00364707 (* 1 = 0.00364707 loss)
I0617 00:37:49.383289 29366 sgd_solver.cpp:105] Iteration 107200, lr = 0.0001
I0617 00:38:47.130548 29366 solver.cpp:218] Iteration 107250 (0.865849 iter/s, 57.7468s/50 iters), loss = 0.0064726
I0617 00:38:47.130714 29366 solver.cpp:237]     Train net output #0: loss = 0.00647266 (* 1 = 0.00647266 loss)
I0617 00:38:47.130746 29366 sgd_solver.cpp:105] Iteration 107250, lr = 0.0001
I0617 00:39:44.899574 29366 solver.cpp:218] Iteration 107300 (0.865525 iter/s, 57.7684s/50 iters), loss = 0.00604552
I0617 00:39:44.899752 29366 solver.cpp:237]     Train net output #0: loss = 0.00604558 (* 1 = 0.00604558 loss)
I0617 00:39:44.899778 29366 sgd_solver.cpp:105] Iteration 107300, lr = 0.0001
I0617 00:40:42.651594 29366 solver.cpp:218] Iteration 107350 (0.86578 iter/s, 57.7514s/50 iters), loss = 0.00334282
I0617 00:40:42.651793 29366 solver.cpp:237]     Train net output #0: loss = 0.00334288 (* 1 = 0.00334288 loss)
I0617 00:40:42.651818 29366 sgd_solver.cpp:105] Iteration 107350, lr = 0.0001
I0617 00:41:40.409070 29366 solver.cpp:218] Iteration 107400 (0.865699 iter/s, 57.7568s/50 iters), loss = 0.00420137
I0617 00:41:40.409325 29366 solver.cpp:237]     Train net output #0: loss = 0.00420144 (* 1 = 0.00420144 loss)
I0617 00:41:40.409350 29366 sgd_solver.cpp:105] Iteration 107400, lr = 0.0001
I0617 00:42:38.157650 29366 solver.cpp:218] Iteration 107450 (0.865833 iter/s, 57.7479s/50 iters), loss = 0.00523085
I0617 00:42:38.157827 29366 solver.cpp:237]     Train net output #0: loss = 0.00523091 (* 1 = 0.00523091 loss)
I0617 00:42:38.157852 29366 sgd_solver.cpp:105] Iteration 107450, lr = 0.0001
I0617 00:43:35.925753 29366 solver.cpp:218] Iteration 107500 (0.865539 iter/s, 57.7675s/50 iters), loss = 0.00618898
I0617 00:43:35.928596 29366 solver.cpp:237]     Train net output #0: loss = 0.00618904 (* 1 = 0.00618904 loss)
I0617 00:43:35.928620 29366 sgd_solver.cpp:105] Iteration 107500, lr = 0.0001
I0617 00:44:33.685113 29366 solver.cpp:218] Iteration 107550 (0.86571 iter/s, 57.7561s/50 iters), loss = 0.0104541
I0617 00:44:33.685246 29366 solver.cpp:237]     Train net output #0: loss = 0.0104542 (* 1 = 0.0104542 loss)
I0617 00:44:33.685271 29366 sgd_solver.cpp:105] Iteration 107550, lr = 0.0001
I0617 00:45:31.451292 29366 solver.cpp:218] Iteration 107600 (0.865567 iter/s, 57.7656s/50 iters), loss = 0.00565265
I0617 00:45:31.451529 29366 solver.cpp:237]     Train net output #0: loss = 0.00565271 (* 1 = 0.00565271 loss)
I0617 00:45:31.451573 29366 sgd_solver.cpp:105] Iteration 107600, lr = 0.0001
I0617 00:46:29.200815 29366 solver.cpp:218] Iteration 107650 (0.865818 iter/s, 57.7489s/50 iters), loss = 0.0075097
I0617 00:46:29.200956 29366 solver.cpp:237]     Train net output #0: loss = 0.00750976 (* 1 = 0.00750976 loss)
I0617 00:46:29.200981 29366 sgd_solver.cpp:105] Iteration 107650, lr = 0.0001
I0617 00:47:26.957118 29366 solver.cpp:218] Iteration 107700 (0.865716 iter/s, 57.7557s/50 iters), loss = 0.00430219
I0617 00:47:26.957314 29366 solver.cpp:237]     Train net output #0: loss = 0.00430225 (* 1 = 0.00430225 loss)
I0617 00:47:26.957339 29366 sgd_solver.cpp:105] Iteration 107700, lr = 0.0001
I0617 00:48:24.728662 29366 solver.cpp:218] Iteration 107750 (0.865488 iter/s, 57.7709s/50 iters), loss = 0.00489991
I0617 00:48:24.729472 29366 solver.cpp:237]     Train net output #0: loss = 0.00489997 (* 1 = 0.00489997 loss)
I0617 00:48:24.729496 29366 sgd_solver.cpp:105] Iteration 107750, lr = 0.0001
I0617 00:49:22.504914 29366 solver.cpp:218] Iteration 107800 (0.865427 iter/s, 57.775s/50 iters), loss = 0.00752257
I0617 00:49:22.505111 29366 solver.cpp:237]     Train net output #0: loss = 0.00752263 (* 1 = 0.00752263 loss)
I0617 00:49:22.505137 29366 sgd_solver.cpp:105] Iteration 107800, lr = 0.0001
I0617 00:50:20.271270 29366 solver.cpp:218] Iteration 107850 (0.865566 iter/s, 57.7657s/50 iters), loss = 0.00486786
I0617 00:50:20.271448 29366 solver.cpp:237]     Train net output #0: loss = 0.00486792 (* 1 = 0.00486792 loss)
I0617 00:50:20.271473 29366 sgd_solver.cpp:105] Iteration 107850, lr = 0.0001
I0617 00:51:18.048362 29366 solver.cpp:218] Iteration 107900 (0.865404 iter/s, 57.7765s/50 iters), loss = 0.00716279
I0617 00:51:18.048552 29366 solver.cpp:237]     Train net output #0: loss = 0.00716285 (* 1 = 0.00716285 loss)
I0617 00:51:18.048579 29366 sgd_solver.cpp:105] Iteration 107900, lr = 0.0001
I0617 00:52:15.821882 29366 solver.cpp:218] Iteration 107950 (0.865458 iter/s, 57.7729s/50 iters), loss = 0.00645025
I0617 00:52:15.822067 29366 solver.cpp:237]     Train net output #0: loss = 0.00645031 (* 1 = 0.00645031 loss)
I0617 00:52:15.822093 29366 sgd_solver.cpp:105] Iteration 107950, lr = 0.0001
I0617 00:53:13.589960 29366 solver.cpp:218] Iteration 108000 (0.86554 iter/s, 57.7674s/50 iters), loss = 0.00499752
I0617 00:53:13.590139 29366 solver.cpp:237]     Train net output #0: loss = 0.00499758 (* 1 = 0.00499758 loss)
I0617 00:53:13.590164 29366 sgd_solver.cpp:105] Iteration 108000, lr = 0.0001
I0617 00:54:11.360193 29366 solver.cpp:218] Iteration 108050 (0.865507 iter/s, 57.7696s/50 iters), loss = 0.00684421
I0617 00:54:11.360460 29366 solver.cpp:237]     Train net output #0: loss = 0.00684427 (* 1 = 0.00684427 loss)
I0617 00:54:11.360486 29366 sgd_solver.cpp:105] Iteration 108050, lr = 0.0001
I0617 00:55:09.184056 29366 solver.cpp:218] Iteration 108100 (0.864706 iter/s, 57.8231s/50 iters), loss = 0.00542286
I0617 00:55:09.184243 29366 solver.cpp:237]     Train net output #0: loss = 0.00542292 (* 1 = 0.00542292 loss)
I0617 00:55:09.184268 29366 sgd_solver.cpp:105] Iteration 108100, lr = 0.0001
I0617 00:56:06.954283 29366 solver.cpp:218] Iteration 108150 (0.865507 iter/s, 57.7696s/50 iters), loss = 0.00644343
I0617 00:56:06.954469 29366 solver.cpp:237]     Train net output #0: loss = 0.00644349 (* 1 = 0.00644349 loss)
I0617 00:56:06.954495 29366 sgd_solver.cpp:105] Iteration 108150, lr = 0.0001
I0617 00:57:04.723371 29366 solver.cpp:218] Iteration 108200 (0.865524 iter/s, 57.7684s/50 iters), loss = 0.00824656
I0617 00:57:04.723565 29366 solver.cpp:237]     Train net output #0: loss = 0.00824662 (* 1 = 0.00824662 loss)
I0617 00:57:04.723592 29366 sgd_solver.cpp:105] Iteration 108200, lr = 0.0001
I0617 00:58:02.483299 29366 solver.cpp:218] Iteration 108250 (0.865662 iter/s, 57.7593s/50 iters), loss = 0.00815383
I0617 00:58:02.483505 29366 solver.cpp:237]     Train net output #0: loss = 0.00815389 (* 1 = 0.00815389 loss)
I0617 00:58:02.483538 29366 sgd_solver.cpp:105] Iteration 108250, lr = 0.0001
I0617 00:59:00.246116 29366 solver.cpp:218] Iteration 108300 (0.865619 iter/s, 57.7622s/50 iters), loss = 0.0039837
I0617 00:59:00.246289 29366 solver.cpp:237]     Train net output #0: loss = 0.00398376 (* 1 = 0.00398376 loss)
I0617 00:59:00.246315 29366 sgd_solver.cpp:105] Iteration 108300, lr = 0.0001
I0617 00:59:58.008782 29366 solver.cpp:218] Iteration 108350 (0.86562 iter/s, 57.7621s/50 iters), loss = 0.00535403
I0617 00:59:58.008913 29366 solver.cpp:237]     Train net output #0: loss = 0.00535409 (* 1 = 0.00535409 loss)
I0617 00:59:58.008937 29366 sgd_solver.cpp:105] Iteration 108350, lr = 0.0001
I0617 01:00:55.759066 29366 solver.cpp:218] Iteration 108400 (0.865805 iter/s, 57.7497s/50 iters), loss = 0.00688485
I0617 01:00:55.759240 29366 solver.cpp:237]     Train net output #0: loss = 0.00688491 (* 1 = 0.00688491 loss)
I0617 01:00:55.759264 29366 sgd_solver.cpp:105] Iteration 108400, lr = 0.0001
I0617 01:01:53.528064 29366 solver.cpp:218] Iteration 108450 (0.865526 iter/s, 57.7684s/50 iters), loss = 0.00445155
I0617 01:01:53.528332 29366 solver.cpp:237]     Train net output #0: loss = 0.00445162 (* 1 = 0.00445162 loss)
I0617 01:01:53.528357 29366 sgd_solver.cpp:105] Iteration 108450, lr = 0.0001
I0617 01:02:51.270833 29366 solver.cpp:218] Iteration 108500 (0.865921 iter/s, 57.742s/50 iters), loss = 0.00752946
I0617 01:02:51.271033 29366 solver.cpp:237]     Train net output #0: loss = 0.00752953 (* 1 = 0.00752953 loss)
I0617 01:02:51.271064 29366 sgd_solver.cpp:105] Iteration 108500, lr = 0.0001
I0617 01:03:49.035954 29366 solver.cpp:218] Iteration 108550 (0.865584 iter/s, 57.7645s/50 iters), loss = 0.00761917
I0617 01:03:49.036134 29366 solver.cpp:237]     Train net output #0: loss = 0.00761923 (* 1 = 0.00761923 loss)
I0617 01:03:49.036157 29366 sgd_solver.cpp:105] Iteration 108550, lr = 0.0001
I0617 01:04:46.783895 29366 solver.cpp:218] Iteration 108600 (0.865841 iter/s, 57.7473s/50 iters), loss = 0.00837565
I0617 01:04:46.784093 29366 solver.cpp:237]     Train net output #0: loss = 0.00837571 (* 1 = 0.00837571 loss)
I0617 01:04:46.784122 29366 sgd_solver.cpp:105] Iteration 108600, lr = 0.0001
I0617 01:05:44.547268 29366 solver.cpp:218] Iteration 108650 (0.865611 iter/s, 57.7627s/50 iters), loss = 0.00844302
I0617 01:05:44.547467 29366 solver.cpp:237]     Train net output #0: loss = 0.00844308 (* 1 = 0.00844308 loss)
I0617 01:05:44.547499 29366 sgd_solver.cpp:105] Iteration 108650, lr = 0.0001
I0617 01:06:42.309553 29366 solver.cpp:218] Iteration 108700 (0.865626 iter/s, 57.7617s/50 iters), loss = 0.00450929
I0617 01:06:42.309689 29366 solver.cpp:237]     Train net output #0: loss = 0.00450935 (* 1 = 0.00450935 loss)
I0617 01:06:42.309720 29366 sgd_solver.cpp:105] Iteration 108700, lr = 0.0001
I0617 01:07:40.075947 29366 solver.cpp:218] Iteration 108750 (0.865564 iter/s, 57.7658s/50 iters), loss = 0.00419755
I0617 01:07:40.076100 29366 solver.cpp:237]     Train net output #0: loss = 0.00419761 (* 1 = 0.00419761 loss)
I0617 01:07:40.076125 29366 sgd_solver.cpp:105] Iteration 108750, lr = 0.0001
I0617 01:08:37.815907 29366 solver.cpp:218] Iteration 108800 (0.865962 iter/s, 57.7393s/50 iters), loss = 0.00542904
I0617 01:08:37.816102 29366 solver.cpp:237]     Train net output #0: loss = 0.00542911 (* 1 = 0.00542911 loss)
I0617 01:08:37.816134 29366 sgd_solver.cpp:105] Iteration 108800, lr = 0.0001
I0617 01:09:35.566800 29366 solver.cpp:218] Iteration 108850 (0.865797 iter/s, 57.7503s/50 iters), loss = 0.00534544
I0617 01:09:35.566967 29366 solver.cpp:237]     Train net output #0: loss = 0.0053455 (* 1 = 0.0053455 loss)
I0617 01:09:35.566994 29366 sgd_solver.cpp:105] Iteration 108850, lr = 0.0001
I0617 01:10:33.315847 29366 solver.cpp:218] Iteration 108900 (0.865826 iter/s, 57.7484s/50 iters), loss = 0.00789742
I0617 01:10:33.316020 29366 solver.cpp:237]     Train net output #0: loss = 0.00789748 (* 1 = 0.00789748 loss)
I0617 01:10:33.316045 29366 sgd_solver.cpp:105] Iteration 108900, lr = 0.0001
I0617 01:11:31.057495 29366 solver.cpp:218] Iteration 108950 (0.865939 iter/s, 57.7408s/50 iters), loss = 0.00601523
I0617 01:11:31.057727 29366 solver.cpp:237]     Train net output #0: loss = 0.00601529 (* 1 = 0.00601529 loss)
I0617 01:11:31.057754 29366 sgd_solver.cpp:105] Iteration 108950, lr = 0.0001
I0617 01:12:28.802984 29366 solver.cpp:218] Iteration 109000 (0.865882 iter/s, 57.7446s/50 iters), loss = 0.00472044
I0617 01:12:28.803138 29366 solver.cpp:237]     Train net output #0: loss = 0.0047205 (* 1 = 0.0047205 loss)
I0617 01:12:28.803164 29366 sgd_solver.cpp:105] Iteration 109000, lr = 0.0001
I0617 01:13:26.608189 29366 solver.cpp:218] Iteration 109050 (0.864987 iter/s, 57.8044s/50 iters), loss = 0.00575136
I0617 01:13:26.608340 29366 solver.cpp:237]     Train net output #0: loss = 0.00575143 (* 1 = 0.00575143 loss)
I0617 01:13:26.608364 29366 sgd_solver.cpp:105] Iteration 109050, lr = 0.0001
I0617 01:14:24.340405 29366 solver.cpp:218] Iteration 109100 (0.866081 iter/s, 57.7314s/50 iters), loss = 0.00907155
I0617 01:14:24.340540 29366 solver.cpp:237]     Train net output #0: loss = 0.00907161 (* 1 = 0.00907161 loss)
I0617 01:14:24.340574 29366 sgd_solver.cpp:105] Iteration 109100, lr = 0.0001
I0617 01:15:22.074415 29366 solver.cpp:218] Iteration 109150 (0.866053 iter/s, 57.7332s/50 iters), loss = 0.00694381
I0617 01:15:22.074571 29366 solver.cpp:237]     Train net output #0: loss = 0.00694387 (* 1 = 0.00694387 loss)
I0617 01:15:22.074596 29366 sgd_solver.cpp:105] Iteration 109150, lr = 0.0001
I0617 01:16:19.885783 29366 solver.cpp:218] Iteration 109200 (0.864895 iter/s, 57.8105s/50 iters), loss = 0.00448604
I0617 01:16:19.885978 29366 solver.cpp:237]     Train net output #0: loss = 0.0044861 (* 1 = 0.0044861 loss)
I0617 01:16:19.886003 29366 sgd_solver.cpp:105] Iteration 109200, lr = 0.0001
I0617 01:17:17.629364 29366 solver.cpp:218] Iteration 109250 (0.86591 iter/s, 57.7427s/50 iters), loss = 0.00522062
I0617 01:17:17.629511 29366 solver.cpp:237]     Train net output #0: loss = 0.00522068 (* 1 = 0.00522068 loss)
I0617 01:17:17.629544 29366 sgd_solver.cpp:105] Iteration 109250, lr = 0.0001
I0617 01:18:15.358448 29366 solver.cpp:218] Iteration 109300 (0.866127 iter/s, 57.7283s/50 iters), loss = 0.00532692
I0617 01:18:15.361310 29366 solver.cpp:237]     Train net output #0: loss = 0.00532698 (* 1 = 0.00532698 loss)
I0617 01:18:15.361335 29366 sgd_solver.cpp:105] Iteration 109300, lr = 0.0001
I0617 01:19:13.083220 29366 solver.cpp:218] Iteration 109350 (0.866232 iter/s, 57.7212s/50 iters), loss = 0.00859579
I0617 01:19:13.083372 29366 solver.cpp:237]     Train net output #0: loss = 0.00859585 (* 1 = 0.00859585 loss)
I0617 01:19:13.083398 29366 sgd_solver.cpp:105] Iteration 109350, lr = 0.0001
I0617 01:20:10.813118 29366 solver.cpp:218] Iteration 109400 (0.866115 iter/s, 57.729s/50 iters), loss = 0.00684437
I0617 01:20:10.813308 29366 solver.cpp:237]     Train net output #0: loss = 0.00684444 (* 1 = 0.00684444 loss)
I0617 01:20:10.813334 29366 sgd_solver.cpp:105] Iteration 109400, lr = 0.0001
I0617 01:21:08.601250 29366 solver.cpp:218] Iteration 109450 (0.865243 iter/s, 57.7872s/50 iters), loss = 0.0041647
I0617 01:21:08.601433 29366 solver.cpp:237]     Train net output #0: loss = 0.00416476 (* 1 = 0.00416476 loss)
I0617 01:21:08.601456 29366 sgd_solver.cpp:105] Iteration 109450, lr = 0.0001
I0617 01:22:06.340654 29366 solver.cpp:218] Iteration 109500 (0.865972 iter/s, 57.7386s/50 iters), loss = 0.00529047
I0617 01:22:06.340795 29366 solver.cpp:237]     Train net output #0: loss = 0.00529053 (* 1 = 0.00529053 loss)
I0617 01:22:06.340819 29366 sgd_solver.cpp:105] Iteration 109500, lr = 0.0001
I0617 01:23:04.077229 29366 solver.cpp:218] Iteration 109550 (0.866015 iter/s, 57.7357s/50 iters), loss = 0.00663798
I0617 01:23:04.077394 29366 solver.cpp:237]     Train net output #0: loss = 0.00663805 (* 1 = 0.00663805 loss)
I0617 01:23:04.077419 29366 sgd_solver.cpp:105] Iteration 109550, lr = 0.0001
I0617 01:24:01.802712 29366 solver.cpp:218] Iteration 109600 (0.866181 iter/s, 57.7246s/50 iters), loss = 0.00533207
I0617 01:24:01.802983 29366 solver.cpp:237]     Train net output #0: loss = 0.00533213 (* 1 = 0.00533213 loss)
I0617 01:24:01.803021 29366 sgd_solver.cpp:105] Iteration 109600, lr = 0.0001
I0617 01:28:08.956164 13482 caffe.cpp:218] Using GPUs 3
I0617 01:28:09.106170 13482 caffe.cpp:223] GPU 3: Tesla K40m
I0617 01:28:09.472604 13482 solver.cpp:44] Initializing solver from parameters: 
base_lr: 0.01
display: 50
max_iter: 200000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.001
stepsize: 50000
snapshot: 10000
snapshot_prefix: "mobilenet/mobile_2"
solver_mode: GPU
device_id: 3
net: "/home/xingzhaolong/caffe_project/caffe_mobile/models/oxford/mobilenet/mobilenet_deploy.prototxt"
train_state {
  level: 0
  stage: ""
}
I0617 01:28:09.472988 13482 solver.cpp:87] Creating training net from net file: /home/xingzhaolong/caffe_project/caffe_mobile/models/oxford/mobilenet/mobilenet_deploy.prototxt
I0617 01:28:09.475621 13482 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/xingzhaolong/caffe_project/caffe_mobile/models/oxford/mobilenet/mobilenet_deploy.prototxt
I0617 01:28:09.475649 13482 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0617 01:28:09.475965 13482 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0617 01:28:09.476061 13482 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0617 01:28:09.477035 13482 net.cpp:51] Initializing net from parameters: 
name: "MOBILENET"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_file: "/home/xingzhaolong/caffe_project/caffe/models/caffe-oxford102/imagenet_mean.binaryproto"
  }
  image_data_param {
    source: "/home/xingzhaolong/caffe_project/caffe/models/caffe-oxford102/test.txt"
    batch_size: 50
    new_height: 256
    new_width: 256
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv1/bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1/scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2_1/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv1"
  top: "conv2_1/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 32
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv2_1/dw"
  top: "conv2_1/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_1/dw/scale"
  type: "Scale"
  bottom: "conv2_1/dw"
  top: "conv2_1/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_1/dw"
  type: "ReLU"
  bottom: "conv2_1/dw"
  top: "conv2_1/dw"
}
layer {
  name: "conv2_1/sep"
  type: "Convolution"
  bottom: "conv2_1/dw"
  top: "conv2_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv2_1/sep"
  top: "conv2_1/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_1/sep/scale"
  type: "Scale"
  bottom: "conv2_1/sep"
  top: "conv2_1/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_1/sep"
  type: "ReLU"
  bottom: "conv2_1/sep"
  top: "conv2_1/sep"
}
layer {
  name: "conv2_2/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv2_1/sep"
  top: "conv2_2/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 64
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv2_2/dw"
  top: "conv2_2/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_2/dw/scale"
  type: "Scale"
  bottom: "conv2_2/dw"
  top: "conv2_2/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_2/dw"
  type: "ReLU"
  bottom: "conv2_2/dw"
  top: "conv2_2/dw"
}
layer {
  name: "conv2_2/sep"
  type: "Convolution"
  bottom: "conv2_2/dw"
  top: "conv2_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv2_2/sep"
  top: "conv2_2/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_2/sep/scale"
  type: "Scale"
  bottom: "conv2_2/sep"
  top: "conv2_2/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_2/sep"
  type: "ReLU"
  bottom: "conv2_2/sep"
  top: "conv2_2/sep"
}
layer {
  name: "conv3_1/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv2_2/sep"
  top: "conv3_1/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv3_1/dw"
  top: "conv3_1/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_1/dw/scale"
  type: "Scale"
  bottom: "conv3_1/dw"
  top: "conv3_1/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_1/dw"
  type: "ReLU"
  bottom: "conv3_1/dw"
  top: "conv3_1/dw"
}
layer {
  name: "conv3_1/sep"
  type: "Convolution"
  bottom: "conv3_1/dw"
  top: "conv3_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv3_1/sep"
  top: "conv3_1/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_1/sep/scale"
  type: "Scale"
  bottom: "conv3_1/sep"
  top: "conv3_1/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_1/sep"
  type: "ReLU"
  bottom: "conv3_1/sep"
  top: "conv3_1/sep"
}
layer {
  name: "conv3_2/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv3_1/sep"
  top: "conv3_2/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv3_2/dw"
  top: "conv3_2/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_2/dw/scale"
  type: "Scale"
  bottom: "conv3_2/dw"
  top: "conv3_2/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_2/dw"
  type: "ReLU"
  bottom: "conv3_2/dw"
  top: "conv3_2/dw"
}
layer {
  name: "conv3_2/sep"
  type: "Convolution"
  bottom: "conv3_2/dw"
  top: "conv3_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv3_2/sep"
  top: "conv3_2/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_2/sep/scale"
  type: "Scale"
  bottom: "conv3_2/sep"
  top: "conv3_2/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_2/sep"
  type: "ReLU"
  bottom: "conv3_2/sep"
  top: "conv3_2/sep"
}
layer {
  name: "conv4_1/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv3_2/sep"
  top: "conv4_1/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv4_1/dw"
  top: "conv4_1/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv4_1/dw/scale"
  type: "Scale"
  bottom: "conv4_1/dw"
  top: "conv4_1/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu4_1/dw"
  type: "ReLU"
  bottom: "conv4_1/dw"
  top: "conv4_1/dw"
}
layer {
  name: "conv4_1/sep"
  type: "Convolution"
  bottom: "conv4_1/dw"
  top: "conv4_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv4_1/sep"
  top: "conv4_1/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv4_1/sep/scale"
  type: "Scale"
  bottom: "conv4_1/sep"
  top: "conv4_1/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu4_1/sep"
  type: "ReLU"
  bottom: "conv4_1/sep"
  top: "conv4_1/sep"
}
layer {
  name: "conv4_2/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv4_1/sep"
  top: "conv4_2/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv4_2/dw"
  top: "conv4_2/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv4_2/dw/scale"
  type: "Scale"
  bottom: "conv4_2/dw"
  top: "conv4_2/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu4_2/dw"
  type: "ReLU"
  bottom: "conv4_2/dw"
  top: "conv4_2/dw"
}
layer {
  name: "conv4_2/sep"
  type: "Convolution"
  bottom: "conv4_2/dw"
  top: "conv4_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv4_2/sep"
  top: "conv4_2/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv4_2/sep/scale"
  type: "Scale"
  bottom: "conv4_2/sep"
  top: "conv4_2/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu4_2/sep"
  type: "ReLU"
  bottom: "conv4_2/sep"
  top: "conv4_2/sep"
}
layer {
  name: "conv5_1/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv4_2/sep"
  top: "conv5_1/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_1/dw"
  top: "conv5_1/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_1/dw/scale"
  type: "Scale"
  bottom: "conv5_1/dw"
  top: "conv5_1/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_1/dw"
  type: "ReLU"
  bottom: "conv5_1/dw"
  top: "conv5_1/dw"
}
layer {
  name: "conv5_1/sep"
  type: "Convolution"
  bottom: "conv5_1/dw"
  top: "conv5_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_1/sep"
  top: "conv5_1/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_1/sep/scale"
  type: "Scale"
  bottom: "conv5_1/sep"
  top: "conv5_1/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_1/sep"
  type: "ReLU"
  bottom: "conv5_1/sep"
  top: "conv5_1/sep"
}
layer {
  name: "conv5_2/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_1/sep"
  top: "conv5_2/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_2/dw"
  top: "conv5_2/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_2/dw/scale"
  type: "Scale"
  bottom: "conv5_2/dw"
  top: "conv5_2/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_2/dw"
  type: "ReLU"
  bottom: "conv5_2/dw"
  top: "conv5_2/dw"
}
layer {
  name: "conv5_2/sep"
  type: "Convolution"
  bottom: "conv5_2/dw"
  top: "conv5_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_2/sep"
  top: "conv5_2/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_2/sep/scale"
  type: "Scale"
  bottom: "conv5_2/sep"
  top: "conv5_2/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_2/sep"
  type: "ReLU"
  bottom: "conv5_2/sep"
  top: "conv5_2/sep"
}
layer {
  name: "conv5_3/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_2/sep"
  top: "conv5_3/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_3/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_3/dw"
  top: "conv5_3/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_3/dw/scale"
  type: "Scale"
  bottom: "conv5_3/dw"
  top: "conv5_3/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_3/dw"
  type: "ReLU"
  bottom: "conv5_3/dw"
  top: "conv5_3/dw"
}
layer {
  name: "conv5_3/sep"
  type: "Convolution"
  bottom: "conv5_3/dw"
  top: "conv5_3/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_3/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_3/sep"
  top: "conv5_3/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_3/sep/scale"
  type: "Scale"
  bottom: "conv5_3/sep"
  top: "conv5_3/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_3/sep"
  type: "ReLU"
  bottom: "conv5_3/sep"
  top: "conv5_3/sep"
}
layer {
  name: "conv5_4/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_3/sep"
  top: "conv5_4/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_4/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_4/dw"
  top: "conv5_4/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_4/dw/scale"
  type: "Scale"
  bottom: "conv5_4/dw"
  top: "conv5_4/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_4/dw"
  type: "ReLU"
  bottom: "conv5_4/dw"
  top: "conv5_4/dw"
}
layer {
  name: "conv5_4/sep"
  type: "Convolution"
  bottom: "conv5_4/dw"
  top: "conv5_4/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_4/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_4/sep"
  top: "conv5_4/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_4/sep/scale"
  type: "Scale"
  bottom: "conv5_4/sep"
  top: "conv5_4/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_4/sep"
  type: "ReLU"
  bottom: "conv5_4/sep"
  top: "conv5_4/sep"
}
layer {
  name: "conv5_5/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_4/sep"
  top: "conv5_5/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_5/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_5/dw"
  top: "conv5_5/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_5/dw/scale"
  type: "Scale"
  bottom: "conv5_5/dw"
  top: "conv5_5/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_5/dw"
  type: "ReLU"
  bottom: "conv5_5/dw"
  top: "conv5_5/dw"
}
layer {
  name: "conv5_5/sep"
  type: "Convolution"
  bottom: "conv5_5/dw"
  top: "conv5_5/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_5/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_5/sep"
  top: "conv5_5/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_5/sep/scale"
  type: "Scale"
  bottom: "conv5_5/sep"
  top: "conv5_5/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_5/sep"
  type: "ReLU"
  bottom: "conv5_5/sep"
  top: "conv5_5/sep"
}
layer {
  name: "conv5_6/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_5/sep"
  top: "conv5_6/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_6/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_6/dw"
  top: "conv5_6/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_6/dw/scale"
  type: "Scale"
  bottom: "conv5_6/dw"
  top: "conv5_6/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_6/dw"
  type: "ReLU"
  bottom: "conv5_6/dw"
  top: "conv5_6/dw"
}
layer {
  name: "conv5_6/sep"
  type: "Convolution"
  bottom: "conv5_6/dw"
  top: "conv5_6/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_6/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_6/sep"
  top: "conv5_6/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_6/sep/scale"
  type: "Scale"
  bottom: "conv5_6/sep"
  top: "conv5_6/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_6/sep"
  type: "ReLU"
  bottom: "conv5_6/sep"
  top: "conv5_6/sep"
}
layer {
  name: "conv6/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_6/sep"
  top: "conv6/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 1024
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv6/dw/bn"
  type: "BatchNorm"
  bottom: "conv6/dw"
  top: "conv6/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv6/dw/scale"
  type: "Scale"
  bottom: "conv6/dw"
  top: "conv6/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu6/dw"
  type: "ReLU"
  bottom: "conv6/dw"
  top: "conv6/dw"
}
layer {
  name: "conv6/sep"
  type: "Convolution"
  bottom: "conv6/dw"
  top: "conv6/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv6/sep/bn"
  type: "BatchNorm"
  bottom: "conv6/sep"
  top: "conv6/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv6/sep/scale"
  type: "Scale"
  bottom: "conv6/sep"
  top: "conv6/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu6/sep"
  type: "ReLU"
  bottom: "conv6/sep"
  top: "conv6/sep"
}
layer {
  name: "pool6"
  type: "Pooling"
  bottom: "conv6/sep"
  top: "pool6"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc7"
  type: "Convolution"
  bottom: "pool6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 102
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc7"
  bottom: "label"
  top: "loss"
}
I0617 01:28:09.477572 13482 layer_factory.hpp:77] Creating layer data
I0617 01:28:09.477672 13482 net.cpp:84] Creating Layer data
I0617 01:28:09.477697 13482 net.cpp:380] data -> data
I0617 01:28:09.477746 13482 net.cpp:380] data -> label
I0617 01:28:09.477780 13482 data_transformer.cpp:25] Loading mean file from: /home/xingzhaolong/caffe_project/caffe/models/caffe-oxford102/imagenet_mean.binaryproto
I0617 01:28:09.482879 13482 image_data_layer.cpp:38] Opening file /home/xingzhaolong/caffe_project/caffe/models/caffe-oxford102/test.txt
I0617 01:28:09.485126 13482 image_data_layer.cpp:63] A total of 6149 images.
I0617 01:28:09.493723 13482 image_data_layer.cpp:90] output data size: 50,3,224,224
I0617 01:28:09.596482 13482 net.cpp:122] Setting up data
I0617 01:28:09.596563 13482 net.cpp:129] Top shape: 50 3 224 224 (7526400)
I0617 01:28:09.596578 13482 net.cpp:129] Top shape: 50 (50)
I0617 01:28:09.596587 13482 net.cpp:137] Memory required for data: 30105800
I0617 01:28:09.596603 13482 layer_factory.hpp:77] Creating layer conv1
I0617 01:28:09.596654 13482 net.cpp:84] Creating Layer conv1
I0617 01:28:09.596670 13482 net.cpp:406] conv1 <- data
I0617 01:28:09.596709 13482 net.cpp:380] conv1 -> conv1
I0617 01:28:09.824939 13482 net.cpp:122] Setting up conv1
I0617 01:28:09.825002 13482 net.cpp:129] Top shape: 50 32 112 112 (20070400)
I0617 01:28:09.825012 13482 net.cpp:137] Memory required for data: 110387400
I0617 01:28:09.825052 13482 layer_factory.hpp:77] Creating layer conv1/bn
I0617 01:28:09.825083 13482 net.cpp:84] Creating Layer conv1/bn
I0617 01:28:09.825095 13482 net.cpp:406] conv1/bn <- conv1
I0617 01:28:09.825115 13482 net.cpp:367] conv1/bn -> conv1 (in-place)
I0617 01:28:09.826231 13482 net.cpp:122] Setting up conv1/bn
I0617 01:28:09.826253 13482 net.cpp:129] Top shape: 50 32 112 112 (20070400)
I0617 01:28:09.826262 13482 net.cpp:137] Memory required for data: 190669000
I0617 01:28:09.826288 13482 layer_factory.hpp:77] Creating layer conv1/scale
I0617 01:28:09.826310 13482 net.cpp:84] Creating Layer conv1/scale
I0617 01:28:09.826320 13482 net.cpp:406] conv1/scale <- conv1
I0617 01:28:09.826331 13482 net.cpp:367] conv1/scale -> conv1 (in-place)
I0617 01:28:09.826405 13482 layer_factory.hpp:77] Creating layer conv1/scale
I0617 01:28:09.826596 13482 net.cpp:122] Setting up conv1/scale
I0617 01:28:09.826617 13482 net.cpp:129] Top shape: 50 32 112 112 (20070400)
I0617 01:28:09.826625 13482 net.cpp:137] Memory required for data: 270950600
I0617 01:28:09.826642 13482 layer_factory.hpp:77] Creating layer relu1
I0617 01:28:09.826661 13482 net.cpp:84] Creating Layer relu1
I0617 01:28:09.826671 13482 net.cpp:406] relu1 <- conv1
I0617 01:28:09.826683 13482 net.cpp:367] relu1 -> conv1 (in-place)
I0617 01:28:09.827128 13482 net.cpp:122] Setting up relu1
I0617 01:28:09.827152 13482 net.cpp:129] Top shape: 50 32 112 112 (20070400)
I0617 01:28:09.827162 13482 net.cpp:137] Memory required for data: 351232200
I0617 01:28:09.827169 13482 layer_factory.hpp:77] Creating layer conv2_1/dw
I0617 01:28:09.827190 13482 net.cpp:84] Creating Layer conv2_1/dw
I0617 01:28:09.827200 13482 net.cpp:406] conv2_1/dw <- conv1
I0617 01:28:09.827216 13482 net.cpp:380] conv2_1/dw -> conv2_1/dw
I0617 01:28:09.829711 13482 net.cpp:122] Setting up conv2_1/dw
I0617 01:28:09.829735 13482 net.cpp:129] Top shape: 50 32 112 112 (20070400)
I0617 01:28:09.829743 13482 net.cpp:137] Memory required for data: 431513800
I0617 01:28:09.829774 13482 layer_factory.hpp:77] Creating layer conv2_1/dw/bn
I0617 01:28:09.829788 13482 net.cpp:84] Creating Layer conv2_1/dw/bn
I0617 01:28:09.829797 13482 net.cpp:406] conv2_1/dw/bn <- conv2_1/dw
I0617 01:28:09.829813 13482 net.cpp:367] conv2_1/dw/bn -> conv2_1/dw (in-place)
I0617 01:28:09.830049 13482 net.cpp:122] Setting up conv2_1/dw/bn
I0617 01:28:09.830066 13482 net.cpp:129] Top shape: 50 32 112 112 (20070400)
I0617 01:28:09.830075 13482 net.cpp:137] Memory required for data: 511795400
I0617 01:28:09.830091 13482 layer_factory.hpp:77] Creating layer conv2_1/dw/scale
I0617 01:28:09.830108 13482 net.cpp:84] Creating Layer conv2_1/dw/scale
I0617 01:28:09.830117 13482 net.cpp:406] conv2_1/dw/scale <- conv2_1/dw
I0617 01:28:09.830129 13482 net.cpp:367] conv2_1/dw/scale -> conv2_1/dw (in-place)
I0617 01:28:09.830185 13482 layer_factory.hpp:77] Creating layer conv2_1/dw/scale
I0617 01:28:09.830349 13482 net.cpp:122] Setting up conv2_1/dw/scale
I0617 01:28:09.830368 13482 net.cpp:129] Top shape: 50 32 112 112 (20070400)
I0617 01:28:09.830375 13482 net.cpp:137] Memory required for data: 592077000
I0617 01:28:09.830387 13482 layer_factory.hpp:77] Creating layer relu2_1/dw
I0617 01:28:09.830404 13482 net.cpp:84] Creating Layer relu2_1/dw
I0617 01:28:09.830413 13482 net.cpp:406] relu2_1/dw <- conv2_1/dw
I0617 01:28:09.830425 13482 net.cpp:367] relu2_1/dw -> conv2_1/dw (in-place)
I0617 01:28:09.830659 13482 net.cpp:122] Setting up relu2_1/dw
I0617 01:28:09.830680 13482 net.cpp:129] Top shape: 50 32 112 112 (20070400)
I0617 01:28:09.830689 13482 net.cpp:137] Memory required for data: 672358600
I0617 01:28:09.830698 13482 layer_factory.hpp:77] Creating layer conv2_1/sep
I0617 01:28:09.830720 13482 net.cpp:84] Creating Layer conv2_1/sep
I0617 01:28:09.830730 13482 net.cpp:406] conv2_1/sep <- conv2_1/dw
I0617 01:28:09.830744 13482 net.cpp:380] conv2_1/sep -> conv2_1/sep
I0617 01:28:09.832909 13482 net.cpp:122] Setting up conv2_1/sep
I0617 01:28:09.832936 13482 net.cpp:129] Top shape: 50 64 112 112 (40140800)
I0617 01:28:09.832944 13482 net.cpp:137] Memory required for data: 832921800
I0617 01:28:09.832955 13482 layer_factory.hpp:77] Creating layer conv2_1/sep/bn
I0617 01:28:09.832968 13482 net.cpp:84] Creating Layer conv2_1/sep/bn
I0617 01:28:09.832978 13482 net.cpp:406] conv2_1/sep/bn <- conv2_1/sep
I0617 01:28:09.832993 13482 net.cpp:367] conv2_1/sep/bn -> conv2_1/sep (in-place)
I0617 01:28:09.833240 13482 net.cpp:122] Setting up conv2_1/sep/bn
I0617 01:28:09.833257 13482 net.cpp:129] Top shape: 50 64 112 112 (40140800)
I0617 01:28:09.833266 13482 net.cpp:137] Memory required for data: 993485000
I0617 01:28:09.833279 13482 layer_factory.hpp:77] Creating layer conv2_1/sep/scale
I0617 01:28:09.833292 13482 net.cpp:84] Creating Layer conv2_1/sep/scale
I0617 01:28:09.833302 13482 net.cpp:406] conv2_1/sep/scale <- conv2_1/sep
I0617 01:28:09.833313 13482 net.cpp:367] conv2_1/sep/scale -> conv2_1/sep (in-place)
I0617 01:28:09.833375 13482 layer_factory.hpp:77] Creating layer conv2_1/sep/scale
I0617 01:28:09.833564 13482 net.cpp:122] Setting up conv2_1/sep/scale
I0617 01:28:09.833585 13482 net.cpp:129] Top shape: 50 64 112 112 (40140800)
I0617 01:28:09.833592 13482 net.cpp:137] Memory required for data: 1154048200
I0617 01:28:09.833612 13482 layer_factory.hpp:77] Creating layer relu2_1/sep
I0617 01:28:09.833626 13482 net.cpp:84] Creating Layer relu2_1/sep
I0617 01:28:09.833634 13482 net.cpp:406] relu2_1/sep <- conv2_1/sep
I0617 01:28:09.833645 13482 net.cpp:367] relu2_1/sep -> conv2_1/sep (in-place)
I0617 01:28:09.834074 13482 net.cpp:122] Setting up relu2_1/sep
I0617 01:28:09.834095 13482 net.cpp:129] Top shape: 50 64 112 112 (40140800)
I0617 01:28:09.834103 13482 net.cpp:137] Memory required for data: 1314611400
I0617 01:28:09.834112 13482 layer_factory.hpp:77] Creating layer conv2_2/dw
I0617 01:28:09.834131 13482 net.cpp:84] Creating Layer conv2_2/dw
I0617 01:28:09.834151 13482 net.cpp:406] conv2_2/dw <- conv2_1/sep
I0617 01:28:09.834167 13482 net.cpp:380] conv2_2/dw -> conv2_2/dw
I0617 01:28:09.835223 13482 net.cpp:122] Setting up conv2_2/dw
I0617 01:28:09.835247 13482 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0617 01:28:09.835255 13482 net.cpp:137] Memory required for data: 1354752200
I0617 01:28:09.835265 13482 layer_factory.hpp:77] Creating layer conv2_2/dw/bn
I0617 01:28:09.835278 13482 net.cpp:84] Creating Layer conv2_2/dw/bn
I0617 01:28:09.835288 13482 net.cpp:406] conv2_2/dw/bn <- conv2_2/dw
I0617 01:28:09.835302 13482 net.cpp:367] conv2_2/dw/bn -> conv2_2/dw (in-place)
I0617 01:28:09.835553 13482 net.cpp:122] Setting up conv2_2/dw/bn
I0617 01:28:09.835572 13482 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0617 01:28:09.835580 13482 net.cpp:137] Memory required for data: 1394893000
I0617 01:28:09.835594 13482 layer_factory.hpp:77] Creating layer conv2_2/dw/scale
I0617 01:28:09.835608 13482 net.cpp:84] Creating Layer conv2_2/dw/scale
I0617 01:28:09.835616 13482 net.cpp:406] conv2_2/dw/scale <- conv2_2/dw
I0617 01:28:09.835628 13482 net.cpp:367] conv2_2/dw/scale -> conv2_2/dw (in-place)
I0617 01:28:09.835693 13482 layer_factory.hpp:77] Creating layer conv2_2/dw/scale
I0617 01:28:09.835856 13482 net.cpp:122] Setting up conv2_2/dw/scale
I0617 01:28:09.835875 13482 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0617 01:28:09.835882 13482 net.cpp:137] Memory required for data: 1435033800
I0617 01:28:09.835894 13482 layer_factory.hpp:77] Creating layer relu2_2/dw
I0617 01:28:09.835907 13482 net.cpp:84] Creating Layer relu2_2/dw
I0617 01:28:09.835917 13482 net.cpp:406] relu2_2/dw <- conv2_2/dw
I0617 01:28:09.835932 13482 net.cpp:367] relu2_2/dw -> conv2_2/dw (in-place)
I0617 01:28:09.836159 13482 net.cpp:122] Setting up relu2_2/dw
I0617 01:28:09.836179 13482 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0617 01:28:09.836186 13482 net.cpp:137] Memory required for data: 1475174600
I0617 01:28:09.836195 13482 layer_factory.hpp:77] Creating layer conv2_2/sep
I0617 01:28:09.836213 13482 net.cpp:84] Creating Layer conv2_2/sep
I0617 01:28:09.836223 13482 net.cpp:406] conv2_2/sep <- conv2_2/dw
I0617 01:28:09.836239 13482 net.cpp:380] conv2_2/sep -> conv2_2/sep
I0617 01:28:09.837713 13482 net.cpp:122] Setting up conv2_2/sep
I0617 01:28:09.837736 13482 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0617 01:28:09.837745 13482 net.cpp:137] Memory required for data: 1555456200
I0617 01:28:09.837756 13482 layer_factory.hpp:77] Creating layer conv2_2/sep/bn
I0617 01:28:09.837772 13482 net.cpp:84] Creating Layer conv2_2/sep/bn
I0617 01:28:09.837782 13482 net.cpp:406] conv2_2/sep/bn <- conv2_2/sep
I0617 01:28:09.837793 13482 net.cpp:367] conv2_2/sep/bn -> conv2_2/sep (in-place)
I0617 01:28:09.838029 13482 net.cpp:122] Setting up conv2_2/sep/bn
I0617 01:28:09.838047 13482 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0617 01:28:09.838054 13482 net.cpp:137] Memory required for data: 1635737800
I0617 01:28:09.838068 13482 layer_factory.hpp:77] Creating layer conv2_2/sep/scale
I0617 01:28:09.838080 13482 net.cpp:84] Creating Layer conv2_2/sep/scale
I0617 01:28:09.838089 13482 net.cpp:406] conv2_2/sep/scale <- conv2_2/sep
I0617 01:28:09.838100 13482 net.cpp:367] conv2_2/sep/scale -> conv2_2/sep (in-place)
I0617 01:28:09.838166 13482 layer_factory.hpp:77] Creating layer conv2_2/sep/scale
I0617 01:28:09.838315 13482 net.cpp:122] Setting up conv2_2/sep/scale
I0617 01:28:09.838331 13482 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0617 01:28:09.838340 13482 net.cpp:137] Memory required for data: 1716019400
I0617 01:28:09.838351 13482 layer_factory.hpp:77] Creating layer relu2_2/sep
I0617 01:28:09.838366 13482 net.cpp:84] Creating Layer relu2_2/sep
I0617 01:28:09.838376 13482 net.cpp:406] relu2_2/sep <- conv2_2/sep
I0617 01:28:09.838385 13482 net.cpp:367] relu2_2/sep -> conv2_2/sep (in-place)
I0617 01:28:09.838629 13482 net.cpp:122] Setting up relu2_2/sep
I0617 01:28:09.838649 13482 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0617 01:28:09.838665 13482 net.cpp:137] Memory required for data: 1796301000
I0617 01:28:09.838675 13482 layer_factory.hpp:77] Creating layer conv3_1/dw
I0617 01:28:09.838703 13482 net.cpp:84] Creating Layer conv3_1/dw
I0617 01:28:09.838714 13482 net.cpp:406] conv3_1/dw <- conv2_2/sep
I0617 01:28:09.838727 13482 net.cpp:380] conv3_1/dw -> conv3_1/dw
I0617 01:28:09.839787 13482 net.cpp:122] Setting up conv3_1/dw
I0617 01:28:09.839810 13482 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0617 01:28:09.839818 13482 net.cpp:137] Memory required for data: 1876582600
I0617 01:28:09.839829 13482 layer_factory.hpp:77] Creating layer conv3_1/dw/bn
I0617 01:28:09.839845 13482 net.cpp:84] Creating Layer conv3_1/dw/bn
I0617 01:28:09.839854 13482 net.cpp:406] conv3_1/dw/bn <- conv3_1/dw
I0617 01:28:09.839865 13482 net.cpp:367] conv3_1/dw/bn -> conv3_1/dw (in-place)
I0617 01:28:09.840096 13482 net.cpp:122] Setting up conv3_1/dw/bn
I0617 01:28:09.840113 13482 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0617 01:28:09.840121 13482 net.cpp:137] Memory required for data: 1956864200
I0617 01:28:09.840140 13482 layer_factory.hpp:77] Creating layer conv3_1/dw/scale
I0617 01:28:09.840158 13482 net.cpp:84] Creating Layer conv3_1/dw/scale
I0617 01:28:09.840168 13482 net.cpp:406] conv3_1/dw/scale <- conv3_1/dw
I0617 01:28:09.840179 13482 net.cpp:367] conv3_1/dw/scale -> conv3_1/dw (in-place)
I0617 01:28:09.840237 13482 layer_factory.hpp:77] Creating layer conv3_1/dw/scale
I0617 01:28:09.840391 13482 net.cpp:122] Setting up conv3_1/dw/scale
I0617 01:28:09.840409 13482 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0617 01:28:09.840416 13482 net.cpp:137] Memory required for data: 2037145800
I0617 01:28:09.840428 13482 layer_factory.hpp:77] Creating layer relu3_1/dw
I0617 01:28:09.840440 13482 net.cpp:84] Creating Layer relu3_1/dw
I0617 01:28:09.840448 13482 net.cpp:406] relu3_1/dw <- conv3_1/dw
I0617 01:28:09.840459 13482 net.cpp:367] relu3_1/dw -> conv3_1/dw (in-place)
I0617 01:28:09.840896 13482 net.cpp:122] Setting up relu3_1/dw
I0617 01:28:09.840919 13482 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0617 01:28:09.840927 13482 net.cpp:137] Memory required for data: 2117427400
I0617 01:28:09.840935 13482 layer_factory.hpp:77] Creating layer conv3_1/sep
I0617 01:28:09.840956 13482 net.cpp:84] Creating Layer conv3_1/sep
I0617 01:28:09.840966 13482 net.cpp:406] conv3_1/sep <- conv3_1/dw
I0617 01:28:09.840979 13482 net.cpp:380] conv3_1/sep -> conv3_1/sep
I0617 01:28:09.842762 13482 net.cpp:122] Setting up conv3_1/sep
I0617 01:28:09.842789 13482 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0617 01:28:09.842799 13482 net.cpp:137] Memory required for data: 2197709000
I0617 01:28:09.842810 13482 layer_factory.hpp:77] Creating layer conv3_1/sep/bn
I0617 01:28:09.842825 13482 net.cpp:84] Creating Layer conv3_1/sep/bn
I0617 01:28:09.842835 13482 net.cpp:406] conv3_1/sep/bn <- conv3_1/sep
I0617 01:28:09.842846 13482 net.cpp:367] conv3_1/sep/bn -> conv3_1/sep (in-place)
I0617 01:28:09.843085 13482 net.cpp:122] Setting up conv3_1/sep/bn
I0617 01:28:09.843101 13482 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0617 01:28:09.843111 13482 net.cpp:137] Memory required for data: 2277990600
I0617 01:28:09.843123 13482 layer_factory.hpp:77] Creating layer conv3_1/sep/scale
I0617 01:28:09.843139 13482 net.cpp:84] Creating Layer conv3_1/sep/scale
I0617 01:28:09.843148 13482 net.cpp:406] conv3_1/sep/scale <- conv3_1/sep
I0617 01:28:09.843160 13482 net.cpp:367] conv3_1/sep/scale -> conv3_1/sep (in-place)
I0617 01:28:09.843219 13482 layer_factory.hpp:77] Creating layer conv3_1/sep/scale
I0617 01:28:09.843367 13482 net.cpp:122] Setting up conv3_1/sep/scale
I0617 01:28:09.843384 13482 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0617 01:28:09.843394 13482 net.cpp:137] Memory required for data: 2358272200
I0617 01:28:09.843405 13482 layer_factory.hpp:77] Creating layer relu3_1/sep
I0617 01:28:09.843416 13482 net.cpp:84] Creating Layer relu3_1/sep
I0617 01:28:09.843425 13482 net.cpp:406] relu3_1/sep <- conv3_1/sep
I0617 01:28:09.843438 13482 net.cpp:367] relu3_1/sep -> conv3_1/sep (in-place)
I0617 01:28:09.843683 13482 net.cpp:122] Setting up relu3_1/sep
I0617 01:28:09.843703 13482 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0617 01:28:09.843721 13482 net.cpp:137] Memory required for data: 2438553800
I0617 01:28:09.843729 13482 layer_factory.hpp:77] Creating layer conv3_2/dw
I0617 01:28:09.843746 13482 net.cpp:84] Creating Layer conv3_2/dw
I0617 01:28:09.843756 13482 net.cpp:406] conv3_2/dw <- conv3_1/sep
I0617 01:28:09.843770 13482 net.cpp:380] conv3_2/dw -> conv3_2/dw
I0617 01:28:09.844714 13482 net.cpp:122] Setting up conv3_2/dw
I0617 01:28:09.844736 13482 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0617 01:28:09.844744 13482 net.cpp:137] Memory required for data: 2458624200
I0617 01:28:09.844755 13482 layer_factory.hpp:77] Creating layer conv3_2/dw/bn
I0617 01:28:09.844771 13482 net.cpp:84] Creating Layer conv3_2/dw/bn
I0617 01:28:09.844781 13482 net.cpp:406] conv3_2/dw/bn <- conv3_2/dw
I0617 01:28:09.844794 13482 net.cpp:367] conv3_2/dw/bn -> conv3_2/dw (in-place)
I0617 01:28:09.845037 13482 net.cpp:122] Setting up conv3_2/dw/bn
I0617 01:28:09.845054 13482 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0617 01:28:09.845062 13482 net.cpp:137] Memory required for data: 2478694600
I0617 01:28:09.845079 13482 layer_factory.hpp:77] Creating layer conv3_2/dw/scale
I0617 01:28:09.845093 13482 net.cpp:84] Creating Layer conv3_2/dw/scale
I0617 01:28:09.845101 13482 net.cpp:406] conv3_2/dw/scale <- conv3_2/dw
I0617 01:28:09.845113 13482 net.cpp:367] conv3_2/dw/scale -> conv3_2/dw (in-place)
I0617 01:28:09.845172 13482 layer_factory.hpp:77] Creating layer conv3_2/dw/scale
I0617 01:28:09.845325 13482 net.cpp:122] Setting up conv3_2/dw/scale
I0617 01:28:09.845342 13482 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0617 01:28:09.845350 13482 net.cpp:137] Memory required for data: 2498765000
I0617 01:28:09.845362 13482 layer_factory.hpp:77] Creating layer relu3_2/dw
I0617 01:28:09.845381 13482 net.cpp:84] Creating Layer relu3_2/dw
I0617 01:28:09.845391 13482 net.cpp:406] relu3_2/dw <- conv3_2/dw
I0617 01:28:09.845403 13482 net.cpp:367] relu3_2/dw -> conv3_2/dw (in-place)
I0617 01:28:09.845849 13482 net.cpp:122] Setting up relu3_2/dw
I0617 01:28:09.845871 13482 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0617 01:28:09.845880 13482 net.cpp:137] Memory required for data: 2518835400
I0617 01:28:09.845888 13482 layer_factory.hpp:77] Creating layer conv3_2/sep
I0617 01:28:09.845907 13482 net.cpp:84] Creating Layer conv3_2/sep
I0617 01:28:09.845917 13482 net.cpp:406] conv3_2/sep <- conv3_2/dw
I0617 01:28:09.845930 13482 net.cpp:380] conv3_2/sep -> conv3_2/sep
I0617 01:28:09.847735 13482 net.cpp:122] Setting up conv3_2/sep
I0617 01:28:09.847759 13482 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0617 01:28:09.847767 13482 net.cpp:137] Memory required for data: 2558976200
I0617 01:28:09.847779 13482 layer_factory.hpp:77] Creating layer conv3_2/sep/bn
I0617 01:28:09.847795 13482 net.cpp:84] Creating Layer conv3_2/sep/bn
I0617 01:28:09.847805 13482 net.cpp:406] conv3_2/sep/bn <- conv3_2/sep
I0617 01:28:09.847816 13482 net.cpp:367] conv3_2/sep/bn -> conv3_2/sep (in-place)
I0617 01:28:09.848057 13482 net.cpp:122] Setting up conv3_2/sep/bn
I0617 01:28:09.848074 13482 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0617 01:28:09.848083 13482 net.cpp:137] Memory required for data: 2599117000
I0617 01:28:09.848095 13482 layer_factory.hpp:77] Creating layer conv3_2/sep/scale
I0617 01:28:09.848111 13482 net.cpp:84] Creating Layer conv3_2/sep/scale
I0617 01:28:09.848121 13482 net.cpp:406] conv3_2/sep/scale <- conv3_2/sep
I0617 01:28:09.848132 13482 net.cpp:367] conv3_2/sep/scale -> conv3_2/sep (in-place)
I0617 01:28:09.848191 13482 layer_factory.hpp:77] Creating layer conv3_2/sep/scale
I0617 01:28:09.848350 13482 net.cpp:122] Setting up conv3_2/sep/scale
I0617 01:28:09.848366 13482 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0617 01:28:09.848374 13482 net.cpp:137] Memory required for data: 2639257800
I0617 01:28:09.848387 13482 layer_factory.hpp:77] Creating layer relu3_2/sep
I0617 01:28:09.848407 13482 net.cpp:84] Creating Layer relu3_2/sep
I0617 01:28:09.848415 13482 net.cpp:406] relu3_2/sep <- conv3_2/sep
I0617 01:28:09.848439 13482 net.cpp:367] relu3_2/sep -> conv3_2/sep (in-place)
I0617 01:28:09.848676 13482 net.cpp:122] Setting up relu3_2/sep
I0617 01:28:09.848696 13482 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0617 01:28:09.848706 13482 net.cpp:137] Memory required for data: 2679398600
I0617 01:28:09.848713 13482 layer_factory.hpp:77] Creating layer conv4_1/dw
I0617 01:28:09.848731 13482 net.cpp:84] Creating Layer conv4_1/dw
I0617 01:28:09.848740 13482 net.cpp:406] conv4_1/dw <- conv3_2/sep
I0617 01:28:09.848757 13482 net.cpp:380] conv4_1/dw -> conv4_1/dw
I0617 01:28:09.848939 13482 net.cpp:122] Setting up conv4_1/dw
I0617 01:28:09.848958 13482 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0617 01:28:09.848965 13482 net.cpp:137] Memory required for data: 2719539400
I0617 01:28:09.848976 13482 layer_factory.hpp:77] Creating layer conv4_1/dw/bn
I0617 01:28:09.848992 13482 net.cpp:84] Creating Layer conv4_1/dw/bn
I0617 01:28:09.849002 13482 net.cpp:406] conv4_1/dw/bn <- conv4_1/dw
I0617 01:28:09.849014 13482 net.cpp:367] conv4_1/dw/bn -> conv4_1/dw (in-place)
I0617 01:28:09.849249 13482 net.cpp:122] Setting up conv4_1/dw/bn
I0617 01:28:09.849265 13482 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0617 01:28:09.849274 13482 net.cpp:137] Memory required for data: 2759680200
I0617 01:28:09.849287 13482 layer_factory.hpp:77] Creating layer conv4_1/dw/scale
I0617 01:28:09.849300 13482 net.cpp:84] Creating Layer conv4_1/dw/scale
I0617 01:28:09.849308 13482 net.cpp:406] conv4_1/dw/scale <- conv4_1/dw
I0617 01:28:09.849323 13482 net.cpp:367] conv4_1/dw/scale -> conv4_1/dw (in-place)
I0617 01:28:09.849378 13482 layer_factory.hpp:77] Creating layer conv4_1/dw/scale
I0617 01:28:09.849545 13482 net.cpp:122] Setting up conv4_1/dw/scale
I0617 01:28:09.849565 13482 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0617 01:28:09.849572 13482 net.cpp:137] Memory required for data: 2799821000
I0617 01:28:09.849584 13482 layer_factory.hpp:77] Creating layer relu4_1/dw
I0617 01:28:09.849599 13482 net.cpp:84] Creating Layer relu4_1/dw
I0617 01:28:09.849608 13482 net.cpp:406] relu4_1/dw <- conv4_1/dw
I0617 01:28:09.849619 13482 net.cpp:367] relu4_1/dw -> conv4_1/dw (in-place)
I0617 01:28:09.850064 13482 net.cpp:122] Setting up relu4_1/dw
I0617 01:28:09.850085 13482 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0617 01:28:09.850093 13482 net.cpp:137] Memory required for data: 2839961800
I0617 01:28:09.850101 13482 layer_factory.hpp:77] Creating layer conv4_1/sep
I0617 01:28:09.850121 13482 net.cpp:84] Creating Layer conv4_1/sep
I0617 01:28:09.850131 13482 net.cpp:406] conv4_1/sep <- conv4_1/dw
I0617 01:28:09.850147 13482 net.cpp:380] conv4_1/sep -> conv4_1/sep
I0617 01:28:09.852237 13482 net.cpp:122] Setting up conv4_1/sep
I0617 01:28:09.852262 13482 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0617 01:28:09.852272 13482 net.cpp:137] Memory required for data: 2880102600
I0617 01:28:09.852282 13482 layer_factory.hpp:77] Creating layer conv4_1/sep/bn
I0617 01:28:09.852298 13482 net.cpp:84] Creating Layer conv4_1/sep/bn
I0617 01:28:09.852308 13482 net.cpp:406] conv4_1/sep/bn <- conv4_1/sep
I0617 01:28:09.852322 13482 net.cpp:367] conv4_1/sep/bn -> conv4_1/sep (in-place)
I0617 01:28:09.852581 13482 net.cpp:122] Setting up conv4_1/sep/bn
I0617 01:28:09.852599 13482 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0617 01:28:09.852607 13482 net.cpp:137] Memory required for data: 2920243400
I0617 01:28:09.852620 13482 layer_factory.hpp:77] Creating layer conv4_1/sep/scale
I0617 01:28:09.852638 13482 net.cpp:84] Creating Layer conv4_1/sep/scale
I0617 01:28:09.852646 13482 net.cpp:406] conv4_1/sep/scale <- conv4_1/sep
I0617 01:28:09.852658 13482 net.cpp:367] conv4_1/sep/scale -> conv4_1/sep (in-place)
I0617 01:28:09.852717 13482 layer_factory.hpp:77] Creating layer conv4_1/sep/scale
I0617 01:28:09.852874 13482 net.cpp:122] Setting up conv4_1/sep/scale
I0617 01:28:09.852890 13482 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0617 01:28:09.852906 13482 net.cpp:137] Memory required for data: 2960384200
I0617 01:28:09.852933 13482 layer_factory.hpp:77] Creating layer relu4_1/sep
I0617 01:28:09.852962 13482 net.cpp:84] Creating Layer relu4_1/sep
I0617 01:28:09.852972 13482 net.cpp:406] relu4_1/sep <- conv4_1/sep
I0617 01:28:09.852982 13482 net.cpp:367] relu4_1/sep -> conv4_1/sep (in-place)
I0617 01:28:09.853432 13482 net.cpp:122] Setting up relu4_1/sep
I0617 01:28:09.853453 13482 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0617 01:28:09.853462 13482 net.cpp:137] Memory required for data: 3000525000
I0617 01:28:09.853471 13482 layer_factory.hpp:77] Creating layer conv4_2/dw
I0617 01:28:09.853488 13482 net.cpp:84] Creating Layer conv4_2/dw
I0617 01:28:09.853498 13482 net.cpp:406] conv4_2/dw <- conv4_1/sep
I0617 01:28:09.853521 13482 net.cpp:380] conv4_2/dw -> conv4_2/dw
I0617 01:28:09.853693 13482 net.cpp:122] Setting up conv4_2/dw
I0617 01:28:09.853711 13482 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0617 01:28:09.853719 13482 net.cpp:137] Memory required for data: 3010560200
I0617 01:28:09.853729 13482 layer_factory.hpp:77] Creating layer conv4_2/dw/bn
I0617 01:28:09.853745 13482 net.cpp:84] Creating Layer conv4_2/dw/bn
I0617 01:28:09.853755 13482 net.cpp:406] conv4_2/dw/bn <- conv4_2/dw
I0617 01:28:09.853770 13482 net.cpp:367] conv4_2/dw/bn -> conv4_2/dw (in-place)
I0617 01:28:09.854010 13482 net.cpp:122] Setting up conv4_2/dw/bn
I0617 01:28:09.854027 13482 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0617 01:28:09.854037 13482 net.cpp:137] Memory required for data: 3020595400
I0617 01:28:09.854049 13482 layer_factory.hpp:77] Creating layer conv4_2/dw/scale
I0617 01:28:09.854063 13482 net.cpp:84] Creating Layer conv4_2/dw/scale
I0617 01:28:09.854071 13482 net.cpp:406] conv4_2/dw/scale <- conv4_2/dw
I0617 01:28:09.854085 13482 net.cpp:367] conv4_2/dw/scale -> conv4_2/dw (in-place)
I0617 01:28:09.854141 13482 layer_factory.hpp:77] Creating layer conv4_2/dw/scale
I0617 01:28:09.854300 13482 net.cpp:122] Setting up conv4_2/dw/scale
I0617 01:28:09.854317 13482 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0617 01:28:09.854326 13482 net.cpp:137] Memory required for data: 3030630600
I0617 01:28:09.854338 13482 layer_factory.hpp:77] Creating layer relu4_2/dw
I0617 01:28:09.854349 13482 net.cpp:84] Creating Layer relu4_2/dw
I0617 01:28:09.854358 13482 net.cpp:406] relu4_2/dw <- conv4_2/dw
I0617 01:28:09.854368 13482 net.cpp:367] relu4_2/dw -> conv4_2/dw (in-place)
I0617 01:28:09.854802 13482 net.cpp:122] Setting up relu4_2/dw
I0617 01:28:09.854825 13482 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0617 01:28:09.854833 13482 net.cpp:137] Memory required for data: 3040665800
I0617 01:28:09.854841 13482 layer_factory.hpp:77] Creating layer conv4_2/sep
I0617 01:28:09.854861 13482 net.cpp:84] Creating Layer conv4_2/sep
I0617 01:28:09.854871 13482 net.cpp:406] conv4_2/sep <- conv4_2/dw
I0617 01:28:09.854887 13482 net.cpp:380] conv4_2/sep -> conv4_2/sep
I0617 01:28:09.858945 13482 net.cpp:122] Setting up conv4_2/sep
I0617 01:28:09.858971 13482 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:28:09.858980 13482 net.cpp:137] Memory required for data: 3060736200
I0617 01:28:09.858991 13482 layer_factory.hpp:77] Creating layer conv4_2/sep/bn
I0617 01:28:09.859009 13482 net.cpp:84] Creating Layer conv4_2/sep/bn
I0617 01:28:09.859019 13482 net.cpp:406] conv4_2/sep/bn <- conv4_2/sep
I0617 01:28:09.859031 13482 net.cpp:367] conv4_2/sep/bn -> conv4_2/sep (in-place)
I0617 01:28:09.859293 13482 net.cpp:122] Setting up conv4_2/sep/bn
I0617 01:28:09.859310 13482 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:28:09.859318 13482 net.cpp:137] Memory required for data: 3080806600
I0617 01:28:09.859333 13482 layer_factory.hpp:77] Creating layer conv4_2/sep/scale
I0617 01:28:09.859349 13482 net.cpp:84] Creating Layer conv4_2/sep/scale
I0617 01:28:09.859359 13482 net.cpp:406] conv4_2/sep/scale <- conv4_2/sep
I0617 01:28:09.859370 13482 net.cpp:367] conv4_2/sep/scale -> conv4_2/sep (in-place)
I0617 01:28:09.859428 13482 layer_factory.hpp:77] Creating layer conv4_2/sep/scale
I0617 01:28:09.859603 13482 net.cpp:122] Setting up conv4_2/sep/scale
I0617 01:28:09.859622 13482 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:28:09.859642 13482 net.cpp:137] Memory required for data: 3100877000
I0617 01:28:09.859653 13482 layer_factory.hpp:77] Creating layer relu4_2/sep
I0617 01:28:09.859665 13482 net.cpp:84] Creating Layer relu4_2/sep
I0617 01:28:09.859674 13482 net.cpp:406] relu4_2/sep <- conv4_2/sep
I0617 01:28:09.859688 13482 net.cpp:367] relu4_2/sep -> conv4_2/sep (in-place)
I0617 01:28:09.860126 13482 net.cpp:122] Setting up relu4_2/sep
I0617 01:28:09.860146 13482 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:28:09.860155 13482 net.cpp:137] Memory required for data: 3120947400
I0617 01:28:09.860163 13482 layer_factory.hpp:77] Creating layer conv5_1/dw
I0617 01:28:09.860182 13482 net.cpp:84] Creating Layer conv5_1/dw
I0617 01:28:09.860191 13482 net.cpp:406] conv5_1/dw <- conv4_2/sep
I0617 01:28:09.860203 13482 net.cpp:380] conv5_1/dw -> conv5_1/dw
I0617 01:28:09.860417 13482 net.cpp:122] Setting up conv5_1/dw
I0617 01:28:09.860435 13482 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:28:09.860443 13482 net.cpp:137] Memory required for data: 3141017800
I0617 01:28:09.860455 13482 layer_factory.hpp:77] Creating layer conv5_1/dw/bn
I0617 01:28:09.860471 13482 net.cpp:84] Creating Layer conv5_1/dw/bn
I0617 01:28:09.860481 13482 net.cpp:406] conv5_1/dw/bn <- conv5_1/dw
I0617 01:28:09.860491 13482 net.cpp:367] conv5_1/dw/bn -> conv5_1/dw (in-place)
I0617 01:28:09.860750 13482 net.cpp:122] Setting up conv5_1/dw/bn
I0617 01:28:09.860769 13482 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:28:09.860777 13482 net.cpp:137] Memory required for data: 3161088200
I0617 01:28:09.860791 13482 layer_factory.hpp:77] Creating layer conv5_1/dw/scale
I0617 01:28:09.860807 13482 net.cpp:84] Creating Layer conv5_1/dw/scale
I0617 01:28:09.860816 13482 net.cpp:406] conv5_1/dw/scale <- conv5_1/dw
I0617 01:28:09.860828 13482 net.cpp:367] conv5_1/dw/scale -> conv5_1/dw (in-place)
I0617 01:28:09.860888 13482 layer_factory.hpp:77] Creating layer conv5_1/dw/scale
I0617 01:28:09.861047 13482 net.cpp:122] Setting up conv5_1/dw/scale
I0617 01:28:09.861064 13482 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:28:09.861073 13482 net.cpp:137] Memory required for data: 3181158600
I0617 01:28:09.861084 13482 layer_factory.hpp:77] Creating layer relu5_1/dw
I0617 01:28:09.861099 13482 net.cpp:84] Creating Layer relu5_1/dw
I0617 01:28:09.861109 13482 net.cpp:406] relu5_1/dw <- conv5_1/dw
I0617 01:28:09.861119 13482 net.cpp:367] relu5_1/dw -> conv5_1/dw (in-place)
I0617 01:28:09.861347 13482 net.cpp:122] Setting up relu5_1/dw
I0617 01:28:09.861366 13482 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:28:09.861374 13482 net.cpp:137] Memory required for data: 3201229000
I0617 01:28:09.861383 13482 layer_factory.hpp:77] Creating layer conv5_1/sep
I0617 01:28:09.861403 13482 net.cpp:84] Creating Layer conv5_1/sep
I0617 01:28:09.861413 13482 net.cpp:406] conv5_1/sep <- conv5_1/dw
I0617 01:28:09.861426 13482 net.cpp:380] conv5_1/sep -> conv5_1/sep
I0617 01:28:09.867429 13482 net.cpp:122] Setting up conv5_1/sep
I0617 01:28:09.867455 13482 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:28:09.867465 13482 net.cpp:137] Memory required for data: 3221299400
I0617 01:28:09.867476 13482 layer_factory.hpp:77] Creating layer conv5_1/sep/bn
I0617 01:28:09.867492 13482 net.cpp:84] Creating Layer conv5_1/sep/bn
I0617 01:28:09.867502 13482 net.cpp:406] conv5_1/sep/bn <- conv5_1/sep
I0617 01:28:09.867523 13482 net.cpp:367] conv5_1/sep/bn -> conv5_1/sep (in-place)
I0617 01:28:09.867780 13482 net.cpp:122] Setting up conv5_1/sep/bn
I0617 01:28:09.867797 13482 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:28:09.867806 13482 net.cpp:137] Memory required for data: 3241369800
I0617 01:28:09.867820 13482 layer_factory.hpp:77] Creating layer conv5_1/sep/scale
I0617 01:28:09.867833 13482 net.cpp:84] Creating Layer conv5_1/sep/scale
I0617 01:28:09.867849 13482 net.cpp:406] conv5_1/sep/scale <- conv5_1/sep
I0617 01:28:09.867864 13482 net.cpp:367] conv5_1/sep/scale -> conv5_1/sep (in-place)
I0617 01:28:09.867929 13482 layer_factory.hpp:77] Creating layer conv5_1/sep/scale
I0617 01:28:09.868086 13482 net.cpp:122] Setting up conv5_1/sep/scale
I0617 01:28:09.868103 13482 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:28:09.868111 13482 net.cpp:137] Memory required for data: 3261440200
I0617 01:28:09.868124 13482 layer_factory.hpp:77] Creating layer relu5_1/sep
I0617 01:28:09.868137 13482 net.cpp:84] Creating Layer relu5_1/sep
I0617 01:28:09.868146 13482 net.cpp:406] relu5_1/sep <- conv5_1/sep
I0617 01:28:09.868157 13482 net.cpp:367] relu5_1/sep -> conv5_1/sep (in-place)
I0617 01:28:09.868609 13482 net.cpp:122] Setting up relu5_1/sep
I0617 01:28:09.868631 13482 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:28:09.868640 13482 net.cpp:137] Memory required for data: 3281510600
I0617 01:28:09.868649 13482 layer_factory.hpp:77] Creating layer conv5_2/dw
I0617 01:28:09.868665 13482 net.cpp:84] Creating Layer conv5_2/dw
I0617 01:28:09.868674 13482 net.cpp:406] conv5_2/dw <- conv5_1/sep
I0617 01:28:09.868690 13482 net.cpp:380] conv5_2/dw -> conv5_2/dw
I0617 01:28:09.868901 13482 net.cpp:122] Setting up conv5_2/dw
I0617 01:28:09.868918 13482 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:28:09.868927 13482 net.cpp:137] Memory required for data: 3301581000
I0617 01:28:09.868937 13482 layer_factory.hpp:77] Creating layer conv5_2/dw/bn
I0617 01:28:09.868952 13482 net.cpp:84] Creating Layer conv5_2/dw/bn
I0617 01:28:09.868962 13482 net.cpp:406] conv5_2/dw/bn <- conv5_2/dw
I0617 01:28:09.868975 13482 net.cpp:367] conv5_2/dw/bn -> conv5_2/dw (in-place)
I0617 01:28:09.869215 13482 net.cpp:122] Setting up conv5_2/dw/bn
I0617 01:28:09.869231 13482 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:28:09.869240 13482 net.cpp:137] Memory required for data: 3321651400
I0617 01:28:09.869253 13482 layer_factory.hpp:77] Creating layer conv5_2/dw/scale
I0617 01:28:09.869266 13482 net.cpp:84] Creating Layer conv5_2/dw/scale
I0617 01:28:09.869276 13482 net.cpp:406] conv5_2/dw/scale <- conv5_2/dw
I0617 01:28:09.869289 13482 net.cpp:367] conv5_2/dw/scale -> conv5_2/dw (in-place)
I0617 01:28:09.869344 13482 layer_factory.hpp:77] Creating layer conv5_2/dw/scale
I0617 01:28:09.869505 13482 net.cpp:122] Setting up conv5_2/dw/scale
I0617 01:28:09.869534 13482 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:28:09.869542 13482 net.cpp:137] Memory required for data: 3341721800
I0617 01:28:09.869554 13482 layer_factory.hpp:77] Creating layer relu5_2/dw
I0617 01:28:09.869575 13482 net.cpp:84] Creating Layer relu5_2/dw
I0617 01:28:09.869585 13482 net.cpp:406] relu5_2/dw <- conv5_2/dw
I0617 01:28:09.869596 13482 net.cpp:367] relu5_2/dw -> conv5_2/dw (in-place)
I0617 01:28:09.869827 13482 net.cpp:122] Setting up relu5_2/dw
I0617 01:28:09.869844 13482 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:28:09.869853 13482 net.cpp:137] Memory required for data: 3361792200
I0617 01:28:09.869861 13482 layer_factory.hpp:77] Creating layer conv5_2/sep
I0617 01:28:09.869879 13482 net.cpp:84] Creating Layer conv5_2/sep
I0617 01:28:09.869889 13482 net.cpp:406] conv5_2/sep <- conv5_2/dw
I0617 01:28:09.869904 13482 net.cpp:380] conv5_2/sep -> conv5_2/sep
I0617 01:28:09.875675 13482 net.cpp:122] Setting up conv5_2/sep
I0617 01:28:09.875700 13482 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:28:09.875710 13482 net.cpp:137] Memory required for data: 3381862600
I0617 01:28:09.875721 13482 layer_factory.hpp:77] Creating layer conv5_2/sep/bn
I0617 01:28:09.875737 13482 net.cpp:84] Creating Layer conv5_2/sep/bn
I0617 01:28:09.875748 13482 net.cpp:406] conv5_2/sep/bn <- conv5_2/sep
I0617 01:28:09.875759 13482 net.cpp:367] conv5_2/sep/bn -> conv5_2/sep (in-place)
I0617 01:28:09.876019 13482 net.cpp:122] Setting up conv5_2/sep/bn
I0617 01:28:09.876036 13482 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:28:09.876044 13482 net.cpp:137] Memory required for data: 3401933000
I0617 01:28:09.876066 13482 layer_factory.hpp:77] Creating layer conv5_2/sep/scale
I0617 01:28:09.876080 13482 net.cpp:84] Creating Layer conv5_2/sep/scale
I0617 01:28:09.876099 13482 net.cpp:406] conv5_2/sep/scale <- conv5_2/sep
I0617 01:28:09.876114 13482 net.cpp:367] conv5_2/sep/scale -> conv5_2/sep (in-place)
I0617 01:28:09.876171 13482 layer_factory.hpp:77] Creating layer conv5_2/sep/scale
I0617 01:28:09.876332 13482 net.cpp:122] Setting up conv5_2/sep/scale
I0617 01:28:09.876349 13482 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:28:09.876358 13482 net.cpp:137] Memory required for data: 3422003400
I0617 01:28:09.876369 13482 layer_factory.hpp:77] Creating layer relu5_2/sep
I0617 01:28:09.876384 13482 net.cpp:84] Creating Layer relu5_2/sep
I0617 01:28:09.876394 13482 net.cpp:406] relu5_2/sep <- conv5_2/sep
I0617 01:28:09.876404 13482 net.cpp:367] relu5_2/sep -> conv5_2/sep (in-place)
I0617 01:28:09.876863 13482 net.cpp:122] Setting up relu5_2/sep
I0617 01:28:09.876885 13482 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:28:09.876894 13482 net.cpp:137] Memory required for data: 3442073800
I0617 01:28:09.876902 13482 layer_factory.hpp:77] Creating layer conv5_3/dw
I0617 01:28:09.876920 13482 net.cpp:84] Creating Layer conv5_3/dw
I0617 01:28:09.876930 13482 net.cpp:406] conv5_3/dw <- conv5_2/sep
I0617 01:28:09.876945 13482 net.cpp:380] conv5_3/dw -> conv5_3/dw
I0617 01:28:09.877162 13482 net.cpp:122] Setting up conv5_3/dw
I0617 01:28:09.877180 13482 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:28:09.877188 13482 net.cpp:137] Memory required for data: 3462144200
I0617 01:28:09.877199 13482 layer_factory.hpp:77] Creating layer conv5_3/dw/bn
I0617 01:28:09.877215 13482 net.cpp:84] Creating Layer conv5_3/dw/bn
I0617 01:28:09.877224 13482 net.cpp:406] conv5_3/dw/bn <- conv5_3/dw
I0617 01:28:09.877236 13482 net.cpp:367] conv5_3/dw/bn -> conv5_3/dw (in-place)
I0617 01:28:09.877483 13482 net.cpp:122] Setting up conv5_3/dw/bn
I0617 01:28:09.877501 13482 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:28:09.877508 13482 net.cpp:137] Memory required for data: 3482214600
I0617 01:28:09.877529 13482 layer_factory.hpp:77] Creating layer conv5_3/dw/scale
I0617 01:28:09.877544 13482 net.cpp:84] Creating Layer conv5_3/dw/scale
I0617 01:28:09.877553 13482 net.cpp:406] conv5_3/dw/scale <- conv5_3/dw
I0617 01:28:09.877568 13482 net.cpp:367] conv5_3/dw/scale -> conv5_3/dw (in-place)
I0617 01:28:09.877624 13482 layer_factory.hpp:77] Creating layer conv5_3/dw/scale
I0617 01:28:09.877785 13482 net.cpp:122] Setting up conv5_3/dw/scale
I0617 01:28:09.877805 13482 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:28:09.877813 13482 net.cpp:137] Memory required for data: 3502285000
I0617 01:28:09.877825 13482 layer_factory.hpp:77] Creating layer relu5_3/dw
I0617 01:28:09.877836 13482 net.cpp:84] Creating Layer relu5_3/dw
I0617 01:28:09.877846 13482 net.cpp:406] relu5_3/dw <- conv5_3/dw
I0617 01:28:09.877856 13482 net.cpp:367] relu5_3/dw -> conv5_3/dw (in-place)
I0617 01:28:09.878090 13482 net.cpp:122] Setting up relu5_3/dw
I0617 01:28:09.878113 13482 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:28:09.878120 13482 net.cpp:137] Memory required for data: 3522355400
I0617 01:28:09.878129 13482 layer_factory.hpp:77] Creating layer conv5_3/sep
I0617 01:28:09.878144 13482 net.cpp:84] Creating Layer conv5_3/sep
I0617 01:28:09.878154 13482 net.cpp:406] conv5_3/sep <- conv5_3/dw
I0617 01:28:09.878168 13482 net.cpp:380] conv5_3/sep -> conv5_3/sep
I0617 01:28:09.883947 13482 net.cpp:122] Setting up conv5_3/sep
I0617 01:28:09.883976 13482 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:28:09.883986 13482 net.cpp:137] Memory required for data: 3542425800
I0617 01:28:09.883997 13482 layer_factory.hpp:77] Creating layer conv5_3/sep/bn
I0617 01:28:09.884011 13482 net.cpp:84] Creating Layer conv5_3/sep/bn
I0617 01:28:09.884021 13482 net.cpp:406] conv5_3/sep/bn <- conv5_3/sep
I0617 01:28:09.884035 13482 net.cpp:367] conv5_3/sep/bn -> conv5_3/sep (in-place)
I0617 01:28:09.884304 13482 net.cpp:122] Setting up conv5_3/sep/bn
I0617 01:28:09.884328 13482 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:28:09.884337 13482 net.cpp:137] Memory required for data: 3562496200
I0617 01:28:09.884361 13482 layer_factory.hpp:77] Creating layer conv5_3/sep/scale
I0617 01:28:09.884374 13482 net.cpp:84] Creating Layer conv5_3/sep/scale
I0617 01:28:09.884383 13482 net.cpp:406] conv5_3/sep/scale <- conv5_3/sep
I0617 01:28:09.884394 13482 net.cpp:367] conv5_3/sep/scale -> conv5_3/sep (in-place)
I0617 01:28:09.884456 13482 layer_factory.hpp:77] Creating layer conv5_3/sep/scale
I0617 01:28:09.884629 13482 net.cpp:122] Setting up conv5_3/sep/scale
I0617 01:28:09.884649 13482 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:28:09.884657 13482 net.cpp:137] Memory required for data: 3582566600
I0617 01:28:09.884668 13482 layer_factory.hpp:77] Creating layer relu5_3/sep
I0617 01:28:09.884680 13482 net.cpp:84] Creating Layer relu5_3/sep
I0617 01:28:09.884690 13482 net.cpp:406] relu5_3/sep <- conv5_3/sep
I0617 01:28:09.884702 13482 net.cpp:367] relu5_3/sep -> conv5_3/sep (in-place)
I0617 01:28:09.884944 13482 net.cpp:122] Setting up relu5_3/sep
I0617 01:28:09.884963 13482 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:28:09.884973 13482 net.cpp:137] Memory required for data: 3602637000
I0617 01:28:09.884980 13482 layer_factory.hpp:77] Creating layer conv5_4/dw
I0617 01:28:09.884996 13482 net.cpp:84] Creating Layer conv5_4/dw
I0617 01:28:09.885006 13482 net.cpp:406] conv5_4/dw <- conv5_3/sep
I0617 01:28:09.885018 13482 net.cpp:380] conv5_4/dw -> conv5_4/dw
I0617 01:28:09.885246 13482 net.cpp:122] Setting up conv5_4/dw
I0617 01:28:09.885263 13482 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:28:09.885272 13482 net.cpp:137] Memory required for data: 3622707400
I0617 01:28:09.885282 13482 layer_factory.hpp:77] Creating layer conv5_4/dw/bn
I0617 01:28:09.885298 13482 net.cpp:84] Creating Layer conv5_4/dw/bn
I0617 01:28:09.885308 13482 net.cpp:406] conv5_4/dw/bn <- conv5_4/dw
I0617 01:28:09.885318 13482 net.cpp:367] conv5_4/dw/bn -> conv5_4/dw (in-place)
I0617 01:28:09.885581 13482 net.cpp:122] Setting up conv5_4/dw/bn
I0617 01:28:09.885599 13482 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:28:09.885607 13482 net.cpp:137] Memory required for data: 3642777800
I0617 01:28:09.885622 13482 layer_factory.hpp:77] Creating layer conv5_4/dw/scale
I0617 01:28:09.885637 13482 net.cpp:84] Creating Layer conv5_4/dw/scale
I0617 01:28:09.885646 13482 net.cpp:406] conv5_4/dw/scale <- conv5_4/dw
I0617 01:28:09.885658 13482 net.cpp:367] conv5_4/dw/scale -> conv5_4/dw (in-place)
I0617 01:28:09.885716 13482 layer_factory.hpp:77] Creating layer conv5_4/dw/scale
I0617 01:28:09.885890 13482 net.cpp:122] Setting up conv5_4/dw/scale
I0617 01:28:09.885907 13482 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:28:09.885915 13482 net.cpp:137] Memory required for data: 3662848200
I0617 01:28:09.885927 13482 layer_factory.hpp:77] Creating layer relu5_4/dw
I0617 01:28:09.885938 13482 net.cpp:84] Creating Layer relu5_4/dw
I0617 01:28:09.885947 13482 net.cpp:406] relu5_4/dw <- conv5_4/dw
I0617 01:28:09.885962 13482 net.cpp:367] relu5_4/dw -> conv5_4/dw (in-place)
I0617 01:28:09.886399 13482 net.cpp:122] Setting up relu5_4/dw
I0617 01:28:09.886420 13482 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:28:09.886430 13482 net.cpp:137] Memory required for data: 3682918600
I0617 01:28:09.886438 13482 layer_factory.hpp:77] Creating layer conv5_4/sep
I0617 01:28:09.886457 13482 net.cpp:84] Creating Layer conv5_4/sep
I0617 01:28:09.886467 13482 net.cpp:406] conv5_4/sep <- conv5_4/dw
I0617 01:28:09.886483 13482 net.cpp:380] conv5_4/sep -> conv5_4/sep
I0617 01:28:09.892277 13482 net.cpp:122] Setting up conv5_4/sep
I0617 01:28:09.892302 13482 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:28:09.892312 13482 net.cpp:137] Memory required for data: 3702989000
I0617 01:28:09.892323 13482 layer_factory.hpp:77] Creating layer conv5_4/sep/bn
I0617 01:28:09.892338 13482 net.cpp:84] Creating Layer conv5_4/sep/bn
I0617 01:28:09.892349 13482 net.cpp:406] conv5_4/sep/bn <- conv5_4/sep
I0617 01:28:09.892369 13482 net.cpp:367] conv5_4/sep/bn -> conv5_4/sep (in-place)
I0617 01:28:09.892650 13482 net.cpp:122] Setting up conv5_4/sep/bn
I0617 01:28:09.892679 13482 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:28:09.892688 13482 net.cpp:137] Memory required for data: 3723059400
I0617 01:28:09.892701 13482 layer_factory.hpp:77] Creating layer conv5_4/sep/scale
I0617 01:28:09.892719 13482 net.cpp:84] Creating Layer conv5_4/sep/scale
I0617 01:28:09.892729 13482 net.cpp:406] conv5_4/sep/scale <- conv5_4/sep
I0617 01:28:09.892740 13482 net.cpp:367] conv5_4/sep/scale -> conv5_4/sep (in-place)
I0617 01:28:09.892807 13482 layer_factory.hpp:77] Creating layer conv5_4/sep/scale
I0617 01:28:09.892972 13482 net.cpp:122] Setting up conv5_4/sep/scale
I0617 01:28:09.892989 13482 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:28:09.892997 13482 net.cpp:137] Memory required for data: 3743129800
I0617 01:28:09.893009 13482 layer_factory.hpp:77] Creating layer relu5_4/sep
I0617 01:28:09.893023 13482 net.cpp:84] Creating Layer relu5_4/sep
I0617 01:28:09.893033 13482 net.cpp:406] relu5_4/sep <- conv5_4/sep
I0617 01:28:09.893044 13482 net.cpp:367] relu5_4/sep -> conv5_4/sep (in-place)
I0617 01:28:09.893285 13482 net.cpp:122] Setting up relu5_4/sep
I0617 01:28:09.893303 13482 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:28:09.893312 13482 net.cpp:137] Memory required for data: 3763200200
I0617 01:28:09.893321 13482 layer_factory.hpp:77] Creating layer conv5_5/dw
I0617 01:28:09.893337 13482 net.cpp:84] Creating Layer conv5_5/dw
I0617 01:28:09.893347 13482 net.cpp:406] conv5_5/dw <- conv5_4/sep
I0617 01:28:09.893362 13482 net.cpp:380] conv5_5/dw -> conv5_5/dw
I0617 01:28:09.893594 13482 net.cpp:122] Setting up conv5_5/dw
I0617 01:28:09.893615 13482 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:28:09.893622 13482 net.cpp:137] Memory required for data: 3783270600
I0617 01:28:09.893632 13482 layer_factory.hpp:77] Creating layer conv5_5/dw/bn
I0617 01:28:09.893648 13482 net.cpp:84] Creating Layer conv5_5/dw/bn
I0617 01:28:09.893658 13482 net.cpp:406] conv5_5/dw/bn <- conv5_5/dw
I0617 01:28:09.893672 13482 net.cpp:367] conv5_5/dw/bn -> conv5_5/dw (in-place)
I0617 01:28:09.893925 13482 net.cpp:122] Setting up conv5_5/dw/bn
I0617 01:28:09.893941 13482 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:28:09.893950 13482 net.cpp:137] Memory required for data: 3803341000
I0617 01:28:09.893990 13482 layer_factory.hpp:77] Creating layer conv5_5/dw/scale
I0617 01:28:09.894011 13482 net.cpp:84] Creating Layer conv5_5/dw/scale
I0617 01:28:09.894022 13482 net.cpp:406] conv5_5/dw/scale <- conv5_5/dw
I0617 01:28:09.894034 13482 net.cpp:367] conv5_5/dw/scale -> conv5_5/dw (in-place)
I0617 01:28:09.894098 13482 layer_factory.hpp:77] Creating layer conv5_5/dw/scale
I0617 01:28:09.894260 13482 net.cpp:122] Setting up conv5_5/dw/scale
I0617 01:28:09.894278 13482 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:28:09.894285 13482 net.cpp:137] Memory required for data: 3823411400
I0617 01:28:09.894297 13482 layer_factory.hpp:77] Creating layer relu5_5/dw
I0617 01:28:09.894309 13482 net.cpp:84] Creating Layer relu5_5/dw
I0617 01:28:09.894318 13482 net.cpp:406] relu5_5/dw <- conv5_5/dw
I0617 01:28:09.894328 13482 net.cpp:367] relu5_5/dw -> conv5_5/dw (in-place)
I0617 01:28:09.894798 13482 net.cpp:122] Setting up relu5_5/dw
I0617 01:28:09.894819 13482 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:28:09.894829 13482 net.cpp:137] Memory required for data: 3843481800
I0617 01:28:09.894836 13482 layer_factory.hpp:77] Creating layer conv5_5/sep
I0617 01:28:09.894855 13482 net.cpp:84] Creating Layer conv5_5/sep
I0617 01:28:09.894865 13482 net.cpp:406] conv5_5/sep <- conv5_5/dw
I0617 01:28:09.894883 13482 net.cpp:380] conv5_5/sep -> conv5_5/sep
I0617 01:28:09.900710 13482 net.cpp:122] Setting up conv5_5/sep
I0617 01:28:09.900735 13482 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:28:09.900745 13482 net.cpp:137] Memory required for data: 3863552200
I0617 01:28:09.900763 13482 layer_factory.hpp:77] Creating layer conv5_5/sep/bn
I0617 01:28:09.900776 13482 net.cpp:84] Creating Layer conv5_5/sep/bn
I0617 01:28:09.900795 13482 net.cpp:406] conv5_5/sep/bn <- conv5_5/sep
I0617 01:28:09.900810 13482 net.cpp:367] conv5_5/sep/bn -> conv5_5/sep (in-place)
I0617 01:28:09.901082 13482 net.cpp:122] Setting up conv5_5/sep/bn
I0617 01:28:09.901099 13482 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:28:09.901108 13482 net.cpp:137] Memory required for data: 3883622600
I0617 01:28:09.901121 13482 layer_factory.hpp:77] Creating layer conv5_5/sep/scale
I0617 01:28:09.901134 13482 net.cpp:84] Creating Layer conv5_5/sep/scale
I0617 01:28:09.901144 13482 net.cpp:406] conv5_5/sep/scale <- conv5_5/sep
I0617 01:28:09.901154 13482 net.cpp:367] conv5_5/sep/scale -> conv5_5/sep (in-place)
I0617 01:28:09.901214 13482 layer_factory.hpp:77] Creating layer conv5_5/sep/scale
I0617 01:28:09.901377 13482 net.cpp:122] Setting up conv5_5/sep/scale
I0617 01:28:09.901394 13482 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:28:09.901402 13482 net.cpp:137] Memory required for data: 3903693000
I0617 01:28:09.901414 13482 layer_factory.hpp:77] Creating layer relu5_5/sep
I0617 01:28:09.901427 13482 net.cpp:84] Creating Layer relu5_5/sep
I0617 01:28:09.901435 13482 net.cpp:406] relu5_5/sep <- conv5_5/sep
I0617 01:28:09.901448 13482 net.cpp:367] relu5_5/sep -> conv5_5/sep (in-place)
I0617 01:28:09.901716 13482 net.cpp:122] Setting up relu5_5/sep
I0617 01:28:09.901736 13482 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:28:09.901746 13482 net.cpp:137] Memory required for data: 3923763400
I0617 01:28:09.901753 13482 layer_factory.hpp:77] Creating layer conv5_6/dw
I0617 01:28:09.901772 13482 net.cpp:84] Creating Layer conv5_6/dw
I0617 01:28:09.901782 13482 net.cpp:406] conv5_6/dw <- conv5_5/sep
I0617 01:28:09.901794 13482 net.cpp:380] conv5_6/dw -> conv5_6/dw
I0617 01:28:09.902009 13482 net.cpp:122] Setting up conv5_6/dw
I0617 01:28:09.902027 13482 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0617 01:28:09.902036 13482 net.cpp:137] Memory required for data: 3928781000
I0617 01:28:09.902046 13482 layer_factory.hpp:77] Creating layer conv5_6/dw/bn
I0617 01:28:09.902061 13482 net.cpp:84] Creating Layer conv5_6/dw/bn
I0617 01:28:09.902070 13482 net.cpp:406] conv5_6/dw/bn <- conv5_6/dw
I0617 01:28:09.902081 13482 net.cpp:367] conv5_6/dw/bn -> conv5_6/dw (in-place)
I0617 01:28:09.902345 13482 net.cpp:122] Setting up conv5_6/dw/bn
I0617 01:28:09.902362 13482 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0617 01:28:09.902370 13482 net.cpp:137] Memory required for data: 3933798600
I0617 01:28:09.902384 13482 layer_factory.hpp:77] Creating layer conv5_6/dw/scale
I0617 01:28:09.902400 13482 net.cpp:84] Creating Layer conv5_6/dw/scale
I0617 01:28:09.902408 13482 net.cpp:406] conv5_6/dw/scale <- conv5_6/dw
I0617 01:28:09.902420 13482 net.cpp:367] conv5_6/dw/scale -> conv5_6/dw (in-place)
I0617 01:28:09.902480 13482 layer_factory.hpp:77] Creating layer conv5_6/dw/scale
I0617 01:28:09.902653 13482 net.cpp:122] Setting up conv5_6/dw/scale
I0617 01:28:09.902673 13482 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0617 01:28:09.902681 13482 net.cpp:137] Memory required for data: 3938816200
I0617 01:28:09.902693 13482 layer_factory.hpp:77] Creating layer relu5_6/dw
I0617 01:28:09.902707 13482 net.cpp:84] Creating Layer relu5_6/dw
I0617 01:28:09.902716 13482 net.cpp:406] relu5_6/dw <- conv5_6/dw
I0617 01:28:09.902727 13482 net.cpp:367] relu5_6/dw -> conv5_6/dw (in-place)
I0617 01:28:09.903172 13482 net.cpp:122] Setting up relu5_6/dw
I0617 01:28:09.903193 13482 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0617 01:28:09.903203 13482 net.cpp:137] Memory required for data: 3943833800
I0617 01:28:09.903210 13482 layer_factory.hpp:77] Creating layer conv5_6/sep
I0617 01:28:09.903228 13482 net.cpp:84] Creating Layer conv5_6/sep
I0617 01:28:09.903239 13482 net.cpp:406] conv5_6/sep <- conv5_6/dw
I0617 01:28:09.903257 13482 net.cpp:380] conv5_6/sep -> conv5_6/sep
I0617 01:28:09.913717 13482 net.cpp:122] Setting up conv5_6/sep
I0617 01:28:09.913750 13482 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0617 01:28:09.913760 13482 net.cpp:137] Memory required for data: 3953869000
I0617 01:28:09.913784 13482 layer_factory.hpp:77] Creating layer conv5_6/sep/bn
I0617 01:28:09.913801 13482 net.cpp:84] Creating Layer conv5_6/sep/bn
I0617 01:28:09.913811 13482 net.cpp:406] conv5_6/sep/bn <- conv5_6/sep
I0617 01:28:09.913822 13482 net.cpp:367] conv5_6/sep/bn -> conv5_6/sep (in-place)
I0617 01:28:09.914101 13482 net.cpp:122] Setting up conv5_6/sep/bn
I0617 01:28:09.914119 13482 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0617 01:28:09.914127 13482 net.cpp:137] Memory required for data: 3963904200
I0617 01:28:09.914141 13482 layer_factory.hpp:77] Creating layer conv5_6/sep/scale
I0617 01:28:09.914155 13482 net.cpp:84] Creating Layer conv5_6/sep/scale
I0617 01:28:09.914163 13482 net.cpp:406] conv5_6/sep/scale <- conv5_6/sep
I0617 01:28:09.914180 13482 net.cpp:367] conv5_6/sep/scale -> conv5_6/sep (in-place)
I0617 01:28:09.914239 13482 layer_factory.hpp:77] Creating layer conv5_6/sep/scale
I0617 01:28:09.914408 13482 net.cpp:122] Setting up conv5_6/sep/scale
I0617 01:28:09.914425 13482 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0617 01:28:09.914433 13482 net.cpp:137] Memory required for data: 3973939400
I0617 01:28:09.914445 13482 layer_factory.hpp:77] Creating layer relu5_6/sep
I0617 01:28:09.914460 13482 net.cpp:84] Creating Layer relu5_6/sep
I0617 01:28:09.914469 13482 net.cpp:406] relu5_6/sep <- conv5_6/sep
I0617 01:28:09.914480 13482 net.cpp:367] relu5_6/sep -> conv5_6/sep (in-place)
I0617 01:28:09.914744 13482 net.cpp:122] Setting up relu5_6/sep
I0617 01:28:09.914764 13482 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0617 01:28:09.914772 13482 net.cpp:137] Memory required for data: 3983974600
I0617 01:28:09.914780 13482 layer_factory.hpp:77] Creating layer conv6/dw
I0617 01:28:09.914798 13482 net.cpp:84] Creating Layer conv6/dw
I0617 01:28:09.914808 13482 net.cpp:406] conv6/dw <- conv5_6/sep
I0617 01:28:09.914824 13482 net.cpp:380] conv6/dw -> conv6/dw
I0617 01:28:09.915114 13482 net.cpp:122] Setting up conv6/dw
I0617 01:28:09.915135 13482 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0617 01:28:09.915144 13482 net.cpp:137] Memory required for data: 3994009800
I0617 01:28:09.915154 13482 layer_factory.hpp:77] Creating layer conv6/dw/bn
I0617 01:28:09.915168 13482 net.cpp:84] Creating Layer conv6/dw/bn
I0617 01:28:09.915176 13482 net.cpp:406] conv6/dw/bn <- conv6/dw
I0617 01:28:09.915190 13482 net.cpp:367] conv6/dw/bn -> conv6/dw (in-place)
I0617 01:28:09.915460 13482 net.cpp:122] Setting up conv6/dw/bn
I0617 01:28:09.915478 13482 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0617 01:28:09.915487 13482 net.cpp:137] Memory required for data: 4004045000
I0617 01:28:09.915499 13482 layer_factory.hpp:77] Creating layer conv6/dw/scale
I0617 01:28:09.915513 13482 net.cpp:84] Creating Layer conv6/dw/scale
I0617 01:28:09.915530 13482 net.cpp:406] conv6/dw/scale <- conv6/dw
I0617 01:28:09.915541 13482 net.cpp:367] conv6/dw/scale -> conv6/dw (in-place)
I0617 01:28:09.915604 13482 layer_factory.hpp:77] Creating layer conv6/dw/scale
I0617 01:28:09.915776 13482 net.cpp:122] Setting up conv6/dw/scale
I0617 01:28:09.915794 13482 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0617 01:28:09.915802 13482 net.cpp:137] Memory required for data: 4014080200
I0617 01:28:09.915814 13482 layer_factory.hpp:77] Creating layer relu6/dw
I0617 01:28:09.915828 13482 net.cpp:84] Creating Layer relu6/dw
I0617 01:28:09.915838 13482 net.cpp:406] relu6/dw <- conv6/dw
I0617 01:28:09.915848 13482 net.cpp:367] relu6/dw -> conv6/dw (in-place)
I0617 01:28:09.916307 13482 net.cpp:122] Setting up relu6/dw
I0617 01:28:09.916332 13482 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0617 01:28:09.916342 13482 net.cpp:137] Memory required for data: 4024115400
I0617 01:28:09.916349 13482 layer_factory.hpp:77] Creating layer conv6/sep
I0617 01:28:09.916373 13482 net.cpp:84] Creating Layer conv6/sep
I0617 01:28:09.916383 13482 net.cpp:406] conv6/sep <- conv6/dw
I0617 01:28:09.916395 13482 net.cpp:380] conv6/sep -> conv6/sep
I0617 01:28:09.935009 13482 net.cpp:122] Setting up conv6/sep
I0617 01:28:09.935040 13482 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0617 01:28:09.935063 13482 net.cpp:137] Memory required for data: 4034150600
I0617 01:28:09.935075 13482 layer_factory.hpp:77] Creating layer conv6/sep/bn
I0617 01:28:09.935093 13482 net.cpp:84] Creating Layer conv6/sep/bn
I0617 01:28:09.935104 13482 net.cpp:406] conv6/sep/bn <- conv6/sep
I0617 01:28:09.935119 13482 net.cpp:367] conv6/sep/bn -> conv6/sep (in-place)
I0617 01:28:09.935396 13482 net.cpp:122] Setting up conv6/sep/bn
I0617 01:28:09.935415 13482 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0617 01:28:09.935422 13482 net.cpp:137] Memory required for data: 4044185800
I0617 01:28:09.935436 13482 layer_factory.hpp:77] Creating layer conv6/sep/scale
I0617 01:28:09.935451 13482 net.cpp:84] Creating Layer conv6/sep/scale
I0617 01:28:09.935459 13482 net.cpp:406] conv6/sep/scale <- conv6/sep
I0617 01:28:09.935477 13482 net.cpp:367] conv6/sep/scale -> conv6/sep (in-place)
I0617 01:28:09.935545 13482 layer_factory.hpp:77] Creating layer conv6/sep/scale
I0617 01:28:09.935722 13482 net.cpp:122] Setting up conv6/sep/scale
I0617 01:28:09.935740 13482 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0617 01:28:09.935748 13482 net.cpp:137] Memory required for data: 4054221000
I0617 01:28:09.935760 13482 layer_factory.hpp:77] Creating layer relu6/sep
I0617 01:28:09.935771 13482 net.cpp:84] Creating Layer relu6/sep
I0617 01:28:09.935781 13482 net.cpp:406] relu6/sep <- conv6/sep
I0617 01:28:09.935791 13482 net.cpp:367] relu6/sep -> conv6/sep (in-place)
I0617 01:28:09.936240 13482 net.cpp:122] Setting up relu6/sep
I0617 01:28:09.936262 13482 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0617 01:28:09.936271 13482 net.cpp:137] Memory required for data: 4064256200
I0617 01:28:09.936280 13482 layer_factory.hpp:77] Creating layer pool6
I0617 01:28:09.936300 13482 net.cpp:84] Creating Layer pool6
I0617 01:28:09.936308 13482 net.cpp:406] pool6 <- conv6/sep
I0617 01:28:09.936324 13482 net.cpp:380] pool6 -> pool6
I0617 01:28:09.936663 13482 net.cpp:122] Setting up pool6
I0617 01:28:09.936684 13482 net.cpp:129] Top shape: 50 1024 1 1 (51200)
I0617 01:28:09.936692 13482 net.cpp:137] Memory required for data: 4064461000
I0617 01:28:09.936700 13482 layer_factory.hpp:77] Creating layer fc7
I0617 01:28:09.936720 13482 net.cpp:84] Creating Layer fc7
I0617 01:28:09.936731 13482 net.cpp:406] fc7 <- pool6
I0617 01:28:09.936746 13482 net.cpp:380] fc7 -> fc7
I0617 01:28:09.939754 13482 net.cpp:122] Setting up fc7
I0617 01:28:09.939779 13482 net.cpp:129] Top shape: 50 102 1 1 (5100)
I0617 01:28:09.939787 13482 net.cpp:137] Memory required for data: 4064481400
I0617 01:28:09.939800 13482 layer_factory.hpp:77] Creating layer loss
I0617 01:28:09.939820 13482 net.cpp:84] Creating Layer loss
I0617 01:28:09.939829 13482 net.cpp:406] loss <- fc7
I0617 01:28:09.939839 13482 net.cpp:406] loss <- label
I0617 01:28:09.939857 13482 net.cpp:380] loss -> loss
I0617 01:28:09.939879 13482 layer_factory.hpp:77] Creating layer loss
I0617 01:28:09.940497 13482 net.cpp:122] Setting up loss
I0617 01:28:09.940526 13482 net.cpp:129] Top shape: (1)
I0617 01:28:09.940537 13482 net.cpp:132]     with loss weight 1
I0617 01:28:09.940604 13482 net.cpp:137] Memory required for data: 4064481404
I0617 01:28:09.940614 13482 net.cpp:198] loss needs backward computation.
I0617 01:28:09.940623 13482 net.cpp:198] fc7 needs backward computation.
I0617 01:28:09.940632 13482 net.cpp:198] pool6 needs backward computation.
I0617 01:28:09.940640 13482 net.cpp:198] relu6/sep needs backward computation.
I0617 01:28:09.940649 13482 net.cpp:198] conv6/sep/scale needs backward computation.
I0617 01:28:09.940656 13482 net.cpp:198] conv6/sep/bn needs backward computation.
I0617 01:28:09.940665 13482 net.cpp:198] conv6/sep needs backward computation.
I0617 01:28:09.940672 13482 net.cpp:198] relu6/dw needs backward computation.
I0617 01:28:09.940680 13482 net.cpp:198] conv6/dw/scale needs backward computation.
I0617 01:28:09.940697 13482 net.cpp:198] conv6/dw/bn needs backward computation.
I0617 01:28:09.940706 13482 net.cpp:198] conv6/dw needs backward computation.
I0617 01:28:09.940723 13482 net.cpp:198] relu5_6/sep needs backward computation.
I0617 01:28:09.940732 13482 net.cpp:198] conv5_6/sep/scale needs backward computation.
I0617 01:28:09.940739 13482 net.cpp:198] conv5_6/sep/bn needs backward computation.
I0617 01:28:09.940747 13482 net.cpp:198] conv5_6/sep needs backward computation.
I0617 01:28:09.940755 13482 net.cpp:198] relu5_6/dw needs backward computation.
I0617 01:28:09.940763 13482 net.cpp:198] conv5_6/dw/scale needs backward computation.
I0617 01:28:09.940771 13482 net.cpp:198] conv5_6/dw/bn needs backward computation.
I0617 01:28:09.940778 13482 net.cpp:198] conv5_6/dw needs backward computation.
I0617 01:28:09.940788 13482 net.cpp:198] relu5_5/sep needs backward computation.
I0617 01:28:09.940795 13482 net.cpp:198] conv5_5/sep/scale needs backward computation.
I0617 01:28:09.940803 13482 net.cpp:198] conv5_5/sep/bn needs backward computation.
I0617 01:28:09.940810 13482 net.cpp:198] conv5_5/sep needs backward computation.
I0617 01:28:09.940819 13482 net.cpp:198] relu5_5/dw needs backward computation.
I0617 01:28:09.940826 13482 net.cpp:198] conv5_5/dw/scale needs backward computation.
I0617 01:28:09.940834 13482 net.cpp:198] conv5_5/dw/bn needs backward computation.
I0617 01:28:09.940842 13482 net.cpp:198] conv5_5/dw needs backward computation.
I0617 01:28:09.940850 13482 net.cpp:198] relu5_4/sep needs backward computation.
I0617 01:28:09.940858 13482 net.cpp:198] conv5_4/sep/scale needs backward computation.
I0617 01:28:09.940866 13482 net.cpp:198] conv5_4/sep/bn needs backward computation.
I0617 01:28:09.940874 13482 net.cpp:198] conv5_4/sep needs backward computation.
I0617 01:28:09.940882 13482 net.cpp:198] relu5_4/dw needs backward computation.
I0617 01:28:09.940889 13482 net.cpp:198] conv5_4/dw/scale needs backward computation.
I0617 01:28:09.940897 13482 net.cpp:198] conv5_4/dw/bn needs backward computation.
I0617 01:28:09.940906 13482 net.cpp:198] conv5_4/dw needs backward computation.
I0617 01:28:09.940913 13482 net.cpp:198] relu5_3/sep needs backward computation.
I0617 01:28:09.940922 13482 net.cpp:198] conv5_3/sep/scale needs backward computation.
I0617 01:28:09.940929 13482 net.cpp:198] conv5_3/sep/bn needs backward computation.
I0617 01:28:09.940937 13482 net.cpp:198] conv5_3/sep needs backward computation.
I0617 01:28:09.940944 13482 net.cpp:198] relu5_3/dw needs backward computation.
I0617 01:28:09.940958 13482 net.cpp:198] conv5_3/dw/scale needs backward computation.
I0617 01:28:09.940964 13482 net.cpp:198] conv5_3/dw/bn needs backward computation.
I0617 01:28:09.940973 13482 net.cpp:198] conv5_3/dw needs backward computation.
I0617 01:28:09.940980 13482 net.cpp:198] relu5_2/sep needs backward computation.
I0617 01:28:09.940989 13482 net.cpp:198] conv5_2/sep/scale needs backward computation.
I0617 01:28:09.940996 13482 net.cpp:198] conv5_2/sep/bn needs backward computation.
I0617 01:28:09.941004 13482 net.cpp:198] conv5_2/sep needs backward computation.
I0617 01:28:09.941011 13482 net.cpp:198] relu5_2/dw needs backward computation.
I0617 01:28:09.941020 13482 net.cpp:198] conv5_2/dw/scale needs backward computation.
I0617 01:28:09.941027 13482 net.cpp:198] conv5_2/dw/bn needs backward computation.
I0617 01:28:09.941035 13482 net.cpp:198] conv5_2/dw needs backward computation.
I0617 01:28:09.941043 13482 net.cpp:198] relu5_1/sep needs backward computation.
I0617 01:28:09.941051 13482 net.cpp:198] conv5_1/sep/scale needs backward computation.
I0617 01:28:09.941058 13482 net.cpp:198] conv5_1/sep/bn needs backward computation.
I0617 01:28:09.941066 13482 net.cpp:198] conv5_1/sep needs backward computation.
I0617 01:28:09.941074 13482 net.cpp:198] relu5_1/dw needs backward computation.
I0617 01:28:09.941082 13482 net.cpp:198] conv5_1/dw/scale needs backward computation.
I0617 01:28:09.941090 13482 net.cpp:198] conv5_1/dw/bn needs backward computation.
I0617 01:28:09.941097 13482 net.cpp:198] conv5_1/dw needs backward computation.
I0617 01:28:09.941112 13482 net.cpp:198] relu4_2/sep needs backward computation.
I0617 01:28:09.941120 13482 net.cpp:198] conv4_2/sep/scale needs backward computation.
I0617 01:28:09.941135 13482 net.cpp:198] conv4_2/sep/bn needs backward computation.
I0617 01:28:09.941144 13482 net.cpp:198] conv4_2/sep needs backward computation.
I0617 01:28:09.941153 13482 net.cpp:198] relu4_2/dw needs backward computation.
I0617 01:28:09.941160 13482 net.cpp:198] conv4_2/dw/scale needs backward computation.
I0617 01:28:09.941169 13482 net.cpp:198] conv4_2/dw/bn needs backward computation.
I0617 01:28:09.941175 13482 net.cpp:198] conv4_2/dw needs backward computation.
I0617 01:28:09.941184 13482 net.cpp:198] relu4_1/sep needs backward computation.
I0617 01:28:09.941192 13482 net.cpp:198] conv4_1/sep/scale needs backward computation.
I0617 01:28:09.941200 13482 net.cpp:198] conv4_1/sep/bn needs backward computation.
I0617 01:28:09.941207 13482 net.cpp:198] conv4_1/sep needs backward computation.
I0617 01:28:09.941215 13482 net.cpp:198] relu4_1/dw needs backward computation.
I0617 01:28:09.941223 13482 net.cpp:198] conv4_1/dw/scale needs backward computation.
I0617 01:28:09.941231 13482 net.cpp:198] conv4_1/dw/bn needs backward computation.
I0617 01:28:09.941238 13482 net.cpp:198] conv4_1/dw needs backward computation.
I0617 01:28:09.941247 13482 net.cpp:198] relu3_2/sep needs backward computation.
I0617 01:28:09.941256 13482 net.cpp:198] conv3_2/sep/scale needs backward computation.
I0617 01:28:09.941262 13482 net.cpp:198] conv3_2/sep/bn needs backward computation.
I0617 01:28:09.941270 13482 net.cpp:198] conv3_2/sep needs backward computation.
I0617 01:28:09.941278 13482 net.cpp:198] relu3_2/dw needs backward computation.
I0617 01:28:09.941285 13482 net.cpp:198] conv3_2/dw/scale needs backward computation.
I0617 01:28:09.941293 13482 net.cpp:198] conv3_2/dw/bn needs backward computation.
I0617 01:28:09.941301 13482 net.cpp:198] conv3_2/dw needs backward computation.
I0617 01:28:09.941309 13482 net.cpp:198] relu3_1/sep needs backward computation.
I0617 01:28:09.941318 13482 net.cpp:198] conv3_1/sep/scale needs backward computation.
I0617 01:28:09.941324 13482 net.cpp:198] conv3_1/sep/bn needs backward computation.
I0617 01:28:09.941332 13482 net.cpp:198] conv3_1/sep needs backward computation.
I0617 01:28:09.941340 13482 net.cpp:198] relu3_1/dw needs backward computation.
I0617 01:28:09.941349 13482 net.cpp:198] conv3_1/dw/scale needs backward computation.
I0617 01:28:09.941356 13482 net.cpp:198] conv3_1/dw/bn needs backward computation.
I0617 01:28:09.941364 13482 net.cpp:198] conv3_1/dw needs backward computation.
I0617 01:28:09.941372 13482 net.cpp:198] relu2_2/sep needs backward computation.
I0617 01:28:09.941380 13482 net.cpp:198] conv2_2/sep/scale needs backward computation.
I0617 01:28:09.941387 13482 net.cpp:198] conv2_2/sep/bn needs backward computation.
I0617 01:28:09.941395 13482 net.cpp:198] conv2_2/sep needs backward computation.
I0617 01:28:09.941403 13482 net.cpp:198] relu2_2/dw needs backward computation.
I0617 01:28:09.941411 13482 net.cpp:198] conv2_2/dw/scale needs backward computation.
I0617 01:28:09.941418 13482 net.cpp:198] conv2_2/dw/bn needs backward computation.
I0617 01:28:09.941426 13482 net.cpp:198] conv2_2/dw needs backward computation.
I0617 01:28:09.941434 13482 net.cpp:198] relu2_1/sep needs backward computation.
I0617 01:28:09.941442 13482 net.cpp:198] conv2_1/sep/scale needs backward computation.
I0617 01:28:09.941450 13482 net.cpp:198] conv2_1/sep/bn needs backward computation.
I0617 01:28:09.941457 13482 net.cpp:198] conv2_1/sep needs backward computation.
I0617 01:28:09.941465 13482 net.cpp:198] relu2_1/dw needs backward computation.
I0617 01:28:09.941473 13482 net.cpp:198] conv2_1/dw/scale needs backward computation.
I0617 01:28:09.941481 13482 net.cpp:198] conv2_1/dw/bn needs backward computation.
I0617 01:28:09.941488 13482 net.cpp:198] conv2_1/dw needs backward computation.
I0617 01:28:09.941496 13482 net.cpp:198] relu1 needs backward computation.
I0617 01:28:09.941504 13482 net.cpp:198] conv1/scale needs backward computation.
I0617 01:28:09.941529 13482 net.cpp:198] conv1/bn needs backward computation.
I0617 01:28:09.941540 13482 net.cpp:198] conv1 needs backward computation.
I0617 01:28:09.941557 13482 net.cpp:200] data does not need backward computation.
I0617 01:28:09.941565 13482 net.cpp:242] This network produces output loss
I0617 01:28:09.941637 13482 net.cpp:255] Network initialization done.
I0617 01:28:09.941968 13482 solver.cpp:56] Solver scaffolding done.
I0617 01:28:09.949766 13482 caffe.cpp:155] Finetuning from mobilenet/mobilenet.caffemodel
I0617 01:28:09.972342 13482 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: mobilenet/mobilenet.caffemodel
I0617 01:28:09.972409 13482 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0617 01:28:09.972426 13482 net.cpp:744] Ignoring source layer label_data_1_split
F0617 01:28:09.979980 13482 net.cpp:757] Cannot copy param 0 weights from layer 'fc7'; shape mismatch.  Source param shape is 1000 1024 1 1 (1024000); target param shape is 102 1024 1 1 (104448). To learn this layer's parameters from scratch rather than copying from a saved net, rename the layer.
*** Check failure stack trace: ***
    @     0x7fb19159ea3d  google::LogMessage::Fail()
    @     0x7fb1915a2ed7  google::LogMessage::SendToLog()
    @     0x7fb1915a0d39  google::LogMessage::Flush()
    @     0x7fb1915a103d  google::LogMessageFatal::~LogMessageFatal()
    @     0x7fb19863bbc1  caffe::Net<>::CopyTrainedLayersFrom()
    @     0x7fb198644ea2  caffe::Net<>::CopyTrainedLayersFromBinaryProto()
    @     0x7fb198644f30  caffe::Net<>::CopyTrainedLayersFrom()
    @           0x409895  CopyLayers()
    @           0x40a295  train()
    @           0x4073bc  main
    @       0x318ae1ecdd  (unknown)
    @           0x407c2d  (unknown)
train_mobilenet.sh: line 1: 13482 Aborted                 ../../build/tools/caffe.bin train -solver=mobilenet/solver.prototxt -weights=mobilenet/mobilenet.caffemodel -gpu=3
I0617 01:29:10.234220 18816 caffe.cpp:218] Using GPUs 3
I0617 01:29:10.384863 18816 caffe.cpp:223] GPU 3: Tesla K40m
I0617 01:29:10.733867 18816 solver.cpp:44] Initializing solver from parameters: 
base_lr: 0.01
display: 50
max_iter: 200000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.001
stepsize: 50000
snapshot: 10000
snapshot_prefix: "mobilenet/mobile_2"
solver_mode: GPU
device_id: 3
net: "/home/xingzhaolong/caffe_project/caffe_mobile/models/oxford/mobilenet/mobilenet_deploy.prototxt"
train_state {
  level: 0
  stage: ""
}
I0617 01:29:10.734246 18816 solver.cpp:87] Creating training net from net file: /home/xingzhaolong/caffe_project/caffe_mobile/models/oxford/mobilenet/mobilenet_deploy.prototxt
I0617 01:29:10.736918 18816 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/xingzhaolong/caffe_project/caffe_mobile/models/oxford/mobilenet/mobilenet_deploy.prototxt
I0617 01:29:10.736946 18816 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0617 01:29:10.737254 18816 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0617 01:29:10.737350 18816 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0617 01:29:10.738339 18816 net.cpp:51] Initializing net from parameters: 
name: "MOBILENET"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_file: "/home/xingzhaolong/caffe_project/caffe/models/caffe-oxford102/imagenet_mean.binaryproto"
  }
  image_data_param {
    source: "/home/xingzhaolong/caffe_project/caffe/models/caffe-oxford102/test.txt"
    batch_size: 50
    new_height: 256
    new_width: 256
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv1/bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1/scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2_1/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv1"
  top: "conv2_1/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 32
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv2_1/dw"
  top: "conv2_1/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_1/dw/scale"
  type: "Scale"
  bottom: "conv2_1/dw"
  top: "conv2_1/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_1/dw"
  type: "ReLU"
  bottom: "conv2_1/dw"
  top: "conv2_1/dw"
}
layer {
  name: "conv2_1/sep"
  type: "Convolution"
  bottom: "conv2_1/dw"
  top: "conv2_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv2_1/sep"
  top: "conv2_1/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_1/sep/scale"
  type: "Scale"
  bottom: "conv2_1/sep"
  top: "conv2_1/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_1/sep"
  type: "ReLU"
  bottom: "conv2_1/sep"
  top: "conv2_1/sep"
}
layer {
  name: "conv2_2/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv2_1/sep"
  top: "conv2_2/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 64
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv2_2/dw"
  top: "conv2_2/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_2/dw/scale"
  type: "Scale"
  bottom: "conv2_2/dw"
  top: "conv2_2/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_2/dw"
  type: "ReLU"
  bottom: "conv2_2/dw"
  top: "conv2_2/dw"
}
layer {
  name: "conv2_2/sep"
  type: "Convolution"
  bottom: "conv2_2/dw"
  top: "conv2_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv2_2/sep"
  top: "conv2_2/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_2/sep/scale"
  type: "Scale"
  bottom: "conv2_2/sep"
  top: "conv2_2/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_2/sep"
  type: "ReLU"
  bottom: "conv2_2/sep"
  top: "conv2_2/sep"
}
layer {
  name: "conv3_1/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv2_2/sep"
  top: "conv3_1/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv3_1/dw"
  top: "conv3_1/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_1/dw/scale"
  type: "Scale"
  bottom: "conv3_1/dw"
  top: "conv3_1/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_1/dw"
  type: "ReLU"
  bottom: "conv3_1/dw"
  top: "conv3_1/dw"
}
layer {
  name: "conv3_1/sep"
  type: "Convolution"
  bottom: "conv3_1/dw"
  top: "conv3_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv3_1/sep"
  top: "conv3_1/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_1/sep/scale"
  type: "Scale"
  bottom: "conv3_1/sep"
  top: "conv3_1/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_1/sep"
  type: "ReLU"
  bottom: "conv3_1/sep"
  top: "conv3_1/sep"
}
layer {
  name: "conv3_2/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv3_1/sep"
  top: "conv3_2/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv3_2/dw"
  top: "conv3_2/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_2/dw/scale"
  type: "Scale"
  bottom: "conv3_2/dw"
  top: "conv3_2/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_2/dw"
  type: "ReLU"
  bottom: "conv3_2/dw"
  top: "conv3_2/dw"
}
layer {
  name: "conv3_2/sep"
  type: "Convolution"
  bottom: "conv3_2/dw"
  top: "conv3_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv3_2/sep"
  top: "conv3_2/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_2/sep/scale"
  type: "Scale"
  bottom: "conv3_2/sep"
  top: "conv3_2/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_2/sep"
  type: "ReLU"
  bottom: "conv3_2/sep"
  top: "conv3_2/sep"
}
layer {
  name: "conv4_1/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv3_2/sep"
  top: "conv4_1/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv4_1/dw"
  top: "conv4_1/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv4_1/dw/scale"
  type: "Scale"
  bottom: "conv4_1/dw"
  top: "conv4_1/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu4_1/dw"
  type: "ReLU"
  bottom: "conv4_1/dw"
  top: "conv4_1/dw"
}
layer {
  name: "conv4_1/sep"
  type: "Convolution"
  bottom: "conv4_1/dw"
  top: "conv4_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv4_1/sep"
  top: "conv4_1/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv4_1/sep/scale"
  type: "Scale"
  bottom: "conv4_1/sep"
  top: "conv4_1/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu4_1/sep"
  type: "ReLU"
  bottom: "conv4_1/sep"
  top: "conv4_1/sep"
}
layer {
  name: "conv4_2/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv4_1/sep"
  top: "conv4_2/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv4_2/dw"
  top: "conv4_2/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv4_2/dw/scale"
  type: "Scale"
  bottom: "conv4_2/dw"
  top: "conv4_2/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu4_2/dw"
  type: "ReLU"
  bottom: "conv4_2/dw"
  top: "conv4_2/dw"
}
layer {
  name: "conv4_2/sep"
  type: "Convolution"
  bottom: "conv4_2/dw"
  top: "conv4_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv4_2/sep"
  top: "conv4_2/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv4_2/sep/scale"
  type: "Scale"
  bottom: "conv4_2/sep"
  top: "conv4_2/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu4_2/sep"
  type: "ReLU"
  bottom: "conv4_2/sep"
  top: "conv4_2/sep"
}
layer {
  name: "conv5_1/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv4_2/sep"
  top: "conv5_1/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_1/dw"
  top: "conv5_1/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_1/dw/scale"
  type: "Scale"
  bottom: "conv5_1/dw"
  top: "conv5_1/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_1/dw"
  type: "ReLU"
  bottom: "conv5_1/dw"
  top: "conv5_1/dw"
}
layer {
  name: "conv5_1/sep"
  type: "Convolution"
  bottom: "conv5_1/dw"
  top: "conv5_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_1/sep"
  top: "conv5_1/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_1/sep/scale"
  type: "Scale"
  bottom: "conv5_1/sep"
  top: "conv5_1/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_1/sep"
  type: "ReLU"
  bottom: "conv5_1/sep"
  top: "conv5_1/sep"
}
layer {
  name: "conv5_2/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_1/sep"
  top: "conv5_2/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_2/dw"
  top: "conv5_2/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_2/dw/scale"
  type: "Scale"
  bottom: "conv5_2/dw"
  top: "conv5_2/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_2/dw"
  type: "ReLU"
  bottom: "conv5_2/dw"
  top: "conv5_2/dw"
}
layer {
  name: "conv5_2/sep"
  type: "Convolution"
  bottom: "conv5_2/dw"
  top: "conv5_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_2/sep"
  top: "conv5_2/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_2/sep/scale"
  type: "Scale"
  bottom: "conv5_2/sep"
  top: "conv5_2/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_2/sep"
  type: "ReLU"
  bottom: "conv5_2/sep"
  top: "conv5_2/sep"
}
layer {
  name: "conv5_3/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_2/sep"
  top: "conv5_3/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_3/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_3/dw"
  top: "conv5_3/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_3/dw/scale"
  type: "Scale"
  bottom: "conv5_3/dw"
  top: "conv5_3/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_3/dw"
  type: "ReLU"
  bottom: "conv5_3/dw"
  top: "conv5_3/dw"
}
layer {
  name: "conv5_3/sep"
  type: "Convolution"
  bottom: "conv5_3/dw"
  top: "conv5_3/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_3/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_3/sep"
  top: "conv5_3/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_3/sep/scale"
  type: "Scale"
  bottom: "conv5_3/sep"
  top: "conv5_3/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_3/sep"
  type: "ReLU"
  bottom: "conv5_3/sep"
  top: "conv5_3/sep"
}
layer {
  name: "conv5_4/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_3/sep"
  top: "conv5_4/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_4/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_4/dw"
  top: "conv5_4/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_4/dw/scale"
  type: "Scale"
  bottom: "conv5_4/dw"
  top: "conv5_4/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_4/dw"
  type: "ReLU"
  bottom: "conv5_4/dw"
  top: "conv5_4/dw"
}
layer {
  name: "conv5_4/sep"
  type: "Convolution"
  bottom: "conv5_4/dw"
  top: "conv5_4/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_4/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_4/sep"
  top: "conv5_4/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_4/sep/scale"
  type: "Scale"
  bottom: "conv5_4/sep"
  top: "conv5_4/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_4/sep"
  type: "ReLU"
  bottom: "conv5_4/sep"
  top: "conv5_4/sep"
}
layer {
  name: "conv5_5/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_4/sep"
  top: "conv5_5/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_5/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_5/dw"
  top: "conv5_5/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_5/dw/scale"
  type: "Scale"
  bottom: "conv5_5/dw"
  top: "conv5_5/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_5/dw"
  type: "ReLU"
  bottom: "conv5_5/dw"
  top: "conv5_5/dw"
}
layer {
  name: "conv5_5/sep"
  type: "Convolution"
  bottom: "conv5_5/dw"
  top: "conv5_5/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_5/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_5/sep"
  top: "conv5_5/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_5/sep/scale"
  type: "Scale"
  bottom: "conv5_5/sep"
  top: "conv5_5/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_5/sep"
  type: "ReLU"
  bottom: "conv5_5/sep"
  top: "conv5_5/sep"
}
layer {
  name: "conv5_6/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_5/sep"
  top: "conv5_6/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_6/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_6/dw"
  top: "conv5_6/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_6/dw/scale"
  type: "Scale"
  bottom: "conv5_6/dw"
  top: "conv5_6/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_6/dw"
  type: "ReLU"
  bottom: "conv5_6/dw"
  top: "conv5_6/dw"
}
layer {
  name: "conv5_6/sep"
  type: "Convolution"
  bottom: "conv5_6/dw"
  top: "conv5_6/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_6/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_6/sep"
  top: "conv5_6/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_6/sep/scale"
  type: "Scale"
  bottom: "conv5_6/sep"
  top: "conv5_6/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_6/sep"
  type: "ReLU"
  bottom: "conv5_6/sep"
  top: "conv5_6/sep"
}
layer {
  name: "conv6/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_6/sep"
  top: "conv6/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 1024
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv6/dw/bn"
  type: "BatchNorm"
  bottom: "conv6/dw"
  top: "conv6/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv6/dw/scale"
  type: "Scale"
  bottom: "conv6/dw"
  top: "conv6/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu6/dw"
  type: "ReLU"
  bottom: "conv6/dw"
  top: "conv6/dw"
}
layer {
  name: "conv6/sep"
  type: "Convolution"
  bottom: "conv6/dw"
  top: "conv6/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv6/sep/bn"
  type: "BatchNorm"
  bottom: "conv6/sep"
  top: "conv6/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv6/sep/scale"
  type: "Scale"
  bottom: "conv6/sep"
  top: "conv6/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu6/sep"
  type: "ReLU"
  bottom: "conv6/sep"
  top: "conv6/sep"
}
layer {
  name: "pool6"
  type: "Pooling"
  bottom: "conv6/sep"
  top: "pool6"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc7_oxford"
  type: "Convolution"
  bottom: "pool6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 102
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc7"
  bottom: "label"
  top: "loss"
}
I0617 01:29:10.738867 18816 layer_factory.hpp:77] Creating layer data
I0617 01:29:10.738970 18816 net.cpp:84] Creating Layer data
I0617 01:29:10.738996 18816 net.cpp:380] data -> data
I0617 01:29:10.739045 18816 net.cpp:380] data -> label
I0617 01:29:10.739080 18816 data_transformer.cpp:25] Loading mean file from: /home/xingzhaolong/caffe_project/caffe/models/caffe-oxford102/imagenet_mean.binaryproto
I0617 01:29:10.744179 18816 image_data_layer.cpp:38] Opening file /home/xingzhaolong/caffe_project/caffe/models/caffe-oxford102/test.txt
I0617 01:29:10.746425 18816 image_data_layer.cpp:63] A total of 6149 images.
I0617 01:29:10.755023 18816 image_data_layer.cpp:90] output data size: 50,3,224,224
I0617 01:29:10.857323 18816 net.cpp:122] Setting up data
I0617 01:29:10.857398 18816 net.cpp:129] Top shape: 50 3 224 224 (7526400)
I0617 01:29:10.857411 18816 net.cpp:129] Top shape: 50 (50)
I0617 01:29:10.857419 18816 net.cpp:137] Memory required for data: 30105800
I0617 01:29:10.857434 18816 layer_factory.hpp:77] Creating layer conv1
I0617 01:29:10.857486 18816 net.cpp:84] Creating Layer conv1
I0617 01:29:10.857501 18816 net.cpp:406] conv1 <- data
I0617 01:29:10.857547 18816 net.cpp:380] conv1 -> conv1
I0617 01:29:11.086712 18816 net.cpp:122] Setting up conv1
I0617 01:29:11.086799 18816 net.cpp:129] Top shape: 50 32 112 112 (20070400)
I0617 01:29:11.086812 18816 net.cpp:137] Memory required for data: 110387400
I0617 01:29:11.086853 18816 layer_factory.hpp:77] Creating layer conv1/bn
I0617 01:29:11.086886 18816 net.cpp:84] Creating Layer conv1/bn
I0617 01:29:11.086899 18816 net.cpp:406] conv1/bn <- conv1
I0617 01:29:11.086913 18816 net.cpp:367] conv1/bn -> conv1 (in-place)
I0617 01:29:11.088018 18816 net.cpp:122] Setting up conv1/bn
I0617 01:29:11.088042 18816 net.cpp:129] Top shape: 50 32 112 112 (20070400)
I0617 01:29:11.088050 18816 net.cpp:137] Memory required for data: 190669000
I0617 01:29:11.088073 18816 layer_factory.hpp:77] Creating layer conv1/scale
I0617 01:29:11.088094 18816 net.cpp:84] Creating Layer conv1/scale
I0617 01:29:11.088104 18816 net.cpp:406] conv1/scale <- conv1
I0617 01:29:11.088115 18816 net.cpp:367] conv1/scale -> conv1 (in-place)
I0617 01:29:11.088184 18816 layer_factory.hpp:77] Creating layer conv1/scale
I0617 01:29:11.088345 18816 net.cpp:122] Setting up conv1/scale
I0617 01:29:11.088363 18816 net.cpp:129] Top shape: 50 32 112 112 (20070400)
I0617 01:29:11.088372 18816 net.cpp:137] Memory required for data: 270950600
I0617 01:29:11.088388 18816 layer_factory.hpp:77] Creating layer relu1
I0617 01:29:11.088407 18816 net.cpp:84] Creating Layer relu1
I0617 01:29:11.088415 18816 net.cpp:406] relu1 <- conv1
I0617 01:29:11.088426 18816 net.cpp:367] relu1 -> conv1 (in-place)
I0617 01:29:11.088861 18816 net.cpp:122] Setting up relu1
I0617 01:29:11.088884 18816 net.cpp:129] Top shape: 50 32 112 112 (20070400)
I0617 01:29:11.088893 18816 net.cpp:137] Memory required for data: 351232200
I0617 01:29:11.088902 18816 layer_factory.hpp:77] Creating layer conv2_1/dw
I0617 01:29:11.088923 18816 net.cpp:84] Creating Layer conv2_1/dw
I0617 01:29:11.088933 18816 net.cpp:406] conv2_1/dw <- conv1
I0617 01:29:11.088946 18816 net.cpp:380] conv2_1/dw -> conv2_1/dw
I0617 01:29:11.091420 18816 net.cpp:122] Setting up conv2_1/dw
I0617 01:29:11.091445 18816 net.cpp:129] Top shape: 50 32 112 112 (20070400)
I0617 01:29:11.091475 18816 net.cpp:137] Memory required for data: 431513800
I0617 01:29:11.091487 18816 layer_factory.hpp:77] Creating layer conv2_1/dw/bn
I0617 01:29:11.091500 18816 net.cpp:84] Creating Layer conv2_1/dw/bn
I0617 01:29:11.091509 18816 net.cpp:406] conv2_1/dw/bn <- conv2_1/dw
I0617 01:29:11.091528 18816 net.cpp:367] conv2_1/dw/bn -> conv2_1/dw (in-place)
I0617 01:29:11.091747 18816 net.cpp:122] Setting up conv2_1/dw/bn
I0617 01:29:11.091764 18816 net.cpp:129] Top shape: 50 32 112 112 (20070400)
I0617 01:29:11.091773 18816 net.cpp:137] Memory required for data: 511795400
I0617 01:29:11.091791 18816 layer_factory.hpp:77] Creating layer conv2_1/dw/scale
I0617 01:29:11.091804 18816 net.cpp:84] Creating Layer conv2_1/dw/scale
I0617 01:29:11.091814 18816 net.cpp:406] conv2_1/dw/scale <- conv2_1/dw
I0617 01:29:11.091825 18816 net.cpp:367] conv2_1/dw/scale -> conv2_1/dw (in-place)
I0617 01:29:11.091877 18816 layer_factory.hpp:77] Creating layer conv2_1/dw/scale
I0617 01:29:11.092020 18816 net.cpp:122] Setting up conv2_1/dw/scale
I0617 01:29:11.092038 18816 net.cpp:129] Top shape: 50 32 112 112 (20070400)
I0617 01:29:11.092046 18816 net.cpp:137] Memory required for data: 592077000
I0617 01:29:11.092059 18816 layer_factory.hpp:77] Creating layer relu2_1/dw
I0617 01:29:11.092072 18816 net.cpp:84] Creating Layer relu2_1/dw
I0617 01:29:11.092082 18816 net.cpp:406] relu2_1/dw <- conv2_1/dw
I0617 01:29:11.092092 18816 net.cpp:367] relu2_1/dw -> conv2_1/dw (in-place)
I0617 01:29:11.092303 18816 net.cpp:122] Setting up relu2_1/dw
I0617 01:29:11.092322 18816 net.cpp:129] Top shape: 50 32 112 112 (20070400)
I0617 01:29:11.092331 18816 net.cpp:137] Memory required for data: 672358600
I0617 01:29:11.092340 18816 layer_factory.hpp:77] Creating layer conv2_1/sep
I0617 01:29:11.092357 18816 net.cpp:84] Creating Layer conv2_1/sep
I0617 01:29:11.092366 18816 net.cpp:406] conv2_1/sep <- conv2_1/dw
I0617 01:29:11.092378 18816 net.cpp:380] conv2_1/sep -> conv2_1/sep
I0617 01:29:11.094455 18816 net.cpp:122] Setting up conv2_1/sep
I0617 01:29:11.094485 18816 net.cpp:129] Top shape: 50 64 112 112 (40140800)
I0617 01:29:11.094494 18816 net.cpp:137] Memory required for data: 832921800
I0617 01:29:11.094506 18816 layer_factory.hpp:77] Creating layer conv2_1/sep/bn
I0617 01:29:11.094525 18816 net.cpp:84] Creating Layer conv2_1/sep/bn
I0617 01:29:11.094537 18816 net.cpp:406] conv2_1/sep/bn <- conv2_1/sep
I0617 01:29:11.094552 18816 net.cpp:367] conv2_1/sep/bn -> conv2_1/sep (in-place)
I0617 01:29:11.094801 18816 net.cpp:122] Setting up conv2_1/sep/bn
I0617 01:29:11.094818 18816 net.cpp:129] Top shape: 50 64 112 112 (40140800)
I0617 01:29:11.094827 18816 net.cpp:137] Memory required for data: 993485000
I0617 01:29:11.094841 18816 layer_factory.hpp:77] Creating layer conv2_1/sep/scale
I0617 01:29:11.094856 18816 net.cpp:84] Creating Layer conv2_1/sep/scale
I0617 01:29:11.094864 18816 net.cpp:406] conv2_1/sep/scale <- conv2_1/sep
I0617 01:29:11.094876 18816 net.cpp:367] conv2_1/sep/scale -> conv2_1/sep (in-place)
I0617 01:29:11.094933 18816 layer_factory.hpp:77] Creating layer conv2_1/sep/scale
I0617 01:29:11.095095 18816 net.cpp:122] Setting up conv2_1/sep/scale
I0617 01:29:11.095113 18816 net.cpp:129] Top shape: 50 64 112 112 (40140800)
I0617 01:29:11.095121 18816 net.cpp:137] Memory required for data: 1154048200
I0617 01:29:11.095142 18816 layer_factory.hpp:77] Creating layer relu2_1/sep
I0617 01:29:11.095155 18816 net.cpp:84] Creating Layer relu2_1/sep
I0617 01:29:11.095163 18816 net.cpp:406] relu2_1/sep <- conv2_1/sep
I0617 01:29:11.095175 18816 net.cpp:367] relu2_1/sep -> conv2_1/sep (in-place)
I0617 01:29:11.095614 18816 net.cpp:122] Setting up relu2_1/sep
I0617 01:29:11.095638 18816 net.cpp:129] Top shape: 50 64 112 112 (40140800)
I0617 01:29:11.095646 18816 net.cpp:137] Memory required for data: 1314611400
I0617 01:29:11.095655 18816 layer_factory.hpp:77] Creating layer conv2_2/dw
I0617 01:29:11.095674 18816 net.cpp:84] Creating Layer conv2_2/dw
I0617 01:29:11.095685 18816 net.cpp:406] conv2_2/dw <- conv2_1/sep
I0617 01:29:11.095701 18816 net.cpp:380] conv2_2/dw -> conv2_2/dw
I0617 01:29:11.096761 18816 net.cpp:122] Setting up conv2_2/dw
I0617 01:29:11.096787 18816 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0617 01:29:11.096797 18816 net.cpp:137] Memory required for data: 1354752200
I0617 01:29:11.096808 18816 layer_factory.hpp:77] Creating layer conv2_2/dw/bn
I0617 01:29:11.096822 18816 net.cpp:84] Creating Layer conv2_2/dw/bn
I0617 01:29:11.096830 18816 net.cpp:406] conv2_2/dw/bn <- conv2_2/dw
I0617 01:29:11.096845 18816 net.cpp:367] conv2_2/dw/bn -> conv2_2/dw (in-place)
I0617 01:29:11.097077 18816 net.cpp:122] Setting up conv2_2/dw/bn
I0617 01:29:11.097095 18816 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0617 01:29:11.097103 18816 net.cpp:137] Memory required for data: 1394893000
I0617 01:29:11.097117 18816 layer_factory.hpp:77] Creating layer conv2_2/dw/scale
I0617 01:29:11.097131 18816 net.cpp:84] Creating Layer conv2_2/dw/scale
I0617 01:29:11.097139 18816 net.cpp:406] conv2_2/dw/scale <- conv2_2/dw
I0617 01:29:11.097151 18816 net.cpp:367] conv2_2/dw/scale -> conv2_2/dw (in-place)
I0617 01:29:11.097208 18816 layer_factory.hpp:77] Creating layer conv2_2/dw/scale
I0617 01:29:11.097368 18816 net.cpp:122] Setting up conv2_2/dw/scale
I0617 01:29:11.097386 18816 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0617 01:29:11.097394 18816 net.cpp:137] Memory required for data: 1435033800
I0617 01:29:11.097407 18816 layer_factory.hpp:77] Creating layer relu2_2/dw
I0617 01:29:11.097420 18816 net.cpp:84] Creating Layer relu2_2/dw
I0617 01:29:11.097429 18816 net.cpp:406] relu2_2/dw <- conv2_2/dw
I0617 01:29:11.097440 18816 net.cpp:367] relu2_2/dw -> conv2_2/dw (in-place)
I0617 01:29:11.097677 18816 net.cpp:122] Setting up relu2_2/dw
I0617 01:29:11.097698 18816 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0617 01:29:11.097707 18816 net.cpp:137] Memory required for data: 1475174600
I0617 01:29:11.097715 18816 layer_factory.hpp:77] Creating layer conv2_2/sep
I0617 01:29:11.097733 18816 net.cpp:84] Creating Layer conv2_2/sep
I0617 01:29:11.097750 18816 net.cpp:406] conv2_2/sep <- conv2_2/dw
I0617 01:29:11.097767 18816 net.cpp:380] conv2_2/sep -> conv2_2/sep
I0617 01:29:11.099233 18816 net.cpp:122] Setting up conv2_2/sep
I0617 01:29:11.099257 18816 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0617 01:29:11.099267 18816 net.cpp:137] Memory required for data: 1555456200
I0617 01:29:11.099278 18816 layer_factory.hpp:77] Creating layer conv2_2/sep/bn
I0617 01:29:11.099297 18816 net.cpp:84] Creating Layer conv2_2/sep/bn
I0617 01:29:11.099306 18816 net.cpp:406] conv2_2/sep/bn <- conv2_2/sep
I0617 01:29:11.099318 18816 net.cpp:367] conv2_2/sep/bn -> conv2_2/sep (in-place)
I0617 01:29:11.099560 18816 net.cpp:122] Setting up conv2_2/sep/bn
I0617 01:29:11.099578 18816 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0617 01:29:11.099587 18816 net.cpp:137] Memory required for data: 1635737800
I0617 01:29:11.099601 18816 layer_factory.hpp:77] Creating layer conv2_2/sep/scale
I0617 01:29:11.099617 18816 net.cpp:84] Creating Layer conv2_2/sep/scale
I0617 01:29:11.099627 18816 net.cpp:406] conv2_2/sep/scale <- conv2_2/sep
I0617 01:29:11.099637 18816 net.cpp:367] conv2_2/sep/scale -> conv2_2/sep (in-place)
I0617 01:29:11.099695 18816 layer_factory.hpp:77] Creating layer conv2_2/sep/scale
I0617 01:29:11.099841 18816 net.cpp:122] Setting up conv2_2/sep/scale
I0617 01:29:11.099859 18816 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0617 01:29:11.099867 18816 net.cpp:137] Memory required for data: 1716019400
I0617 01:29:11.099880 18816 layer_factory.hpp:77] Creating layer relu2_2/sep
I0617 01:29:11.099895 18816 net.cpp:84] Creating Layer relu2_2/sep
I0617 01:29:11.099905 18816 net.cpp:406] relu2_2/sep <- conv2_2/sep
I0617 01:29:11.099915 18816 net.cpp:367] relu2_2/sep -> conv2_2/sep (in-place)
I0617 01:29:11.100133 18816 net.cpp:122] Setting up relu2_2/sep
I0617 01:29:11.100152 18816 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0617 01:29:11.100160 18816 net.cpp:137] Memory required for data: 1796301000
I0617 01:29:11.100169 18816 layer_factory.hpp:77] Creating layer conv3_1/dw
I0617 01:29:11.100195 18816 net.cpp:84] Creating Layer conv3_1/dw
I0617 01:29:11.100205 18816 net.cpp:406] conv3_1/dw <- conv2_2/sep
I0617 01:29:11.100222 18816 net.cpp:380] conv3_1/dw -> conv3_1/dw
I0617 01:29:11.101224 18816 net.cpp:122] Setting up conv3_1/dw
I0617 01:29:11.101246 18816 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0617 01:29:11.101255 18816 net.cpp:137] Memory required for data: 1876582600
I0617 01:29:11.101266 18816 layer_factory.hpp:77] Creating layer conv3_1/dw/bn
I0617 01:29:11.101279 18816 net.cpp:84] Creating Layer conv3_1/dw/bn
I0617 01:29:11.101289 18816 net.cpp:406] conv3_1/dw/bn <- conv3_1/dw
I0617 01:29:11.101302 18816 net.cpp:367] conv3_1/dw/bn -> conv3_1/dw (in-place)
I0617 01:29:11.101537 18816 net.cpp:122] Setting up conv3_1/dw/bn
I0617 01:29:11.101555 18816 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0617 01:29:11.101564 18816 net.cpp:137] Memory required for data: 1956864200
I0617 01:29:11.101583 18816 layer_factory.hpp:77] Creating layer conv3_1/dw/scale
I0617 01:29:11.101598 18816 net.cpp:84] Creating Layer conv3_1/dw/scale
I0617 01:29:11.101606 18816 net.cpp:406] conv3_1/dw/scale <- conv3_1/dw
I0617 01:29:11.101620 18816 net.cpp:367] conv3_1/dw/scale -> conv3_1/dw (in-place)
I0617 01:29:11.101677 18816 layer_factory.hpp:77] Creating layer conv3_1/dw/scale
I0617 01:29:11.101831 18816 net.cpp:122] Setting up conv3_1/dw/scale
I0617 01:29:11.101848 18816 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0617 01:29:11.101856 18816 net.cpp:137] Memory required for data: 2037145800
I0617 01:29:11.101869 18816 layer_factory.hpp:77] Creating layer relu3_1/dw
I0617 01:29:11.101881 18816 net.cpp:84] Creating Layer relu3_1/dw
I0617 01:29:11.101889 18816 net.cpp:406] relu3_1/dw <- conv3_1/dw
I0617 01:29:11.101900 18816 net.cpp:367] relu3_1/dw -> conv3_1/dw (in-place)
I0617 01:29:11.102335 18816 net.cpp:122] Setting up relu3_1/dw
I0617 01:29:11.102356 18816 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0617 01:29:11.102373 18816 net.cpp:137] Memory required for data: 2117427400
I0617 01:29:11.102382 18816 layer_factory.hpp:77] Creating layer conv3_1/sep
I0617 01:29:11.102406 18816 net.cpp:84] Creating Layer conv3_1/sep
I0617 01:29:11.102416 18816 net.cpp:406] conv3_1/sep <- conv3_1/dw
I0617 01:29:11.102429 18816 net.cpp:380] conv3_1/sep -> conv3_1/sep
I0617 01:29:11.104226 18816 net.cpp:122] Setting up conv3_1/sep
I0617 01:29:11.104250 18816 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0617 01:29:11.104259 18816 net.cpp:137] Memory required for data: 2197709000
I0617 01:29:11.104270 18816 layer_factory.hpp:77] Creating layer conv3_1/sep/bn
I0617 01:29:11.104286 18816 net.cpp:84] Creating Layer conv3_1/sep/bn
I0617 01:29:11.104296 18816 net.cpp:406] conv3_1/sep/bn <- conv3_1/sep
I0617 01:29:11.104310 18816 net.cpp:367] conv3_1/sep/bn -> conv3_1/sep (in-place)
I0617 01:29:11.104557 18816 net.cpp:122] Setting up conv3_1/sep/bn
I0617 01:29:11.104575 18816 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0617 01:29:11.104583 18816 net.cpp:137] Memory required for data: 2277990600
I0617 01:29:11.104598 18816 layer_factory.hpp:77] Creating layer conv3_1/sep/scale
I0617 01:29:11.104614 18816 net.cpp:84] Creating Layer conv3_1/sep/scale
I0617 01:29:11.104624 18816 net.cpp:406] conv3_1/sep/scale <- conv3_1/sep
I0617 01:29:11.104635 18816 net.cpp:367] conv3_1/sep/scale -> conv3_1/sep (in-place)
I0617 01:29:11.104693 18816 layer_factory.hpp:77] Creating layer conv3_1/sep/scale
I0617 01:29:11.104846 18816 net.cpp:122] Setting up conv3_1/sep/scale
I0617 01:29:11.104862 18816 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0617 01:29:11.104871 18816 net.cpp:137] Memory required for data: 2358272200
I0617 01:29:11.104883 18816 layer_factory.hpp:77] Creating layer relu3_1/sep
I0617 01:29:11.104894 18816 net.cpp:84] Creating Layer relu3_1/sep
I0617 01:29:11.104903 18816 net.cpp:406] relu3_1/sep <- conv3_1/sep
I0617 01:29:11.104913 18816 net.cpp:367] relu3_1/sep -> conv3_1/sep (in-place)
I0617 01:29:11.105150 18816 net.cpp:122] Setting up relu3_1/sep
I0617 01:29:11.105170 18816 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0617 01:29:11.105187 18816 net.cpp:137] Memory required for data: 2438553800
I0617 01:29:11.105196 18816 layer_factory.hpp:77] Creating layer conv3_2/dw
I0617 01:29:11.105216 18816 net.cpp:84] Creating Layer conv3_2/dw
I0617 01:29:11.105226 18816 net.cpp:406] conv3_2/dw <- conv3_1/sep
I0617 01:29:11.105239 18816 net.cpp:380] conv3_2/dw -> conv3_2/dw
I0617 01:29:11.106216 18816 net.cpp:122] Setting up conv3_2/dw
I0617 01:29:11.106240 18816 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0617 01:29:11.106247 18816 net.cpp:137] Memory required for data: 2458624200
I0617 01:29:11.106258 18816 layer_factory.hpp:77] Creating layer conv3_2/dw/bn
I0617 01:29:11.106276 18816 net.cpp:84] Creating Layer conv3_2/dw/bn
I0617 01:29:11.106286 18816 net.cpp:406] conv3_2/dw/bn <- conv3_2/dw
I0617 01:29:11.106297 18816 net.cpp:367] conv3_2/dw/bn -> conv3_2/dw (in-place)
I0617 01:29:11.106547 18816 net.cpp:122] Setting up conv3_2/dw/bn
I0617 01:29:11.106566 18816 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0617 01:29:11.106575 18816 net.cpp:137] Memory required for data: 2478694600
I0617 01:29:11.106588 18816 layer_factory.hpp:77] Creating layer conv3_2/dw/scale
I0617 01:29:11.106606 18816 net.cpp:84] Creating Layer conv3_2/dw/scale
I0617 01:29:11.106614 18816 net.cpp:406] conv3_2/dw/scale <- conv3_2/dw
I0617 01:29:11.106626 18816 net.cpp:367] conv3_2/dw/scale -> conv3_2/dw (in-place)
I0617 01:29:11.106683 18816 layer_factory.hpp:77] Creating layer conv3_2/dw/scale
I0617 01:29:11.106837 18816 net.cpp:122] Setting up conv3_2/dw/scale
I0617 01:29:11.106854 18816 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0617 01:29:11.106863 18816 net.cpp:137] Memory required for data: 2498765000
I0617 01:29:11.106875 18816 layer_factory.hpp:77] Creating layer relu3_2/dw
I0617 01:29:11.106894 18816 net.cpp:84] Creating Layer relu3_2/dw
I0617 01:29:11.106902 18816 net.cpp:406] relu3_2/dw <- conv3_2/dw
I0617 01:29:11.106914 18816 net.cpp:367] relu3_2/dw -> conv3_2/dw (in-place)
I0617 01:29:11.107359 18816 net.cpp:122] Setting up relu3_2/dw
I0617 01:29:11.107383 18816 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0617 01:29:11.107393 18816 net.cpp:137] Memory required for data: 2518835400
I0617 01:29:11.107403 18816 layer_factory.hpp:77] Creating layer conv3_2/sep
I0617 01:29:11.107420 18816 net.cpp:84] Creating Layer conv3_2/sep
I0617 01:29:11.107431 18816 net.cpp:406] conv3_2/sep <- conv3_2/dw
I0617 01:29:11.107445 18816 net.cpp:380] conv3_2/sep -> conv3_2/sep
I0617 01:29:11.109244 18816 net.cpp:122] Setting up conv3_2/sep
I0617 01:29:11.109268 18816 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0617 01:29:11.109277 18816 net.cpp:137] Memory required for data: 2558976200
I0617 01:29:11.109289 18816 layer_factory.hpp:77] Creating layer conv3_2/sep/bn
I0617 01:29:11.109313 18816 net.cpp:84] Creating Layer conv3_2/sep/bn
I0617 01:29:11.109323 18816 net.cpp:406] conv3_2/sep/bn <- conv3_2/sep
I0617 01:29:11.109335 18816 net.cpp:367] conv3_2/sep/bn -> conv3_2/sep (in-place)
I0617 01:29:11.109582 18816 net.cpp:122] Setting up conv3_2/sep/bn
I0617 01:29:11.109602 18816 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0617 01:29:11.109611 18816 net.cpp:137] Memory required for data: 2599117000
I0617 01:29:11.109624 18816 layer_factory.hpp:77] Creating layer conv3_2/sep/scale
I0617 01:29:11.109642 18816 net.cpp:84] Creating Layer conv3_2/sep/scale
I0617 01:29:11.109650 18816 net.cpp:406] conv3_2/sep/scale <- conv3_2/sep
I0617 01:29:11.109663 18816 net.cpp:367] conv3_2/sep/scale -> conv3_2/sep (in-place)
I0617 01:29:11.109724 18816 layer_factory.hpp:77] Creating layer conv3_2/sep/scale
I0617 01:29:11.109876 18816 net.cpp:122] Setting up conv3_2/sep/scale
I0617 01:29:11.109894 18816 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0617 01:29:11.109901 18816 net.cpp:137] Memory required for data: 2639257800
I0617 01:29:11.109915 18816 layer_factory.hpp:77] Creating layer relu3_2/sep
I0617 01:29:11.109925 18816 net.cpp:84] Creating Layer relu3_2/sep
I0617 01:29:11.109935 18816 net.cpp:406] relu3_2/sep <- conv3_2/sep
I0617 01:29:11.109961 18816 net.cpp:367] relu3_2/sep -> conv3_2/sep (in-place)
I0617 01:29:11.110184 18816 net.cpp:122] Setting up relu3_2/sep
I0617 01:29:11.110203 18816 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0617 01:29:11.110211 18816 net.cpp:137] Memory required for data: 2679398600
I0617 01:29:11.110220 18816 layer_factory.hpp:77] Creating layer conv4_1/dw
I0617 01:29:11.110237 18816 net.cpp:84] Creating Layer conv4_1/dw
I0617 01:29:11.110247 18816 net.cpp:406] conv4_1/dw <- conv3_2/sep
I0617 01:29:11.110260 18816 net.cpp:380] conv4_1/dw -> conv4_1/dw
I0617 01:29:11.110443 18816 net.cpp:122] Setting up conv4_1/dw
I0617 01:29:11.110462 18816 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0617 01:29:11.110471 18816 net.cpp:137] Memory required for data: 2719539400
I0617 01:29:11.110481 18816 layer_factory.hpp:77] Creating layer conv4_1/dw/bn
I0617 01:29:11.110493 18816 net.cpp:84] Creating Layer conv4_1/dw/bn
I0617 01:29:11.110502 18816 net.cpp:406] conv4_1/dw/bn <- conv4_1/dw
I0617 01:29:11.110523 18816 net.cpp:367] conv4_1/dw/bn -> conv4_1/dw (in-place)
I0617 01:29:11.110764 18816 net.cpp:122] Setting up conv4_1/dw/bn
I0617 01:29:11.110780 18816 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0617 01:29:11.110788 18816 net.cpp:137] Memory required for data: 2759680200
I0617 01:29:11.110802 18816 layer_factory.hpp:77] Creating layer conv4_1/dw/scale
I0617 01:29:11.110816 18816 net.cpp:84] Creating Layer conv4_1/dw/scale
I0617 01:29:11.110824 18816 net.cpp:406] conv4_1/dw/scale <- conv4_1/dw
I0617 01:29:11.110836 18816 net.cpp:367] conv4_1/dw/scale -> conv4_1/dw (in-place)
I0617 01:29:11.110893 18816 layer_factory.hpp:77] Creating layer conv4_1/dw/scale
I0617 01:29:11.111044 18816 net.cpp:122] Setting up conv4_1/dw/scale
I0617 01:29:11.111062 18816 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0617 01:29:11.111069 18816 net.cpp:137] Memory required for data: 2799821000
I0617 01:29:11.111083 18816 layer_factory.hpp:77] Creating layer relu4_1/dw
I0617 01:29:11.111100 18816 net.cpp:84] Creating Layer relu4_1/dw
I0617 01:29:11.111110 18816 net.cpp:406] relu4_1/dw <- conv4_1/dw
I0617 01:29:11.111124 18816 net.cpp:367] relu4_1/dw -> conv4_1/dw (in-place)
I0617 01:29:11.111577 18816 net.cpp:122] Setting up relu4_1/dw
I0617 01:29:11.111598 18816 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0617 01:29:11.111608 18816 net.cpp:137] Memory required for data: 2839961800
I0617 01:29:11.111616 18816 layer_factory.hpp:77] Creating layer conv4_1/sep
I0617 01:29:11.111634 18816 net.cpp:84] Creating Layer conv4_1/sep
I0617 01:29:11.111644 18816 net.cpp:406] conv4_1/sep <- conv4_1/dw
I0617 01:29:11.111660 18816 net.cpp:380] conv4_1/sep -> conv4_1/sep
I0617 01:29:11.113736 18816 net.cpp:122] Setting up conv4_1/sep
I0617 01:29:11.113760 18816 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0617 01:29:11.113770 18816 net.cpp:137] Memory required for data: 2880102600
I0617 01:29:11.113780 18816 layer_factory.hpp:77] Creating layer conv4_1/sep/bn
I0617 01:29:11.113796 18816 net.cpp:84] Creating Layer conv4_1/sep/bn
I0617 01:29:11.113806 18816 net.cpp:406] conv4_1/sep/bn <- conv4_1/sep
I0617 01:29:11.113821 18816 net.cpp:367] conv4_1/sep/bn -> conv4_1/sep (in-place)
I0617 01:29:11.114063 18816 net.cpp:122] Setting up conv4_1/sep/bn
I0617 01:29:11.114079 18816 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0617 01:29:11.114087 18816 net.cpp:137] Memory required for data: 2920243400
I0617 01:29:11.114102 18816 layer_factory.hpp:77] Creating layer conv4_1/sep/scale
I0617 01:29:11.114114 18816 net.cpp:84] Creating Layer conv4_1/sep/scale
I0617 01:29:11.114123 18816 net.cpp:406] conv4_1/sep/scale <- conv4_1/sep
I0617 01:29:11.114138 18816 net.cpp:367] conv4_1/sep/scale -> conv4_1/sep (in-place)
I0617 01:29:11.114195 18816 layer_factory.hpp:77] Creating layer conv4_1/sep/scale
I0617 01:29:11.114356 18816 net.cpp:122] Setting up conv4_1/sep/scale
I0617 01:29:11.114373 18816 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0617 01:29:11.114382 18816 net.cpp:137] Memory required for data: 2960384200
I0617 01:29:11.114409 18816 layer_factory.hpp:77] Creating layer relu4_1/sep
I0617 01:29:11.114437 18816 net.cpp:84] Creating Layer relu4_1/sep
I0617 01:29:11.114447 18816 net.cpp:406] relu4_1/sep <- conv4_1/sep
I0617 01:29:11.114459 18816 net.cpp:367] relu4_1/sep -> conv4_1/sep (in-place)
I0617 01:29:11.114907 18816 net.cpp:122] Setting up relu4_1/sep
I0617 01:29:11.114928 18816 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0617 01:29:11.114938 18816 net.cpp:137] Memory required for data: 3000525000
I0617 01:29:11.114946 18816 layer_factory.hpp:77] Creating layer conv4_2/dw
I0617 01:29:11.114964 18816 net.cpp:84] Creating Layer conv4_2/dw
I0617 01:29:11.114974 18816 net.cpp:406] conv4_2/dw <- conv4_1/sep
I0617 01:29:11.114989 18816 net.cpp:380] conv4_2/dw -> conv4_2/dw
I0617 01:29:11.115157 18816 net.cpp:122] Setting up conv4_2/dw
I0617 01:29:11.115175 18816 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0617 01:29:11.115183 18816 net.cpp:137] Memory required for data: 3010560200
I0617 01:29:11.115195 18816 layer_factory.hpp:77] Creating layer conv4_2/dw/bn
I0617 01:29:11.115211 18816 net.cpp:84] Creating Layer conv4_2/dw/bn
I0617 01:29:11.115219 18816 net.cpp:406] conv4_2/dw/bn <- conv4_2/dw
I0617 01:29:11.115231 18816 net.cpp:367] conv4_2/dw/bn -> conv4_2/dw (in-place)
I0617 01:29:11.115478 18816 net.cpp:122] Setting up conv4_2/dw/bn
I0617 01:29:11.115495 18816 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0617 01:29:11.115504 18816 net.cpp:137] Memory required for data: 3020595400
I0617 01:29:11.115525 18816 layer_factory.hpp:77] Creating layer conv4_2/dw/scale
I0617 01:29:11.115540 18816 net.cpp:84] Creating Layer conv4_2/dw/scale
I0617 01:29:11.115550 18816 net.cpp:406] conv4_2/dw/scale <- conv4_2/dw
I0617 01:29:11.115563 18816 net.cpp:367] conv4_2/dw/scale -> conv4_2/dw (in-place)
I0617 01:29:11.115622 18816 layer_factory.hpp:77] Creating layer conv4_2/dw/scale
I0617 01:29:11.115772 18816 net.cpp:122] Setting up conv4_2/dw/scale
I0617 01:29:11.115788 18816 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0617 01:29:11.115804 18816 net.cpp:137] Memory required for data: 3030630600
I0617 01:29:11.115818 18816 layer_factory.hpp:77] Creating layer relu4_2/dw
I0617 01:29:11.115838 18816 net.cpp:84] Creating Layer relu4_2/dw
I0617 01:29:11.115846 18816 net.cpp:406] relu4_2/dw <- conv4_2/dw
I0617 01:29:11.115857 18816 net.cpp:367] relu4_2/dw -> conv4_2/dw (in-place)
I0617 01:29:11.116286 18816 net.cpp:122] Setting up relu4_2/dw
I0617 01:29:11.116308 18816 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0617 01:29:11.116317 18816 net.cpp:137] Memory required for data: 3040665800
I0617 01:29:11.116325 18816 layer_factory.hpp:77] Creating layer conv4_2/sep
I0617 01:29:11.116344 18816 net.cpp:84] Creating Layer conv4_2/sep
I0617 01:29:11.116355 18816 net.cpp:406] conv4_2/sep <- conv4_2/dw
I0617 01:29:11.116371 18816 net.cpp:380] conv4_2/sep -> conv4_2/sep
I0617 01:29:11.120379 18816 net.cpp:122] Setting up conv4_2/sep
I0617 01:29:11.120404 18816 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:29:11.120414 18816 net.cpp:137] Memory required for data: 3060736200
I0617 01:29:11.120424 18816 layer_factory.hpp:77] Creating layer conv4_2/sep/bn
I0617 01:29:11.120440 18816 net.cpp:84] Creating Layer conv4_2/sep/bn
I0617 01:29:11.120450 18816 net.cpp:406] conv4_2/sep/bn <- conv4_2/sep
I0617 01:29:11.120465 18816 net.cpp:367] conv4_2/sep/bn -> conv4_2/sep (in-place)
I0617 01:29:11.120728 18816 net.cpp:122] Setting up conv4_2/sep/bn
I0617 01:29:11.120746 18816 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:29:11.120754 18816 net.cpp:137] Memory required for data: 3080806600
I0617 01:29:11.120769 18816 layer_factory.hpp:77] Creating layer conv4_2/sep/scale
I0617 01:29:11.120785 18816 net.cpp:84] Creating Layer conv4_2/sep/scale
I0617 01:29:11.120795 18816 net.cpp:406] conv4_2/sep/scale <- conv4_2/sep
I0617 01:29:11.120806 18816 net.cpp:367] conv4_2/sep/scale -> conv4_2/sep (in-place)
I0617 01:29:11.120863 18816 layer_factory.hpp:77] Creating layer conv4_2/sep/scale
I0617 01:29:11.121022 18816 net.cpp:122] Setting up conv4_2/sep/scale
I0617 01:29:11.121039 18816 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:29:11.121059 18816 net.cpp:137] Memory required for data: 3100877000
I0617 01:29:11.121073 18816 layer_factory.hpp:77] Creating layer relu4_2/sep
I0617 01:29:11.121084 18816 net.cpp:84] Creating Layer relu4_2/sep
I0617 01:29:11.121093 18816 net.cpp:406] relu4_2/sep <- conv4_2/sep
I0617 01:29:11.121107 18816 net.cpp:367] relu4_2/sep -> conv4_2/sep (in-place)
I0617 01:29:11.121552 18816 net.cpp:122] Setting up relu4_2/sep
I0617 01:29:11.121574 18816 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:29:11.121583 18816 net.cpp:137] Memory required for data: 3120947400
I0617 01:29:11.121592 18816 layer_factory.hpp:77] Creating layer conv5_1/dw
I0617 01:29:11.121609 18816 net.cpp:84] Creating Layer conv5_1/dw
I0617 01:29:11.121619 18816 net.cpp:406] conv5_1/dw <- conv4_2/sep
I0617 01:29:11.121631 18816 net.cpp:380] conv5_1/dw -> conv5_1/dw
I0617 01:29:11.121842 18816 net.cpp:122] Setting up conv5_1/dw
I0617 01:29:11.121860 18816 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:29:11.121870 18816 net.cpp:137] Memory required for data: 3141017800
I0617 01:29:11.121879 18816 layer_factory.hpp:77] Creating layer conv5_1/dw/bn
I0617 01:29:11.121896 18816 net.cpp:84] Creating Layer conv5_1/dw/bn
I0617 01:29:11.121904 18816 net.cpp:406] conv5_1/dw/bn <- conv5_1/dw
I0617 01:29:11.121915 18816 net.cpp:367] conv5_1/dw/bn -> conv5_1/dw (in-place)
I0617 01:29:11.122156 18816 net.cpp:122] Setting up conv5_1/dw/bn
I0617 01:29:11.122174 18816 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:29:11.122181 18816 net.cpp:137] Memory required for data: 3161088200
I0617 01:29:11.122195 18816 layer_factory.hpp:77] Creating layer conv5_1/dw/scale
I0617 01:29:11.122211 18816 net.cpp:84] Creating Layer conv5_1/dw/scale
I0617 01:29:11.122221 18816 net.cpp:406] conv5_1/dw/scale <- conv5_1/dw
I0617 01:29:11.122232 18816 net.cpp:367] conv5_1/dw/scale -> conv5_1/dw (in-place)
I0617 01:29:11.122300 18816 layer_factory.hpp:77] Creating layer conv5_1/dw/scale
I0617 01:29:11.122457 18816 net.cpp:122] Setting up conv5_1/dw/scale
I0617 01:29:11.122474 18816 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:29:11.122483 18816 net.cpp:137] Memory required for data: 3181158600
I0617 01:29:11.122495 18816 layer_factory.hpp:77] Creating layer relu5_1/dw
I0617 01:29:11.122508 18816 net.cpp:84] Creating Layer relu5_1/dw
I0617 01:29:11.122522 18816 net.cpp:406] relu5_1/dw <- conv5_1/dw
I0617 01:29:11.122540 18816 net.cpp:367] relu5_1/dw -> conv5_1/dw (in-place)
I0617 01:29:11.122766 18816 net.cpp:122] Setting up relu5_1/dw
I0617 01:29:11.122786 18816 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:29:11.122793 18816 net.cpp:137] Memory required for data: 3201229000
I0617 01:29:11.122802 18816 layer_factory.hpp:77] Creating layer conv5_1/sep
I0617 01:29:11.122820 18816 net.cpp:84] Creating Layer conv5_1/sep
I0617 01:29:11.122830 18816 net.cpp:406] conv5_1/sep <- conv5_1/dw
I0617 01:29:11.122845 18816 net.cpp:380] conv5_1/sep -> conv5_1/sep
I0617 01:29:11.128782 18816 net.cpp:122] Setting up conv5_1/sep
I0617 01:29:11.128808 18816 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:29:11.128818 18816 net.cpp:137] Memory required for data: 3221299400
I0617 01:29:11.128829 18816 layer_factory.hpp:77] Creating layer conv5_1/sep/bn
I0617 01:29:11.128841 18816 net.cpp:84] Creating Layer conv5_1/sep/bn
I0617 01:29:11.128850 18816 net.cpp:406] conv5_1/sep/bn <- conv5_1/sep
I0617 01:29:11.128865 18816 net.cpp:367] conv5_1/sep/bn -> conv5_1/sep (in-place)
I0617 01:29:11.129138 18816 net.cpp:122] Setting up conv5_1/sep/bn
I0617 01:29:11.129159 18816 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:29:11.129168 18816 net.cpp:137] Memory required for data: 3241369800
I0617 01:29:11.129182 18816 layer_factory.hpp:77] Creating layer conv5_1/sep/scale
I0617 01:29:11.129195 18816 net.cpp:84] Creating Layer conv5_1/sep/scale
I0617 01:29:11.129205 18816 net.cpp:406] conv5_1/sep/scale <- conv5_1/sep
I0617 01:29:11.129216 18816 net.cpp:367] conv5_1/sep/scale -> conv5_1/sep (in-place)
I0617 01:29:11.129289 18816 layer_factory.hpp:77] Creating layer conv5_1/sep/scale
I0617 01:29:11.129452 18816 net.cpp:122] Setting up conv5_1/sep/scale
I0617 01:29:11.129469 18816 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:29:11.129478 18816 net.cpp:137] Memory required for data: 3261440200
I0617 01:29:11.129492 18816 layer_factory.hpp:77] Creating layer relu5_1/sep
I0617 01:29:11.129503 18816 net.cpp:84] Creating Layer relu5_1/sep
I0617 01:29:11.129511 18816 net.cpp:406] relu5_1/sep <- conv5_1/sep
I0617 01:29:11.129539 18816 net.cpp:367] relu5_1/sep -> conv5_1/sep (in-place)
I0617 01:29:11.129983 18816 net.cpp:122] Setting up relu5_1/sep
I0617 01:29:11.130004 18816 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:29:11.130013 18816 net.cpp:137] Memory required for data: 3281510600
I0617 01:29:11.130023 18816 layer_factory.hpp:77] Creating layer conv5_2/dw
I0617 01:29:11.130039 18816 net.cpp:84] Creating Layer conv5_2/dw
I0617 01:29:11.130049 18816 net.cpp:406] conv5_2/dw <- conv5_1/sep
I0617 01:29:11.130062 18816 net.cpp:380] conv5_2/dw -> conv5_2/dw
I0617 01:29:11.130276 18816 net.cpp:122] Setting up conv5_2/dw
I0617 01:29:11.130295 18816 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:29:11.130303 18816 net.cpp:137] Memory required for data: 3301581000
I0617 01:29:11.130314 18816 layer_factory.hpp:77] Creating layer conv5_2/dw/bn
I0617 01:29:11.130331 18816 net.cpp:84] Creating Layer conv5_2/dw/bn
I0617 01:29:11.130340 18816 net.cpp:406] conv5_2/dw/bn <- conv5_2/dw
I0617 01:29:11.130352 18816 net.cpp:367] conv5_2/dw/bn -> conv5_2/dw (in-place)
I0617 01:29:11.130600 18816 net.cpp:122] Setting up conv5_2/dw/bn
I0617 01:29:11.130620 18816 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:29:11.130627 18816 net.cpp:137] Memory required for data: 3321651400
I0617 01:29:11.130641 18816 layer_factory.hpp:77] Creating layer conv5_2/dw/scale
I0617 01:29:11.130653 18816 net.cpp:84] Creating Layer conv5_2/dw/scale
I0617 01:29:11.130671 18816 net.cpp:406] conv5_2/dw/scale <- conv5_2/dw
I0617 01:29:11.130686 18816 net.cpp:367] conv5_2/dw/scale -> conv5_2/dw (in-place)
I0617 01:29:11.130741 18816 layer_factory.hpp:77] Creating layer conv5_2/dw/scale
I0617 01:29:11.130900 18816 net.cpp:122] Setting up conv5_2/dw/scale
I0617 01:29:11.130918 18816 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:29:11.130925 18816 net.cpp:137] Memory required for data: 3341721800
I0617 01:29:11.130937 18816 layer_factory.hpp:77] Creating layer relu5_2/dw
I0617 01:29:11.130959 18816 net.cpp:84] Creating Layer relu5_2/dw
I0617 01:29:11.130970 18816 net.cpp:406] relu5_2/dw <- conv5_2/dw
I0617 01:29:11.130982 18816 net.cpp:367] relu5_2/dw -> conv5_2/dw (in-place)
I0617 01:29:11.131222 18816 net.cpp:122] Setting up relu5_2/dw
I0617 01:29:11.131242 18816 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:29:11.131250 18816 net.cpp:137] Memory required for data: 3361792200
I0617 01:29:11.131259 18816 layer_factory.hpp:77] Creating layer conv5_2/sep
I0617 01:29:11.131278 18816 net.cpp:84] Creating Layer conv5_2/sep
I0617 01:29:11.131289 18816 net.cpp:406] conv5_2/sep <- conv5_2/dw
I0617 01:29:11.131304 18816 net.cpp:380] conv5_2/sep -> conv5_2/sep
I0617 01:29:11.137044 18816 net.cpp:122] Setting up conv5_2/sep
I0617 01:29:11.137069 18816 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:29:11.137079 18816 net.cpp:137] Memory required for data: 3381862600
I0617 01:29:11.137090 18816 layer_factory.hpp:77] Creating layer conv5_2/sep/bn
I0617 01:29:11.137104 18816 net.cpp:84] Creating Layer conv5_2/sep/bn
I0617 01:29:11.137112 18816 net.cpp:406] conv5_2/sep/bn <- conv5_2/sep
I0617 01:29:11.137127 18816 net.cpp:367] conv5_2/sep/bn -> conv5_2/sep (in-place)
I0617 01:29:11.137384 18816 net.cpp:122] Setting up conv5_2/sep/bn
I0617 01:29:11.137401 18816 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:29:11.137409 18816 net.cpp:137] Memory required for data: 3401933000
I0617 01:29:11.137423 18816 layer_factory.hpp:77] Creating layer conv5_2/sep/scale
I0617 01:29:11.137436 18816 net.cpp:84] Creating Layer conv5_2/sep/scale
I0617 01:29:11.137459 18816 net.cpp:406] conv5_2/sep/scale <- conv5_2/sep
I0617 01:29:11.137470 18816 net.cpp:367] conv5_2/sep/scale -> conv5_2/sep (in-place)
I0617 01:29:11.137537 18816 layer_factory.hpp:77] Creating layer conv5_2/sep/scale
I0617 01:29:11.137702 18816 net.cpp:122] Setting up conv5_2/sep/scale
I0617 01:29:11.137719 18816 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:29:11.137727 18816 net.cpp:137] Memory required for data: 3422003400
I0617 01:29:11.137740 18816 layer_factory.hpp:77] Creating layer relu5_2/sep
I0617 01:29:11.137753 18816 net.cpp:84] Creating Layer relu5_2/sep
I0617 01:29:11.137761 18816 net.cpp:406] relu5_2/sep <- conv5_2/sep
I0617 01:29:11.137775 18816 net.cpp:367] relu5_2/sep -> conv5_2/sep (in-place)
I0617 01:29:11.138218 18816 net.cpp:122] Setting up relu5_2/sep
I0617 01:29:11.138239 18816 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:29:11.138248 18816 net.cpp:137] Memory required for data: 3442073800
I0617 01:29:11.138257 18816 layer_factory.hpp:77] Creating layer conv5_3/dw
I0617 01:29:11.138274 18816 net.cpp:84] Creating Layer conv5_3/dw
I0617 01:29:11.138284 18816 net.cpp:406] conv5_3/dw <- conv5_2/sep
I0617 01:29:11.138298 18816 net.cpp:380] conv5_3/dw -> conv5_3/dw
I0617 01:29:11.138521 18816 net.cpp:122] Setting up conv5_3/dw
I0617 01:29:11.138541 18816 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:29:11.138550 18816 net.cpp:137] Memory required for data: 3462144200
I0617 01:29:11.138559 18816 layer_factory.hpp:77] Creating layer conv5_3/dw/bn
I0617 01:29:11.138576 18816 net.cpp:84] Creating Layer conv5_3/dw/bn
I0617 01:29:11.138586 18816 net.cpp:406] conv5_3/dw/bn <- conv5_3/dw
I0617 01:29:11.138595 18816 net.cpp:367] conv5_3/dw/bn -> conv5_3/dw (in-place)
I0617 01:29:11.138840 18816 net.cpp:122] Setting up conv5_3/dw/bn
I0617 01:29:11.138857 18816 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:29:11.138865 18816 net.cpp:137] Memory required for data: 3482214600
I0617 01:29:11.138886 18816 layer_factory.hpp:77] Creating layer conv5_3/dw/scale
I0617 01:29:11.138900 18816 net.cpp:84] Creating Layer conv5_3/dw/scale
I0617 01:29:11.138909 18816 net.cpp:406] conv5_3/dw/scale <- conv5_3/dw
I0617 01:29:11.138921 18816 net.cpp:367] conv5_3/dw/scale -> conv5_3/dw (in-place)
I0617 01:29:11.138980 18816 layer_factory.hpp:77] Creating layer conv5_3/dw/scale
I0617 01:29:11.139142 18816 net.cpp:122] Setting up conv5_3/dw/scale
I0617 01:29:11.139159 18816 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:29:11.139168 18816 net.cpp:137] Memory required for data: 3502285000
I0617 01:29:11.139180 18816 layer_factory.hpp:77] Creating layer relu5_3/dw
I0617 01:29:11.139194 18816 net.cpp:84] Creating Layer relu5_3/dw
I0617 01:29:11.139204 18816 net.cpp:406] relu5_3/dw <- conv5_3/dw
I0617 01:29:11.139214 18816 net.cpp:367] relu5_3/dw -> conv5_3/dw (in-place)
I0617 01:29:11.139448 18816 net.cpp:122] Setting up relu5_3/dw
I0617 01:29:11.139467 18816 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:29:11.139475 18816 net.cpp:137] Memory required for data: 3522355400
I0617 01:29:11.139484 18816 layer_factory.hpp:77] Creating layer conv5_3/sep
I0617 01:29:11.139503 18816 net.cpp:84] Creating Layer conv5_3/sep
I0617 01:29:11.139519 18816 net.cpp:406] conv5_3/sep <- conv5_3/dw
I0617 01:29:11.139539 18816 net.cpp:380] conv5_3/sep -> conv5_3/sep
I0617 01:29:11.145275 18816 net.cpp:122] Setting up conv5_3/sep
I0617 01:29:11.145301 18816 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:29:11.145310 18816 net.cpp:137] Memory required for data: 3542425800
I0617 01:29:11.145323 18816 layer_factory.hpp:77] Creating layer conv5_3/sep/bn
I0617 01:29:11.145339 18816 net.cpp:84] Creating Layer conv5_3/sep/bn
I0617 01:29:11.145349 18816 net.cpp:406] conv5_3/sep/bn <- conv5_3/sep
I0617 01:29:11.145360 18816 net.cpp:367] conv5_3/sep/bn -> conv5_3/sep (in-place)
I0617 01:29:11.145628 18816 net.cpp:122] Setting up conv5_3/sep/bn
I0617 01:29:11.145648 18816 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:29:11.145656 18816 net.cpp:137] Memory required for data: 3562496200
I0617 01:29:11.145683 18816 layer_factory.hpp:77] Creating layer conv5_3/sep/scale
I0617 01:29:11.145696 18816 net.cpp:84] Creating Layer conv5_3/sep/scale
I0617 01:29:11.145705 18816 net.cpp:406] conv5_3/sep/scale <- conv5_3/sep
I0617 01:29:11.145717 18816 net.cpp:367] conv5_3/sep/scale -> conv5_3/sep (in-place)
I0617 01:29:11.145777 18816 layer_factory.hpp:77] Creating layer conv5_3/sep/scale
I0617 01:29:11.145946 18816 net.cpp:122] Setting up conv5_3/sep/scale
I0617 01:29:11.145962 18816 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:29:11.145970 18816 net.cpp:137] Memory required for data: 3582566600
I0617 01:29:11.145983 18816 layer_factory.hpp:77] Creating layer relu5_3/sep
I0617 01:29:11.145998 18816 net.cpp:84] Creating Layer relu5_3/sep
I0617 01:29:11.146008 18816 net.cpp:406] relu5_3/sep <- conv5_3/sep
I0617 01:29:11.146018 18816 net.cpp:367] relu5_3/sep -> conv5_3/sep (in-place)
I0617 01:29:11.146250 18816 net.cpp:122] Setting up relu5_3/sep
I0617 01:29:11.146268 18816 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:29:11.146276 18816 net.cpp:137] Memory required for data: 3602637000
I0617 01:29:11.146286 18816 layer_factory.hpp:77] Creating layer conv5_4/dw
I0617 01:29:11.146306 18816 net.cpp:84] Creating Layer conv5_4/dw
I0617 01:29:11.146317 18816 net.cpp:406] conv5_4/dw <- conv5_3/sep
I0617 01:29:11.146332 18816 net.cpp:380] conv5_4/dw -> conv5_4/dw
I0617 01:29:11.146554 18816 net.cpp:122] Setting up conv5_4/dw
I0617 01:29:11.146574 18816 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:29:11.146582 18816 net.cpp:137] Memory required for data: 3622707400
I0617 01:29:11.146594 18816 layer_factory.hpp:77] Creating layer conv5_4/dw/bn
I0617 01:29:11.146610 18816 net.cpp:84] Creating Layer conv5_4/dw/bn
I0617 01:29:11.146618 18816 net.cpp:406] conv5_4/dw/bn <- conv5_4/dw
I0617 01:29:11.146632 18816 net.cpp:367] conv5_4/dw/bn -> conv5_4/dw (in-place)
I0617 01:29:11.146878 18816 net.cpp:122] Setting up conv5_4/dw/bn
I0617 01:29:11.146903 18816 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:29:11.146911 18816 net.cpp:137] Memory required for data: 3642777800
I0617 01:29:11.146924 18816 layer_factory.hpp:77] Creating layer conv5_4/dw/scale
I0617 01:29:11.146940 18816 net.cpp:84] Creating Layer conv5_4/dw/scale
I0617 01:29:11.146950 18816 net.cpp:406] conv5_4/dw/scale <- conv5_4/dw
I0617 01:29:11.146961 18816 net.cpp:367] conv5_4/dw/scale -> conv5_4/dw (in-place)
I0617 01:29:11.147017 18816 layer_factory.hpp:77] Creating layer conv5_4/dw/scale
I0617 01:29:11.147179 18816 net.cpp:122] Setting up conv5_4/dw/scale
I0617 01:29:11.147197 18816 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:29:11.147204 18816 net.cpp:137] Memory required for data: 3662848200
I0617 01:29:11.147217 18816 layer_factory.hpp:77] Creating layer relu5_4/dw
I0617 01:29:11.147228 18816 net.cpp:84] Creating Layer relu5_4/dw
I0617 01:29:11.147238 18816 net.cpp:406] relu5_4/dw <- conv5_4/dw
I0617 01:29:11.147250 18816 net.cpp:367] relu5_4/dw -> conv5_4/dw (in-place)
I0617 01:29:11.147696 18816 net.cpp:122] Setting up relu5_4/dw
I0617 01:29:11.147718 18816 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:29:11.147727 18816 net.cpp:137] Memory required for data: 3682918600
I0617 01:29:11.147735 18816 layer_factory.hpp:77] Creating layer conv5_4/sep
I0617 01:29:11.147754 18816 net.cpp:84] Creating Layer conv5_4/sep
I0617 01:29:11.147764 18816 net.cpp:406] conv5_4/sep <- conv5_4/dw
I0617 01:29:11.147778 18816 net.cpp:380] conv5_4/sep -> conv5_4/sep
I0617 01:29:11.153553 18816 net.cpp:122] Setting up conv5_4/sep
I0617 01:29:11.153578 18816 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:29:11.153587 18816 net.cpp:137] Memory required for data: 3702989000
I0617 01:29:11.153599 18816 layer_factory.hpp:77] Creating layer conv5_4/sep/bn
I0617 01:29:11.153615 18816 net.cpp:84] Creating Layer conv5_4/sep/bn
I0617 01:29:11.153625 18816 net.cpp:406] conv5_4/sep/bn <- conv5_4/sep
I0617 01:29:11.153637 18816 net.cpp:367] conv5_4/sep/bn -> conv5_4/sep (in-place)
I0617 01:29:11.153908 18816 net.cpp:122] Setting up conv5_4/sep/bn
I0617 01:29:11.153928 18816 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:29:11.153935 18816 net.cpp:137] Memory required for data: 3723059400
I0617 01:29:11.153949 18816 layer_factory.hpp:77] Creating layer conv5_4/sep/scale
I0617 01:29:11.153966 18816 net.cpp:84] Creating Layer conv5_4/sep/scale
I0617 01:29:11.153976 18816 net.cpp:406] conv5_4/sep/scale <- conv5_4/sep
I0617 01:29:11.153987 18816 net.cpp:367] conv5_4/sep/scale -> conv5_4/sep (in-place)
I0617 01:29:11.154048 18816 layer_factory.hpp:77] Creating layer conv5_4/sep/scale
I0617 01:29:11.154209 18816 net.cpp:122] Setting up conv5_4/sep/scale
I0617 01:29:11.154227 18816 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:29:11.154234 18816 net.cpp:137] Memory required for data: 3743129800
I0617 01:29:11.154247 18816 layer_factory.hpp:77] Creating layer relu5_4/sep
I0617 01:29:11.154259 18816 net.cpp:84] Creating Layer relu5_4/sep
I0617 01:29:11.154268 18816 net.cpp:406] relu5_4/sep <- conv5_4/sep
I0617 01:29:11.154283 18816 net.cpp:367] relu5_4/sep -> conv5_4/sep (in-place)
I0617 01:29:11.154522 18816 net.cpp:122] Setting up relu5_4/sep
I0617 01:29:11.154543 18816 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:29:11.154552 18816 net.cpp:137] Memory required for data: 3763200200
I0617 01:29:11.154561 18816 layer_factory.hpp:77] Creating layer conv5_5/dw
I0617 01:29:11.154579 18816 net.cpp:84] Creating Layer conv5_5/dw
I0617 01:29:11.154590 18816 net.cpp:406] conv5_5/dw <- conv5_4/sep
I0617 01:29:11.154605 18816 net.cpp:380] conv5_5/dw -> conv5_5/dw
I0617 01:29:11.154824 18816 net.cpp:122] Setting up conv5_5/dw
I0617 01:29:11.154841 18816 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:29:11.154850 18816 net.cpp:137] Memory required for data: 3783270600
I0617 01:29:11.154860 18816 layer_factory.hpp:77] Creating layer conv5_5/dw/bn
I0617 01:29:11.154875 18816 net.cpp:84] Creating Layer conv5_5/dw/bn
I0617 01:29:11.154892 18816 net.cpp:406] conv5_5/dw/bn <- conv5_5/dw
I0617 01:29:11.154903 18816 net.cpp:367] conv5_5/dw/bn -> conv5_5/dw (in-place)
I0617 01:29:11.155153 18816 net.cpp:122] Setting up conv5_5/dw/bn
I0617 01:29:11.155169 18816 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:29:11.155177 18816 net.cpp:137] Memory required for data: 3803341000
I0617 01:29:11.155217 18816 layer_factory.hpp:77] Creating layer conv5_5/dw/scale
I0617 01:29:11.155232 18816 net.cpp:84] Creating Layer conv5_5/dw/scale
I0617 01:29:11.155242 18816 net.cpp:406] conv5_5/dw/scale <- conv5_5/dw
I0617 01:29:11.155258 18816 net.cpp:367] conv5_5/dw/scale -> conv5_5/dw (in-place)
I0617 01:29:11.155320 18816 layer_factory.hpp:77] Creating layer conv5_5/dw/scale
I0617 01:29:11.155481 18816 net.cpp:122] Setting up conv5_5/dw/scale
I0617 01:29:11.155501 18816 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:29:11.155510 18816 net.cpp:137] Memory required for data: 3823411400
I0617 01:29:11.155531 18816 layer_factory.hpp:77] Creating layer relu5_5/dw
I0617 01:29:11.155544 18816 net.cpp:84] Creating Layer relu5_5/dw
I0617 01:29:11.155552 18816 net.cpp:406] relu5_5/dw <- conv5_5/dw
I0617 01:29:11.155562 18816 net.cpp:367] relu5_5/dw -> conv5_5/dw (in-place)
I0617 01:29:11.156014 18816 net.cpp:122] Setting up relu5_5/dw
I0617 01:29:11.156035 18816 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:29:11.156044 18816 net.cpp:137] Memory required for data: 3843481800
I0617 01:29:11.156054 18816 layer_factory.hpp:77] Creating layer conv5_5/sep
I0617 01:29:11.156072 18816 net.cpp:84] Creating Layer conv5_5/sep
I0617 01:29:11.156082 18816 net.cpp:406] conv5_5/sep <- conv5_5/dw
I0617 01:29:11.156100 18816 net.cpp:380] conv5_5/sep -> conv5_5/sep
I0617 01:29:11.161804 18816 net.cpp:122] Setting up conv5_5/sep
I0617 01:29:11.161833 18816 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:29:11.161842 18816 net.cpp:137] Memory required for data: 3863552200
I0617 01:29:11.161854 18816 layer_factory.hpp:77] Creating layer conv5_5/sep/bn
I0617 01:29:11.161867 18816 net.cpp:84] Creating Layer conv5_5/sep/bn
I0617 01:29:11.161888 18816 net.cpp:406] conv5_5/sep/bn <- conv5_5/sep
I0617 01:29:11.161905 18816 net.cpp:367] conv5_5/sep/bn -> conv5_5/sep (in-place)
I0617 01:29:11.162170 18816 net.cpp:122] Setting up conv5_5/sep/bn
I0617 01:29:11.162187 18816 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:29:11.162196 18816 net.cpp:137] Memory required for data: 3883622600
I0617 01:29:11.162210 18816 layer_factory.hpp:77] Creating layer conv5_5/sep/scale
I0617 01:29:11.162223 18816 net.cpp:84] Creating Layer conv5_5/sep/scale
I0617 01:29:11.162232 18816 net.cpp:406] conv5_5/sep/scale <- conv5_5/sep
I0617 01:29:11.162243 18816 net.cpp:367] conv5_5/sep/scale -> conv5_5/sep (in-place)
I0617 01:29:11.162304 18816 layer_factory.hpp:77] Creating layer conv5_5/sep/scale
I0617 01:29:11.162470 18816 net.cpp:122] Setting up conv5_5/sep/scale
I0617 01:29:11.162487 18816 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:29:11.162497 18816 net.cpp:137] Memory required for data: 3903693000
I0617 01:29:11.162508 18816 layer_factory.hpp:77] Creating layer relu5_5/sep
I0617 01:29:11.162531 18816 net.cpp:84] Creating Layer relu5_5/sep
I0617 01:29:11.162541 18816 net.cpp:406] relu5_5/sep <- conv5_5/sep
I0617 01:29:11.162554 18816 net.cpp:367] relu5_5/sep -> conv5_5/sep (in-place)
I0617 01:29:11.162818 18816 net.cpp:122] Setting up relu5_5/sep
I0617 01:29:11.162838 18816 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:29:11.162847 18816 net.cpp:137] Memory required for data: 3923763400
I0617 01:29:11.162855 18816 layer_factory.hpp:77] Creating layer conv5_6/dw
I0617 01:29:11.162873 18816 net.cpp:84] Creating Layer conv5_6/dw
I0617 01:29:11.162883 18816 net.cpp:406] conv5_6/dw <- conv5_5/sep
I0617 01:29:11.162895 18816 net.cpp:380] conv5_6/dw -> conv5_6/dw
I0617 01:29:11.163110 18816 net.cpp:122] Setting up conv5_6/dw
I0617 01:29:11.163128 18816 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0617 01:29:11.163137 18816 net.cpp:137] Memory required for data: 3928781000
I0617 01:29:11.163154 18816 layer_factory.hpp:77] Creating layer conv5_6/dw/bn
I0617 01:29:11.163172 18816 net.cpp:84] Creating Layer conv5_6/dw/bn
I0617 01:29:11.163180 18816 net.cpp:406] conv5_6/dw/bn <- conv5_6/dw
I0617 01:29:11.163192 18816 net.cpp:367] conv5_6/dw/bn -> conv5_6/dw (in-place)
I0617 01:29:11.163449 18816 net.cpp:122] Setting up conv5_6/dw/bn
I0617 01:29:11.163465 18816 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0617 01:29:11.163473 18816 net.cpp:137] Memory required for data: 3933798600
I0617 01:29:11.163487 18816 layer_factory.hpp:77] Creating layer conv5_6/dw/scale
I0617 01:29:11.163503 18816 net.cpp:84] Creating Layer conv5_6/dw/scale
I0617 01:29:11.163519 18816 net.cpp:406] conv5_6/dw/scale <- conv5_6/dw
I0617 01:29:11.163533 18816 net.cpp:367] conv5_6/dw/scale -> conv5_6/dw (in-place)
I0617 01:29:11.163594 18816 layer_factory.hpp:77] Creating layer conv5_6/dw/scale
I0617 01:29:11.163758 18816 net.cpp:122] Setting up conv5_6/dw/scale
I0617 01:29:11.163774 18816 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0617 01:29:11.163782 18816 net.cpp:137] Memory required for data: 3938816200
I0617 01:29:11.163795 18816 layer_factory.hpp:77] Creating layer relu5_6/dw
I0617 01:29:11.163806 18816 net.cpp:84] Creating Layer relu5_6/dw
I0617 01:29:11.163815 18816 net.cpp:406] relu5_6/dw <- conv5_6/dw
I0617 01:29:11.163830 18816 net.cpp:367] relu5_6/dw -> conv5_6/dw (in-place)
I0617 01:29:11.164276 18816 net.cpp:122] Setting up relu5_6/dw
I0617 01:29:11.164299 18816 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0617 01:29:11.164307 18816 net.cpp:137] Memory required for data: 3943833800
I0617 01:29:11.164315 18816 layer_factory.hpp:77] Creating layer conv5_6/sep
I0617 01:29:11.164335 18816 net.cpp:84] Creating Layer conv5_6/sep
I0617 01:29:11.164345 18816 net.cpp:406] conv5_6/sep <- conv5_6/dw
I0617 01:29:11.164361 18816 net.cpp:380] conv5_6/sep -> conv5_6/sep
I0617 01:29:11.174796 18816 net.cpp:122] Setting up conv5_6/sep
I0617 01:29:11.174823 18816 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0617 01:29:11.174832 18816 net.cpp:137] Memory required for data: 3953869000
I0617 01:29:11.174854 18816 layer_factory.hpp:77] Creating layer conv5_6/sep/bn
I0617 01:29:11.174870 18816 net.cpp:84] Creating Layer conv5_6/sep/bn
I0617 01:29:11.174878 18816 net.cpp:406] conv5_6/sep/bn <- conv5_6/sep
I0617 01:29:11.174893 18816 net.cpp:367] conv5_6/sep/bn -> conv5_6/sep (in-place)
I0617 01:29:11.175173 18816 net.cpp:122] Setting up conv5_6/sep/bn
I0617 01:29:11.175190 18816 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0617 01:29:11.175199 18816 net.cpp:137] Memory required for data: 3963904200
I0617 01:29:11.175212 18816 layer_factory.hpp:77] Creating layer conv5_6/sep/scale
I0617 01:29:11.175225 18816 net.cpp:84] Creating Layer conv5_6/sep/scale
I0617 01:29:11.175235 18816 net.cpp:406] conv5_6/sep/scale <- conv5_6/sep
I0617 01:29:11.175246 18816 net.cpp:367] conv5_6/sep/scale -> conv5_6/sep (in-place)
I0617 01:29:11.175308 18816 layer_factory.hpp:77] Creating layer conv5_6/sep/scale
I0617 01:29:11.175474 18816 net.cpp:122] Setting up conv5_6/sep/scale
I0617 01:29:11.175492 18816 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0617 01:29:11.175500 18816 net.cpp:137] Memory required for data: 3973939400
I0617 01:29:11.175519 18816 layer_factory.hpp:77] Creating layer relu5_6/sep
I0617 01:29:11.175534 18816 net.cpp:84] Creating Layer relu5_6/sep
I0617 01:29:11.175542 18816 net.cpp:406] relu5_6/sep <- conv5_6/sep
I0617 01:29:11.175557 18816 net.cpp:367] relu5_6/sep -> conv5_6/sep (in-place)
I0617 01:29:11.175801 18816 net.cpp:122] Setting up relu5_6/sep
I0617 01:29:11.175820 18816 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0617 01:29:11.175829 18816 net.cpp:137] Memory required for data: 3983974600
I0617 01:29:11.175837 18816 layer_factory.hpp:77] Creating layer conv6/dw
I0617 01:29:11.175854 18816 net.cpp:84] Creating Layer conv6/dw
I0617 01:29:11.175864 18816 net.cpp:406] conv6/dw <- conv5_6/sep
I0617 01:29:11.175876 18816 net.cpp:380] conv6/dw -> conv6/dw
I0617 01:29:11.176154 18816 net.cpp:122] Setting up conv6/dw
I0617 01:29:11.176179 18816 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0617 01:29:11.176188 18816 net.cpp:137] Memory required for data: 3994009800
I0617 01:29:11.176198 18816 layer_factory.hpp:77] Creating layer conv6/dw/bn
I0617 01:29:11.176214 18816 net.cpp:84] Creating Layer conv6/dw/bn
I0617 01:29:11.176224 18816 net.cpp:406] conv6/dw/bn <- conv6/dw
I0617 01:29:11.176234 18816 net.cpp:367] conv6/dw/bn -> conv6/dw (in-place)
I0617 01:29:11.176499 18816 net.cpp:122] Setting up conv6/dw/bn
I0617 01:29:11.176523 18816 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0617 01:29:11.176533 18816 net.cpp:137] Memory required for data: 4004045000
I0617 01:29:11.176548 18816 layer_factory.hpp:77] Creating layer conv6/dw/scale
I0617 01:29:11.176563 18816 net.cpp:84] Creating Layer conv6/dw/scale
I0617 01:29:11.176573 18816 net.cpp:406] conv6/dw/scale <- conv6/dw
I0617 01:29:11.176584 18816 net.cpp:367] conv6/dw/scale -> conv6/dw (in-place)
I0617 01:29:11.176645 18816 layer_factory.hpp:77] Creating layer conv6/dw/scale
I0617 01:29:11.176818 18816 net.cpp:122] Setting up conv6/dw/scale
I0617 01:29:11.176836 18816 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0617 01:29:11.176843 18816 net.cpp:137] Memory required for data: 4014080200
I0617 01:29:11.176856 18816 layer_factory.hpp:77] Creating layer relu6/dw
I0617 01:29:11.176870 18816 net.cpp:84] Creating Layer relu6/dw
I0617 01:29:11.176880 18816 net.cpp:406] relu6/dw <- conv6/dw
I0617 01:29:11.176890 18816 net.cpp:367] relu6/dw -> conv6/dw (in-place)
I0617 01:29:11.177341 18816 net.cpp:122] Setting up relu6/dw
I0617 01:29:11.177363 18816 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0617 01:29:11.177372 18816 net.cpp:137] Memory required for data: 4024115400
I0617 01:29:11.177381 18816 layer_factory.hpp:77] Creating layer conv6/sep
I0617 01:29:11.177399 18816 net.cpp:84] Creating Layer conv6/sep
I0617 01:29:11.177410 18816 net.cpp:406] conv6/sep <- conv6/dw
I0617 01:29:11.177426 18816 net.cpp:380] conv6/sep -> conv6/sep
I0617 01:29:11.195983 18816 net.cpp:122] Setting up conv6/sep
I0617 01:29:11.196017 18816 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0617 01:29:11.196040 18816 net.cpp:137] Memory required for data: 4034150600
I0617 01:29:11.196053 18816 layer_factory.hpp:77] Creating layer conv6/sep/bn
I0617 01:29:11.196071 18816 net.cpp:84] Creating Layer conv6/sep/bn
I0617 01:29:11.196081 18816 net.cpp:406] conv6/sep/bn <- conv6/sep
I0617 01:29:11.196096 18816 net.cpp:367] conv6/sep/bn -> conv6/sep (in-place)
I0617 01:29:11.196372 18816 net.cpp:122] Setting up conv6/sep/bn
I0617 01:29:11.196388 18816 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0617 01:29:11.196398 18816 net.cpp:137] Memory required for data: 4044185800
I0617 01:29:11.196411 18816 layer_factory.hpp:77] Creating layer conv6/sep/scale
I0617 01:29:11.196424 18816 net.cpp:84] Creating Layer conv6/sep/scale
I0617 01:29:11.196434 18816 net.cpp:406] conv6/sep/scale <- conv6/sep
I0617 01:29:11.196450 18816 net.cpp:367] conv6/sep/scale -> conv6/sep (in-place)
I0617 01:29:11.196511 18816 layer_factory.hpp:77] Creating layer conv6/sep/scale
I0617 01:29:11.196693 18816 net.cpp:122] Setting up conv6/sep/scale
I0617 01:29:11.196714 18816 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0617 01:29:11.196723 18816 net.cpp:137] Memory required for data: 4054221000
I0617 01:29:11.196737 18816 layer_factory.hpp:77] Creating layer relu6/sep
I0617 01:29:11.196748 18816 net.cpp:84] Creating Layer relu6/sep
I0617 01:29:11.196758 18816 net.cpp:406] relu6/sep <- conv6/sep
I0617 01:29:11.196768 18816 net.cpp:367] relu6/sep -> conv6/sep (in-place)
I0617 01:29:11.197216 18816 net.cpp:122] Setting up relu6/sep
I0617 01:29:11.197237 18816 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0617 01:29:11.197247 18816 net.cpp:137] Memory required for data: 4064256200
I0617 01:29:11.197255 18816 layer_factory.hpp:77] Creating layer pool6
I0617 01:29:11.197273 18816 net.cpp:84] Creating Layer pool6
I0617 01:29:11.197283 18816 net.cpp:406] pool6 <- conv6/sep
I0617 01:29:11.197293 18816 net.cpp:380] pool6 -> pool6
I0617 01:29:11.197634 18816 net.cpp:122] Setting up pool6
I0617 01:29:11.197656 18816 net.cpp:129] Top shape: 50 1024 1 1 (51200)
I0617 01:29:11.197665 18816 net.cpp:137] Memory required for data: 4064461000
I0617 01:29:11.197674 18816 layer_factory.hpp:77] Creating layer fc7_oxford
I0617 01:29:11.197693 18816 net.cpp:84] Creating Layer fc7_oxford
I0617 01:29:11.197703 18816 net.cpp:406] fc7_oxford <- pool6
I0617 01:29:11.197716 18816 net.cpp:380] fc7_oxford -> fc7
I0617 01:29:11.200711 18816 net.cpp:122] Setting up fc7_oxford
I0617 01:29:11.200736 18816 net.cpp:129] Top shape: 50 102 1 1 (5100)
I0617 01:29:11.200744 18816 net.cpp:137] Memory required for data: 4064481400
I0617 01:29:11.200757 18816 layer_factory.hpp:77] Creating layer loss
I0617 01:29:11.200778 18816 net.cpp:84] Creating Layer loss
I0617 01:29:11.200788 18816 net.cpp:406] loss <- fc7
I0617 01:29:11.200798 18816 net.cpp:406] loss <- label
I0617 01:29:11.200810 18816 net.cpp:380] loss -> loss
I0617 01:29:11.200834 18816 layer_factory.hpp:77] Creating layer loss
I0617 01:29:11.201463 18816 net.cpp:122] Setting up loss
I0617 01:29:11.201485 18816 net.cpp:129] Top shape: (1)
I0617 01:29:11.201494 18816 net.cpp:132]     with loss weight 1
I0617 01:29:11.201571 18816 net.cpp:137] Memory required for data: 4064481404
I0617 01:29:11.201581 18816 net.cpp:198] loss needs backward computation.
I0617 01:29:11.201591 18816 net.cpp:198] fc7_oxford needs backward computation.
I0617 01:29:11.201598 18816 net.cpp:198] pool6 needs backward computation.
I0617 01:29:11.201607 18816 net.cpp:198] relu6/sep needs backward computation.
I0617 01:29:11.201616 18816 net.cpp:198] conv6/sep/scale needs backward computation.
I0617 01:29:11.201622 18816 net.cpp:198] conv6/sep/bn needs backward computation.
I0617 01:29:11.201630 18816 net.cpp:198] conv6/sep needs backward computation.
I0617 01:29:11.201638 18816 net.cpp:198] relu6/dw needs backward computation.
I0617 01:29:11.201647 18816 net.cpp:198] conv6/dw/scale needs backward computation.
I0617 01:29:11.201654 18816 net.cpp:198] conv6/dw/bn needs backward computation.
I0617 01:29:11.201663 18816 net.cpp:198] conv6/dw needs backward computation.
I0617 01:29:11.201681 18816 net.cpp:198] relu5_6/sep needs backward computation.
I0617 01:29:11.201690 18816 net.cpp:198] conv5_6/sep/scale needs backward computation.
I0617 01:29:11.201699 18816 net.cpp:198] conv5_6/sep/bn needs backward computation.
I0617 01:29:11.201706 18816 net.cpp:198] conv5_6/sep needs backward computation.
I0617 01:29:11.201714 18816 net.cpp:198] relu5_6/dw needs backward computation.
I0617 01:29:11.201722 18816 net.cpp:198] conv5_6/dw/scale needs backward computation.
I0617 01:29:11.201730 18816 net.cpp:198] conv5_6/dw/bn needs backward computation.
I0617 01:29:11.201738 18816 net.cpp:198] conv5_6/dw needs backward computation.
I0617 01:29:11.201746 18816 net.cpp:198] relu5_5/sep needs backward computation.
I0617 01:29:11.201755 18816 net.cpp:198] conv5_5/sep/scale needs backward computation.
I0617 01:29:11.201762 18816 net.cpp:198] conv5_5/sep/bn needs backward computation.
I0617 01:29:11.201771 18816 net.cpp:198] conv5_5/sep needs backward computation.
I0617 01:29:11.201779 18816 net.cpp:198] relu5_5/dw needs backward computation.
I0617 01:29:11.201787 18816 net.cpp:198] conv5_5/dw/scale needs backward computation.
I0617 01:29:11.201795 18816 net.cpp:198] conv5_5/dw/bn needs backward computation.
I0617 01:29:11.201803 18816 net.cpp:198] conv5_5/dw needs backward computation.
I0617 01:29:11.201812 18816 net.cpp:198] relu5_4/sep needs backward computation.
I0617 01:29:11.201820 18816 net.cpp:198] conv5_4/sep/scale needs backward computation.
I0617 01:29:11.201828 18816 net.cpp:198] conv5_4/sep/bn needs backward computation.
I0617 01:29:11.201836 18816 net.cpp:198] conv5_4/sep needs backward computation.
I0617 01:29:11.201844 18816 net.cpp:198] relu5_4/dw needs backward computation.
I0617 01:29:11.201853 18816 net.cpp:198] conv5_4/dw/scale needs backward computation.
I0617 01:29:11.201860 18816 net.cpp:198] conv5_4/dw/bn needs backward computation.
I0617 01:29:11.201869 18816 net.cpp:198] conv5_4/dw needs backward computation.
I0617 01:29:11.201884 18816 net.cpp:198] relu5_3/sep needs backward computation.
I0617 01:29:11.201892 18816 net.cpp:198] conv5_3/sep/scale needs backward computation.
I0617 01:29:11.201900 18816 net.cpp:198] conv5_3/sep/bn needs backward computation.
I0617 01:29:11.201908 18816 net.cpp:198] conv5_3/sep needs backward computation.
I0617 01:29:11.201916 18816 net.cpp:198] relu5_3/dw needs backward computation.
I0617 01:29:11.201925 18816 net.cpp:198] conv5_3/dw/scale needs backward computation.
I0617 01:29:11.201932 18816 net.cpp:198] conv5_3/dw/bn needs backward computation.
I0617 01:29:11.201941 18816 net.cpp:198] conv5_3/dw needs backward computation.
I0617 01:29:11.201948 18816 net.cpp:198] relu5_2/sep needs backward computation.
I0617 01:29:11.201956 18816 net.cpp:198] conv5_2/sep/scale needs backward computation.
I0617 01:29:11.201964 18816 net.cpp:198] conv5_2/sep/bn needs backward computation.
I0617 01:29:11.201972 18816 net.cpp:198] conv5_2/sep needs backward computation.
I0617 01:29:11.201980 18816 net.cpp:198] relu5_2/dw needs backward computation.
I0617 01:29:11.201988 18816 net.cpp:198] conv5_2/dw/scale needs backward computation.
I0617 01:29:11.201997 18816 net.cpp:198] conv5_2/dw/bn needs backward computation.
I0617 01:29:11.202003 18816 net.cpp:198] conv5_2/dw needs backward computation.
I0617 01:29:11.202013 18816 net.cpp:198] relu5_1/sep needs backward computation.
I0617 01:29:11.202020 18816 net.cpp:198] conv5_1/sep/scale needs backward computation.
I0617 01:29:11.202028 18816 net.cpp:198] conv5_1/sep/bn needs backward computation.
I0617 01:29:11.202036 18816 net.cpp:198] conv5_1/sep needs backward computation.
I0617 01:29:11.202044 18816 net.cpp:198] relu5_1/dw needs backward computation.
I0617 01:29:11.202052 18816 net.cpp:198] conv5_1/dw/scale needs backward computation.
I0617 01:29:11.202059 18816 net.cpp:198] conv5_1/dw/bn needs backward computation.
I0617 01:29:11.202067 18816 net.cpp:198] conv5_1/dw needs backward computation.
I0617 01:29:11.202076 18816 net.cpp:198] relu4_2/sep needs backward computation.
I0617 01:29:11.202092 18816 net.cpp:198] conv4_2/sep/scale needs backward computation.
I0617 01:29:11.202101 18816 net.cpp:198] conv4_2/sep/bn needs backward computation.
I0617 01:29:11.202109 18816 net.cpp:198] conv4_2/sep needs backward computation.
I0617 01:29:11.202118 18816 net.cpp:198] relu4_2/dw needs backward computation.
I0617 01:29:11.202126 18816 net.cpp:198] conv4_2/dw/scale needs backward computation.
I0617 01:29:11.202134 18816 net.cpp:198] conv4_2/dw/bn needs backward computation.
I0617 01:29:11.202142 18816 net.cpp:198] conv4_2/dw needs backward computation.
I0617 01:29:11.202150 18816 net.cpp:198] relu4_1/sep needs backward computation.
I0617 01:29:11.202159 18816 net.cpp:198] conv4_1/sep/scale needs backward computation.
I0617 01:29:11.202167 18816 net.cpp:198] conv4_1/sep/bn needs backward computation.
I0617 01:29:11.202175 18816 net.cpp:198] conv4_1/sep needs backward computation.
I0617 01:29:11.202183 18816 net.cpp:198] relu4_1/dw needs backward computation.
I0617 01:29:11.202191 18816 net.cpp:198] conv4_1/dw/scale needs backward computation.
I0617 01:29:11.202199 18816 net.cpp:198] conv4_1/dw/bn needs backward computation.
I0617 01:29:11.202208 18816 net.cpp:198] conv4_1/dw needs backward computation.
I0617 01:29:11.202215 18816 net.cpp:198] relu3_2/sep needs backward computation.
I0617 01:29:11.202224 18816 net.cpp:198] conv3_2/sep/scale needs backward computation.
I0617 01:29:11.202232 18816 net.cpp:198] conv3_2/sep/bn needs backward computation.
I0617 01:29:11.202244 18816 net.cpp:198] conv3_2/sep needs backward computation.
I0617 01:29:11.202255 18816 net.cpp:198] relu3_2/dw needs backward computation.
I0617 01:29:11.202270 18816 net.cpp:198] conv3_2/dw/scale needs backward computation.
I0617 01:29:11.202277 18816 net.cpp:198] conv3_2/dw/bn needs backward computation.
I0617 01:29:11.202286 18816 net.cpp:198] conv3_2/dw needs backward computation.
I0617 01:29:11.202294 18816 net.cpp:198] relu3_1/sep needs backward computation.
I0617 01:29:11.202308 18816 net.cpp:198] conv3_1/sep/scale needs backward computation.
I0617 01:29:11.202316 18816 net.cpp:198] conv3_1/sep/bn needs backward computation.
I0617 01:29:11.202324 18816 net.cpp:198] conv3_1/sep needs backward computation.
I0617 01:29:11.202332 18816 net.cpp:198] relu3_1/dw needs backward computation.
I0617 01:29:11.202340 18816 net.cpp:198] conv3_1/dw/scale needs backward computation.
I0617 01:29:11.202348 18816 net.cpp:198] conv3_1/dw/bn needs backward computation.
I0617 01:29:11.202356 18816 net.cpp:198] conv3_1/dw needs backward computation.
I0617 01:29:11.202364 18816 net.cpp:198] relu2_2/sep needs backward computation.
I0617 01:29:11.202373 18816 net.cpp:198] conv2_2/sep/scale needs backward computation.
I0617 01:29:11.202380 18816 net.cpp:198] conv2_2/sep/bn needs backward computation.
I0617 01:29:11.202389 18816 net.cpp:198] conv2_2/sep needs backward computation.
I0617 01:29:11.202396 18816 net.cpp:198] relu2_2/dw needs backward computation.
I0617 01:29:11.202404 18816 net.cpp:198] conv2_2/dw/scale needs backward computation.
I0617 01:29:11.202412 18816 net.cpp:198] conv2_2/dw/bn needs backward computation.
I0617 01:29:11.202420 18816 net.cpp:198] conv2_2/dw needs backward computation.
I0617 01:29:11.202428 18816 net.cpp:198] relu2_1/sep needs backward computation.
I0617 01:29:11.202436 18816 net.cpp:198] conv2_1/sep/scale needs backward computation.
I0617 01:29:11.202445 18816 net.cpp:198] conv2_1/sep/bn needs backward computation.
I0617 01:29:11.202451 18816 net.cpp:198] conv2_1/sep needs backward computation.
I0617 01:29:11.202461 18816 net.cpp:198] relu2_1/dw needs backward computation.
I0617 01:29:11.202467 18816 net.cpp:198] conv2_1/dw/scale needs backward computation.
I0617 01:29:11.202476 18816 net.cpp:198] conv2_1/dw/bn needs backward computation.
I0617 01:29:11.202483 18816 net.cpp:198] conv2_1/dw needs backward computation.
I0617 01:29:11.202491 18816 net.cpp:198] relu1 needs backward computation.
I0617 01:29:11.202499 18816 net.cpp:198] conv1/scale needs backward computation.
I0617 01:29:11.202507 18816 net.cpp:198] conv1/bn needs backward computation.
I0617 01:29:11.202531 18816 net.cpp:198] conv1 needs backward computation.
I0617 01:29:11.202541 18816 net.cpp:200] data does not need backward computation.
I0617 01:29:11.202550 18816 net.cpp:242] This network produces output loss
I0617 01:29:11.202623 18816 net.cpp:255] Network initialization done.
I0617 01:29:11.202940 18816 solver.cpp:56] Solver scaffolding done.
I0617 01:29:11.210569 18816 caffe.cpp:155] Finetuning from mobilenet/mobilenet.caffemodel
I0617 01:29:11.233924 18816 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: mobilenet/mobilenet.caffemodel
I0617 01:29:11.234088 18816 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0617 01:29:11.234141 18816 net.cpp:744] Ignoring source layer label_data_1_split
I0617 01:29:11.239117 18816 net.cpp:744] Ignoring source layer fc7
I0617 01:29:11.239177 18816 net.cpp:744] Ignoring source layer fc7_fc7_0_split
I0617 01:29:11.239188 18816 net.cpp:744] Ignoring source layer top1/acc
I0617 01:29:11.239197 18816 net.cpp:744] Ignoring source layer top5/acc
I0617 01:29:11.240751 18816 caffe.cpp:248] Starting Optimization
I0617 01:29:11.240804 18816 solver.cpp:272] Solving MOBILENET
I0617 01:29:11.240816 18816 solver.cpp:273] Learning Rate Policy: step
I0617 01:29:11.248286 18816 blocking_queue.cpp:49] Waiting for data
I0617 01:29:12.477416 18816 solver.cpp:218] Iteration 0 (-8.26766e-44 iter/s, 1.23631s/50 iters), loss = 5.69646
I0617 01:29:12.477695 18816 solver.cpp:237]     Train net output #0: loss = 5.69646 (* 1 = 5.69646 loss)
I0617 01:29:12.477792 18816 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I0617 01:30:10.199800 18816 solver.cpp:218] Iteration 50 (0.866224 iter/s, 57.7218s/50 iters), loss = 0.542689
I0617 01:30:10.200057 18816 solver.cpp:237]     Train net output #0: loss = 0.542689 (* 1 = 0.542689 loss)
I0617 01:30:10.200083 18816 sgd_solver.cpp:105] Iteration 50, lr = 0.01
I0617 01:31:07.929715 18816 solver.cpp:218] Iteration 100 (0.866115 iter/s, 57.7291s/50 iters), loss = 0.403661
I0617 01:31:07.929862 18816 solver.cpp:237]     Train net output #0: loss = 0.403661 (* 1 = 0.403661 loss)
I0617 01:31:07.929889 18816 sgd_solver.cpp:105] Iteration 100, lr = 0.01
I0617 01:32:05.660071 18816 solver.cpp:218] Iteration 150 (0.866107 iter/s, 57.7296s/50 iters), loss = 0.0769148
I0617 01:32:05.660230 18816 solver.cpp:237]     Train net output #0: loss = 0.0769147 (* 1 = 0.0769147 loss)
I0617 01:32:05.660259 18816 sgd_solver.cpp:105] Iteration 150, lr = 0.01
I0617 01:33:03.396991 18816 solver.cpp:218] Iteration 200 (0.866009 iter/s, 57.7361s/50 iters), loss = 0.0569754
I0617 01:33:03.397151 18816 solver.cpp:237]     Train net output #0: loss = 0.0569754 (* 1 = 0.0569754 loss)
I0617 01:33:03.397178 18816 sgd_solver.cpp:105] Iteration 200, lr = 0.01
I0617 01:34:01.132261 18816 solver.cpp:218] Iteration 250 (0.866034 iter/s, 57.7344s/50 iters), loss = 0.0461283
I0617 01:34:01.132400 18816 solver.cpp:237]     Train net output #0: loss = 0.0461283 (* 1 = 0.0461283 loss)
I0617 01:34:01.132426 18816 sgd_solver.cpp:105] Iteration 250, lr = 0.01
I0617 01:34:58.884099 18816 solver.cpp:218] Iteration 300 (0.865785 iter/s, 57.751s/50 iters), loss = 0.0277295
I0617 01:34:58.884254 18816 solver.cpp:237]     Train net output #0: loss = 0.0277295 (* 1 = 0.0277295 loss)
I0617 01:34:58.884281 18816 sgd_solver.cpp:105] Iteration 300, lr = 0.01
I0617 01:35:56.618516 18816 solver.cpp:218] Iteration 350 (0.866047 iter/s, 57.7336s/50 iters), loss = 0.00839179
I0617 01:35:56.618747 18816 solver.cpp:237]     Train net output #0: loss = 0.00839176 (* 1 = 0.00839176 loss)
I0617 01:35:56.618775 18816 sgd_solver.cpp:105] Iteration 350, lr = 0.01
I0617 01:36:54.360250 18816 solver.cpp:218] Iteration 400 (0.865938 iter/s, 57.7408s/50 iters), loss = 0.0421592
I0617 01:36:54.360388 18816 solver.cpp:237]     Train net output #0: loss = 0.0421592 (* 1 = 0.0421592 loss)
I0617 01:36:54.360421 18816 sgd_solver.cpp:105] Iteration 400, lr = 0.01
I0617 01:37:52.107795 18816 solver.cpp:218] Iteration 450 (0.86585 iter/s, 57.7467s/50 iters), loss = 0.0138355
I0617 01:37:52.107956 18816 solver.cpp:237]     Train net output #0: loss = 0.0138355 (* 1 = 0.0138355 loss)
I0617 01:37:52.107985 18816 sgd_solver.cpp:105] Iteration 450, lr = 0.01
I0617 01:38:14.056511 18816 solver.cpp:447] Snapshotting to binary proto file mobilenet/mobile_2_iter_470.caffemodel
I0617 01:38:14.150715 18816 sgd_solver.cpp:273] Snapshotting solver state to binary proto file mobilenet/mobile_2_iter_470.solverstate
I0617 01:38:14.180320 18816 solver.cpp:294] Optimization stopped early.
I0617 01:38:14.180367 18816 caffe.cpp:259] Optimization Done.
I0617 01:38:25.362216 12178 caffe.cpp:218] Using GPUs 3
I0617 01:38:25.564817 12178 caffe.cpp:223] GPU 3: Tesla K40m
I0617 01:38:25.919271 12178 solver.cpp:44] Initializing solver from parameters: 
base_lr: 0.01
display: 50
max_iter: 200000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.001
stepsize: 50000
snapshot: 10000
snapshot_prefix: "mobilenet/mobile_2"
solver_mode: GPU
device_id: 3
net: "/home/xingzhaolong/caffe_project/caffe_mobile/models/oxford/mobilenet/mobilenet_deploy.prototxt"
train_state {
  level: 0
  stage: ""
}
I0617 01:38:25.919603 12178 solver.cpp:87] Creating training net from net file: /home/xingzhaolong/caffe_project/caffe_mobile/models/oxford/mobilenet/mobilenet_deploy.prototxt
I0617 01:38:25.922226 12178 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/xingzhaolong/caffe_project/caffe_mobile/models/oxford/mobilenet/mobilenet_deploy.prototxt
I0617 01:38:25.922253 12178 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0617 01:38:25.922549 12178 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0617 01:38:25.923563 12178 net.cpp:51] Initializing net from parameters: 
name: "MOBILENET"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_file: "/home/xingzhaolong/caffe_project/caffe/models/caffe-oxford102/imagenet_mean.binaryproto"
  }
  image_data_param {
    source: "/home/xingzhaolong/caffe_project/caffe/models/caffe-oxford102/test.txt"
    batch_size: 50
    new_height: 256
    new_width: 256
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv1/bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1/scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2_1/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv1"
  top: "conv2_1/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 32
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv2_1/dw"
  top: "conv2_1/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_1/dw/scale"
  type: "Scale"
  bottom: "conv2_1/dw"
  top: "conv2_1/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_1/dw"
  type: "ReLU"
  bottom: "conv2_1/dw"
  top: "conv2_1/dw"
}
layer {
  name: "conv2_1/sep"
  type: "Convolution"
  bottom: "conv2_1/dw"
  top: "conv2_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv2_1/sep"
  top: "conv2_1/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_1/sep/scale"
  type: "Scale"
  bottom: "conv2_1/sep"
  top: "conv2_1/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_1/sep"
  type: "ReLU"
  bottom: "conv2_1/sep"
  top: "conv2_1/sep"
}
layer {
  name: "conv2_2/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv2_1/sep"
  top: "conv2_2/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 64
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv2_2/dw"
  top: "conv2_2/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_2/dw/scale"
  type: "Scale"
  bottom: "conv2_2/dw"
  top: "conv2_2/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_2/dw"
  type: "ReLU"
  bottom: "conv2_2/dw"
  top: "conv2_2/dw"
}
layer {
  name: "conv2_2/sep"
  type: "Convolution"
  bottom: "conv2_2/dw"
  top: "conv2_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv2_2/sep"
  top: "conv2_2/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_2/sep/scale"
  type: "Scale"
  bottom: "conv2_2/sep"
  top: "conv2_2/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_2/sep"
  type: "ReLU"
  bottom: "conv2_2/sep"
  top: "conv2_2/sep"
}
layer {
  name: "conv3_1/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv2_2/sep"
  top: "conv3_1/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv3_1/dw"
  top: "conv3_1/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_1/dw/scale"
  type: "Scale"
  bottom: "conv3_1/dw"
  top: "conv3_1/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_1/dw"
  type: "ReLU"
  bottom: "conv3_1/dw"
  top: "conv3_1/dw"
}
layer {
  name: "conv3_1/sep"
  type: "Convolution"
  bottom: "conv3_1/dw"
  top: "conv3_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv3_1/sep"
  top: "conv3_1/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_1/sep/scale"
  type: "Scale"
  bottom: "conv3_1/sep"
  top: "conv3_1/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_1/sep"
  type: "ReLU"
  bottom: "conv3_1/sep"
  top: "conv3_1/sep"
}
layer {
  name: "conv3_2/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv3_1/sep"
  top: "conv3_2/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv3_2/dw"
  top: "conv3_2/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_2/dw/scale"
  type: "Scale"
  bottom: "conv3_2/dw"
  top: "conv3_2/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_2/dw"
  type: "ReLU"
  bottom: "conv3_2/dw"
  top: "conv3_2/dw"
}
layer {
  name: "conv3_2/sep"
  type: "Convolution"
  bottom: "conv3_2/dw"
  top: "conv3_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv3_2/sep"
  top: "conv3_2/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_2/sep/scale"
  type: "Scale"
  bottom: "conv3_2/sep"
  top: "conv3_2/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_2/sep"
  type: "ReLU"
  bottom: "conv3_2/sep"
  top: "conv3_2/sep"
}
layer {
  name: "conv4_1/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv3_2/sep"
  top: "conv4_1/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv4_1/dw"
  top: "conv4_1/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv4_1/dw/scale"
  type: "Scale"
  bottom: "conv4_1/dw"
  top: "conv4_1/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu4_1/dw"
  type: "ReLU"
  bottom: "conv4_1/dw"
  top: "conv4_1/dw"
}
layer {
  name: "conv4_1/sep"
  type: "Convolution"
  bottom: "conv4_1/dw"
  top: "conv4_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv4_1/sep"
  top: "conv4_1/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv4_1/sep/scale"
  type: "Scale"
  bottom: "conv4_1/sep"
  top: "conv4_1/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu4_1/sep"
  type: "ReLU"
  bottom: "conv4_1/sep"
  top: "conv4_1/sep"
}
layer {
  name: "conv4_2/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv4_1/sep"
  top: "conv4_2/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv4_2/dw"
  top: "conv4_2/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv4_2/dw/scale"
  type: "Scale"
  bottom: "conv4_2/dw"
  top: "conv4_2/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu4_2/dw"
  type: "ReLU"
  bottom: "conv4_2/dw"
  top: "conv4_2/dw"
}
layer {
  name: "conv4_2/sep"
  type: "Convolution"
  bottom: "conv4_2/dw"
  top: "conv4_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv4_2/sep"
  top: "conv4_2/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv4_2/sep/scale"
  type: "Scale"
  bottom: "conv4_2/sep"
  top: "conv4_2/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu4_2/sep"
  type: "ReLU"
  bottom: "conv4_2/sep"
  top: "conv4_2/sep"
}
layer {
  name: "conv5_1/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv4_2/sep"
  top: "conv5_1/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_1/dw"
  top: "conv5_1/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_1/dw/scale"
  type: "Scale"
  bottom: "conv5_1/dw"
  top: "conv5_1/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_1/dw"
  type: "ReLU"
  bottom: "conv5_1/dw"
  top: "conv5_1/dw"
}
layer {
  name: "conv5_1/sep"
  type: "Convolution"
  bottom: "conv5_1/dw"
  top: "conv5_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_1/sep"
  top: "conv5_1/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_1/sep/scale"
  type: "Scale"
  bottom: "conv5_1/sep"
  top: "conv5_1/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_1/sep"
  type: "ReLU"
  bottom: "conv5_1/sep"
  top: "conv5_1/sep"
}
layer {
  name: "conv5_2/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_1/sep"
  top: "conv5_2/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_2/dw"
  top: "conv5_2/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_2/dw/scale"
  type: "Scale"
  bottom: "conv5_2/dw"
  top: "conv5_2/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_2/dw"
  type: "ReLU"
  bottom: "conv5_2/dw"
  top: "conv5_2/dw"
}
layer {
  name: "conv5_2/sep"
  type: "Convolution"
  bottom: "conv5_2/dw"
  top: "conv5_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_2/sep"
  top: "conv5_2/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_2/sep/scale"
  type: "Scale"
  bottom: "conv5_2/sep"
  top: "conv5_2/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_2/sep"
  type: "ReLU"
  bottom: "conv5_2/sep"
  top: "conv5_2/sep"
}
layer {
  name: "conv5_3/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_2/sep"
  top: "conv5_3/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_3/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_3/dw"
  top: "conv5_3/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_3/dw/scale"
  type: "Scale"
  bottom: "conv5_3/dw"
  top: "conv5_3/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_3/dw"
  type: "ReLU"
  bottom: "conv5_3/dw"
  top: "conv5_3/dw"
}
layer {
  name: "conv5_3/sep"
  type: "Convolution"
  bottom: "conv5_3/dw"
  top: "conv5_3/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_3/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_3/sep"
  top: "conv5_3/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_3/sep/scale"
  type: "Scale"
  bottom: "conv5_3/sep"
  top: "conv5_3/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_3/sep"
  type: "ReLU"
  bottom: "conv5_3/sep"
  top: "conv5_3/sep"
}
layer {
  name: "conv5_4/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_3/sep"
  top: "conv5_4/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_4/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_4/dw"
  top: "conv5_4/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_4/dw/scale"
  type: "Scale"
  bottom: "conv5_4/dw"
  top: "conv5_4/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_4/dw"
  type: "ReLU"
  bottom: "conv5_4/dw"
  top: "conv5_4/dw"
}
layer {
  name: "conv5_4/sep"
  type: "Convolution"
  bottom: "conv5_4/dw"
  top: "conv5_4/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_4/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_4/sep"
  top: "conv5_4/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_4/sep/scale"
  type: "Scale"
  bottom: "conv5_4/sep"
  top: "conv5_4/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_4/sep"
  type: "ReLU"
  bottom: "conv5_4/sep"
  top: "conv5_4/sep"
}
layer {
  name: "conv5_5/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_4/sep"
  top: "conv5_5/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_5/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_5/dw"
  top: "conv5_5/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_5/dw/scale"
  type: "Scale"
  bottom: "conv5_5/dw"
  top: "conv5_5/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_5/dw"
  type: "ReLU"
  bottom: "conv5_5/dw"
  top: "conv5_5/dw"
}
layer {
  name: "conv5_5/sep"
  type: "Convolution"
  bottom: "conv5_5/dw"
  top: "conv5_5/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_5/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_5/sep"
  top: "conv5_5/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_5/sep/scale"
  type: "Scale"
  bottom: "conv5_5/sep"
  top: "conv5_5/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_5/sep"
  type: "ReLU"
  bottom: "conv5_5/sep"
  top: "conv5_5/sep"
}
layer {
  name: "conv5_6/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_5/sep"
  top: "conv5_6/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_6/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_6/dw"
  top: "conv5_6/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_6/dw/scale"
  type: "Scale"
  bottom: "conv5_6/dw"
  top: "conv5_6/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_6/dw"
  type: "ReLU"
  bottom: "conv5_6/dw"
  top: "conv5_6/dw"
}
layer {
  name: "conv5_6/sep"
  type: "Convolution"
  bottom: "conv5_6/dw"
  top: "conv5_6/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_6/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_6/sep"
  top: "conv5_6/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_6/sep/scale"
  type: "Scale"
  bottom: "conv5_6/sep"
  top: "conv5_6/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_6/sep"
  type: "ReLU"
  bottom: "conv5_6/sep"
  top: "conv5_6/sep"
}
layer {
  name: "conv6/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_6/sep"
  top: "conv6/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 1024
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv6/dw/bn"
  type: "BatchNorm"
  bottom: "conv6/dw"
  top: "conv6/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv6/dw/scale"
  type: "Scale"
  bottom: "conv6/dw"
  top: "conv6/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu6/dw"
  type: "ReLU"
  bottom: "conv6/dw"
  top: "conv6/dw"
}
layer {
  name: "conv6/sep"
  type: "Convolution"
  bottom: "conv6/dw"
  top: "conv6/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv6/sep/bn"
  type: "BatchNorm"
  bottom: "conv6/sep"
  top: "conv6/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv6/sep/scale"
  type: "Scale"
  bottom: "conv6/sep"
  top: "conv6/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu6/sep"
  type: "ReLU"
  bottom: "conv6/sep"
  top: "conv6/sep"
}
layer {
  name: "pool6"
  type: "Pooling"
  bottom: "conv6/sep"
  top: "pool6"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc7_oxford"
  type: "Convolution"
  bottom: "pool6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 102
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc7"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc7"
  bottom: "label"
  top: "loss"
}
I0617 01:38:25.924141 12178 layer_factory.hpp:77] Creating layer data
I0617 01:38:25.924222 12178 net.cpp:84] Creating Layer data
I0617 01:38:25.924247 12178 net.cpp:380] data -> data
I0617 01:38:25.924288 12178 net.cpp:380] data -> label
I0617 01:38:25.924321 12178 data_transformer.cpp:25] Loading mean file from: /home/xingzhaolong/caffe_project/caffe/models/caffe-oxford102/imagenet_mean.binaryproto
I0617 01:38:25.929363 12178 image_data_layer.cpp:38] Opening file /home/xingzhaolong/caffe_project/caffe/models/caffe-oxford102/test.txt
I0617 01:38:25.931640 12178 image_data_layer.cpp:63] A total of 6149 images.
I0617 01:38:25.940171 12178 image_data_layer.cpp:90] output data size: 50,3,224,224
I0617 01:38:26.040745 12178 net.cpp:122] Setting up data
I0617 01:38:26.040807 12178 net.cpp:129] Top shape: 50 3 224 224 (7526400)
I0617 01:38:26.040820 12178 net.cpp:129] Top shape: 50 (50)
I0617 01:38:26.040829 12178 net.cpp:137] Memory required for data: 30105800
I0617 01:38:26.040843 12178 layer_factory.hpp:77] Creating layer label_data_1_split
I0617 01:38:26.040868 12178 net.cpp:84] Creating Layer label_data_1_split
I0617 01:38:26.040882 12178 net.cpp:406] label_data_1_split <- label
I0617 01:38:26.040913 12178 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0617 01:38:26.040935 12178 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0617 01:38:26.040997 12178 net.cpp:122] Setting up label_data_1_split
I0617 01:38:26.041013 12178 net.cpp:129] Top shape: 50 (50)
I0617 01:38:26.041023 12178 net.cpp:129] Top shape: 50 (50)
I0617 01:38:26.041030 12178 net.cpp:137] Memory required for data: 30106200
I0617 01:38:26.041038 12178 layer_factory.hpp:77] Creating layer conv1
I0617 01:38:26.041070 12178 net.cpp:84] Creating Layer conv1
I0617 01:38:26.041080 12178 net.cpp:406] conv1 <- data
I0617 01:38:26.041095 12178 net.cpp:380] conv1 -> conv1
I0617 01:38:26.270287 12178 net.cpp:122] Setting up conv1
I0617 01:38:26.270352 12178 net.cpp:129] Top shape: 50 32 112 112 (20070400)
I0617 01:38:26.270364 12178 net.cpp:137] Memory required for data: 110387800
I0617 01:38:26.270400 12178 layer_factory.hpp:77] Creating layer conv1/bn
I0617 01:38:26.270426 12178 net.cpp:84] Creating Layer conv1/bn
I0617 01:38:26.270437 12178 net.cpp:406] conv1/bn <- conv1
I0617 01:38:26.270452 12178 net.cpp:367] conv1/bn -> conv1 (in-place)
I0617 01:38:26.271574 12178 net.cpp:122] Setting up conv1/bn
I0617 01:38:26.271597 12178 net.cpp:129] Top shape: 50 32 112 112 (20070400)
I0617 01:38:26.271607 12178 net.cpp:137] Memory required for data: 190669400
I0617 01:38:26.271627 12178 layer_factory.hpp:77] Creating layer conv1/scale
I0617 01:38:26.271651 12178 net.cpp:84] Creating Layer conv1/scale
I0617 01:38:26.271661 12178 net.cpp:406] conv1/scale <- conv1
I0617 01:38:26.271672 12178 net.cpp:367] conv1/scale -> conv1 (in-place)
I0617 01:38:26.271739 12178 layer_factory.hpp:77] Creating layer conv1/scale
I0617 01:38:26.271894 12178 net.cpp:122] Setting up conv1/scale
I0617 01:38:26.271912 12178 net.cpp:129] Top shape: 50 32 112 112 (20070400)
I0617 01:38:26.271921 12178 net.cpp:137] Memory required for data: 270951000
I0617 01:38:26.271936 12178 layer_factory.hpp:77] Creating layer relu1
I0617 01:38:26.271952 12178 net.cpp:84] Creating Layer relu1
I0617 01:38:26.271961 12178 net.cpp:406] relu1 <- conv1
I0617 01:38:26.271972 12178 net.cpp:367] relu1 -> conv1 (in-place)
I0617 01:38:26.272426 12178 net.cpp:122] Setting up relu1
I0617 01:38:26.272447 12178 net.cpp:129] Top shape: 50 32 112 112 (20070400)
I0617 01:38:26.272456 12178 net.cpp:137] Memory required for data: 351232600
I0617 01:38:26.272464 12178 layer_factory.hpp:77] Creating layer conv2_1/dw
I0617 01:38:26.272483 12178 net.cpp:84] Creating Layer conv2_1/dw
I0617 01:38:26.272493 12178 net.cpp:406] conv2_1/dw <- conv1
I0617 01:38:26.272506 12178 net.cpp:380] conv2_1/dw -> conv2_1/dw
I0617 01:38:26.275053 12178 net.cpp:122] Setting up conv2_1/dw
I0617 01:38:26.275077 12178 net.cpp:129] Top shape: 50 32 112 112 (20070400)
I0617 01:38:26.275086 12178 net.cpp:137] Memory required for data: 431514200
I0617 01:38:26.275097 12178 layer_factory.hpp:77] Creating layer conv2_1/dw/bn
I0617 01:38:26.275110 12178 net.cpp:84] Creating Layer conv2_1/dw/bn
I0617 01:38:26.275120 12178 net.cpp:406] conv2_1/dw/bn <- conv2_1/dw
I0617 01:38:26.275130 12178 net.cpp:367] conv2_1/dw/bn -> conv2_1/dw (in-place)
I0617 01:38:26.275348 12178 net.cpp:122] Setting up conv2_1/dw/bn
I0617 01:38:26.275365 12178 net.cpp:129] Top shape: 50 32 112 112 (20070400)
I0617 01:38:26.275374 12178 net.cpp:137] Memory required for data: 511795800
I0617 01:38:26.275393 12178 layer_factory.hpp:77] Creating layer conv2_1/dw/scale
I0617 01:38:26.275418 12178 net.cpp:84] Creating Layer conv2_1/dw/scale
I0617 01:38:26.275429 12178 net.cpp:406] conv2_1/dw/scale <- conv2_1/dw
I0617 01:38:26.275439 12178 net.cpp:367] conv2_1/dw/scale -> conv2_1/dw (in-place)
I0617 01:38:26.275493 12178 layer_factory.hpp:77] Creating layer conv2_1/dw/scale
I0617 01:38:26.275640 12178 net.cpp:122] Setting up conv2_1/dw/scale
I0617 01:38:26.275660 12178 net.cpp:129] Top shape: 50 32 112 112 (20070400)
I0617 01:38:26.275668 12178 net.cpp:137] Memory required for data: 592077400
I0617 01:38:26.275681 12178 layer_factory.hpp:77] Creating layer relu2_1/dw
I0617 01:38:26.275692 12178 net.cpp:84] Creating Layer relu2_1/dw
I0617 01:38:26.275701 12178 net.cpp:406] relu2_1/dw <- conv2_1/dw
I0617 01:38:26.275712 12178 net.cpp:367] relu2_1/dw -> conv2_1/dw (in-place)
I0617 01:38:26.275918 12178 net.cpp:122] Setting up relu2_1/dw
I0617 01:38:26.275936 12178 net.cpp:129] Top shape: 50 32 112 112 (20070400)
I0617 01:38:26.275945 12178 net.cpp:137] Memory required for data: 672359000
I0617 01:38:26.275954 12178 layer_factory.hpp:77] Creating layer conv2_1/sep
I0617 01:38:26.275969 12178 net.cpp:84] Creating Layer conv2_1/sep
I0617 01:38:26.275979 12178 net.cpp:406] conv2_1/sep <- conv2_1/dw
I0617 01:38:26.275991 12178 net.cpp:380] conv2_1/sep -> conv2_1/sep
I0617 01:38:26.278069 12178 net.cpp:122] Setting up conv2_1/sep
I0617 01:38:26.278092 12178 net.cpp:129] Top shape: 50 64 112 112 (40140800)
I0617 01:38:26.278102 12178 net.cpp:137] Memory required for data: 832922200
I0617 01:38:26.278112 12178 layer_factory.hpp:77] Creating layer conv2_1/sep/bn
I0617 01:38:26.278126 12178 net.cpp:84] Creating Layer conv2_1/sep/bn
I0617 01:38:26.278136 12178 net.cpp:406] conv2_1/sep/bn <- conv2_1/sep
I0617 01:38:26.278146 12178 net.cpp:367] conv2_1/sep/bn -> conv2_1/sep (in-place)
I0617 01:38:26.278367 12178 net.cpp:122] Setting up conv2_1/sep/bn
I0617 01:38:26.278384 12178 net.cpp:129] Top shape: 50 64 112 112 (40140800)
I0617 01:38:26.278393 12178 net.cpp:137] Memory required for data: 993485400
I0617 01:38:26.278406 12178 layer_factory.hpp:77] Creating layer conv2_1/sep/scale
I0617 01:38:26.278419 12178 net.cpp:84] Creating Layer conv2_1/sep/scale
I0617 01:38:26.278429 12178 net.cpp:406] conv2_1/sep/scale <- conv2_1/sep
I0617 01:38:26.278439 12178 net.cpp:367] conv2_1/sep/scale -> conv2_1/sep (in-place)
I0617 01:38:26.278491 12178 layer_factory.hpp:77] Creating layer conv2_1/sep/scale
I0617 01:38:26.278641 12178 net.cpp:122] Setting up conv2_1/sep/scale
I0617 01:38:26.278661 12178 net.cpp:129] Top shape: 50 64 112 112 (40140800)
I0617 01:38:26.278669 12178 net.cpp:137] Memory required for data: 1154048600
I0617 01:38:26.278686 12178 layer_factory.hpp:77] Creating layer relu2_1/sep
I0617 01:38:26.278697 12178 net.cpp:84] Creating Layer relu2_1/sep
I0617 01:38:26.278719 12178 net.cpp:406] relu2_1/sep <- conv2_1/sep
I0617 01:38:26.278731 12178 net.cpp:367] relu2_1/sep -> conv2_1/sep (in-place)
I0617 01:38:26.279136 12178 net.cpp:122] Setting up relu2_1/sep
I0617 01:38:26.279158 12178 net.cpp:129] Top shape: 50 64 112 112 (40140800)
I0617 01:38:26.279166 12178 net.cpp:137] Memory required for data: 1314611800
I0617 01:38:26.279175 12178 layer_factory.hpp:77] Creating layer conv2_2/dw
I0617 01:38:26.279189 12178 net.cpp:84] Creating Layer conv2_2/dw
I0617 01:38:26.279198 12178 net.cpp:406] conv2_2/dw <- conv2_1/sep
I0617 01:38:26.279211 12178 net.cpp:380] conv2_2/dw -> conv2_2/dw
I0617 01:38:26.280278 12178 net.cpp:122] Setting up conv2_2/dw
I0617 01:38:26.280303 12178 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0617 01:38:26.280311 12178 net.cpp:137] Memory required for data: 1354752600
I0617 01:38:26.280321 12178 layer_factory.hpp:77] Creating layer conv2_2/dw/bn
I0617 01:38:26.280335 12178 net.cpp:84] Creating Layer conv2_2/dw/bn
I0617 01:38:26.280344 12178 net.cpp:406] conv2_2/dw/bn <- conv2_2/dw
I0617 01:38:26.280356 12178 net.cpp:367] conv2_2/dw/bn -> conv2_2/dw (in-place)
I0617 01:38:26.280580 12178 net.cpp:122] Setting up conv2_2/dw/bn
I0617 01:38:26.280598 12178 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0617 01:38:26.280616 12178 net.cpp:137] Memory required for data: 1394893400
I0617 01:38:26.280629 12178 layer_factory.hpp:77] Creating layer conv2_2/dw/scale
I0617 01:38:26.280645 12178 net.cpp:84] Creating Layer conv2_2/dw/scale
I0617 01:38:26.280654 12178 net.cpp:406] conv2_2/dw/scale <- conv2_2/dw
I0617 01:38:26.280666 12178 net.cpp:367] conv2_2/dw/scale -> conv2_2/dw (in-place)
I0617 01:38:26.280720 12178 layer_factory.hpp:77] Creating layer conv2_2/dw/scale
I0617 01:38:26.280860 12178 net.cpp:122] Setting up conv2_2/dw/scale
I0617 01:38:26.280877 12178 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0617 01:38:26.280885 12178 net.cpp:137] Memory required for data: 1435034200
I0617 01:38:26.280897 12178 layer_factory.hpp:77] Creating layer relu2_2/dw
I0617 01:38:26.280908 12178 net.cpp:84] Creating Layer relu2_2/dw
I0617 01:38:26.280917 12178 net.cpp:406] relu2_2/dw <- conv2_2/dw
I0617 01:38:26.280928 12178 net.cpp:367] relu2_2/dw -> conv2_2/dw (in-place)
I0617 01:38:26.281136 12178 net.cpp:122] Setting up relu2_2/dw
I0617 01:38:26.281155 12178 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0617 01:38:26.281164 12178 net.cpp:137] Memory required for data: 1475175000
I0617 01:38:26.281172 12178 layer_factory.hpp:77] Creating layer conv2_2/sep
I0617 01:38:26.281188 12178 net.cpp:84] Creating Layer conv2_2/sep
I0617 01:38:26.281198 12178 net.cpp:406] conv2_2/sep <- conv2_2/dw
I0617 01:38:26.281210 12178 net.cpp:380] conv2_2/sep -> conv2_2/sep
I0617 01:38:26.282610 12178 net.cpp:122] Setting up conv2_2/sep
I0617 01:38:26.282639 12178 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0617 01:38:26.282649 12178 net.cpp:137] Memory required for data: 1555456600
I0617 01:38:26.282660 12178 layer_factory.hpp:77] Creating layer conv2_2/sep/bn
I0617 01:38:26.282672 12178 net.cpp:84] Creating Layer conv2_2/sep/bn
I0617 01:38:26.282682 12178 net.cpp:406] conv2_2/sep/bn <- conv2_2/sep
I0617 01:38:26.282696 12178 net.cpp:367] conv2_2/sep/bn -> conv2_2/sep (in-place)
I0617 01:38:26.282934 12178 net.cpp:122] Setting up conv2_2/sep/bn
I0617 01:38:26.282951 12178 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0617 01:38:26.282959 12178 net.cpp:137] Memory required for data: 1635738200
I0617 01:38:26.282974 12178 layer_factory.hpp:77] Creating layer conv2_2/sep/scale
I0617 01:38:26.282986 12178 net.cpp:84] Creating Layer conv2_2/sep/scale
I0617 01:38:26.282995 12178 net.cpp:406] conv2_2/sep/scale <- conv2_2/sep
I0617 01:38:26.283006 12178 net.cpp:367] conv2_2/sep/scale -> conv2_2/sep (in-place)
I0617 01:38:26.283063 12178 layer_factory.hpp:77] Creating layer conv2_2/sep/scale
I0617 01:38:26.283223 12178 net.cpp:122] Setting up conv2_2/sep/scale
I0617 01:38:26.283241 12178 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0617 01:38:26.283251 12178 net.cpp:137] Memory required for data: 1716019800
I0617 01:38:26.283273 12178 layer_factory.hpp:77] Creating layer relu2_2/sep
I0617 01:38:26.283287 12178 net.cpp:84] Creating Layer relu2_2/sep
I0617 01:38:26.283295 12178 net.cpp:406] relu2_2/sep <- conv2_2/sep
I0617 01:38:26.283308 12178 net.cpp:367] relu2_2/sep -> conv2_2/sep (in-place)
I0617 01:38:26.283550 12178 net.cpp:122] Setting up relu2_2/sep
I0617 01:38:26.283571 12178 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0617 01:38:26.283579 12178 net.cpp:137] Memory required for data: 1796301400
I0617 01:38:26.283587 12178 layer_factory.hpp:77] Creating layer conv3_1/dw
I0617 01:38:26.283604 12178 net.cpp:84] Creating Layer conv3_1/dw
I0617 01:38:26.283614 12178 net.cpp:406] conv3_1/dw <- conv2_2/sep
I0617 01:38:26.283627 12178 net.cpp:380] conv3_1/dw -> conv3_1/dw
I0617 01:38:26.284732 12178 net.cpp:122] Setting up conv3_1/dw
I0617 01:38:26.284755 12178 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0617 01:38:26.284765 12178 net.cpp:137] Memory required for data: 1876583000
I0617 01:38:26.284775 12178 layer_factory.hpp:77] Creating layer conv3_1/dw/bn
I0617 01:38:26.284793 12178 net.cpp:84] Creating Layer conv3_1/dw/bn
I0617 01:38:26.284803 12178 net.cpp:406] conv3_1/dw/bn <- conv3_1/dw
I0617 01:38:26.284822 12178 net.cpp:367] conv3_1/dw/bn -> conv3_1/dw (in-place)
I0617 01:38:26.285054 12178 net.cpp:122] Setting up conv3_1/dw/bn
I0617 01:38:26.285071 12178 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0617 01:38:26.285079 12178 net.cpp:137] Memory required for data: 1956864600
I0617 01:38:26.285099 12178 layer_factory.hpp:77] Creating layer conv3_1/dw/scale
I0617 01:38:26.285117 12178 net.cpp:84] Creating Layer conv3_1/dw/scale
I0617 01:38:26.285127 12178 net.cpp:406] conv3_1/dw/scale <- conv3_1/dw
I0617 01:38:26.285140 12178 net.cpp:367] conv3_1/dw/scale -> conv3_1/dw (in-place)
I0617 01:38:26.285198 12178 layer_factory.hpp:77] Creating layer conv3_1/dw/scale
I0617 01:38:26.285351 12178 net.cpp:122] Setting up conv3_1/dw/scale
I0617 01:38:26.285367 12178 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0617 01:38:26.285375 12178 net.cpp:137] Memory required for data: 2037146200
I0617 01:38:26.285387 12178 layer_factory.hpp:77] Creating layer relu3_1/dw
I0617 01:38:26.285399 12178 net.cpp:84] Creating Layer relu3_1/dw
I0617 01:38:26.285408 12178 net.cpp:406] relu3_1/dw <- conv3_1/dw
I0617 01:38:26.285421 12178 net.cpp:367] relu3_1/dw -> conv3_1/dw (in-place)
I0617 01:38:26.285877 12178 net.cpp:122] Setting up relu3_1/dw
I0617 01:38:26.285899 12178 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0617 01:38:26.285908 12178 net.cpp:137] Memory required for data: 2117427800
I0617 01:38:26.285917 12178 layer_factory.hpp:77] Creating layer conv3_1/sep
I0617 01:38:26.285943 12178 net.cpp:84] Creating Layer conv3_1/sep
I0617 01:38:26.285953 12178 net.cpp:406] conv3_1/sep <- conv3_1/dw
I0617 01:38:26.285965 12178 net.cpp:380] conv3_1/sep -> conv3_1/sep
I0617 01:38:26.287806 12178 net.cpp:122] Setting up conv3_1/sep
I0617 01:38:26.287829 12178 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0617 01:38:26.287838 12178 net.cpp:137] Memory required for data: 2197709400
I0617 01:38:26.287849 12178 layer_factory.hpp:77] Creating layer conv3_1/sep/bn
I0617 01:38:26.287866 12178 net.cpp:84] Creating Layer conv3_1/sep/bn
I0617 01:38:26.287876 12178 net.cpp:406] conv3_1/sep/bn <- conv3_1/sep
I0617 01:38:26.287888 12178 net.cpp:367] conv3_1/sep/bn -> conv3_1/sep (in-place)
I0617 01:38:26.288121 12178 net.cpp:122] Setting up conv3_1/sep/bn
I0617 01:38:26.288139 12178 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0617 01:38:26.288147 12178 net.cpp:137] Memory required for data: 2277991000
I0617 01:38:26.288161 12178 layer_factory.hpp:77] Creating layer conv3_1/sep/scale
I0617 01:38:26.288180 12178 net.cpp:84] Creating Layer conv3_1/sep/scale
I0617 01:38:26.288190 12178 net.cpp:406] conv3_1/sep/scale <- conv3_1/sep
I0617 01:38:26.288202 12178 net.cpp:367] conv3_1/sep/scale -> conv3_1/sep (in-place)
I0617 01:38:26.288260 12178 layer_factory.hpp:77] Creating layer conv3_1/sep/scale
I0617 01:38:26.288422 12178 net.cpp:122] Setting up conv3_1/sep/scale
I0617 01:38:26.288440 12178 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0617 01:38:26.288449 12178 net.cpp:137] Memory required for data: 2358272600
I0617 01:38:26.288460 12178 layer_factory.hpp:77] Creating layer relu3_1/sep
I0617 01:38:26.288471 12178 net.cpp:84] Creating Layer relu3_1/sep
I0617 01:38:26.288480 12178 net.cpp:406] relu3_1/sep <- conv3_1/sep
I0617 01:38:26.288493 12178 net.cpp:367] relu3_1/sep -> conv3_1/sep (in-place)
I0617 01:38:26.288735 12178 net.cpp:122] Setting up relu3_1/sep
I0617 01:38:26.288755 12178 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0617 01:38:26.288764 12178 net.cpp:137] Memory required for data: 2438554200
I0617 01:38:26.288772 12178 layer_factory.hpp:77] Creating layer conv3_2/dw
I0617 01:38:26.288789 12178 net.cpp:84] Creating Layer conv3_2/dw
I0617 01:38:26.288799 12178 net.cpp:406] conv3_2/dw <- conv3_1/sep
I0617 01:38:26.288815 12178 net.cpp:380] conv3_2/dw -> conv3_2/dw
I0617 01:38:26.289834 12178 net.cpp:122] Setting up conv3_2/dw
I0617 01:38:26.289860 12178 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0617 01:38:26.289870 12178 net.cpp:137] Memory required for data: 2458624600
I0617 01:38:26.289880 12178 layer_factory.hpp:77] Creating layer conv3_2/dw/bn
I0617 01:38:26.289899 12178 net.cpp:84] Creating Layer conv3_2/dw/bn
I0617 01:38:26.289909 12178 net.cpp:406] conv3_2/dw/bn <- conv3_2/dw
I0617 01:38:26.289924 12178 net.cpp:367] conv3_2/dw/bn -> conv3_2/dw (in-place)
I0617 01:38:26.290163 12178 net.cpp:122] Setting up conv3_2/dw/bn
I0617 01:38:26.290179 12178 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0617 01:38:26.290187 12178 net.cpp:137] Memory required for data: 2478695000
I0617 01:38:26.290200 12178 layer_factory.hpp:77] Creating layer conv3_2/dw/scale
I0617 01:38:26.290216 12178 net.cpp:84] Creating Layer conv3_2/dw/scale
I0617 01:38:26.290226 12178 net.cpp:406] conv3_2/dw/scale <- conv3_2/dw
I0617 01:38:26.290237 12178 net.cpp:367] conv3_2/dw/scale -> conv3_2/dw (in-place)
I0617 01:38:26.290298 12178 layer_factory.hpp:77] Creating layer conv3_2/dw/scale
I0617 01:38:26.290448 12178 net.cpp:122] Setting up conv3_2/dw/scale
I0617 01:38:26.290465 12178 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0617 01:38:26.290473 12178 net.cpp:137] Memory required for data: 2498765400
I0617 01:38:26.290484 12178 layer_factory.hpp:77] Creating layer relu3_2/dw
I0617 01:38:26.290496 12178 net.cpp:84] Creating Layer relu3_2/dw
I0617 01:38:26.290505 12178 net.cpp:406] relu3_2/dw <- conv3_2/dw
I0617 01:38:26.290526 12178 net.cpp:367] relu3_2/dw -> conv3_2/dw (in-place)
I0617 01:38:26.290982 12178 net.cpp:122] Setting up relu3_2/dw
I0617 01:38:26.291002 12178 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0617 01:38:26.291012 12178 net.cpp:137] Memory required for data: 2518835800
I0617 01:38:26.291020 12178 layer_factory.hpp:77] Creating layer conv3_2/sep
I0617 01:38:26.291038 12178 net.cpp:84] Creating Layer conv3_2/sep
I0617 01:38:26.291049 12178 net.cpp:406] conv3_2/sep <- conv3_2/dw
I0617 01:38:26.291072 12178 net.cpp:380] conv3_2/sep -> conv3_2/sep
I0617 01:38:26.292886 12178 net.cpp:122] Setting up conv3_2/sep
I0617 01:38:26.292912 12178 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0617 01:38:26.292919 12178 net.cpp:137] Memory required for data: 2558976600
I0617 01:38:26.292930 12178 layer_factory.hpp:77] Creating layer conv3_2/sep/bn
I0617 01:38:26.292946 12178 net.cpp:84] Creating Layer conv3_2/sep/bn
I0617 01:38:26.292956 12178 net.cpp:406] conv3_2/sep/bn <- conv3_2/sep
I0617 01:38:26.292968 12178 net.cpp:367] conv3_2/sep/bn -> conv3_2/sep (in-place)
I0617 01:38:26.293205 12178 net.cpp:122] Setting up conv3_2/sep/bn
I0617 01:38:26.293222 12178 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0617 01:38:26.293231 12178 net.cpp:137] Memory required for data: 2599117400
I0617 01:38:26.293243 12178 layer_factory.hpp:77] Creating layer conv3_2/sep/scale
I0617 01:38:26.293259 12178 net.cpp:84] Creating Layer conv3_2/sep/scale
I0617 01:38:26.293269 12178 net.cpp:406] conv3_2/sep/scale <- conv3_2/sep
I0617 01:38:26.293293 12178 net.cpp:367] conv3_2/sep/scale -> conv3_2/sep (in-place)
I0617 01:38:26.293354 12178 layer_factory.hpp:77] Creating layer conv3_2/sep/scale
I0617 01:38:26.293503 12178 net.cpp:122] Setting up conv3_2/sep/scale
I0617 01:38:26.293530 12178 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0617 01:38:26.293540 12178 net.cpp:137] Memory required for data: 2639258200
I0617 01:38:26.293551 12178 layer_factory.hpp:77] Creating layer relu3_2/sep
I0617 01:38:26.293566 12178 net.cpp:84] Creating Layer relu3_2/sep
I0617 01:38:26.293576 12178 net.cpp:406] relu3_2/sep <- conv3_2/sep
I0617 01:38:26.293586 12178 net.cpp:367] relu3_2/sep -> conv3_2/sep (in-place)
I0617 01:38:26.293808 12178 net.cpp:122] Setting up relu3_2/sep
I0617 01:38:26.293828 12178 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0617 01:38:26.293835 12178 net.cpp:137] Memory required for data: 2679399000
I0617 01:38:26.293843 12178 layer_factory.hpp:77] Creating layer conv4_1/dw
I0617 01:38:26.293859 12178 net.cpp:84] Creating Layer conv4_1/dw
I0617 01:38:26.293869 12178 net.cpp:406] conv4_1/dw <- conv3_2/sep
I0617 01:38:26.293886 12178 net.cpp:380] conv4_1/dw -> conv4_1/dw
I0617 01:38:26.294065 12178 net.cpp:122] Setting up conv4_1/dw
I0617 01:38:26.294083 12178 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0617 01:38:26.294100 12178 net.cpp:137] Memory required for data: 2719539800
I0617 01:38:26.294111 12178 layer_factory.hpp:77] Creating layer conv4_1/dw/bn
I0617 01:38:26.294126 12178 net.cpp:84] Creating Layer conv4_1/dw/bn
I0617 01:38:26.294136 12178 net.cpp:406] conv4_1/dw/bn <- conv4_1/dw
I0617 01:38:26.294147 12178 net.cpp:367] conv4_1/dw/bn -> conv4_1/dw (in-place)
I0617 01:38:26.294378 12178 net.cpp:122] Setting up conv4_1/dw/bn
I0617 01:38:26.294394 12178 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0617 01:38:26.294402 12178 net.cpp:137] Memory required for data: 2759680600
I0617 01:38:26.294415 12178 layer_factory.hpp:77] Creating layer conv4_1/dw/scale
I0617 01:38:26.294427 12178 net.cpp:84] Creating Layer conv4_1/dw/scale
I0617 01:38:26.294436 12178 net.cpp:406] conv4_1/dw/scale <- conv4_1/dw
I0617 01:38:26.294450 12178 net.cpp:367] conv4_1/dw/scale -> conv4_1/dw (in-place)
I0617 01:38:26.294504 12178 layer_factory.hpp:77] Creating layer conv4_1/dw/scale
I0617 01:38:26.294675 12178 net.cpp:122] Setting up conv4_1/dw/scale
I0617 01:38:26.294697 12178 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0617 01:38:26.294706 12178 net.cpp:137] Memory required for data: 2799821400
I0617 01:38:26.294718 12178 layer_factory.hpp:77] Creating layer relu4_1/dw
I0617 01:38:26.294729 12178 net.cpp:84] Creating Layer relu4_1/dw
I0617 01:38:26.294739 12178 net.cpp:406] relu4_1/dw <- conv4_1/dw
I0617 01:38:26.294749 12178 net.cpp:367] relu4_1/dw -> conv4_1/dw (in-place)
I0617 01:38:26.295189 12178 net.cpp:122] Setting up relu4_1/dw
I0617 01:38:26.295210 12178 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0617 01:38:26.295220 12178 net.cpp:137] Memory required for data: 2839962200
I0617 01:38:26.295228 12178 layer_factory.hpp:77] Creating layer conv4_1/sep
I0617 01:38:26.295248 12178 net.cpp:84] Creating Layer conv4_1/sep
I0617 01:38:26.295258 12178 net.cpp:406] conv4_1/sep <- conv4_1/dw
I0617 01:38:26.295274 12178 net.cpp:380] conv4_1/sep -> conv4_1/sep
I0617 01:38:26.297358 12178 net.cpp:122] Setting up conv4_1/sep
I0617 01:38:26.297382 12178 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0617 01:38:26.297391 12178 net.cpp:137] Memory required for data: 2880103000
I0617 01:38:26.297402 12178 layer_factory.hpp:77] Creating layer conv4_1/sep/bn
I0617 01:38:26.297420 12178 net.cpp:84] Creating Layer conv4_1/sep/bn
I0617 01:38:26.297430 12178 net.cpp:406] conv4_1/sep/bn <- conv4_1/sep
I0617 01:38:26.297441 12178 net.cpp:367] conv4_1/sep/bn -> conv4_1/sep (in-place)
I0617 01:38:26.297691 12178 net.cpp:122] Setting up conv4_1/sep/bn
I0617 01:38:26.297710 12178 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0617 01:38:26.297719 12178 net.cpp:137] Memory required for data: 2920243800
I0617 01:38:26.297732 12178 layer_factory.hpp:77] Creating layer conv4_1/sep/scale
I0617 01:38:26.297763 12178 net.cpp:84] Creating Layer conv4_1/sep/scale
I0617 01:38:26.297775 12178 net.cpp:406] conv4_1/sep/scale <- conv4_1/sep
I0617 01:38:26.297785 12178 net.cpp:367] conv4_1/sep/scale -> conv4_1/sep (in-place)
I0617 01:38:26.297847 12178 layer_factory.hpp:77] Creating layer conv4_1/sep/scale
I0617 01:38:26.298003 12178 net.cpp:122] Setting up conv4_1/sep/scale
I0617 01:38:26.298020 12178 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0617 01:38:26.298028 12178 net.cpp:137] Memory required for data: 2960384600
I0617 01:38:26.298063 12178 layer_factory.hpp:77] Creating layer relu4_1/sep
I0617 01:38:26.298076 12178 net.cpp:84] Creating Layer relu4_1/sep
I0617 01:38:26.298085 12178 net.cpp:406] relu4_1/sep <- conv4_1/sep
I0617 01:38:26.298099 12178 net.cpp:367] relu4_1/sep -> conv4_1/sep (in-place)
I0617 01:38:26.298557 12178 net.cpp:122] Setting up relu4_1/sep
I0617 01:38:26.298578 12178 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0617 01:38:26.298588 12178 net.cpp:137] Memory required for data: 3000525400
I0617 01:38:26.298595 12178 layer_factory.hpp:77] Creating layer conv4_2/dw
I0617 01:38:26.298614 12178 net.cpp:84] Creating Layer conv4_2/dw
I0617 01:38:26.298624 12178 net.cpp:406] conv4_2/dw <- conv4_1/sep
I0617 01:38:26.298647 12178 net.cpp:380] conv4_2/dw -> conv4_2/dw
I0617 01:38:26.298815 12178 net.cpp:122] Setting up conv4_2/dw
I0617 01:38:26.298832 12178 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0617 01:38:26.298840 12178 net.cpp:137] Memory required for data: 3010560600
I0617 01:38:26.298851 12178 layer_factory.hpp:77] Creating layer conv4_2/dw/bn
I0617 01:38:26.298871 12178 net.cpp:84] Creating Layer conv4_2/dw/bn
I0617 01:38:26.298882 12178 net.cpp:406] conv4_2/dw/bn <- conv4_2/dw
I0617 01:38:26.298897 12178 net.cpp:367] conv4_2/dw/bn -> conv4_2/dw (in-place)
I0617 01:38:26.299137 12178 net.cpp:122] Setting up conv4_2/dw/bn
I0617 01:38:26.299154 12178 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0617 01:38:26.299162 12178 net.cpp:137] Memory required for data: 3020595800
I0617 01:38:26.299175 12178 layer_factory.hpp:77] Creating layer conv4_2/dw/scale
I0617 01:38:26.299188 12178 net.cpp:84] Creating Layer conv4_2/dw/scale
I0617 01:38:26.299197 12178 net.cpp:406] conv4_2/dw/scale <- conv4_2/dw
I0617 01:38:26.299211 12178 net.cpp:367] conv4_2/dw/scale -> conv4_2/dw (in-place)
I0617 01:38:26.299268 12178 layer_factory.hpp:77] Creating layer conv4_2/dw/scale
I0617 01:38:26.299418 12178 net.cpp:122] Setting up conv4_2/dw/scale
I0617 01:38:26.299435 12178 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0617 01:38:26.299444 12178 net.cpp:137] Memory required for data: 3030631000
I0617 01:38:26.299455 12178 layer_factory.hpp:77] Creating layer relu4_2/dw
I0617 01:38:26.299468 12178 net.cpp:84] Creating Layer relu4_2/dw
I0617 01:38:26.299475 12178 net.cpp:406] relu4_2/dw <- conv4_2/dw
I0617 01:38:26.299485 12178 net.cpp:367] relu4_2/dw -> conv4_2/dw (in-place)
I0617 01:38:26.299932 12178 net.cpp:122] Setting up relu4_2/dw
I0617 01:38:26.299955 12178 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0617 01:38:26.299963 12178 net.cpp:137] Memory required for data: 3040666200
I0617 01:38:26.299973 12178 layer_factory.hpp:77] Creating layer conv4_2/sep
I0617 01:38:26.299990 12178 net.cpp:84] Creating Layer conv4_2/sep
I0617 01:38:26.300000 12178 net.cpp:406] conv4_2/sep <- conv4_2/dw
I0617 01:38:26.300016 12178 net.cpp:380] conv4_2/sep -> conv4_2/sep
I0617 01:38:26.304081 12178 net.cpp:122] Setting up conv4_2/sep
I0617 01:38:26.304107 12178 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:38:26.304117 12178 net.cpp:137] Memory required for data: 3060736600
I0617 01:38:26.304128 12178 layer_factory.hpp:77] Creating layer conv4_2/sep/bn
I0617 01:38:26.304144 12178 net.cpp:84] Creating Layer conv4_2/sep/bn
I0617 01:38:26.304154 12178 net.cpp:406] conv4_2/sep/bn <- conv4_2/sep
I0617 01:38:26.304167 12178 net.cpp:367] conv4_2/sep/bn -> conv4_2/sep (in-place)
I0617 01:38:26.304425 12178 net.cpp:122] Setting up conv4_2/sep/bn
I0617 01:38:26.304455 12178 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:38:26.304463 12178 net.cpp:137] Memory required for data: 3080807000
I0617 01:38:26.304477 12178 layer_factory.hpp:77] Creating layer conv4_2/sep/scale
I0617 01:38:26.304491 12178 net.cpp:84] Creating Layer conv4_2/sep/scale
I0617 01:38:26.304499 12178 net.cpp:406] conv4_2/sep/scale <- conv4_2/sep
I0617 01:38:26.304510 12178 net.cpp:367] conv4_2/sep/scale -> conv4_2/sep (in-place)
I0617 01:38:26.304582 12178 layer_factory.hpp:77] Creating layer conv4_2/sep/scale
I0617 01:38:26.304739 12178 net.cpp:122] Setting up conv4_2/sep/scale
I0617 01:38:26.304757 12178 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:38:26.304765 12178 net.cpp:137] Memory required for data: 3100877400
I0617 01:38:26.304777 12178 layer_factory.hpp:77] Creating layer relu4_2/sep
I0617 01:38:26.304800 12178 net.cpp:84] Creating Layer relu4_2/sep
I0617 01:38:26.304810 12178 net.cpp:406] relu4_2/sep <- conv4_2/sep
I0617 01:38:26.304821 12178 net.cpp:367] relu4_2/sep -> conv4_2/sep (in-place)
I0617 01:38:26.305249 12178 net.cpp:122] Setting up relu4_2/sep
I0617 01:38:26.305275 12178 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:38:26.305285 12178 net.cpp:137] Memory required for data: 3120947800
I0617 01:38:26.305300 12178 layer_factory.hpp:77] Creating layer conv5_1/dw
I0617 01:38:26.305315 12178 net.cpp:84] Creating Layer conv5_1/dw
I0617 01:38:26.305325 12178 net.cpp:406] conv5_1/dw <- conv4_2/sep
I0617 01:38:26.305341 12178 net.cpp:380] conv5_1/dw -> conv5_1/dw
I0617 01:38:26.305560 12178 net.cpp:122] Setting up conv5_1/dw
I0617 01:38:26.305583 12178 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:38:26.305591 12178 net.cpp:137] Memory required for data: 3141018200
I0617 01:38:26.305601 12178 layer_factory.hpp:77] Creating layer conv5_1/dw/bn
I0617 01:38:26.305613 12178 net.cpp:84] Creating Layer conv5_1/dw/bn
I0617 01:38:26.305622 12178 net.cpp:406] conv5_1/dw/bn <- conv5_1/dw
I0617 01:38:26.305636 12178 net.cpp:367] conv5_1/dw/bn -> conv5_1/dw (in-place)
I0617 01:38:26.305886 12178 net.cpp:122] Setting up conv5_1/dw/bn
I0617 01:38:26.305903 12178 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:38:26.305912 12178 net.cpp:137] Memory required for data: 3161088600
I0617 01:38:26.305924 12178 layer_factory.hpp:77] Creating layer conv5_1/dw/scale
I0617 01:38:26.305938 12178 net.cpp:84] Creating Layer conv5_1/dw/scale
I0617 01:38:26.305946 12178 net.cpp:406] conv5_1/dw/scale <- conv5_1/dw
I0617 01:38:26.305956 12178 net.cpp:367] conv5_1/dw/scale -> conv5_1/dw (in-place)
I0617 01:38:26.306015 12178 layer_factory.hpp:77] Creating layer conv5_1/dw/scale
I0617 01:38:26.306171 12178 net.cpp:122] Setting up conv5_1/dw/scale
I0617 01:38:26.306190 12178 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:38:26.306197 12178 net.cpp:137] Memory required for data: 3181159000
I0617 01:38:26.306210 12178 layer_factory.hpp:77] Creating layer relu5_1/dw
I0617 01:38:26.306221 12178 net.cpp:84] Creating Layer relu5_1/dw
I0617 01:38:26.306229 12178 net.cpp:406] relu5_1/dw <- conv5_1/dw
I0617 01:38:26.306242 12178 net.cpp:367] relu5_1/dw -> conv5_1/dw (in-place)
I0617 01:38:26.306484 12178 net.cpp:122] Setting up relu5_1/dw
I0617 01:38:26.306504 12178 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:38:26.306519 12178 net.cpp:137] Memory required for data: 3201229400
I0617 01:38:26.306529 12178 layer_factory.hpp:77] Creating layer conv5_1/sep
I0617 01:38:26.306548 12178 net.cpp:84] Creating Layer conv5_1/sep
I0617 01:38:26.306558 12178 net.cpp:406] conv5_1/sep <- conv5_1/dw
I0617 01:38:26.306571 12178 net.cpp:380] conv5_1/sep -> conv5_1/sep
I0617 01:38:26.312628 12178 net.cpp:122] Setting up conv5_1/sep
I0617 01:38:26.312652 12178 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:38:26.312661 12178 net.cpp:137] Memory required for data: 3221299800
I0617 01:38:26.312672 12178 layer_factory.hpp:77] Creating layer conv5_1/sep/bn
I0617 01:38:26.312690 12178 net.cpp:84] Creating Layer conv5_1/sep/bn
I0617 01:38:26.312700 12178 net.cpp:406] conv5_1/sep/bn <- conv5_1/sep
I0617 01:38:26.312722 12178 net.cpp:367] conv5_1/sep/bn -> conv5_1/sep (in-place)
I0617 01:38:26.312981 12178 net.cpp:122] Setting up conv5_1/sep/bn
I0617 01:38:26.312999 12178 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:38:26.313007 12178 net.cpp:137] Memory required for data: 3241370200
I0617 01:38:26.313021 12178 layer_factory.hpp:77] Creating layer conv5_1/sep/scale
I0617 01:38:26.313035 12178 net.cpp:84] Creating Layer conv5_1/sep/scale
I0617 01:38:26.313043 12178 net.cpp:406] conv5_1/sep/scale <- conv5_1/sep
I0617 01:38:26.313058 12178 net.cpp:367] conv5_1/sep/scale -> conv5_1/sep (in-place)
I0617 01:38:26.313114 12178 layer_factory.hpp:77] Creating layer conv5_1/sep/scale
I0617 01:38:26.313269 12178 net.cpp:122] Setting up conv5_1/sep/scale
I0617 01:38:26.313289 12178 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:38:26.313298 12178 net.cpp:137] Memory required for data: 3261440600
I0617 01:38:26.313310 12178 layer_factory.hpp:77] Creating layer relu5_1/sep
I0617 01:38:26.313321 12178 net.cpp:84] Creating Layer relu5_1/sep
I0617 01:38:26.313330 12178 net.cpp:406] relu5_1/sep <- conv5_1/sep
I0617 01:38:26.313340 12178 net.cpp:367] relu5_1/sep -> conv5_1/sep (in-place)
I0617 01:38:26.313804 12178 net.cpp:122] Setting up relu5_1/sep
I0617 01:38:26.313834 12178 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:38:26.313844 12178 net.cpp:137] Memory required for data: 3281511000
I0617 01:38:26.313853 12178 layer_factory.hpp:77] Creating layer conv5_2/dw
I0617 01:38:26.313870 12178 net.cpp:84] Creating Layer conv5_2/dw
I0617 01:38:26.313880 12178 net.cpp:406] conv5_2/dw <- conv5_1/sep
I0617 01:38:26.313896 12178 net.cpp:380] conv5_2/dw -> conv5_2/dw
I0617 01:38:26.314107 12178 net.cpp:122] Setting up conv5_2/dw
I0617 01:38:26.314126 12178 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:38:26.314134 12178 net.cpp:137] Memory required for data: 3301581400
I0617 01:38:26.314144 12178 layer_factory.hpp:77] Creating layer conv5_2/dw/bn
I0617 01:38:26.314160 12178 net.cpp:84] Creating Layer conv5_2/dw/bn
I0617 01:38:26.314169 12178 net.cpp:406] conv5_2/dw/bn <- conv5_2/dw
I0617 01:38:26.314184 12178 net.cpp:367] conv5_2/dw/bn -> conv5_2/dw (in-place)
I0617 01:38:26.314430 12178 net.cpp:122] Setting up conv5_2/dw/bn
I0617 01:38:26.314447 12178 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:38:26.314455 12178 net.cpp:137] Memory required for data: 3321651800
I0617 01:38:26.314468 12178 layer_factory.hpp:77] Creating layer conv5_2/dw/scale
I0617 01:38:26.314491 12178 net.cpp:84] Creating Layer conv5_2/dw/scale
I0617 01:38:26.314502 12178 net.cpp:406] conv5_2/dw/scale <- conv5_2/dw
I0617 01:38:26.314518 12178 net.cpp:367] conv5_2/dw/scale -> conv5_2/dw (in-place)
I0617 01:38:26.314585 12178 layer_factory.hpp:77] Creating layer conv5_2/dw/scale
I0617 01:38:26.314744 12178 net.cpp:122] Setting up conv5_2/dw/scale
I0617 01:38:26.314762 12178 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:38:26.314770 12178 net.cpp:137] Memory required for data: 3341722200
I0617 01:38:26.314782 12178 layer_factory.hpp:77] Creating layer relu5_2/dw
I0617 01:38:26.314798 12178 net.cpp:84] Creating Layer relu5_2/dw
I0617 01:38:26.314807 12178 net.cpp:406] relu5_2/dw <- conv5_2/dw
I0617 01:38:26.314818 12178 net.cpp:367] relu5_2/dw -> conv5_2/dw (in-place)
I0617 01:38:26.315043 12178 net.cpp:122] Setting up relu5_2/dw
I0617 01:38:26.315062 12178 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:38:26.315071 12178 net.cpp:137] Memory required for data: 3361792600
I0617 01:38:26.315079 12178 layer_factory.hpp:77] Creating layer conv5_2/sep
I0617 01:38:26.315134 12178 net.cpp:84] Creating Layer conv5_2/sep
I0617 01:38:26.315147 12178 net.cpp:406] conv5_2/sep <- conv5_2/dw
I0617 01:38:26.315160 12178 net.cpp:380] conv5_2/sep -> conv5_2/sep
I0617 01:38:26.320951 12178 net.cpp:122] Setting up conv5_2/sep
I0617 01:38:26.320976 12178 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:38:26.320986 12178 net.cpp:137] Memory required for data: 3381863000
I0617 01:38:26.320996 12178 layer_factory.hpp:77] Creating layer conv5_2/sep/bn
I0617 01:38:26.321024 12178 net.cpp:84] Creating Layer conv5_2/sep/bn
I0617 01:38:26.321034 12178 net.cpp:406] conv5_2/sep/bn <- conv5_2/sep
I0617 01:38:26.321046 12178 net.cpp:367] conv5_2/sep/bn -> conv5_2/sep (in-place)
I0617 01:38:26.321303 12178 net.cpp:122] Setting up conv5_2/sep/bn
I0617 01:38:26.321321 12178 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:38:26.321329 12178 net.cpp:137] Memory required for data: 3401933400
I0617 01:38:26.321343 12178 layer_factory.hpp:77] Creating layer conv5_2/sep/scale
I0617 01:38:26.321357 12178 net.cpp:84] Creating Layer conv5_2/sep/scale
I0617 01:38:26.321364 12178 net.cpp:406] conv5_2/sep/scale <- conv5_2/sep
I0617 01:38:26.321379 12178 net.cpp:367] conv5_2/sep/scale -> conv5_2/sep (in-place)
I0617 01:38:26.321435 12178 layer_factory.hpp:77] Creating layer conv5_2/sep/scale
I0617 01:38:26.321604 12178 net.cpp:122] Setting up conv5_2/sep/scale
I0617 01:38:26.321627 12178 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:38:26.321636 12178 net.cpp:137] Memory required for data: 3422003800
I0617 01:38:26.321648 12178 layer_factory.hpp:77] Creating layer relu5_2/sep
I0617 01:38:26.321660 12178 net.cpp:84] Creating Layer relu5_2/sep
I0617 01:38:26.321668 12178 net.cpp:406] relu5_2/sep <- conv5_2/sep
I0617 01:38:26.321686 12178 net.cpp:367] relu5_2/sep -> conv5_2/sep (in-place)
I0617 01:38:26.322149 12178 net.cpp:122] Setting up relu5_2/sep
I0617 01:38:26.322170 12178 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:38:26.322180 12178 net.cpp:137] Memory required for data: 3442074200
I0617 01:38:26.322188 12178 layer_factory.hpp:77] Creating layer conv5_3/dw
I0617 01:38:26.322206 12178 net.cpp:84] Creating Layer conv5_3/dw
I0617 01:38:26.322216 12178 net.cpp:406] conv5_3/dw <- conv5_2/sep
I0617 01:38:26.322232 12178 net.cpp:380] conv5_3/dw -> conv5_3/dw
I0617 01:38:26.322446 12178 net.cpp:122] Setting up conv5_3/dw
I0617 01:38:26.322468 12178 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:38:26.322477 12178 net.cpp:137] Memory required for data: 3462144600
I0617 01:38:26.322489 12178 layer_factory.hpp:77] Creating layer conv5_3/dw/bn
I0617 01:38:26.322505 12178 net.cpp:84] Creating Layer conv5_3/dw/bn
I0617 01:38:26.322525 12178 net.cpp:406] conv5_3/dw/bn <- conv5_3/dw
I0617 01:38:26.322541 12178 net.cpp:367] conv5_3/dw/bn -> conv5_3/dw (in-place)
I0617 01:38:26.322785 12178 net.cpp:122] Setting up conv5_3/dw/bn
I0617 01:38:26.322803 12178 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:38:26.322810 12178 net.cpp:137] Memory required for data: 3482215000
I0617 01:38:26.322824 12178 layer_factory.hpp:77] Creating layer conv5_3/dw/scale
I0617 01:38:26.322836 12178 net.cpp:84] Creating Layer conv5_3/dw/scale
I0617 01:38:26.322845 12178 net.cpp:406] conv5_3/dw/scale <- conv5_3/dw
I0617 01:38:26.322860 12178 net.cpp:367] conv5_3/dw/scale -> conv5_3/dw (in-place)
I0617 01:38:26.322916 12178 layer_factory.hpp:77] Creating layer conv5_3/dw/scale
I0617 01:38:26.323078 12178 net.cpp:122] Setting up conv5_3/dw/scale
I0617 01:38:26.323096 12178 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:38:26.323103 12178 net.cpp:137] Memory required for data: 3502285400
I0617 01:38:26.323115 12178 layer_factory.hpp:77] Creating layer relu5_3/dw
I0617 01:38:26.323127 12178 net.cpp:84] Creating Layer relu5_3/dw
I0617 01:38:26.323135 12178 net.cpp:406] relu5_3/dw <- conv5_3/dw
I0617 01:38:26.323146 12178 net.cpp:367] relu5_3/dw -> conv5_3/dw (in-place)
I0617 01:38:26.323381 12178 net.cpp:122] Setting up relu5_3/dw
I0617 01:38:26.323402 12178 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:38:26.323411 12178 net.cpp:137] Memory required for data: 3522355800
I0617 01:38:26.323420 12178 layer_factory.hpp:77] Creating layer conv5_3/sep
I0617 01:38:26.323437 12178 net.cpp:84] Creating Layer conv5_3/sep
I0617 01:38:26.323447 12178 net.cpp:406] conv5_3/sep <- conv5_3/dw
I0617 01:38:26.323459 12178 net.cpp:380] conv5_3/sep -> conv5_3/sep
I0617 01:38:26.329282 12178 net.cpp:122] Setting up conv5_3/sep
I0617 01:38:26.329320 12178 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:38:26.329330 12178 net.cpp:137] Memory required for data: 3542426200
I0617 01:38:26.329341 12178 layer_factory.hpp:77] Creating layer conv5_3/sep/bn
I0617 01:38:26.329355 12178 net.cpp:84] Creating Layer conv5_3/sep/bn
I0617 01:38:26.329363 12178 net.cpp:406] conv5_3/sep/bn <- conv5_3/sep
I0617 01:38:26.329378 12178 net.cpp:367] conv5_3/sep/bn -> conv5_3/sep (in-place)
I0617 01:38:26.329653 12178 net.cpp:122] Setting up conv5_3/sep/bn
I0617 01:38:26.329674 12178 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:38:26.329681 12178 net.cpp:137] Memory required for data: 3562496600
I0617 01:38:26.329695 12178 layer_factory.hpp:77] Creating layer conv5_3/sep/scale
I0617 01:38:26.329708 12178 net.cpp:84] Creating Layer conv5_3/sep/scale
I0617 01:38:26.329717 12178 net.cpp:406] conv5_3/sep/scale <- conv5_3/sep
I0617 01:38:26.329728 12178 net.cpp:367] conv5_3/sep/scale -> conv5_3/sep (in-place)
I0617 01:38:26.329788 12178 layer_factory.hpp:77] Creating layer conv5_3/sep/scale
I0617 01:38:26.329947 12178 net.cpp:122] Setting up conv5_3/sep/scale
I0617 01:38:26.329967 12178 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:38:26.329977 12178 net.cpp:137] Memory required for data: 3582567000
I0617 01:38:26.329995 12178 layer_factory.hpp:77] Creating layer relu5_3/sep
I0617 01:38:26.330008 12178 net.cpp:84] Creating Layer relu5_3/sep
I0617 01:38:26.330016 12178 net.cpp:406] relu5_3/sep <- conv5_3/sep
I0617 01:38:26.330030 12178 net.cpp:367] relu5_3/sep -> conv5_3/sep (in-place)
I0617 01:38:26.330276 12178 net.cpp:122] Setting up relu5_3/sep
I0617 01:38:26.330294 12178 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:38:26.330303 12178 net.cpp:137] Memory required for data: 3602637400
I0617 01:38:26.330312 12178 layer_factory.hpp:77] Creating layer conv5_4/dw
I0617 01:38:26.330328 12178 net.cpp:84] Creating Layer conv5_4/dw
I0617 01:38:26.330338 12178 net.cpp:406] conv5_4/dw <- conv5_3/sep
I0617 01:38:26.330351 12178 net.cpp:380] conv5_4/dw -> conv5_4/dw
I0617 01:38:26.330575 12178 net.cpp:122] Setting up conv5_4/dw
I0617 01:38:26.330595 12178 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:38:26.330603 12178 net.cpp:137] Memory required for data: 3622707800
I0617 01:38:26.330613 12178 layer_factory.hpp:77] Creating layer conv5_4/dw/bn
I0617 01:38:26.330628 12178 net.cpp:84] Creating Layer conv5_4/dw/bn
I0617 01:38:26.330638 12178 net.cpp:406] conv5_4/dw/bn <- conv5_4/dw
I0617 01:38:26.330648 12178 net.cpp:367] conv5_4/dw/bn -> conv5_4/dw (in-place)
I0617 01:38:26.330894 12178 net.cpp:122] Setting up conv5_4/dw/bn
I0617 01:38:26.330911 12178 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:38:26.330919 12178 net.cpp:137] Memory required for data: 3642778200
I0617 01:38:26.330932 12178 layer_factory.hpp:77] Creating layer conv5_4/dw/scale
I0617 01:38:26.330948 12178 net.cpp:84] Creating Layer conv5_4/dw/scale
I0617 01:38:26.330957 12178 net.cpp:406] conv5_4/dw/scale <- conv5_4/dw
I0617 01:38:26.330968 12178 net.cpp:367] conv5_4/dw/scale -> conv5_4/dw (in-place)
I0617 01:38:26.331027 12178 layer_factory.hpp:77] Creating layer conv5_4/dw/scale
I0617 01:38:26.331189 12178 net.cpp:122] Setting up conv5_4/dw/scale
I0617 01:38:26.331207 12178 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:38:26.331214 12178 net.cpp:137] Memory required for data: 3662848600
I0617 01:38:26.331226 12178 layer_factory.hpp:77] Creating layer relu5_4/dw
I0617 01:38:26.331238 12178 net.cpp:84] Creating Layer relu5_4/dw
I0617 01:38:26.331246 12178 net.cpp:406] relu5_4/dw <- conv5_4/dw
I0617 01:38:26.331260 12178 net.cpp:367] relu5_4/dw -> conv5_4/dw (in-place)
I0617 01:38:26.331708 12178 net.cpp:122] Setting up relu5_4/dw
I0617 01:38:26.331732 12178 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:38:26.331740 12178 net.cpp:137] Memory required for data: 3682919000
I0617 01:38:26.331748 12178 layer_factory.hpp:77] Creating layer conv5_4/sep
I0617 01:38:26.331768 12178 net.cpp:84] Creating Layer conv5_4/sep
I0617 01:38:26.331778 12178 net.cpp:406] conv5_4/sep <- conv5_4/dw
I0617 01:38:26.331804 12178 net.cpp:380] conv5_4/sep -> conv5_4/sep
I0617 01:38:26.337635 12178 net.cpp:122] Setting up conv5_4/sep
I0617 01:38:26.337659 12178 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:38:26.337669 12178 net.cpp:137] Memory required for data: 3702989400
I0617 01:38:26.337679 12178 layer_factory.hpp:77] Creating layer conv5_4/sep/bn
I0617 01:38:26.337695 12178 net.cpp:84] Creating Layer conv5_4/sep/bn
I0617 01:38:26.337705 12178 net.cpp:406] conv5_4/sep/bn <- conv5_4/sep
I0617 01:38:26.337718 12178 net.cpp:367] conv5_4/sep/bn -> conv5_4/sep (in-place)
I0617 01:38:26.337976 12178 net.cpp:122] Setting up conv5_4/sep/bn
I0617 01:38:26.337994 12178 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:38:26.338002 12178 net.cpp:137] Memory required for data: 3723059800
I0617 01:38:26.338016 12178 layer_factory.hpp:77] Creating layer conv5_4/sep/scale
I0617 01:38:26.338034 12178 net.cpp:84] Creating Layer conv5_4/sep/scale
I0617 01:38:26.338044 12178 net.cpp:406] conv5_4/sep/scale <- conv5_4/sep
I0617 01:38:26.338055 12178 net.cpp:367] conv5_4/sep/scale -> conv5_4/sep (in-place)
I0617 01:38:26.338115 12178 layer_factory.hpp:77] Creating layer conv5_4/sep/scale
I0617 01:38:26.338282 12178 net.cpp:122] Setting up conv5_4/sep/scale
I0617 01:38:26.338306 12178 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:38:26.338315 12178 net.cpp:137] Memory required for data: 3743130200
I0617 01:38:26.338327 12178 layer_factory.hpp:77] Creating layer relu5_4/sep
I0617 01:38:26.338342 12178 net.cpp:84] Creating Layer relu5_4/sep
I0617 01:38:26.338351 12178 net.cpp:406] relu5_4/sep <- conv5_4/sep
I0617 01:38:26.338362 12178 net.cpp:367] relu5_4/sep -> conv5_4/sep (in-place)
I0617 01:38:26.338601 12178 net.cpp:122] Setting up relu5_4/sep
I0617 01:38:26.338621 12178 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:38:26.338630 12178 net.cpp:137] Memory required for data: 3763200600
I0617 01:38:26.338639 12178 layer_factory.hpp:77] Creating layer conv5_5/dw
I0617 01:38:26.338656 12178 net.cpp:84] Creating Layer conv5_5/dw
I0617 01:38:26.338667 12178 net.cpp:406] conv5_5/dw <- conv5_4/sep
I0617 01:38:26.338682 12178 net.cpp:380] conv5_5/dw -> conv5_5/dw
I0617 01:38:26.338897 12178 net.cpp:122] Setting up conv5_5/dw
I0617 01:38:26.338915 12178 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:38:26.338923 12178 net.cpp:137] Memory required for data: 3783271000
I0617 01:38:26.338933 12178 layer_factory.hpp:77] Creating layer conv5_5/dw/bn
I0617 01:38:26.338948 12178 net.cpp:84] Creating Layer conv5_5/dw/bn
I0617 01:38:26.338958 12178 net.cpp:406] conv5_5/dw/bn <- conv5_5/dw
I0617 01:38:26.338971 12178 net.cpp:367] conv5_5/dw/bn -> conv5_5/dw (in-place)
I0617 01:38:26.339221 12178 net.cpp:122] Setting up conv5_5/dw/bn
I0617 01:38:26.339237 12178 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:38:26.339246 12178 net.cpp:137] Memory required for data: 3803341400
I0617 01:38:26.339282 12178 layer_factory.hpp:77] Creating layer conv5_5/dw/scale
I0617 01:38:26.339303 12178 net.cpp:84] Creating Layer conv5_5/dw/scale
I0617 01:38:26.339313 12178 net.cpp:406] conv5_5/dw/scale <- conv5_5/dw
I0617 01:38:26.339324 12178 net.cpp:367] conv5_5/dw/scale -> conv5_5/dw (in-place)
I0617 01:38:26.339390 12178 layer_factory.hpp:77] Creating layer conv5_5/dw/scale
I0617 01:38:26.339560 12178 net.cpp:122] Setting up conv5_5/dw/scale
I0617 01:38:26.339578 12178 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:38:26.339586 12178 net.cpp:137] Memory required for data: 3823411800
I0617 01:38:26.339598 12178 layer_factory.hpp:77] Creating layer relu5_5/dw
I0617 01:38:26.339610 12178 net.cpp:84] Creating Layer relu5_5/dw
I0617 01:38:26.339618 12178 net.cpp:406] relu5_5/dw <- conv5_5/dw
I0617 01:38:26.339628 12178 net.cpp:367] relu5_5/dw -> conv5_5/dw (in-place)
I0617 01:38:26.340083 12178 net.cpp:122] Setting up relu5_5/dw
I0617 01:38:26.340104 12178 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:38:26.340113 12178 net.cpp:137] Memory required for data: 3843482200
I0617 01:38:26.340132 12178 layer_factory.hpp:77] Creating layer conv5_5/sep
I0617 01:38:26.340152 12178 net.cpp:84] Creating Layer conv5_5/sep
I0617 01:38:26.340162 12178 net.cpp:406] conv5_5/sep <- conv5_5/dw
I0617 01:38:26.340180 12178 net.cpp:380] conv5_5/sep -> conv5_5/sep
I0617 01:38:26.346026 12178 net.cpp:122] Setting up conv5_5/sep
I0617 01:38:26.346051 12178 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:38:26.346061 12178 net.cpp:137] Memory required for data: 3863552600
I0617 01:38:26.346071 12178 layer_factory.hpp:77] Creating layer conv5_5/sep/bn
I0617 01:38:26.346084 12178 net.cpp:84] Creating Layer conv5_5/sep/bn
I0617 01:38:26.346093 12178 net.cpp:406] conv5_5/sep/bn <- conv5_5/sep
I0617 01:38:26.346117 12178 net.cpp:367] conv5_5/sep/bn -> conv5_5/sep (in-place)
I0617 01:38:26.346385 12178 net.cpp:122] Setting up conv5_5/sep/bn
I0617 01:38:26.346402 12178 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:38:26.346410 12178 net.cpp:137] Memory required for data: 3883623000
I0617 01:38:26.346423 12178 layer_factory.hpp:77] Creating layer conv5_5/sep/scale
I0617 01:38:26.346436 12178 net.cpp:84] Creating Layer conv5_5/sep/scale
I0617 01:38:26.346446 12178 net.cpp:406] conv5_5/sep/scale <- conv5_5/sep
I0617 01:38:26.346457 12178 net.cpp:367] conv5_5/sep/scale -> conv5_5/sep (in-place)
I0617 01:38:26.346534 12178 layer_factory.hpp:77] Creating layer conv5_5/sep/scale
I0617 01:38:26.346701 12178 net.cpp:122] Setting up conv5_5/sep/scale
I0617 01:38:26.346719 12178 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:38:26.346726 12178 net.cpp:137] Memory required for data: 3903693400
I0617 01:38:26.346738 12178 layer_factory.hpp:77] Creating layer relu5_5/sep
I0617 01:38:26.346750 12178 net.cpp:84] Creating Layer relu5_5/sep
I0617 01:38:26.346762 12178 net.cpp:406] relu5_5/sep <- conv5_5/sep
I0617 01:38:26.346773 12178 net.cpp:367] relu5_5/sep -> conv5_5/sep (in-place)
I0617 01:38:26.347038 12178 net.cpp:122] Setting up relu5_5/sep
I0617 01:38:26.347056 12178 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 01:38:26.347064 12178 net.cpp:137] Memory required for data: 3923763800
I0617 01:38:26.347072 12178 layer_factory.hpp:77] Creating layer conv5_6/dw
I0617 01:38:26.347090 12178 net.cpp:84] Creating Layer conv5_6/dw
I0617 01:38:26.347100 12178 net.cpp:406] conv5_6/dw <- conv5_5/sep
I0617 01:38:26.347112 12178 net.cpp:380] conv5_6/dw -> conv5_6/dw
I0617 01:38:26.347323 12178 net.cpp:122] Setting up conv5_6/dw
I0617 01:38:26.347342 12178 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0617 01:38:26.347349 12178 net.cpp:137] Memory required for data: 3928781400
I0617 01:38:26.347360 12178 layer_factory.hpp:77] Creating layer conv5_6/dw/bn
I0617 01:38:26.347375 12178 net.cpp:84] Creating Layer conv5_6/dw/bn
I0617 01:38:26.347385 12178 net.cpp:406] conv5_6/dw/bn <- conv5_6/dw
I0617 01:38:26.347396 12178 net.cpp:367] conv5_6/dw/bn -> conv5_6/dw (in-place)
I0617 01:38:26.347676 12178 net.cpp:122] Setting up conv5_6/dw/bn
I0617 01:38:26.347695 12178 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0617 01:38:26.347703 12178 net.cpp:137] Memory required for data: 3933799000
I0617 01:38:26.347717 12178 layer_factory.hpp:77] Creating layer conv5_6/dw/scale
I0617 01:38:26.347733 12178 net.cpp:84] Creating Layer conv5_6/dw/scale
I0617 01:38:26.347743 12178 net.cpp:406] conv5_6/dw/scale <- conv5_6/dw
I0617 01:38:26.347754 12178 net.cpp:367] conv5_6/dw/scale -> conv5_6/dw (in-place)
I0617 01:38:26.347815 12178 layer_factory.hpp:77] Creating layer conv5_6/dw/scale
I0617 01:38:26.347980 12178 net.cpp:122] Setting up conv5_6/dw/scale
I0617 01:38:26.347998 12178 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0617 01:38:26.348006 12178 net.cpp:137] Memory required for data: 3938816600
I0617 01:38:26.348018 12178 layer_factory.hpp:77] Creating layer relu5_6/dw
I0617 01:38:26.348033 12178 net.cpp:84] Creating Layer relu5_6/dw
I0617 01:38:26.348042 12178 net.cpp:406] relu5_6/dw <- conv5_6/dw
I0617 01:38:26.348053 12178 net.cpp:367] relu5_6/dw -> conv5_6/dw (in-place)
I0617 01:38:26.348508 12178 net.cpp:122] Setting up relu5_6/dw
I0617 01:38:26.348551 12178 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0617 01:38:26.348562 12178 net.cpp:137] Memory required for data: 3943834200
I0617 01:38:26.348569 12178 layer_factory.hpp:77] Creating layer conv5_6/sep
I0617 01:38:26.348589 12178 net.cpp:84] Creating Layer conv5_6/sep
I0617 01:38:26.348599 12178 net.cpp:406] conv5_6/sep <- conv5_6/dw
I0617 01:38:26.348618 12178 net.cpp:380] conv5_6/sep -> conv5_6/sep
I0617 01:38:26.359211 12178 net.cpp:122] Setting up conv5_6/sep
I0617 01:38:26.359236 12178 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0617 01:38:26.359246 12178 net.cpp:137] Memory required for data: 3953869400
I0617 01:38:26.359257 12178 layer_factory.hpp:77] Creating layer conv5_6/sep/bn
I0617 01:38:26.359273 12178 net.cpp:84] Creating Layer conv5_6/sep/bn
I0617 01:38:26.359283 12178 net.cpp:406] conv5_6/sep/bn <- conv5_6/sep
I0617 01:38:26.359295 12178 net.cpp:367] conv5_6/sep/bn -> conv5_6/sep (in-place)
I0617 01:38:26.359577 12178 net.cpp:122] Setting up conv5_6/sep/bn
I0617 01:38:26.359597 12178 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0617 01:38:26.359606 12178 net.cpp:137] Memory required for data: 3963904600
I0617 01:38:26.359618 12178 layer_factory.hpp:77] Creating layer conv5_6/sep/scale
I0617 01:38:26.359632 12178 net.cpp:84] Creating Layer conv5_6/sep/scale
I0617 01:38:26.359647 12178 net.cpp:406] conv5_6/sep/scale <- conv5_6/sep
I0617 01:38:26.359663 12178 net.cpp:367] conv5_6/sep/scale -> conv5_6/sep (in-place)
I0617 01:38:26.359722 12178 layer_factory.hpp:77] Creating layer conv5_6/sep/scale
I0617 01:38:26.359889 12178 net.cpp:122] Setting up conv5_6/sep/scale
I0617 01:38:26.359910 12178 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0617 01:38:26.359920 12178 net.cpp:137] Memory required for data: 3973939800
I0617 01:38:26.359931 12178 layer_factory.hpp:77] Creating layer relu5_6/sep
I0617 01:38:26.359942 12178 net.cpp:84] Creating Layer relu5_6/sep
I0617 01:38:26.359951 12178 net.cpp:406] relu5_6/sep <- conv5_6/sep
I0617 01:38:26.359961 12178 net.cpp:367] relu5_6/sep -> conv5_6/sep (in-place)
I0617 01:38:26.360209 12178 net.cpp:122] Setting up relu5_6/sep
I0617 01:38:26.360239 12178 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0617 01:38:26.360249 12178 net.cpp:137] Memory required for data: 3983975000
I0617 01:38:26.360257 12178 layer_factory.hpp:77] Creating layer conv6/dw
I0617 01:38:26.360271 12178 net.cpp:84] Creating Layer conv6/dw
I0617 01:38:26.360280 12178 net.cpp:406] conv6/dw <- conv5_6/sep
I0617 01:38:26.360296 12178 net.cpp:380] conv6/dw -> conv6/dw
I0617 01:38:26.360584 12178 net.cpp:122] Setting up conv6/dw
I0617 01:38:26.360606 12178 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0617 01:38:26.360615 12178 net.cpp:137] Memory required for data: 3994010200
I0617 01:38:26.360625 12178 layer_factory.hpp:77] Creating layer conv6/dw/bn
I0617 01:38:26.360636 12178 net.cpp:84] Creating Layer conv6/dw/bn
I0617 01:38:26.360646 12178 net.cpp:406] conv6/dw/bn <- conv6/dw
I0617 01:38:26.360659 12178 net.cpp:367] conv6/dw/bn -> conv6/dw (in-place)
I0617 01:38:26.360924 12178 net.cpp:122] Setting up conv6/dw/bn
I0617 01:38:26.360941 12178 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0617 01:38:26.360949 12178 net.cpp:137] Memory required for data: 4004045400
I0617 01:38:26.360963 12178 layer_factory.hpp:77] Creating layer conv6/dw/scale
I0617 01:38:26.360975 12178 net.cpp:84] Creating Layer conv6/dw/scale
I0617 01:38:26.360985 12178 net.cpp:406] conv6/dw/scale <- conv6/dw
I0617 01:38:26.360996 12178 net.cpp:367] conv6/dw/scale -> conv6/dw (in-place)
I0617 01:38:26.361057 12178 layer_factory.hpp:77] Creating layer conv6/dw/scale
I0617 01:38:26.361232 12178 net.cpp:122] Setting up conv6/dw/scale
I0617 01:38:26.361249 12178 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0617 01:38:26.361258 12178 net.cpp:137] Memory required for data: 4014080600
I0617 01:38:26.361268 12178 layer_factory.hpp:77] Creating layer relu6/dw
I0617 01:38:26.361280 12178 net.cpp:84] Creating Layer relu6/dw
I0617 01:38:26.361289 12178 net.cpp:406] relu6/dw <- conv6/dw
I0617 01:38:26.361304 12178 net.cpp:367] relu6/dw -> conv6/dw (in-place)
I0617 01:38:26.361785 12178 net.cpp:122] Setting up relu6/dw
I0617 01:38:26.361807 12178 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0617 01:38:26.361816 12178 net.cpp:137] Memory required for data: 4024115800
I0617 01:38:26.361824 12178 layer_factory.hpp:77] Creating layer conv6/sep
I0617 01:38:26.361843 12178 net.cpp:84] Creating Layer conv6/sep
I0617 01:38:26.361853 12178 net.cpp:406] conv6/sep <- conv6/dw
I0617 01:38:26.361866 12178 net.cpp:380] conv6/sep -> conv6/sep
I0617 01:38:26.380508 12178 net.cpp:122] Setting up conv6/sep
I0617 01:38:26.380542 12178 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0617 01:38:26.380553 12178 net.cpp:137] Memory required for data: 4034151000
I0617 01:38:26.380563 12178 layer_factory.hpp:77] Creating layer conv6/sep/bn
I0617 01:38:26.380579 12178 net.cpp:84] Creating Layer conv6/sep/bn
I0617 01:38:26.380589 12178 net.cpp:406] conv6/sep/bn <- conv6/sep
I0617 01:38:26.380604 12178 net.cpp:367] conv6/sep/bn -> conv6/sep (in-place)
I0617 01:38:26.380882 12178 net.cpp:122] Setting up conv6/sep/bn
I0617 01:38:26.380899 12178 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0617 01:38:26.380908 12178 net.cpp:137] Memory required for data: 4044186200
I0617 01:38:26.380921 12178 layer_factory.hpp:77] Creating layer conv6/sep/scale
I0617 01:38:26.380947 12178 net.cpp:84] Creating Layer conv6/sep/scale
I0617 01:38:26.380959 12178 net.cpp:406] conv6/sep/scale <- conv6/sep
I0617 01:38:26.380970 12178 net.cpp:367] conv6/sep/scale -> conv6/sep (in-place)
I0617 01:38:26.381031 12178 layer_factory.hpp:77] Creating layer conv6/sep/scale
I0617 01:38:26.381204 12178 net.cpp:122] Setting up conv6/sep/scale
I0617 01:38:26.381222 12178 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0617 01:38:26.381232 12178 net.cpp:137] Memory required for data: 4054221400
I0617 01:38:26.381242 12178 layer_factory.hpp:77] Creating layer relu6/sep
I0617 01:38:26.381254 12178 net.cpp:84] Creating Layer relu6/sep
I0617 01:38:26.381263 12178 net.cpp:406] relu6/sep <- conv6/sep
I0617 01:38:26.381273 12178 net.cpp:367] relu6/sep -> conv6/sep (in-place)
I0617 01:38:26.381734 12178 net.cpp:122] Setting up relu6/sep
I0617 01:38:26.381757 12178 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0617 01:38:26.381767 12178 net.cpp:137] Memory required for data: 4064256600
I0617 01:38:26.381774 12178 layer_factory.hpp:77] Creating layer pool6
I0617 01:38:26.381791 12178 net.cpp:84] Creating Layer pool6
I0617 01:38:26.381800 12178 net.cpp:406] pool6 <- conv6/sep
I0617 01:38:26.381817 12178 net.cpp:380] pool6 -> pool6
I0617 01:38:26.382133 12178 net.cpp:122] Setting up pool6
I0617 01:38:26.382153 12178 net.cpp:129] Top shape: 50 1024 1 1 (51200)
I0617 01:38:26.382163 12178 net.cpp:137] Memory required for data: 4064461400
I0617 01:38:26.382170 12178 layer_factory.hpp:77] Creating layer fc7_oxford
I0617 01:38:26.382189 12178 net.cpp:84] Creating Layer fc7_oxford
I0617 01:38:26.382200 12178 net.cpp:406] fc7_oxford <- pool6
I0617 01:38:26.382216 12178 net.cpp:380] fc7_oxford -> fc7
I0617 01:38:26.385244 12178 net.cpp:122] Setting up fc7_oxford
I0617 01:38:26.385270 12178 net.cpp:129] Top shape: 50 102 1 1 (5100)
I0617 01:38:26.385282 12178 net.cpp:137] Memory required for data: 4064481800
I0617 01:38:26.385293 12178 layer_factory.hpp:77] Creating layer fc7_fc7_oxford_0_split
I0617 01:38:26.385309 12178 net.cpp:84] Creating Layer fc7_fc7_oxford_0_split
I0617 01:38:26.385318 12178 net.cpp:406] fc7_fc7_oxford_0_split <- fc7
I0617 01:38:26.385330 12178 net.cpp:380] fc7_fc7_oxford_0_split -> fc7_fc7_oxford_0_split_0
I0617 01:38:26.385344 12178 net.cpp:380] fc7_fc7_oxford_0_split -> fc7_fc7_oxford_0_split_1
I0617 01:38:26.385407 12178 net.cpp:122] Setting up fc7_fc7_oxford_0_split
I0617 01:38:26.385423 12178 net.cpp:129] Top shape: 50 102 1 1 (5100)
I0617 01:38:26.385433 12178 net.cpp:129] Top shape: 50 102 1 1 (5100)
I0617 01:38:26.385442 12178 net.cpp:137] Memory required for data: 4064522600
I0617 01:38:26.385449 12178 layer_factory.hpp:77] Creating layer accuracy
I0617 01:38:26.385462 12178 net.cpp:84] Creating Layer accuracy
I0617 01:38:26.385483 12178 net.cpp:406] accuracy <- fc7_fc7_oxford_0_split_0
I0617 01:38:26.385494 12178 net.cpp:406] accuracy <- label_data_1_split_0
I0617 01:38:26.385505 12178 net.cpp:380] accuracy -> accuracy
I0617 01:38:26.385531 12178 net.cpp:122] Setting up accuracy
I0617 01:38:26.385545 12178 net.cpp:129] Top shape: (1)
I0617 01:38:26.385553 12178 net.cpp:137] Memory required for data: 4064522604
I0617 01:38:26.385561 12178 layer_factory.hpp:77] Creating layer loss
I0617 01:38:26.385578 12178 net.cpp:84] Creating Layer loss
I0617 01:38:26.385587 12178 net.cpp:406] loss <- fc7_fc7_oxford_0_split_1
I0617 01:38:26.385597 12178 net.cpp:406] loss <- label_data_1_split_1
I0617 01:38:26.385607 12178 net.cpp:380] loss -> loss
I0617 01:38:26.385630 12178 layer_factory.hpp:77] Creating layer loss
I0617 01:38:26.386251 12178 net.cpp:122] Setting up loss
I0617 01:38:26.386272 12178 net.cpp:129] Top shape: (1)
I0617 01:38:26.386281 12178 net.cpp:132]     with loss weight 1
I0617 01:38:26.386340 12178 net.cpp:137] Memory required for data: 4064522608
I0617 01:38:26.386349 12178 net.cpp:198] loss needs backward computation.
I0617 01:38:26.386359 12178 net.cpp:200] accuracy does not need backward computation.
I0617 01:38:26.386368 12178 net.cpp:198] fc7_fc7_oxford_0_split needs backward computation.
I0617 01:38:26.386384 12178 net.cpp:198] fc7_oxford needs backward computation.
I0617 01:38:26.386394 12178 net.cpp:198] pool6 needs backward computation.
I0617 01:38:26.386401 12178 net.cpp:198] relu6/sep needs backward computation.
I0617 01:38:26.386409 12178 net.cpp:198] conv6/sep/scale needs backward computation.
I0617 01:38:26.386417 12178 net.cpp:198] conv6/sep/bn needs backward computation.
I0617 01:38:26.386425 12178 net.cpp:198] conv6/sep needs backward computation.
I0617 01:38:26.386432 12178 net.cpp:198] relu6/dw needs backward computation.
I0617 01:38:26.386440 12178 net.cpp:198] conv6/dw/scale needs backward computation.
I0617 01:38:26.386448 12178 net.cpp:198] conv6/dw/bn needs backward computation.
I0617 01:38:26.386456 12178 net.cpp:198] conv6/dw needs backward computation.
I0617 01:38:26.386464 12178 net.cpp:198] relu5_6/sep needs backward computation.
I0617 01:38:26.386472 12178 net.cpp:198] conv5_6/sep/scale needs backward computation.
I0617 01:38:26.386481 12178 net.cpp:198] conv5_6/sep/bn needs backward computation.
I0617 01:38:26.386487 12178 net.cpp:198] conv5_6/sep needs backward computation.
I0617 01:38:26.386495 12178 net.cpp:198] relu5_6/dw needs backward computation.
I0617 01:38:26.386503 12178 net.cpp:198] conv5_6/dw/scale needs backward computation.
I0617 01:38:26.386512 12178 net.cpp:198] conv5_6/dw/bn needs backward computation.
I0617 01:38:26.386528 12178 net.cpp:198] conv5_6/dw needs backward computation.
I0617 01:38:26.386538 12178 net.cpp:198] relu5_5/sep needs backward computation.
I0617 01:38:26.386545 12178 net.cpp:198] conv5_5/sep/scale needs backward computation.
I0617 01:38:26.386554 12178 net.cpp:198] conv5_5/sep/bn needs backward computation.
I0617 01:38:26.386560 12178 net.cpp:198] conv5_5/sep needs backward computation.
I0617 01:38:26.386569 12178 net.cpp:198] relu5_5/dw needs backward computation.
I0617 01:38:26.386576 12178 net.cpp:198] conv5_5/dw/scale needs backward computation.
I0617 01:38:26.386584 12178 net.cpp:198] conv5_5/dw/bn needs backward computation.
I0617 01:38:26.386591 12178 net.cpp:198] conv5_5/dw needs backward computation.
I0617 01:38:26.386600 12178 net.cpp:198] relu5_4/sep needs backward computation.
I0617 01:38:26.386607 12178 net.cpp:198] conv5_4/sep/scale needs backward computation.
I0617 01:38:26.386615 12178 net.cpp:198] conv5_4/sep/bn needs backward computation.
I0617 01:38:26.386622 12178 net.cpp:198] conv5_4/sep needs backward computation.
I0617 01:38:26.386629 12178 net.cpp:198] relu5_4/dw needs backward computation.
I0617 01:38:26.386637 12178 net.cpp:198] conv5_4/dw/scale needs backward computation.
I0617 01:38:26.386646 12178 net.cpp:198] conv5_4/dw/bn needs backward computation.
I0617 01:38:26.386653 12178 net.cpp:198] conv5_4/dw needs backward computation.
I0617 01:38:26.386672 12178 net.cpp:198] relu5_3/sep needs backward computation.
I0617 01:38:26.386680 12178 net.cpp:198] conv5_3/sep/scale needs backward computation.
I0617 01:38:26.386688 12178 net.cpp:198] conv5_3/sep/bn needs backward computation.
I0617 01:38:26.386695 12178 net.cpp:198] conv5_3/sep needs backward computation.
I0617 01:38:26.386703 12178 net.cpp:198] relu5_3/dw needs backward computation.
I0617 01:38:26.386711 12178 net.cpp:198] conv5_3/dw/scale needs backward computation.
I0617 01:38:26.386719 12178 net.cpp:198] conv5_3/dw/bn needs backward computation.
I0617 01:38:26.386728 12178 net.cpp:198] conv5_3/dw needs backward computation.
I0617 01:38:26.386735 12178 net.cpp:198] relu5_2/sep needs backward computation.
I0617 01:38:26.386755 12178 net.cpp:198] conv5_2/sep/scale needs backward computation.
I0617 01:38:26.386764 12178 net.cpp:198] conv5_2/sep/bn needs backward computation.
I0617 01:38:26.386770 12178 net.cpp:198] conv5_2/sep needs backward computation.
I0617 01:38:26.386778 12178 net.cpp:198] relu5_2/dw needs backward computation.
I0617 01:38:26.386786 12178 net.cpp:198] conv5_2/dw/scale needs backward computation.
I0617 01:38:26.386795 12178 net.cpp:198] conv5_2/dw/bn needs backward computation.
I0617 01:38:26.386808 12178 net.cpp:198] conv5_2/dw needs backward computation.
I0617 01:38:26.386816 12178 net.cpp:198] relu5_1/sep needs backward computation.
I0617 01:38:26.386824 12178 net.cpp:198] conv5_1/sep/scale needs backward computation.
I0617 01:38:26.386832 12178 net.cpp:198] conv5_1/sep/bn needs backward computation.
I0617 01:38:26.386840 12178 net.cpp:198] conv5_1/sep needs backward computation.
I0617 01:38:26.386848 12178 net.cpp:198] relu5_1/dw needs backward computation.
I0617 01:38:26.386857 12178 net.cpp:198] conv5_1/dw/scale needs backward computation.
I0617 01:38:26.386864 12178 net.cpp:198] conv5_1/dw/bn needs backward computation.
I0617 01:38:26.386871 12178 net.cpp:198] conv5_1/dw needs backward computation.
I0617 01:38:26.386879 12178 net.cpp:198] relu4_2/sep needs backward computation.
I0617 01:38:26.386888 12178 net.cpp:198] conv4_2/sep/scale needs backward computation.
I0617 01:38:26.386895 12178 net.cpp:198] conv4_2/sep/bn needs backward computation.
I0617 01:38:26.386904 12178 net.cpp:198] conv4_2/sep needs backward computation.
I0617 01:38:26.386910 12178 net.cpp:198] relu4_2/dw needs backward computation.
I0617 01:38:26.386919 12178 net.cpp:198] conv4_2/dw/scale needs backward computation.
I0617 01:38:26.386926 12178 net.cpp:198] conv4_2/dw/bn needs backward computation.
I0617 01:38:26.386934 12178 net.cpp:198] conv4_2/dw needs backward computation.
I0617 01:38:26.386941 12178 net.cpp:198] relu4_1/sep needs backward computation.
I0617 01:38:26.386950 12178 net.cpp:198] conv4_1/sep/scale needs backward computation.
I0617 01:38:26.386957 12178 net.cpp:198] conv4_1/sep/bn needs backward computation.
I0617 01:38:26.386965 12178 net.cpp:198] conv4_1/sep needs backward computation.
I0617 01:38:26.386972 12178 net.cpp:198] relu4_1/dw needs backward computation.
I0617 01:38:26.386981 12178 net.cpp:198] conv4_1/dw/scale needs backward computation.
I0617 01:38:26.386988 12178 net.cpp:198] conv4_1/dw/bn needs backward computation.
I0617 01:38:26.386996 12178 net.cpp:198] conv4_1/dw needs backward computation.
I0617 01:38:26.387003 12178 net.cpp:198] relu3_2/sep needs backward computation.
I0617 01:38:26.387012 12178 net.cpp:198] conv3_2/sep/scale needs backward computation.
I0617 01:38:26.387018 12178 net.cpp:198] conv3_2/sep/bn needs backward computation.
I0617 01:38:26.387027 12178 net.cpp:198] conv3_2/sep needs backward computation.
I0617 01:38:26.387034 12178 net.cpp:198] relu3_2/dw needs backward computation.
I0617 01:38:26.387042 12178 net.cpp:198] conv3_2/dw/scale needs backward computation.
I0617 01:38:26.387049 12178 net.cpp:198] conv3_2/dw/bn needs backward computation.
I0617 01:38:26.387058 12178 net.cpp:198] conv3_2/dw needs backward computation.
I0617 01:38:26.387065 12178 net.cpp:198] relu3_1/sep needs backward computation.
I0617 01:38:26.387082 12178 net.cpp:198] conv3_1/sep/scale needs backward computation.
I0617 01:38:26.387090 12178 net.cpp:198] conv3_1/sep/bn needs backward computation.
I0617 01:38:26.387099 12178 net.cpp:198] conv3_1/sep needs backward computation.
I0617 01:38:26.387106 12178 net.cpp:198] relu3_1/dw needs backward computation.
I0617 01:38:26.387115 12178 net.cpp:198] conv3_1/dw/scale needs backward computation.
I0617 01:38:26.387121 12178 net.cpp:198] conv3_1/dw/bn needs backward computation.
I0617 01:38:26.387130 12178 net.cpp:198] conv3_1/dw needs backward computation.
I0617 01:38:26.387137 12178 net.cpp:198] relu2_2/sep needs backward computation.
I0617 01:38:26.387145 12178 net.cpp:198] conv2_2/sep/scale needs backward computation.
I0617 01:38:26.387153 12178 net.cpp:198] conv2_2/sep/bn needs backward computation.
I0617 01:38:26.387161 12178 net.cpp:198] conv2_2/sep needs backward computation.
I0617 01:38:26.387168 12178 net.cpp:198] relu2_2/dw needs backward computation.
I0617 01:38:26.387176 12178 net.cpp:198] conv2_2/dw/scale needs backward computation.
I0617 01:38:26.387184 12178 net.cpp:198] conv2_2/dw/bn needs backward computation.
I0617 01:38:26.387192 12178 net.cpp:198] conv2_2/dw needs backward computation.
I0617 01:38:26.387199 12178 net.cpp:198] relu2_1/sep needs backward computation.
I0617 01:38:26.387213 12178 net.cpp:198] conv2_1/sep/scale needs backward computation.
I0617 01:38:26.387221 12178 net.cpp:198] conv2_1/sep/bn needs backward computation.
I0617 01:38:26.387229 12178 net.cpp:198] conv2_1/sep needs backward computation.
I0617 01:38:26.387238 12178 net.cpp:198] relu2_1/dw needs backward computation.
I0617 01:38:26.387244 12178 net.cpp:198] conv2_1/dw/scale needs backward computation.
I0617 01:38:26.387253 12178 net.cpp:198] conv2_1/dw/bn needs backward computation.
I0617 01:38:26.387260 12178 net.cpp:198] conv2_1/dw needs backward computation.
I0617 01:38:26.387269 12178 net.cpp:198] relu1 needs backward computation.
I0617 01:38:26.387275 12178 net.cpp:198] conv1/scale needs backward computation.
I0617 01:38:26.387284 12178 net.cpp:198] conv1/bn needs backward computation.
I0617 01:38:26.387291 12178 net.cpp:198] conv1 needs backward computation.
I0617 01:38:26.387300 12178 net.cpp:200] label_data_1_split does not need backward computation.
I0617 01:38:26.387308 12178 net.cpp:200] data does not need backward computation.
I0617 01:38:26.387316 12178 net.cpp:242] This network produces output accuracy
I0617 01:38:26.387325 12178 net.cpp:242] This network produces output loss
I0617 01:38:26.387403 12178 net.cpp:255] Network initialization done.
I0617 01:38:26.387753 12178 solver.cpp:56] Solver scaffolding done.
I0617 01:38:26.398265 12178 caffe.cpp:155] Finetuning from mobilenet/mobilenet.caffemodel
I0617 01:38:26.421696 12178 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: mobilenet/mobilenet.caffemodel
I0617 01:38:26.421772 12178 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0617 01:38:26.425151 12178 net.cpp:744] Ignoring source layer fc7
I0617 01:38:26.425199 12178 net.cpp:744] Ignoring source layer fc7_fc7_0_split
I0617 01:38:26.425209 12178 net.cpp:744] Ignoring source layer top1/acc
I0617 01:38:26.425216 12178 net.cpp:744] Ignoring source layer top5/acc
I0617 01:38:26.426829 12178 caffe.cpp:248] Starting Optimization
I0617 01:38:26.426856 12178 solver.cpp:272] Solving MOBILENET
I0617 01:38:26.426867 12178 solver.cpp:273] Learning Rate Policy: step
I0617 01:38:26.434927 12178 blocking_queue.cpp:49] Waiting for data
I0617 01:38:27.679226 12178 solver.cpp:218] Iteration 0 (-1.43241e+25 iter/s, 1.25215s/50 iters), loss = 5.38281
I0617 01:38:27.679343 12178 solver.cpp:237]     Train net output #0: accuracy = 0
I0617 01:38:27.679370 12178 solver.cpp:237]     Train net output #1: loss = 5.38281 (* 1 = 5.38281 loss)
I0617 01:38:27.679414 12178 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I0617 01:39:25.439481 12178 solver.cpp:218] Iteration 50 (0.865659 iter/s, 57.7595s/50 iters), loss = 0.505879
I0617 01:39:25.439981 12178 solver.cpp:237]     Train net output #0: accuracy = 0.92
I0617 01:39:25.440016 12178 solver.cpp:237]     Train net output #1: loss = 0.505879 (* 1 = 0.505879 loss)
I0617 01:39:25.440038 12178 sgd_solver.cpp:105] Iteration 50, lr = 0.01
I0617 01:40:23.168236 12178 solver.cpp:218] Iteration 100 (0.866137 iter/s, 57.7276s/50 iters), loss = 0.396499
I0617 01:40:23.168370 12178 solver.cpp:237]     Train net output #0: accuracy = 0.9
I0617 01:40:23.168401 12178 solver.cpp:237]     Train net output #1: loss = 0.396499 (* 1 = 0.396499 loss)
I0617 01:40:23.168421 12178 sgd_solver.cpp:105] Iteration 100, lr = 0.01
I0617 01:41:20.887456 12178 solver.cpp:218] Iteration 150 (0.866275 iter/s, 57.7184s/50 iters), loss = 0.107712
I0617 01:41:20.887625 12178 solver.cpp:237]     Train net output #0: accuracy = 0.98
I0617 01:41:20.887656 12178 solver.cpp:237]     Train net output #1: loss = 0.107712 (* 1 = 0.107712 loss)
I0617 01:41:20.887676 12178 sgd_solver.cpp:105] Iteration 150, lr = 0.01
I0617 01:42:18.605248 12178 solver.cpp:218] Iteration 200 (0.866296 iter/s, 57.717s/50 iters), loss = 0.0499145
I0617 01:42:18.605388 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 01:42:18.605423 12178 solver.cpp:237]     Train net output #1: loss = 0.0499145 (* 1 = 0.0499145 loss)
I0617 01:42:18.605455 12178 sgd_solver.cpp:105] Iteration 200, lr = 0.01
I0617 01:43:16.319377 12178 solver.cpp:218] Iteration 250 (0.866351 iter/s, 57.7133s/50 iters), loss = 0.0377897
I0617 01:43:16.319511 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 01:43:16.319551 12178 solver.cpp:237]     Train net output #1: loss = 0.0377897 (* 1 = 0.0377897 loss)
I0617 01:43:16.319574 12178 sgd_solver.cpp:105] Iteration 250, lr = 0.01
I0617 01:44:14.042961 12178 solver.cpp:218] Iteration 300 (0.866209 iter/s, 57.7228s/50 iters), loss = 0.0208985
I0617 01:44:14.043113 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 01:44:14.043143 12178 solver.cpp:237]     Train net output #1: loss = 0.0208985 (* 1 = 0.0208985 loss)
I0617 01:44:14.043161 12178 sgd_solver.cpp:105] Iteration 300, lr = 0.01
I0617 01:45:11.757895 12178 solver.cpp:218] Iteration 350 (0.866342 iter/s, 57.7139s/50 iters), loss = 0.00957993
I0617 01:45:11.758091 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 01:45:11.758122 12178 solver.cpp:237]     Train net output #1: loss = 0.00957992 (* 1 = 0.00957992 loss)
I0617 01:45:11.758147 12178 sgd_solver.cpp:105] Iteration 350, lr = 0.01
I0617 01:46:09.468340 12178 solver.cpp:218] Iteration 400 (0.86641 iter/s, 57.7094s/50 iters), loss = 0.0375205
I0617 01:46:09.468488 12178 solver.cpp:237]     Train net output #0: accuracy = 0.98
I0617 01:46:09.468524 12178 solver.cpp:237]     Train net output #1: loss = 0.0375205 (* 1 = 0.0375205 loss)
I0617 01:46:09.468544 12178 sgd_solver.cpp:105] Iteration 400, lr = 0.01
I0617 01:47:07.199878 12178 solver.cpp:218] Iteration 450 (0.866093 iter/s, 57.7305s/50 iters), loss = 0.0172486
I0617 01:47:07.200065 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 01:47:07.200096 12178 solver.cpp:237]     Train net output #1: loss = 0.0172486 (* 1 = 0.0172486 loss)
I0617 01:47:07.200119 12178 sgd_solver.cpp:105] Iteration 450, lr = 0.01
I0617 01:48:04.927099 12178 solver.cpp:218] Iteration 500 (0.866158 iter/s, 57.7262s/50 iters), loss = 0.016972
I0617 01:48:04.927294 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 01:48:04.927323 12178 solver.cpp:237]     Train net output #1: loss = 0.016972 (* 1 = 0.016972 loss)
I0617 01:48:04.927345 12178 sgd_solver.cpp:105] Iteration 500, lr = 0.01
I0617 01:49:02.654259 12178 solver.cpp:218] Iteration 550 (0.866159 iter/s, 57.7261s/50 iters), loss = 0.0116456
I0617 01:49:02.654486 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 01:49:02.654520 12178 solver.cpp:237]     Train net output #1: loss = 0.0116456 (* 1 = 0.0116456 loss)
I0617 01:49:02.654539 12178 sgd_solver.cpp:105] Iteration 550, lr = 0.01
I0617 01:50:00.379963 12178 solver.cpp:218] Iteration 600 (0.866182 iter/s, 57.7246s/50 iters), loss = 0.00716693
I0617 01:50:00.380218 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 01:50:00.380249 12178 solver.cpp:237]     Train net output #1: loss = 0.00716691 (* 1 = 0.00716691 loss)
I0617 01:50:00.380270 12178 sgd_solver.cpp:105] Iteration 600, lr = 0.01
I0617 01:50:58.099320 12178 solver.cpp:218] Iteration 650 (0.866277 iter/s, 57.7182s/50 iters), loss = 0.00482405
I0617 01:50:58.099520 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 01:50:58.099553 12178 solver.cpp:237]     Train net output #1: loss = 0.00482404 (* 1 = 0.00482404 loss)
I0617 01:50:58.099573 12178 sgd_solver.cpp:105] Iteration 650, lr = 0.01
I0617 01:51:55.823972 12178 solver.cpp:218] Iteration 700 (0.866196 iter/s, 57.7236s/50 iters), loss = 0.0064654
I0617 01:51:55.824098 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 01:51:55.824129 12178 solver.cpp:237]     Train net output #1: loss = 0.00646539 (* 1 = 0.00646539 loss)
I0617 01:51:55.824153 12178 sgd_solver.cpp:105] Iteration 700, lr = 0.01
I0617 01:52:53.549023 12178 solver.cpp:218] Iteration 750 (0.866189 iter/s, 57.7241s/50 iters), loss = 0.00647304
I0617 01:52:53.549149 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 01:52:53.549180 12178 solver.cpp:237]     Train net output #1: loss = 0.00647303 (* 1 = 0.00647303 loss)
I0617 01:52:53.549211 12178 sgd_solver.cpp:105] Iteration 750, lr = 0.01
I0617 01:53:51.279243 12178 solver.cpp:218] Iteration 800 (0.866112 iter/s, 57.7293s/50 iters), loss = 0.00803094
I0617 01:53:51.279429 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 01:53:51.279459 12178 solver.cpp:237]     Train net output #1: loss = 0.00803092 (* 1 = 0.00803092 loss)
I0617 01:53:51.279479 12178 sgd_solver.cpp:105] Iteration 800, lr = 0.01
I0617 01:54:48.996703 12178 solver.cpp:218] Iteration 850 (0.866304 iter/s, 57.7165s/50 iters), loss = 0.00602005
I0617 01:54:48.996835 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 01:54:48.996865 12178 solver.cpp:237]     Train net output #1: loss = 0.00602003 (* 1 = 0.00602003 loss)
I0617 01:54:48.996884 12178 sgd_solver.cpp:105] Iteration 850, lr = 0.01
I0617 01:55:46.716389 12178 solver.cpp:218] Iteration 900 (0.86627 iter/s, 57.7187s/50 iters), loss = 0.00524271
I0617 01:55:46.716657 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 01:55:46.716688 12178 solver.cpp:237]     Train net output #1: loss = 0.0052427 (* 1 = 0.0052427 loss)
I0617 01:55:46.716706 12178 sgd_solver.cpp:105] Iteration 900, lr = 0.01
I0617 01:56:44.432395 12178 solver.cpp:218] Iteration 950 (0.866327 iter/s, 57.7149s/50 iters), loss = 0.00394839
I0617 01:56:44.432574 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 01:56:44.432606 12178 solver.cpp:237]     Train net output #1: loss = 0.00394837 (* 1 = 0.00394837 loss)
I0617 01:56:44.432627 12178 sgd_solver.cpp:105] Iteration 950, lr = 0.01
I0617 01:57:42.156538 12178 solver.cpp:218] Iteration 1000 (0.866203 iter/s, 57.7232s/50 iters), loss = 0.0101616
I0617 01:57:42.156657 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 01:57:42.156687 12178 solver.cpp:237]     Train net output #1: loss = 0.0101616 (* 1 = 0.0101616 loss)
I0617 01:57:42.156707 12178 sgd_solver.cpp:105] Iteration 1000, lr = 0.01
I0617 01:58:39.872411 12178 solver.cpp:218] Iteration 1050 (0.866327 iter/s, 57.7149s/50 iters), loss = 0.00671431
I0617 01:58:39.872570 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 01:58:39.872602 12178 solver.cpp:237]     Train net output #1: loss = 0.00671429 (* 1 = 0.00671429 loss)
I0617 01:58:39.872622 12178 sgd_solver.cpp:105] Iteration 1050, lr = 0.01
I0617 01:59:37.597211 12178 solver.cpp:218] Iteration 1100 (0.866193 iter/s, 57.7238s/50 iters), loss = 0.00587698
I0617 01:59:37.597349 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 01:59:37.597379 12178 solver.cpp:237]     Train net output #1: loss = 0.00587697 (* 1 = 0.00587697 loss)
I0617 01:59:37.597399 12178 sgd_solver.cpp:105] Iteration 1100, lr = 0.01
I0617 02:00:35.318240 12178 solver.cpp:218] Iteration 1150 (0.86625 iter/s, 57.7201s/50 iters), loss = 0.00453134
I0617 02:00:35.318454 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 02:00:35.318487 12178 solver.cpp:237]     Train net output #1: loss = 0.00453133 (* 1 = 0.00453133 loss)
I0617 02:00:35.318507 12178 sgd_solver.cpp:105] Iteration 1150, lr = 0.01
I0617 02:01:33.035439 12178 solver.cpp:218] Iteration 1200 (0.866308 iter/s, 57.7162s/50 iters), loss = 0.00457044
I0617 02:01:33.035586 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 02:01:33.035619 12178 solver.cpp:237]     Train net output #1: loss = 0.00457043 (* 1 = 0.00457043 loss)
I0617 02:01:33.035643 12178 sgd_solver.cpp:105] Iteration 1200, lr = 0.01
I0617 02:02:30.753710 12178 solver.cpp:218] Iteration 1250 (0.866291 iter/s, 57.7173s/50 iters), loss = 0.00571418
I0617 02:02:30.753849 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 02:02:30.753880 12178 solver.cpp:237]     Train net output #1: loss = 0.00571417 (* 1 = 0.00571417 loss)
I0617 02:02:30.753901 12178 sgd_solver.cpp:105] Iteration 1250, lr = 0.01
I0617 02:03:28.469223 12178 solver.cpp:218] Iteration 1300 (0.866332 iter/s, 57.7146s/50 iters), loss = 0.00412893
I0617 02:03:28.469350 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 02:03:28.469395 12178 solver.cpp:237]     Train net output #1: loss = 0.00412892 (* 1 = 0.00412892 loss)
I0617 02:03:28.469419 12178 sgd_solver.cpp:105] Iteration 1300, lr = 0.01
I0617 02:04:26.187121 12178 solver.cpp:218] Iteration 1350 (0.866296 iter/s, 57.717s/50 iters), loss = 0.00583993
I0617 02:04:26.187309 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 02:04:26.187341 12178 solver.cpp:237]     Train net output #1: loss = 0.00583992 (* 1 = 0.00583992 loss)
I0617 02:04:26.187361 12178 sgd_solver.cpp:105] Iteration 1350, lr = 0.01
I0617 02:05:23.908812 12178 solver.cpp:218] Iteration 1400 (0.86624 iter/s, 57.7207s/50 iters), loss = 0.00545585
I0617 02:05:23.908990 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 02:05:23.909021 12178 solver.cpp:237]     Train net output #1: loss = 0.00545583 (* 1 = 0.00545583 loss)
I0617 02:05:23.909041 12178 sgd_solver.cpp:105] Iteration 1400, lr = 0.01
I0617 02:06:21.632987 12178 solver.cpp:218] Iteration 1450 (0.866203 iter/s, 57.7232s/50 iters), loss = 0.00629046
I0617 02:06:21.633132 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 02:06:21.633162 12178 solver.cpp:237]     Train net output #1: loss = 0.00629045 (* 1 = 0.00629045 loss)
I0617 02:06:21.633180 12178 sgd_solver.cpp:105] Iteration 1450, lr = 0.01
I0617 02:07:19.358431 12178 solver.cpp:218] Iteration 1500 (0.866183 iter/s, 57.7245s/50 iters), loss = 0.00543228
I0617 02:07:19.358573 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 02:07:19.358604 12178 solver.cpp:237]     Train net output #1: loss = 0.00543227 (* 1 = 0.00543227 loss)
I0617 02:07:19.358623 12178 sgd_solver.cpp:105] Iteration 1500, lr = 0.01
I0617 02:08:17.074437 12178 solver.cpp:218] Iteration 1550 (0.866325 iter/s, 57.7151s/50 iters), loss = 0.00811685
I0617 02:08:17.074626 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 02:08:17.074656 12178 solver.cpp:237]     Train net output #1: loss = 0.00811683 (* 1 = 0.00811683 loss)
I0617 02:08:17.074676 12178 sgd_solver.cpp:105] Iteration 1550, lr = 0.01
I0617 02:09:14.791275 12178 solver.cpp:218] Iteration 1600 (0.866313 iter/s, 57.7159s/50 iters), loss = 0.00734834
I0617 02:09:14.791420 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 02:09:14.791450 12178 solver.cpp:237]     Train net output #1: loss = 0.00734832 (* 1 = 0.00734832 loss)
I0617 02:09:14.791470 12178 sgd_solver.cpp:105] Iteration 1600, lr = 0.01
I0617 02:10:12.513865 12178 solver.cpp:218] Iteration 1650 (0.866226 iter/s, 57.7217s/50 iters), loss = 0.00636876
I0617 02:10:12.514075 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 02:10:12.514112 12178 solver.cpp:237]     Train net output #1: loss = 0.00636875 (* 1 = 0.00636875 loss)
I0617 02:10:12.514135 12178 sgd_solver.cpp:105] Iteration 1650, lr = 0.01
I0617 02:11:10.241610 12178 solver.cpp:218] Iteration 1700 (0.86615 iter/s, 57.7267s/50 iters), loss = 0.00646214
I0617 02:11:10.241773 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 02:11:10.241804 12178 solver.cpp:237]     Train net output #1: loss = 0.00646212 (* 1 = 0.00646212 loss)
I0617 02:11:10.241824 12178 sgd_solver.cpp:105] Iteration 1700, lr = 0.01
I0617 02:12:07.972548 12178 solver.cpp:218] Iteration 1750 (0.866101 iter/s, 57.73s/50 iters), loss = 0.00536948
I0617 02:12:07.972723 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 02:12:07.972753 12178 solver.cpp:237]     Train net output #1: loss = 0.00536947 (* 1 = 0.00536947 loss)
I0617 02:12:07.972772 12178 sgd_solver.cpp:105] Iteration 1750, lr = 0.01
I0617 02:13:05.702970 12178 solver.cpp:218] Iteration 1800 (0.866109 iter/s, 57.7295s/50 iters), loss = 0.00647712
I0617 02:13:05.703090 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 02:13:05.703120 12178 solver.cpp:237]     Train net output #1: loss = 0.0064771 (* 1 = 0.0064771 loss)
I0617 02:13:05.703140 12178 sgd_solver.cpp:105] Iteration 1800, lr = 0.01
I0617 02:14:03.419977 12178 solver.cpp:218] Iteration 1850 (0.866309 iter/s, 57.7161s/50 iters), loss = 0.00371176
I0617 02:14:03.420132 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 02:14:03.420162 12178 solver.cpp:237]     Train net output #1: loss = 0.00371174 (* 1 = 0.00371174 loss)
I0617 02:14:03.420181 12178 sgd_solver.cpp:105] Iteration 1850, lr = 0.01
I0617 02:15:01.136185 12178 solver.cpp:218] Iteration 1900 (0.866322 iter/s, 57.7153s/50 iters), loss = 0.00451401
I0617 02:15:01.136458 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 02:15:01.136489 12178 solver.cpp:237]     Train net output #1: loss = 0.004514 (* 1 = 0.004514 loss)
I0617 02:15:01.136508 12178 sgd_solver.cpp:105] Iteration 1900, lr = 0.01
I0617 02:15:58.856608 12178 solver.cpp:218] Iteration 1950 (0.86626 iter/s, 57.7194s/50 iters), loss = 0.00733766
I0617 02:15:58.856729 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 02:15:58.856761 12178 solver.cpp:237]     Train net output #1: loss = 0.00733765 (* 1 = 0.00733765 loss)
I0617 02:15:58.856781 12178 sgd_solver.cpp:105] Iteration 1950, lr = 0.01
I0617 02:16:56.583384 12178 solver.cpp:218] Iteration 2000 (0.866163 iter/s, 57.7259s/50 iters), loss = 0.00457931
I0617 02:16:56.583523 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 02:16:56.583555 12178 solver.cpp:237]     Train net output #1: loss = 0.0045793 (* 1 = 0.0045793 loss)
I0617 02:16:56.583575 12178 sgd_solver.cpp:105] Iteration 2000, lr = 0.01
I0617 02:17:54.316256 12178 solver.cpp:218] Iteration 2050 (0.866071 iter/s, 57.732s/50 iters), loss = 0.00644164
I0617 02:17:54.316401 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 02:17:54.316432 12178 solver.cpp:237]     Train net output #1: loss = 0.00644163 (* 1 = 0.00644163 loss)
I0617 02:17:54.316450 12178 sgd_solver.cpp:105] Iteration 2050, lr = 0.01
I0617 02:18:52.036525 12178 solver.cpp:218] Iteration 2100 (0.866261 iter/s, 57.7193s/50 iters), loss = 0.00652412
I0617 02:18:52.036681 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 02:18:52.036711 12178 solver.cpp:237]     Train net output #1: loss = 0.00652411 (* 1 = 0.00652411 loss)
I0617 02:18:52.036731 12178 sgd_solver.cpp:105] Iteration 2100, lr = 0.01
I0617 02:19:49.758560 12178 solver.cpp:218] Iteration 2150 (0.866236 iter/s, 57.721s/50 iters), loss = 0.00465134
I0617 02:19:49.758711 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 02:19:49.758741 12178 solver.cpp:237]     Train net output #1: loss = 0.00465132 (* 1 = 0.00465132 loss)
I0617 02:19:49.758761 12178 sgd_solver.cpp:105] Iteration 2150, lr = 0.01
I0617 02:20:47.487010 12178 solver.cpp:218] Iteration 2200 (0.86614 iter/s, 57.7274s/50 iters), loss = 0.0084075
I0617 02:20:47.487318 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 02:20:47.487349 12178 solver.cpp:237]     Train net output #1: loss = 0.00840748 (* 1 = 0.00840748 loss)
I0617 02:20:47.487370 12178 sgd_solver.cpp:105] Iteration 2200, lr = 0.01
I0617 02:21:45.218868 12178 solver.cpp:218] Iteration 2250 (0.866091 iter/s, 57.7307s/50 iters), loss = 0.00516987
I0617 02:21:45.219110 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 02:21:45.219142 12178 solver.cpp:237]     Train net output #1: loss = 0.00516985 (* 1 = 0.00516985 loss)
I0617 02:21:45.219162 12178 sgd_solver.cpp:105] Iteration 2250, lr = 0.01
I0617 02:22:42.932646 12178 solver.cpp:218] Iteration 2300 (0.866361 iter/s, 57.7126s/50 iters), loss = 0.00453538
I0617 02:22:42.932920 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 02:22:42.932952 12178 solver.cpp:237]     Train net output #1: loss = 0.00453536 (* 1 = 0.00453536 loss)
I0617 02:22:42.932972 12178 sgd_solver.cpp:105] Iteration 2300, lr = 0.01
I0617 02:23:40.657140 12178 solver.cpp:218] Iteration 2350 (0.866201 iter/s, 57.7233s/50 iters), loss = 0.00766235
I0617 02:23:40.657407 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 02:23:40.657438 12178 solver.cpp:237]     Train net output #1: loss = 0.00766234 (* 1 = 0.00766234 loss)
I0617 02:23:40.657457 12178 sgd_solver.cpp:105] Iteration 2350, lr = 0.01
I0617 02:24:38.383396 12178 solver.cpp:218] Iteration 2400 (0.866174 iter/s, 57.7251s/50 iters), loss = 0.00998141
I0617 02:24:38.383574 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 02:24:38.383605 12178 solver.cpp:237]     Train net output #1: loss = 0.00998139 (* 1 = 0.00998139 loss)
I0617 02:24:38.383625 12178 sgd_solver.cpp:105] Iteration 2400, lr = 0.01
I0617 02:25:36.107730 12178 solver.cpp:218] Iteration 2450 (0.866202 iter/s, 57.7233s/50 iters), loss = 0.00615896
I0617 02:25:36.107902 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 02:25:36.107933 12178 solver.cpp:237]     Train net output #1: loss = 0.00615894 (* 1 = 0.00615894 loss)
I0617 02:25:36.107952 12178 sgd_solver.cpp:105] Iteration 2450, lr = 0.01
I0617 02:26:33.831408 12178 solver.cpp:218] Iteration 2500 (0.866211 iter/s, 57.7226s/50 iters), loss = 0.00425065
I0617 02:26:33.831547 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 02:26:33.831579 12178 solver.cpp:237]     Train net output #1: loss = 0.00425064 (* 1 = 0.00425064 loss)
I0617 02:26:33.831598 12178 sgd_solver.cpp:105] Iteration 2500, lr = 0.01
I0617 02:27:31.551848 12178 solver.cpp:218] Iteration 2550 (0.86626 iter/s, 57.7194s/50 iters), loss = 0.00780643
I0617 02:27:31.552001 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 02:27:31.552032 12178 solver.cpp:237]     Train net output #1: loss = 0.00780641 (* 1 = 0.00780641 loss)
I0617 02:27:31.552052 12178 sgd_solver.cpp:105] Iteration 2550, lr = 0.01
I0617 02:28:29.262981 12178 solver.cpp:218] Iteration 2600 (0.8664 iter/s, 57.7101s/50 iters), loss = 0.00512538
I0617 02:28:29.263146 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 02:28:29.263177 12178 solver.cpp:237]     Train net output #1: loss = 0.00512537 (* 1 = 0.00512537 loss)
I0617 02:28:29.263197 12178 sgd_solver.cpp:105] Iteration 2600, lr = 0.01
I0617 02:29:26.988327 12178 solver.cpp:218] Iteration 2650 (0.866186 iter/s, 57.7243s/50 iters), loss = 0.00335357
I0617 02:29:26.988499 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 02:29:26.988535 12178 solver.cpp:237]     Train net output #1: loss = 0.00335355 (* 1 = 0.00335355 loss)
I0617 02:29:26.988556 12178 sgd_solver.cpp:105] Iteration 2650, lr = 0.01
I0617 02:30:24.699090 12178 solver.cpp:218] Iteration 2700 (0.866405 iter/s, 57.7097s/50 iters), loss = 0.00521808
I0617 02:30:24.699268 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 02:30:24.699303 12178 solver.cpp:237]     Train net output #1: loss = 0.00521807 (* 1 = 0.00521807 loss)
I0617 02:30:24.699323 12178 sgd_solver.cpp:105] Iteration 2700, lr = 0.01
I0617 02:31:22.421008 12178 solver.cpp:218] Iteration 2750 (0.866238 iter/s, 57.7209s/50 iters), loss = 0.00508049
I0617 02:31:22.421213 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 02:31:22.421244 12178 solver.cpp:237]     Train net output #1: loss = 0.00508047 (* 1 = 0.00508047 loss)
I0617 02:31:22.421264 12178 sgd_solver.cpp:105] Iteration 2750, lr = 0.01
I0617 02:32:20.138803 12178 solver.cpp:218] Iteration 2800 (0.8663 iter/s, 57.7167s/50 iters), loss = 0.00474052
I0617 02:32:20.138969 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 02:32:20.139004 12178 solver.cpp:237]     Train net output #1: loss = 0.00474051 (* 1 = 0.00474051 loss)
I0617 02:32:20.139029 12178 sgd_solver.cpp:105] Iteration 2800, lr = 0.01
I0617 02:33:17.850564 12178 solver.cpp:218] Iteration 2850 (0.86639 iter/s, 57.7107s/50 iters), loss = 0.00534733
I0617 02:33:17.850713 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 02:33:17.850744 12178 solver.cpp:237]     Train net output #1: loss = 0.00534731 (* 1 = 0.00534731 loss)
I0617 02:33:17.850762 12178 sgd_solver.cpp:105] Iteration 2850, lr = 0.01
I0617 02:34:15.561643 12178 solver.cpp:218] Iteration 2900 (0.8664 iter/s, 57.7101s/50 iters), loss = 0.00639831
I0617 02:34:15.561803 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 02:34:15.561835 12178 solver.cpp:237]     Train net output #1: loss = 0.0063983 (* 1 = 0.0063983 loss)
I0617 02:34:15.561864 12178 sgd_solver.cpp:105] Iteration 2900, lr = 0.01
I0617 02:35:13.280622 12178 solver.cpp:218] Iteration 2950 (0.866282 iter/s, 57.718s/50 iters), loss = 0.00643773
I0617 02:35:13.280896 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 02:35:13.280927 12178 solver.cpp:237]     Train net output #1: loss = 0.00643772 (* 1 = 0.00643772 loss)
I0617 02:35:13.280946 12178 sgd_solver.cpp:105] Iteration 2950, lr = 0.01
I0617 02:36:10.994369 12178 solver.cpp:218] Iteration 3000 (0.866362 iter/s, 57.7126s/50 iters), loss = 0.00471903
I0617 02:36:10.994554 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 02:36:10.994586 12178 solver.cpp:237]     Train net output #1: loss = 0.00471902 (* 1 = 0.00471902 loss)
I0617 02:36:10.994606 12178 sgd_solver.cpp:105] Iteration 3000, lr = 0.01
I0617 02:37:08.721343 12178 solver.cpp:218] Iteration 3050 (0.866162 iter/s, 57.7259s/50 iters), loss = 0.00772521
I0617 02:37:08.721536 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 02:37:08.721568 12178 solver.cpp:237]     Train net output #1: loss = 0.0077252 (* 1 = 0.0077252 loss)
I0617 02:37:08.721588 12178 sgd_solver.cpp:105] Iteration 3050, lr = 0.01
I0617 02:38:06.431282 12178 solver.cpp:218] Iteration 3100 (0.866418 iter/s, 57.7089s/50 iters), loss = 0.00423346
I0617 02:38:06.431466 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 02:38:06.431498 12178 solver.cpp:237]     Train net output #1: loss = 0.00423345 (* 1 = 0.00423345 loss)
I0617 02:38:06.431521 12178 sgd_solver.cpp:105] Iteration 3100, lr = 0.01
I0617 02:39:04.144381 12178 solver.cpp:218] Iteration 3150 (0.86637 iter/s, 57.7121s/50 iters), loss = 0.00729105
I0617 02:39:04.144577 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 02:39:04.144613 12178 solver.cpp:237]     Train net output #1: loss = 0.00729104 (* 1 = 0.00729104 loss)
I0617 02:39:04.144634 12178 sgd_solver.cpp:105] Iteration 3150, lr = 0.01
I0617 02:40:01.860152 12178 solver.cpp:218] Iteration 3200 (0.86633 iter/s, 57.7147s/50 iters), loss = 0.00562955
I0617 02:40:01.860296 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 02:40:01.860327 12178 solver.cpp:237]     Train net output #1: loss = 0.00562953 (* 1 = 0.00562953 loss)
I0617 02:40:01.860347 12178 sgd_solver.cpp:105] Iteration 3200, lr = 0.01
I0617 02:40:59.581770 12178 solver.cpp:218] Iteration 3250 (0.866241 iter/s, 57.7206s/50 iters), loss = 0.00640591
I0617 02:40:59.581907 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 02:40:59.581938 12178 solver.cpp:237]     Train net output #1: loss = 0.00640589 (* 1 = 0.00640589 loss)
I0617 02:40:59.581956 12178 sgd_solver.cpp:105] Iteration 3250, lr = 0.01
I0617 02:41:57.301038 12178 solver.cpp:218] Iteration 3300 (0.866276 iter/s, 57.7183s/50 iters), loss = 0.00457753
I0617 02:41:57.301218 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 02:41:57.301249 12178 solver.cpp:237]     Train net output #1: loss = 0.00457751 (* 1 = 0.00457751 loss)
I0617 02:41:57.301268 12178 sgd_solver.cpp:105] Iteration 3300, lr = 0.01
I0617 02:42:55.027681 12178 solver.cpp:218] Iteration 3350 (0.866167 iter/s, 57.7256s/50 iters), loss = 0.00632567
I0617 02:42:55.027837 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 02:42:55.027868 12178 solver.cpp:237]     Train net output #1: loss = 0.00632566 (* 1 = 0.00632566 loss)
I0617 02:42:55.027887 12178 sgd_solver.cpp:105] Iteration 3350, lr = 0.01
I0617 02:43:52.749477 12178 solver.cpp:218] Iteration 3400 (0.866239 iter/s, 57.7208s/50 iters), loss = 0.00699416
I0617 02:43:52.749624 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 02:43:52.749655 12178 solver.cpp:237]     Train net output #1: loss = 0.00699414 (* 1 = 0.00699414 loss)
I0617 02:43:52.749675 12178 sgd_solver.cpp:105] Iteration 3400, lr = 0.01
I0617 02:44:50.473353 12178 solver.cpp:218] Iteration 3450 (0.866207 iter/s, 57.7229s/50 iters), loss = 0.00529405
I0617 02:44:50.473507 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 02:44:50.473544 12178 solver.cpp:237]     Train net output #1: loss = 0.00529403 (* 1 = 0.00529403 loss)
I0617 02:44:50.473563 12178 sgd_solver.cpp:105] Iteration 3450, lr = 0.01
I0617 02:45:48.187759 12178 solver.cpp:218] Iteration 3500 (0.86635 iter/s, 57.7134s/50 iters), loss = 0.00657284
I0617 02:45:48.187906 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 02:45:48.187937 12178 solver.cpp:237]     Train net output #1: loss = 0.00657282 (* 1 = 0.00657282 loss)
I0617 02:45:48.187957 12178 sgd_solver.cpp:105] Iteration 3500, lr = 0.01
I0617 02:46:45.916028 12178 solver.cpp:218] Iteration 3550 (0.866141 iter/s, 57.7273s/50 iters), loss = 0.0063097
I0617 02:46:45.916167 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 02:46:45.916198 12178 solver.cpp:237]     Train net output #1: loss = 0.00630968 (* 1 = 0.00630968 loss)
I0617 02:46:45.916218 12178 sgd_solver.cpp:105] Iteration 3550, lr = 0.01
I0617 02:47:43.621347 12178 solver.cpp:218] Iteration 3600 (0.866486 iter/s, 57.7044s/50 iters), loss = 0.00447545
I0617 02:47:43.621484 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 02:47:43.621520 12178 solver.cpp:237]     Train net output #1: loss = 0.00447543 (* 1 = 0.00447543 loss)
I0617 02:47:43.621541 12178 sgd_solver.cpp:105] Iteration 3600, lr = 0.01
I0617 02:48:41.348362 12178 solver.cpp:218] Iteration 3650 (0.86616 iter/s, 57.7261s/50 iters), loss = 0.00806187
I0617 02:48:41.348508 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 02:48:41.348547 12178 solver.cpp:237]     Train net output #1: loss = 0.00806186 (* 1 = 0.00806186 loss)
I0617 02:48:41.348567 12178 sgd_solver.cpp:105] Iteration 3650, lr = 0.01
I0617 02:49:39.090898 12178 solver.cpp:218] Iteration 3700 (0.865928 iter/s, 57.7416s/50 iters), loss = 0.00639846
I0617 02:49:39.091169 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 02:49:39.091199 12178 solver.cpp:237]     Train net output #1: loss = 0.00639844 (* 1 = 0.00639844 loss)
I0617 02:49:39.091219 12178 sgd_solver.cpp:105] Iteration 3700, lr = 0.01
I0617 02:50:36.814429 12178 solver.cpp:218] Iteration 3750 (0.866214 iter/s, 57.7224s/50 iters), loss = 0.00564352
I0617 02:50:36.814622 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 02:50:36.814653 12178 solver.cpp:237]     Train net output #1: loss = 0.0056435 (* 1 = 0.0056435 loss)
I0617 02:50:36.814673 12178 sgd_solver.cpp:105] Iteration 3750, lr = 0.01
I0617 02:51:34.545246 12178 solver.cpp:218] Iteration 3800 (0.866104 iter/s, 57.7298s/50 iters), loss = 0.00664869
I0617 02:51:34.545814 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 02:51:34.545846 12178 solver.cpp:237]     Train net output #1: loss = 0.00664868 (* 1 = 0.00664868 loss)
I0617 02:51:34.545866 12178 sgd_solver.cpp:105] Iteration 3800, lr = 0.01
I0617 02:52:32.287537 12178 solver.cpp:218] Iteration 3850 (0.865937 iter/s, 57.7409s/50 iters), loss = 0.00844057
I0617 02:52:32.287685 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 02:52:32.287717 12178 solver.cpp:237]     Train net output #1: loss = 0.00844056 (* 1 = 0.00844056 loss)
I0617 02:52:32.287736 12178 sgd_solver.cpp:105] Iteration 3850, lr = 0.01
I0617 02:53:30.024668 12178 solver.cpp:218] Iteration 3900 (0.866007 iter/s, 57.7362s/50 iters), loss = 0.00716951
I0617 02:53:30.024919 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 02:53:30.024947 12178 solver.cpp:237]     Train net output #1: loss = 0.0071695 (* 1 = 0.0071695 loss)
I0617 02:53:30.024967 12178 sgd_solver.cpp:105] Iteration 3900, lr = 0.01
I0617 02:54:27.750551 12178 solver.cpp:218] Iteration 3950 (0.866177 iter/s, 57.7249s/50 iters), loss = 0.00484672
I0617 02:54:27.750711 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 02:54:27.750742 12178 solver.cpp:237]     Train net output #1: loss = 0.00484671 (* 1 = 0.00484671 loss)
I0617 02:54:27.750761 12178 sgd_solver.cpp:105] Iteration 3950, lr = 0.01
I0617 02:55:25.487212 12178 solver.cpp:218] Iteration 4000 (0.866014 iter/s, 57.7358s/50 iters), loss = 0.0102376
I0617 02:55:25.487383 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 02:55:25.487413 12178 solver.cpp:237]     Train net output #1: loss = 0.0102376 (* 1 = 0.0102376 loss)
I0617 02:55:25.487432 12178 sgd_solver.cpp:105] Iteration 4000, lr = 0.01
I0617 02:56:23.213618 12178 solver.cpp:218] Iteration 4050 (0.866168 iter/s, 57.7255s/50 iters), loss = 0.00743432
I0617 02:56:23.213752 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 02:56:23.213783 12178 solver.cpp:237]     Train net output #1: loss = 0.00743431 (* 1 = 0.00743431 loss)
I0617 02:56:23.213800 12178 sgd_solver.cpp:105] Iteration 4050, lr = 0.01
I0617 02:57:20.946900 12178 solver.cpp:218] Iteration 4100 (0.866064 iter/s, 57.7324s/50 iters), loss = 0.00844984
I0617 02:57:20.947036 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 02:57:20.947068 12178 solver.cpp:237]     Train net output #1: loss = 0.00844983 (* 1 = 0.00844983 loss)
I0617 02:57:20.947088 12178 sgd_solver.cpp:105] Iteration 4100, lr = 0.01
I0617 02:58:18.669068 12178 solver.cpp:218] Iteration 4150 (0.866231 iter/s, 57.7213s/50 iters), loss = 0.00683085
I0617 02:58:18.669221 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 02:58:18.669251 12178 solver.cpp:237]     Train net output #1: loss = 0.00683083 (* 1 = 0.00683083 loss)
I0617 02:58:18.669270 12178 sgd_solver.cpp:105] Iteration 4150, lr = 0.01
I0617 02:59:16.413440 12178 solver.cpp:218] Iteration 4200 (0.865898 iter/s, 57.7435s/50 iters), loss = 0.00580232
I0617 02:59:16.413625 12178 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 02:59:16.413655 12178 solver.cpp:237]     Train net output #1: loss = 0.00580231 (* 1 = 0.00580231 loss)
I0617 02:59:16.413674 12178 sgd_solver.cpp:105] Iteration 4200, lr = 0.01
I0617 02:59:59.136765 12178 solver.cpp:447] Snapshotting to binary proto file mobilenet/mobile_2_iter_4238.caffemodel
I0617 02:59:59.238092 12178 sgd_solver.cpp:273] Snapshotting solver state to binary proto file mobilenet/mobile_2_iter_4238.solverstate
I0617 02:59:59.267889 12178 solver.cpp:294] Optimization stopped early.
I0617 02:59:59.267931 12178 caffe.cpp:259] Optimization Done.
I0617 03:45:45.665499  4950 caffe.cpp:218] Using GPUs 1
I0617 03:45:45.811214  4950 caffe.cpp:223] GPU 1: Tesla K40m
I0617 03:45:46.171180  4950 solver.cpp:44] Initializing solver from parameters: 
base_lr: 0.01
display: 50
max_iter: 200000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 50000
snapshot: 10000
snapshot_prefix: "mobilenet/mobile_cub"
solver_mode: GPU
device_id: 1
net: "/home/xingzhaolong/caffe_project/caffe_mobile/models/oxford/mobilenet/mobilenet_cub.prototxt"
train_state {
  level: 0
  stage: ""
}
I0617 03:45:46.171550  4950 solver.cpp:87] Creating training net from net file: /home/xingzhaolong/caffe_project/caffe_mobile/models/oxford/mobilenet/mobilenet_cub.prototxt
I0617 03:45:46.174173  4950 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/xingzhaolong/caffe_project/caffe_mobile/models/oxford/mobilenet/mobilenet_cub.prototxt
I0617 03:45:46.174203  4950 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0617 03:45:46.174494  4950 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0617 03:45:46.174597  4950 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0617 03:45:46.175534  4950 net.cpp:51] Initializing net from parameters: 
name: "MOBILENET"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_file: "/home/xingzhaolong/Dataset/CUB_200_2011/lmdb/mean.binaryproto"
  }
  data_param {
    source: "/home/xingzhaolong/Dataset/CUB_200_2011/lmdb/train"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv1/bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1/scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2_1/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv1"
  top: "conv2_1/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 32
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv2_1/dw"
  top: "conv2_1/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_1/dw/scale"
  type: "Scale"
  bottom: "conv2_1/dw"
  top: "conv2_1/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_1/dw"
  type: "ReLU"
  bottom: "conv2_1/dw"
  top: "conv2_1/dw"
}
layer {
  name: "conv2_1/sep"
  type: "Convolution"
  bottom: "conv2_1/dw"
  top: "conv2_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv2_1/sep"
  top: "conv2_1/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_1/sep/scale"
  type: "Scale"
  bottom: "conv2_1/sep"
  top: "conv2_1/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_1/sep"
  type: "ReLU"
  bottom: "conv2_1/sep"
  top: "conv2_1/sep"
}
layer {
  name: "conv2_2/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv2_1/sep"
  top: "conv2_2/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 64
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv2_2/dw"
  top: "conv2_2/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_2/dw/scale"
  type: "Scale"
  bottom: "conv2_2/dw"
  top: "conv2_2/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_2/dw"
  type: "ReLU"
  bottom: "conv2_2/dw"
  top: "conv2_2/dw"
}
layer {
  name: "conv2_2/sep"
  type: "Convolution"
  bottom: "conv2_2/dw"
  top: "conv2_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv2_2/sep"
  top: "conv2_2/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_2/sep/scale"
  type: "Scale"
  bottom: "conv2_2/sep"
  top: "conv2_2/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_2/sep"
  type: "ReLU"
  bottom: "conv2_2/sep"
  top: "conv2_2/sep"
}
layer {
  name: "conv3_1/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv2_2/sep"
  top: "conv3_1/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv3_1/dw"
  top: "conv3_1/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_1/dw/scale"
  type: "Scale"
  bottom: "conv3_1/dw"
  top: "conv3_1/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_1/dw"
  type: "ReLU"
  bottom: "conv3_1/dw"
  top: "conv3_1/dw"
}
layer {
  name: "conv3_1/sep"
  type: "Convolution"
  bottom: "conv3_1/dw"
  top: "conv3_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv3_1/sep"
  top: "conv3_1/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_1/sep/scale"
  type: "Scale"
  bottom: "conv3_1/sep"
  top: "conv3_1/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_1/sep"
  type: "ReLU"
  bottom: "conv3_1/sep"
  top: "conv3_1/sep"
}
layer {
  name: "conv3_2/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv3_1/sep"
  top: "conv3_2/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv3_2/dw"
  top: "conv3_2/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_2/dw/scale"
  type: "Scale"
  bottom: "conv3_2/dw"
  top: "conv3_2/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_2/dw"
  type: "ReLU"
  bottom: "conv3_2/dw"
  top: "conv3_2/dw"
}
layer {
  name: "conv3_2/sep"
  type: "Convolution"
  bottom: "conv3_2/dw"
  top: "conv3_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv3_2/sep"
  top: "conv3_2/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_2/sep/scale"
  type: "Scale"
  bottom: "conv3_2/sep"
  top: "conv3_2/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_2/sep"
  type: "ReLU"
  bottom: "conv3_2/sep"
  top: "conv3_2/sep"
}
layer {
  name: "conv4_1/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv3_2/sep"
  top: "conv4_1/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv4_1/dw"
  top: "conv4_1/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv4_1/dw/scale"
  type: "Scale"
  bottom: "conv4_1/dw"
  top: "conv4_1/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu4_1/dw"
  type: "ReLU"
  bottom: "conv4_1/dw"
  top: "conv4_1/dw"
}
layer {
  name: "conv4_1/sep"
  type: "Convolution"
  bottom: "conv4_1/dw"
  top: "conv4_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv4_1/sep"
  top: "conv4_1/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv4_1/sep/scale"
  type: "Scale"
  bottom: "conv4_1/sep"
  top: "conv4_1/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu4_1/sep"
  type: "ReLU"
  bottom: "conv4_1/sep"
  top: "conv4_1/sep"
}
layer {
  name: "conv4_2/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv4_1/sep"
  top: "conv4_2/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv4_2/dw"
  top: "conv4_2/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv4_2/dw/scale"
  type: "Scale"
  bottom: "conv4_2/dw"
  top: "conv4_2/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu4_2/dw"
  type: "ReLU"
  bottom: "conv4_2/dw"
  top: "conv4_2/dw"
}
layer {
  name: "conv4_2/sep"
  type: "Convolution"
  bottom: "conv4_2/dw"
  top: "conv4_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv4_2/sep"
  top: "conv4_2/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv4_2/sep/scale"
  type: "Scale"
  bottom: "conv4_2/sep"
  top: "conv4_2/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu4_2/sep"
  type: "ReLU"
  bottom: "conv4_2/sep"
  top: "conv4_2/sep"
}
layer {
  name: "conv5_1/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv4_2/sep"
  top: "conv5_1/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_1/dw"
  top: "conv5_1/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_1/dw/scale"
  type: "Scale"
  bottom: "conv5_1/dw"
  top: "conv5_1/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_1/dw"
  type: "ReLU"
  bottom: "conv5_1/dw"
  top: "conv5_1/dw"
}
layer {
  name: "conv5_1/sep"
  type: "Convolution"
  bottom: "conv5_1/dw"
  top: "conv5_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_1/sep"
  top: "conv5_1/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_1/sep/scale"
  type: "Scale"
  bottom: "conv5_1/sep"
  top: "conv5_1/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_1/sep"
  type: "ReLU"
  bottom: "conv5_1/sep"
  top: "conv5_1/sep"
}
layer {
  name: "conv5_2/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_1/sep"
  top: "conv5_2/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_2/dw"
  top: "conv5_2/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_2/dw/scale"
  type: "Scale"
  bottom: "conv5_2/dw"
  top: "conv5_2/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_2/dw"
  type: "ReLU"
  bottom: "conv5_2/dw"
  top: "conv5_2/dw"
}
layer {
  name: "conv5_2/sep"
  type: "Convolution"
  bottom: "conv5_2/dw"
  top: "conv5_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_2/sep"
  top: "conv5_2/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_2/sep/scale"
  type: "Scale"
  bottom: "conv5_2/sep"
  top: "conv5_2/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_2/sep"
  type: "ReLU"
  bottom: "conv5_2/sep"
  top: "conv5_2/sep"
}
layer {
  name: "conv5_3/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_2/sep"
  top: "conv5_3/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_3/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_3/dw"
  top: "conv5_3/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_3/dw/scale"
  type: "Scale"
  bottom: "conv5_3/dw"
  top: "conv5_3/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_3/dw"
  type: "ReLU"
  bottom: "conv5_3/dw"
  top: "conv5_3/dw"
}
layer {
  name: "conv5_3/sep"
  type: "Convolution"
  bottom: "conv5_3/dw"
  top: "conv5_3/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_3/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_3/sep"
  top: "conv5_3/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_3/sep/scale"
  type: "Scale"
  bottom: "conv5_3/sep"
  top: "conv5_3/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_3/sep"
  type: "ReLU"
  bottom: "conv5_3/sep"
  top: "conv5_3/sep"
}
layer {
  name: "conv5_4/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_3/sep"
  top: "conv5_4/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_4/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_4/dw"
  top: "conv5_4/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_4/dw/scale"
  type: "Scale"
  bottom: "conv5_4/dw"
  top: "conv5_4/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_4/dw"
  type: "ReLU"
  bottom: "conv5_4/dw"
  top: "conv5_4/dw"
}
layer {
  name: "conv5_4/sep"
  type: "Convolution"
  bottom: "conv5_4/dw"
  top: "conv5_4/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_4/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_4/sep"
  top: "conv5_4/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_4/sep/scale"
  type: "Scale"
  bottom: "conv5_4/sep"
  top: "conv5_4/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_4/sep"
  type: "ReLU"
  bottom: "conv5_4/sep"
  top: "conv5_4/sep"
}
layer {
  name: "conv5_5/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_4/sep"
  top: "conv5_5/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_5/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_5/dw"
  top: "conv5_5/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_5/dw/scale"
  type: "Scale"
  bottom: "conv5_5/dw"
  top: "conv5_5/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_5/dw"
  type: "ReLU"
  bottom: "conv5_5/dw"
  top: "conv5_5/dw"
}
layer {
  name: "conv5_5/sep"
  type: "Convolution"
  bottom: "conv5_5/dw"
  top: "conv5_5/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_5/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_5/sep"
  top: "conv5_5/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_5/sep/scale"
  type: "Scale"
  bottom: "conv5_5/sep"
  top: "conv5_5/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_5/sep"
  type: "ReLU"
  bottom: "conv5_5/sep"
  top: "conv5_5/sep"
}
layer {
  name: "conv5_6/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_5/sep"
  top: "conv5_6/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_6/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_6/dw"
  top: "conv5_6/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_6/dw/scale"
  type: "Scale"
  bottom: "conv5_6/dw"
  top: "conv5_6/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_6/dw"
  type: "ReLU"
  bottom: "conv5_6/dw"
  top: "conv5_6/dw"
}
layer {
  name: "conv5_6/sep"
  type: "Convolution"
  bottom: "conv5_6/dw"
  top: "conv5_6/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_6/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_6/sep"
  top: "conv5_6/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_6/sep/scale"
  type: "Scale"
  bottom: "conv5_6/sep"
  top: "conv5_6/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_6/sep"
  type: "ReLU"
  bottom: "conv5_6/sep"
  top: "conv5_6/sep"
}
layer {
  name: "conv6/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_6/sep"
  top: "conv6/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 1024
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv6/dw/bn"
  type: "BatchNorm"
  bottom: "conv6/dw"
  top: "conv6/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv6/dw/scale"
  type: "Scale"
  bottom: "conv6/dw"
  top: "conv6/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu6/dw"
  type: "ReLU"
  bottom: "conv6/dw"
  top: "conv6/dw"
}
layer {
  name: "conv6/sep"
  type: "Convolution"
  bottom: "conv6/dw"
  top: "conv6/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv6/sep/bn"
  type: "BatchNorm"
  bottom: "conv6/sep"
  top: "conv6/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv6/sep/scale"
  type: "Scale"
  bottom: "conv6/sep"
  top: "conv6/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu6/sep"
  type: "ReLU"
  bottom: "conv6/sep"
  top: "conv6/sep"
}
layer {
  name: "pool6"
  type: "Pooling"
  bottom: "conv6/sep"
  top: "pool6"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc7_oxford"
  type: "Convolution"
  bottom: "pool6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 200
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc7"
  bottom: "label"
  top: "loss"
}
I0617 03:45:46.176041  4950 layer_factory.hpp:77] Creating layer data
I0617 03:45:46.176338  4950 db_lmdb.cpp:35] Opened lmdb /home/xingzhaolong/Dataset/CUB_200_2011/lmdb/train
I0617 03:45:46.176411  4950 net.cpp:84] Creating Layer data
I0617 03:45:46.176435  4950 net.cpp:380] data -> data
I0617 03:45:46.176478  4950 net.cpp:380] data -> label
I0617 03:45:46.176520  4950 data_transformer.cpp:25] Loading mean file from: /home/xingzhaolong/Dataset/CUB_200_2011/lmdb/mean.binaryproto
I0617 03:45:46.181885  4950 data_layer.cpp:45] output data size: 50,3,224,224
I0617 03:45:46.289599  4950 net.cpp:122] Setting up data
I0617 03:45:46.289669  4950 net.cpp:129] Top shape: 50 3 224 224 (7526400)
I0617 03:45:46.289682  4950 net.cpp:129] Top shape: 50 (50)
I0617 03:45:46.289691  4950 net.cpp:137] Memory required for data: 30105800
I0617 03:45:46.289713  4950 layer_factory.hpp:77] Creating layer conv1
I0617 03:45:46.289757  4950 net.cpp:84] Creating Layer conv1
I0617 03:45:46.289772  4950 net.cpp:406] conv1 <- data
I0617 03:45:46.289811  4950 net.cpp:380] conv1 -> conv1
I0617 03:45:46.539302  4950 net.cpp:122] Setting up conv1
I0617 03:45:46.539376  4950 net.cpp:129] Top shape: 50 32 112 112 (20070400)
I0617 03:45:46.539386  4950 net.cpp:137] Memory required for data: 110387400
I0617 03:45:46.539422  4950 layer_factory.hpp:77] Creating layer conv1/bn
I0617 03:45:46.539448  4950 net.cpp:84] Creating Layer conv1/bn
I0617 03:45:46.539458  4950 net.cpp:406] conv1/bn <- conv1
I0617 03:45:46.539471  4950 net.cpp:367] conv1/bn -> conv1 (in-place)
I0617 03:45:46.540637  4950 net.cpp:122] Setting up conv1/bn
I0617 03:45:46.540662  4950 net.cpp:129] Top shape: 50 32 112 112 (20070400)
I0617 03:45:46.540670  4950 net.cpp:137] Memory required for data: 190669000
I0617 03:45:46.540691  4950 layer_factory.hpp:77] Creating layer conv1/scale
I0617 03:45:46.540711  4950 net.cpp:84] Creating Layer conv1/scale
I0617 03:45:46.540721  4950 net.cpp:406] conv1/scale <- conv1
I0617 03:45:46.540732  4950 net.cpp:367] conv1/scale -> conv1 (in-place)
I0617 03:45:46.540797  4950 layer_factory.hpp:77] Creating layer conv1/scale
I0617 03:45:46.540952  4950 net.cpp:122] Setting up conv1/scale
I0617 03:45:46.540971  4950 net.cpp:129] Top shape: 50 32 112 112 (20070400)
I0617 03:45:46.540979  4950 net.cpp:137] Memory required for data: 270950600
I0617 03:45:46.540995  4950 layer_factory.hpp:77] Creating layer relu1
I0617 03:45:46.541013  4950 net.cpp:84] Creating Layer relu1
I0617 03:45:46.541021  4950 net.cpp:406] relu1 <- conv1
I0617 03:45:46.541033  4950 net.cpp:367] relu1 -> conv1 (in-place)
I0617 03:45:46.541453  4950 net.cpp:122] Setting up relu1
I0617 03:45:46.541476  4950 net.cpp:129] Top shape: 50 32 112 112 (20070400)
I0617 03:45:46.541484  4950 net.cpp:137] Memory required for data: 351232200
I0617 03:45:46.541493  4950 layer_factory.hpp:77] Creating layer conv2_1/dw
I0617 03:45:46.541519  4950 net.cpp:84] Creating Layer conv2_1/dw
I0617 03:45:46.541532  4950 net.cpp:406] conv2_1/dw <- conv1
I0617 03:45:46.541544  4950 net.cpp:380] conv2_1/dw -> conv2_1/dw
I0617 03:45:46.544068  4950 net.cpp:122] Setting up conv2_1/dw
I0617 03:45:46.544092  4950 net.cpp:129] Top shape: 50 32 112 112 (20070400)
I0617 03:45:46.544101  4950 net.cpp:137] Memory required for data: 431513800
I0617 03:45:46.544112  4950 layer_factory.hpp:77] Creating layer conv2_1/dw/bn
I0617 03:45:46.544126  4950 net.cpp:84] Creating Layer conv2_1/dw/bn
I0617 03:45:46.544155  4950 net.cpp:406] conv2_1/dw/bn <- conv2_1/dw
I0617 03:45:46.544167  4950 net.cpp:367] conv2_1/dw/bn -> conv2_1/dw (in-place)
I0617 03:45:46.544410  4950 net.cpp:122] Setting up conv2_1/dw/bn
I0617 03:45:46.544427  4950 net.cpp:129] Top shape: 50 32 112 112 (20070400)
I0617 03:45:46.544435  4950 net.cpp:137] Memory required for data: 511795400
I0617 03:45:46.544457  4950 layer_factory.hpp:77] Creating layer conv2_1/dw/scale
I0617 03:45:46.544471  4950 net.cpp:84] Creating Layer conv2_1/dw/scale
I0617 03:45:46.544481  4950 net.cpp:406] conv2_1/dw/scale <- conv2_1/dw
I0617 03:45:46.544494  4950 net.cpp:367] conv2_1/dw/scale -> conv2_1/dw (in-place)
I0617 03:45:46.544559  4950 layer_factory.hpp:77] Creating layer conv2_1/dw/scale
I0617 03:45:46.544718  4950 net.cpp:122] Setting up conv2_1/dw/scale
I0617 03:45:46.544735  4950 net.cpp:129] Top shape: 50 32 112 112 (20070400)
I0617 03:45:46.544744  4950 net.cpp:137] Memory required for data: 592077000
I0617 03:45:46.544755  4950 layer_factory.hpp:77] Creating layer relu2_1/dw
I0617 03:45:46.544772  4950 net.cpp:84] Creating Layer relu2_1/dw
I0617 03:45:46.544781  4950 net.cpp:406] relu2_1/dw <- conv2_1/dw
I0617 03:45:46.544791  4950 net.cpp:367] relu2_1/dw -> conv2_1/dw (in-place)
I0617 03:45:46.545013  4950 net.cpp:122] Setting up relu2_1/dw
I0617 03:45:46.545032  4950 net.cpp:129] Top shape: 50 32 112 112 (20070400)
I0617 03:45:46.545042  4950 net.cpp:137] Memory required for data: 672358600
I0617 03:45:46.545049  4950 layer_factory.hpp:77] Creating layer conv2_1/sep
I0617 03:45:46.545071  4950 net.cpp:84] Creating Layer conv2_1/sep
I0617 03:45:46.545081  4950 net.cpp:406] conv2_1/sep <- conv2_1/dw
I0617 03:45:46.545094  4950 net.cpp:380] conv2_1/sep -> conv2_1/sep
I0617 03:45:46.547283  4950 net.cpp:122] Setting up conv2_1/sep
I0617 03:45:46.547309  4950 net.cpp:129] Top shape: 50 64 112 112 (40140800)
I0617 03:45:46.547318  4950 net.cpp:137] Memory required for data: 832921800
I0617 03:45:46.547330  4950 layer_factory.hpp:77] Creating layer conv2_1/sep/bn
I0617 03:45:46.547343  4950 net.cpp:84] Creating Layer conv2_1/sep/bn
I0617 03:45:46.547353  4950 net.cpp:406] conv2_1/sep/bn <- conv2_1/sep
I0617 03:45:46.547369  4950 net.cpp:367] conv2_1/sep/bn -> conv2_1/sep (in-place)
I0617 03:45:46.547624  4950 net.cpp:122] Setting up conv2_1/sep/bn
I0617 03:45:46.547643  4950 net.cpp:129] Top shape: 50 64 112 112 (40140800)
I0617 03:45:46.547652  4950 net.cpp:137] Memory required for data: 993485000
I0617 03:45:46.547667  4950 layer_factory.hpp:77] Creating layer conv2_1/sep/scale
I0617 03:45:46.547679  4950 net.cpp:84] Creating Layer conv2_1/sep/scale
I0617 03:45:46.547688  4950 net.cpp:406] conv2_1/sep/scale <- conv2_1/sep
I0617 03:45:46.547703  4950 net.cpp:367] conv2_1/sep/scale -> conv2_1/sep (in-place)
I0617 03:45:46.547756  4950 layer_factory.hpp:77] Creating layer conv2_1/sep/scale
I0617 03:45:46.547914  4950 net.cpp:122] Setting up conv2_1/sep/scale
I0617 03:45:46.547935  4950 net.cpp:129] Top shape: 50 64 112 112 (40140800)
I0617 03:45:46.547945  4950 net.cpp:137] Memory required for data: 1154048200
I0617 03:45:46.547961  4950 layer_factory.hpp:77] Creating layer relu2_1/sep
I0617 03:45:46.547973  4950 net.cpp:84] Creating Layer relu2_1/sep
I0617 03:45:46.547982  4950 net.cpp:406] relu2_1/sep <- conv2_1/sep
I0617 03:45:46.547992  4950 net.cpp:367] relu2_1/sep -> conv2_1/sep (in-place)
I0617 03:45:46.548418  4950 net.cpp:122] Setting up relu2_1/sep
I0617 03:45:46.548440  4950 net.cpp:129] Top shape: 50 64 112 112 (40140800)
I0617 03:45:46.548449  4950 net.cpp:137] Memory required for data: 1314611400
I0617 03:45:46.548458  4950 layer_factory.hpp:77] Creating layer conv2_2/dw
I0617 03:45:46.548478  4950 net.cpp:84] Creating Layer conv2_2/dw
I0617 03:45:46.548490  4950 net.cpp:406] conv2_2/dw <- conv2_1/sep
I0617 03:45:46.548504  4950 net.cpp:380] conv2_2/dw -> conv2_2/dw
I0617 03:45:46.549576  4950 net.cpp:122] Setting up conv2_2/dw
I0617 03:45:46.549598  4950 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0617 03:45:46.549607  4950 net.cpp:137] Memory required for data: 1354752200
I0617 03:45:46.549628  4950 layer_factory.hpp:77] Creating layer conv2_2/dw/bn
I0617 03:45:46.549643  4950 net.cpp:84] Creating Layer conv2_2/dw/bn
I0617 03:45:46.549651  4950 net.cpp:406] conv2_2/dw/bn <- conv2_2/dw
I0617 03:45:46.549666  4950 net.cpp:367] conv2_2/dw/bn -> conv2_2/dw (in-place)
I0617 03:45:46.549901  4950 net.cpp:122] Setting up conv2_2/dw/bn
I0617 03:45:46.549916  4950 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0617 03:45:46.549926  4950 net.cpp:137] Memory required for data: 1394893000
I0617 03:45:46.549939  4950 layer_factory.hpp:77] Creating layer conv2_2/dw/scale
I0617 03:45:46.549952  4950 net.cpp:84] Creating Layer conv2_2/dw/scale
I0617 03:45:46.549960  4950 net.cpp:406] conv2_2/dw/scale <- conv2_2/dw
I0617 03:45:46.549974  4950 net.cpp:367] conv2_2/dw/scale -> conv2_2/dw (in-place)
I0617 03:45:46.550029  4950 layer_factory.hpp:77] Creating layer conv2_2/dw/scale
I0617 03:45:46.550187  4950 net.cpp:122] Setting up conv2_2/dw/scale
I0617 03:45:46.550204  4950 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0617 03:45:46.550263  4950 net.cpp:137] Memory required for data: 1435033800
I0617 03:45:46.550281  4950 layer_factory.hpp:77] Creating layer relu2_2/dw
I0617 03:45:46.550294  4950 net.cpp:84] Creating Layer relu2_2/dw
I0617 03:45:46.550303  4950 net.cpp:406] relu2_2/dw <- conv2_2/dw
I0617 03:45:46.550318  4950 net.cpp:367] relu2_2/dw -> conv2_2/dw (in-place)
I0617 03:45:46.550560  4950 net.cpp:122] Setting up relu2_2/dw
I0617 03:45:46.550581  4950 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0617 03:45:46.550590  4950 net.cpp:137] Memory required for data: 1475174600
I0617 03:45:46.550598  4950 layer_factory.hpp:77] Creating layer conv2_2/sep
I0617 03:45:46.550617  4950 net.cpp:84] Creating Layer conv2_2/sep
I0617 03:45:46.550634  4950 net.cpp:406] conv2_2/sep <- conv2_2/dw
I0617 03:45:46.550652  4950 net.cpp:380] conv2_2/sep -> conv2_2/sep
I0617 03:45:46.552099  4950 net.cpp:122] Setting up conv2_2/sep
I0617 03:45:46.552127  4950 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0617 03:45:46.552137  4950 net.cpp:137] Memory required for data: 1555456200
I0617 03:45:46.552148  4950 layer_factory.hpp:77] Creating layer conv2_2/sep/bn
I0617 03:45:46.552161  4950 net.cpp:84] Creating Layer conv2_2/sep/bn
I0617 03:45:46.552170  4950 net.cpp:406] conv2_2/sep/bn <- conv2_2/sep
I0617 03:45:46.552184  4950 net.cpp:367] conv2_2/sep/bn -> conv2_2/sep (in-place)
I0617 03:45:46.552420  4950 net.cpp:122] Setting up conv2_2/sep/bn
I0617 03:45:46.552436  4950 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0617 03:45:46.552445  4950 net.cpp:137] Memory required for data: 1635737800
I0617 03:45:46.552459  4950 layer_factory.hpp:77] Creating layer conv2_2/sep/scale
I0617 03:45:46.552472  4950 net.cpp:84] Creating Layer conv2_2/sep/scale
I0617 03:45:46.552480  4950 net.cpp:406] conv2_2/sep/scale <- conv2_2/sep
I0617 03:45:46.552491  4950 net.cpp:367] conv2_2/sep/scale -> conv2_2/sep (in-place)
I0617 03:45:46.552556  4950 layer_factory.hpp:77] Creating layer conv2_2/sep/scale
I0617 03:45:46.552707  4950 net.cpp:122] Setting up conv2_2/sep/scale
I0617 03:45:46.552724  4950 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0617 03:45:46.552733  4950 net.cpp:137] Memory required for data: 1716019400
I0617 03:45:46.552747  4950 layer_factory.hpp:77] Creating layer relu2_2/sep
I0617 03:45:46.552757  4950 net.cpp:84] Creating Layer relu2_2/sep
I0617 03:45:46.552767  4950 net.cpp:406] relu2_2/sep <- conv2_2/sep
I0617 03:45:46.552776  4950 net.cpp:367] relu2_2/sep -> conv2_2/sep (in-place)
I0617 03:45:46.553010  4950 net.cpp:122] Setting up relu2_2/sep
I0617 03:45:46.553030  4950 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0617 03:45:46.553038  4950 net.cpp:137] Memory required for data: 1796301000
I0617 03:45:46.553046  4950 layer_factory.hpp:77] Creating layer conv3_1/dw
I0617 03:45:46.553066  4950 net.cpp:84] Creating Layer conv3_1/dw
I0617 03:45:46.553076  4950 net.cpp:406] conv3_1/dw <- conv2_2/sep
I0617 03:45:46.553088  4950 net.cpp:380] conv3_1/dw -> conv3_1/dw
I0617 03:45:46.554167  4950 net.cpp:122] Setting up conv3_1/dw
I0617 03:45:46.554200  4950 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0617 03:45:46.554210  4950 net.cpp:137] Memory required for data: 1876582600
I0617 03:45:46.554220  4950 layer_factory.hpp:77] Creating layer conv3_1/dw/bn
I0617 03:45:46.554236  4950 net.cpp:84] Creating Layer conv3_1/dw/bn
I0617 03:45:46.554246  4950 net.cpp:406] conv3_1/dw/bn <- conv3_1/dw
I0617 03:45:46.554257  4950 net.cpp:367] conv3_1/dw/bn -> conv3_1/dw (in-place)
I0617 03:45:46.554483  4950 net.cpp:122] Setting up conv3_1/dw/bn
I0617 03:45:46.554502  4950 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0617 03:45:46.554509  4950 net.cpp:137] Memory required for data: 1956864200
I0617 03:45:46.554538  4950 layer_factory.hpp:77] Creating layer conv3_1/dw/scale
I0617 03:45:46.554555  4950 net.cpp:84] Creating Layer conv3_1/dw/scale
I0617 03:45:46.554565  4950 net.cpp:406] conv3_1/dw/scale <- conv3_1/dw
I0617 03:45:46.554576  4950 net.cpp:367] conv3_1/dw/scale -> conv3_1/dw (in-place)
I0617 03:45:46.554637  4950 layer_factory.hpp:77] Creating layer conv3_1/dw/scale
I0617 03:45:46.554790  4950 net.cpp:122] Setting up conv3_1/dw/scale
I0617 03:45:46.554806  4950 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0617 03:45:46.554814  4950 net.cpp:137] Memory required for data: 2037145800
I0617 03:45:46.554826  4950 layer_factory.hpp:77] Creating layer relu3_1/dw
I0617 03:45:46.554838  4950 net.cpp:84] Creating Layer relu3_1/dw
I0617 03:45:46.554847  4950 net.cpp:406] relu3_1/dw <- conv3_1/dw
I0617 03:45:46.554860  4950 net.cpp:367] relu3_1/dw -> conv3_1/dw (in-place)
I0617 03:45:46.555297  4950 net.cpp:122] Setting up relu3_1/dw
I0617 03:45:46.555320  4950 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0617 03:45:46.555337  4950 net.cpp:137] Memory required for data: 2117427400
I0617 03:45:46.555346  4950 layer_factory.hpp:77] Creating layer conv3_1/sep
I0617 03:45:46.555366  4950 net.cpp:84] Creating Layer conv3_1/sep
I0617 03:45:46.555377  4950 net.cpp:406] conv3_1/sep <- conv3_1/dw
I0617 03:45:46.555388  4950 net.cpp:380] conv3_1/sep -> conv3_1/sep
I0617 03:45:46.557188  4950 net.cpp:122] Setting up conv3_1/sep
I0617 03:45:46.557214  4950 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0617 03:45:46.557222  4950 net.cpp:137] Memory required for data: 2197709000
I0617 03:45:46.557234  4950 layer_factory.hpp:77] Creating layer conv3_1/sep/bn
I0617 03:45:46.557250  4950 net.cpp:84] Creating Layer conv3_1/sep/bn
I0617 03:45:46.557260  4950 net.cpp:406] conv3_1/sep/bn <- conv3_1/sep
I0617 03:45:46.557271  4950 net.cpp:367] conv3_1/sep/bn -> conv3_1/sep (in-place)
I0617 03:45:46.557510  4950 net.cpp:122] Setting up conv3_1/sep/bn
I0617 03:45:46.557538  4950 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0617 03:45:46.557545  4950 net.cpp:137] Memory required for data: 2277990600
I0617 03:45:46.557559  4950 layer_factory.hpp:77] Creating layer conv3_1/sep/scale
I0617 03:45:46.557575  4950 net.cpp:84] Creating Layer conv3_1/sep/scale
I0617 03:45:46.557585  4950 net.cpp:406] conv3_1/sep/scale <- conv3_1/sep
I0617 03:45:46.557596  4950 net.cpp:367] conv3_1/sep/scale -> conv3_1/sep (in-place)
I0617 03:45:46.557654  4950 layer_factory.hpp:77] Creating layer conv3_1/sep/scale
I0617 03:45:46.557806  4950 net.cpp:122] Setting up conv3_1/sep/scale
I0617 03:45:46.557822  4950 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0617 03:45:46.557832  4950 net.cpp:137] Memory required for data: 2358272200
I0617 03:45:46.557843  4950 layer_factory.hpp:77] Creating layer relu3_1/sep
I0617 03:45:46.557854  4950 net.cpp:84] Creating Layer relu3_1/sep
I0617 03:45:46.557863  4950 net.cpp:406] relu3_1/sep <- conv3_1/sep
I0617 03:45:46.557876  4950 net.cpp:367] relu3_1/sep -> conv3_1/sep (in-place)
I0617 03:45:46.558115  4950 net.cpp:122] Setting up relu3_1/sep
I0617 03:45:46.558133  4950 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0617 03:45:46.558142  4950 net.cpp:137] Memory required for data: 2438553800
I0617 03:45:46.558151  4950 layer_factory.hpp:77] Creating layer conv3_2/dw
I0617 03:45:46.558167  4950 net.cpp:84] Creating Layer conv3_2/dw
I0617 03:45:46.558187  4950 net.cpp:406] conv3_2/dw <- conv3_1/sep
I0617 03:45:46.558203  4950 net.cpp:380] conv3_2/dw -> conv3_2/dw
I0617 03:45:46.559188  4950 net.cpp:122] Setting up conv3_2/dw
I0617 03:45:46.559214  4950 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0617 03:45:46.559224  4950 net.cpp:137] Memory required for data: 2458624200
I0617 03:45:46.559234  4950 layer_factory.hpp:77] Creating layer conv3_2/dw/bn
I0617 03:45:46.559247  4950 net.cpp:84] Creating Layer conv3_2/dw/bn
I0617 03:45:46.559257  4950 net.cpp:406] conv3_2/dw/bn <- conv3_2/dw
I0617 03:45:46.559270  4950 net.cpp:367] conv3_2/dw/bn -> conv3_2/dw (in-place)
I0617 03:45:46.559511  4950 net.cpp:122] Setting up conv3_2/dw/bn
I0617 03:45:46.559537  4950 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0617 03:45:46.559545  4950 net.cpp:137] Memory required for data: 2478694600
I0617 03:45:46.559559  4950 layer_factory.hpp:77] Creating layer conv3_2/dw/scale
I0617 03:45:46.559571  4950 net.cpp:84] Creating Layer conv3_2/dw/scale
I0617 03:45:46.559581  4950 net.cpp:406] conv3_2/dw/scale <- conv3_2/dw
I0617 03:45:46.559592  4950 net.cpp:367] conv3_2/dw/scale -> conv3_2/dw (in-place)
I0617 03:45:46.559649  4950 layer_factory.hpp:77] Creating layer conv3_2/dw/scale
I0617 03:45:46.559803  4950 net.cpp:122] Setting up conv3_2/dw/scale
I0617 03:45:46.559819  4950 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0617 03:45:46.559828  4950 net.cpp:137] Memory required for data: 2498765000
I0617 03:45:46.559840  4950 layer_factory.hpp:77] Creating layer relu3_2/dw
I0617 03:45:46.559857  4950 net.cpp:84] Creating Layer relu3_2/dw
I0617 03:45:46.559867  4950 net.cpp:406] relu3_2/dw <- conv3_2/dw
I0617 03:45:46.559880  4950 net.cpp:367] relu3_2/dw -> conv3_2/dw (in-place)
I0617 03:45:46.560333  4950 net.cpp:122] Setting up relu3_2/dw
I0617 03:45:46.560354  4950 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0617 03:45:46.560364  4950 net.cpp:137] Memory required for data: 2518835400
I0617 03:45:46.560372  4950 layer_factory.hpp:77] Creating layer conv3_2/sep
I0617 03:45:46.560390  4950 net.cpp:84] Creating Layer conv3_2/sep
I0617 03:45:46.560401  4950 net.cpp:406] conv3_2/sep <- conv3_2/dw
I0617 03:45:46.560416  4950 net.cpp:380] conv3_2/sep -> conv3_2/sep
I0617 03:45:46.562214  4950 net.cpp:122] Setting up conv3_2/sep
I0617 03:45:46.562238  4950 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0617 03:45:46.562247  4950 net.cpp:137] Memory required for data: 2558976200
I0617 03:45:46.562258  4950 layer_factory.hpp:77] Creating layer conv3_2/sep/bn
I0617 03:45:46.562274  4950 net.cpp:84] Creating Layer conv3_2/sep/bn
I0617 03:45:46.562284  4950 net.cpp:406] conv3_2/sep/bn <- conv3_2/sep
I0617 03:45:46.562296  4950 net.cpp:367] conv3_2/sep/bn -> conv3_2/sep (in-place)
I0617 03:45:46.562547  4950 net.cpp:122] Setting up conv3_2/sep/bn
I0617 03:45:46.562566  4950 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0617 03:45:46.562574  4950 net.cpp:137] Memory required for data: 2599117000
I0617 03:45:46.562588  4950 layer_factory.hpp:77] Creating layer conv3_2/sep/scale
I0617 03:45:46.562605  4950 net.cpp:84] Creating Layer conv3_2/sep/scale
I0617 03:45:46.562614  4950 net.cpp:406] conv3_2/sep/scale <- conv3_2/sep
I0617 03:45:46.562625  4950 net.cpp:367] conv3_2/sep/scale -> conv3_2/sep (in-place)
I0617 03:45:46.562685  4950 layer_factory.hpp:77] Creating layer conv3_2/sep/scale
I0617 03:45:46.562836  4950 net.cpp:122] Setting up conv3_2/sep/scale
I0617 03:45:46.562853  4950 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0617 03:45:46.562862  4950 net.cpp:137] Memory required for data: 2639257800
I0617 03:45:46.562875  4950 layer_factory.hpp:77] Creating layer relu3_2/sep
I0617 03:45:46.562889  4950 net.cpp:84] Creating Layer relu3_2/sep
I0617 03:45:46.562898  4950 net.cpp:406] relu3_2/sep <- conv3_2/sep
I0617 03:45:46.562909  4950 net.cpp:367] relu3_2/sep -> conv3_2/sep (in-place)
I0617 03:45:46.563127  4950 net.cpp:122] Setting up relu3_2/sep
I0617 03:45:46.563146  4950 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0617 03:45:46.563172  4950 net.cpp:137] Memory required for data: 2679398600
I0617 03:45:46.563181  4950 layer_factory.hpp:77] Creating layer conv4_1/dw
I0617 03:45:46.563199  4950 net.cpp:84] Creating Layer conv4_1/dw
I0617 03:45:46.563208  4950 net.cpp:406] conv4_1/dw <- conv3_2/sep
I0617 03:45:46.563225  4950 net.cpp:380] conv4_1/dw -> conv4_1/dw
I0617 03:45:46.563405  4950 net.cpp:122] Setting up conv4_1/dw
I0617 03:45:46.563424  4950 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0617 03:45:46.563432  4950 net.cpp:137] Memory required for data: 2719539400
I0617 03:45:46.563442  4950 layer_factory.hpp:77] Creating layer conv4_1/dw/bn
I0617 03:45:46.563458  4950 net.cpp:84] Creating Layer conv4_1/dw/bn
I0617 03:45:46.563467  4950 net.cpp:406] conv4_1/dw/bn <- conv4_1/dw
I0617 03:45:46.563477  4950 net.cpp:367] conv4_1/dw/bn -> conv4_1/dw (in-place)
I0617 03:45:46.563719  4950 net.cpp:122] Setting up conv4_1/dw/bn
I0617 03:45:46.563738  4950 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0617 03:45:46.563746  4950 net.cpp:137] Memory required for data: 2759680200
I0617 03:45:46.563760  4950 layer_factory.hpp:77] Creating layer conv4_1/dw/scale
I0617 03:45:46.563772  4950 net.cpp:84] Creating Layer conv4_1/dw/scale
I0617 03:45:46.563781  4950 net.cpp:406] conv4_1/dw/scale <- conv4_1/dw
I0617 03:45:46.563796  4950 net.cpp:367] conv4_1/dw/scale -> conv4_1/dw (in-place)
I0617 03:45:46.563850  4950 layer_factory.hpp:77] Creating layer conv4_1/dw/scale
I0617 03:45:46.564003  4950 net.cpp:122] Setting up conv4_1/dw/scale
I0617 03:45:46.564024  4950 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0617 03:45:46.564033  4950 net.cpp:137] Memory required for data: 2799821000
I0617 03:45:46.564045  4950 layer_factory.hpp:77] Creating layer relu4_1/dw
I0617 03:45:46.564064  4950 net.cpp:84] Creating Layer relu4_1/dw
I0617 03:45:46.564074  4950 net.cpp:406] relu4_1/dw <- conv4_1/dw
I0617 03:45:46.564083  4950 net.cpp:367] relu4_1/dw -> conv4_1/dw (in-place)
I0617 03:45:46.564522  4950 net.cpp:122] Setting up relu4_1/dw
I0617 03:45:46.564544  4950 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0617 03:45:46.564553  4950 net.cpp:137] Memory required for data: 2839961800
I0617 03:45:46.564561  4950 layer_factory.hpp:77] Creating layer conv4_1/sep
I0617 03:45:46.564580  4950 net.cpp:84] Creating Layer conv4_1/sep
I0617 03:45:46.564590  4950 net.cpp:406] conv4_1/sep <- conv4_1/dw
I0617 03:45:46.564606  4950 net.cpp:380] conv4_1/sep -> conv4_1/sep
I0617 03:45:46.566669  4950 net.cpp:122] Setting up conv4_1/sep
I0617 03:45:46.566694  4950 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0617 03:45:46.566702  4950 net.cpp:137] Memory required for data: 2880102600
I0617 03:45:46.566714  4950 layer_factory.hpp:77] Creating layer conv4_1/sep/bn
I0617 03:45:46.566740  4950 net.cpp:84] Creating Layer conv4_1/sep/bn
I0617 03:45:46.566750  4950 net.cpp:406] conv4_1/sep/bn <- conv4_1/sep
I0617 03:45:46.566761  4950 net.cpp:367] conv4_1/sep/bn -> conv4_1/sep (in-place)
I0617 03:45:46.567003  4950 net.cpp:122] Setting up conv4_1/sep/bn
I0617 03:45:46.567020  4950 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0617 03:45:46.567028  4950 net.cpp:137] Memory required for data: 2920243400
I0617 03:45:46.567044  4950 layer_factory.hpp:77] Creating layer conv4_1/sep/scale
I0617 03:45:46.567059  4950 net.cpp:84] Creating Layer conv4_1/sep/scale
I0617 03:45:46.567068  4950 net.cpp:406] conv4_1/sep/scale <- conv4_1/sep
I0617 03:45:46.567080  4950 net.cpp:367] conv4_1/sep/scale -> conv4_1/sep (in-place)
I0617 03:45:46.567138  4950 layer_factory.hpp:77] Creating layer conv4_1/sep/scale
I0617 03:45:46.567292  4950 net.cpp:122] Setting up conv4_1/sep/scale
I0617 03:45:46.567309  4950 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0617 03:45:46.567317  4950 net.cpp:137] Memory required for data: 2960384200
I0617 03:45:46.567344  4950 layer_factory.hpp:77] Creating layer relu4_1/sep
I0617 03:45:46.567358  4950 net.cpp:84] Creating Layer relu4_1/sep
I0617 03:45:46.567366  4950 net.cpp:406] relu4_1/sep <- conv4_1/sep
I0617 03:45:46.567378  4950 net.cpp:367] relu4_1/sep -> conv4_1/sep (in-place)
I0617 03:45:46.567840  4950 net.cpp:122] Setting up relu4_1/sep
I0617 03:45:46.567862  4950 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0617 03:45:46.567872  4950 net.cpp:137] Memory required for data: 3000525000
I0617 03:45:46.567880  4950 layer_factory.hpp:77] Creating layer conv4_2/dw
I0617 03:45:46.567898  4950 net.cpp:84] Creating Layer conv4_2/dw
I0617 03:45:46.567908  4950 net.cpp:406] conv4_2/dw <- conv4_1/sep
I0617 03:45:46.567922  4950 net.cpp:380] conv4_2/dw -> conv4_2/dw
I0617 03:45:46.568091  4950 net.cpp:122] Setting up conv4_2/dw
I0617 03:45:46.568109  4950 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0617 03:45:46.568117  4950 net.cpp:137] Memory required for data: 3010560200
I0617 03:45:46.568128  4950 layer_factory.hpp:77] Creating layer conv4_2/dw/bn
I0617 03:45:46.568150  4950 net.cpp:84] Creating Layer conv4_2/dw/bn
I0617 03:45:46.568161  4950 net.cpp:406] conv4_2/dw/bn <- conv4_2/dw
I0617 03:45:46.568173  4950 net.cpp:367] conv4_2/dw/bn -> conv4_2/dw (in-place)
I0617 03:45:46.568409  4950 net.cpp:122] Setting up conv4_2/dw/bn
I0617 03:45:46.568425  4950 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0617 03:45:46.568434  4950 net.cpp:137] Memory required for data: 3020595400
I0617 03:45:46.568447  4950 layer_factory.hpp:77] Creating layer conv4_2/dw/scale
I0617 03:45:46.568460  4950 net.cpp:84] Creating Layer conv4_2/dw/scale
I0617 03:45:46.568469  4950 net.cpp:406] conv4_2/dw/scale <- conv4_2/dw
I0617 03:45:46.568483  4950 net.cpp:367] conv4_2/dw/scale -> conv4_2/dw (in-place)
I0617 03:45:46.568547  4950 layer_factory.hpp:77] Creating layer conv4_2/dw/scale
I0617 03:45:46.568702  4950 net.cpp:122] Setting up conv4_2/dw/scale
I0617 03:45:46.568719  4950 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0617 03:45:46.568735  4950 net.cpp:137] Memory required for data: 3030630600
I0617 03:45:46.568747  4950 layer_factory.hpp:77] Creating layer relu4_2/dw
I0617 03:45:46.568759  4950 net.cpp:84] Creating Layer relu4_2/dw
I0617 03:45:46.568768  4950 net.cpp:406] relu4_2/dw <- conv4_2/dw
I0617 03:45:46.568778  4950 net.cpp:367] relu4_2/dw -> conv4_2/dw (in-place)
I0617 03:45:46.569205  4950 net.cpp:122] Setting up relu4_2/dw
I0617 03:45:46.569226  4950 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0617 03:45:46.569236  4950 net.cpp:137] Memory required for data: 3040665800
I0617 03:45:46.569244  4950 layer_factory.hpp:77] Creating layer conv4_2/sep
I0617 03:45:46.569263  4950 net.cpp:84] Creating Layer conv4_2/sep
I0617 03:45:46.569273  4950 net.cpp:406] conv4_2/sep <- conv4_2/dw
I0617 03:45:46.569291  4950 net.cpp:380] conv4_2/sep -> conv4_2/sep
I0617 03:45:46.573369  4950 net.cpp:122] Setting up conv4_2/sep
I0617 03:45:46.573395  4950 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 03:45:46.573405  4950 net.cpp:137] Memory required for data: 3060736200
I0617 03:45:46.573416  4950 layer_factory.hpp:77] Creating layer conv4_2/sep/bn
I0617 03:45:46.573432  4950 net.cpp:84] Creating Layer conv4_2/sep/bn
I0617 03:45:46.573442  4950 net.cpp:406] conv4_2/sep/bn <- conv4_2/sep
I0617 03:45:46.573454  4950 net.cpp:367] conv4_2/sep/bn -> conv4_2/sep (in-place)
I0617 03:45:46.573719  4950 net.cpp:122] Setting up conv4_2/sep/bn
I0617 03:45:46.573737  4950 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 03:45:46.573746  4950 net.cpp:137] Memory required for data: 3080806600
I0617 03:45:46.573760  4950 layer_factory.hpp:77] Creating layer conv4_2/sep/scale
I0617 03:45:46.573779  4950 net.cpp:84] Creating Layer conv4_2/sep/scale
I0617 03:45:46.573791  4950 net.cpp:406] conv4_2/sep/scale <- conv4_2/sep
I0617 03:45:46.573801  4950 net.cpp:367] conv4_2/sep/scale -> conv4_2/sep (in-place)
I0617 03:45:46.573859  4950 layer_factory.hpp:77] Creating layer conv4_2/sep/scale
I0617 03:45:46.574013  4950 net.cpp:122] Setting up conv4_2/sep/scale
I0617 03:45:46.574030  4950 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 03:45:46.574038  4950 net.cpp:137] Memory required for data: 3100877000
I0617 03:45:46.574051  4950 layer_factory.hpp:77] Creating layer relu4_2/sep
I0617 03:45:46.574079  4950 net.cpp:84] Creating Layer relu4_2/sep
I0617 03:45:46.574090  4950 net.cpp:406] relu4_2/sep <- conv4_2/sep
I0617 03:45:46.574100  4950 net.cpp:367] relu4_2/sep -> conv4_2/sep (in-place)
I0617 03:45:46.574538  4950 net.cpp:122] Setting up relu4_2/sep
I0617 03:45:46.574561  4950 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 03:45:46.574570  4950 net.cpp:137] Memory required for data: 3120947400
I0617 03:45:46.574579  4950 layer_factory.hpp:77] Creating layer conv5_1/dw
I0617 03:45:46.574597  4950 net.cpp:84] Creating Layer conv5_1/dw
I0617 03:45:46.574609  4950 net.cpp:406] conv5_1/dw <- conv4_2/sep
I0617 03:45:46.574620  4950 net.cpp:380] conv5_1/dw -> conv5_1/dw
I0617 03:45:46.574831  4950 net.cpp:122] Setting up conv5_1/dw
I0617 03:45:46.574849  4950 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 03:45:46.574857  4950 net.cpp:137] Memory required for data: 3141017800
I0617 03:45:46.574868  4950 layer_factory.hpp:77] Creating layer conv5_1/dw/bn
I0617 03:45:46.574883  4950 net.cpp:84] Creating Layer conv5_1/dw/bn
I0617 03:45:46.574893  4950 net.cpp:406] conv5_1/dw/bn <- conv5_1/dw
I0617 03:45:46.574904  4950 net.cpp:367] conv5_1/dw/bn -> conv5_1/dw (in-place)
I0617 03:45:46.575152  4950 net.cpp:122] Setting up conv5_1/dw/bn
I0617 03:45:46.575170  4950 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 03:45:46.575177  4950 net.cpp:137] Memory required for data: 3161088200
I0617 03:45:46.575191  4950 layer_factory.hpp:77] Creating layer conv5_1/dw/scale
I0617 03:45:46.575207  4950 net.cpp:84] Creating Layer conv5_1/dw/scale
I0617 03:45:46.575217  4950 net.cpp:406] conv5_1/dw/scale <- conv5_1/dw
I0617 03:45:46.575227  4950 net.cpp:367] conv5_1/dw/scale -> conv5_1/dw (in-place)
I0617 03:45:46.575284  4950 layer_factory.hpp:77] Creating layer conv5_1/dw/scale
I0617 03:45:46.575451  4950 net.cpp:122] Setting up conv5_1/dw/scale
I0617 03:45:46.575469  4950 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 03:45:46.575477  4950 net.cpp:137] Memory required for data: 3181158600
I0617 03:45:46.575489  4950 layer_factory.hpp:77] Creating layer relu5_1/dw
I0617 03:45:46.575503  4950 net.cpp:84] Creating Layer relu5_1/dw
I0617 03:45:46.575520  4950 net.cpp:406] relu5_1/dw <- conv5_1/dw
I0617 03:45:46.575532  4950 net.cpp:367] relu5_1/dw -> conv5_1/dw (in-place)
I0617 03:45:46.575760  4950 net.cpp:122] Setting up relu5_1/dw
I0617 03:45:46.575779  4950 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 03:45:46.575788  4950 net.cpp:137] Memory required for data: 3201229000
I0617 03:45:46.575796  4950 layer_factory.hpp:77] Creating layer conv5_1/sep
I0617 03:45:46.575817  4950 net.cpp:84] Creating Layer conv5_1/sep
I0617 03:45:46.575827  4950 net.cpp:406] conv5_1/sep <- conv5_1/dw
I0617 03:45:46.575840  4950 net.cpp:380] conv5_1/sep -> conv5_1/sep
I0617 03:45:46.581840  4950 net.cpp:122] Setting up conv5_1/sep
I0617 03:45:46.581866  4950 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 03:45:46.581876  4950 net.cpp:137] Memory required for data: 3221299400
I0617 03:45:46.581887  4950 layer_factory.hpp:77] Creating layer conv5_1/sep/bn
I0617 03:45:46.581903  4950 net.cpp:84] Creating Layer conv5_1/sep/bn
I0617 03:45:46.581913  4950 net.cpp:406] conv5_1/sep/bn <- conv5_1/sep
I0617 03:45:46.581924  4950 net.cpp:367] conv5_1/sep/bn -> conv5_1/sep (in-place)
I0617 03:45:46.582180  4950 net.cpp:122] Setting up conv5_1/sep/bn
I0617 03:45:46.582197  4950 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 03:45:46.582206  4950 net.cpp:137] Memory required for data: 3241369800
I0617 03:45:46.582219  4950 layer_factory.hpp:77] Creating layer conv5_1/sep/scale
I0617 03:45:46.582232  4950 net.cpp:84] Creating Layer conv5_1/sep/scale
I0617 03:45:46.582242  4950 net.cpp:406] conv5_1/sep/scale <- conv5_1/sep
I0617 03:45:46.582255  4950 net.cpp:367] conv5_1/sep/scale -> conv5_1/sep (in-place)
I0617 03:45:46.582310  4950 layer_factory.hpp:77] Creating layer conv5_1/sep/scale
I0617 03:45:46.582466  4950 net.cpp:122] Setting up conv5_1/sep/scale
I0617 03:45:46.582486  4950 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 03:45:46.582506  4950 net.cpp:137] Memory required for data: 3261440200
I0617 03:45:46.582527  4950 layer_factory.hpp:77] Creating layer relu5_1/sep
I0617 03:45:46.582541  4950 net.cpp:84] Creating Layer relu5_1/sep
I0617 03:45:46.582551  4950 net.cpp:406] relu5_1/sep <- conv5_1/sep
I0617 03:45:46.582561  4950 net.cpp:367] relu5_1/sep -> conv5_1/sep (in-place)
I0617 03:45:46.583003  4950 net.cpp:122] Setting up relu5_1/sep
I0617 03:45:46.583024  4950 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 03:45:46.583034  4950 net.cpp:137] Memory required for data: 3281510600
I0617 03:45:46.583042  4950 layer_factory.hpp:77] Creating layer conv5_2/dw
I0617 03:45:46.583060  4950 net.cpp:84] Creating Layer conv5_2/dw
I0617 03:45:46.583070  4950 net.cpp:406] conv5_2/dw <- conv5_1/sep
I0617 03:45:46.583084  4950 net.cpp:380] conv5_2/dw -> conv5_2/dw
I0617 03:45:46.583298  4950 net.cpp:122] Setting up conv5_2/dw
I0617 03:45:46.583317  4950 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 03:45:46.583325  4950 net.cpp:137] Memory required for data: 3301581000
I0617 03:45:46.583336  4950 layer_factory.hpp:77] Creating layer conv5_2/dw/bn
I0617 03:45:46.583351  4950 net.cpp:84] Creating Layer conv5_2/dw/bn
I0617 03:45:46.583361  4950 net.cpp:406] conv5_2/dw/bn <- conv5_2/dw
I0617 03:45:46.583374  4950 net.cpp:367] conv5_2/dw/bn -> conv5_2/dw (in-place)
I0617 03:45:46.583636  4950 net.cpp:122] Setting up conv5_2/dw/bn
I0617 03:45:46.583654  4950 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 03:45:46.583662  4950 net.cpp:137] Memory required for data: 3321651400
I0617 03:45:46.583675  4950 layer_factory.hpp:77] Creating layer conv5_2/dw/scale
I0617 03:45:46.583688  4950 net.cpp:84] Creating Layer conv5_2/dw/scale
I0617 03:45:46.583704  4950 net.cpp:406] conv5_2/dw/scale <- conv5_2/dw
I0617 03:45:46.583719  4950 net.cpp:367] conv5_2/dw/scale -> conv5_2/dw (in-place)
I0617 03:45:46.583775  4950 layer_factory.hpp:77] Creating layer conv5_2/dw/scale
I0617 03:45:46.583941  4950 net.cpp:122] Setting up conv5_2/dw/scale
I0617 03:45:46.583958  4950 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 03:45:46.583967  4950 net.cpp:137] Memory required for data: 3341721800
I0617 03:45:46.583979  4950 layer_factory.hpp:77] Creating layer relu5_2/dw
I0617 03:45:46.583999  4950 net.cpp:84] Creating Layer relu5_2/dw
I0617 03:45:46.584009  4950 net.cpp:406] relu5_2/dw <- conv5_2/dw
I0617 03:45:46.584020  4950 net.cpp:367] relu5_2/dw -> conv5_2/dw (in-place)
I0617 03:45:46.584251  4950 net.cpp:122] Setting up relu5_2/dw
I0617 03:45:46.584270  4950 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 03:45:46.584278  4950 net.cpp:137] Memory required for data: 3361792200
I0617 03:45:46.584287  4950 layer_factory.hpp:77] Creating layer conv5_2/sep
I0617 03:45:46.584308  4950 net.cpp:84] Creating Layer conv5_2/sep
I0617 03:45:46.584318  4950 net.cpp:406] conv5_2/sep <- conv5_2/dw
I0617 03:45:46.584331  4950 net.cpp:380] conv5_2/sep -> conv5_2/sep
I0617 03:45:46.590126  4950 net.cpp:122] Setting up conv5_2/sep
I0617 03:45:46.590152  4950 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 03:45:46.590160  4950 net.cpp:137] Memory required for data: 3381862600
I0617 03:45:46.590171  4950 layer_factory.hpp:77] Creating layer conv5_2/sep/bn
I0617 03:45:46.590195  4950 net.cpp:84] Creating Layer conv5_2/sep/bn
I0617 03:45:46.590205  4950 net.cpp:406] conv5_2/sep/bn <- conv5_2/sep
I0617 03:45:46.590217  4950 net.cpp:367] conv5_2/sep/bn -> conv5_2/sep (in-place)
I0617 03:45:46.590474  4950 net.cpp:122] Setting up conv5_2/sep/bn
I0617 03:45:46.590492  4950 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 03:45:46.590500  4950 net.cpp:137] Memory required for data: 3401933000
I0617 03:45:46.590522  4950 layer_factory.hpp:77] Creating layer conv5_2/sep/scale
I0617 03:45:46.590536  4950 net.cpp:84] Creating Layer conv5_2/sep/scale
I0617 03:45:46.590545  4950 net.cpp:406] conv5_2/sep/scale <- conv5_2/sep
I0617 03:45:46.590560  4950 net.cpp:367] conv5_2/sep/scale -> conv5_2/sep (in-place)
I0617 03:45:46.590616  4950 layer_factory.hpp:77] Creating layer conv5_2/sep/scale
I0617 03:45:46.590788  4950 net.cpp:122] Setting up conv5_2/sep/scale
I0617 03:45:46.590809  4950 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 03:45:46.590818  4950 net.cpp:137] Memory required for data: 3422003400
I0617 03:45:46.590831  4950 layer_factory.hpp:77] Creating layer relu5_2/sep
I0617 03:45:46.590842  4950 net.cpp:84] Creating Layer relu5_2/sep
I0617 03:45:46.590852  4950 net.cpp:406] relu5_2/sep <- conv5_2/sep
I0617 03:45:46.590862  4950 net.cpp:367] relu5_2/sep -> conv5_2/sep (in-place)
I0617 03:45:46.591312  4950 net.cpp:122] Setting up relu5_2/sep
I0617 03:45:46.591333  4950 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 03:45:46.591342  4950 net.cpp:137] Memory required for data: 3442073800
I0617 03:45:46.591351  4950 layer_factory.hpp:77] Creating layer conv5_3/dw
I0617 03:45:46.591368  4950 net.cpp:84] Creating Layer conv5_3/dw
I0617 03:45:46.591378  4950 net.cpp:406] conv5_3/dw <- conv5_2/sep
I0617 03:45:46.591394  4950 net.cpp:380] conv5_3/dw -> conv5_3/dw
I0617 03:45:46.591616  4950 net.cpp:122] Setting up conv5_3/dw
I0617 03:45:46.591636  4950 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 03:45:46.591645  4950 net.cpp:137] Memory required for data: 3462144200
I0617 03:45:46.591655  4950 layer_factory.hpp:77] Creating layer conv5_3/dw/bn
I0617 03:45:46.591670  4950 net.cpp:84] Creating Layer conv5_3/dw/bn
I0617 03:45:46.591681  4950 net.cpp:406] conv5_3/dw/bn <- conv5_3/dw
I0617 03:45:46.591693  4950 net.cpp:367] conv5_3/dw/bn -> conv5_3/dw (in-place)
I0617 03:45:46.591944  4950 net.cpp:122] Setting up conv5_3/dw/bn
I0617 03:45:46.591960  4950 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 03:45:46.591969  4950 net.cpp:137] Memory required for data: 3482214600
I0617 03:45:46.591990  4950 layer_factory.hpp:77] Creating layer conv5_3/dw/scale
I0617 03:45:46.592005  4950 net.cpp:84] Creating Layer conv5_3/dw/scale
I0617 03:45:46.592013  4950 net.cpp:406] conv5_3/dw/scale <- conv5_3/dw
I0617 03:45:46.592027  4950 net.cpp:367] conv5_3/dw/scale -> conv5_3/dw (in-place)
I0617 03:45:46.592082  4950 layer_factory.hpp:77] Creating layer conv5_3/dw/scale
I0617 03:45:46.592244  4950 net.cpp:122] Setting up conv5_3/dw/scale
I0617 03:45:46.592262  4950 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 03:45:46.592269  4950 net.cpp:137] Memory required for data: 3502285000
I0617 03:45:46.592281  4950 layer_factory.hpp:77] Creating layer relu5_3/dw
I0617 03:45:46.592293  4950 net.cpp:84] Creating Layer relu5_3/dw
I0617 03:45:46.592303  4950 net.cpp:406] relu5_3/dw <- conv5_3/dw
I0617 03:45:46.592313  4950 net.cpp:367] relu5_3/dw -> conv5_3/dw (in-place)
I0617 03:45:46.592653  4950 net.cpp:122] Setting up relu5_3/dw
I0617 03:45:46.592677  4950 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 03:45:46.592686  4950 net.cpp:137] Memory required for data: 3522355400
I0617 03:45:46.592694  4950 layer_factory.hpp:77] Creating layer conv5_3/sep
I0617 03:45:46.592713  4950 net.cpp:84] Creating Layer conv5_3/sep
I0617 03:45:46.592723  4950 net.cpp:406] conv5_3/sep <- conv5_3/dw
I0617 03:45:46.592736  4950 net.cpp:380] conv5_3/sep -> conv5_3/sep
I0617 03:45:46.598506  4950 net.cpp:122] Setting up conv5_3/sep
I0617 03:45:46.598541  4950 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 03:45:46.598551  4950 net.cpp:137] Memory required for data: 3542425800
I0617 03:45:46.598563  4950 layer_factory.hpp:77] Creating layer conv5_3/sep/bn
I0617 03:45:46.598577  4950 net.cpp:84] Creating Layer conv5_3/sep/bn
I0617 03:45:46.598585  4950 net.cpp:406] conv5_3/sep/bn <- conv5_3/sep
I0617 03:45:46.598600  4950 net.cpp:367] conv5_3/sep/bn -> conv5_3/sep (in-place)
I0617 03:45:46.598871  4950 net.cpp:122] Setting up conv5_3/sep/bn
I0617 03:45:46.598889  4950 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 03:45:46.598897  4950 net.cpp:137] Memory required for data: 3562496200
I0617 03:45:46.598912  4950 layer_factory.hpp:77] Creating layer conv5_3/sep/scale
I0617 03:45:46.598924  4950 net.cpp:84] Creating Layer conv5_3/sep/scale
I0617 03:45:46.598933  4950 net.cpp:406] conv5_3/sep/scale <- conv5_3/sep
I0617 03:45:46.598956  4950 net.cpp:367] conv5_3/sep/scale -> conv5_3/sep (in-place)
I0617 03:45:46.599017  4950 layer_factory.hpp:77] Creating layer conv5_3/sep/scale
I0617 03:45:46.599179  4950 net.cpp:122] Setting up conv5_3/sep/scale
I0617 03:45:46.599198  4950 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 03:45:46.599207  4950 net.cpp:137] Memory required for data: 3582566600
I0617 03:45:46.599220  4950 layer_factory.hpp:77] Creating layer relu5_3/sep
I0617 03:45:46.599231  4950 net.cpp:84] Creating Layer relu5_3/sep
I0617 03:45:46.599241  4950 net.cpp:406] relu5_3/sep <- conv5_3/sep
I0617 03:45:46.599253  4950 net.cpp:367] relu5_3/sep -> conv5_3/sep (in-place)
I0617 03:45:46.599483  4950 net.cpp:122] Setting up relu5_3/sep
I0617 03:45:46.599503  4950 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 03:45:46.599511  4950 net.cpp:137] Memory required for data: 3602637000
I0617 03:45:46.599529  4950 layer_factory.hpp:77] Creating layer conv5_4/dw
I0617 03:45:46.599546  4950 net.cpp:84] Creating Layer conv5_4/dw
I0617 03:45:46.599556  4950 net.cpp:406] conv5_4/dw <- conv5_3/sep
I0617 03:45:46.599568  4950 net.cpp:380] conv5_4/dw -> conv5_4/dw
I0617 03:45:46.599783  4950 net.cpp:122] Setting up conv5_4/dw
I0617 03:45:46.599802  4950 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 03:45:46.599809  4950 net.cpp:137] Memory required for data: 3622707400
I0617 03:45:46.599820  4950 layer_factory.hpp:77] Creating layer conv5_4/dw/bn
I0617 03:45:46.599835  4950 net.cpp:84] Creating Layer conv5_4/dw/bn
I0617 03:45:46.599845  4950 net.cpp:406] conv5_4/dw/bn <- conv5_4/dw
I0617 03:45:46.599855  4950 net.cpp:367] conv5_4/dw/bn -> conv5_4/dw (in-place)
I0617 03:45:46.600106  4950 net.cpp:122] Setting up conv5_4/dw/bn
I0617 03:45:46.600131  4950 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 03:45:46.600139  4950 net.cpp:137] Memory required for data: 3642777800
I0617 03:45:46.600152  4950 layer_factory.hpp:77] Creating layer conv5_4/dw/scale
I0617 03:45:46.600175  4950 net.cpp:84] Creating Layer conv5_4/dw/scale
I0617 03:45:46.600185  4950 net.cpp:406] conv5_4/dw/scale <- conv5_4/dw
I0617 03:45:46.600196  4950 net.cpp:367] conv5_4/dw/scale -> conv5_4/dw (in-place)
I0617 03:45:46.600255  4950 layer_factory.hpp:77] Creating layer conv5_4/dw/scale
I0617 03:45:46.600417  4950 net.cpp:122] Setting up conv5_4/dw/scale
I0617 03:45:46.600435  4950 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 03:45:46.600443  4950 net.cpp:137] Memory required for data: 3662848200
I0617 03:45:46.600455  4950 layer_factory.hpp:77] Creating layer relu5_4/dw
I0617 03:45:46.600466  4950 net.cpp:84] Creating Layer relu5_4/dw
I0617 03:45:46.600476  4950 net.cpp:406] relu5_4/dw <- conv5_4/dw
I0617 03:45:46.600489  4950 net.cpp:367] relu5_4/dw -> conv5_4/dw (in-place)
I0617 03:45:46.600926  4950 net.cpp:122] Setting up relu5_4/dw
I0617 03:45:46.600949  4950 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 03:45:46.600957  4950 net.cpp:137] Memory required for data: 3682918600
I0617 03:45:46.600966  4950 layer_factory.hpp:77] Creating layer conv5_4/sep
I0617 03:45:46.600985  4950 net.cpp:84] Creating Layer conv5_4/sep
I0617 03:45:46.600996  4950 net.cpp:406] conv5_4/sep <- conv5_4/dw
I0617 03:45:46.601011  4950 net.cpp:380] conv5_4/sep -> conv5_4/sep
I0617 03:45:46.606812  4950 net.cpp:122] Setting up conv5_4/sep
I0617 03:45:46.606835  4950 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 03:45:46.606845  4950 net.cpp:137] Memory required for data: 3702989000
I0617 03:45:46.606856  4950 layer_factory.hpp:77] Creating layer conv5_4/sep/bn
I0617 03:45:46.606873  4950 net.cpp:84] Creating Layer conv5_4/sep/bn
I0617 03:45:46.606884  4950 net.cpp:406] conv5_4/sep/bn <- conv5_4/sep
I0617 03:45:46.606894  4950 net.cpp:367] conv5_4/sep/bn -> conv5_4/sep (in-place)
I0617 03:45:46.607162  4950 net.cpp:122] Setting up conv5_4/sep/bn
I0617 03:45:46.607180  4950 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 03:45:46.607188  4950 net.cpp:137] Memory required for data: 3723059400
I0617 03:45:46.607203  4950 layer_factory.hpp:77] Creating layer conv5_4/sep/scale
I0617 03:45:46.607230  4950 net.cpp:84] Creating Layer conv5_4/sep/scale
I0617 03:45:46.607241  4950 net.cpp:406] conv5_4/sep/scale <- conv5_4/sep
I0617 03:45:46.607252  4950 net.cpp:367] conv5_4/sep/scale -> conv5_4/sep (in-place)
I0617 03:45:46.607312  4950 layer_factory.hpp:77] Creating layer conv5_4/sep/scale
I0617 03:45:46.607475  4950 net.cpp:122] Setting up conv5_4/sep/scale
I0617 03:45:46.607493  4950 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 03:45:46.607501  4950 net.cpp:137] Memory required for data: 3743129800
I0617 03:45:46.607522  4950 layer_factory.hpp:77] Creating layer relu5_4/sep
I0617 03:45:46.607538  4950 net.cpp:84] Creating Layer relu5_4/sep
I0617 03:45:46.607548  4950 net.cpp:406] relu5_4/sep <- conv5_4/sep
I0617 03:45:46.607558  4950 net.cpp:367] relu5_4/sep -> conv5_4/sep (in-place)
I0617 03:45:46.607786  4950 net.cpp:122] Setting up relu5_4/sep
I0617 03:45:46.607805  4950 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 03:45:46.607813  4950 net.cpp:137] Memory required for data: 3763200200
I0617 03:45:46.607822  4950 layer_factory.hpp:77] Creating layer conv5_5/dw
I0617 03:45:46.607841  4950 net.cpp:84] Creating Layer conv5_5/dw
I0617 03:45:46.607851  4950 net.cpp:406] conv5_5/dw <- conv5_4/sep
I0617 03:45:46.607867  4950 net.cpp:380] conv5_5/dw -> conv5_5/dw
I0617 03:45:46.608079  4950 net.cpp:122] Setting up conv5_5/dw
I0617 03:45:46.608098  4950 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 03:45:46.608105  4950 net.cpp:137] Memory required for data: 3783270600
I0617 03:45:46.608116  4950 layer_factory.hpp:77] Creating layer conv5_5/dw/bn
I0617 03:45:46.608131  4950 net.cpp:84] Creating Layer conv5_5/dw/bn
I0617 03:45:46.608148  4950 net.cpp:406] conv5_5/dw/bn <- conv5_5/dw
I0617 03:45:46.608163  4950 net.cpp:367] conv5_5/dw/bn -> conv5_5/dw (in-place)
I0617 03:45:46.608460  4950 net.cpp:122] Setting up conv5_5/dw/bn
I0617 03:45:46.608479  4950 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 03:45:46.608489  4950 net.cpp:137] Memory required for data: 3803341000
I0617 03:45:46.608539  4950 layer_factory.hpp:77] Creating layer conv5_5/dw/scale
I0617 03:45:46.608572  4950 net.cpp:84] Creating Layer conv5_5/dw/scale
I0617 03:45:46.608583  4950 net.cpp:406] conv5_5/dw/scale <- conv5_5/dw
I0617 03:45:46.608595  4950 net.cpp:367] conv5_5/dw/scale -> conv5_5/dw (in-place)
I0617 03:45:46.608659  4950 layer_factory.hpp:77] Creating layer conv5_5/dw/scale
I0617 03:45:46.608821  4950 net.cpp:122] Setting up conv5_5/dw/scale
I0617 03:45:46.608839  4950 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 03:45:46.608847  4950 net.cpp:137] Memory required for data: 3823411400
I0617 03:45:46.608860  4950 layer_factory.hpp:77] Creating layer relu5_5/dw
I0617 03:45:46.608870  4950 net.cpp:84] Creating Layer relu5_5/dw
I0617 03:45:46.608880  4950 net.cpp:406] relu5_5/dw <- conv5_5/dw
I0617 03:45:46.608889  4950 net.cpp:367] relu5_5/dw -> conv5_5/dw (in-place)
I0617 03:45:46.609334  4950 net.cpp:122] Setting up relu5_5/dw
I0617 03:45:46.609355  4950 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 03:45:46.609364  4950 net.cpp:137] Memory required for data: 3843481800
I0617 03:45:46.609374  4950 layer_factory.hpp:77] Creating layer conv5_5/sep
I0617 03:45:46.609392  4950 net.cpp:84] Creating Layer conv5_5/sep
I0617 03:45:46.609402  4950 net.cpp:406] conv5_5/sep <- conv5_5/dw
I0617 03:45:46.609421  4950 net.cpp:380] conv5_5/sep -> conv5_5/sep
I0617 03:45:46.615231  4950 net.cpp:122] Setting up conv5_5/sep
I0617 03:45:46.615259  4950 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 03:45:46.615270  4950 net.cpp:137] Memory required for data: 3863552200
I0617 03:45:46.615281  4950 layer_factory.hpp:77] Creating layer conv5_5/sep/bn
I0617 03:45:46.615295  4950 net.cpp:84] Creating Layer conv5_5/sep/bn
I0617 03:45:46.615305  4950 net.cpp:406] conv5_5/sep/bn <- conv5_5/sep
I0617 03:45:46.615320  4950 net.cpp:367] conv5_5/sep/bn -> conv5_5/sep (in-place)
I0617 03:45:46.615608  4950 net.cpp:122] Setting up conv5_5/sep/bn
I0617 03:45:46.615643  4950 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 03:45:46.615653  4950 net.cpp:137] Memory required for data: 3883622600
I0617 03:45:46.615666  4950 layer_factory.hpp:77] Creating layer conv5_5/sep/scale
I0617 03:45:46.615680  4950 net.cpp:84] Creating Layer conv5_5/sep/scale
I0617 03:45:46.615689  4950 net.cpp:406] conv5_5/sep/scale <- conv5_5/sep
I0617 03:45:46.615701  4950 net.cpp:367] conv5_5/sep/scale -> conv5_5/sep (in-place)
I0617 03:45:46.615762  4950 layer_factory.hpp:77] Creating layer conv5_5/sep/scale
I0617 03:45:46.615927  4950 net.cpp:122] Setting up conv5_5/sep/scale
I0617 03:45:46.615945  4950 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 03:45:46.615954  4950 net.cpp:137] Memory required for data: 3903693000
I0617 03:45:46.615967  4950 layer_factory.hpp:77] Creating layer relu5_5/sep
I0617 03:45:46.615978  4950 net.cpp:84] Creating Layer relu5_5/sep
I0617 03:45:46.615993  4950 net.cpp:406] relu5_5/sep <- conv5_5/sep
I0617 03:45:46.616003  4950 net.cpp:367] relu5_5/sep -> conv5_5/sep (in-place)
I0617 03:45:46.616266  4950 net.cpp:122] Setting up relu5_5/sep
I0617 03:45:46.616286  4950 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 03:45:46.616295  4950 net.cpp:137] Memory required for data: 3923763400
I0617 03:45:46.616303  4950 layer_factory.hpp:77] Creating layer conv5_6/dw
I0617 03:45:46.616322  4950 net.cpp:84] Creating Layer conv5_6/dw
I0617 03:45:46.616331  4950 net.cpp:406] conv5_6/dw <- conv5_5/sep
I0617 03:45:46.616344  4950 net.cpp:380] conv5_6/dw -> conv5_6/dw
I0617 03:45:46.616569  4950 net.cpp:122] Setting up conv5_6/dw
I0617 03:45:46.616590  4950 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0617 03:45:46.616597  4950 net.cpp:137] Memory required for data: 3928781000
I0617 03:45:46.616617  4950 layer_factory.hpp:77] Creating layer conv5_6/dw/bn
I0617 03:45:46.616633  4950 net.cpp:84] Creating Layer conv5_6/dw/bn
I0617 03:45:46.616642  4950 net.cpp:406] conv5_6/dw/bn <- conv5_6/dw
I0617 03:45:46.616653  4950 net.cpp:367] conv5_6/dw/bn -> conv5_6/dw (in-place)
I0617 03:45:46.616977  4950 net.cpp:122] Setting up conv5_6/dw/bn
I0617 03:45:46.616997  4950 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0617 03:45:46.617005  4950 net.cpp:137] Memory required for data: 3933798600
I0617 03:45:46.617019  4950 layer_factory.hpp:77] Creating layer conv5_6/dw/scale
I0617 03:45:46.617036  4950 net.cpp:84] Creating Layer conv5_6/dw/scale
I0617 03:45:46.617046  4950 net.cpp:406] conv5_6/dw/scale <- conv5_6/dw
I0617 03:45:46.617058  4950 net.cpp:367] conv5_6/dw/scale -> conv5_6/dw (in-place)
I0617 03:45:46.617118  4950 layer_factory.hpp:77] Creating layer conv5_6/dw/scale
I0617 03:45:46.617285  4950 net.cpp:122] Setting up conv5_6/dw/scale
I0617 03:45:46.617301  4950 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0617 03:45:46.617311  4950 net.cpp:137] Memory required for data: 3938816200
I0617 03:45:46.617322  4950 layer_factory.hpp:77] Creating layer relu5_6/dw
I0617 03:45:46.617337  4950 net.cpp:84] Creating Layer relu5_6/dw
I0617 03:45:46.617347  4950 net.cpp:406] relu5_6/dw <- conv5_6/dw
I0617 03:45:46.617357  4950 net.cpp:367] relu5_6/dw -> conv5_6/dw (in-place)
I0617 03:45:46.617807  4950 net.cpp:122] Setting up relu5_6/dw
I0617 03:45:46.617830  4950 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0617 03:45:46.617842  4950 net.cpp:137] Memory required for data: 3943833800
I0617 03:45:46.617851  4950 layer_factory.hpp:77] Creating layer conv5_6/sep
I0617 03:45:46.617867  4950 net.cpp:84] Creating Layer conv5_6/sep
I0617 03:45:46.617877  4950 net.cpp:406] conv5_6/sep <- conv5_6/dw
I0617 03:45:46.617895  4950 net.cpp:380] conv5_6/sep -> conv5_6/sep
I0617 03:45:46.628417  4950 net.cpp:122] Setting up conv5_6/sep
I0617 03:45:46.628442  4950 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0617 03:45:46.628451  4950 net.cpp:137] Memory required for data: 3953869000
I0617 03:45:46.628463  4950 layer_factory.hpp:77] Creating layer conv5_6/sep/bn
I0617 03:45:46.628479  4950 net.cpp:84] Creating Layer conv5_6/sep/bn
I0617 03:45:46.628489  4950 net.cpp:406] conv5_6/sep/bn <- conv5_6/sep
I0617 03:45:46.628511  4950 net.cpp:367] conv5_6/sep/bn -> conv5_6/sep (in-place)
I0617 03:45:46.628798  4950 net.cpp:122] Setting up conv5_6/sep/bn
I0617 03:45:46.628814  4950 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0617 03:45:46.628823  4950 net.cpp:137] Memory required for data: 3963904200
I0617 03:45:46.628837  4950 layer_factory.hpp:77] Creating layer conv5_6/sep/scale
I0617 03:45:46.628850  4950 net.cpp:84] Creating Layer conv5_6/sep/scale
I0617 03:45:46.628859  4950 net.cpp:406] conv5_6/sep/scale <- conv5_6/sep
I0617 03:45:46.628873  4950 net.cpp:367] conv5_6/sep/scale -> conv5_6/sep (in-place)
I0617 03:45:46.628932  4950 layer_factory.hpp:77] Creating layer conv5_6/sep/scale
I0617 03:45:46.629097  4950 net.cpp:122] Setting up conv5_6/sep/scale
I0617 03:45:46.629118  4950 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0617 03:45:46.629127  4950 net.cpp:137] Memory required for data: 3973939400
I0617 03:45:46.629139  4950 layer_factory.hpp:77] Creating layer relu5_6/sep
I0617 03:45:46.629150  4950 net.cpp:84] Creating Layer relu5_6/sep
I0617 03:45:46.629159  4950 net.cpp:406] relu5_6/sep <- conv5_6/sep
I0617 03:45:46.629169  4950 net.cpp:367] relu5_6/sep -> conv5_6/sep (in-place)
I0617 03:45:46.629415  4950 net.cpp:122] Setting up relu5_6/sep
I0617 03:45:46.629437  4950 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0617 03:45:46.629446  4950 net.cpp:137] Memory required for data: 3983974600
I0617 03:45:46.629454  4950 layer_factory.hpp:77] Creating layer conv6/dw
I0617 03:45:46.629468  4950 net.cpp:84] Creating Layer conv6/dw
I0617 03:45:46.629478  4950 net.cpp:406] conv6/dw <- conv5_6/sep
I0617 03:45:46.629493  4950 net.cpp:380] conv6/dw -> conv6/dw
I0617 03:45:46.629786  4950 net.cpp:122] Setting up conv6/dw
I0617 03:45:46.629815  4950 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0617 03:45:46.629824  4950 net.cpp:137] Memory required for data: 3994009800
I0617 03:45:46.629835  4950 layer_factory.hpp:77] Creating layer conv6/dw/bn
I0617 03:45:46.629848  4950 net.cpp:84] Creating Layer conv6/dw/bn
I0617 03:45:46.629856  4950 net.cpp:406] conv6/dw/bn <- conv6/dw
I0617 03:45:46.629869  4950 net.cpp:367] conv6/dw/bn -> conv6/dw (in-place)
I0617 03:45:46.630138  4950 net.cpp:122] Setting up conv6/dw/bn
I0617 03:45:46.630156  4950 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0617 03:45:46.630163  4950 net.cpp:137] Memory required for data: 4004045000
I0617 03:45:46.630177  4950 layer_factory.hpp:77] Creating layer conv6/dw/scale
I0617 03:45:46.630189  4950 net.cpp:84] Creating Layer conv6/dw/scale
I0617 03:45:46.630198  4950 net.cpp:406] conv6/dw/scale <- conv6/dw
I0617 03:45:46.630209  4950 net.cpp:367] conv6/dw/scale -> conv6/dw (in-place)
I0617 03:45:46.630270  4950 layer_factory.hpp:77] Creating layer conv6/dw/scale
I0617 03:45:46.630445  4950 net.cpp:122] Setting up conv6/dw/scale
I0617 03:45:46.630461  4950 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0617 03:45:46.630470  4950 net.cpp:137] Memory required for data: 4014080200
I0617 03:45:46.630482  4950 layer_factory.hpp:77] Creating layer relu6/dw
I0617 03:45:46.630493  4950 net.cpp:84] Creating Layer relu6/dw
I0617 03:45:46.630502  4950 net.cpp:406] relu6/dw <- conv6/dw
I0617 03:45:46.630522  4950 net.cpp:367] relu6/dw -> conv6/dw (in-place)
I0617 03:45:46.630981  4950 net.cpp:122] Setting up relu6/dw
I0617 03:45:46.631002  4950 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0617 03:45:46.631011  4950 net.cpp:137] Memory required for data: 4024115400
I0617 03:45:46.631021  4950 layer_factory.hpp:77] Creating layer conv6/sep
I0617 03:45:46.631039  4950 net.cpp:84] Creating Layer conv6/sep
I0617 03:45:46.631050  4950 net.cpp:406] conv6/sep <- conv6/dw
I0617 03:45:46.631063  4950 net.cpp:380] conv6/sep -> conv6/sep
I0617 03:45:46.649828  4950 net.cpp:122] Setting up conv6/sep
I0617 03:45:46.649857  4950 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0617 03:45:46.649866  4950 net.cpp:137] Memory required for data: 4034150600
I0617 03:45:46.649878  4950 layer_factory.hpp:77] Creating layer conv6/sep/bn
I0617 03:45:46.649894  4950 net.cpp:84] Creating Layer conv6/sep/bn
I0617 03:45:46.649915  4950 net.cpp:406] conv6/sep/bn <- conv6/sep
I0617 03:45:46.649931  4950 net.cpp:367] conv6/sep/bn -> conv6/sep (in-place)
I0617 03:45:46.650213  4950 net.cpp:122] Setting up conv6/sep/bn
I0617 03:45:46.650230  4950 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0617 03:45:46.650238  4950 net.cpp:137] Memory required for data: 4044185800
I0617 03:45:46.650252  4950 layer_factory.hpp:77] Creating layer conv6/sep/scale
I0617 03:45:46.650270  4950 net.cpp:84] Creating Layer conv6/sep/scale
I0617 03:45:46.650280  4950 net.cpp:406] conv6/sep/scale <- conv6/sep
I0617 03:45:46.650292  4950 net.cpp:367] conv6/sep/scale -> conv6/sep (in-place)
I0617 03:45:46.650352  4950 layer_factory.hpp:77] Creating layer conv6/sep/scale
I0617 03:45:46.650534  4950 net.cpp:122] Setting up conv6/sep/scale
I0617 03:45:46.650553  4950 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0617 03:45:46.650562  4950 net.cpp:137] Memory required for data: 4054221000
I0617 03:45:46.650574  4950 layer_factory.hpp:77] Creating layer relu6/sep
I0617 03:45:46.650586  4950 net.cpp:84] Creating Layer relu6/sep
I0617 03:45:46.650594  4950 net.cpp:406] relu6/sep <- conv6/sep
I0617 03:45:46.650604  4950 net.cpp:367] relu6/sep -> conv6/sep (in-place)
I0617 03:45:46.651057  4950 net.cpp:122] Setting up relu6/sep
I0617 03:45:46.651078  4950 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0617 03:45:46.651088  4950 net.cpp:137] Memory required for data: 4064256200
I0617 03:45:46.651096  4950 layer_factory.hpp:77] Creating layer pool6
I0617 03:45:46.651113  4950 net.cpp:84] Creating Layer pool6
I0617 03:45:46.651123  4950 net.cpp:406] pool6 <- conv6/sep
I0617 03:45:46.651139  4950 net.cpp:380] pool6 -> pool6
I0617 03:45:46.651458  4950 net.cpp:122] Setting up pool6
I0617 03:45:46.651477  4950 net.cpp:129] Top shape: 50 1024 1 1 (51200)
I0617 03:45:46.651486  4950 net.cpp:137] Memory required for data: 4064461000
I0617 03:45:46.651494  4950 layer_factory.hpp:77] Creating layer fc7_oxford
I0617 03:45:46.651522  4950 net.cpp:84] Creating Layer fc7_oxford
I0617 03:45:46.651535  4950 net.cpp:406] fc7_oxford <- pool6
I0617 03:45:46.651558  4950 net.cpp:380] fc7_oxford -> fc7
I0617 03:45:46.656703  4950 net.cpp:122] Setting up fc7_oxford
I0617 03:45:46.656733  4950 net.cpp:129] Top shape: 50 200 1 1 (10000)
I0617 03:45:46.656743  4950 net.cpp:137] Memory required for data: 4064501000
I0617 03:45:46.656755  4950 layer_factory.hpp:77] Creating layer loss
I0617 03:45:46.656771  4950 net.cpp:84] Creating Layer loss
I0617 03:45:46.656780  4950 net.cpp:406] loss <- fc7
I0617 03:45:46.656791  4950 net.cpp:406] loss <- label
I0617 03:45:46.656805  4950 net.cpp:380] loss -> loss
I0617 03:45:46.656824  4950 layer_factory.hpp:77] Creating layer loss
I0617 03:45:46.657616  4950 net.cpp:122] Setting up loss
I0617 03:45:46.657639  4950 net.cpp:129] Top shape: (1)
I0617 03:45:46.657649  4950 net.cpp:132]     with loss weight 1
I0617 03:45:46.657704  4950 net.cpp:137] Memory required for data: 4064501004
I0617 03:45:46.657713  4950 net.cpp:198] loss needs backward computation.
I0617 03:45:46.657723  4950 net.cpp:198] fc7_oxford needs backward computation.
I0617 03:45:46.657732  4950 net.cpp:198] pool6 needs backward computation.
I0617 03:45:46.657739  4950 net.cpp:198] relu6/sep needs backward computation.
I0617 03:45:46.657747  4950 net.cpp:198] conv6/sep/scale needs backward computation.
I0617 03:45:46.657755  4950 net.cpp:198] conv6/sep/bn needs backward computation.
I0617 03:45:46.657763  4950 net.cpp:198] conv6/sep needs backward computation.
I0617 03:45:46.657771  4950 net.cpp:198] relu6/dw needs backward computation.
I0617 03:45:46.657779  4950 net.cpp:198] conv6/dw/scale needs backward computation.
I0617 03:45:46.657788  4950 net.cpp:198] conv6/dw/bn needs backward computation.
I0617 03:45:46.657794  4950 net.cpp:198] conv6/dw needs backward computation.
I0617 03:45:46.657802  4950 net.cpp:198] relu5_6/sep needs backward computation.
I0617 03:45:46.657810  4950 net.cpp:198] conv5_6/sep/scale needs backward computation.
I0617 03:45:46.657829  4950 net.cpp:198] conv5_6/sep/bn needs backward computation.
I0617 03:45:46.657837  4950 net.cpp:198] conv5_6/sep needs backward computation.
I0617 03:45:46.657846  4950 net.cpp:198] relu5_6/dw needs backward computation.
I0617 03:45:46.657855  4950 net.cpp:198] conv5_6/dw/scale needs backward computation.
I0617 03:45:46.657862  4950 net.cpp:198] conv5_6/dw/bn needs backward computation.
I0617 03:45:46.657869  4950 net.cpp:198] conv5_6/dw needs backward computation.
I0617 03:45:46.657877  4950 net.cpp:198] relu5_5/sep needs backward computation.
I0617 03:45:46.657886  4950 net.cpp:198] conv5_5/sep/scale needs backward computation.
I0617 03:45:46.657893  4950 net.cpp:198] conv5_5/sep/bn needs backward computation.
I0617 03:45:46.657902  4950 net.cpp:198] conv5_5/sep needs backward computation.
I0617 03:45:46.657909  4950 net.cpp:198] relu5_5/dw needs backward computation.
I0617 03:45:46.657917  4950 net.cpp:198] conv5_5/dw/scale needs backward computation.
I0617 03:45:46.657924  4950 net.cpp:198] conv5_5/dw/bn needs backward computation.
I0617 03:45:46.657932  4950 net.cpp:198] conv5_5/dw needs backward computation.
I0617 03:45:46.657939  4950 net.cpp:198] relu5_4/sep needs backward computation.
I0617 03:45:46.657948  4950 net.cpp:198] conv5_4/sep/scale needs backward computation.
I0617 03:45:46.657955  4950 net.cpp:198] conv5_4/sep/bn needs backward computation.
I0617 03:45:46.657963  4950 net.cpp:198] conv5_4/sep needs backward computation.
I0617 03:45:46.657970  4950 net.cpp:198] relu5_4/dw needs backward computation.
I0617 03:45:46.657979  4950 net.cpp:198] conv5_4/dw/scale needs backward computation.
I0617 03:45:46.657986  4950 net.cpp:198] conv5_4/dw/bn needs backward computation.
I0617 03:45:46.657994  4950 net.cpp:198] conv5_4/dw needs backward computation.
I0617 03:45:46.658008  4950 net.cpp:198] relu5_3/sep needs backward computation.
I0617 03:45:46.658017  4950 net.cpp:198] conv5_3/sep/scale needs backward computation.
I0617 03:45:46.658025  4950 net.cpp:198] conv5_3/sep/bn needs backward computation.
I0617 03:45:46.658032  4950 net.cpp:198] conv5_3/sep needs backward computation.
I0617 03:45:46.658041  4950 net.cpp:198] relu5_3/dw needs backward computation.
I0617 03:45:46.658048  4950 net.cpp:198] conv5_3/dw/scale needs backward computation.
I0617 03:45:46.658056  4950 net.cpp:198] conv5_3/dw/bn needs backward computation.
I0617 03:45:46.658064  4950 net.cpp:198] conv5_3/dw needs backward computation.
I0617 03:45:46.658072  4950 net.cpp:198] relu5_2/sep needs backward computation.
I0617 03:45:46.658080  4950 net.cpp:198] conv5_2/sep/scale needs backward computation.
I0617 03:45:46.658087  4950 net.cpp:198] conv5_2/sep/bn needs backward computation.
I0617 03:45:46.658095  4950 net.cpp:198] conv5_2/sep needs backward computation.
I0617 03:45:46.658103  4950 net.cpp:198] relu5_2/dw needs backward computation.
I0617 03:45:46.658110  4950 net.cpp:198] conv5_2/dw/scale needs backward computation.
I0617 03:45:46.658118  4950 net.cpp:198] conv5_2/dw/bn needs backward computation.
I0617 03:45:46.658126  4950 net.cpp:198] conv5_2/dw needs backward computation.
I0617 03:45:46.658134  4950 net.cpp:198] relu5_1/sep needs backward computation.
I0617 03:45:46.658141  4950 net.cpp:198] conv5_1/sep/scale needs backward computation.
I0617 03:45:46.658149  4950 net.cpp:198] conv5_1/sep/bn needs backward computation.
I0617 03:45:46.658157  4950 net.cpp:198] conv5_1/sep needs backward computation.
I0617 03:45:46.658165  4950 net.cpp:198] relu5_1/dw needs backward computation.
I0617 03:45:46.658174  4950 net.cpp:198] conv5_1/dw/scale needs backward computation.
I0617 03:45:46.658270  4950 net.cpp:198] conv5_1/dw/bn needs backward computation.
I0617 03:45:46.658283  4950 net.cpp:198] conv5_1/dw needs backward computation.
I0617 03:45:46.658293  4950 net.cpp:198] relu4_2/sep needs backward computation.
I0617 03:45:46.658300  4950 net.cpp:198] conv4_2/sep/scale needs backward computation.
I0617 03:45:46.658308  4950 net.cpp:198] conv4_2/sep/bn needs backward computation.
I0617 03:45:46.658316  4950 net.cpp:198] conv4_2/sep needs backward computation.
I0617 03:45:46.658334  4950 net.cpp:198] relu4_2/dw needs backward computation.
I0617 03:45:46.658342  4950 net.cpp:198] conv4_2/dw/scale needs backward computation.
I0617 03:45:46.658350  4950 net.cpp:198] conv4_2/dw/bn needs backward computation.
I0617 03:45:46.658359  4950 net.cpp:198] conv4_2/dw needs backward computation.
I0617 03:45:46.658366  4950 net.cpp:198] relu4_1/sep needs backward computation.
I0617 03:45:46.658375  4950 net.cpp:198] conv4_1/sep/scale needs backward computation.
I0617 03:45:46.658383  4950 net.cpp:198] conv4_1/sep/bn needs backward computation.
I0617 03:45:46.658390  4950 net.cpp:198] conv4_1/sep needs backward computation.
I0617 03:45:46.658398  4950 net.cpp:198] relu4_1/dw needs backward computation.
I0617 03:45:46.658406  4950 net.cpp:198] conv4_1/dw/scale needs backward computation.
I0617 03:45:46.658414  4950 net.cpp:198] conv4_1/dw/bn needs backward computation.
I0617 03:45:46.658422  4950 net.cpp:198] conv4_1/dw needs backward computation.
I0617 03:45:46.658430  4950 net.cpp:198] relu3_2/sep needs backward computation.
I0617 03:45:46.658438  4950 net.cpp:198] conv3_2/sep/scale needs backward computation.
I0617 03:45:46.658447  4950 net.cpp:198] conv3_2/sep/bn needs backward computation.
I0617 03:45:46.658454  4950 net.cpp:198] conv3_2/sep needs backward computation.
I0617 03:45:46.658463  4950 net.cpp:198] relu3_2/dw needs backward computation.
I0617 03:45:46.658471  4950 net.cpp:198] conv3_2/dw/scale needs backward computation.
I0617 03:45:46.658479  4950 net.cpp:198] conv3_2/dw/bn needs backward computation.
I0617 03:45:46.658488  4950 net.cpp:198] conv3_2/dw needs backward computation.
I0617 03:45:46.658495  4950 net.cpp:198] relu3_1/sep needs backward computation.
I0617 03:45:46.658509  4950 net.cpp:198] conv3_1/sep/scale needs backward computation.
I0617 03:45:46.658526  4950 net.cpp:198] conv3_1/sep/bn needs backward computation.
I0617 03:45:46.658535  4950 net.cpp:198] conv3_1/sep needs backward computation.
I0617 03:45:46.658542  4950 net.cpp:198] relu3_1/dw needs backward computation.
I0617 03:45:46.658550  4950 net.cpp:198] conv3_1/dw/scale needs backward computation.
I0617 03:45:46.658558  4950 net.cpp:198] conv3_1/dw/bn needs backward computation.
I0617 03:45:46.658566  4950 net.cpp:198] conv3_1/dw needs backward computation.
I0617 03:45:46.658578  4950 net.cpp:198] relu2_2/sep needs backward computation.
I0617 03:45:46.658587  4950 net.cpp:198] conv2_2/sep/scale needs backward computation.
I0617 03:45:46.658596  4950 net.cpp:198] conv2_2/sep/bn needs backward computation.
I0617 03:45:46.658603  4950 net.cpp:198] conv2_2/sep needs backward computation.
I0617 03:45:46.658612  4950 net.cpp:198] relu2_2/dw needs backward computation.
I0617 03:45:46.658619  4950 net.cpp:198] conv2_2/dw/scale needs backward computation.
I0617 03:45:46.658627  4950 net.cpp:198] conv2_2/dw/bn needs backward computation.
I0617 03:45:46.658635  4950 net.cpp:198] conv2_2/dw needs backward computation.
I0617 03:45:46.658643  4950 net.cpp:198] relu2_1/sep needs backward computation.
I0617 03:45:46.658651  4950 net.cpp:198] conv2_1/sep/scale needs backward computation.
I0617 03:45:46.658659  4950 net.cpp:198] conv2_1/sep/bn needs backward computation.
I0617 03:45:46.658668  4950 net.cpp:198] conv2_1/sep needs backward computation.
I0617 03:45:46.658675  4950 net.cpp:198] relu2_1/dw needs backward computation.
I0617 03:45:46.658684  4950 net.cpp:198] conv2_1/dw/scale needs backward computation.
I0617 03:45:46.658691  4950 net.cpp:198] conv2_1/dw/bn needs backward computation.
I0617 03:45:46.658699  4950 net.cpp:198] conv2_1/dw needs backward computation.
I0617 03:45:46.658707  4950 net.cpp:198] relu1 needs backward computation.
I0617 03:45:46.658715  4950 net.cpp:198] conv1/scale needs backward computation.
I0617 03:45:46.658723  4950 net.cpp:198] conv1/bn needs backward computation.
I0617 03:45:46.658730  4950 net.cpp:198] conv1 needs backward computation.
I0617 03:45:46.658740  4950 net.cpp:200] data does not need backward computation.
I0617 03:45:46.658748  4950 net.cpp:242] This network produces output loss
I0617 03:45:46.658836  4950 net.cpp:255] Network initialization done.
I0617 03:45:46.659145  4950 solver.cpp:56] Solver scaffolding done.
I0617 03:45:46.667125  4950 caffe.cpp:155] Finetuning from mobilenet/mobilenet.caffemodel
I0617 03:45:46.690011  4950 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: mobilenet/mobilenet.caffemodel
I0617 03:45:46.690079  4950 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0617 03:45:46.690096  4950 net.cpp:744] Ignoring source layer label_data_1_split
I0617 03:45:46.693361  4950 net.cpp:744] Ignoring source layer fc7
I0617 03:45:46.693406  4950 net.cpp:744] Ignoring source layer fc7_fc7_0_split
I0617 03:45:46.693415  4950 net.cpp:744] Ignoring source layer top1/acc
I0617 03:45:46.693423  4950 net.cpp:744] Ignoring source layer top5/acc
I0617 03:45:46.695010  4950 caffe.cpp:248] Starting Optimization
I0617 03:45:46.695036  4950 solver.cpp:272] Solving MOBILENET
I0617 03:45:46.695044  4950 solver.cpp:273] Learning Rate Policy: step
I0617 03:45:47.927320  4950 solver.cpp:218] Iteration 0 (0 iter/s, 1.23216s/50 iters), loss = 6.07523
I0617 03:45:47.927584  4950 solver.cpp:237]     Train net output #0: loss = 6.07523 (* 1 = 6.07523 loss)
I0617 03:45:47.927670  4950 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I0617 03:46:46.581065  4950 solver.cpp:218] Iteration 50 (0.852468 iter/s, 58.6532s/50 iters), loss = 2.94025
I0617 03:46:46.581334  4950 solver.cpp:237]     Train net output #0: loss = 2.94025 (* 1 = 2.94025 loss)
I0617 03:46:46.581362  4950 sgd_solver.cpp:105] Iteration 50, lr = 0.01
I0617 03:47:45.249842  4950 solver.cpp:218] Iteration 100 (0.852253 iter/s, 58.668s/50 iters), loss = 2.18269
I0617 03:47:45.249974  4950 solver.cpp:237]     Train net output #0: loss = 2.18269 (* 1 = 2.18269 loss)
I0617 03:47:45.249997  4950 sgd_solver.cpp:105] Iteration 100, lr = 0.01
I0617 03:48:02.957825  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 03:48:43.925843  4950 solver.cpp:218] Iteration 150 (0.852147 iter/s, 58.6753s/50 iters), loss = 1.23012
I0617 03:48:43.926012  4950 solver.cpp:237]     Train net output #0: loss = 1.23012 (* 1 = 1.23012 loss)
I0617 03:48:43.926036  4950 sgd_solver.cpp:105] Iteration 150, lr = 0.01
I0617 03:49:42.614442  4950 solver.cpp:218] Iteration 200 (0.851965 iter/s, 58.6879s/50 iters), loss = 1.08742
I0617 03:49:42.614694  4950 solver.cpp:237]     Train net output #0: loss = 1.08742 (* 1 = 1.08742 loss)
I0617 03:49:42.614717  4950 sgd_solver.cpp:105] Iteration 200, lr = 0.01
I0617 03:50:23.864099  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 03:50:41.406294  4950 solver.cpp:218] Iteration 250 (0.850473 iter/s, 58.7908s/50 iters), loss = 0.759156
I0617 03:50:41.406510  4950 solver.cpp:237]     Train net output #0: loss = 0.759156 (* 1 = 0.759156 loss)
I0617 03:50:41.406566  4950 sgd_solver.cpp:105] Iteration 250, lr = 0.01
I0617 03:51:40.239282  4950 solver.cpp:218] Iteration 300 (0.849875 iter/s, 58.8322s/50 iters), loss = 0.631829
I0617 03:51:40.239578  4950 solver.cpp:237]     Train net output #0: loss = 0.631829 (* 1 = 0.631829 loss)
I0617 03:51:40.239617  4950 sgd_solver.cpp:105] Iteration 300, lr = 0.01
I0617 03:52:38.910666  4950 solver.cpp:218] Iteration 350 (0.852217 iter/s, 58.6705s/50 iters), loss = 0.47083
I0617 03:52:38.910845  4950 solver.cpp:237]     Train net output #0: loss = 0.47083 (* 1 = 0.47083 loss)
I0617 03:52:38.910867  4950 sgd_solver.cpp:105] Iteration 350, lr = 0.01
I0617 03:52:44.847175  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 03:53:37.554451  4950 solver.cpp:218] Iteration 400 (0.852616 iter/s, 58.643s/50 iters), loss = 0.342784
I0617 03:53:37.554728  4950 solver.cpp:237]     Train net output #0: loss = 0.342784 (* 1 = 0.342784 loss)
I0617 03:53:37.554750  4950 sgd_solver.cpp:105] Iteration 400, lr = 0.01
I0617 03:54:36.194213  4950 solver.cpp:218] Iteration 450 (0.852676 iter/s, 58.6389s/50 iters), loss = 0.324637
I0617 03:54:36.194372  4950 solver.cpp:237]     Train net output #0: loss = 0.324637 (* 1 = 0.324637 loss)
I0617 03:54:36.194396  4950 sgd_solver.cpp:105] Iteration 450, lr = 0.01
I0617 03:55:05.587419  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 03:55:34.839114  4950 solver.cpp:218] Iteration 500 (0.8526 iter/s, 58.6442s/50 iters), loss = 0.275333
I0617 03:55:34.839257  4950 solver.cpp:237]     Train net output #0: loss = 0.275333 (* 1 = 0.275333 loss)
I0617 03:55:34.839278  4950 sgd_solver.cpp:105] Iteration 500, lr = 0.01
I0617 03:56:33.476953  4950 solver.cpp:218] Iteration 550 (0.852702 iter/s, 58.6371s/50 iters), loss = 0.17085
I0617 03:56:33.477219  4950 solver.cpp:237]     Train net output #0: loss = 0.17085 (* 1 = 0.17085 loss)
I0617 03:56:33.477248  4950 sgd_solver.cpp:105] Iteration 550, lr = 0.01
I0617 03:57:26.332033  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 03:57:32.111763  4950 solver.cpp:218] Iteration 600 (0.852748 iter/s, 58.634s/50 iters), loss = 0.18644
I0617 03:57:32.111851  4950 solver.cpp:237]     Train net output #0: loss = 0.18644 (* 1 = 0.18644 loss)
I0617 03:57:32.111877  4950 sgd_solver.cpp:105] Iteration 600, lr = 0.01
I0617 03:58:30.757822  4950 solver.cpp:218] Iteration 650 (0.852582 iter/s, 58.6454s/50 iters), loss = 0.16001
I0617 03:58:30.758342  4950 solver.cpp:237]     Train net output #0: loss = 0.16001 (* 1 = 0.16001 loss)
I0617 03:58:30.758363  4950 sgd_solver.cpp:105] Iteration 650, lr = 0.01
I0617 03:59:29.584374  4950 solver.cpp:218] Iteration 700 (0.849972 iter/s, 58.8255s/50 iters), loss = 0.0812291
I0617 03:59:29.584520  4950 solver.cpp:237]     Train net output #0: loss = 0.0812291 (* 1 = 0.0812291 loss)
I0617 03:59:29.584553  4950 sgd_solver.cpp:105] Iteration 700, lr = 0.01
I0617 03:59:47.251648  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 04:00:28.265770  4950 solver.cpp:218] Iteration 750 (0.852069 iter/s, 58.6807s/50 iters), loss = 0.0695976
I0617 04:00:28.265911  4950 solver.cpp:237]     Train net output #0: loss = 0.0695976 (* 1 = 0.0695976 loss)
I0617 04:00:28.265934  4950 sgd_solver.cpp:105] Iteration 750, lr = 0.01
I0617 04:01:26.933851  4950 solver.cpp:218] Iteration 800 (0.852261 iter/s, 58.6674s/50 iters), loss = 0.070293
I0617 04:01:26.933986  4950 solver.cpp:237]     Train net output #0: loss = 0.070293 (* 1 = 0.070293 loss)
I0617 04:01:26.934013  4950 sgd_solver.cpp:105] Iteration 800, lr = 0.01
I0617 04:02:08.056854  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 04:02:25.606128  4950 solver.cpp:218] Iteration 850 (0.852199 iter/s, 58.6717s/50 iters), loss = 0.060657
I0617 04:02:25.606230  4950 solver.cpp:237]     Train net output #0: loss = 0.060657 (* 1 = 0.060657 loss)
I0617 04:02:25.606257  4950 sgd_solver.cpp:105] Iteration 850, lr = 0.01
I0617 04:03:24.288627  4950 solver.cpp:218] Iteration 900 (0.85205 iter/s, 58.682s/50 iters), loss = 0.043757
I0617 04:03:24.288828  4950 solver.cpp:237]     Train net output #0: loss = 0.043757 (* 1 = 0.043757 loss)
I0617 04:03:24.288863  4950 sgd_solver.cpp:105] Iteration 900, lr = 0.01
I0617 04:04:22.991175  4950 solver.cpp:218] Iteration 950 (0.851761 iter/s, 58.7019s/50 iters), loss = 0.0516681
I0617 04:04:22.991343  4950 solver.cpp:237]     Train net output #0: loss = 0.0516681 (* 1 = 0.0516681 loss)
I0617 04:04:22.991371  4950 sgd_solver.cpp:105] Iteration 950, lr = 0.01
I0617 04:04:28.905292  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 04:05:21.692302  4950 solver.cpp:218] Iteration 1000 (0.851781 iter/s, 58.7005s/50 iters), loss = 0.0374363
I0617 04:05:21.692503  4950 solver.cpp:237]     Train net output #0: loss = 0.0374363 (* 1 = 0.0374363 loss)
I0617 04:05:21.692546  4950 sgd_solver.cpp:105] Iteration 1000, lr = 0.01
I0617 04:06:20.384671  4950 solver.cpp:218] Iteration 1050 (0.851909 iter/s, 58.6917s/50 iters), loss = 0.0401014
I0617 04:06:20.384909  4950 solver.cpp:237]     Train net output #0: loss = 0.0401014 (* 1 = 0.0401014 loss)
I0617 04:06:20.384937  4950 sgd_solver.cpp:105] Iteration 1050, lr = 0.01
I0617 04:06:48.631327  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 04:07:19.086650  4950 solver.cpp:218] Iteration 1100 (0.85177 iter/s, 58.7013s/50 iters), loss = 0.0222268
I0617 04:07:19.086856  4950 solver.cpp:237]     Train net output #0: loss = 0.0222268 (* 1 = 0.0222268 loss)
I0617 04:07:19.086885  4950 sgd_solver.cpp:105] Iteration 1100, lr = 0.01
I0617 04:08:17.782188  4950 solver.cpp:218] Iteration 1150 (0.851863 iter/s, 58.6949s/50 iters), loss = 0.0270189
I0617 04:08:17.782411  4950 solver.cpp:237]     Train net output #0: loss = 0.0270189 (* 1 = 0.0270189 loss)
I0617 04:08:17.782443  4950 sgd_solver.cpp:105] Iteration 1150, lr = 0.01
I0617 04:09:09.501688  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 04:09:16.476147  4950 solver.cpp:218] Iteration 1200 (0.851886 iter/s, 58.6933s/50 iters), loss = 0.0213359
I0617 04:09:16.476248  4950 solver.cpp:237]     Train net output #0: loss = 0.0213359 (* 1 = 0.0213359 loss)
I0617 04:09:16.476274  4950 sgd_solver.cpp:105] Iteration 1200, lr = 0.01
I0617 04:10:15.171196  4950 solver.cpp:218] Iteration 1250 (0.851869 iter/s, 58.6945s/50 iters), loss = 0.0200471
I0617 04:10:15.171349  4950 solver.cpp:237]     Train net output #0: loss = 0.0200471 (* 1 = 0.0200471 loss)
I0617 04:10:15.171377  4950 sgd_solver.cpp:105] Iteration 1250, lr = 0.01
I0617 04:11:13.868989  4950 solver.cpp:218] Iteration 1300 (0.85183 iter/s, 58.6972s/50 iters), loss = 0.0196822
I0617 04:11:13.869182  4950 solver.cpp:237]     Train net output #0: loss = 0.0196822 (* 1 = 0.0196822 loss)
I0617 04:11:13.869210  4950 sgd_solver.cpp:105] Iteration 1300, lr = 0.01
I0617 04:11:30.373628  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 04:12:12.576140  4950 solver.cpp:218] Iteration 1350 (0.851695 iter/s, 58.7065s/50 iters), loss = 0.0258923
I0617 04:12:12.576359  4950 solver.cpp:237]     Train net output #0: loss = 0.0258923 (* 1 = 0.0258923 loss)
I0617 04:12:12.576395  4950 sgd_solver.cpp:105] Iteration 1350, lr = 0.01
I0617 04:13:11.280104  4950 solver.cpp:218] Iteration 1400 (0.851741 iter/s, 58.7033s/50 iters), loss = 0.0218739
I0617 04:13:11.280330  4950 solver.cpp:237]     Train net output #0: loss = 0.0218739 (* 1 = 0.0218739 loss)
I0617 04:13:11.280359  4950 sgd_solver.cpp:105] Iteration 1400, lr = 0.01
I0617 04:13:51.253918  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 04:14:09.980669  4950 solver.cpp:218] Iteration 1450 (0.85179 iter/s, 58.6999s/50 iters), loss = 0.0166628
I0617 04:14:09.980774  4950 solver.cpp:237]     Train net output #0: loss = 0.0166628 (* 1 = 0.0166628 loss)
I0617 04:14:09.980801  4950 sgd_solver.cpp:105] Iteration 1450, lr = 0.01
I0617 04:15:08.687136  4950 solver.cpp:218] Iteration 1500 (0.851703 iter/s, 58.7059s/50 iters), loss = 0.0164076
I0617 04:15:08.687337  4950 solver.cpp:237]     Train net output #0: loss = 0.0164076 (* 1 = 0.0164076 loss)
I0617 04:15:08.687364  4950 sgd_solver.cpp:105] Iteration 1500, lr = 0.01
I0617 04:16:07.384657  4950 solver.cpp:218] Iteration 1550 (0.851835 iter/s, 58.6968s/50 iters), loss = 0.0228625
I0617 04:16:07.384845  4950 solver.cpp:237]     Train net output #0: loss = 0.0228625 (* 1 = 0.0228625 loss)
I0617 04:16:07.384872  4950 sgd_solver.cpp:105] Iteration 1550, lr = 0.01
I0617 04:16:12.131238  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 04:17:06.100659  4950 solver.cpp:218] Iteration 1600 (0.851566 iter/s, 58.7153s/50 iters), loss = 0.0145663
I0617 04:17:06.100850  4950 solver.cpp:237]     Train net output #0: loss = 0.0145663 (* 1 = 0.0145663 loss)
I0617 04:17:06.100877  4950 sgd_solver.cpp:105] Iteration 1600, lr = 0.01
I0617 04:18:04.820132  4950 solver.cpp:218] Iteration 1650 (0.851516 iter/s, 58.7188s/50 iters), loss = 0.0146803
I0617 04:18:04.820354  4950 solver.cpp:237]     Train net output #0: loss = 0.0146803 (* 1 = 0.0146803 loss)
I0617 04:18:04.820382  4950 sgd_solver.cpp:105] Iteration 1650, lr = 0.01
I0617 04:18:33.060001  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 04:19:03.528600  4950 solver.cpp:218] Iteration 1700 (0.851676 iter/s, 58.7078s/50 iters), loss = 0.0133418
I0617 04:19:03.528810  4950 solver.cpp:237]     Train net output #0: loss = 0.0133418 (* 1 = 0.0133418 loss)
I0617 04:19:03.528837  4950 sgd_solver.cpp:105] Iteration 1700, lr = 0.01
I0617 04:20:02.236569  4950 solver.cpp:218] Iteration 1750 (0.851683 iter/s, 58.7073s/50 iters), loss = 0.0154774
I0617 04:20:02.236750  4950 solver.cpp:237]     Train net output #0: loss = 0.0154774 (* 1 = 0.0154774 loss)
I0617 04:20:02.236778  4950 sgd_solver.cpp:105] Iteration 1750, lr = 0.01
I0617 04:20:53.965214  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 04:21:00.934564  4950 solver.cpp:218] Iteration 1800 (0.851827 iter/s, 58.6973s/50 iters), loss = 0.0116892
I0617 04:21:00.934664  4950 solver.cpp:237]     Train net output #0: loss = 0.0116892 (* 1 = 0.0116892 loss)
I0617 04:21:00.934690  4950 sgd_solver.cpp:105] Iteration 1800, lr = 0.01
I0617 04:21:59.627924  4950 solver.cpp:218] Iteration 1850 (0.851894 iter/s, 58.6928s/50 iters), loss = 0.0100301
I0617 04:21:59.628114  4950 solver.cpp:237]     Train net output #0: loss = 0.0100301 (* 1 = 0.0100301 loss)
I0617 04:21:59.628142  4950 sgd_solver.cpp:105] Iteration 1850, lr = 0.01
I0617 04:22:58.328114  4950 solver.cpp:218] Iteration 1900 (0.851796 iter/s, 58.6995s/50 iters), loss = 0.0165997
I0617 04:22:58.328253  4950 solver.cpp:237]     Train net output #0: loss = 0.0165997 (* 1 = 0.0165997 loss)
I0617 04:22:58.328279  4950 sgd_solver.cpp:105] Iteration 1900, lr = 0.01
I0617 04:23:14.833240  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 04:23:57.010803  4950 solver.cpp:218] Iteration 1950 (0.852049 iter/s, 58.6821s/50 iters), loss = 0.0128314
I0617 04:23:57.010979  4950 solver.cpp:237]     Train net output #0: loss = 0.0128314 (* 1 = 0.0128314 loss)
I0617 04:23:57.011006  4950 sgd_solver.cpp:105] Iteration 1950, lr = 0.01
I0617 04:24:55.696491  4950 solver.cpp:218] Iteration 2000 (0.852006 iter/s, 58.685s/50 iters), loss = 0.0144375
I0617 04:24:55.696629  4950 solver.cpp:237]     Train net output #0: loss = 0.0144375 (* 1 = 0.0144375 loss)
I0617 04:24:55.696655  4950 sgd_solver.cpp:105] Iteration 2000, lr = 0.01
I0617 04:25:34.502635  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 04:25:54.377964  4950 solver.cpp:218] Iteration 2050 (0.852067 iter/s, 58.6808s/50 iters), loss = 0.0110024
I0617 04:25:54.378067  4950 solver.cpp:237]     Train net output #0: loss = 0.0110024 (* 1 = 0.0110024 loss)
I0617 04:25:54.378094  4950 sgd_solver.cpp:105] Iteration 2050, lr = 0.01
I0617 04:26:53.062500  4950 solver.cpp:218] Iteration 2100 (0.852022 iter/s, 58.6839s/50 iters), loss = 0.0146856
I0617 04:26:53.062640  4950 solver.cpp:237]     Train net output #0: loss = 0.0146856 (* 1 = 0.0146856 loss)
I0617 04:26:53.062666  4950 sgd_solver.cpp:105] Iteration 2100, lr = 0.01
I0617 04:27:51.750360  4950 solver.cpp:218] Iteration 2150 (0.851974 iter/s, 58.6872s/50 iters), loss = 0.0116734
I0617 04:27:51.750494  4950 solver.cpp:237]     Train net output #0: loss = 0.0116734 (* 1 = 0.0116734 loss)
I0617 04:27:51.750525  4950 sgd_solver.cpp:105] Iteration 2150, lr = 0.01
I0617 04:27:55.373023  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 04:28:50.426863  4950 solver.cpp:218] Iteration 2200 (0.852139 iter/s, 58.6759s/50 iters), loss = 0.0160299
I0617 04:28:50.426998  4950 solver.cpp:237]     Train net output #0: loss = 0.0160299 (* 1 = 0.0160299 loss)
I0617 04:28:50.427024  4950 sgd_solver.cpp:105] Iteration 2200, lr = 0.01
I0617 04:29:49.124248  4950 solver.cpp:218] Iteration 2250 (0.851836 iter/s, 58.6967s/50 iters), loss = 0.0104668
I0617 04:29:49.124387  4950 solver.cpp:237]     Train net output #0: loss = 0.0104668 (* 1 = 0.0104668 loss)
I0617 04:29:49.124415  4950 sgd_solver.cpp:105] Iteration 2250, lr = 0.01
I0617 04:30:16.213485  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 04:30:47.799939  4950 solver.cpp:218] Iteration 2300 (0.852151 iter/s, 58.675s/50 iters), loss = 0.0108102
I0617 04:30:47.800102  4950 solver.cpp:237]     Train net output #0: loss = 0.0108102 (* 1 = 0.0108102 loss)
I0617 04:30:47.800135  4950 sgd_solver.cpp:105] Iteration 2300, lr = 0.01
I0617 04:31:46.475456  4950 solver.cpp:218] Iteration 2350 (0.852154 iter/s, 58.6748s/50 iters), loss = 0.00932087
I0617 04:31:46.475813  4950 solver.cpp:237]     Train net output #0: loss = 0.00932087 (* 1 = 0.00932087 loss)
I0617 04:31:46.475841  4950 sgd_solver.cpp:105] Iteration 2350, lr = 0.01
I0617 04:32:37.004384  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 04:32:45.148012  4950 solver.cpp:218] Iteration 2400 (0.8522 iter/s, 58.6717s/50 iters), loss = 0.00964972
I0617 04:32:45.148104  4950 solver.cpp:237]     Train net output #0: loss = 0.00964972 (* 1 = 0.00964972 loss)
I0617 04:32:45.148131  4950 sgd_solver.cpp:105] Iteration 2400, lr = 0.01
I0617 04:33:43.814318  4950 solver.cpp:218] Iteration 2450 (0.852287 iter/s, 58.6657s/50 iters), loss = 0.00970773
I0617 04:33:43.814505  4950 solver.cpp:237]     Train net output #0: loss = 0.00970773 (* 1 = 0.00970773 loss)
I0617 04:33:43.814540  4950 sgd_solver.cpp:105] Iteration 2450, lr = 0.01
I0617 04:34:42.489943  4950 solver.cpp:218] Iteration 2500 (0.852153 iter/s, 58.6749s/50 iters), loss = 0.0123404
I0617 04:34:42.490093  4950 solver.cpp:237]     Train net output #0: loss = 0.0123404 (* 1 = 0.0123404 loss)
I0617 04:34:42.490120  4950 sgd_solver.cpp:105] Iteration 2500, lr = 0.01
I0617 04:34:57.805068  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 04:35:41.159427  4950 solver.cpp:218] Iteration 2550 (0.852242 iter/s, 58.6688s/50 iters), loss = 0.0139216
I0617 04:35:41.159606  4950 solver.cpp:237]     Train net output #0: loss = 0.0139216 (* 1 = 0.0139216 loss)
I0617 04:35:41.159644  4950 sgd_solver.cpp:105] Iteration 2550, lr = 0.01
I0617 04:36:39.825997  4950 solver.cpp:218] Iteration 2600 (0.852284 iter/s, 58.6659s/50 iters), loss = 0.0107438
I0617 04:36:39.826122  4950 solver.cpp:237]     Train net output #0: loss = 0.0107438 (* 1 = 0.0107438 loss)
I0617 04:36:39.826148  4950 sgd_solver.cpp:105] Iteration 2600, lr = 0.01
I0617 04:37:18.600029  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 04:37:36.153373  4950 solver.cpp:447] Snapshotting to binary proto file mobilenet/mobile_cub_iter_2649.caffemodel
I0617 04:37:36.257323  4950 sgd_solver.cpp:273] Snapshotting solver state to binary proto file mobilenet/mobile_cub_iter_2649.solverstate
I0617 04:37:38.630416  4950 solver.cpp:218] Iteration 2650 (0.850286 iter/s, 58.8038s/50 iters), loss = 0.0103691
I0617 04:37:38.630497  4950 solver.cpp:237]     Train net output #0: loss = 0.0103691 (* 1 = 0.0103691 loss)
I0617 04:37:38.630535  4950 sgd_solver.cpp:105] Iteration 2650, lr = 0.01
I0617 04:38:37.307399  4950 solver.cpp:218] Iteration 2700 (0.852132 iter/s, 58.6763s/50 iters), loss = 0.0100067
I0617 04:38:37.307543  4950 solver.cpp:237]     Train net output #0: loss = 0.0100067 (* 1 = 0.0100067 loss)
I0617 04:38:37.307569  4950 sgd_solver.cpp:105] Iteration 2700, lr = 0.01
I0617 04:39:35.987226  4950 solver.cpp:218] Iteration 2750 (0.852092 iter/s, 58.6791s/50 iters), loss = 0.00763031
I0617 04:39:35.987380  4950 solver.cpp:237]     Train net output #0: loss = 0.00763031 (* 1 = 0.00763031 loss)
I0617 04:39:35.987409  4950 sgd_solver.cpp:105] Iteration 2750, lr = 0.01
I0617 04:39:39.564005  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 04:40:34.674010  4950 solver.cpp:218] Iteration 2800 (0.851991 iter/s, 58.6861s/50 iters), loss = 0.0141457
I0617 04:40:34.674155  4950 solver.cpp:237]     Train net output #0: loss = 0.0141457 (* 1 = 0.0141457 loss)
I0617 04:40:34.674178  4950 sgd_solver.cpp:105] Iteration 2800, lr = 0.01
I0617 04:41:33.361821  4950 solver.cpp:218] Iteration 2850 (0.851976 iter/s, 58.6871s/50 iters), loss = 0.0105009
I0617 04:41:33.362028  4950 solver.cpp:237]     Train net output #0: loss = 0.0105009 (* 1 = 0.0105009 loss)
I0617 04:41:33.362052  4950 sgd_solver.cpp:105] Iteration 2850, lr = 0.01
I0617 04:42:00.438751  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 04:42:32.062151  4950 solver.cpp:218] Iteration 2900 (0.851795 iter/s, 58.6996s/50 iters), loss = 0.0074335
I0617 04:42:32.062297  4950 solver.cpp:237]     Train net output #0: loss = 0.0074335 (* 1 = 0.0074335 loss)
I0617 04:42:32.062322  4950 sgd_solver.cpp:105] Iteration 2900, lr = 0.01
I0617 04:43:30.745872  4950 solver.cpp:218] Iteration 2950 (0.852035 iter/s, 58.683s/50 iters), loss = 0.0133211
I0617 04:43:30.746014  4950 solver.cpp:237]     Train net output #0: loss = 0.0133211 (* 1 = 0.0133211 loss)
I0617 04:43:30.746037  4950 sgd_solver.cpp:105] Iteration 2950, lr = 0.01
I0617 04:44:20.117758  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 04:44:29.437165  4950 solver.cpp:218] Iteration 3000 (0.851925 iter/s, 58.6906s/50 iters), loss = 0.0108286
I0617 04:44:29.437283  4950 solver.cpp:237]     Train net output #0: loss = 0.0108286 (* 1 = 0.0108286 loss)
I0617 04:44:29.437306  4950 sgd_solver.cpp:105] Iteration 3000, lr = 0.01
I0617 04:45:28.115257  4950 solver.cpp:218] Iteration 3050 (0.852117 iter/s, 58.6774s/50 iters), loss = 0.0151204
I0617 04:45:28.115401  4950 solver.cpp:237]     Train net output #0: loss = 0.0151204 (* 1 = 0.0151204 loss)
I0617 04:45:28.115425  4950 sgd_solver.cpp:105] Iteration 3050, lr = 0.01
I0617 04:46:26.799571  4950 solver.cpp:218] Iteration 3100 (0.852027 iter/s, 58.6836s/50 iters), loss = 0.012839
I0617 04:46:26.799720  4950 solver.cpp:237]     Train net output #0: loss = 0.012839 (* 1 = 0.012839 loss)
I0617 04:46:26.799744  4950 sgd_solver.cpp:105] Iteration 3100, lr = 0.01
I0617 04:46:40.950695  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 04:47:25.488222  4950 solver.cpp:218] Iteration 3150 (0.851964 iter/s, 58.6879s/50 iters), loss = 0.00893284
I0617 04:47:25.488417  4950 solver.cpp:237]     Train net output #0: loss = 0.00893284 (* 1 = 0.00893284 loss)
I0617 04:47:25.488441  4950 sgd_solver.cpp:105] Iteration 3150, lr = 0.01
I0617 04:48:24.161168  4950 solver.cpp:218] Iteration 3200 (0.852193 iter/s, 58.6722s/50 iters), loss = 0.00829366
I0617 04:48:24.161314  4950 solver.cpp:237]     Train net output #0: loss = 0.00829366 (* 1 = 0.00829366 loss)
I0617 04:48:24.161339  4950 sgd_solver.cpp:105] Iteration 3200, lr = 0.01
I0617 04:49:01.816242  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 04:49:22.847673  4950 solver.cpp:218] Iteration 3250 (0.851995 iter/s, 58.6858s/50 iters), loss = 0.00933513
I0617 04:49:22.847777  4950 solver.cpp:237]     Train net output #0: loss = 0.00933513 (* 1 = 0.00933513 loss)
I0617 04:49:22.847800  4950 sgd_solver.cpp:105] Iteration 3250, lr = 0.01
I0617 04:50:21.534040  4950 solver.cpp:218] Iteration 3300 (0.851997 iter/s, 58.6857s/50 iters), loss = 0.0104865
I0617 04:50:21.534184  4950 solver.cpp:237]     Train net output #0: loss = 0.0104865 (* 1 = 0.0104865 loss)
I0617 04:50:21.534209  4950 sgd_solver.cpp:105] Iteration 3300, lr = 0.01
I0617 04:51:20.216491  4950 solver.cpp:218] Iteration 3350 (0.852054 iter/s, 58.6817s/50 iters), loss = 0.0118009
I0617 04:51:20.216629  4950 solver.cpp:237]     Train net output #0: loss = 0.0118009 (* 1 = 0.0118009 loss)
I0617 04:51:20.216652  4950 sgd_solver.cpp:105] Iteration 3350, lr = 0.01
I0617 04:51:22.635346  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 04:52:18.927093  4950 solver.cpp:218] Iteration 3400 (0.851645 iter/s, 58.7099s/50 iters), loss = 0.0116647
I0617 04:52:18.927242  4950 solver.cpp:237]     Train net output #0: loss = 0.0116647 (* 1 = 0.0116647 loss)
I0617 04:52:18.927265  4950 sgd_solver.cpp:105] Iteration 3400, lr = 0.01
I0617 04:53:17.644901  4950 solver.cpp:218] Iteration 3450 (0.851541 iter/s, 58.7171s/50 iters), loss = 0.00913504
I0617 04:53:17.645045  4950 solver.cpp:237]     Train net output #0: loss = 0.00913504 (* 1 = 0.00913504 loss)
I0617 04:53:17.645071  4950 sgd_solver.cpp:105] Iteration 3450, lr = 0.01
I0617 04:53:43.537845  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 04:54:16.365838  4950 solver.cpp:218] Iteration 3500 (0.851496 iter/s, 58.7202s/50 iters), loss = 0.00781651
I0617 04:54:16.366660  4950 solver.cpp:237]     Train net output #0: loss = 0.00781651 (* 1 = 0.00781651 loss)
I0617 04:54:16.366696  4950 sgd_solver.cpp:105] Iteration 3500, lr = 0.01
I0617 04:55:15.072564  4950 solver.cpp:218] Iteration 3550 (0.851711 iter/s, 58.7053s/50 iters), loss = 0.0102013
I0617 04:55:15.072701  4950 solver.cpp:237]     Train net output #0: loss = 0.0102013 (* 1 = 0.0102013 loss)
I0617 04:55:15.072726  4950 sgd_solver.cpp:105] Iteration 3550, lr = 0.01
I0617 04:56:04.463904  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 04:56:13.773157  4950 solver.cpp:218] Iteration 3600 (0.851791 iter/s, 58.6998s/50 iters), loss = 0.0103964
I0617 04:56:13.773260  4950 solver.cpp:237]     Train net output #0: loss = 0.0103964 (* 1 = 0.0103964 loss)
I0617 04:56:13.773288  4950 sgd_solver.cpp:105] Iteration 3600, lr = 0.01
I0617 04:57:12.486912  4950 solver.cpp:218] Iteration 3650 (0.851599 iter/s, 58.7131s/50 iters), loss = 0.0113923
I0617 04:57:12.487119  4950 solver.cpp:237]     Train net output #0: loss = 0.0113923 (* 1 = 0.0113923 loss)
I0617 04:57:12.487143  4950 sgd_solver.cpp:105] Iteration 3650, lr = 0.01
I0617 04:58:11.209846  4950 solver.cpp:218] Iteration 3700 (0.851468 iter/s, 58.7221s/50 iters), loss = 0.0130679
I0617 04:58:11.210052  4950 solver.cpp:237]     Train net output #0: loss = 0.0130679 (* 1 = 0.0130679 loss)
I0617 04:58:11.210077  4950 sgd_solver.cpp:105] Iteration 3700, lr = 0.01
I0617 04:58:25.354357  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 04:59:09.927373  4950 solver.cpp:218] Iteration 3750 (0.851546 iter/s, 58.7167s/50 iters), loss = 0.00895841
I0617 04:59:09.927669  4950 solver.cpp:237]     Train net output #0: loss = 0.00895841 (* 1 = 0.00895841 loss)
I0617 04:59:09.927692  4950 sgd_solver.cpp:105] Iteration 3750, lr = 0.01
I0617 05:00:08.637706  4950 solver.cpp:218] Iteration 3800 (0.851652 iter/s, 58.7094s/50 iters), loss = 0.0104026
I0617 05:00:08.637848  4950 solver.cpp:237]     Train net output #0: loss = 0.0104026 (* 1 = 0.0104026 loss)
I0617 05:00:08.637873  4950 sgd_solver.cpp:105] Iteration 3800, lr = 0.01
I0617 05:00:46.273486  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 05:01:07.330482  4950 solver.cpp:218] Iteration 3850 (0.851904 iter/s, 58.692s/50 iters), loss = 0.0086334
I0617 05:01:07.330590  4950 solver.cpp:237]     Train net output #0: loss = 0.0086334 (* 1 = 0.0086334 loss)
I0617 05:01:07.330612  4950 sgd_solver.cpp:105] Iteration 3850, lr = 0.01
I0617 05:02:06.027300  4950 solver.cpp:218] Iteration 3900 (0.851845 iter/s, 58.6961s/50 iters), loss = 0.0128847
I0617 05:02:06.027454  4950 solver.cpp:237]     Train net output #0: loss = 0.0128847 (* 1 = 0.0128847 loss)
I0617 05:02:06.027480  4950 sgd_solver.cpp:105] Iteration 3900, lr = 0.01
I0617 05:03:04.712812  4950 solver.cpp:218] Iteration 3950 (0.85201 iter/s, 58.6848s/50 iters), loss = 0.0124852
I0617 05:03:04.712957  4950 solver.cpp:237]     Train net output #0: loss = 0.0124852 (* 1 = 0.0124852 loss)
I0617 05:03:04.712981  4950 sgd_solver.cpp:105] Iteration 3950, lr = 0.01
I0617 05:03:07.101688  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 05:04:03.399878  4950 solver.cpp:218] Iteration 4000 (0.851988 iter/s, 58.6863s/50 iters), loss = 0.00915328
I0617 05:04:03.400017  4950 solver.cpp:237]     Train net output #0: loss = 0.00915328 (* 1 = 0.00915328 loss)
I0617 05:04:03.400045  4950 sgd_solver.cpp:105] Iteration 4000, lr = 0.01
I0617 05:05:02.088693  4950 solver.cpp:218] Iteration 4050 (0.851962 iter/s, 58.6881s/50 iters), loss = 0.0089914
I0617 05:05:02.088829  4950 solver.cpp:237]     Train net output #0: loss = 0.0089914 (* 1 = 0.0089914 loss)
I0617 05:05:02.088852  4950 sgd_solver.cpp:105] Iteration 4050, lr = 0.01
I0617 05:05:26.838098  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 05:06:00.768941  4950 solver.cpp:218] Iteration 4100 (0.852087 iter/s, 58.6795s/50 iters), loss = 0.0100376
I0617 05:06:00.769284  4950 solver.cpp:237]     Train net output #0: loss = 0.0100376 (* 1 = 0.0100376 loss)
I0617 05:06:00.769309  4950 sgd_solver.cpp:105] Iteration 4100, lr = 0.01
I0617 05:06:59.466177  4950 solver.cpp:218] Iteration 4150 (0.851843 iter/s, 58.6963s/50 iters), loss = 0.0089395
I0617 05:06:59.466346  4950 solver.cpp:237]     Train net output #0: loss = 0.0089395 (* 1 = 0.0089395 loss)
I0617 05:06:59.466369  4950 sgd_solver.cpp:105] Iteration 4150, lr = 0.01
I0617 05:07:47.652933  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 05:07:58.158073  4950 solver.cpp:218] Iteration 4200 (0.851918 iter/s, 58.6911s/50 iters), loss = 0.0107894
I0617 05:07:58.158211  4950 solver.cpp:237]     Train net output #0: loss = 0.0107894 (* 1 = 0.0107894 loss)
I0617 05:07:58.158236  4950 sgd_solver.cpp:105] Iteration 4200, lr = 0.01
I0617 05:08:57.033728  4950 solver.cpp:218] Iteration 4250 (0.849259 iter/s, 58.8749s/50 iters), loss = 0.00811364
I0617 05:08:57.034023  4950 solver.cpp:237]     Train net output #0: loss = 0.00811364 (* 1 = 0.00811364 loss)
I0617 05:08:57.034049  4950 sgd_solver.cpp:105] Iteration 4250, lr = 0.01
I0617 05:09:55.746016  4950 solver.cpp:218] Iteration 4300 (0.851623 iter/s, 58.7114s/50 iters), loss = 0.0101477
I0617 05:09:55.746153  4950 solver.cpp:237]     Train net output #0: loss = 0.0101477 (* 1 = 0.0101477 loss)
I0617 05:09:55.746179  4950 sgd_solver.cpp:105] Iteration 4300, lr = 0.01
I0617 05:10:08.726442  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 05:10:54.419153  4950 solver.cpp:218] Iteration 4350 (0.852188 iter/s, 58.6725s/50 iters), loss = 0.00985452
I0617 05:10:54.419308  4950 solver.cpp:237]     Train net output #0: loss = 0.00985452 (* 1 = 0.00985452 loss)
I0617 05:10:54.419345  4950 sgd_solver.cpp:105] Iteration 4350, lr = 0.01
I0617 05:11:53.095667  4950 solver.cpp:218] Iteration 4400 (0.85214 iter/s, 58.6758s/50 iters), loss = 0.00859468
I0617 05:11:53.095809  4950 solver.cpp:237]     Train net output #0: loss = 0.00859468 (* 1 = 0.00859468 loss)
I0617 05:11:53.095834  4950 sgd_solver.cpp:105] Iteration 4400, lr = 0.01
I0617 05:12:29.539224  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 05:12:51.777401  4950 solver.cpp:218] Iteration 4450 (0.852064 iter/s, 58.681s/50 iters), loss = 0.00853573
I0617 05:12:51.777554  4950 solver.cpp:237]     Train net output #0: loss = 0.00853573 (* 1 = 0.00853573 loss)
I0617 05:12:51.777580  4950 sgd_solver.cpp:105] Iteration 4450, lr = 0.01
I0617 05:13:50.458493  4950 solver.cpp:218] Iteration 4500 (0.852074 iter/s, 58.6804s/50 iters), loss = 0.0104858
I0617 05:13:50.458742  4950 solver.cpp:237]     Train net output #0: loss = 0.0104858 (* 1 = 0.0104858 loss)
I0617 05:13:50.458772  4950 sgd_solver.cpp:105] Iteration 4500, lr = 0.01
I0617 05:14:49.142097  4950 solver.cpp:218] Iteration 4550 (0.852038 iter/s, 58.6828s/50 iters), loss = 0.00982838
I0617 05:14:49.142222  4950 solver.cpp:237]     Train net output #0: loss = 0.00982838 (* 1 = 0.00982838 loss)
I0617 05:14:49.142244  4950 sgd_solver.cpp:105] Iteration 4550, lr = 0.01
I0617 05:14:50.376230  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 05:15:47.821820  4950 solver.cpp:218] Iteration 4600 (0.852093 iter/s, 58.6791s/50 iters), loss = 0.0107862
I0617 05:15:47.821966  4950 solver.cpp:237]     Train net output #0: loss = 0.0107862 (* 1 = 0.0107862 loss)
I0617 05:15:47.821991  4950 sgd_solver.cpp:105] Iteration 4600, lr = 0.01
I0617 05:16:46.501013  4950 solver.cpp:218] Iteration 4650 (0.852101 iter/s, 58.6785s/50 iters), loss = 0.00942366
I0617 05:16:46.501212  4950 solver.cpp:237]     Train net output #0: loss = 0.00942366 (* 1 = 0.00942366 loss)
I0617 05:16:46.501237  4950 sgd_solver.cpp:105] Iteration 4650, lr = 0.01
I0617 05:17:11.193738  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 05:17:45.182184  4950 solver.cpp:218] Iteration 4700 (0.852073 iter/s, 58.6804s/50 iters), loss = 0.00839222
I0617 05:17:45.182381  4950 solver.cpp:237]     Train net output #0: loss = 0.00839222 (* 1 = 0.00839222 loss)
I0617 05:17:45.182407  4950 sgd_solver.cpp:105] Iteration 4700, lr = 0.01
I0617 05:18:43.864511  4950 solver.cpp:218] Iteration 4750 (0.852056 iter/s, 58.6816s/50 iters), loss = 0.00986062
I0617 05:18:43.864660  4950 solver.cpp:237]     Train net output #0: loss = 0.00986062 (* 1 = 0.00986062 loss)
I0617 05:18:43.864683  4950 sgd_solver.cpp:105] Iteration 4750, lr = 0.01
I0617 05:19:32.049471  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 05:19:42.568353  4950 solver.cpp:218] Iteration 4800 (0.851743 iter/s, 58.7031s/50 iters), loss = 0.00915188
I0617 05:19:42.568444  4950 solver.cpp:237]     Train net output #0: loss = 0.00915188 (* 1 = 0.00915188 loss)
I0617 05:19:42.568466  4950 sgd_solver.cpp:105] Iteration 4800, lr = 0.01
I0617 05:20:41.246976  4950 solver.cpp:218] Iteration 4850 (0.852109 iter/s, 58.6779s/50 iters), loss = 0.00919662
I0617 05:20:41.247104  4950 solver.cpp:237]     Train net output #0: loss = 0.00919662 (* 1 = 0.00919662 loss)
I0617 05:20:41.247133  4950 sgd_solver.cpp:105] Iteration 4850, lr = 0.01
I0617 05:21:39.929764  4950 solver.cpp:218] Iteration 4900 (0.852049 iter/s, 58.6821s/50 iters), loss = 0.00951363
I0617 05:21:39.929905  4950 solver.cpp:237]     Train net output #0: loss = 0.00951363 (* 1 = 0.00951363 loss)
I0617 05:21:39.929929  4950 sgd_solver.cpp:105] Iteration 4900, lr = 0.01
I0617 05:21:52.893759  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 05:22:38.621920  4950 solver.cpp:218] Iteration 4950 (0.851913 iter/s, 58.6914s/50 iters), loss = 0.00938296
I0617 05:22:38.622058  4950 solver.cpp:237]     Train net output #0: loss = 0.00938296 (* 1 = 0.00938296 loss)
I0617 05:22:38.622082  4950 sgd_solver.cpp:105] Iteration 4950, lr = 0.01
I0617 05:23:37.309695  4950 solver.cpp:218] Iteration 5000 (0.851976 iter/s, 58.6871s/50 iters), loss = 0.0132533
I0617 05:23:37.309913  4950 solver.cpp:237]     Train net output #0: loss = 0.0132533 (* 1 = 0.0132533 loss)
I0617 05:23:37.309938  4950 sgd_solver.cpp:105] Iteration 5000, lr = 0.01
I0617 05:24:12.589462  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 05:24:35.999912  4950 solver.cpp:218] Iteration 5050 (0.851942 iter/s, 58.6894s/50 iters), loss = 0.0100672
I0617 05:24:36.000018  4950 solver.cpp:237]     Train net output #0: loss = 0.0100672 (* 1 = 0.0100672 loss)
I0617 05:24:36.000042  4950 sgd_solver.cpp:105] Iteration 5050, lr = 0.01
I0617 05:25:34.683950  4950 solver.cpp:218] Iteration 5100 (0.852031 iter/s, 58.6833s/50 iters), loss = 0.00959628
I0617 05:25:34.684152  4950 solver.cpp:237]     Train net output #0: loss = 0.00959628 (* 1 = 0.00959628 loss)
I0617 05:25:34.684185  4950 sgd_solver.cpp:105] Iteration 5100, lr = 0.01
I0617 05:26:33.359993  4950 solver.cpp:218] Iteration 5150 (0.852148 iter/s, 58.6753s/50 iters), loss = 0.00879005
I0617 05:26:33.360139  4950 solver.cpp:237]     Train net output #0: loss = 0.00879005 (* 1 = 0.00879005 loss)
I0617 05:26:33.360163  4950 sgd_solver.cpp:105] Iteration 5150, lr = 0.01
I0617 05:26:33.460566  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 05:27:32.045711  4950 solver.cpp:218] Iteration 5200 (0.852009 iter/s, 58.6848s/50 iters), loss = 0.00702349
I0617 05:27:32.045874  4950 solver.cpp:237]     Train net output #0: loss = 0.00702349 (* 1 = 0.00702349 loss)
I0617 05:27:32.045903  4950 sgd_solver.cpp:105] Iteration 5200, lr = 0.01
I0617 05:28:30.721407  4950 solver.cpp:218] Iteration 5250 (0.852154 iter/s, 58.6748s/50 iters), loss = 0.00967559
I0617 05:28:30.721571  4950 solver.cpp:237]     Train net output #0: loss = 0.00967559 (* 1 = 0.00967559 loss)
I0617 05:28:30.721596  4950 sgd_solver.cpp:105] Iteration 5250, lr = 0.01
I0617 05:28:54.294726  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 05:29:29.412212  4950 solver.cpp:218] Iteration 5300 (0.851935 iter/s, 58.6899s/50 iters), loss = 0.00916659
I0617 05:29:29.412387  4950 solver.cpp:237]     Train net output #0: loss = 0.00916659 (* 1 = 0.00916659 loss)
I0617 05:29:29.412412  4950 sgd_solver.cpp:105] Iteration 5300, lr = 0.01
I0617 05:30:28.095582  4950 solver.cpp:218] Iteration 5350 (0.852044 iter/s, 58.6824s/50 iters), loss = 0.00916248
I0617 05:30:28.095779  4950 solver.cpp:237]     Train net output #0: loss = 0.00916248 (* 1 = 0.00916248 loss)
I0617 05:30:28.095804  4950 sgd_solver.cpp:105] Iteration 5350, lr = 0.01
I0617 05:31:15.116477  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 05:31:26.792153  4950 solver.cpp:218] Iteration 5400 (0.851852 iter/s, 58.6956s/50 iters), loss = 0.0104535
I0617 05:31:26.792261  4950 solver.cpp:237]     Train net output #0: loss = 0.0104535 (* 1 = 0.0104535 loss)
I0617 05:31:26.792285  4950 sgd_solver.cpp:105] Iteration 5400, lr = 0.01
I0617 05:32:25.486549  4950 solver.cpp:218] Iteration 5450 (0.851882 iter/s, 58.6935s/50 iters), loss = 0.0119251
I0617 05:32:25.486718  4950 solver.cpp:237]     Train net output #0: loss = 0.0119251 (* 1 = 0.0119251 loss)
I0617 05:32:25.486743  4950 sgd_solver.cpp:105] Iteration 5450, lr = 0.01
I0617 05:33:24.170783  4950 solver.cpp:218] Iteration 5500 (0.852031 iter/s, 58.6833s/50 iters), loss = 0.0125194
I0617 05:33:24.170951  4950 solver.cpp:237]     Train net output #0: loss = 0.0125194 (* 1 = 0.0125194 loss)
I0617 05:33:24.170977  4950 sgd_solver.cpp:105] Iteration 5500, lr = 0.01
I0617 05:33:35.995313  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 05:34:22.855566  4950 solver.cpp:218] Iteration 5550 (0.852023 iter/s, 58.6839s/50 iters), loss = 0.0117373
I0617 05:34:22.856760  4950 solver.cpp:237]     Train net output #0: loss = 0.0117373 (* 1 = 0.0117373 loss)
I0617 05:34:22.856787  4950 sgd_solver.cpp:105] Iteration 5550, lr = 0.01
I0617 05:35:21.538116  4950 solver.cpp:218] Iteration 5600 (0.85207 iter/s, 58.6806s/50 iters), loss = 0.00998154
I0617 05:35:21.538328  4950 solver.cpp:237]     Train net output #0: loss = 0.00998154 (* 1 = 0.00998154 loss)
I0617 05:35:21.538353  4950 sgd_solver.cpp:105] Iteration 5600, lr = 0.01
I0617 05:35:56.808535  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 05:36:20.221184  4950 solver.cpp:218] Iteration 5650 (0.852048 iter/s, 58.6821s/50 iters), loss = 0.00800696
I0617 05:36:20.221295  4950 solver.cpp:237]     Train net output #0: loss = 0.00800696 (* 1 = 0.00800696 loss)
I0617 05:36:20.221318  4950 sgd_solver.cpp:105] Iteration 5650, lr = 0.01
I0617 05:37:18.908466  4950 solver.cpp:218] Iteration 5700 (0.851986 iter/s, 58.6864s/50 iters), loss = 0.00994415
I0617 05:37:18.908670  4950 solver.cpp:237]     Train net output #0: loss = 0.00994415 (* 1 = 0.00994415 loss)
I0617 05:37:18.908696  4950 sgd_solver.cpp:105] Iteration 5700, lr = 0.01
I0617 05:38:17.597054  4950 solver.cpp:218] Iteration 5750 (0.851968 iter/s, 58.6877s/50 iters), loss = 0.0136682
I0617 05:38:17.597703  4950 solver.cpp:237]     Train net output #0: loss = 0.0136682 (* 1 = 0.0136682 loss)
I0617 05:38:17.597728  4950 sgd_solver.cpp:105] Iteration 5750, lr = 0.01
I0617 05:38:17.678999  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 05:39:16.282973  4950 solver.cpp:218] Iteration 5800 (0.852013 iter/s, 58.6845s/50 iters), loss = 0.00819664
I0617 05:39:16.283109  4950 solver.cpp:237]     Train net output #0: loss = 0.00819664 (* 1 = 0.00819664 loss)
I0617 05:39:16.283134  4950 sgd_solver.cpp:105] Iteration 5800, lr = 0.01
I0617 05:40:14.967562  4950 solver.cpp:218] Iteration 5850 (0.852025 iter/s, 58.6837s/50 iters), loss = 0.00976747
I0617 05:40:14.967700  4950 solver.cpp:237]     Train net output #0: loss = 0.00976747 (* 1 = 0.00976747 loss)
I0617 05:40:14.967723  4950 sgd_solver.cpp:105] Iteration 5850, lr = 0.01
I0617 05:40:38.484063  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 05:41:13.651481  4950 solver.cpp:218] Iteration 5900 (0.852035 iter/s, 58.683s/50 iters), loss = 0.00886323
I0617 05:41:13.651739  4950 solver.cpp:237]     Train net output #0: loss = 0.00886323 (* 1 = 0.00886323 loss)
I0617 05:41:13.651765  4950 sgd_solver.cpp:105] Iteration 5900, lr = 0.01
I0617 05:42:12.322870  4950 solver.cpp:218] Iteration 5950 (0.852218 iter/s, 58.6704s/50 iters), loss = 0.0114761
I0617 05:42:12.323021  4950 solver.cpp:237]     Train net output #0: loss = 0.0114761 (* 1 = 0.0114761 loss)
I0617 05:42:12.323045  4950 sgd_solver.cpp:105] Iteration 5950, lr = 0.01
I0617 05:42:58.200215  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 05:43:11.003594  4950 solver.cpp:218] Iteration 6000 (0.852082 iter/s, 58.6798s/50 iters), loss = 0.0120215
I0617 05:43:11.003695  4950 solver.cpp:237]     Train net output #0: loss = 0.0120215 (* 1 = 0.0120215 loss)
I0617 05:43:11.003722  4950 sgd_solver.cpp:105] Iteration 6000, lr = 0.01
I0617 05:44:09.699858  4950 solver.cpp:218] Iteration 6050 (0.851855 iter/s, 58.6954s/50 iters), loss = 0.00839873
I0617 05:44:09.700124  4950 solver.cpp:237]     Train net output #0: loss = 0.00839873 (* 1 = 0.00839873 loss)
I0617 05:44:09.700150  4950 sgd_solver.cpp:105] Iteration 6050, lr = 0.01
I0617 05:45:08.384169  4950 solver.cpp:218] Iteration 6100 (0.852031 iter/s, 58.6833s/50 iters), loss = 0.0100317
I0617 05:45:08.384317  4950 solver.cpp:237]     Train net output #0: loss = 0.0100317 (* 1 = 0.0100317 loss)
I0617 05:45:08.384341  4950 sgd_solver.cpp:105] Iteration 6100, lr = 0.01
I0617 05:45:19.046982  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 05:46:07.069094  4950 solver.cpp:218] Iteration 6150 (0.85202 iter/s, 58.6841s/50 iters), loss = 0.0105457
I0617 05:46:07.069228  4950 solver.cpp:237]     Train net output #0: loss = 0.0105457 (* 1 = 0.0105457 loss)
I0617 05:46:07.069252  4950 sgd_solver.cpp:105] Iteration 6150, lr = 0.01
I0617 05:47:05.747766  4950 solver.cpp:218] Iteration 6200 (0.852111 iter/s, 58.6778s/50 iters), loss = 0.0113583
I0617 05:47:05.747900  4950 solver.cpp:237]     Train net output #0: loss = 0.0113583 (* 1 = 0.0113583 loss)
I0617 05:47:05.747938  4950 sgd_solver.cpp:105] Iteration 6200, lr = 0.01
I0617 05:47:39.857810  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 05:48:04.442311  4950 solver.cpp:218] Iteration 6250 (0.851881 iter/s, 58.6937s/50 iters), loss = 0.0113697
I0617 05:48:04.442441  4950 solver.cpp:237]     Train net output #0: loss = 0.0113697 (* 1 = 0.0113697 loss)
I0617 05:48:04.442466  4950 sgd_solver.cpp:105] Iteration 6250, lr = 0.01
I0617 05:49:03.173890  4950 solver.cpp:218] Iteration 6300 (0.851344 iter/s, 58.7307s/50 iters), loss = 0.0100964
I0617 05:49:03.174094  4950 solver.cpp:237]     Train net output #0: loss = 0.0100964 (* 1 = 0.0100964 loss)
I0617 05:49:03.174126  4950 sgd_solver.cpp:105] Iteration 6300, lr = 0.01
I0617 05:50:00.798444  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 05:50:01.908263  4950 solver.cpp:218] Iteration 6350 (0.851304 iter/s, 58.7334s/50 iters), loss = 0.00816807
I0617 05:50:01.908402  4950 solver.cpp:237]     Train net output #0: loss = 0.00816807 (* 1 = 0.00816807 loss)
I0617 05:50:01.908426  4950 sgd_solver.cpp:105] Iteration 6350, lr = 0.01
I0617 05:51:00.643432  4950 solver.cpp:218] Iteration 6400 (0.851292 iter/s, 58.7343s/50 iters), loss = 0.00972177
I0617 05:51:00.643705  4950 solver.cpp:237]     Train net output #0: loss = 0.00972177 (* 1 = 0.00972177 loss)
I0617 05:51:00.643730  4950 sgd_solver.cpp:105] Iteration 6400, lr = 0.01
I0617 05:51:59.370468  4950 solver.cpp:218] Iteration 6450 (0.851411 iter/s, 58.726s/50 iters), loss = 0.00941061
I0617 05:51:59.370666  4950 solver.cpp:237]     Train net output #0: loss = 0.00941061 (* 1 = 0.00941061 loss)
I0617 05:51:59.370692  4950 sgd_solver.cpp:105] Iteration 6450, lr = 0.01
I0617 05:52:21.747649  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 05:52:58.108603  4950 solver.cpp:218] Iteration 6500 (0.851249 iter/s, 58.7372s/50 iters), loss = 0.00916043
I0617 05:52:58.108809  4950 solver.cpp:237]     Train net output #0: loss = 0.00916043 (* 1 = 0.00916043 loss)
I0617 05:52:58.108834  4950 sgd_solver.cpp:105] Iteration 6500, lr = 0.01
I0617 05:53:56.836796  4950 solver.cpp:218] Iteration 6550 (0.851394 iter/s, 58.7272s/50 iters), loss = 0.01022
I0617 05:53:56.837050  4950 solver.cpp:237]     Train net output #0: loss = 0.01022 (* 1 = 0.01022 loss)
I0617 05:53:56.837075  4950 sgd_solver.cpp:105] Iteration 6550, lr = 0.01
I0617 05:54:42.699340  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 05:54:55.571499  4950 solver.cpp:218] Iteration 6600 (0.8513 iter/s, 58.7337s/50 iters), loss = 0.00645475
I0617 05:54:55.571621  4950 solver.cpp:237]     Train net output #0: loss = 0.00645475 (* 1 = 0.00645475 loss)
I0617 05:54:55.571646  4950 sgd_solver.cpp:105] Iteration 6600, lr = 0.01
I0617 05:55:54.307754  4950 solver.cpp:218] Iteration 6650 (0.851276 iter/s, 58.7354s/50 iters), loss = 0.00776747
I0617 05:55:54.307951  4950 solver.cpp:237]     Train net output #0: loss = 0.00776747 (* 1 = 0.00776747 loss)
I0617 05:55:54.307977  4950 sgd_solver.cpp:105] Iteration 6650, lr = 0.01
I0617 05:56:53.047977  4950 solver.cpp:218] Iteration 6700 (0.851219 iter/s, 58.7393s/50 iters), loss = 0.0107578
I0617 05:56:53.048532  4950 solver.cpp:237]     Train net output #0: loss = 0.0107578 (* 1 = 0.0107578 loss)
I0617 05:56:53.048568  4950 sgd_solver.cpp:105] Iteration 6700, lr = 0.01
I0617 05:57:03.676144  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 05:57:51.789713  4950 solver.cpp:218] Iteration 6750 (0.851202 iter/s, 58.7405s/50 iters), loss = 0.00834803
I0617 05:57:51.789870  4950 solver.cpp:237]     Train net output #0: loss = 0.00834803 (* 1 = 0.00834803 loss)
I0617 05:57:51.789892  4950 sgd_solver.cpp:105] Iteration 6750, lr = 0.01
I0617 05:58:50.474658  4950 solver.cpp:218] Iteration 6800 (0.85202 iter/s, 58.6841s/50 iters), loss = 0.00874835
I0617 05:58:50.474808  4950 solver.cpp:237]     Train net output #0: loss = 0.00874835 (* 1 = 0.00874835 loss)
I0617 05:58:50.474844  4950 sgd_solver.cpp:105] Iteration 6800, lr = 0.01
I0617 05:59:24.554116  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 05:59:49.161175  4950 solver.cpp:218] Iteration 6850 (0.851997 iter/s, 58.6856s/50 iters), loss = 0.0100232
I0617 05:59:49.161321  4950 solver.cpp:237]     Train net output #0: loss = 0.0100232 (* 1 = 0.0100232 loss)
I0617 05:59:49.161345  4950 sgd_solver.cpp:105] Iteration 6850, lr = 0.01
I0617 06:00:47.847234  4950 solver.cpp:218] Iteration 6900 (0.852003 iter/s, 58.6852s/50 iters), loss = 0.0124524
I0617 06:00:47.847379  4950 solver.cpp:237]     Train net output #0: loss = 0.0124524 (* 1 = 0.0124524 loss)
I0617 06:00:47.847405  4950 sgd_solver.cpp:105] Iteration 6900, lr = 0.01
I0617 06:01:45.379946  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 06:01:46.521391  4950 solver.cpp:218] Iteration 6950 (0.852174 iter/s, 58.6735s/50 iters), loss = 0.011149
I0617 06:01:46.521512  4950 solver.cpp:237]     Train net output #0: loss = 0.011149 (* 1 = 0.011149 loss)
I0617 06:01:46.521541  4950 sgd_solver.cpp:105] Iteration 6950, lr = 0.01
I0617 06:02:45.186575  4950 solver.cpp:218] Iteration 7000 (0.852304 iter/s, 58.6645s/50 iters), loss = 0.0110746
I0617 06:02:45.186699  4950 solver.cpp:237]     Train net output #0: loss = 0.0110746 (* 1 = 0.0110746 loss)
I0617 06:02:45.186724  4950 sgd_solver.cpp:105] Iteration 7000, lr = 0.01
I0617 06:03:43.866961  4950 solver.cpp:218] Iteration 7050 (0.852083 iter/s, 58.6797s/50 iters), loss = 0.00974029
I0617 06:03:43.867141  4950 solver.cpp:237]     Train net output #0: loss = 0.00974029 (* 1 = 0.00974029 loss)
I0617 06:03:43.867166  4950 sgd_solver.cpp:105] Iteration 7050, lr = 0.01
I0617 06:04:05.089258  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 06:04:42.539476  4950 solver.cpp:218] Iteration 7100 (0.852198 iter/s, 58.6718s/50 iters), loss = 0.011088
I0617 06:04:42.539626  4950 solver.cpp:237]     Train net output #0: loss = 0.011088 (* 1 = 0.011088 loss)
I0617 06:04:42.539652  4950 sgd_solver.cpp:105] Iteration 7100, lr = 0.01
I0617 06:05:41.208501  4950 solver.cpp:218] Iteration 7150 (0.852248 iter/s, 58.6683s/50 iters), loss = 0.0107406
I0617 06:05:41.208678  4950 solver.cpp:237]     Train net output #0: loss = 0.0107406 (* 1 = 0.0107406 loss)
I0617 06:05:41.208701  4950 sgd_solver.cpp:105] Iteration 7150, lr = 0.01
I0617 06:06:25.894913  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 06:06:39.877203  4950 solver.cpp:218] Iteration 7200 (0.852254 iter/s, 58.668s/50 iters), loss = 0.00947437
I0617 06:06:39.877324  4950 solver.cpp:237]     Train net output #0: loss = 0.00947437 (* 1 = 0.00947437 loss)
I0617 06:06:39.877347  4950 sgd_solver.cpp:105] Iteration 7200, lr = 0.01
I0617 06:07:38.550981  4950 solver.cpp:218] Iteration 7250 (0.852179 iter/s, 58.6731s/50 iters), loss = 0.0101731
I0617 06:07:38.551120  4950 solver.cpp:237]     Train net output #0: loss = 0.0101731 (* 1 = 0.0101731 loss)
I0617 06:07:38.551142  4950 sgd_solver.cpp:105] Iteration 7250, lr = 0.01
I0617 06:08:37.224964  4950 solver.cpp:218] Iteration 7300 (0.852176 iter/s, 58.6733s/50 iters), loss = 0.00935649
I0617 06:08:37.225510  4950 solver.cpp:237]     Train net output #0: loss = 0.00935649 (* 1 = 0.00935649 loss)
I0617 06:08:37.225543  4950 sgd_solver.cpp:105] Iteration 7300, lr = 0.01
I0617 06:08:46.687561  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 06:09:35.917240  4950 solver.cpp:218] Iteration 7350 (0.851917 iter/s, 58.6912s/50 iters), loss = 0.0090566
I0617 06:09:35.917366  4950 solver.cpp:237]     Train net output #0: loss = 0.0090566 (* 1 = 0.0090566 loss)
I0617 06:09:35.917388  4950 sgd_solver.cpp:105] Iteration 7350, lr = 0.01
I0617 06:10:34.604954  4950 solver.cpp:218] Iteration 7400 (0.851977 iter/s, 58.687s/50 iters), loss = 0.0083503
I0617 06:10:34.605124  4950 solver.cpp:237]     Train net output #0: loss = 0.0083503 (* 1 = 0.0083503 loss)
I0617 06:10:34.605149  4950 sgd_solver.cpp:105] Iteration 7400, lr = 0.01
I0617 06:11:07.533653  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 06:11:33.298308  4950 solver.cpp:218] Iteration 7450 (0.851896 iter/s, 58.6926s/50 iters), loss = 0.00909996
I0617 06:11:33.298411  4950 solver.cpp:237]     Train net output #0: loss = 0.00909996 (* 1 = 0.00909996 loss)
I0617 06:11:33.298435  4950 sgd_solver.cpp:105] Iteration 7450, lr = 0.01
I0617 06:12:31.983337  4950 solver.cpp:218] Iteration 7500 (0.852016 iter/s, 58.6844s/50 iters), loss = 0.00985507
I0617 06:12:31.983625  4950 solver.cpp:237]     Train net output #0: loss = 0.00985507 (* 1 = 0.00985507 loss)
I0617 06:12:31.983652  4950 sgd_solver.cpp:105] Iteration 7500, lr = 0.01
I0617 06:13:28.396953  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 06:13:30.659952  4950 solver.cpp:218] Iteration 7550 (0.85214 iter/s, 58.6758s/50 iters), loss = 0.00845633
I0617 06:13:30.660087  4950 solver.cpp:237]     Train net output #0: loss = 0.00845633 (* 1 = 0.00845633 loss)
I0617 06:13:30.660111  4950 sgd_solver.cpp:105] Iteration 7550, lr = 0.01
I0617 06:14:29.344542  4950 solver.cpp:218] Iteration 7600 (0.852022 iter/s, 58.6839s/50 iters), loss = 0.00949828
I0617 06:14:29.344689  4950 solver.cpp:237]     Train net output #0: loss = 0.00949828 (* 1 = 0.00949828 loss)
I0617 06:14:29.344713  4950 sgd_solver.cpp:105] Iteration 7600, lr = 0.01
I0617 06:15:28.018028  4950 solver.cpp:218] Iteration 7650 (0.852184 iter/s, 58.6728s/50 iters), loss = 0.0106494
I0617 06:15:28.018172  4950 solver.cpp:237]     Train net output #0: loss = 0.0106494 (* 1 = 0.0106494 loss)
I0617 06:15:28.018201  4950 sgd_solver.cpp:105] Iteration 7650, lr = 0.01
I0617 06:15:49.218670  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 06:16:26.699144  4950 solver.cpp:218] Iteration 7700 (0.852073 iter/s, 58.6804s/50 iters), loss = 0.0097197
I0617 06:16:26.699293  4950 solver.cpp:237]     Train net output #0: loss = 0.0097197 (* 1 = 0.0097197 loss)
I0617 06:16:26.699317  4950 sgd_solver.cpp:105] Iteration 7700, lr = 0.01
I0617 06:17:25.382395  4950 solver.cpp:218] Iteration 7750 (0.852043 iter/s, 58.6825s/50 iters), loss = 0.010599
I0617 06:17:25.382624  4950 solver.cpp:237]     Train net output #0: loss = 0.010599 (* 1 = 0.010599 loss)
I0617 06:17:25.382654  4950 sgd_solver.cpp:105] Iteration 7750, lr = 0.01
I0617 06:18:10.035169  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 06:18:24.060588  4950 solver.cpp:218] Iteration 7800 (0.852117 iter/s, 58.6774s/50 iters), loss = 0.00743008
I0617 06:18:24.060722  4950 solver.cpp:237]     Train net output #0: loss = 0.00743008 (* 1 = 0.00743008 loss)
I0617 06:18:24.060748  4950 sgd_solver.cpp:105] Iteration 7800, lr = 0.01
I0617 06:19:22.735615  4950 solver.cpp:218] Iteration 7850 (0.852161 iter/s, 58.6743s/50 iters), loss = 0.00934006
I0617 06:19:22.736284  4950 solver.cpp:237]     Train net output #0: loss = 0.00934006 (* 1 = 0.00934006 loss)
I0617 06:19:22.736310  4950 sgd_solver.cpp:105] Iteration 7850, lr = 0.01
I0617 06:20:21.415725  4950 solver.cpp:218] Iteration 7900 (0.852095 iter/s, 58.6789s/50 iters), loss = 0.00929309
I0617 06:20:21.415855  4950 solver.cpp:237]     Train net output #0: loss = 0.00929309 (* 1 = 0.00929309 loss)
I0617 06:20:21.415880  4950 sgd_solver.cpp:105] Iteration 7900, lr = 0.01
I0617 06:20:30.880394  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 06:21:20.102629  4950 solver.cpp:218] Iteration 7950 (0.851989 iter/s, 58.6862s/50 iters), loss = 0.00871183
I0617 06:21:20.102797  4950 solver.cpp:237]     Train net output #0: loss = 0.00871183 (* 1 = 0.00871183 loss)
I0617 06:21:20.102820  4950 sgd_solver.cpp:105] Iteration 7950, lr = 0.01
I0617 06:22:18.786280  4950 solver.cpp:218] Iteration 8000 (0.852037 iter/s, 58.6829s/50 iters), loss = 0.0102422
I0617 06:22:18.786417  4950 solver.cpp:237]     Train net output #0: loss = 0.0102422 (* 1 = 0.0102422 loss)
I0617 06:22:18.786445  4950 sgd_solver.cpp:105] Iteration 8000, lr = 0.01
I0617 06:22:50.549243  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 06:23:17.460995  4950 solver.cpp:218] Iteration 8050 (0.852166 iter/s, 58.674s/50 iters), loss = 0.00849332
I0617 06:23:17.461086  4950 solver.cpp:237]     Train net output #0: loss = 0.00849332 (* 1 = 0.00849332 loss)
I0617 06:23:17.461109  4950 sgd_solver.cpp:105] Iteration 8050, lr = 0.01
I0617 06:24:16.141119  4950 solver.cpp:218] Iteration 8100 (0.852087 iter/s, 58.6795s/50 iters), loss = 0.0103117
I0617 06:24:16.141286  4950 solver.cpp:237]     Train net output #0: loss = 0.0103117 (* 1 = 0.0103117 loss)
I0617 06:24:16.141311  4950 sgd_solver.cpp:105] Iteration 8100, lr = 0.01
I0617 06:25:11.382284  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 06:25:14.827577  4950 solver.cpp:218] Iteration 8150 (0.851996 iter/s, 58.6857s/50 iters), loss = 0.00929763
I0617 06:25:14.827668  4950 solver.cpp:237]     Train net output #0: loss = 0.00929763 (* 1 = 0.00929763 loss)
I0617 06:25:14.827690  4950 sgd_solver.cpp:105] Iteration 8150, lr = 0.01
I0617 06:26:13.501334  4950 solver.cpp:218] Iteration 8200 (0.852179 iter/s, 58.6731s/50 iters), loss = 0.0101002
I0617 06:26:13.501597  4950 solver.cpp:237]     Train net output #0: loss = 0.0101002 (* 1 = 0.0101002 loss)
I0617 06:26:13.501623  4950 sgd_solver.cpp:105] Iteration 8200, lr = 0.01
I0617 06:27:12.173871  4950 solver.cpp:218] Iteration 8250 (0.852199 iter/s, 58.6717s/50 iters), loss = 0.00834533
I0617 06:27:12.173997  4950 solver.cpp:237]     Train net output #0: loss = 0.00834533 (* 1 = 0.00834533 loss)
I0617 06:27:12.174021  4950 sgd_solver.cpp:105] Iteration 8250, lr = 0.01
I0617 06:27:32.201074  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 06:28:10.844790  4950 solver.cpp:218] Iteration 8300 (0.852221 iter/s, 58.6702s/50 iters), loss = 0.00850771
I0617 06:28:10.844933  4950 solver.cpp:237]     Train net output #0: loss = 0.00850771 (* 1 = 0.00850771 loss)
I0617 06:28:10.844959  4950 sgd_solver.cpp:105] Iteration 8300, lr = 0.01
I0617 06:29:09.511123  4950 solver.cpp:218] Iteration 8350 (0.852288 iter/s, 58.6656s/50 iters), loss = 0.0100878
I0617 06:29:09.511294  4950 solver.cpp:237]     Train net output #0: loss = 0.0100878 (* 1 = 0.0100878 loss)
I0617 06:29:09.511317  4950 sgd_solver.cpp:105] Iteration 8350, lr = 0.01
I0617 06:29:53.024673  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 06:30:08.190179  4950 solver.cpp:218] Iteration 8400 (0.852103 iter/s, 58.6783s/50 iters), loss = 0.00996852
I0617 06:30:08.190282  4950 solver.cpp:237]     Train net output #0: loss = 0.00996852 (* 1 = 0.00996852 loss)
I0617 06:30:08.190305  4950 sgd_solver.cpp:105] Iteration 8400, lr = 0.01
I0617 06:31:06.854604  4950 solver.cpp:218] Iteration 8450 (0.852315 iter/s, 58.6638s/50 iters), loss = 0.00949873
I0617 06:31:06.854730  4950 solver.cpp:237]     Train net output #0: loss = 0.00949873 (* 1 = 0.00949873 loss)
I0617 06:31:06.854754  4950 sgd_solver.cpp:105] Iteration 8450, lr = 0.01
I0617 06:32:05.534431  4950 solver.cpp:218] Iteration 8500 (0.852092 iter/s, 58.6791s/50 iters), loss = 0.00873002
I0617 06:32:05.534718  4950 solver.cpp:237]     Train net output #0: loss = 0.00873002 (* 1 = 0.00873002 loss)
I0617 06:32:05.534744  4950 sgd_solver.cpp:105] Iteration 8500, lr = 0.01
I0617 06:32:13.807978  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 06:33:04.230625  4950 solver.cpp:218] Iteration 8550 (0.851856 iter/s, 58.6953s/50 iters), loss = 0.0102162
I0617 06:33:04.230762  4950 solver.cpp:237]     Train net output #0: loss = 0.0102162 (* 1 = 0.0102162 loss)
I0617 06:33:04.230787  4950 sgd_solver.cpp:105] Iteration 8550, lr = 0.01
I0617 06:34:02.920387  4950 solver.cpp:218] Iteration 8600 (0.851948 iter/s, 58.689s/50 iters), loss = 0.0086113
I0617 06:34:02.920560  4950 solver.cpp:237]     Train net output #0: loss = 0.00861131 (* 1 = 0.00861131 loss)
I0617 06:34:02.920593  4950 sgd_solver.cpp:105] Iteration 8600, lr = 0.01
I0617 06:34:34.659469  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 06:35:01.599361  4950 solver.cpp:218] Iteration 8650 (0.852105 iter/s, 58.6782s/50 iters), loss = 0.0104949
I0617 06:35:01.599472  4950 solver.cpp:237]     Train net output #0: loss = 0.0104949 (* 1 = 0.0104949 loss)
I0617 06:35:01.599495  4950 sgd_solver.cpp:105] Iteration 8650, lr = 0.01
I0617 06:36:00.267662  4950 solver.cpp:218] Iteration 8700 (0.85226 iter/s, 58.6675s/50 iters), loss = 0.0112418
I0617 06:36:00.267855  4950 solver.cpp:237]     Train net output #0: loss = 0.0112418 (* 1 = 0.0112418 loss)
I0617 06:36:00.267881  4950 sgd_solver.cpp:105] Iteration 8700, lr = 0.01
I0617 06:36:55.489413  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 06:36:58.936271  4950 solver.cpp:218] Iteration 8750 (0.852257 iter/s, 58.6678s/50 iters), loss = 0.00746434
I0617 06:36:58.936399  4950 solver.cpp:237]     Train net output #0: loss = 0.00746434 (* 1 = 0.00746434 loss)
I0617 06:36:58.936422  4950 sgd_solver.cpp:105] Iteration 8750, lr = 0.01
I0617 06:37:57.597700  4950 solver.cpp:218] Iteration 8800 (0.85236 iter/s, 58.6607s/50 iters), loss = 0.00913617
I0617 06:37:57.597831  4950 solver.cpp:237]     Train net output #0: loss = 0.00913617 (* 1 = 0.00913617 loss)
I0617 06:37:57.597854  4950 sgd_solver.cpp:105] Iteration 8800, lr = 0.01
I0617 06:38:56.280086  4950 solver.cpp:218] Iteration 8850 (0.852056 iter/s, 58.6816s/50 iters), loss = 0.00949115
I0617 06:38:56.280242  4950 solver.cpp:237]     Train net output #0: loss = 0.00949115 (* 1 = 0.00949115 loss)
I0617 06:38:56.280267  4950 sgd_solver.cpp:105] Iteration 8850, lr = 0.01
I0617 06:39:16.303505  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 06:39:54.950073  4950 solver.cpp:218] Iteration 8900 (0.852237 iter/s, 58.6692s/50 iters), loss = 0.00954514
I0617 06:39:54.950222  4950 solver.cpp:237]     Train net output #0: loss = 0.00954514 (* 1 = 0.00954514 loss)
I0617 06:39:54.950249  4950 sgd_solver.cpp:105] Iteration 8900, lr = 0.01
I0617 06:40:53.633288  4950 solver.cpp:218] Iteration 8950 (0.852044 iter/s, 58.6824s/50 iters), loss = 0.0108679
I0617 06:40:53.633435  4950 solver.cpp:237]     Train net output #0: loss = 0.0108679 (* 1 = 0.0108679 loss)
I0617 06:40:53.633458  4950 sgd_solver.cpp:105] Iteration 8950, lr = 0.01
I0617 06:41:35.967618  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 06:41:52.306673  4950 solver.cpp:218] Iteration 9000 (0.852187 iter/s, 58.6726s/50 iters), loss = 0.00854415
I0617 06:41:52.306776  4950 solver.cpp:237]     Train net output #0: loss = 0.00854415 (* 1 = 0.00854415 loss)
I0617 06:41:52.306799  4950 sgd_solver.cpp:105] Iteration 9000, lr = 0.01
I0617 06:42:50.984560  4950 solver.cpp:218] Iteration 9050 (0.852121 iter/s, 58.6771s/50 iters), loss = 0.0113802
I0617 06:42:50.984689  4950 solver.cpp:237]     Train net output #0: loss = 0.0113802 (* 1 = 0.0113802 loss)
I0617 06:42:50.984714  4950 sgd_solver.cpp:105] Iteration 9050, lr = 0.01
I0617 06:43:49.666524  4950 solver.cpp:218] Iteration 9100 (0.852062 iter/s, 58.6812s/50 iters), loss = 0.0105821
I0617 06:43:49.666657  4950 solver.cpp:237]     Train net output #0: loss = 0.0105821 (* 1 = 0.0105821 loss)
I0617 06:43:49.666683  4950 sgd_solver.cpp:105] Iteration 9100, lr = 0.01
I0617 06:43:56.812557  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 06:44:48.335698  4950 solver.cpp:218] Iteration 9150 (0.852247 iter/s, 58.6684s/50 iters), loss = 0.0115015
I0617 06:44:48.335836  4950 solver.cpp:237]     Train net output #0: loss = 0.0115015 (* 1 = 0.0115015 loss)
I0617 06:44:48.335860  4950 sgd_solver.cpp:105] Iteration 9150, lr = 0.01
I0617 06:45:47.010987  4950 solver.cpp:218] Iteration 9200 (0.852159 iter/s, 58.6745s/50 iters), loss = 0.00895486
I0617 06:45:47.011129  4950 solver.cpp:237]     Train net output #0: loss = 0.00895486 (* 1 = 0.00895486 loss)
I0617 06:45:47.011153  4950 sgd_solver.cpp:105] Iteration 9200, lr = 0.01
I0617 06:46:17.590381  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 06:46:45.709075  4950 solver.cpp:218] Iteration 9250 (0.851828 iter/s, 58.6973s/50 iters), loss = 0.00948885
I0617 06:46:45.709208  4950 solver.cpp:237]     Train net output #0: loss = 0.00948885 (* 1 = 0.00948885 loss)
I0617 06:46:45.709254  4950 sgd_solver.cpp:105] Iteration 9250, lr = 0.01
I0617 06:47:44.403537  4950 solver.cpp:218] Iteration 9300 (0.85188 iter/s, 58.6937s/50 iters), loss = 0.00875023
I0617 06:47:44.403681  4950 solver.cpp:237]     Train net output #0: loss = 0.00875023 (* 1 = 0.00875023 loss)
I0617 06:47:44.403707  4950 sgd_solver.cpp:105] Iteration 9300, lr = 0.01
I0617 06:48:38.470824  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 06:48:43.107337  4950 solver.cpp:218] Iteration 9350 (0.851745 iter/s, 58.703s/50 iters), loss = 0.0108994
I0617 06:48:43.107452  4950 solver.cpp:237]     Train net output #0: loss = 0.0108994 (* 1 = 0.0108994 loss)
I0617 06:48:43.107475  4950 sgd_solver.cpp:105] Iteration 9350, lr = 0.01
I0617 06:49:41.824358  4950 solver.cpp:218] Iteration 9400 (0.851553 iter/s, 58.7163s/50 iters), loss = 0.00951555
I0617 06:49:41.824545  4950 solver.cpp:237]     Train net output #0: loss = 0.00951555 (* 1 = 0.00951555 loss)
I0617 06:49:41.824571  4950 sgd_solver.cpp:105] Iteration 9400, lr = 0.01
I0617 06:50:40.529108  4950 solver.cpp:218] Iteration 9450 (0.851732 iter/s, 58.7039s/50 iters), loss = 0.00797239
I0617 06:50:40.529270  4950 solver.cpp:237]     Train net output #0: loss = 0.00797239 (* 1 = 0.00797239 loss)
I0617 06:50:40.529295  4950 sgd_solver.cpp:105] Iteration 9450, lr = 0.01
I0617 06:50:59.374146  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 06:51:39.219414  4950 solver.cpp:218] Iteration 9500 (0.851942 iter/s, 58.6895s/50 iters), loss = 0.00766378
I0617 06:51:39.219631  4950 solver.cpp:237]     Train net output #0: loss = 0.00766378 (* 1 = 0.00766378 loss)
I0617 06:51:39.219671  4950 sgd_solver.cpp:105] Iteration 9500, lr = 0.01
I0617 06:52:37.875463  4950 solver.cpp:218] Iteration 9550 (0.85244 iter/s, 58.6551s/50 iters), loss = 0.0101422
I0617 06:52:37.875640  4950 solver.cpp:237]     Train net output #0: loss = 0.0101422 (* 1 = 0.0101422 loss)
I0617 06:52:37.875663  4950 sgd_solver.cpp:105] Iteration 9550, lr = 0.01
I0617 06:53:20.158538  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 06:53:36.511340  4950 solver.cpp:218] Iteration 9600 (0.852733 iter/s, 58.635s/50 iters), loss = 0.00840424
I0617 06:53:36.511485  4950 solver.cpp:237]     Train net output #0: loss = 0.00840424 (* 1 = 0.00840424 loss)
I0617 06:53:36.511525  4950 sgd_solver.cpp:105] Iteration 9600, lr = 0.01
I0617 06:54:35.154834  4950 solver.cpp:218] Iteration 9650 (0.852621 iter/s, 58.6427s/50 iters), loss = 0.0106372
I0617 06:54:35.154968  4950 solver.cpp:237]     Train net output #0: loss = 0.0106372 (* 1 = 0.0106372 loss)
I0617 06:54:35.154990  4950 sgd_solver.cpp:105] Iteration 9650, lr = 0.01
I0617 06:55:33.785588  4950 solver.cpp:218] Iteration 9700 (0.852806 iter/s, 58.63s/50 iters), loss = 0.00928387
I0617 06:55:33.785709  4950 solver.cpp:237]     Train net output #0: loss = 0.00928387 (* 1 = 0.00928387 loss)
I0617 06:55:33.785732  4950 sgd_solver.cpp:105] Iteration 9700, lr = 0.01
I0617 06:55:40.879318  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 06:56:32.421504  4950 solver.cpp:218] Iteration 9750 (0.852731 iter/s, 58.6351s/50 iters), loss = 0.00817368
I0617 06:56:32.421638  4950 solver.cpp:237]     Train net output #0: loss = 0.00817369 (* 1 = 0.00817369 loss)
I0617 06:56:32.421658  4950 sgd_solver.cpp:105] Iteration 9750, lr = 0.01
I0617 06:57:31.053339  4950 solver.cpp:218] Iteration 9800 (0.85279 iter/s, 58.6311s/50 iters), loss = 0.0100321
I0617 06:57:31.053458  4950 solver.cpp:237]     Train net output #0: loss = 0.0100321 (* 1 = 0.0100321 loss)
I0617 06:57:31.053493  4950 sgd_solver.cpp:105] Iteration 9800, lr = 0.01
I0617 06:58:01.590200  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 06:58:29.688407  4950 solver.cpp:218] Iteration 9850 (0.852743 iter/s, 58.6343s/50 iters), loss = 0.00981053
I0617 06:58:29.688495  4950 solver.cpp:237]     Train net output #0: loss = 0.00981053 (* 1 = 0.00981053 loss)
I0617 06:58:29.688522  4950 sgd_solver.cpp:105] Iteration 9850, lr = 0.01
I0617 06:59:28.353740  4950 solver.cpp:218] Iteration 9900 (0.852303 iter/s, 58.6646s/50 iters), loss = 0.00806872
I0617 06:59:28.353862  4950 solver.cpp:237]     Train net output #0: loss = 0.00806872 (* 1 = 0.00806872 loss)
I0617 06:59:28.353885  4950 sgd_solver.cpp:105] Iteration 9900, lr = 0.01
I0617 07:00:22.354439  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 07:00:26.997977  4950 solver.cpp:218] Iteration 9950 (0.85261 iter/s, 58.6435s/50 iters), loss = 0.0081322
I0617 07:00:26.998057  4950 solver.cpp:237]     Train net output #0: loss = 0.0081322 (* 1 = 0.0081322 loss)
I0617 07:00:26.998078  4950 sgd_solver.cpp:105] Iteration 9950, lr = 0.01
I0617 07:01:24.465924  4950 solver.cpp:447] Snapshotting to binary proto file mobilenet/mobile_cub_iter_10000.caffemodel
I0617 07:01:24.556784  4950 sgd_solver.cpp:273] Snapshotting solver state to binary proto file mobilenet/mobile_cub_iter_10000.solverstate
I0617 07:01:25.757963  4950 solver.cpp:218] Iteration 10000 (0.850929 iter/s, 58.7593s/50 iters), loss = 0.00858541
I0617 07:01:25.758054  4950 solver.cpp:237]     Train net output #0: loss = 0.00858542 (* 1 = 0.00858542 loss)
I0617 07:01:25.758074  4950 sgd_solver.cpp:105] Iteration 10000, lr = 0.01
I0617 07:02:24.420101  4950 solver.cpp:218] Iteration 10050 (0.852349 iter/s, 58.6614s/50 iters), loss = 0.0101371
I0617 07:02:24.420224  4950 solver.cpp:237]     Train net output #0: loss = 0.0101371 (* 1 = 0.0101371 loss)
I0617 07:02:24.420246  4950 sgd_solver.cpp:105] Iteration 10050, lr = 0.01
I0617 07:02:42.123442  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 07:03:23.087440  4950 solver.cpp:218] Iteration 10100 (0.852274 iter/s, 58.6666s/50 iters), loss = 0.0079594
I0617 07:03:23.087625  4950 solver.cpp:237]     Train net output #0: loss = 0.0079594 (* 1 = 0.0079594 loss)
I0617 07:03:23.087646  4950 sgd_solver.cpp:105] Iteration 10100, lr = 0.01
I0617 07:04:21.735605  4950 solver.cpp:218] Iteration 10150 (0.852554 iter/s, 58.6473s/50 iters), loss = 0.0116695
I0617 07:04:21.735743  4950 solver.cpp:237]     Train net output #0: loss = 0.0116695 (* 1 = 0.0116695 loss)
I0617 07:04:21.735766  4950 sgd_solver.cpp:105] Iteration 10150, lr = 0.01
I0617 07:05:02.889680  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 07:05:20.386529  4950 solver.cpp:218] Iteration 10200 (0.852513 iter/s, 58.6502s/50 iters), loss = 0.00861342
I0617 07:05:20.386616  4950 solver.cpp:237]     Train net output #0: loss = 0.00861343 (* 1 = 0.00861343 loss)
I0617 07:05:20.386638  4950 sgd_solver.cpp:105] Iteration 10200, lr = 0.01
I0617 07:06:19.028919  4950 solver.cpp:218] Iteration 10250 (0.852636 iter/s, 58.6416s/50 iters), loss = 0.00891254
I0617 07:06:19.029062  4950 solver.cpp:237]     Train net output #0: loss = 0.00891255 (* 1 = 0.00891255 loss)
I0617 07:06:19.029089  4950 sgd_solver.cpp:105] Iteration 10250, lr = 0.01
I0617 07:07:17.680536  4950 solver.cpp:218] Iteration 10300 (0.852503 iter/s, 58.6508s/50 iters), loss = 0.00792982
I0617 07:07:17.680655  4950 solver.cpp:237]     Train net output #0: loss = 0.00792982 (* 1 = 0.00792982 loss)
I0617 07:07:17.680681  4950 sgd_solver.cpp:105] Iteration 10300, lr = 0.01
I0617 07:07:23.640811  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 07:08:16.325278  4950 solver.cpp:218] Iteration 10350 (0.852602 iter/s, 58.644s/50 iters), loss = 0.00981774
I0617 07:08:16.325417  4950 solver.cpp:237]     Train net output #0: loss = 0.00981774 (* 1 = 0.00981774 loss)
I0617 07:08:16.325440  4950 sgd_solver.cpp:105] Iteration 10350, lr = 0.01
I0617 07:09:14.959681  4950 solver.cpp:218] Iteration 10400 (0.852753 iter/s, 58.6336s/50 iters), loss = 0.00981718
I0617 07:09:14.959803  4950 solver.cpp:237]     Train net output #0: loss = 0.00981719 (* 1 = 0.00981719 loss)
I0617 07:09:14.959827  4950 sgd_solver.cpp:105] Iteration 10400, lr = 0.01
I0617 07:09:44.373983  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 07:10:13.606201  4950 solver.cpp:218] Iteration 10450 (0.852576 iter/s, 58.6458s/50 iters), loss = 0.0100063
I0617 07:10:13.606338  4950 solver.cpp:237]     Train net output #0: loss = 0.0100063 (* 1 = 0.0100063 loss)
I0617 07:10:13.606360  4950 sgd_solver.cpp:105] Iteration 10450, lr = 0.01
I0617 07:11:12.258615  4950 solver.cpp:218] Iteration 10500 (0.85249 iter/s, 58.6517s/50 iters), loss = 0.0100236
I0617 07:11:12.258756  4950 solver.cpp:237]     Train net output #0: loss = 0.0100236 (* 1 = 0.0100236 loss)
I0617 07:11:12.258780  4950 sgd_solver.cpp:105] Iteration 10500, lr = 0.01
I0617 07:12:05.116734  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 07:12:10.922616  4950 solver.cpp:218] Iteration 10550 (0.852322 iter/s, 58.6633s/50 iters), loss = 0.00945406
I0617 07:12:10.922703  4950 solver.cpp:237]     Train net output #0: loss = 0.00945406 (* 1 = 0.00945406 loss)
I0617 07:12:10.922725  4950 sgd_solver.cpp:105] Iteration 10550, lr = 0.01
I0617 07:13:09.563544  4950 solver.cpp:218] Iteration 10600 (0.852657 iter/s, 58.6403s/50 iters), loss = 0.00746373
I0617 07:13:09.563675  4950 solver.cpp:237]     Train net output #0: loss = 0.00746373 (* 1 = 0.00746373 loss)
I0617 07:13:09.563699  4950 sgd_solver.cpp:105] Iteration 10600, lr = 0.01
I0617 07:14:08.221899  4950 solver.cpp:218] Iteration 10650 (0.852404 iter/s, 58.6576s/50 iters), loss = 0.00935837
I0617 07:14:08.222002  4950 solver.cpp:237]     Train net output #0: loss = 0.00935837 (* 1 = 0.00935837 loss)
I0617 07:14:08.222023  4950 sgd_solver.cpp:105] Iteration 10650, lr = 0.01
I0617 07:14:25.870304  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 07:15:06.873482  4950 solver.cpp:218] Iteration 10700 (0.852502 iter/s, 58.6509s/50 iters), loss = 0.00926861
I0617 07:15:06.873627  4950 solver.cpp:237]     Train net output #0: loss = 0.00926861 (* 1 = 0.00926861 loss)
I0617 07:15:06.873649  4950 sgd_solver.cpp:105] Iteration 10700, lr = 0.01
I0617 07:16:05.527381  4950 solver.cpp:218] Iteration 10750 (0.852469 iter/s, 58.6532s/50 iters), loss = 0.0102256
I0617 07:16:05.527530  4950 solver.cpp:237]     Train net output #0: loss = 0.0102256 (* 1 = 0.0102256 loss)
I0617 07:16:05.527557  4950 sgd_solver.cpp:105] Iteration 10750, lr = 0.01
I0617 07:16:46.667348  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 07:17:04.188648  4950 solver.cpp:218] Iteration 10800 (0.852362 iter/s, 58.6605s/50 iters), loss = 0.0100154
I0617 07:17:04.188733  4950 solver.cpp:237]     Train net output #0: loss = 0.0100154 (* 1 = 0.0100154 loss)
I0617 07:17:04.188755  4950 sgd_solver.cpp:105] Iteration 10800, lr = 0.01
I0617 07:18:02.833464  4950 solver.cpp:218] Iteration 10850 (0.8526 iter/s, 58.6441s/50 iters), loss = 0.00849965
I0617 07:18:02.833601  4950 solver.cpp:237]     Train net output #0: loss = 0.00849965 (* 1 = 0.00849965 loss)
I0617 07:18:02.833626  4950 sgd_solver.cpp:105] Iteration 10850, lr = 0.01
I0617 07:19:01.474256  4950 solver.cpp:218] Iteration 10900 (0.85266 iter/s, 58.6401s/50 iters), loss = 0.0110402
I0617 07:19:01.474505  4950 solver.cpp:237]     Train net output #0: loss = 0.0110402 (* 1 = 0.0110402 loss)
I0617 07:19:01.474534  4950 sgd_solver.cpp:105] Iteration 10900, lr = 0.01
I0617 07:19:07.392431  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 07:20:00.132246  4950 solver.cpp:218] Iteration 10950 (0.852411 iter/s, 58.6572s/50 iters), loss = 0.00763544
I0617 07:20:00.132385  4950 solver.cpp:237]     Train net output #0: loss = 0.00763544 (* 1 = 0.00763544 loss)
I0617 07:20:00.132410  4950 sgd_solver.cpp:105] Iteration 10950, lr = 0.01
I0617 07:20:58.780418  4950 solver.cpp:218] Iteration 11000 (0.852552 iter/s, 58.6475s/50 iters), loss = 0.00888935
I0617 07:20:58.780553  4950 solver.cpp:237]     Train net output #0: loss = 0.00888935 (* 1 = 0.00888935 loss)
I0617 07:20:58.780578  4950 sgd_solver.cpp:105] Iteration 11000, lr = 0.01
I0617 07:21:27.037477  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 07:21:57.437517  4950 solver.cpp:218] Iteration 11050 (0.852422 iter/s, 58.6564s/50 iters), loss = 0.00842474
I0617 07:21:57.437717  4950 solver.cpp:237]     Train net output #0: loss = 0.00842475 (* 1 = 0.00842475 loss)
I0617 07:21:57.437739  4950 sgd_solver.cpp:105] Iteration 11050, lr = 0.01
I0617 07:22:56.091334  4950 solver.cpp:218] Iteration 11100 (0.852471 iter/s, 58.653s/50 iters), loss = 0.00906181
I0617 07:22:56.091460  4950 solver.cpp:237]     Train net output #0: loss = 0.00906181 (* 1 = 0.00906181 loss)
I0617 07:22:56.091481  4950 sgd_solver.cpp:105] Iteration 11100, lr = 0.01
I0617 07:23:47.788669  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 07:23:54.748085  4950 solver.cpp:218] Iteration 11150 (0.852427 iter/s, 58.656s/50 iters), loss = 0.00902718
I0617 07:23:54.748191  4950 solver.cpp:237]     Train net output #0: loss = 0.00902718 (* 1 = 0.00902718 loss)
I0617 07:23:54.748214  4950 sgd_solver.cpp:105] Iteration 11150, lr = 0.01
I0617 07:24:53.409118  4950 solver.cpp:218] Iteration 11200 (0.852365 iter/s, 58.6603s/50 iters), loss = 0.00992329
I0617 07:24:53.409253  4950 solver.cpp:237]     Train net output #0: loss = 0.00992329 (* 1 = 0.00992329 loss)
I0617 07:24:53.409276  4950 sgd_solver.cpp:105] Iteration 11200, lr = 0.01
I0617 07:25:52.066221  4950 solver.cpp:218] Iteration 11250 (0.852422 iter/s, 58.6564s/50 iters), loss = 0.00884778
I0617 07:25:52.066342  4950 solver.cpp:237]     Train net output #0: loss = 0.00884778 (* 1 = 0.00884778 loss)
I0617 07:25:52.066365  4950 sgd_solver.cpp:105] Iteration 11250, lr = 0.01
I0617 07:26:08.566967  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 07:26:50.718541  4950 solver.cpp:218] Iteration 11300 (0.852491 iter/s, 58.6516s/50 iters), loss = 0.0102586
I0617 07:26:50.718667  4950 solver.cpp:237]     Train net output #0: loss = 0.0102586 (* 1 = 0.0102586 loss)
I0617 07:26:50.718688  4950 sgd_solver.cpp:105] Iteration 11300, lr = 0.01
I0617 07:27:49.379503  4950 solver.cpp:218] Iteration 11350 (0.852365 iter/s, 58.6603s/50 iters), loss = 0.00851895
I0617 07:27:49.379674  4950 solver.cpp:237]     Train net output #0: loss = 0.00851895 (* 1 = 0.00851895 loss)
I0617 07:27:49.379698  4950 sgd_solver.cpp:105] Iteration 11350, lr = 0.01
I0617 07:28:29.350693  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 07:28:48.024236  4950 solver.cpp:218] Iteration 11400 (0.852602 iter/s, 58.644s/50 iters), loss = 0.0085198
I0617 07:28:48.024322  4950 solver.cpp:237]     Train net output #0: loss = 0.00851981 (* 1 = 0.00851981 loss)
I0617 07:28:48.024344  4950 sgd_solver.cpp:105] Iteration 11400, lr = 0.01
I0617 07:29:46.663328  4950 solver.cpp:218] Iteration 11450 (0.852683 iter/s, 58.6385s/50 iters), loss = 0.0100452
I0617 07:29:46.663511  4950 solver.cpp:237]     Train net output #0: loss = 0.0100452 (* 1 = 0.0100452 loss)
I0617 07:29:46.663540  4950 sgd_solver.cpp:105] Iteration 11450, lr = 0.01
I0617 07:30:45.306828  4950 solver.cpp:218] Iteration 11500 (0.85262 iter/s, 58.6428s/50 iters), loss = 0.0103895
I0617 07:30:45.307016  4950 solver.cpp:237]     Train net output #0: loss = 0.0103895 (* 1 = 0.0103895 loss)
I0617 07:30:45.307037  4950 sgd_solver.cpp:105] Iteration 11500, lr = 0.01
I0617 07:30:50.052054  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 07:31:43.947132  4950 solver.cpp:218] Iteration 11550 (0.852666 iter/s, 58.6396s/50 iters), loss = 0.00768005
I0617 07:31:43.947329  4950 solver.cpp:237]     Train net output #0: loss = 0.00768006 (* 1 = 0.00768006 loss)
I0617 07:31:43.947352  4950 sgd_solver.cpp:105] Iteration 11550, lr = 0.01
I0617 07:32:42.593144  4950 solver.cpp:218] Iteration 11600 (0.852584 iter/s, 58.6453s/50 iters), loss = 0.00993419
I0617 07:32:42.593269  4950 solver.cpp:237]     Train net output #0: loss = 0.00993419 (* 1 = 0.00993419 loss)
I0617 07:32:42.593292  4950 sgd_solver.cpp:105] Iteration 11600, lr = 0.01
I0617 07:33:10.804401  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 07:33:41.233229  4950 solver.cpp:218] Iteration 11650 (0.852669 iter/s, 58.6394s/50 iters), loss = 0.00795377
I0617 07:33:41.233361  4950 solver.cpp:237]     Train net output #0: loss = 0.00795377 (* 1 = 0.00795377 loss)
I0617 07:33:41.233397  4950 sgd_solver.cpp:105] Iteration 11650, lr = 0.01
I0617 07:34:39.884874  4950 solver.cpp:218] Iteration 11700 (0.852501 iter/s, 58.651s/50 iters), loss = 0.00833853
I0617 07:34:39.885000  4950 solver.cpp:237]     Train net output #0: loss = 0.00833854 (* 1 = 0.00833854 loss)
I0617 07:34:39.885022  4950 sgd_solver.cpp:105] Iteration 11700, lr = 0.01
I0617 07:35:31.549590  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 07:35:38.531538  4950 solver.cpp:218] Iteration 11750 (0.852574 iter/s, 58.6459s/50 iters), loss = 0.00789473
I0617 07:35:38.531651  4950 solver.cpp:237]     Train net output #0: loss = 0.00789474 (* 1 = 0.00789474 loss)
I0617 07:35:38.531679  4950 sgd_solver.cpp:105] Iteration 11750, lr = 0.01
I0617 07:36:37.172106  4950 solver.cpp:218] Iteration 11800 (0.852661 iter/s, 58.6399s/50 iters), loss = 0.00759497
I0617 07:36:37.172242  4950 solver.cpp:237]     Train net output #0: loss = 0.00759497 (* 1 = 0.00759497 loss)
I0617 07:36:37.172266  4950 sgd_solver.cpp:105] Iteration 11800, lr = 0.01
I0617 07:37:35.836968  4950 solver.cpp:218] Iteration 11850 (0.852309 iter/s, 58.6642s/50 iters), loss = 0.00928139
I0617 07:37:35.837116  4950 solver.cpp:237]     Train net output #0: loss = 0.0092814 (* 1 = 0.0092814 loss)
I0617 07:37:35.837137  4950 sgd_solver.cpp:105] Iteration 11850, lr = 0.01
I0617 07:37:52.336519  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 07:38:34.492930  4950 solver.cpp:218] Iteration 11900 (0.852439 iter/s, 58.6552s/50 iters), loss = 0.00960099
I0617 07:38:34.493144  4950 solver.cpp:237]     Train net output #0: loss = 0.00960099 (* 1 = 0.00960099 loss)
I0617 07:38:34.493185  4950 sgd_solver.cpp:105] Iteration 11900, lr = 0.01
I0617 07:39:33.139286  4950 solver.cpp:218] Iteration 11950 (0.852579 iter/s, 58.6456s/50 iters), loss = 0.00895065
I0617 07:39:33.139395  4950 solver.cpp:237]     Train net output #0: loss = 0.00895065 (* 1 = 0.00895065 loss)
I0617 07:39:33.139418  4950 sgd_solver.cpp:105] Iteration 11950, lr = 0.01
I0617 07:40:11.932293  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 07:40:31.787161  4950 solver.cpp:218] Iteration 12000 (0.852556 iter/s, 58.6472s/50 iters), loss = 0.0106875
I0617 07:40:31.787289  4950 solver.cpp:237]     Train net output #0: loss = 0.0106875 (* 1 = 0.0106875 loss)
I0617 07:40:31.787318  4950 sgd_solver.cpp:105] Iteration 12000, lr = 0.01
I0617 07:41:30.429819  4950 solver.cpp:218] Iteration 12050 (0.852631 iter/s, 58.642s/50 iters), loss = 0.00851712
I0617 07:41:30.429956  4950 solver.cpp:237]     Train net output #0: loss = 0.00851712 (* 1 = 0.00851712 loss)
I0617 07:41:30.429980  4950 sgd_solver.cpp:105] Iteration 12050, lr = 0.01
I0617 07:42:29.079416  4950 solver.cpp:218] Iteration 12100 (0.852531 iter/s, 58.6489s/50 iters), loss = 0.00936441
I0617 07:42:29.079613  4950 solver.cpp:237]     Train net output #0: loss = 0.00936441 (* 1 = 0.00936441 loss)
I0617 07:42:29.079643  4950 sgd_solver.cpp:105] Iteration 12100, lr = 0.01
I0617 07:42:32.701552  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 07:43:27.729329  4950 solver.cpp:218] Iteration 12150 (0.852526 iter/s, 58.6492s/50 iters), loss = 0.00692685
I0617 07:43:27.729456  4950 solver.cpp:237]     Train net output #0: loss = 0.00692685 (* 1 = 0.00692685 loss)
I0617 07:43:27.729485  4950 sgd_solver.cpp:105] Iteration 12150, lr = 0.01
I0617 07:44:26.381546  4950 solver.cpp:218] Iteration 12200 (0.85249 iter/s, 58.6517s/50 iters), loss = 0.00887401
I0617 07:44:26.381685  4950 solver.cpp:237]     Train net output #0: loss = 0.00887401 (* 1 = 0.00887401 loss)
I0617 07:44:26.381708  4950 sgd_solver.cpp:105] Iteration 12200, lr = 0.01
I0617 07:44:53.443560  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 07:45:25.039014  4950 solver.cpp:218] Iteration 12250 (0.852413 iter/s, 58.657s/50 iters), loss = 0.0102587
I0617 07:45:25.039129  4950 solver.cpp:237]     Train net output #0: loss = 0.0102587 (* 1 = 0.0102587 loss)
I0617 07:45:25.039161  4950 sgd_solver.cpp:105] Iteration 12250, lr = 0.01
I0617 07:46:23.679662  4950 solver.cpp:218] Iteration 12300 (0.852658 iter/s, 58.6402s/50 iters), loss = 0.00876991
I0617 07:46:23.679800  4950 solver.cpp:237]     Train net output #0: loss = 0.00876991 (* 1 = 0.00876991 loss)
I0617 07:46:23.679822  4950 sgd_solver.cpp:105] Iteration 12300, lr = 0.01
I0617 07:47:14.205101  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 07:47:22.323177  4950 solver.cpp:218] Iteration 12350 (0.852616 iter/s, 58.643s/50 iters), loss = 0.00848308
I0617 07:47:22.323264  4950 solver.cpp:237]     Train net output #0: loss = 0.00848308 (* 1 = 0.00848308 loss)
I0617 07:47:22.323287  4950 sgd_solver.cpp:105] Iteration 12350, lr = 0.01
I0617 07:48:20.958365  4950 solver.cpp:218] Iteration 12400 (0.852737 iter/s, 58.6347s/50 iters), loss = 0.00914627
I0617 07:48:20.958489  4950 solver.cpp:237]     Train net output #0: loss = 0.00914627 (* 1 = 0.00914627 loss)
I0617 07:48:20.958518  4950 sgd_solver.cpp:105] Iteration 12400, lr = 0.01
I0617 07:49:19.600319  4950 solver.cpp:218] Iteration 12450 (0.852639 iter/s, 58.6414s/50 iters), loss = 0.0091628
I0617 07:49:19.600486  4950 solver.cpp:237]     Train net output #0: loss = 0.0091628 (* 1 = 0.0091628 loss)
I0617 07:49:19.600509  4950 sgd_solver.cpp:105] Iteration 12450, lr = 0.01
I0617 07:49:34.917662  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 07:50:18.261363  4950 solver.cpp:218] Iteration 12500 (0.852362 iter/s, 58.6605s/50 iters), loss = 0.00944298
I0617 07:50:18.261476  4950 solver.cpp:237]     Train net output #0: loss = 0.00944298 (* 1 = 0.00944298 loss)
I0617 07:50:18.261497  4950 sgd_solver.cpp:105] Iteration 12500, lr = 0.01
I0617 07:51:16.894435  4950 solver.cpp:218] Iteration 12550 (0.852768 iter/s, 58.6326s/50 iters), loss = 0.00798308
I0617 07:51:16.894670  4950 solver.cpp:237]     Train net output #0: loss = 0.00798308 (* 1 = 0.00798308 loss)
I0617 07:51:16.894697  4950 sgd_solver.cpp:105] Iteration 12550, lr = 0.01
I0617 07:51:55.657814  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 07:52:15.532838  4950 solver.cpp:218] Iteration 12600 (0.852693 iter/s, 58.6378s/50 iters), loss = 0.00920056
I0617 07:52:15.532953  4950 solver.cpp:237]     Train net output #0: loss = 0.00920056 (* 1 = 0.00920056 loss)
I0617 07:52:15.532974  4950 sgd_solver.cpp:105] Iteration 12600, lr = 0.01
I0617 07:53:14.168295  4950 solver.cpp:218] Iteration 12650 (0.852734 iter/s, 58.635s/50 iters), loss = 0.00861028
I0617 07:53:14.168419  4950 solver.cpp:237]     Train net output #0: loss = 0.00861029 (* 1 = 0.00861029 loss)
I0617 07:53:14.168442  4950 sgd_solver.cpp:105] Iteration 12650, lr = 0.01
I0617 07:54:12.805048  4950 solver.cpp:218] Iteration 12700 (0.852715 iter/s, 58.6362s/50 iters), loss = 0.00746902
I0617 07:54:12.805200  4950 solver.cpp:237]     Train net output #0: loss = 0.00746903 (* 1 = 0.00746903 loss)
I0617 07:54:12.805222  4950 sgd_solver.cpp:105] Iteration 12700, lr = 0.01
I0617 07:54:16.400179  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 07:55:11.449810  4950 solver.cpp:218] Iteration 12750 (0.852599 iter/s, 58.6442s/50 iters), loss = 0.0115429
I0617 07:55:11.449931  4950 solver.cpp:237]     Train net output #0: loss = 0.0115429 (* 1 = 0.0115429 loss)
I0617 07:55:11.449954  4950 sgd_solver.cpp:105] Iteration 12750, lr = 0.01
I0617 07:56:10.091348  4950 solver.cpp:218] Iteration 12800 (0.852645 iter/s, 58.641s/50 iters), loss = 0.0127045
I0617 07:56:10.091480  4950 solver.cpp:237]     Train net output #0: loss = 0.0127045 (* 1 = 0.0127045 loss)
I0617 07:56:10.091501  4950 sgd_solver.cpp:105] Iteration 12800, lr = 0.01
I0617 07:56:37.144418  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 07:57:08.727979  4950 solver.cpp:218] Iteration 12850 (0.852717 iter/s, 58.6361s/50 iters), loss = 0.00954201
I0617 07:57:08.728150  4950 solver.cpp:237]     Train net output #0: loss = 0.00954201 (* 1 = 0.00954201 loss)
I0617 07:57:08.728173  4950 sgd_solver.cpp:105] Iteration 12850, lr = 0.01
I0617 07:58:07.371078  4950 solver.cpp:218] Iteration 12900 (0.852624 iter/s, 58.6425s/50 iters), loss = 0.00866082
I0617 07:58:07.371210  4950 solver.cpp:237]     Train net output #0: loss = 0.00866082 (* 1 = 0.00866082 loss)
I0617 07:58:07.371237  4950 sgd_solver.cpp:105] Iteration 12900, lr = 0.01
I0617 07:58:57.868543  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 07:59:06.007648  4950 solver.cpp:218] Iteration 12950 (0.852718 iter/s, 58.636s/50 iters), loss = 0.0390816
I0617 07:59:06.007735  4950 solver.cpp:237]     Train net output #0: loss = 0.0390816 (* 1 = 0.0390816 loss)
I0617 07:59:06.007756  4950 sgd_solver.cpp:105] Iteration 12950, lr = 0.01
I0617 08:00:04.642894  4950 solver.cpp:218] Iteration 13000 (0.852737 iter/s, 58.6348s/50 iters), loss = 0.942616
I0617 08:00:04.643014  4950 solver.cpp:237]     Train net output #0: loss = 0.942616 (* 1 = 0.942616 loss)
I0617 08:00:04.643038  4950 sgd_solver.cpp:105] Iteration 13000, lr = 0.01
I0617 08:01:03.284667  4950 solver.cpp:218] Iteration 13050 (0.852642 iter/s, 58.6412s/50 iters), loss = 1.31855
I0617 08:01:03.284793  4950 solver.cpp:237]     Train net output #0: loss = 1.31855 (* 1 = 1.31855 loss)
I0617 08:01:03.284819  4950 sgd_solver.cpp:105] Iteration 13050, lr = 0.01
I0617 08:01:17.462959  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 08:02:01.933573  4950 solver.cpp:218] Iteration 13100 (0.852539 iter/s, 58.6484s/50 iters), loss = 0.790091
I0617 08:02:01.933722  4950 solver.cpp:237]     Train net output #0: loss = 0.790091 (* 1 = 0.790091 loss)
I0617 08:02:01.933744  4950 sgd_solver.cpp:105] Iteration 13100, lr = 0.01
I0617 08:03:00.592633  4950 solver.cpp:218] Iteration 13150 (0.852391 iter/s, 58.6585s/50 iters), loss = 0.8225
I0617 08:03:00.592775  4950 solver.cpp:237]     Train net output #0: loss = 0.8225 (* 1 = 0.8225 loss)
I0617 08:03:00.592798  4950 sgd_solver.cpp:105] Iteration 13150, lr = 0.01
I0617 08:03:38.190023  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 08:03:59.244702  4950 solver.cpp:218] Iteration 13200 (0.852494 iter/s, 58.6515s/50 iters), loss = 0.611602
I0617 08:03:59.244828  4950 solver.cpp:237]     Train net output #0: loss = 0.611602 (* 1 = 0.611602 loss)
I0617 08:03:59.244858  4950 sgd_solver.cpp:105] Iteration 13200, lr = 0.01
I0617 08:04:57.893069  4950 solver.cpp:218] Iteration 13250 (0.852547 iter/s, 58.6478s/50 iters), loss = 0.400221
I0617 08:04:57.893389  4950 solver.cpp:237]     Train net output #0: loss = 0.400221 (* 1 = 0.400221 loss)
I0617 08:04:57.893435  4950 sgd_solver.cpp:105] Iteration 13250, lr = 0.01
I0617 08:05:56.529937  4950 solver.cpp:218] Iteration 13300 (0.852716 iter/s, 58.6362s/50 iters), loss = 0.527842
I0617 08:05:56.530097  4950 solver.cpp:237]     Train net output #0: loss = 0.527842 (* 1 = 0.527842 loss)
I0617 08:05:56.530119  4950 sgd_solver.cpp:105] Iteration 13300, lr = 0.01
I0617 08:05:58.969998  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 08:06:55.179780  4950 solver.cpp:218] Iteration 13350 (0.852526 iter/s, 58.6493s/50 iters), loss = 0.2641
I0617 08:06:55.179895  4950 solver.cpp:237]     Train net output #0: loss = 0.2641 (* 1 = 0.2641 loss)
I0617 08:06:55.179918  4950 sgd_solver.cpp:105] Iteration 13350, lr = 0.01
I0617 08:07:53.854712  4950 solver.cpp:218] Iteration 13400 (0.852161 iter/s, 58.6744s/50 iters), loss = 0.312127
I0617 08:07:53.854948  4950 solver.cpp:237]     Train net output #0: loss = 0.312127 (* 1 = 0.312127 loss)
I0617 08:07:53.854972  4950 sgd_solver.cpp:105] Iteration 13400, lr = 0.01
I0617 08:08:19.758224  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 08:08:52.528584  4950 solver.cpp:218] Iteration 13450 (0.852178 iter/s, 58.6732s/50 iters), loss = 0.241482
I0617 08:08:52.528769  4950 solver.cpp:237]     Train net output #0: loss = 0.241482 (* 1 = 0.241482 loss)
I0617 08:08:52.528792  4950 sgd_solver.cpp:105] Iteration 13450, lr = 0.01
I0617 08:09:51.207442  4950 solver.cpp:218] Iteration 13500 (0.852105 iter/s, 58.6782s/50 iters), loss = 0.242653
I0617 08:09:51.207597  4950 solver.cpp:237]     Train net output #0: loss = 0.242653 (* 1 = 0.242653 loss)
I0617 08:09:51.207620  4950 sgd_solver.cpp:105] Iteration 13500, lr = 0.01
I0617 08:10:40.584045  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 08:10:49.887747  4950 solver.cpp:218] Iteration 13550 (0.852083 iter/s, 58.6797s/50 iters), loss = 0.166629
I0617 08:10:49.887852  4950 solver.cpp:237]     Train net output #0: loss = 0.166629 (* 1 = 0.166629 loss)
I0617 08:10:49.887889  4950 sgd_solver.cpp:105] Iteration 13550, lr = 0.01
I0617 08:11:48.563714  4950 solver.cpp:218] Iteration 13600 (0.852146 iter/s, 58.6754s/50 iters), loss = 0.12759
I0617 08:11:48.563864  4950 solver.cpp:237]     Train net output #0: loss = 0.127591 (* 1 = 0.127591 loss)
I0617 08:11:48.563889  4950 sgd_solver.cpp:105] Iteration 13600, lr = 0.01
I0617 08:12:47.242025  4950 solver.cpp:218] Iteration 13650 (0.852112 iter/s, 58.6777s/50 iters), loss = 0.0958845
I0617 08:12:47.242166  4950 solver.cpp:237]     Train net output #0: loss = 0.0958845 (* 1 = 0.0958845 loss)
I0617 08:12:47.242194  4950 sgd_solver.cpp:105] Iteration 13650, lr = 0.01
I0617 08:13:01.374650  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 08:13:45.922416  4950 solver.cpp:218] Iteration 13700 (0.852082 iter/s, 58.6798s/50 iters), loss = 0.150877
I0617 08:13:45.922582  4950 solver.cpp:237]     Train net output #0: loss = 0.150877 (* 1 = 0.150877 loss)
I0617 08:13:45.922606  4950 sgd_solver.cpp:105] Iteration 13700, lr = 0.01
I0617 08:14:44.594966  4950 solver.cpp:218] Iteration 13750 (0.852196 iter/s, 58.6719s/50 iters), loss = 0.0986793
I0617 08:14:44.595119  4950 solver.cpp:237]     Train net output #0: loss = 0.0986793 (* 1 = 0.0986793 loss)
I0617 08:14:44.595146  4950 sgd_solver.cpp:105] Iteration 13750, lr = 0.01
I0617 08:15:22.200645  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 08:15:43.273485  4950 solver.cpp:218] Iteration 13800 (0.852109 iter/s, 58.6779s/50 iters), loss = 0.0876305
I0617 08:15:43.273592  4950 solver.cpp:237]     Train net output #0: loss = 0.0876305 (* 1 = 0.0876305 loss)
I0617 08:15:43.273617  4950 sgd_solver.cpp:105] Iteration 13800, lr = 0.01
I0617 08:16:41.948555  4950 solver.cpp:218] Iteration 13850 (0.852159 iter/s, 58.6745s/50 iters), loss = 0.0970059
I0617 08:16:41.948771  4950 solver.cpp:237]     Train net output #0: loss = 0.0970058 (* 1 = 0.0970058 loss)
I0617 08:16:41.948796  4950 sgd_solver.cpp:105] Iteration 13850, lr = 0.01
I0617 08:17:40.617168  4950 solver.cpp:218] Iteration 13900 (0.852256 iter/s, 58.6678s/50 iters), loss = 0.0796888
I0617 08:17:40.617314  4950 solver.cpp:237]     Train net output #0: loss = 0.0796888 (* 1 = 0.0796888 loss)
I0617 08:17:40.617337  4950 sgd_solver.cpp:105] Iteration 13900, lr = 0.01
I0617 08:17:43.014400  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 08:18:39.287117  4950 solver.cpp:218] Iteration 13950 (0.852238 iter/s, 58.669s/50 iters), loss = 0.146174
I0617 08:18:39.287215  4950 solver.cpp:237]     Train net output #0: loss = 0.146174 (* 1 = 0.146174 loss)
I0617 08:18:39.287238  4950 sgd_solver.cpp:105] Iteration 13950, lr = 0.01
I0617 08:19:37.960680  4950 solver.cpp:218] Iteration 14000 (0.852185 iter/s, 58.6727s/50 iters), loss = 0.0659053
I0617 08:19:37.960847  4950 solver.cpp:237]     Train net output #0: loss = 0.0659053 (* 1 = 0.0659053 loss)
I0617 08:19:37.960872  4950 sgd_solver.cpp:105] Iteration 14000, lr = 0.01
I0617 08:20:02.705145  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 08:20:36.629526  4950 solver.cpp:218] Iteration 14050 (0.852255 iter/s, 58.6679s/50 iters), loss = 0.0454125
I0617 08:20:36.629714  4950 solver.cpp:237]     Train net output #0: loss = 0.0454125 (* 1 = 0.0454125 loss)
I0617 08:20:36.629740  4950 sgd_solver.cpp:105] Iteration 14050, lr = 0.01
I0617 08:21:35.297066  4950 solver.cpp:218] Iteration 14100 (0.852274 iter/s, 58.6666s/50 iters), loss = 0.0208482
I0617 08:21:35.297210  4950 solver.cpp:237]     Train net output #0: loss = 0.0208482 (* 1 = 0.0208482 loss)
I0617 08:21:35.297248  4950 sgd_solver.cpp:105] Iteration 14100, lr = 0.01
I0617 08:22:23.509404  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 08:22:33.970366  4950 solver.cpp:218] Iteration 14150 (0.852189 iter/s, 58.6724s/50 iters), loss = 0.0362427
I0617 08:22:33.970474  4950 solver.cpp:237]     Train net output #0: loss = 0.0362427 (* 1 = 0.0362427 loss)
I0617 08:22:33.970497  4950 sgd_solver.cpp:105] Iteration 14150, lr = 0.01
I0617 08:23:32.632566  4950 solver.cpp:218] Iteration 14200 (0.85235 iter/s, 58.6613s/50 iters), loss = 0.0320307
I0617 08:23:32.632725  4950 solver.cpp:237]     Train net output #0: loss = 0.0320306 (* 1 = 0.0320306 loss)
I0617 08:23:32.632755  4950 sgd_solver.cpp:105] Iteration 14200, lr = 0.01
I0617 08:24:31.306545  4950 solver.cpp:218] Iteration 14250 (0.85218 iter/s, 58.6731s/50 iters), loss = 0.101221
I0617 08:24:31.306701  4950 solver.cpp:237]     Train net output #0: loss = 0.101221 (* 1 = 0.101221 loss)
I0617 08:24:31.306725  4950 sgd_solver.cpp:105] Iteration 14250, lr = 0.01
I0617 08:24:44.284036  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 08:25:29.970285  4950 solver.cpp:218] Iteration 14300 (0.852328 iter/s, 58.6628s/50 iters), loss = 0.0364852
I0617 08:25:29.970419  4950 solver.cpp:237]     Train net output #0: loss = 0.0364851 (* 1 = 0.0364851 loss)
I0617 08:25:29.970443  4950 sgd_solver.cpp:105] Iteration 14300, lr = 0.01
I0617 08:26:28.628021  4950 solver.cpp:218] Iteration 14350 (0.852415 iter/s, 58.6569s/50 iters), loss = 0.0314258
I0617 08:26:28.628160  4950 solver.cpp:237]     Train net output #0: loss = 0.0314257 (* 1 = 0.0314257 loss)
I0617 08:26:28.628185  4950 sgd_solver.cpp:105] Iteration 14350, lr = 0.01
I0617 08:27:05.075548  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 08:27:27.302289  4950 solver.cpp:218] Iteration 14400 (0.852175 iter/s, 58.6734s/50 iters), loss = 0.0356323
I0617 08:27:27.302394  4950 solver.cpp:237]     Train net output #0: loss = 0.0356323 (* 1 = 0.0356323 loss)
I0617 08:27:27.302418  4950 sgd_solver.cpp:105] Iteration 14400, lr = 0.01
I0617 08:28:25.999868  4950 solver.cpp:218] Iteration 14450 (0.851836 iter/s, 58.6967s/50 iters), loss = 0.0106842
I0617 08:28:26.000166  4950 solver.cpp:237]     Train net output #0: loss = 0.0106841 (* 1 = 0.0106841 loss)
I0617 08:28:26.000192  4950 sgd_solver.cpp:105] Iteration 14450, lr = 0.01
I0617 08:29:24.708706  4950 solver.cpp:218] Iteration 14500 (0.851676 iter/s, 58.7078s/50 iters), loss = 0.0135262
I0617 08:29:24.708894  4950 solver.cpp:237]     Train net output #0: loss = 0.0135262 (* 1 = 0.0135262 loss)
I0617 08:29:24.708922  4950 sgd_solver.cpp:105] Iteration 14500, lr = 0.01
I0617 08:29:25.938146  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 08:30:23.421284  4950 solver.cpp:218] Iteration 14550 (0.85162 iter/s, 58.7116s/50 iters), loss = 0.00792141
I0617 08:30:23.421473  4950 solver.cpp:237]     Train net output #0: loss = 0.00792137 (* 1 = 0.00792137 loss)
I0617 08:30:23.421499  4950 sgd_solver.cpp:105] Iteration 14550, lr = 0.01
I0617 08:31:22.136371  4950 solver.cpp:218] Iteration 14600 (0.851583 iter/s, 58.7142s/50 iters), loss = 0.0133681
I0617 08:31:22.136544  4950 solver.cpp:237]     Train net output #0: loss = 0.0133681 (* 1 = 0.0133681 loss)
I0617 08:31:22.136571  4950 sgd_solver.cpp:105] Iteration 14600, lr = 0.01
I0617 08:31:46.857022  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 08:32:20.845268  4950 solver.cpp:218] Iteration 14650 (0.851673 iter/s, 58.708s/50 iters), loss = 0.00512548
I0617 08:32:20.845443  4950 solver.cpp:237]     Train net output #0: loss = 0.00512544 (* 1 = 0.00512544 loss)
I0617 08:32:20.845468  4950 sgd_solver.cpp:105] Iteration 14650, lr = 0.01
I0617 08:33:19.560118  4950 solver.cpp:218] Iteration 14700 (0.851587 iter/s, 58.7139s/50 iters), loss = 0.00927718
I0617 08:33:19.560293  4950 solver.cpp:237]     Train net output #0: loss = 0.00927713 (* 1 = 0.00927713 loss)
I0617 08:33:19.560338  4950 sgd_solver.cpp:105] Iteration 14700, lr = 0.01
I0617 08:34:07.764804  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 08:34:18.278025  4950 solver.cpp:218] Iteration 14750 (0.851542 iter/s, 58.717s/50 iters), loss = 0.00703855
I0617 08:34:18.278161  4950 solver.cpp:237]     Train net output #0: loss = 0.0070385 (* 1 = 0.0070385 loss)
I0617 08:34:18.278185  4950 sgd_solver.cpp:105] Iteration 14750, lr = 0.01
I0617 08:35:16.991974  4950 solver.cpp:218] Iteration 14800 (0.851599 iter/s, 58.7131s/50 iters), loss = 0.00812752
I0617 08:35:16.992180  4950 solver.cpp:237]     Train net output #0: loss = 0.00812748 (* 1 = 0.00812748 loss)
I0617 08:35:16.992207  4950 sgd_solver.cpp:105] Iteration 14800, lr = 0.01
I0617 08:36:15.706063  4950 solver.cpp:218] Iteration 14850 (0.851598 iter/s, 58.7131s/50 iters), loss = 0.0062233
I0617 08:36:15.706233  4950 solver.cpp:237]     Train net output #0: loss = 0.00622326 (* 1 = 0.00622326 loss)
I0617 08:36:15.706259  4950 sgd_solver.cpp:105] Iteration 14850, lr = 0.01
I0617 08:36:28.664410  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 08:37:14.419705  4950 solver.cpp:218] Iteration 14900 (0.851604 iter/s, 58.7127s/50 iters), loss = 0.00591856
I0617 08:37:14.419869  4950 solver.cpp:237]     Train net output #0: loss = 0.00591851 (* 1 = 0.00591851 loss)
I0617 08:37:14.419894  4950 sgd_solver.cpp:105] Iteration 14900, lr = 0.01
I0617 08:38:13.110383  4950 solver.cpp:218] Iteration 14950 (0.851937 iter/s, 58.6898s/50 iters), loss = 0.00485014
I0617 08:38:13.110523  4950 solver.cpp:237]     Train net output #0: loss = 0.0048501 (* 1 = 0.0048501 loss)
I0617 08:38:13.110550  4950 sgd_solver.cpp:105] Iteration 14950, lr = 0.01
I0617 08:38:48.415215  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 08:39:11.769371  4950 solver.cpp:218] Iteration 15000 (0.852397 iter/s, 58.6581s/50 iters), loss = 0.00675769
I0617 08:39:11.769464  4950 solver.cpp:237]     Train net output #0: loss = 0.00675764 (* 1 = 0.00675764 loss)
I0617 08:39:11.769491  4950 sgd_solver.cpp:105] Iteration 15000, lr = 0.01
I0617 08:40:10.449630  4950 solver.cpp:218] Iteration 15050 (0.852087 iter/s, 58.6794s/50 iters), loss = 0.00424044
I0617 08:40:10.449841  4950 solver.cpp:237]     Train net output #0: loss = 0.0042404 (* 1 = 0.0042404 loss)
I0617 08:40:10.449864  4950 sgd_solver.cpp:105] Iteration 15050, lr = 0.01
I0617 08:41:09.123450  4950 solver.cpp:218] Iteration 15100 (0.852183 iter/s, 58.6729s/50 iters), loss = 0.00439064
I0617 08:41:09.123622  4950 solver.cpp:237]     Train net output #0: loss = 0.0043906 (* 1 = 0.0043906 loss)
I0617 08:41:09.123652  4950 sgd_solver.cpp:105] Iteration 15100, lr = 0.01
I0617 08:41:09.200186  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 08:42:07.795295  4950 solver.cpp:218] Iteration 15150 (0.85221 iter/s, 58.671s/50 iters), loss = 0.00330221
I0617 08:42:07.795438  4950 solver.cpp:237]     Train net output #0: loss = 0.00330217 (* 1 = 0.00330217 loss)
I0617 08:42:07.795461  4950 sgd_solver.cpp:105] Iteration 15150, lr = 0.01
I0617 08:43:06.461603  4950 solver.cpp:218] Iteration 15200 (0.852291 iter/s, 58.6654s/50 iters), loss = 0.00483413
I0617 08:43:06.461747  4950 solver.cpp:237]     Train net output #0: loss = 0.00483409 (* 1 = 0.00483409 loss)
I0617 08:43:06.461771  4950 sgd_solver.cpp:105] Iteration 15200, lr = 0.01
I0617 08:43:30.000593  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 08:44:05.131319  4950 solver.cpp:218] Iteration 15250 (0.852241 iter/s, 58.6689s/50 iters), loss = 0.00384362
I0617 08:44:05.131534  4950 solver.cpp:237]     Train net output #0: loss = 0.00384358 (* 1 = 0.00384358 loss)
I0617 08:44:05.131564  4950 sgd_solver.cpp:105] Iteration 15250, lr = 0.01
I0617 08:45:03.795377  4950 solver.cpp:218] Iteration 15300 (0.852324 iter/s, 58.6631s/50 iters), loss = 0.00471578
I0617 08:45:03.795541  4950 solver.cpp:237]     Train net output #0: loss = 0.00471574 (* 1 = 0.00471574 loss)
I0617 08:45:03.795565  4950 sgd_solver.cpp:105] Iteration 15300, lr = 0.01
I0617 08:45:50.803059  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 08:46:02.474925  4950 solver.cpp:218] Iteration 15350 (0.852099 iter/s, 58.6787s/50 iters), loss = 0.00529376
I0617 08:46:02.475064  4950 solver.cpp:237]     Train net output #0: loss = 0.00529372 (* 1 = 0.00529372 loss)
I0617 08:46:02.475090  4950 sgd_solver.cpp:105] Iteration 15350, lr = 0.01
I0617 08:47:01.144529  4950 solver.cpp:218] Iteration 15400 (0.852242 iter/s, 58.6688s/50 iters), loss = 0.00786602
I0617 08:47:01.144634  4950 solver.cpp:237]     Train net output #0: loss = 0.00786598 (* 1 = 0.00786598 loss)
I0617 08:47:01.144659  4950 sgd_solver.cpp:105] Iteration 15400, lr = 0.01
I0617 08:47:59.813002  4950 solver.cpp:218] Iteration 15450 (0.852258 iter/s, 58.6676s/50 iters), loss = 0.00503323
I0617 08:47:59.813248  4950 solver.cpp:237]     Train net output #0: loss = 0.00503318 (* 1 = 0.00503318 loss)
I0617 08:47:59.813272  4950 sgd_solver.cpp:105] Iteration 15450, lr = 0.01
I0617 08:48:11.603910  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 08:48:58.487354  4950 solver.cpp:218] Iteration 15500 (0.852175 iter/s, 58.6734s/50 iters), loss = 0.00655654
I0617 08:48:58.487504  4950 solver.cpp:237]     Train net output #0: loss = 0.0065565 (* 1 = 0.0065565 loss)
I0617 08:48:58.487534  4950 sgd_solver.cpp:105] Iteration 15500, lr = 0.01
I0617 08:49:57.161419  4950 solver.cpp:218] Iteration 15550 (0.852178 iter/s, 58.6732s/50 iters), loss = 0.00511376
I0617 08:49:57.161571  4950 solver.cpp:237]     Train net output #0: loss = 0.00511372 (* 1 = 0.00511372 loss)
I0617 08:49:57.161600  4950 sgd_solver.cpp:105] Iteration 15550, lr = 0.01
I0617 08:50:32.442140  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 08:50:55.829308  4950 solver.cpp:218] Iteration 15600 (0.852267 iter/s, 58.667s/50 iters), loss = 0.00512578
I0617 08:50:55.829413  4950 solver.cpp:237]     Train net output #0: loss = 0.00512574 (* 1 = 0.00512574 loss)
I0617 08:50:55.829437  4950 sgd_solver.cpp:105] Iteration 15600, lr = 0.01
I0617 08:51:54.511190  4950 solver.cpp:218] Iteration 15650 (0.852064 iter/s, 58.6811s/50 iters), loss = 0.00430314
I0617 08:51:54.511404  4950 solver.cpp:237]     Train net output #0: loss = 0.00430309 (* 1 = 0.00430309 loss)
I0617 08:51:54.511430  4950 sgd_solver.cpp:105] Iteration 15650, lr = 0.01
I0617 08:52:53.201603  4950 solver.cpp:218] Iteration 15700 (0.851941 iter/s, 58.6895s/50 iters), loss = 0.00678959
I0617 08:52:53.202076  4950 solver.cpp:237]     Train net output #0: loss = 0.00678955 (* 1 = 0.00678955 loss)
I0617 08:52:53.202101  4950 sgd_solver.cpp:105] Iteration 15700, lr = 0.01
I0617 08:52:53.253988  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 08:53:51.887315  4950 solver.cpp:218] Iteration 15750 (0.852013 iter/s, 58.6845s/50 iters), loss = 0.00428767
I0617 08:53:51.887428  4950 solver.cpp:237]     Train net output #0: loss = 0.00428763 (* 1 = 0.00428763 loss)
I0617 08:53:51.887450  4950 sgd_solver.cpp:105] Iteration 15750, lr = 0.01
I0617 08:54:50.566169  4950 solver.cpp:218] Iteration 15800 (0.852107 iter/s, 58.6781s/50 iters), loss = 0.00522513
I0617 08:54:50.566315  4950 solver.cpp:237]     Train net output #0: loss = 0.00522508 (* 1 = 0.00522508 loss)
I0617 08:54:50.566339  4950 sgd_solver.cpp:105] Iteration 15800, lr = 0.01
I0617 08:55:14.106026  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 08:55:49.233594  4950 solver.cpp:218] Iteration 15850 (0.852274 iter/s, 58.6666s/50 iters), loss = 0.00368474
I0617 08:55:49.233724  4950 solver.cpp:237]     Train net output #0: loss = 0.00368469 (* 1 = 0.00368469 loss)
I0617 08:55:49.233752  4950 sgd_solver.cpp:105] Iteration 15850, lr = 0.01
I0617 08:56:47.897107  4950 solver.cpp:218] Iteration 15900 (0.852331 iter/s, 58.6627s/50 iters), loss = 0.00437869
I0617 08:56:47.897305  4950 solver.cpp:237]     Train net output #0: loss = 0.00437864 (* 1 = 0.00437864 loss)
I0617 08:56:47.897330  4950 sgd_solver.cpp:105] Iteration 15900, lr = 0.01
I0617 08:57:34.910321  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 08:57:46.571699  4950 solver.cpp:218] Iteration 15950 (0.852171 iter/s, 58.6737s/50 iters), loss = 0.00842832
I0617 08:57:46.571805  4950 solver.cpp:237]     Train net output #0: loss = 0.00842827 (* 1 = 0.00842827 loss)
I0617 08:57:46.571827  4950 sgd_solver.cpp:105] Iteration 15950, lr = 0.01
I0617 08:58:45.240861  4950 solver.cpp:218] Iteration 16000 (0.852248 iter/s, 58.6683s/50 iters), loss = 0.00488109
I0617 08:58:45.241027  4950 solver.cpp:237]     Train net output #0: loss = 0.00488105 (* 1 = 0.00488105 loss)
I0617 08:58:45.241052  4950 sgd_solver.cpp:105] Iteration 16000, lr = 0.01
I0617 08:59:43.916627  4950 solver.cpp:218] Iteration 16050 (0.852153 iter/s, 58.6749s/50 iters), loss = 0.00428166
I0617 08:59:43.916769  4950 solver.cpp:237]     Train net output #0: loss = 0.00428161 (* 1 = 0.00428161 loss)
I0617 08:59:43.916798  4950 sgd_solver.cpp:105] Iteration 16050, lr = 0.01
I0617 08:59:54.542276  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 09:00:42.582613  4950 solver.cpp:218] Iteration 16100 (0.852295 iter/s, 58.6652s/50 iters), loss = 0.00608897
I0617 09:00:42.582764  4950 solver.cpp:237]     Train net output #0: loss = 0.00608892 (* 1 = 0.00608892 loss)
I0617 09:00:42.582788  4950 sgd_solver.cpp:105] Iteration 16100, lr = 0.01
I0617 09:01:41.257050  4950 solver.cpp:218] Iteration 16150 (0.852172 iter/s, 58.6736s/50 iters), loss = 0.00587919
I0617 09:01:41.257184  4950 solver.cpp:237]     Train net output #0: loss = 0.00587915 (* 1 = 0.00587915 loss)
I0617 09:01:41.257208  4950 sgd_solver.cpp:105] Iteration 16150, lr = 0.01
I0617 09:02:15.363831  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 09:02:39.942714  4950 solver.cpp:218] Iteration 16200 (0.852009 iter/s, 58.6848s/50 iters), loss = 0.00563545
I0617 09:02:39.942811  4950 solver.cpp:237]     Train net output #0: loss = 0.0056354 (* 1 = 0.0056354 loss)
I0617 09:02:39.942833  4950 sgd_solver.cpp:105] Iteration 16200, lr = 0.01
I0617 09:03:38.622397  4950 solver.cpp:218] Iteration 16250 (0.852095 iter/s, 58.6789s/50 iters), loss = 0.00730598
I0617 09:03:38.622588  4950 solver.cpp:237]     Train net output #0: loss = 0.00730593 (* 1 = 0.00730593 loss)
I0617 09:03:38.622612  4950 sgd_solver.cpp:105] Iteration 16250, lr = 0.01
I0617 09:04:36.218448  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 09:04:37.296653  4950 solver.cpp:218] Iteration 16300 (0.852175 iter/s, 58.6734s/50 iters), loss = 0.00646208
I0617 09:04:37.296772  4950 solver.cpp:237]     Train net output #0: loss = 0.00646203 (* 1 = 0.00646203 loss)
I0617 09:04:37.296795  4950 sgd_solver.cpp:105] Iteration 16300, lr = 0.01
I0617 09:05:35.976502  4950 solver.cpp:218] Iteration 16350 (0.852093 iter/s, 58.6791s/50 iters), loss = 0.00510081
I0617 09:05:35.976660  4950 solver.cpp:237]     Train net output #0: loss = 0.00510077 (* 1 = 0.00510077 loss)
I0617 09:05:35.976685  4950 sgd_solver.cpp:105] Iteration 16350, lr = 0.01
I0617 09:06:34.645349  4950 solver.cpp:218] Iteration 16400 (0.852253 iter/s, 58.668s/50 iters), loss = 0.00625673
I0617 09:06:34.645498  4950 solver.cpp:237]     Train net output #0: loss = 0.00625668 (* 1 = 0.00625668 loss)
I0617 09:06:34.645529  4950 sgd_solver.cpp:105] Iteration 16400, lr = 0.01
I0617 09:06:57.027900  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 09:07:33.304286  4950 solver.cpp:218] Iteration 16450 (0.852398 iter/s, 58.658s/50 iters), loss = 0.00621833
I0617 09:07:33.304488  4950 solver.cpp:237]     Train net output #0: loss = 0.00621828 (* 1 = 0.00621828 loss)
I0617 09:07:33.304527  4950 sgd_solver.cpp:105] Iteration 16450, lr = 0.01
I0617 09:08:31.984719  4950 solver.cpp:218] Iteration 16500 (0.852086 iter/s, 58.6796s/50 iters), loss = 0.00508292
I0617 09:08:31.984866  4950 solver.cpp:237]     Train net output #0: loss = 0.00508287 (* 1 = 0.00508287 loss)
I0617 09:08:31.984891  4950 sgd_solver.cpp:105] Iteration 16500, lr = 0.01
I0617 09:09:17.804699  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 09:09:30.657018  4950 solver.cpp:218] Iteration 16550 (0.852203 iter/s, 58.6714s/50 iters), loss = 0.00434045
I0617 09:09:30.657125  4950 solver.cpp:237]     Train net output #0: loss = 0.0043404 (* 1 = 0.0043404 loss)
I0617 09:09:30.657153  4950 sgd_solver.cpp:105] Iteration 16550, lr = 0.01
I0617 09:10:29.332790  4950 solver.cpp:218] Iteration 16600 (0.852152 iter/s, 58.675s/50 iters), loss = 0.00489275
I0617 09:10:29.332923  4950 solver.cpp:237]     Train net output #0: loss = 0.00489271 (* 1 = 0.00489271 loss)
I0617 09:10:29.332948  4950 sgd_solver.cpp:105] Iteration 16600, lr = 0.01
I0617 09:11:28.005152  4950 solver.cpp:218] Iteration 16650 (0.852202 iter/s, 58.6715s/50 iters), loss = 0.0062678
I0617 09:11:28.005292  4950 solver.cpp:237]     Train net output #0: loss = 0.00626775 (* 1 = 0.00626775 loss)
I0617 09:11:28.005316  4950 sgd_solver.cpp:105] Iteration 16650, lr = 0.01
I0617 09:11:38.612675  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 09:12:26.683709  4950 solver.cpp:218] Iteration 16700 (0.852113 iter/s, 58.6777s/50 iters), loss = 0.00415397
I0617 09:12:26.683866  4950 solver.cpp:237]     Train net output #0: loss = 0.00415392 (* 1 = 0.00415392 loss)
I0617 09:12:26.683889  4950 sgd_solver.cpp:105] Iteration 16700, lr = 0.01
I0617 09:13:25.358649  4950 solver.cpp:218] Iteration 16750 (0.852165 iter/s, 58.6741s/50 iters), loss = 0.00559387
I0617 09:13:25.358813  4950 solver.cpp:237]     Train net output #0: loss = 0.00559383 (* 1 = 0.00559383 loss)
I0617 09:13:25.358837  4950 sgd_solver.cpp:105] Iteration 16750, lr = 0.01
I0617 09:13:59.436867  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 09:14:24.025847  4950 solver.cpp:218] Iteration 16800 (0.852278 iter/s, 58.6663s/50 iters), loss = 0.00621354
I0617 09:14:24.025943  4950 solver.cpp:237]     Train net output #0: loss = 0.00621349 (* 1 = 0.00621349 loss)
I0617 09:14:24.025967  4950 sgd_solver.cpp:105] Iteration 16800, lr = 0.01
I0617 09:15:22.705611  4950 solver.cpp:218] Iteration 16850 (0.852094 iter/s, 58.6789s/50 iters), loss = 0.00549531
I0617 09:15:22.705881  4950 solver.cpp:237]     Train net output #0: loss = 0.00549526 (* 1 = 0.00549526 loss)
I0617 09:15:22.705907  4950 sgd_solver.cpp:105] Iteration 16850, lr = 0.01
I0617 09:16:20.237579  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 09:16:21.363775  4950 solver.cpp:218] Iteration 16900 (0.852411 iter/s, 58.6572s/50 iters), loss = 0.00591576
I0617 09:16:21.363886  4950 solver.cpp:237]     Train net output #0: loss = 0.00591571 (* 1 = 0.00591571 loss)
I0617 09:16:21.363914  4950 sgd_solver.cpp:105] Iteration 16900, lr = 0.01
I0617 09:17:20.044589  4950 solver.cpp:218] Iteration 16950 (0.852079 iter/s, 58.68s/50 iters), loss = 0.0074995
I0617 09:17:20.044745  4950 solver.cpp:237]     Train net output #0: loss = 0.00749946 (* 1 = 0.00749946 loss)
I0617 09:17:20.044770  4950 sgd_solver.cpp:105] Iteration 16950, lr = 0.01
I0617 09:18:18.722764  4950 solver.cpp:218] Iteration 17000 (0.852118 iter/s, 58.6773s/50 iters), loss = 0.00610388
I0617 09:18:18.722920  4950 solver.cpp:237]     Train net output #0: loss = 0.00610383 (* 1 = 0.00610383 loss)
I0617 09:18:18.722945  4950 sgd_solver.cpp:105] Iteration 17000, lr = 0.01
I0617 09:18:39.953701  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 09:19:17.404392  4950 solver.cpp:218] Iteration 17050 (0.852068 iter/s, 58.6808s/50 iters), loss = 0.00625303
I0617 09:19:17.404577  4950 solver.cpp:237]     Train net output #0: loss = 0.00625298 (* 1 = 0.00625298 loss)
I0617 09:19:17.404603  4950 sgd_solver.cpp:105] Iteration 17050, lr = 0.01
I0617 09:20:16.085572  4950 solver.cpp:218] Iteration 17100 (0.852075 iter/s, 58.6803s/50 iters), loss = 0.00621757
I0617 09:20:16.085717  4950 solver.cpp:237]     Train net output #0: loss = 0.00621753 (* 1 = 0.00621753 loss)
I0617 09:20:16.085741  4950 sgd_solver.cpp:105] Iteration 17100, lr = 0.01
I0617 09:21:00.759003  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 09:21:14.767766  4950 solver.cpp:218] Iteration 17150 (0.85206 iter/s, 58.6813s/50 iters), loss = 0.00676282
I0617 09:21:14.767910  4950 solver.cpp:237]     Train net output #0: loss = 0.00676278 (* 1 = 0.00676278 loss)
I0617 09:21:14.767935  4950 sgd_solver.cpp:105] Iteration 17150, lr = 0.01
I0617 09:22:13.445798  4950 solver.cpp:218] Iteration 17200 (0.85212 iter/s, 58.6772s/50 iters), loss = 0.00695698
I0617 09:22:13.445986  4950 solver.cpp:237]     Train net output #0: loss = 0.00695693 (* 1 = 0.00695693 loss)
I0617 09:22:13.446017  4950 sgd_solver.cpp:105] Iteration 17200, lr = 0.01
I0617 09:23:12.134944  4950 solver.cpp:218] Iteration 17250 (0.851959 iter/s, 58.6883s/50 iters), loss = 0.0055583
I0617 09:23:12.135093  4950 solver.cpp:237]     Train net output #0: loss = 0.00555825 (* 1 = 0.00555825 loss)
I0617 09:23:12.135118  4950 sgd_solver.cpp:105] Iteration 17250, lr = 0.01
I0617 09:23:21.591522  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 09:24:10.814451  4950 solver.cpp:218] Iteration 17300 (0.852099 iter/s, 58.6786s/50 iters), loss = 0.00786528
I0617 09:24:10.814637  4950 solver.cpp:237]     Train net output #0: loss = 0.00786524 (* 1 = 0.00786524 loss)
I0617 09:24:10.814662  4950 sgd_solver.cpp:105] Iteration 17300, lr = 0.01
I0617 09:25:09.490891  4950 solver.cpp:218] Iteration 17350 (0.852143 iter/s, 58.6756s/50 iters), loss = 0.00581202
I0617 09:25:09.491049  4950 solver.cpp:237]     Train net output #0: loss = 0.00581197 (* 1 = 0.00581197 loss)
I0617 09:25:09.491073  4950 sgd_solver.cpp:105] Iteration 17350, lr = 0.01
I0617 09:25:42.448719  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 09:26:08.176067  4950 solver.cpp:218] Iteration 17400 (0.852017 iter/s, 58.6843s/50 iters), loss = 0.00540938
I0617 09:26:08.176188  4950 solver.cpp:237]     Train net output #0: loss = 0.00540933 (* 1 = 0.00540933 loss)
I0617 09:26:08.176213  4950 sgd_solver.cpp:105] Iteration 17400, lr = 0.01
I0617 09:27:06.854893  4950 solver.cpp:218] Iteration 17450 (0.852108 iter/s, 58.678s/50 iters), loss = 0.00606307
I0617 09:27:06.855041  4950 solver.cpp:237]     Train net output #0: loss = 0.00606303 (* 1 = 0.00606303 loss)
I0617 09:27:06.855065  4950 sgd_solver.cpp:105] Iteration 17450, lr = 0.01
I0617 09:28:03.252002  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 09:28:05.540830  4950 solver.cpp:218] Iteration 17500 (0.852006 iter/s, 58.685s/50 iters), loss = 0.00638131
I0617 09:28:05.540971  4950 solver.cpp:237]     Train net output #0: loss = 0.00638126 (* 1 = 0.00638126 loss)
I0617 09:28:05.540997  4950 sgd_solver.cpp:105] Iteration 17500, lr = 0.01
I0617 09:29:04.257675  4950 solver.cpp:218] Iteration 17550 (0.851558 iter/s, 58.7159s/50 iters), loss = 0.0071344
I0617 09:29:04.257879  4950 solver.cpp:237]     Train net output #0: loss = 0.00713435 (* 1 = 0.00713435 loss)
I0617 09:29:04.257911  4950 sgd_solver.cpp:105] Iteration 17550, lr = 0.01
I0617 09:30:02.981427  4950 solver.cpp:218] Iteration 17600 (0.851458 iter/s, 58.7228s/50 iters), loss = 0.0079371
I0617 09:30:02.981603  4950 solver.cpp:237]     Train net output #0: loss = 0.00793705 (* 1 = 0.00793705 loss)
I0617 09:30:02.981629  4950 sgd_solver.cpp:105] Iteration 17600, lr = 0.01
I0617 09:30:24.176286  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 09:31:01.699713  4950 solver.cpp:218] Iteration 17650 (0.851537 iter/s, 58.7174s/50 iters), loss = 0.00650704
I0617 09:31:01.699919  4950 solver.cpp:237]     Train net output #0: loss = 0.00650699 (* 1 = 0.00650699 loss)
I0617 09:31:01.699945  4950 sgd_solver.cpp:105] Iteration 17650, lr = 0.01
I0617 09:32:00.413769  4950 solver.cpp:218] Iteration 17700 (0.851599 iter/s, 58.7131s/50 iters), loss = 0.00812004
I0617 09:32:00.413960  4950 solver.cpp:237]     Train net output #0: loss = 0.00811999 (* 1 = 0.00811999 loss)
I0617 09:32:00.413991  4950 sgd_solver.cpp:105] Iteration 17700, lr = 0.01
I0617 09:32:45.097657  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 09:32:59.133039  4950 solver.cpp:218] Iteration 17750 (0.851522 iter/s, 58.7184s/50 iters), loss = 0.0064521
I0617 09:32:59.133198  4950 solver.cpp:237]     Train net output #0: loss = 0.00645205 (* 1 = 0.00645205 loss)
I0617 09:32:59.133224  4950 sgd_solver.cpp:105] Iteration 17750, lr = 0.01
I0617 09:33:57.858554  4950 solver.cpp:218] Iteration 17800 (0.851432 iter/s, 58.7246s/50 iters), loss = 0.00845727
I0617 09:33:57.858727  4950 solver.cpp:237]     Train net output #0: loss = 0.00845722 (* 1 = 0.00845722 loss)
I0617 09:33:57.858752  4950 sgd_solver.cpp:105] Iteration 17800, lr = 0.01
I0617 09:34:56.575136  4950 solver.cpp:218] Iteration 17850 (0.851562 iter/s, 58.7157s/50 iters), loss = 0.00599547
I0617 09:34:56.575340  4950 solver.cpp:237]     Train net output #0: loss = 0.00599542 (* 1 = 0.00599542 loss)
I0617 09:34:56.575372  4950 sgd_solver.cpp:105] Iteration 17850, lr = 0.01
I0617 09:35:06.018601  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 09:35:55.294865  4950 solver.cpp:218] Iteration 17900 (0.851516 iter/s, 58.7188s/50 iters), loss = 0.0067011
I0617 09:35:55.295047  4950 solver.cpp:237]     Train net output #0: loss = 0.00670106 (* 1 = 0.00670106 loss)
I0617 09:35:55.295070  4950 sgd_solver.cpp:105] Iteration 17900, lr = 0.01
I0617 09:36:54.023352  4950 solver.cpp:218] Iteration 17950 (0.851389 iter/s, 58.7276s/50 iters), loss = 0.00865213
I0617 09:36:54.023541  4950 solver.cpp:237]     Train net output #0: loss = 0.00865208 (* 1 = 0.00865208 loss)
I0617 09:36:54.023567  4950 sgd_solver.cpp:105] Iteration 17950, lr = 0.01
I0617 09:37:25.807797  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 09:37:52.745538  4950 solver.cpp:218] Iteration 18000 (0.85148 iter/s, 58.7213s/50 iters), loss = 0.00899848
I0617 09:37:52.745649  4950 solver.cpp:237]     Train net output #0: loss = 0.00899844 (* 1 = 0.00899844 loss)
I0617 09:37:52.745677  4950 sgd_solver.cpp:105] Iteration 18000, lr = 0.01
I0617 09:38:51.424953  4950 solver.cpp:218] Iteration 18050 (0.852099 iter/s, 58.6786s/50 iters), loss = 0.00558523
I0617 09:38:51.425096  4950 solver.cpp:237]     Train net output #0: loss = 0.00558518 (* 1 = 0.00558518 loss)
I0617 09:38:51.425122  4950 sgd_solver.cpp:105] Iteration 18050, lr = 0.01
I0617 09:39:46.654044  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 09:39:50.105701  4950 solver.cpp:218] Iteration 18100 (0.852081 iter/s, 58.6798s/50 iters), loss = 0.00669811
I0617 09:39:50.105798  4950 solver.cpp:237]     Train net output #0: loss = 0.00669806 (* 1 = 0.00669806 loss)
I0617 09:39:50.105826  4950 sgd_solver.cpp:105] Iteration 18100, lr = 0.01
I0617 09:40:48.777127  4950 solver.cpp:218] Iteration 18150 (0.852215 iter/s, 58.6706s/50 iters), loss = 0.00796597
I0617 09:40:48.777276  4950 solver.cpp:237]     Train net output #0: loss = 0.00796592 (* 1 = 0.00796592 loss)
I0617 09:40:48.777302  4950 sgd_solver.cpp:105] Iteration 18150, lr = 0.01
I0617 09:41:47.459995  4950 solver.cpp:218] Iteration 18200 (0.85205 iter/s, 58.682s/50 iters), loss = 0.00567536
I0617 09:41:47.460145  4950 solver.cpp:237]     Train net output #0: loss = 0.00567531 (* 1 = 0.00567531 loss)
I0617 09:41:47.460170  4950 sgd_solver.cpp:105] Iteration 18200, lr = 0.01
I0617 09:42:07.492553  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 09:42:46.151250  4950 solver.cpp:218] Iteration 18250 (0.851928 iter/s, 58.6904s/50 iters), loss = 0.00725277
I0617 09:42:46.151392  4950 solver.cpp:237]     Train net output #0: loss = 0.00725272 (* 1 = 0.00725272 loss)
I0617 09:42:46.151415  4950 sgd_solver.cpp:105] Iteration 18250, lr = 0.01
I0617 09:43:44.829666  4950 solver.cpp:218] Iteration 18300 (0.852114 iter/s, 58.6776s/50 iters), loss = 0.00706552
I0617 09:43:44.829823  4950 solver.cpp:237]     Train net output #0: loss = 0.00706547 (* 1 = 0.00706547 loss)
I0617 09:43:44.829845  4950 sgd_solver.cpp:105] Iteration 18300, lr = 0.01
I0617 09:44:28.315332  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 09:44:43.495407  4950 solver.cpp:218] Iteration 18350 (0.852299 iter/s, 58.6649s/50 iters), loss = 0.00633289
I0617 09:44:43.495534  4950 solver.cpp:237]     Train net output #0: loss = 0.00633285 (* 1 = 0.00633285 loss)
I0617 09:44:43.495560  4950 sgd_solver.cpp:105] Iteration 18350, lr = 0.01
I0617 09:45:42.169415  4950 solver.cpp:218] Iteration 18400 (0.852178 iter/s, 58.6732s/50 iters), loss = 0.00806431
I0617 09:45:42.169553  4950 solver.cpp:237]     Train net output #0: loss = 0.00806426 (* 1 = 0.00806426 loss)
I0617 09:45:42.169579  4950 sgd_solver.cpp:105] Iteration 18400, lr = 0.01
I0617 09:46:40.850365  4950 solver.cpp:218] Iteration 18450 (0.852077 iter/s, 58.6801s/50 iters), loss = 0.00673928
I0617 09:46:40.850487  4950 solver.cpp:237]     Train net output #0: loss = 0.00673924 (* 1 = 0.00673924 loss)
I0617 09:46:40.850512  4950 sgd_solver.cpp:105] Iteration 18450, lr = 0.01
I0617 09:46:49.131292  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 09:47:39.538606  4950 solver.cpp:218] Iteration 18500 (0.851971 iter/s, 58.6874s/50 iters), loss = 0.00884313
I0617 09:47:39.538741  4950 solver.cpp:237]     Train net output #0: loss = 0.00884308 (* 1 = 0.00884308 loss)
I0617 09:47:39.538764  4950 sgd_solver.cpp:105] Iteration 18500, lr = 0.01
I0617 09:48:38.210249  4950 solver.cpp:218] Iteration 18550 (0.852213 iter/s, 58.6708s/50 iters), loss = 0.00740039
I0617 09:48:38.210451  4950 solver.cpp:237]     Train net output #0: loss = 0.00740034 (* 1 = 0.00740034 loss)
I0617 09:48:38.210476  4950 sgd_solver.cpp:105] Iteration 18550, lr = 0.01
I0617 09:49:09.959275  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 09:49:36.885634  4950 solver.cpp:218] Iteration 18600 (0.852159 iter/s, 58.6745s/50 iters), loss = 0.00847164
I0617 09:49:36.885731  4950 solver.cpp:237]     Train net output #0: loss = 0.00847159 (* 1 = 0.00847159 loss)
I0617 09:49:36.885756  4950 sgd_solver.cpp:105] Iteration 18600, lr = 0.01
I0617 09:50:35.564697  4950 solver.cpp:218] Iteration 18650 (0.852104 iter/s, 58.6783s/50 iters), loss = 0.00927149
I0617 09:50:35.564834  4950 solver.cpp:237]     Train net output #0: loss = 0.00927144 (* 1 = 0.00927144 loss)
I0617 09:50:35.564858  4950 sgd_solver.cpp:105] Iteration 18650, lr = 0.01
I0617 09:51:30.798766  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 09:51:34.239446  4950 solver.cpp:218] Iteration 18700 (0.852167 iter/s, 58.6739s/50 iters), loss = 0.00754762
I0617 09:51:34.239552  4950 solver.cpp:237]     Train net output #0: loss = 0.00754757 (* 1 = 0.00754757 loss)
I0617 09:51:34.239576  4950 sgd_solver.cpp:105] Iteration 18700, lr = 0.01
I0617 09:52:32.917570  4950 solver.cpp:218] Iteration 18750 (0.852118 iter/s, 58.6773s/50 iters), loss = 0.00565946
I0617 09:52:32.917727  4950 solver.cpp:237]     Train net output #0: loss = 0.00565941 (* 1 = 0.00565941 loss)
I0617 09:52:32.917757  4950 sgd_solver.cpp:105] Iteration 18750, lr = 0.01
I0617 09:53:31.589151  4950 solver.cpp:218] Iteration 18800 (0.852214 iter/s, 58.6707s/50 iters), loss = 0.00916476
I0617 09:53:31.589300  4950 solver.cpp:237]     Train net output #0: loss = 0.00916471 (* 1 = 0.00916471 loss)
I0617 09:53:31.589325  4950 sgd_solver.cpp:105] Iteration 18800, lr = 0.01
I0617 09:53:51.583158  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 09:54:30.256892  4950 solver.cpp:218] Iteration 18850 (0.852269 iter/s, 58.6669s/50 iters), loss = 0.00665338
I0617 09:54:30.257024  4950 solver.cpp:237]     Train net output #0: loss = 0.00665334 (* 1 = 0.00665334 loss)
I0617 09:54:30.257048  4950 sgd_solver.cpp:105] Iteration 18850, lr = 0.01
I0617 09:55:28.943271  4950 solver.cpp:218] Iteration 18900 (0.851998 iter/s, 58.6856s/50 iters), loss = 0.00840975
I0617 09:55:28.943397  4950 solver.cpp:237]     Train net output #0: loss = 0.00840971 (* 1 = 0.00840971 loss)
I0617 09:55:28.943420  4950 sgd_solver.cpp:105] Iteration 18900, lr = 0.01
I0617 09:56:12.425055  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 09:56:27.608882  4950 solver.cpp:218] Iteration 18950 (0.8523 iter/s, 58.6648s/50 iters), loss = 0.00629647
I0617 09:56:27.608988  4950 solver.cpp:237]     Train net output #0: loss = 0.00629642 (* 1 = 0.00629642 loss)
I0617 09:56:27.609030  4950 sgd_solver.cpp:105] Iteration 18950, lr = 0.01
I0617 09:57:26.282855  4950 solver.cpp:218] Iteration 19000 (0.852178 iter/s, 58.6732s/50 iters), loss = 0.00919177
I0617 09:57:26.283007  4950 solver.cpp:237]     Train net output #0: loss = 0.00919172 (* 1 = 0.00919172 loss)
I0617 09:57:26.283032  4950 sgd_solver.cpp:105] Iteration 19000, lr = 0.01
I0617 09:58:24.968780  4950 solver.cpp:218] Iteration 19050 (0.852006 iter/s, 58.685s/50 iters), loss = 0.00787997
I0617 09:58:24.968984  4950 solver.cpp:237]     Train net output #0: loss = 0.00787992 (* 1 = 0.00787992 loss)
I0617 09:58:24.969015  4950 sgd_solver.cpp:105] Iteration 19050, lr = 0.01
I0617 09:58:32.088523  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 09:59:23.668771  4950 solver.cpp:218] Iteration 19100 (0.851802 iter/s, 58.6991s/50 iters), loss = 0.00872286
I0617 09:59:23.668905  4950 solver.cpp:237]     Train net output #0: loss = 0.00872281 (* 1 = 0.00872281 loss)
I0617 09:59:23.668928  4950 sgd_solver.cpp:105] Iteration 19100, lr = 0.01
I0617 10:00:22.362635  4950 solver.cpp:218] Iteration 19150 (0.85189 iter/s, 58.693s/50 iters), loss = 0.00948853
I0617 10:00:22.362926  4950 solver.cpp:237]     Train net output #0: loss = 0.00948848 (* 1 = 0.00948848 loss)
I0617 10:00:22.362952  4950 sgd_solver.cpp:105] Iteration 19150, lr = 0.01
I0617 10:00:52.958978  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 10:01:21.050240  4950 solver.cpp:218] Iteration 19200 (0.851983 iter/s, 58.6866s/50 iters), loss = 0.00753395
I0617 10:01:21.050338  4950 solver.cpp:237]     Train net output #0: loss = 0.0075339 (* 1 = 0.0075339 loss)
I0617 10:01:21.050361  4950 sgd_solver.cpp:105] Iteration 19200, lr = 0.01
I0617 10:02:19.749050  4950 solver.cpp:218] Iteration 19250 (0.851817 iter/s, 58.698s/50 iters), loss = 0.00758692
I0617 10:02:19.749188  4950 solver.cpp:237]     Train net output #0: loss = 0.00758687 (* 1 = 0.00758687 loss)
I0617 10:02:19.749212  4950 sgd_solver.cpp:105] Iteration 19250, lr = 0.01
I0617 10:03:13.796807  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 10:03:18.422623  4950 solver.cpp:218] Iteration 19300 (0.852184 iter/s, 58.6728s/50 iters), loss = 0.00838686
I0617 10:03:18.422721  4950 solver.cpp:237]     Train net output #0: loss = 0.00838682 (* 1 = 0.00838682 loss)
I0617 10:03:18.422744  4950 sgd_solver.cpp:105] Iteration 19300, lr = 0.01
I0617 10:04:17.109668  4950 solver.cpp:218] Iteration 19350 (0.851988 iter/s, 58.6863s/50 iters), loss = 0.00869845
I0617 10:04:17.109851  4950 solver.cpp:237]     Train net output #0: loss = 0.0086984 (* 1 = 0.0086984 loss)
I0617 10:04:17.109877  4950 sgd_solver.cpp:105] Iteration 19350, lr = 0.01
I0617 10:05:15.793285  4950 solver.cpp:218] Iteration 19400 (0.852039 iter/s, 58.6827s/50 iters), loss = 0.00658244
I0617 10:05:15.793431  4950 solver.cpp:237]     Train net output #0: loss = 0.00658239 (* 1 = 0.00658239 loss)
I0617 10:05:15.793460  4950 sgd_solver.cpp:105] Iteration 19400, lr = 0.01
I0617 10:05:34.632887  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 10:06:14.479579  4950 solver.cpp:218] Iteration 19450 (0.851999 iter/s, 58.6855s/50 iters), loss = 0.00855642
I0617 10:06:14.479706  4950 solver.cpp:237]     Train net output #0: loss = 0.00855637 (* 1 = 0.00855637 loss)
I0617 10:06:14.479728  4950 sgd_solver.cpp:105] Iteration 19450, lr = 0.01
I0617 10:07:13.170850  4950 solver.cpp:218] Iteration 19500 (0.851928 iter/s, 58.6904s/50 iters), loss = 0.00860134
I0617 10:07:13.171058  4950 solver.cpp:237]     Train net output #0: loss = 0.00860129 (* 1 = 0.00860129 loss)
I0617 10:07:13.171090  4950 sgd_solver.cpp:105] Iteration 19500, lr = 0.01
I0617 10:07:55.499367  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 10:08:11.866930  4950 solver.cpp:218] Iteration 19550 (0.851858 iter/s, 58.6952s/50 iters), loss = 0.00726452
I0617 10:08:11.867033  4950 solver.cpp:237]     Train net output #0: loss = 0.00726447 (* 1 = 0.00726447 loss)
I0617 10:08:11.867069  4950 sgd_solver.cpp:105] Iteration 19550, lr = 0.01
I0617 10:09:10.548584  4950 solver.cpp:218] Iteration 19600 (0.852067 iter/s, 58.6809s/50 iters), loss = 0.00835207
I0617 10:09:10.548766  4950 solver.cpp:237]     Train net output #0: loss = 0.00835202 (* 1 = 0.00835202 loss)
I0617 10:09:10.548792  4950 sgd_solver.cpp:105] Iteration 19600, lr = 0.01
I0617 10:10:09.223614  4950 solver.cpp:218] Iteration 19650 (0.852164 iter/s, 58.6742s/50 iters), loss = 0.00884986
I0617 10:10:09.223736  4950 solver.cpp:237]     Train net output #0: loss = 0.00884982 (* 1 = 0.00884982 loss)
I0617 10:10:09.223760  4950 sgd_solver.cpp:105] Iteration 19650, lr = 0.01
I0617 10:10:16.346400  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 10:11:07.901288  4950 solver.cpp:218] Iteration 19700 (0.852125 iter/s, 58.6769s/50 iters), loss = 0.00682901
I0617 10:11:07.901427  4950 solver.cpp:237]     Train net output #0: loss = 0.00682896 (* 1 = 0.00682896 loss)
I0617 10:11:07.901449  4950 sgd_solver.cpp:105] Iteration 19700, lr = 0.01
I0617 10:12:06.578299  4950 solver.cpp:218] Iteration 19750 (0.852135 iter/s, 58.6762s/50 iters), loss = 0.00869302
I0617 10:12:06.578503  4950 solver.cpp:237]     Train net output #0: loss = 0.00869298 (* 1 = 0.00869298 loss)
I0617 10:12:06.578542  4950 sgd_solver.cpp:105] Iteration 19750, lr = 0.01
I0617 10:12:37.144963  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 10:13:05.264217  4950 solver.cpp:218] Iteration 19800 (0.852006 iter/s, 58.6851s/50 iters), loss = 0.00884086
I0617 10:13:05.264328  4950 solver.cpp:237]     Train net output #0: loss = 0.00884081 (* 1 = 0.00884081 loss)
I0617 10:13:05.264350  4950 sgd_solver.cpp:105] Iteration 19800, lr = 0.01
I0617 10:14:03.928503  4950 solver.cpp:218] Iteration 19850 (0.852318 iter/s, 58.6635s/50 iters), loss = 0.00649729
I0617 10:14:03.928681  4950 solver.cpp:237]     Train net output #0: loss = 0.00649724 (* 1 = 0.00649724 loss)
I0617 10:14:03.928704  4950 sgd_solver.cpp:105] Iteration 19850, lr = 0.01
I0617 10:14:57.988431  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 10:15:02.610855  4950 solver.cpp:218] Iteration 19900 (0.852057 iter/s, 58.6815s/50 iters), loss = 0.00983625
I0617 10:15:02.610940  4950 solver.cpp:237]     Train net output #0: loss = 0.0098362 (* 1 = 0.0098362 loss)
I0617 10:15:02.610961  4950 sgd_solver.cpp:105] Iteration 19900, lr = 0.01
I0617 10:16:01.291072  4950 solver.cpp:218] Iteration 19950 (0.852087 iter/s, 58.6795s/50 iters), loss = 0.00642883
I0617 10:16:01.291201  4950 solver.cpp:237]     Train net output #0: loss = 0.00642878 (* 1 = 0.00642878 loss)
I0617 10:16:01.291225  4950 sgd_solver.cpp:105] Iteration 19950, lr = 0.01
I0617 10:16:58.797844  4950 solver.cpp:447] Snapshotting to binary proto file mobilenet/mobile_cub_iter_20000.caffemodel
I0617 10:16:58.881811  4950 sgd_solver.cpp:273] Snapshotting solver state to binary proto file mobilenet/mobile_cub_iter_20000.solverstate
I0617 10:17:00.083120  4950 solver.cpp:218] Iteration 20000 (0.850466 iter/s, 58.7913s/50 iters), loss = 0.0086675
I0617 10:17:00.083199  4950 solver.cpp:237]     Train net output #0: loss = 0.00866745 (* 1 = 0.00866745 loss)
I0617 10:17:00.083221  4950 sgd_solver.cpp:105] Iteration 20000, lr = 0.01
I0617 10:17:17.766330  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 10:17:58.756232  4950 solver.cpp:218] Iteration 20050 (0.852188 iter/s, 58.6725s/50 iters), loss = 0.00860805
I0617 10:17:58.756381  4950 solver.cpp:237]     Train net output #0: loss = 0.008608 (* 1 = 0.008608 loss)
I0617 10:17:58.756407  4950 sgd_solver.cpp:105] Iteration 20050, lr = 0.01
I0617 10:18:57.425434  4950 solver.cpp:218] Iteration 20100 (0.852246 iter/s, 58.6685s/50 iters), loss = 0.00869574
I0617 10:18:57.425576  4950 solver.cpp:237]     Train net output #0: loss = 0.00869569 (* 1 = 0.00869569 loss)
I0617 10:18:57.425601  4950 sgd_solver.cpp:105] Iteration 20100, lr = 0.01
I0617 10:19:38.583595  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 10:19:56.114229  4950 solver.cpp:218] Iteration 20150 (0.851961 iter/s, 58.6881s/50 iters), loss = 0.00837933
I0617 10:19:56.114344  4950 solver.cpp:237]     Train net output #0: loss = 0.00837928 (* 1 = 0.00837928 loss)
I0617 10:19:56.114369  4950 sgd_solver.cpp:105] Iteration 20150, lr = 0.01
I0617 10:20:54.804371  4950 solver.cpp:218] Iteration 20200 (0.851941 iter/s, 58.6895s/50 iters), loss = 0.0106464
I0617 10:20:54.804510  4950 solver.cpp:237]     Train net output #0: loss = 0.0106463 (* 1 = 0.0106463 loss)
I0617 10:20:54.804539  4950 sgd_solver.cpp:105] Iteration 20200, lr = 0.01
I0617 10:21:53.480648  4950 solver.cpp:218] Iteration 20250 (0.852143 iter/s, 58.6756s/50 iters), loss = 0.006739
I0617 10:21:53.480805  4950 solver.cpp:237]     Train net output #0: loss = 0.00673895 (* 1 = 0.00673895 loss)
I0617 10:21:53.480830  4950 sgd_solver.cpp:105] Iteration 20250, lr = 0.01
I0617 10:21:59.419178  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 10:22:52.165410  4950 solver.cpp:218] Iteration 20300 (0.85202 iter/s, 58.684s/50 iters), loss = 0.010312
I0617 10:22:52.165565  4950 solver.cpp:237]     Train net output #0: loss = 0.0103119 (* 1 = 0.0103119 loss)
I0617 10:22:52.165591  4950 sgd_solver.cpp:105] Iteration 20300, lr = 0.01
I0617 10:23:50.843238  4950 solver.cpp:218] Iteration 20350 (0.852121 iter/s, 58.6771s/50 iters), loss = 0.0090565
I0617 10:23:50.843441  4950 solver.cpp:237]     Train net output #0: loss = 0.00905645 (* 1 = 0.00905645 loss)
I0617 10:23:50.843467  4950 sgd_solver.cpp:105] Iteration 20350, lr = 0.01
I0617 10:24:20.241525  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 10:24:49.517987  4950 solver.cpp:218] Iteration 20400 (0.852167 iter/s, 58.674s/50 iters), loss = 0.0087688
I0617 10:24:49.518142  4950 solver.cpp:237]     Train net output #0: loss = 0.00876875 (* 1 = 0.00876875 loss)
I0617 10:24:49.518173  4950 sgd_solver.cpp:105] Iteration 20400, lr = 0.01
I0617 10:25:48.191190  4950 solver.cpp:218] Iteration 20450 (0.852188 iter/s, 58.6725s/50 iters), loss = 0.00871284
I0617 10:25:48.191421  4950 solver.cpp:237]     Train net output #0: loss = 0.00871279 (* 1 = 0.00871279 loss)
I0617 10:25:48.191445  4950 sgd_solver.cpp:105] Iteration 20450, lr = 0.01
I0617 10:26:41.079761  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 10:26:46.860052  4950 solver.cpp:218] Iteration 20500 (0.852252 iter/s, 58.6681s/50 iters), loss = 0.0104095
I0617 10:26:46.860189  4950 solver.cpp:237]     Train net output #0: loss = 0.0104094 (* 1 = 0.0104094 loss)
I0617 10:26:46.860213  4950 sgd_solver.cpp:105] Iteration 20500, lr = 0.01
I0617 10:27:45.545155  4950 solver.cpp:218] Iteration 20550 (0.852015 iter/s, 58.6844s/50 iters), loss = 0.00686081
I0617 10:27:45.545294  4950 solver.cpp:237]     Train net output #0: loss = 0.00686077 (* 1 = 0.00686077 loss)
I0617 10:27:45.545317  4950 sgd_solver.cpp:105] Iteration 20550, lr = 0.01
I0617 10:28:44.219270  4950 solver.cpp:218] Iteration 20600 (0.852175 iter/s, 58.6734s/50 iters), loss = 0.00653569
I0617 10:28:44.219398  4950 solver.cpp:237]     Train net output #0: loss = 0.00653564 (* 1 = 0.00653564 loss)
I0617 10:28:44.219420  4950 sgd_solver.cpp:105] Iteration 20600, lr = 0.01
I0617 10:29:01.902914  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 10:29:42.890295  4950 solver.cpp:218] Iteration 20650 (0.85222 iter/s, 58.6703s/50 iters), loss = 0.00871534
I0617 10:29:42.890470  4950 solver.cpp:237]     Train net output #0: loss = 0.00871529 (* 1 = 0.00871529 loss)
I0617 10:29:42.890496  4950 sgd_solver.cpp:105] Iteration 20650, lr = 0.01
I0617 10:30:41.568320  4950 solver.cpp:218] Iteration 20700 (0.852119 iter/s, 58.6773s/50 iters), loss = 0.00960458
I0617 10:30:41.568506  4950 solver.cpp:237]     Train net output #0: loss = 0.00960453 (* 1 = 0.00960453 loss)
I0617 10:30:41.568543  4950 sgd_solver.cpp:105] Iteration 20700, lr = 0.01
I0617 10:31:22.709489  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 10:31:40.236706  4950 solver.cpp:218] Iteration 20750 (0.852259 iter/s, 58.6676s/50 iters), loss = 0.00957363
I0617 10:31:40.236840  4950 solver.cpp:237]     Train net output #0: loss = 0.00957358 (* 1 = 0.00957358 loss)
I0617 10:31:40.236863  4950 sgd_solver.cpp:105] Iteration 20750, lr = 0.01
I0617 10:32:38.922765  4950 solver.cpp:218] Iteration 20800 (0.852001 iter/s, 58.6854s/50 iters), loss = 0.0075624
I0617 10:32:38.922904  4950 solver.cpp:237]     Train net output #0: loss = 0.00756236 (* 1 = 0.00756236 loss)
I0617 10:32:38.922929  4950 sgd_solver.cpp:105] Iteration 20800, lr = 0.01
I0617 10:33:37.593188  4950 solver.cpp:218] Iteration 20850 (0.852229 iter/s, 58.6697s/50 iters), loss = 0.00963439
I0617 10:33:37.593370  4950 solver.cpp:237]     Train net output #0: loss = 0.00963434 (* 1 = 0.00963434 loss)
I0617 10:33:37.593394  4950 sgd_solver.cpp:105] Iteration 20850, lr = 0.01
I0617 10:33:43.502449  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 10:34:36.267629  4950 solver.cpp:218] Iteration 20900 (0.852171 iter/s, 58.6737s/50 iters), loss = 0.00844297
I0617 10:34:36.267765  4950 solver.cpp:237]     Train net output #0: loss = 0.00844292 (* 1 = 0.00844292 loss)
I0617 10:34:36.267789  4950 sgd_solver.cpp:105] Iteration 20900, lr = 0.01
I0617 10:35:34.951846  4950 solver.cpp:218] Iteration 20950 (0.852028 iter/s, 58.6835s/50 iters), loss = 0.0106963
I0617 10:35:34.952003  4950 solver.cpp:237]     Train net output #0: loss = 0.0106963 (* 1 = 0.0106963 loss)
I0617 10:35:34.952029  4950 sgd_solver.cpp:105] Iteration 20950, lr = 0.01
I0617 10:36:03.214985  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 10:36:33.610096  4950 solver.cpp:218] Iteration 21000 (0.852405 iter/s, 58.6575s/50 iters), loss = 0.0085137
I0617 10:36:33.610224  4950 solver.cpp:237]     Train net output #0: loss = 0.00851366 (* 1 = 0.00851366 loss)
I0617 10:36:33.610246  4950 sgd_solver.cpp:105] Iteration 21000, lr = 0.01
I0617 10:37:32.281101  4950 solver.cpp:218] Iteration 21050 (0.85222 iter/s, 58.6703s/50 iters), loss = 0.00846803
I0617 10:37:32.281242  4950 solver.cpp:237]     Train net output #0: loss = 0.00846798 (* 1 = 0.00846798 loss)
I0617 10:37:32.281275  4950 sgd_solver.cpp:105] Iteration 21050, lr = 0.01
I0617 10:38:24.018250  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 10:38:30.958292  4950 solver.cpp:218] Iteration 21100 (0.85213 iter/s, 58.6765s/50 iters), loss = 0.0104841
I0617 10:38:30.958392  4950 solver.cpp:237]     Train net output #0: loss = 0.010484 (* 1 = 0.010484 loss)
I0617 10:38:30.958415  4950 sgd_solver.cpp:105] Iteration 21100, lr = 0.01
I0617 10:39:29.628796  4950 solver.cpp:218] Iteration 21150 (0.852227 iter/s, 58.6698s/50 iters), loss = 0.00742706
I0617 10:39:29.628952  4950 solver.cpp:237]     Train net output #0: loss = 0.00742701 (* 1 = 0.00742701 loss)
I0617 10:39:29.628974  4950 sgd_solver.cpp:105] Iteration 21150, lr = 0.01
I0617 10:40:28.304924  4950 solver.cpp:218] Iteration 21200 (0.852146 iter/s, 58.6754s/50 iters), loss = 0.00784767
I0617 10:40:28.305048  4950 solver.cpp:237]     Train net output #0: loss = 0.00784763 (* 1 = 0.00784763 loss)
I0617 10:40:28.305070  4950 sgd_solver.cpp:105] Iteration 21200, lr = 0.01
I0617 10:40:44.797489  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 10:41:26.970981  4950 solver.cpp:218] Iteration 21250 (0.852292 iter/s, 58.6654s/50 iters), loss = 0.0121568
I0617 10:41:26.971125  4950 solver.cpp:237]     Train net output #0: loss = 0.0121567 (* 1 = 0.0121567 loss)
I0617 10:41:26.971148  4950 sgd_solver.cpp:105] Iteration 21250, lr = 0.01
I0617 10:42:25.642069  4950 solver.cpp:218] Iteration 21300 (0.852219 iter/s, 58.6704s/50 iters), loss = 0.0101717
I0617 10:42:25.642221  4950 solver.cpp:237]     Train net output #0: loss = 0.0101716 (* 1 = 0.0101716 loss)
I0617 10:42:25.642246  4950 sgd_solver.cpp:105] Iteration 21300, lr = 0.01
I0617 10:43:05.606442  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 10:43:24.319399  4950 solver.cpp:218] Iteration 21350 (0.852128 iter/s, 58.6766s/50 iters), loss = 0.00906455
I0617 10:43:24.319525  4950 solver.cpp:237]     Train net output #0: loss = 0.0090645 (* 1 = 0.0090645 loss)
I0617 10:43:24.319555  4950 sgd_solver.cpp:105] Iteration 21350, lr = 0.01
I0617 10:44:22.996104  4950 solver.cpp:218] Iteration 21400 (0.852137 iter/s, 58.676s/50 iters), loss = 0.00906202
I0617 10:44:22.996215  4950 solver.cpp:237]     Train net output #0: loss = 0.00906197 (* 1 = 0.00906197 loss)
I0617 10:44:22.996238  4950 sgd_solver.cpp:105] Iteration 21400, lr = 0.01
I0617 10:45:21.698027  4950 solver.cpp:218] Iteration 21450 (0.851771 iter/s, 58.7012s/50 iters), loss = 0.0123515
I0617 10:45:21.698190  4950 solver.cpp:237]     Train net output #0: loss = 0.0123515 (* 1 = 0.0123515 loss)
I0617 10:45:21.698215  4950 sgd_solver.cpp:105] Iteration 21450, lr = 0.01
I0617 10:45:26.484215  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 10:46:20.378496  4950 solver.cpp:218] Iteration 21500 (0.852083 iter/s, 58.6797s/50 iters), loss = 0.00860658
I0617 10:46:20.378638  4950 solver.cpp:237]     Train net output #0: loss = 0.00860653 (* 1 = 0.00860653 loss)
I0617 10:46:20.378662  4950 sgd_solver.cpp:105] Iteration 21500, lr = 0.01
I0617 10:47:19.049983  4950 solver.cpp:218] Iteration 21550 (0.852213 iter/s, 58.6708s/50 iters), loss = 0.0103495
I0617 10:47:19.050187  4950 solver.cpp:237]     Train net output #0: loss = 0.0103494 (* 1 = 0.0103494 loss)
I0617 10:47:19.050210  4950 sgd_solver.cpp:105] Iteration 21550, lr = 0.01
I0617 10:47:47.300124  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 10:48:17.740838  4950 solver.cpp:218] Iteration 21600 (0.851933 iter/s, 58.6901s/50 iters), loss = 0.00883957
I0617 10:48:17.741005  4950 solver.cpp:237]     Train net output #0: loss = 0.00883952 (* 1 = 0.00883952 loss)
I0617 10:48:17.741029  4950 sgd_solver.cpp:105] Iteration 21600, lr = 0.01
I0617 10:49:16.459952  4950 solver.cpp:218] Iteration 21650 (0.851522 iter/s, 58.7184s/50 iters), loss = 0.0112216
I0617 10:49:16.460141  4950 solver.cpp:237]     Train net output #0: loss = 0.0112216 (* 1 = 0.0112216 loss)
I0617 10:49:16.460165  4950 sgd_solver.cpp:105] Iteration 21650, lr = 0.01
I0617 10:50:08.172060  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 10:50:15.178522  4950 solver.cpp:218] Iteration 21700 (0.851531 iter/s, 58.7178s/50 iters), loss = 0.0096454
I0617 10:50:15.178670  4950 solver.cpp:237]     Train net output #0: loss = 0.00964535 (* 1 = 0.00964535 loss)
I0617 10:50:15.178702  4950 sgd_solver.cpp:105] Iteration 21700, lr = 0.01
I0617 10:51:13.895653  4950 solver.cpp:218] Iteration 21750 (0.851551 iter/s, 58.7164s/50 iters), loss = 0.00648793
I0617 10:51:13.895835  4950 solver.cpp:237]     Train net output #0: loss = 0.00648788 (* 1 = 0.00648788 loss)
I0617 10:51:13.895860  4950 sgd_solver.cpp:105] Iteration 21750, lr = 0.01
I0617 10:52:12.624510  4950 solver.cpp:218] Iteration 21800 (0.851381 iter/s, 58.7281s/50 iters), loss = 0.00876114
I0617 10:52:12.624639  4950 solver.cpp:237]     Train net output #0: loss = 0.0087611 (* 1 = 0.0087611 loss)
I0617 10:52:12.624662  4950 sgd_solver.cpp:105] Iteration 21800, lr = 0.01
I0617 10:52:29.108043  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 10:53:11.342440  4950 solver.cpp:218] Iteration 21850 (0.851539 iter/s, 58.7172s/50 iters), loss = 0.055513
I0617 10:53:11.342625  4950 solver.cpp:237]     Train net output #0: loss = 0.055513 (* 1 = 0.055513 loss)
I0617 10:53:11.342650  4950 sgd_solver.cpp:105] Iteration 21850, lr = 0.01
I0617 10:54:10.067101  4950 solver.cpp:218] Iteration 21900 (0.851442 iter/s, 58.7239s/50 iters), loss = 1.63037
I0617 10:54:10.067245  4950 solver.cpp:237]     Train net output #0: loss = 1.63037 (* 1 = 1.63037 loss)
I0617 10:54:10.067270  4950 sgd_solver.cpp:105] Iteration 21900, lr = 0.01
I0617 10:54:50.049834  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 10:55:08.789643  4950 solver.cpp:218] Iteration 21950 (0.851473 iter/s, 58.7218s/50 iters), loss = 1.80738
I0617 10:55:08.789791  4950 solver.cpp:237]     Train net output #0: loss = 1.80738 (* 1 = 1.80738 loss)
I0617 10:55:08.789839  4950 sgd_solver.cpp:105] Iteration 21950, lr = 0.01
I0617 10:56:07.509703  4950 solver.cpp:218] Iteration 22000 (0.851509 iter/s, 58.7193s/50 iters), loss = 1.02452
I0617 10:56:07.509896  4950 solver.cpp:237]     Train net output #0: loss = 1.02452 (* 1 = 1.02452 loss)
I0617 10:56:07.509919  4950 sgd_solver.cpp:105] Iteration 22000, lr = 0.01
I0617 10:57:06.224634  4950 solver.cpp:218] Iteration 22050 (0.851584 iter/s, 58.7141s/50 iters), loss = 1.40565
I0617 10:57:06.224813  4950 solver.cpp:237]     Train net output #0: loss = 1.40565 (* 1 = 1.40565 loss)
I0617 10:57:06.224838  4950 sgd_solver.cpp:105] Iteration 22050, lr = 0.01
I0617 10:57:09.816452  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 10:58:04.940222  4950 solver.cpp:218] Iteration 22100 (0.851574 iter/s, 58.7148s/50 iters), loss = 0.850179
I0617 10:58:04.940384  4950 solver.cpp:237]     Train net output #0: loss = 0.850179 (* 1 = 0.850179 loss)
I0617 10:58:04.940409  4950 sgd_solver.cpp:105] Iteration 22100, lr = 0.01
I0617 10:59:03.637322  4950 solver.cpp:218] Iteration 22150 (0.851842 iter/s, 58.6963s/50 iters), loss = 0.931147
I0617 10:59:03.637496  4950 solver.cpp:237]     Train net output #0: loss = 0.931147 (* 1 = 0.931147 loss)
I0617 10:59:03.637527  4950 sgd_solver.cpp:105] Iteration 22150, lr = 0.01
I0617 10:59:30.710712  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 11:00:02.350667  4950 solver.cpp:218] Iteration 22200 (0.851606 iter/s, 58.7126s/50 iters), loss = 0.757508
I0617 11:00:02.350821  4950 solver.cpp:237]     Train net output #0: loss = 0.757508 (* 1 = 0.757508 loss)
I0617 11:00:02.350845  4950 sgd_solver.cpp:105] Iteration 22200, lr = 0.01
I0617 11:01:01.019902  4950 solver.cpp:218] Iteration 22250 (0.852246 iter/s, 58.6685s/50 iters), loss = 0.695206
I0617 11:01:01.020038  4950 solver.cpp:237]     Train net output #0: loss = 0.695206 (* 1 = 0.695206 loss)
I0617 11:01:01.020061  4950 sgd_solver.cpp:105] Iteration 22250, lr = 0.01
I0617 11:01:51.519867  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 11:01:59.657045  4950 solver.cpp:218] Iteration 22300 (0.852713 iter/s, 58.6364s/50 iters), loss = 0.546952
I0617 11:01:59.657150  4950 solver.cpp:237]     Train net output #0: loss = 0.546952 (* 1 = 0.546952 loss)
I0617 11:01:59.657173  4950 sgd_solver.cpp:105] Iteration 22300, lr = 0.01
I0617 11:02:58.310070  4950 solver.cpp:218] Iteration 22350 (0.852481 iter/s, 58.6523s/50 iters), loss = 0.471347
I0617 11:02:58.310256  4950 solver.cpp:237]     Train net output #0: loss = 0.471347 (* 1 = 0.471347 loss)
I0617 11:02:58.310278  4950 sgd_solver.cpp:105] Iteration 22350, lr = 0.01
I0617 11:03:56.947315  4950 solver.cpp:218] Iteration 22400 (0.852711 iter/s, 58.6365s/50 iters), loss = 0.612485
I0617 11:03:56.947479  4950 solver.cpp:237]     Train net output #0: loss = 0.612485 (* 1 = 0.612485 loss)
I0617 11:03:56.947501  4950 sgd_solver.cpp:105] Iteration 22400, lr = 0.01
I0617 11:04:12.278285  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 11:04:55.595229  4950 solver.cpp:218] Iteration 22450 (0.852556 iter/s, 58.6472s/50 iters), loss = 0.309828
I0617 11:04:55.595378  4950 solver.cpp:237]     Train net output #0: loss = 0.309828 (* 1 = 0.309828 loss)
I0617 11:04:55.595404  4950 sgd_solver.cpp:105] Iteration 22450, lr = 0.01
I0617 11:05:54.239281  4950 solver.cpp:218] Iteration 22500 (0.852612 iter/s, 58.6433s/50 iters), loss = 0.298479
I0617 11:05:54.239409  4950 solver.cpp:237]     Train net output #0: loss = 0.298479 (* 1 = 0.298479 loss)
I0617 11:05:54.239433  4950 sgd_solver.cpp:105] Iteration 22500, lr = 0.01
I0617 11:06:33.023113  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 11:06:52.882145  4950 solver.cpp:218] Iteration 22550 (0.852629 iter/s, 58.6421s/50 iters), loss = 0.298815
I0617 11:06:52.882231  4950 solver.cpp:237]     Train net output #0: loss = 0.298815 (* 1 = 0.298815 loss)
I0617 11:06:52.882252  4950 sgd_solver.cpp:105] Iteration 22550, lr = 0.01
I0617 11:07:51.513239  4950 solver.cpp:218] Iteration 22600 (0.8528 iter/s, 58.6304s/50 iters), loss = 0.253678
I0617 11:07:51.513504  4950 solver.cpp:237]     Train net output #0: loss = 0.253678 (* 1 = 0.253678 loss)
I0617 11:07:51.513540  4950 sgd_solver.cpp:105] Iteration 22600, lr = 0.01
I0617 11:08:50.148932  4950 solver.cpp:218] Iteration 22650 (0.852736 iter/s, 58.6348s/50 iters), loss = 0.269655
I0617 11:08:50.149055  4950 solver.cpp:237]     Train net output #0: loss = 0.269655 (* 1 = 0.269655 loss)
I0617 11:08:50.149082  4950 sgd_solver.cpp:105] Iteration 22650, lr = 0.01
I0617 11:08:53.746718  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 11:09:48.797868  4950 solver.cpp:218] Iteration 22700 (0.852542 iter/s, 58.6481s/50 iters), loss = 0.226697
I0617 11:09:48.798065  4950 solver.cpp:237]     Train net output #0: loss = 0.226697 (* 1 = 0.226697 loss)
I0617 11:09:48.798089  4950 sgd_solver.cpp:105] Iteration 22700, lr = 0.01
I0617 11:10:47.443878  4950 solver.cpp:218] Iteration 22750 (0.852585 iter/s, 58.6452s/50 iters), loss = 0.179092
I0617 11:10:47.444062  4950 solver.cpp:237]     Train net output #0: loss = 0.179092 (* 1 = 0.179092 loss)
I0617 11:10:47.444084  4950 sgd_solver.cpp:105] Iteration 22750, lr = 0.01
I0617 11:11:14.470404  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 11:11:46.084837  4950 solver.cpp:218] Iteration 22800 (0.852659 iter/s, 58.6401s/50 iters), loss = 0.0871351
I0617 11:11:46.084949  4950 solver.cpp:237]     Train net output #0: loss = 0.0871351 (* 1 = 0.0871351 loss)
I0617 11:11:46.084970  4950 sgd_solver.cpp:105] Iteration 22800, lr = 0.01
I0617 11:12:44.736485  4950 solver.cpp:218] Iteration 22850 (0.852502 iter/s, 58.6509s/50 iters), loss = 0.0655185
I0617 11:12:44.736619  4950 solver.cpp:237]     Train net output #0: loss = 0.0655185 (* 1 = 0.0655185 loss)
I0617 11:12:44.736641  4950 sgd_solver.cpp:105] Iteration 22850, lr = 0.01
I0617 11:13:35.242460  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 11:13:43.383106  4950 solver.cpp:218] Iteration 22900 (0.852575 iter/s, 58.6458s/50 iters), loss = 0.0773996
I0617 11:13:43.383195  4950 solver.cpp:237]     Train net output #0: loss = 0.0773996 (* 1 = 0.0773996 loss)
I0617 11:13:43.383216  4950 sgd_solver.cpp:105] Iteration 22900, lr = 0.01
I0617 11:14:42.060842  4950 solver.cpp:218] Iteration 22950 (0.852123 iter/s, 58.677s/50 iters), loss = 0.0953713
I0617 11:14:42.061055  4950 solver.cpp:237]     Train net output #0: loss = 0.0953713 (* 1 = 0.0953713 loss)
I0617 11:14:42.061081  4950 sgd_solver.cpp:105] Iteration 22950, lr = 0.01
I0617 11:15:40.748373  4950 solver.cpp:218] Iteration 23000 (0.851983 iter/s, 58.6866s/50 iters), loss = 0.0688849
I0617 11:15:40.748551  4950 solver.cpp:237]     Train net output #0: loss = 0.068885 (* 1 = 0.068885 loss)
I0617 11:15:40.748577  4950 sgd_solver.cpp:105] Iteration 23000, lr = 0.01
I0617 11:15:54.902585  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 11:16:39.427868  4950 solver.cpp:218] Iteration 23050 (0.852098 iter/s, 58.6787s/50 iters), loss = 0.046567
I0617 11:16:39.428086  4950 solver.cpp:237]     Train net output #0: loss = 0.046567 (* 1 = 0.046567 loss)
I0617 11:16:39.428122  4950 sgd_solver.cpp:105] Iteration 23050, lr = 0.01
I0617 11:17:38.111963  4950 solver.cpp:218] Iteration 23100 (0.852033 iter/s, 58.6832s/50 iters), loss = 0.0291457
I0617 11:17:38.112161  4950 solver.cpp:237]     Train net output #0: loss = 0.0291457 (* 1 = 0.0291457 loss)
I0617 11:17:38.112203  4950 sgd_solver.cpp:105] Iteration 23100, lr = 0.01
I0617 11:18:15.762507  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 11:18:36.781033  4950 solver.cpp:218] Iteration 23150 (0.85225 iter/s, 58.6682s/50 iters), loss = 0.0544627
I0617 11:18:36.781127  4950 solver.cpp:237]     Train net output #0: loss = 0.0544627 (* 1 = 0.0544627 loss)
I0617 11:18:36.781152  4950 sgd_solver.cpp:105] Iteration 23150, lr = 0.01
I0617 11:19:35.446959  4950 solver.cpp:218] Iteration 23200 (0.852295 iter/s, 58.6652s/50 iters), loss = 0.0307627
I0617 11:19:35.447109  4950 solver.cpp:237]     Train net output #0: loss = 0.0307627 (* 1 = 0.0307627 loss)
I0617 11:19:35.447139  4950 sgd_solver.cpp:105] Iteration 23200, lr = 0.01
I0617 11:20:34.122030  4950 solver.cpp:218] Iteration 23250 (0.852162 iter/s, 58.6743s/50 iters), loss = 0.03582
I0617 11:20:34.122184  4950 solver.cpp:237]     Train net output #0: loss = 0.0358201 (* 1 = 0.0358201 loss)
I0617 11:20:34.122208  4950 sgd_solver.cpp:105] Iteration 23250, lr = 0.01
I0617 11:20:36.540762  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 11:21:32.796931  4950 solver.cpp:218] Iteration 23300 (0.852165 iter/s, 58.6741s/50 iters), loss = 0.0272321
I0617 11:21:32.797135  4950 solver.cpp:237]     Train net output #0: loss = 0.0272321 (* 1 = 0.0272321 loss)
I0617 11:21:32.797161  4950 sgd_solver.cpp:105] Iteration 23300, lr = 0.01
I0617 11:22:31.483096  4950 solver.cpp:218] Iteration 23350 (0.852002 iter/s, 58.6853s/50 iters), loss = 0.0208025
I0617 11:22:31.483247  4950 solver.cpp:237]     Train net output #0: loss = 0.0208025 (* 1 = 0.0208025 loss)
I0617 11:22:31.483270  4950 sgd_solver.cpp:105] Iteration 23350, lr = 0.01
I0617 11:22:57.408048  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 11:23:30.183507  4950 solver.cpp:218] Iteration 23400 (0.851795 iter/s, 58.6996s/50 iters), loss = 0.0170188
I0617 11:23:30.183670  4950 solver.cpp:237]     Train net output #0: loss = 0.0170188 (* 1 = 0.0170188 loss)
I0617 11:23:30.183693  4950 sgd_solver.cpp:105] Iteration 23400, lr = 0.01
I0617 11:24:28.865365  4950 solver.cpp:218] Iteration 23450 (0.852064 iter/s, 58.681s/50 iters), loss = 0.0189372
I0617 11:24:28.865572  4950 solver.cpp:237]     Train net output #0: loss = 0.0189372 (* 1 = 0.0189372 loss)
I0617 11:24:28.865600  4950 sgd_solver.cpp:105] Iteration 23450, lr = 0.01
I0617 11:25:18.226555  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 11:25:27.558197  4950 solver.cpp:218] Iteration 23500 (0.851906 iter/s, 58.692s/50 iters), loss = 0.0124458
I0617 11:25:27.558305  4950 solver.cpp:237]     Train net output #0: loss = 0.0124458 (* 1 = 0.0124458 loss)
I0617 11:25:27.558329  4950 sgd_solver.cpp:105] Iteration 23500, lr = 0.01
I0617 11:26:26.244773  4950 solver.cpp:218] Iteration 23550 (0.851995 iter/s, 58.6858s/50 iters), loss = 0.0174079
I0617 11:26:26.244998  4950 solver.cpp:237]     Train net output #0: loss = 0.0174079 (* 1 = 0.0174079 loss)
I0617 11:26:26.245023  4950 sgd_solver.cpp:105] Iteration 23550, lr = 0.01
I0617 11:27:24.928609  4950 solver.cpp:218] Iteration 23600 (0.852036 iter/s, 58.683s/50 iters), loss = 0.0156075
I0617 11:27:24.928756  4950 solver.cpp:237]     Train net output #0: loss = 0.0156075 (* 1 = 0.0156075 loss)
I0617 11:27:24.928779  4950 sgd_solver.cpp:105] Iteration 23600, lr = 0.01
I0617 11:27:39.091233  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 11:28:23.604215  4950 solver.cpp:218] Iteration 23650 (0.852155 iter/s, 58.6748s/50 iters), loss = 0.0062502
I0617 11:28:23.604377  4950 solver.cpp:237]     Train net output #0: loss = 0.00625021 (* 1 = 0.00625021 loss)
I0617 11:28:23.604401  4950 sgd_solver.cpp:105] Iteration 23650, lr = 0.01
I0617 11:29:22.287072  4950 solver.cpp:218] Iteration 23700 (0.852049 iter/s, 58.682s/50 iters), loss = 0.00814266
I0617 11:29:22.287233  4950 solver.cpp:237]     Train net output #0: loss = 0.00814267 (* 1 = 0.00814267 loss)
I0617 11:29:22.287262  4950 sgd_solver.cpp:105] Iteration 23700, lr = 0.01
I0617 11:29:59.924720  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 11:30:20.971338  4950 solver.cpp:218] Iteration 23750 (0.852029 iter/s, 58.6834s/50 iters), loss = 0.008013
I0617 11:30:20.971438  4950 solver.cpp:237]     Train net output #0: loss = 0.00801301 (* 1 = 0.00801301 loss)
I0617 11:30:20.971462  4950 sgd_solver.cpp:105] Iteration 23750, lr = 0.01
I0617 11:31:19.655755  4950 solver.cpp:218] Iteration 23800 (0.852026 iter/s, 58.6837s/50 iters), loss = 0.0148233
I0617 11:31:19.655900  4950 solver.cpp:237]     Train net output #0: loss = 0.0148233 (* 1 = 0.0148233 loss)
I0617 11:31:19.655932  4950 sgd_solver.cpp:105] Iteration 23800, lr = 0.01
I0617 11:32:18.345415  4950 solver.cpp:218] Iteration 23850 (0.851951 iter/s, 58.6888s/50 iters), loss = 0.00650655
I0617 11:32:18.345685  4950 solver.cpp:237]     Train net output #0: loss = 0.00650656 (* 1 = 0.00650656 loss)
I0617 11:32:18.345710  4950 sgd_solver.cpp:105] Iteration 23850, lr = 0.01
I0617 11:32:20.766950  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 11:33:17.029534  4950 solver.cpp:218] Iteration 23900 (0.852033 iter/s, 58.6832s/50 iters), loss = 0.00485161
I0617 11:33:17.029736  4950 solver.cpp:237]     Train net output #0: loss = 0.00485162 (* 1 = 0.00485162 loss)
I0617 11:33:17.029762  4950 sgd_solver.cpp:105] Iteration 23900, lr = 0.01
I0617 11:34:15.714504  4950 solver.cpp:218] Iteration 23950 (0.85202 iter/s, 58.6841s/50 iters), loss = 0.0102542
I0617 11:34:15.714701  4950 solver.cpp:237]     Train net output #0: loss = 0.0102542 (* 1 = 0.0102542 loss)
I0617 11:34:15.714725  4950 sgd_solver.cpp:105] Iteration 23950, lr = 0.01
I0617 11:34:40.436610  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 11:35:14.413655  4950 solver.cpp:218] Iteration 24000 (0.851813 iter/s, 58.6983s/50 iters), loss = 0.00440317
I0617 11:35:14.413803  4950 solver.cpp:237]     Train net output #0: loss = 0.00440318 (* 1 = 0.00440318 loss)
I0617 11:35:14.413826  4950 sgd_solver.cpp:105] Iteration 24000, lr = 0.01
I0617 11:36:13.096117  4950 solver.cpp:218] Iteration 24050 (0.852055 iter/s, 58.6816s/50 iters), loss = 0.00950898
I0617 11:36:13.096280  4950 solver.cpp:237]     Train net output #0: loss = 0.00950899 (* 1 = 0.00950899 loss)
I0617 11:36:13.096310  4950 sgd_solver.cpp:105] Iteration 24050, lr = 0.01
I0617 11:37:01.315716  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 11:37:11.778458  4950 solver.cpp:218] Iteration 24100 (0.852057 iter/s, 58.6815s/50 iters), loss = 0.00705782
I0617 11:37:11.778565  4950 solver.cpp:237]     Train net output #0: loss = 0.00705783 (* 1 = 0.00705783 loss)
I0617 11:37:11.778590  4950 sgd_solver.cpp:105] Iteration 24100, lr = 0.01
I0617 11:38:10.462494  4950 solver.cpp:218] Iteration 24150 (0.852032 iter/s, 58.6833s/50 iters), loss = 0.00763888
I0617 11:38:10.462743  4950 solver.cpp:237]     Train net output #0: loss = 0.00763889 (* 1 = 0.00763889 loss)
I0617 11:38:10.462769  4950 sgd_solver.cpp:105] Iteration 24150, lr = 0.01
I0617 11:39:09.180254  4950 solver.cpp:218] Iteration 24200 (0.851544 iter/s, 58.7168s/50 iters), loss = 0.00655335
I0617 11:39:09.180435  4950 solver.cpp:237]     Train net output #0: loss = 0.00655336 (* 1 = 0.00655336 loss)
I0617 11:39:09.180459  4950 sgd_solver.cpp:105] Iteration 24200, lr = 0.01
I0617 11:39:22.163529  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 11:40:07.899653  4950 solver.cpp:218] Iteration 24250 (0.85152 iter/s, 58.7185s/50 iters), loss = 0.00449861
I0617 11:40:07.899850  4950 solver.cpp:237]     Train net output #0: loss = 0.00449862 (* 1 = 0.00449862 loss)
I0617 11:40:07.899876  4950 sgd_solver.cpp:105] Iteration 24250, lr = 0.01
I0617 11:41:06.614878  4950 solver.cpp:218] Iteration 24300 (0.85158 iter/s, 58.7144s/50 iters), loss = 0.00530097
I0617 11:41:06.615053  4950 solver.cpp:237]     Train net output #0: loss = 0.00530098 (* 1 = 0.00530098 loss)
I0617 11:41:06.615079  4950 sgd_solver.cpp:105] Iteration 24300, lr = 0.01
I0617 11:41:43.073900  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 11:42:05.321669  4950 solver.cpp:218] Iteration 24350 (0.851703 iter/s, 58.7059s/50 iters), loss = 0.00536395
I0617 11:42:05.321807  4950 solver.cpp:237]     Train net output #0: loss = 0.00536396 (* 1 = 0.00536396 loss)
I0617 11:42:05.321831  4950 sgd_solver.cpp:105] Iteration 24350, lr = 0.01
I0617 11:43:04.036535  4950 solver.cpp:218] Iteration 24400 (0.851587 iter/s, 58.7139s/50 iters), loss = 0.00473759
I0617 11:43:04.036725  4950 solver.cpp:237]     Train net output #0: loss = 0.00473759 (* 1 = 0.00473759 loss)
I0617 11:43:04.036772  4950 sgd_solver.cpp:105] Iteration 24400, lr = 0.01
I0617 11:44:02.763459  4950 solver.cpp:218] Iteration 24450 (0.851412 iter/s, 58.726s/50 iters), loss = 0.00638462
I0617 11:44:02.763669  4950 solver.cpp:237]     Train net output #0: loss = 0.00638462 (* 1 = 0.00638462 loss)
I0617 11:44:02.763692  4950 sgd_solver.cpp:105] Iteration 24450, lr = 0.01
I0617 11:44:04.002457  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 11:45:01.492430  4950 solver.cpp:218] Iteration 24500 (0.851383 iter/s, 58.728s/50 iters), loss = 0.00621253
I0617 11:45:01.492615  4950 solver.cpp:237]     Train net output #0: loss = 0.00621254 (* 1 = 0.00621254 loss)
I0617 11:45:01.492640  4950 sgd_solver.cpp:105] Iteration 24500, lr = 0.01
I0617 11:46:00.214187  4950 solver.cpp:218] Iteration 24550 (0.851487 iter/s, 58.7208s/50 iters), loss = 0.00620424
I0617 11:46:00.214339  4950 solver.cpp:237]     Train net output #0: loss = 0.00620425 (* 1 = 0.00620425 loss)
I0617 11:46:00.214365  4950 sgd_solver.cpp:105] Iteration 24550, lr = 0.01
I0617 11:46:24.936668  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 11:46:58.937021  4950 solver.cpp:218] Iteration 24600 (0.851471 iter/s, 58.7219s/50 iters), loss = 0.00549814
I0617 11:46:58.937186  4950 solver.cpp:237]     Train net output #0: loss = 0.00549815 (* 1 = 0.00549815 loss)
I0617 11:46:58.937211  4950 sgd_solver.cpp:105] Iteration 24600, lr = 0.01
I0617 11:47:57.666069  4950 solver.cpp:218] Iteration 24650 (0.851381 iter/s, 58.7281s/50 iters), loss = 0.00466531
I0617 11:47:57.666210  4950 solver.cpp:237]     Train net output #0: loss = 0.00466532 (* 1 = 0.00466532 loss)
I0617 11:47:57.666239  4950 sgd_solver.cpp:105] Iteration 24650, lr = 0.01
I0617 11:48:45.867569  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 11:48:56.350432  4950 solver.cpp:218] Iteration 24700 (0.852029 iter/s, 58.6835s/50 iters), loss = 0.00644136
I0617 11:48:56.350563  4950 solver.cpp:237]     Train net output #0: loss = 0.00644137 (* 1 = 0.00644137 loss)
I0617 11:48:56.350589  4950 sgd_solver.cpp:105] Iteration 24700, lr = 0.01
I0617 11:49:55.039786  4950 solver.cpp:218] Iteration 24750 (0.851956 iter/s, 58.6885s/50 iters), loss = 0.00685449
I0617 11:49:55.040043  4950 solver.cpp:237]     Train net output #0: loss = 0.00685449 (* 1 = 0.00685449 loss)
I0617 11:49:55.040073  4950 sgd_solver.cpp:105] Iteration 24750, lr = 0.01
I0617 11:50:53.734429  4950 solver.cpp:218] Iteration 24800 (0.851881 iter/s, 58.6937s/50 iters), loss = 0.00549347
I0617 11:50:53.734599  4950 solver.cpp:237]     Train net output #0: loss = 0.00549347 (* 1 = 0.00549347 loss)
I0617 11:50:53.734623  4950 sgd_solver.cpp:105] Iteration 24800, lr = 0.01
I0617 11:51:06.715860  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 11:51:52.418804  4950 solver.cpp:218] Iteration 24850 (0.852029 iter/s, 58.6835s/50 iters), loss = 0.00487885
I0617 11:51:52.418962  4950 solver.cpp:237]     Train net output #0: loss = 0.00487886 (* 1 = 0.00487886 loss)
I0617 11:51:52.418987  4950 sgd_solver.cpp:105] Iteration 24850, lr = 0.01
I0617 11:52:51.106719  4950 solver.cpp:218] Iteration 24900 (0.851977 iter/s, 58.687s/50 iters), loss = 0.00569449
I0617 11:52:51.106870  4950 solver.cpp:237]     Train net output #0: loss = 0.0056945 (* 1 = 0.0056945 loss)
I0617 11:52:51.106894  4950 sgd_solver.cpp:105] Iteration 24900, lr = 0.01
I0617 11:53:27.527117  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 11:53:49.789656  4950 solver.cpp:218] Iteration 24950 (0.85205 iter/s, 58.682s/50 iters), loss = 0.00559253
I0617 11:53:49.789793  4950 solver.cpp:237]     Train net output #0: loss = 0.00559253 (* 1 = 0.00559253 loss)
I0617 11:53:49.789818  4950 sgd_solver.cpp:105] Iteration 24950, lr = 0.01
I0617 11:54:48.486173  4950 solver.cpp:218] Iteration 25000 (0.851852 iter/s, 58.6956s/50 iters), loss = 0.00607083
I0617 11:54:48.486323  4950 solver.cpp:237]     Train net output #0: loss = 0.00607083 (* 1 = 0.00607083 loss)
I0617 11:54:48.486361  4950 sgd_solver.cpp:105] Iteration 25000, lr = 0.01
I0617 11:55:47.167418  4950 solver.cpp:218] Iteration 25050 (0.852074 iter/s, 58.6804s/50 iters), loss = 0.00479382
I0617 11:55:47.167572  4950 solver.cpp:237]     Train net output #0: loss = 0.00479382 (* 1 = 0.00479382 loss)
I0617 11:55:47.167596  4950 sgd_solver.cpp:105] Iteration 25050, lr = 0.01
I0617 11:55:47.269292  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 11:56:45.854972  4950 solver.cpp:218] Iteration 25100 (0.851983 iter/s, 58.6866s/50 iters), loss = 0.00492389
I0617 11:56:45.855146  4950 solver.cpp:237]     Train net output #0: loss = 0.00492389 (* 1 = 0.00492389 loss)
I0617 11:56:45.855177  4950 sgd_solver.cpp:105] Iteration 25100, lr = 0.01
I0617 11:57:44.547503  4950 solver.cpp:218] Iteration 25150 (0.85191 iter/s, 58.6916s/50 iters), loss = 0.00653506
I0617 11:57:44.547673  4950 solver.cpp:237]     Train net output #0: loss = 0.00653506 (* 1 = 0.00653506 loss)
I0617 11:57:44.547698  4950 sgd_solver.cpp:105] Iteration 25150, lr = 0.01
I0617 11:58:08.096685  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 11:58:43.267339  4950 solver.cpp:218] Iteration 25200 (0.851514 iter/s, 58.7189s/50 iters), loss = 0.00591122
I0617 11:58:43.267567  4950 solver.cpp:237]     Train net output #0: loss = 0.00591122 (* 1 = 0.00591122 loss)
I0617 11:58:43.267593  4950 sgd_solver.cpp:105] Iteration 25200, lr = 0.01
I0617 11:59:41.995113  4950 solver.cpp:218] Iteration 25250 (0.8514 iter/s, 58.7268s/50 iters), loss = 0.00581445
I0617 11:59:41.995260  4950 solver.cpp:237]     Train net output #0: loss = 0.00581446 (* 1 = 0.00581446 loss)
I0617 11:59:41.995285  4950 sgd_solver.cpp:105] Iteration 25250, lr = 0.01
I0617 12:00:29.056800  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 12:00:40.733511  4950 solver.cpp:218] Iteration 25300 (0.851246 iter/s, 58.7375s/50 iters), loss = 0.00616237
I0617 12:00:40.733645  4950 solver.cpp:237]     Train net output #0: loss = 0.00616238 (* 1 = 0.00616238 loss)
I0617 12:00:40.733675  4950 sgd_solver.cpp:105] Iteration 25300, lr = 0.01
I0617 12:01:39.463635  4950 solver.cpp:218] Iteration 25350 (0.851365 iter/s, 58.7292s/50 iters), loss = 0.00665873
I0617 12:01:39.463876  4950 solver.cpp:237]     Train net output #0: loss = 0.00665873 (* 1 = 0.00665873 loss)
I0617 12:01:39.463901  4950 sgd_solver.cpp:105] Iteration 25350, lr = 0.01
I0617 12:02:38.189622  4950 solver.cpp:218] Iteration 25400 (0.851427 iter/s, 58.725s/50 iters), loss = 0.00598571
I0617 12:02:38.190613  4950 solver.cpp:237]     Train net output #0: loss = 0.00598571 (* 1 = 0.00598571 loss)
I0617 12:02:38.190639  4950 sgd_solver.cpp:105] Iteration 25400, lr = 0.01
I0617 12:02:50.004796  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 12:03:36.913383  4950 solver.cpp:218] Iteration 25450 (0.85147 iter/s, 58.722s/50 iters), loss = 0.00801219
I0617 12:03:36.913563  4950 solver.cpp:237]     Train net output #0: loss = 0.0080122 (* 1 = 0.0080122 loss)
I0617 12:03:36.913589  4950 sgd_solver.cpp:105] Iteration 25450, lr = 0.01
I0617 12:04:35.630311  4950 solver.cpp:218] Iteration 25500 (0.851557 iter/s, 58.716s/50 iters), loss = 0.00514555
I0617 12:04:35.630487  4950 solver.cpp:237]     Train net output #0: loss = 0.00514556 (* 1 = 0.00514556 loss)
I0617 12:04:35.630519  4950 sgd_solver.cpp:105] Iteration 25500, lr = 0.01
I0617 12:05:10.929038  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 12:05:34.352036  4950 solver.cpp:218] Iteration 25550 (0.851487 iter/s, 58.7208s/50 iters), loss = 0.00668236
I0617 12:05:34.352169  4950 solver.cpp:237]     Train net output #0: loss = 0.00668236 (* 1 = 0.00668236 loss)
I0617 12:05:34.352191  4950 sgd_solver.cpp:105] Iteration 25550, lr = 0.01
I0617 12:06:33.077327  4950 solver.cpp:218] Iteration 25600 (0.851435 iter/s, 58.7244s/50 iters), loss = 0.00557098
I0617 12:06:33.077494  4950 solver.cpp:237]     Train net output #0: loss = 0.00557099 (* 1 = 0.00557099 loss)
I0617 12:06:33.077523  4950 sgd_solver.cpp:105] Iteration 25600, lr = 0.01
I0617 12:07:31.808993  4950 solver.cpp:218] Iteration 25650 (0.851343 iter/s, 58.7307s/50 iters), loss = 0.00806561
I0617 12:07:31.809233  4950 solver.cpp:237]     Train net output #0: loss = 0.00806562 (* 1 = 0.00806562 loss)
I0617 12:07:31.809258  4950 sgd_solver.cpp:105] Iteration 25650, lr = 0.01
I0617 12:07:31.858932  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 12:08:30.513619  4950 solver.cpp:218] Iteration 25700 (0.851736 iter/s, 58.7036s/50 iters), loss = 0.00575536
I0617 12:08:30.513764  4950 solver.cpp:237]     Train net output #0: loss = 0.00575537 (* 1 = 0.00575537 loss)
I0617 12:08:30.513789  4950 sgd_solver.cpp:105] Iteration 25700, lr = 0.01
I0617 12:09:29.199793  4950 solver.cpp:218] Iteration 25750 (0.852003 iter/s, 58.6853s/50 iters), loss = 0.00538643
I0617 12:09:29.199960  4950 solver.cpp:237]     Train net output #0: loss = 0.00538644 (* 1 = 0.00538644 loss)
I0617 12:09:29.199986  4950 sgd_solver.cpp:105] Iteration 25750, lr = 0.01
I0617 12:09:52.749719  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 12:10:27.890674  4950 solver.cpp:218] Iteration 25800 (0.851934 iter/s, 58.69s/50 iters), loss = 0.00538018
I0617 12:10:27.890811  4950 solver.cpp:237]     Train net output #0: loss = 0.00538018 (* 1 = 0.00538018 loss)
I0617 12:10:27.890841  4950 sgd_solver.cpp:105] Iteration 25800, lr = 0.01
I0617 12:11:26.560346  4950 solver.cpp:218] Iteration 25850 (0.852242 iter/s, 58.6688s/50 iters), loss = 0.00580716
I0617 12:11:26.560477  4950 solver.cpp:237]     Train net output #0: loss = 0.00580717 (* 1 = 0.00580717 loss)
I0617 12:11:26.560500  4950 sgd_solver.cpp:105] Iteration 25850, lr = 0.01
I0617 12:12:13.546954  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 12:12:25.247241  4950 solver.cpp:218] Iteration 25900 (0.851992 iter/s, 58.686s/50 iters), loss = 0.00769666
I0617 12:12:25.247366  4950 solver.cpp:237]     Train net output #0: loss = 0.00769667 (* 1 = 0.00769667 loss)
I0617 12:12:25.247390  4950 sgd_solver.cpp:105] Iteration 25900, lr = 0.01
I0617 12:13:23.935360  4950 solver.cpp:218] Iteration 25950 (0.851974 iter/s, 58.6873s/50 iters), loss = 0.00629123
I0617 12:13:23.935575  4950 solver.cpp:237]     Train net output #0: loss = 0.00629124 (* 1 = 0.00629124 loss)
I0617 12:13:23.935600  4950 sgd_solver.cpp:105] Iteration 25950, lr = 0.01
I0617 12:14:22.618546  4950 solver.cpp:218] Iteration 26000 (0.852047 iter/s, 58.6822s/50 iters), loss = 0.00549467
I0617 12:14:22.618706  4950 solver.cpp:237]     Train net output #0: loss = 0.00549468 (* 1 = 0.00549468 loss)
I0617 12:14:22.618731  4950 sgd_solver.cpp:105] Iteration 26000, lr = 0.01
I0617 12:14:33.288661  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 12:15:21.299296  4950 solver.cpp:218] Iteration 26050 (0.852081 iter/s, 58.6799s/50 iters), loss = 0.0100824
I0617 12:15:21.299453  4950 solver.cpp:237]     Train net output #0: loss = 0.0100824 (* 1 = 0.0100824 loss)
I0617 12:15:21.299476  4950 sgd_solver.cpp:105] Iteration 26050, lr = 0.01
I0617 12:16:19.967798  4950 solver.cpp:218] Iteration 26100 (0.852259 iter/s, 58.6676s/50 iters), loss = 0.00473643
I0617 12:16:19.967964  4950 solver.cpp:237]     Train net output #0: loss = 0.00473643 (* 1 = 0.00473643 loss)
I0617 12:16:19.967993  4950 sgd_solver.cpp:105] Iteration 26100, lr = 0.01
I0617 12:16:54.074287  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 12:17:18.641521  4950 solver.cpp:218] Iteration 26150 (0.852183 iter/s, 58.6729s/50 iters), loss = 0.0068422
I0617 12:17:18.641628  4950 solver.cpp:237]     Train net output #0: loss = 0.00684221 (* 1 = 0.00684221 loss)
I0617 12:17:18.641652  4950 sgd_solver.cpp:105] Iteration 26150, lr = 0.01
I0617 12:18:17.332723  4950 solver.cpp:218] Iteration 26200 (0.851928 iter/s, 58.6904s/50 iters), loss = 0.00607505
I0617 12:18:17.332865  4950 solver.cpp:237]     Train net output #0: loss = 0.00607505 (* 1 = 0.00607505 loss)
I0617 12:18:17.332888  4950 sgd_solver.cpp:105] Iteration 26200, lr = 0.01
I0617 12:19:14.925127  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 12:19:16.002454  4950 solver.cpp:218] Iteration 26250 (0.85224 iter/s, 58.6689s/50 iters), loss = 0.00492719
I0617 12:19:16.002570  4950 solver.cpp:237]     Train net output #0: loss = 0.00492719 (* 1 = 0.00492719 loss)
I0617 12:19:16.002595  4950 sgd_solver.cpp:105] Iteration 26250, lr = 0.01
I0617 12:20:14.670083  4950 solver.cpp:218] Iteration 26300 (0.85227 iter/s, 58.6668s/50 iters), loss = 0.00748358
I0617 12:20:14.670235  4950 solver.cpp:237]     Train net output #0: loss = 0.00748359 (* 1 = 0.00748359 loss)
I0617 12:20:14.670259  4950 sgd_solver.cpp:105] Iteration 26300, lr = 0.01
I0617 12:21:13.347503  4950 solver.cpp:218] Iteration 26350 (0.852129 iter/s, 58.6766s/50 iters), loss = 0.00576346
I0617 12:21:13.347636  4950 solver.cpp:237]     Train net output #0: loss = 0.00576347 (* 1 = 0.00576347 loss)
I0617 12:21:13.347659  4950 sgd_solver.cpp:105] Iteration 26350, lr = 0.01
I0617 12:21:35.698017  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 12:22:12.023259  4950 solver.cpp:218] Iteration 26400 (0.852152 iter/s, 58.6749s/50 iters), loss = 0.00688769
I0617 12:22:12.023416  4950 solver.cpp:237]     Train net output #0: loss = 0.0068877 (* 1 = 0.0068877 loss)
I0617 12:22:12.023440  4950 sgd_solver.cpp:105] Iteration 26400, lr = 0.01
I0617 12:23:10.689561  4950 solver.cpp:218] Iteration 26450 (0.85229 iter/s, 58.6655s/50 iters), loss = 0.0060094
I0617 12:23:10.689712  4950 solver.cpp:237]     Train net output #0: loss = 0.00600941 (* 1 = 0.00600941 loss)
I0617 12:23:10.689740  4950 sgd_solver.cpp:105] Iteration 26450, lr = 0.01
I0617 12:23:56.508015  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 12:24:09.366160  4950 solver.cpp:218] Iteration 26500 (0.85214 iter/s, 58.6758s/50 iters), loss = 0.00602333
I0617 12:24:09.366262  4950 solver.cpp:237]     Train net output #0: loss = 0.00602334 (* 1 = 0.00602334 loss)
I0617 12:24:09.366286  4950 sgd_solver.cpp:105] Iteration 26500, lr = 0.01
I0617 12:25:08.064754  4950 solver.cpp:218] Iteration 26550 (0.851821 iter/s, 58.6978s/50 iters), loss = 0.00670195
I0617 12:25:08.064935  4950 solver.cpp:237]     Train net output #0: loss = 0.00670196 (* 1 = 0.00670196 loss)
I0617 12:25:08.064960  4950 sgd_solver.cpp:105] Iteration 26550, lr = 0.01
I0617 12:26:06.731108  4950 solver.cpp:218] Iteration 26600 (0.85229 iter/s, 58.6655s/50 iters), loss = 0.00757103
I0617 12:26:06.731284  4950 solver.cpp:237]     Train net output #0: loss = 0.00757103 (* 1 = 0.00757103 loss)
I0617 12:26:06.731308  4950 sgd_solver.cpp:105] Iteration 26600, lr = 0.01
I0617 12:26:17.353584  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 12:27:05.405551  4950 solver.cpp:218] Iteration 26650 (0.852172 iter/s, 58.6736s/50 iters), loss = 0.00726997
I0617 12:27:05.405683  4950 solver.cpp:237]     Train net output #0: loss = 0.00726998 (* 1 = 0.00726998 loss)
I0617 12:27:05.405707  4950 sgd_solver.cpp:105] Iteration 26650, lr = 0.01
I0617 12:28:04.080790  4950 solver.cpp:218] Iteration 26700 (0.85216 iter/s, 58.6744s/50 iters), loss = 0.00673527
I0617 12:28:04.080941  4950 solver.cpp:237]     Train net output #0: loss = 0.00673527 (* 1 = 0.00673527 loss)
I0617 12:28:04.080965  4950 sgd_solver.cpp:105] Iteration 26700, lr = 0.01
I0617 12:28:38.163071  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 12:29:02.758905  4950 solver.cpp:218] Iteration 26750 (0.852118 iter/s, 58.6773s/50 iters), loss = 0.00673475
I0617 12:29:02.759011  4950 solver.cpp:237]     Train net output #0: loss = 0.00673475 (* 1 = 0.00673475 loss)
I0617 12:29:02.759032  4950 sgd_solver.cpp:105] Iteration 26750, lr = 0.01
I0617 12:30:01.445549  4950 solver.cpp:218] Iteration 26800 (0.851995 iter/s, 58.6858s/50 iters), loss = 0.00737742
I0617 12:30:01.445819  4950 solver.cpp:237]     Train net output #0: loss = 0.00737743 (* 1 = 0.00737743 loss)
I0617 12:30:01.445852  4950 sgd_solver.cpp:105] Iteration 26800, lr = 0.01
I0617 12:30:59.009172  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 12:31:00.130425  4950 solver.cpp:218] Iteration 26850 (0.852022 iter/s, 58.6839s/50 iters), loss = 0.00766665
I0617 12:31:00.130512  4950 solver.cpp:237]     Train net output #0: loss = 0.00766666 (* 1 = 0.00766666 loss)
I0617 12:31:00.130542  4950 sgd_solver.cpp:105] Iteration 26850, lr = 0.01
I0617 12:31:58.804149  4950 solver.cpp:218] Iteration 26900 (0.852181 iter/s, 58.673s/50 iters), loss = 0.00790447
I0617 12:31:58.804297  4950 solver.cpp:237]     Train net output #0: loss = 0.00790448 (* 1 = 0.00790448 loss)
I0617 12:31:58.804322  4950 sgd_solver.cpp:105] Iteration 26900, lr = 0.01
I0617 12:32:57.484025  4950 solver.cpp:218] Iteration 26950 (0.852093 iter/s, 58.6791s/50 iters), loss = 0.00910472
I0617 12:32:57.484167  4950 solver.cpp:237]     Train net output #0: loss = 0.00910472 (* 1 = 0.00910472 loss)
I0617 12:32:57.484191  4950 sgd_solver.cpp:105] Iteration 26950, lr = 0.01
I0617 12:33:18.683300  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 12:33:56.156560  4950 solver.cpp:218] Iteration 27000 (0.852199 iter/s, 58.6718s/50 iters), loss = 0.00790022
I0617 12:33:56.156718  4950 solver.cpp:237]     Train net output #0: loss = 0.00790023 (* 1 = 0.00790023 loss)
I0617 12:33:56.156740  4950 sgd_solver.cpp:105] Iteration 27000, lr = 0.01
I0617 12:34:54.826503  4950 solver.cpp:218] Iteration 27050 (0.852236 iter/s, 58.6692s/50 iters), loss = 0.00988031
I0617 12:34:54.826656  4950 solver.cpp:237]     Train net output #0: loss = 0.00988032 (* 1 = 0.00988032 loss)
I0617 12:34:54.826680  4950 sgd_solver.cpp:105] Iteration 27050, lr = 0.01
I0617 12:35:39.492257  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 12:35:53.506022  4950 solver.cpp:218] Iteration 27100 (0.852097 iter/s, 58.6788s/50 iters), loss = 0.00662011
I0617 12:35:53.506134  4950 solver.cpp:237]     Train net output #0: loss = 0.00662012 (* 1 = 0.00662012 loss)
I0617 12:35:53.506162  4950 sgd_solver.cpp:105] Iteration 27100, lr = 0.01
I0617 12:36:52.183709  4950 solver.cpp:218] Iteration 27150 (0.852122 iter/s, 58.677s/50 iters), loss = 0.00845717
I0617 12:36:52.185905  4950 solver.cpp:237]     Train net output #0: loss = 0.00845717 (* 1 = 0.00845717 loss)
I0617 12:36:52.185930  4950 sgd_solver.cpp:105] Iteration 27150, lr = 0.01
I0617 12:37:50.879746  4950 solver.cpp:218] Iteration 27200 (0.851887 iter/s, 58.6932s/50 iters), loss = 0.00702054
I0617 12:37:50.879942  4950 solver.cpp:237]     Train net output #0: loss = 0.00702055 (* 1 = 0.00702055 loss)
I0617 12:37:50.879972  4950 sgd_solver.cpp:105] Iteration 27200, lr = 0.01
I0617 12:38:00.348276  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 12:38:49.562834  4950 solver.cpp:218] Iteration 27250 (0.852046 iter/s, 58.6823s/50 iters), loss = 0.00882228
I0617 12:38:49.563025  4950 solver.cpp:237]     Train net output #0: loss = 0.00882229 (* 1 = 0.00882229 loss)
I0617 12:38:49.563050  4950 sgd_solver.cpp:105] Iteration 27250, lr = 0.01
I0617 12:39:48.237977  4950 solver.cpp:218] Iteration 27300 (0.852161 iter/s, 58.6744s/50 iters), loss = 0.00722824
I0617 12:39:48.238104  4950 solver.cpp:237]     Train net output #0: loss = 0.00722825 (* 1 = 0.00722825 loss)
I0617 12:39:48.238129  4950 sgd_solver.cpp:105] Iteration 27300, lr = 0.01
I0617 12:40:21.188340  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 12:40:46.920392  4950 solver.cpp:218] Iteration 27350 (0.852054 iter/s, 58.6817s/50 iters), loss = 0.00740528
I0617 12:40:46.920480  4950 solver.cpp:237]     Train net output #0: loss = 0.00740529 (* 1 = 0.00740529 loss)
I0617 12:40:46.920503  4950 sgd_solver.cpp:105] Iteration 27350, lr = 0.01
I0617 12:41:45.595130  4950 solver.cpp:218] Iteration 27400 (0.852165 iter/s, 58.6741s/50 iters), loss = 0.00761474
I0617 12:41:45.595278  4950 solver.cpp:237]     Train net output #0: loss = 0.00761475 (* 1 = 0.00761475 loss)
I0617 12:41:45.595301  4950 sgd_solver.cpp:105] Iteration 27400, lr = 0.01
I0617 12:42:41.979313  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 12:42:44.269335  4950 solver.cpp:218] Iteration 27450 (0.852174 iter/s, 58.6735s/50 iters), loss = 0.00732979
I0617 12:42:44.269433  4950 solver.cpp:237]     Train net output #0: loss = 0.00732979 (* 1 = 0.00732979 loss)
I0617 12:42:44.269455  4950 sgd_solver.cpp:105] Iteration 27450, lr = 0.01
I0617 12:43:42.950949  4950 solver.cpp:218] Iteration 27500 (0.852066 iter/s, 58.6809s/50 iters), loss = 0.00860596
I0617 12:43:42.951105  4950 solver.cpp:237]     Train net output #0: loss = 0.00860597 (* 1 = 0.00860597 loss)
I0617 12:43:42.951130  4950 sgd_solver.cpp:105] Iteration 27500, lr = 0.01
I0617 12:44:41.636867  4950 solver.cpp:218] Iteration 27550 (0.852004 iter/s, 58.6851s/50 iters), loss = 0.00743058
I0617 12:44:41.637024  4950 solver.cpp:237]     Train net output #0: loss = 0.00743059 (* 1 = 0.00743059 loss)
I0617 12:44:41.637054  4950 sgd_solver.cpp:105] Iteration 27550, lr = 0.01
I0617 12:45:02.820704  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 12:45:40.310849  4950 solver.cpp:218] Iteration 27600 (0.852177 iter/s, 58.6732s/50 iters), loss = 0.0101274
I0617 12:45:40.310971  4950 solver.cpp:237]     Train net output #0: loss = 0.0101274 (* 1 = 0.0101274 loss)
I0617 12:45:40.310994  4950 sgd_solver.cpp:105] Iteration 27600, lr = 0.01
I0617 12:46:38.983721  4950 solver.cpp:218] Iteration 27650 (0.852193 iter/s, 58.6721s/50 iters), loss = 0.00716321
I0617 12:46:38.983870  4950 solver.cpp:237]     Train net output #0: loss = 0.00716322 (* 1 = 0.00716322 loss)
I0617 12:46:38.983892  4950 sgd_solver.cpp:105] Iteration 27650, lr = 0.01
I0617 12:47:23.658530  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 12:47:37.666877  4950 solver.cpp:218] Iteration 27700 (0.852044 iter/s, 58.6824s/50 iters), loss = 0.00781841
I0617 12:47:37.666967  4950 solver.cpp:237]     Train net output #0: loss = 0.00781842 (* 1 = 0.00781842 loss)
I0617 12:47:37.666991  4950 sgd_solver.cpp:105] Iteration 27700, lr = 0.01
I0617 12:48:36.340683  4950 solver.cpp:218] Iteration 27750 (0.852179 iter/s, 58.6731s/50 iters), loss = 0.00985009
I0617 12:48:36.340828  4950 solver.cpp:237]     Train net output #0: loss = 0.00985009 (* 1 = 0.00985009 loss)
I0617 12:48:36.340853  4950 sgd_solver.cpp:105] Iteration 27750, lr = 0.01
I0617 12:49:35.030529  4950 solver.cpp:218] Iteration 27800 (0.851948 iter/s, 58.6891s/50 iters), loss = 0.00743627
I0617 12:49:35.030767  4950 solver.cpp:237]     Train net output #0: loss = 0.00743628 (* 1 = 0.00743628 loss)
I0617 12:49:35.030797  4950 sgd_solver.cpp:105] Iteration 27800, lr = 0.01
I0617 12:49:44.472648  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 12:50:33.724326  4950 solver.cpp:218] Iteration 27850 (0.851891 iter/s, 58.6929s/50 iters), loss = 0.00888665
I0617 12:50:33.724553  4950 solver.cpp:237]     Train net output #0: loss = 0.00888666 (* 1 = 0.00888666 loss)
I0617 12:50:33.724581  4950 sgd_solver.cpp:105] Iteration 27850, lr = 0.01
I0617 12:51:32.395289  4950 solver.cpp:218] Iteration 27900 (0.852223 iter/s, 58.6701s/50 iters), loss = 0.00950376
I0617 12:51:32.395452  4950 solver.cpp:237]     Train net output #0: loss = 0.00950377 (* 1 = 0.00950377 loss)
I0617 12:51:32.395483  4950 sgd_solver.cpp:105] Iteration 27900, lr = 0.01
I0617 12:52:05.294214  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 12:52:31.068822  4950 solver.cpp:218] Iteration 27950 (0.852184 iter/s, 58.6728s/50 iters), loss = 0.0100137
I0617 12:52:31.068928  4950 solver.cpp:237]     Train net output #0: loss = 0.0100137 (* 1 = 0.0100137 loss)
I0617 12:52:31.068950  4950 sgd_solver.cpp:105] Iteration 27950, lr = 0.01
I0617 12:53:29.743963  4950 solver.cpp:218] Iteration 28000 (0.85216 iter/s, 58.6744s/50 iters), loss = 0.00722772
I0617 12:53:29.744114  4950 solver.cpp:237]     Train net output #0: loss = 0.00722773 (* 1 = 0.00722773 loss)
I0617 12:53:29.744138  4950 sgd_solver.cpp:105] Iteration 28000, lr = 0.01
I0617 12:54:24.974120  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 12:54:28.416574  4950 solver.cpp:218] Iteration 28050 (0.852197 iter/s, 58.6719s/50 iters), loss = 0.00964715
I0617 12:54:28.416688  4950 solver.cpp:237]     Train net output #0: loss = 0.00964716 (* 1 = 0.00964716 loss)
I0617 12:54:28.416710  4950 sgd_solver.cpp:105] Iteration 28050, lr = 0.01
I0617 12:55:27.103824  4950 solver.cpp:218] Iteration 28100 (0.851984 iter/s, 58.6865s/50 iters), loss = 0.00801412
I0617 12:55:27.104018  4950 solver.cpp:237]     Train net output #0: loss = 0.00801413 (* 1 = 0.00801413 loss)
I0617 12:55:27.104044  4950 sgd_solver.cpp:105] Iteration 28100, lr = 0.01
I0617 12:56:25.787796  4950 solver.cpp:218] Iteration 28150 (0.852033 iter/s, 58.6832s/50 iters), loss = 0.00766402
I0617 12:56:25.787993  4950 solver.cpp:237]     Train net output #0: loss = 0.00766402 (* 1 = 0.00766402 loss)
I0617 12:56:25.788017  4950 sgd_solver.cpp:105] Iteration 28150, lr = 0.01
I0617 12:56:45.801940  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 12:57:24.461856  4950 solver.cpp:218] Iteration 28200 (0.852177 iter/s, 58.6732s/50 iters), loss = 0.00882244
I0617 12:57:24.461993  4950 solver.cpp:237]     Train net output #0: loss = 0.00882244 (* 1 = 0.00882244 loss)
I0617 12:57:24.462021  4950 sgd_solver.cpp:105] Iteration 28200, lr = 0.01
I0617 12:58:23.143488  4950 solver.cpp:218] Iteration 28250 (0.852066 iter/s, 58.6809s/50 iters), loss = 0.00742219
I0617 12:58:23.143623  4950 solver.cpp:237]     Train net output #0: loss = 0.00742219 (* 1 = 0.00742219 loss)
I0617 12:58:23.143648  4950 sgd_solver.cpp:105] Iteration 28250, lr = 0.01
I0617 12:59:06.665364  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 12:59:21.833588  4950 solver.cpp:218] Iteration 28300 (0.851943 iter/s, 58.6894s/50 iters), loss = 0.00808023
I0617 12:59:21.833684  4950 solver.cpp:237]     Train net output #0: loss = 0.00808024 (* 1 = 0.00808024 loss)
I0617 12:59:21.833709  4950 sgd_solver.cpp:105] Iteration 28300, lr = 0.01
I0617 13:00:20.507669  4950 solver.cpp:218] Iteration 28350 (0.852175 iter/s, 58.6734s/50 iters), loss = 0.00835855
I0617 13:00:20.507809  4950 solver.cpp:237]     Train net output #0: loss = 0.00835856 (* 1 = 0.00835856 loss)
I0617 13:00:20.507833  4950 sgd_solver.cpp:105] Iteration 28350, lr = 0.01
I0617 13:01:19.184207  4950 solver.cpp:218] Iteration 28400 (0.85214 iter/s, 58.6758s/50 iters), loss = 0.0135352
I0617 13:01:19.184437  4950 solver.cpp:237]     Train net output #0: loss = 0.0135352 (* 1 = 0.0135352 loss)
I0617 13:01:19.184461  4950 sgd_solver.cpp:105] Iteration 28400, lr = 0.01
I0617 13:01:27.462976  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 13:02:17.878214  4950 solver.cpp:218] Iteration 28450 (0.851888 iter/s, 58.6932s/50 iters), loss = 0.00909407
I0617 13:02:17.878412  4950 solver.cpp:237]     Train net output #0: loss = 0.00909408 (* 1 = 0.00909408 loss)
I0617 13:02:17.878437  4950 sgd_solver.cpp:105] Iteration 28450, lr = 0.01
I0617 13:03:16.567080  4950 solver.cpp:218] Iteration 28500 (0.851962 iter/s, 58.6881s/50 iters), loss = 0.00915436
I0617 13:03:16.567219  4950 solver.cpp:237]     Train net output #0: loss = 0.00915437 (* 1 = 0.00915437 loss)
I0617 13:03:16.567247  4950 sgd_solver.cpp:105] Iteration 28500, lr = 0.01
I0617 13:03:48.341259  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 13:04:15.251458  4950 solver.cpp:218] Iteration 28550 (0.852027 iter/s, 58.6836s/50 iters), loss = 0.00827568
I0617 13:04:15.251595  4950 solver.cpp:237]     Train net output #0: loss = 0.00827569 (* 1 = 0.00827569 loss)
I0617 13:04:15.251619  4950 sgd_solver.cpp:105] Iteration 28550, lr = 0.01
I0617 13:05:13.919450  4950 solver.cpp:218] Iteration 28600 (0.852264 iter/s, 58.6672s/50 iters), loss = 0.0087451
I0617 13:05:13.919606  4950 solver.cpp:237]     Train net output #0: loss = 0.0087451 (* 1 = 0.0087451 loss)
I0617 13:05:13.919628  4950 sgd_solver.cpp:105] Iteration 28600, lr = 0.01
I0617 13:06:09.160214  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 13:06:12.598517  4950 solver.cpp:218] Iteration 28650 (0.852104 iter/s, 58.6783s/50 iters), loss = 0.00846524
I0617 13:06:12.598654  4950 solver.cpp:237]     Train net output #0: loss = 0.00846524 (* 1 = 0.00846524 loss)
I0617 13:06:12.598681  4950 sgd_solver.cpp:105] Iteration 28650, lr = 0.01
I0617 13:07:11.264921  4950 solver.cpp:218] Iteration 28700 (0.852287 iter/s, 58.6657s/50 iters), loss = 0.00837059
I0617 13:07:11.265059  4950 solver.cpp:237]     Train net output #0: loss = 0.00837059 (* 1 = 0.00837059 loss)
I0617 13:07:11.265084  4950 sgd_solver.cpp:105] Iteration 28700, lr = 0.01
I0617 13:08:09.924089  4950 solver.cpp:218] Iteration 28750 (0.852393 iter/s, 58.6584s/50 iters), loss = 0.00831353
I0617 13:08:09.924221  4950 solver.cpp:237]     Train net output #0: loss = 0.00831354 (* 1 = 0.00831354 loss)
I0617 13:08:09.924244  4950 sgd_solver.cpp:105] Iteration 28750, lr = 0.01
I0617 13:08:29.946701  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 13:09:08.597796  4950 solver.cpp:218] Iteration 28800 (0.852182 iter/s, 58.6729s/50 iters), loss = 0.00880127
I0617 13:09:08.597955  4950 solver.cpp:237]     Train net output #0: loss = 0.00880127 (* 1 = 0.00880127 loss)
I0617 13:09:08.597980  4950 sgd_solver.cpp:105] Iteration 28800, lr = 0.01
I0617 13:10:07.305368  4950 solver.cpp:218] Iteration 28850 (0.851691 iter/s, 58.7067s/50 iters), loss = 0.00860245
I0617 13:10:07.305539  4950 solver.cpp:237]     Train net output #0: loss = 0.00860246 (* 1 = 0.00860246 loss)
I0617 13:10:07.305564  4950 sgd_solver.cpp:105] Iteration 28850, lr = 0.01
I0617 13:10:50.797355  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 13:11:05.991135  4950 solver.cpp:218] Iteration 28900 (0.852007 iter/s, 58.6849s/50 iters), loss = 0.00817233
I0617 13:11:05.991271  4950 solver.cpp:237]     Train net output #0: loss = 0.00817233 (* 1 = 0.00817233 loss)
I0617 13:11:05.991295  4950 sgd_solver.cpp:105] Iteration 28900, lr = 0.01
I0617 13:12:04.692356  4950 solver.cpp:218] Iteration 28950 (0.851783 iter/s, 58.7004s/50 iters), loss = 0.0098861
I0617 13:12:04.692535  4950 solver.cpp:237]     Train net output #0: loss = 0.00988611 (* 1 = 0.00988611 loss)
I0617 13:12:04.692561  4950 sgd_solver.cpp:105] Iteration 28950, lr = 0.01
I0617 13:13:03.378540  4950 solver.cpp:218] Iteration 29000 (0.852002 iter/s, 58.6853s/50 iters), loss = 0.00977253
I0617 13:13:03.378729  4950 solver.cpp:237]     Train net output #0: loss = 0.00977254 (* 1 = 0.00977254 loss)
I0617 13:13:03.378759  4950 sgd_solver.cpp:105] Iteration 29000, lr = 0.01
I0617 13:13:10.504075  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 13:14:02.086565  4950 solver.cpp:218] Iteration 29050 (0.851685 iter/s, 58.7072s/50 iters), loss = 0.0112244
I0617 13:14:02.086719  4950 solver.cpp:237]     Train net output #0: loss = 0.0112244 (* 1 = 0.0112244 loss)
I0617 13:14:02.086745  4950 sgd_solver.cpp:105] Iteration 29050, lr = 0.01
I0617 13:15:00.784965  4950 solver.cpp:218] Iteration 29100 (0.851824 iter/s, 58.6976s/50 iters), loss = 0.00886198
I0617 13:15:00.785120  4950 solver.cpp:237]     Train net output #0: loss = 0.00886198 (* 1 = 0.00886198 loss)
I0617 13:15:00.785148  4950 sgd_solver.cpp:105] Iteration 29100, lr = 0.01
I0617 13:15:31.355033  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 13:15:59.427193  4950 solver.cpp:218] Iteration 29150 (0.85264 iter/s, 58.6414s/50 iters), loss = 0.00913302
I0617 13:15:59.427311  4950 solver.cpp:237]     Train net output #0: loss = 0.00913302 (* 1 = 0.00913302 loss)
I0617 13:15:59.427333  4950 sgd_solver.cpp:105] Iteration 29150, lr = 0.01
I0617 13:16:58.091418  4950 solver.cpp:218] Iteration 29200 (0.852319 iter/s, 58.6635s/50 iters), loss = 0.00831141
I0617 13:16:58.091584  4950 solver.cpp:237]     Train net output #0: loss = 0.00831142 (* 1 = 0.00831142 loss)
I0617 13:16:58.091609  4950 sgd_solver.cpp:105] Iteration 29200, lr = 0.01
I0617 13:17:52.124411  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 13:17:56.719751  4950 solver.cpp:218] Iteration 29250 (0.852841 iter/s, 58.6275s/50 iters), loss = 0.0100339
I0617 13:17:56.719844  4950 solver.cpp:237]     Train net output #0: loss = 0.0100339 (* 1 = 0.0100339 loss)
I0617 13:17:56.719877  4950 sgd_solver.cpp:105] Iteration 29250, lr = 0.01
I0617 13:18:55.386144  4950 solver.cpp:218] Iteration 29300 (0.852288 iter/s, 58.6656s/50 iters), loss = 0.0103546
I0617 13:18:55.386951  4950 solver.cpp:237]     Train net output #0: loss = 0.0103547 (* 1 = 0.0103547 loss)
I0617 13:18:55.386977  4950 sgd_solver.cpp:105] Iteration 29300, lr = 0.01
I0617 13:19:54.093360  4950 solver.cpp:218] Iteration 29350 (0.851706 iter/s, 58.7057s/50 iters), loss = 0.0080647
I0617 13:19:54.093569  4950 solver.cpp:237]     Train net output #0: loss = 0.00806471 (* 1 = 0.00806471 loss)
I0617 13:19:54.093602  4950 sgd_solver.cpp:105] Iteration 29350, lr = 0.01
I0617 13:20:12.974143  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 13:20:52.773715  4950 solver.cpp:218] Iteration 29400 (0.852087 iter/s, 58.6795s/50 iters), loss = 0.0105337
I0617 13:20:52.773893  4950 solver.cpp:237]     Train net output #0: loss = 0.0105337 (* 1 = 0.0105337 loss)
I0617 13:20:52.773916  4950 sgd_solver.cpp:105] Iteration 29400, lr = 0.01
I0617 13:21:51.484921  4950 solver.cpp:218] Iteration 29450 (0.851638 iter/s, 58.7104s/50 iters), loss = 0.0108494
I0617 13:21:51.485092  4950 solver.cpp:237]     Train net output #0: loss = 0.0108494 (* 1 = 0.0108494 loss)
I0617 13:21:51.485133  4950 sgd_solver.cpp:105] Iteration 29450, lr = 0.01
I0617 13:22:33.833389  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 13:22:50.175289  4950 solver.cpp:218] Iteration 29500 (0.85194 iter/s, 58.6895s/50 iters), loss = 0.00717044
I0617 13:22:50.175385  4950 solver.cpp:237]     Train net output #0: loss = 0.00717045 (* 1 = 0.00717045 loss)
I0617 13:22:50.175410  4950 sgd_solver.cpp:105] Iteration 29500, lr = 0.01
I0617 13:23:48.877782  4950 solver.cpp:218] Iteration 29550 (0.851764 iter/s, 58.7017s/50 iters), loss = 0.0110267
I0617 13:23:48.877962  4950 solver.cpp:237]     Train net output #0: loss = 0.0110267 (* 1 = 0.0110267 loss)
I0617 13:23:48.877986  4950 sgd_solver.cpp:105] Iteration 29550, lr = 0.01
I0617 13:24:47.578094  4950 solver.cpp:218] Iteration 29600 (0.851796 iter/s, 58.6995s/50 iters), loss = 0.010495
I0617 13:24:47.578297  4950 solver.cpp:237]     Train net output #0: loss = 0.010495 (* 1 = 0.010495 loss)
I0617 13:24:47.578320  4950 sgd_solver.cpp:105] Iteration 29600, lr = 0.01
I0617 13:24:54.666651  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 13:25:46.223335  4950 solver.cpp:218] Iteration 29650 (0.852596 iter/s, 58.6444s/50 iters), loss = 0.0075276
I0617 13:25:46.223485  4950 solver.cpp:237]     Train net output #0: loss = 0.00752761 (* 1 = 0.00752761 loss)
I0617 13:25:46.223507  4950 sgd_solver.cpp:105] Iteration 29650, lr = 0.01
I0617 13:26:44.862920  4950 solver.cpp:218] Iteration 29700 (0.852678 iter/s, 58.6388s/50 iters), loss = 0.00878114
I0617 13:26:44.863116  4950 solver.cpp:237]     Train net output #0: loss = 0.00878115 (* 1 = 0.00878115 loss)
I0617 13:26:44.863148  4950 sgd_solver.cpp:105] Iteration 29700, lr = 0.01
I0617 13:27:15.445672  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 13:27:43.518955  4950 solver.cpp:218] Iteration 29750 (0.852439 iter/s, 58.6553s/50 iters), loss = 0.00884305
I0617 13:27:43.519057  4950 solver.cpp:237]     Train net output #0: loss = 0.00884306 (* 1 = 0.00884306 loss)
I0617 13:27:43.519091  4950 sgd_solver.cpp:105] Iteration 29750, lr = 0.01
I0617 13:28:42.160102  4950 solver.cpp:218] Iteration 29800 (0.852654 iter/s, 58.6405s/50 iters), loss = 0.00825387
I0617 13:28:42.160225  4950 solver.cpp:237]     Train net output #0: loss = 0.00825388 (* 1 = 0.00825388 loss)
I0617 13:28:42.160246  4950 sgd_solver.cpp:105] Iteration 29800, lr = 0.01
I0617 13:29:36.169163  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 13:29:40.811247  4950 solver.cpp:218] Iteration 29850 (0.852509 iter/s, 58.6504s/50 iters), loss = 0.0101643
I0617 13:29:40.811341  4950 solver.cpp:237]     Train net output #0: loss = 0.0101643 (* 1 = 0.0101643 loss)
I0617 13:29:40.811375  4950 sgd_solver.cpp:105] Iteration 29850, lr = 0.01
I0617 13:30:39.439401  4950 solver.cpp:218] Iteration 29900 (0.852843 iter/s, 58.6275s/50 iters), loss = 0.0098593
I0617 13:30:39.439592  4950 solver.cpp:237]     Train net output #0: loss = 0.00985931 (* 1 = 0.00985931 loss)
I0617 13:30:39.439615  4950 sgd_solver.cpp:105] Iteration 29900, lr = 0.01
I0617 13:31:38.066555  4950 solver.cpp:218] Iteration 29950 (0.852859 iter/s, 58.6264s/50 iters), loss = 0.00904241
I0617 13:31:38.066689  4950 solver.cpp:237]     Train net output #0: loss = 0.00904241 (* 1 = 0.00904241 loss)
I0617 13:31:38.066709  4950 sgd_solver.cpp:105] Iteration 29950, lr = 0.01
I0617 13:31:55.741222  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 13:32:35.534241  4950 solver.cpp:447] Snapshotting to binary proto file mobilenet/mobile_cub_iter_30000.caffemodel
I0617 13:32:35.619438  4950 sgd_solver.cpp:273] Snapshotting solver state to binary proto file mobilenet/mobile_cub_iter_30000.solverstate
I0617 13:32:36.822093  4950 solver.cpp:218] Iteration 30000 (0.850995 iter/s, 58.7547s/50 iters), loss = 0.010437
I0617 13:32:36.822232  4950 solver.cpp:237]     Train net output #0: loss = 0.010437 (* 1 = 0.010437 loss)
I0617 13:32:36.822268  4950 sgd_solver.cpp:105] Iteration 30000, lr = 0.01
I0617 13:33:35.499311  4950 solver.cpp:218] Iteration 30050 (0.85213 iter/s, 58.6765s/50 iters), loss = 0.0092906
I0617 13:33:35.499511  4950 solver.cpp:237]     Train net output #0: loss = 0.00929061 (* 1 = 0.00929061 loss)
I0617 13:33:35.499542  4950 sgd_solver.cpp:105] Iteration 30050, lr = 0.01
I0617 13:34:16.647543  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 13:34:34.174379  4950 solver.cpp:218] Iteration 30100 (0.852162 iter/s, 58.6743s/50 iters), loss = 0.0111486
I0617 13:34:34.174480  4950 solver.cpp:237]     Train net output #0: loss = 0.0111486 (* 1 = 0.0111486 loss)
I0617 13:34:34.174504  4950 sgd_solver.cpp:105] Iteration 30100, lr = 0.01
I0617 13:35:32.847797  4950 solver.cpp:218] Iteration 30150 (0.852185 iter/s, 58.6727s/50 iters), loss = 0.00911771
I0617 13:35:32.847990  4950 solver.cpp:237]     Train net output #0: loss = 0.00911772 (* 1 = 0.00911772 loss)
I0617 13:35:32.848027  4950 sgd_solver.cpp:105] Iteration 30150, lr = 0.01
I0617 13:36:31.519973  4950 solver.cpp:218] Iteration 30200 (0.852204 iter/s, 58.6714s/50 iters), loss = 0.00927611
I0617 13:36:31.520161  4950 solver.cpp:237]     Train net output #0: loss = 0.00927612 (* 1 = 0.00927612 loss)
I0617 13:36:31.520186  4950 sgd_solver.cpp:105] Iteration 30200, lr = 0.01
I0617 13:36:37.461263  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 13:37:30.194003  4950 solver.cpp:218] Iteration 30250 (0.852177 iter/s, 58.6732s/50 iters), loss = 0.0110596
I0617 13:37:30.194131  4950 solver.cpp:237]     Train net output #0: loss = 0.0110596 (* 1 = 0.0110596 loss)
I0617 13:37:30.194154  4950 sgd_solver.cpp:105] Iteration 30250, lr = 0.01
I0617 13:38:28.876910  4950 solver.cpp:218] Iteration 30300 (0.852048 iter/s, 58.6822s/50 iters), loss = 0.00885609
I0617 13:38:28.877090  4950 solver.cpp:237]     Train net output #0: loss = 0.0088561 (* 1 = 0.0088561 loss)
I0617 13:38:28.877113  4950 sgd_solver.cpp:105] Iteration 30300, lr = 0.01
I0617 13:38:58.301504  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 13:39:27.602715  4950 solver.cpp:218] Iteration 30350 (0.851426 iter/s, 58.725s/50 iters), loss = 0.0104194
I0617 13:39:27.602903  4950 solver.cpp:237]     Train net output #0: loss = 0.0104194 (* 1 = 0.0104194 loss)
I0617 13:39:27.602936  4950 sgd_solver.cpp:105] Iteration 30350, lr = 0.01
I0617 13:40:26.322206  4950 solver.cpp:218] Iteration 30400 (0.851518 iter/s, 58.7187s/50 iters), loss = 0.0109811
I0617 13:40:26.322388  4950 solver.cpp:237]     Train net output #0: loss = 0.0109811 (* 1 = 0.0109811 loss)
I0617 13:40:26.322419  4950 sgd_solver.cpp:105] Iteration 30400, lr = 0.01
I0617 13:41:19.234733  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 13:41:25.051802  4950 solver.cpp:218] Iteration 30450 (0.851371 iter/s, 58.7288s/50 iters), loss = 0.00951141
I0617 13:41:25.051918  4950 solver.cpp:237]     Train net output #0: loss = 0.00951142 (* 1 = 0.00951142 loss)
I0617 13:41:25.051940  4950 sgd_solver.cpp:105] Iteration 30450, lr = 0.01
I0617 13:42:23.774899  4950 solver.cpp:218] Iteration 30500 (0.851464 iter/s, 58.7224s/50 iters), loss = 0.00931776
I0617 13:42:23.775066  4950 solver.cpp:237]     Train net output #0: loss = 0.00931777 (* 1 = 0.00931777 loss)
I0617 13:42:23.775091  4950 sgd_solver.cpp:105] Iteration 30500, lr = 0.01
I0617 13:43:22.489682  4950 solver.cpp:218] Iteration 30550 (0.851586 iter/s, 58.714s/50 iters), loss = 0.00842068
I0617 13:43:22.489866  4950 solver.cpp:237]     Train net output #0: loss = 0.00842069 (* 1 = 0.00842069 loss)
I0617 13:43:22.489892  4950 sgd_solver.cpp:105] Iteration 30550, lr = 0.01
I0617 13:43:40.160830  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 13:44:21.210860  4950 solver.cpp:218] Iteration 30600 (0.851493 iter/s, 58.7204s/50 iters), loss = 0.010212
I0617 13:44:21.211025  4950 solver.cpp:237]     Train net output #0: loss = 0.010212 (* 1 = 0.010212 loss)
I0617 13:44:21.211050  4950 sgd_solver.cpp:105] Iteration 30600, lr = 0.01
I0617 13:45:19.937222  4950 solver.cpp:218] Iteration 30650 (0.851418 iter/s, 58.7256s/50 iters), loss = 0.0109657
I0617 13:45:19.937386  4950 solver.cpp:237]     Train net output #0: loss = 0.0109657 (* 1 = 0.0109657 loss)
I0617 13:45:19.937410  4950 sgd_solver.cpp:105] Iteration 30650, lr = 0.01
I0617 13:46:01.089277  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 13:46:18.654883  4950 solver.cpp:218] Iteration 30700 (0.851544 iter/s, 58.7169s/50 iters), loss = 0.0123052
I0617 13:46:18.655014  4950 solver.cpp:237]     Train net output #0: loss = 0.0123052 (* 1 = 0.0123052 loss)
I0617 13:46:18.655037  4950 sgd_solver.cpp:105] Iteration 30700, lr = 0.01
I0617 13:47:17.362293  4950 solver.cpp:218] Iteration 30750 (0.851692 iter/s, 58.7066s/50 iters), loss = 0.00960361
I0617 13:47:17.362471  4950 solver.cpp:237]     Train net output #0: loss = 0.00960362 (* 1 = 0.00960362 loss)
I0617 13:47:17.362504  4950 sgd_solver.cpp:105] Iteration 30750, lr = 0.01
I0617 13:48:16.066607  4950 solver.cpp:218] Iteration 30800 (0.851737 iter/s, 58.7035s/50 iters), loss = 0.0108662
I0617 13:48:16.066783  4950 solver.cpp:237]     Train net output #0: loss = 0.0108662 (* 1 = 0.0108662 loss)
I0617 13:48:16.066807  4950 sgd_solver.cpp:105] Iteration 30800, lr = 0.01
I0617 13:48:22.008327  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 13:49:14.729552  4950 solver.cpp:218] Iteration 30850 (0.852338 iter/s, 58.6622s/50 iters), loss = 0.0086183
I0617 13:49:14.729696  4950 solver.cpp:237]     Train net output #0: loss = 0.00861831 (* 1 = 0.00861831 loss)
I0617 13:49:14.729719  4950 sgd_solver.cpp:105] Iteration 30850, lr = 0.01
I0617 13:50:13.399603  4950 solver.cpp:218] Iteration 30900 (0.852235 iter/s, 58.6693s/50 iters), loss = 0.00937168
I0617 13:50:13.399725  4950 solver.cpp:237]     Train net output #0: loss = 0.00937169 (* 1 = 0.00937169 loss)
I0617 13:50:13.399749  4950 sgd_solver.cpp:105] Iteration 30900, lr = 0.01
I0617 13:50:42.808972  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 13:51:12.071581  4950 solver.cpp:218] Iteration 30950 (0.852207 iter/s, 58.6712s/50 iters), loss = 0.0110338
I0617 13:51:12.071717  4950 solver.cpp:237]     Train net output #0: loss = 0.0110338 (* 1 = 0.0110338 loss)
I0617 13:51:12.071745  4950 sgd_solver.cpp:105] Iteration 30950, lr = 0.01
I0617 13:52:10.757055  4950 solver.cpp:218] Iteration 31000 (0.85201 iter/s, 58.6847s/50 iters), loss = 0.00841476
I0617 13:52:10.757189  4950 solver.cpp:237]     Train net output #0: loss = 0.00841477 (* 1 = 0.00841477 loss)
I0617 13:52:10.757218  4950 sgd_solver.cpp:105] Iteration 31000, lr = 0.01
I0617 13:53:02.484056  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 13:53:09.418453  4950 solver.cpp:218] Iteration 31050 (0.85236 iter/s, 58.6607s/50 iters), loss = 0.0120624
I0617 13:53:09.418560  4950 solver.cpp:237]     Train net output #0: loss = 0.0120624 (* 1 = 0.0120624 loss)
I0617 13:53:09.418583  4950 sgd_solver.cpp:105] Iteration 31050, lr = 0.01
I0617 13:54:08.078055  4950 solver.cpp:218] Iteration 31100 (0.852386 iter/s, 58.6589s/50 iters), loss = 0.00990396
I0617 13:54:08.078186  4950 solver.cpp:237]     Train net output #0: loss = 0.00990397 (* 1 = 0.00990397 loss)
I0617 13:54:08.078208  4950 sgd_solver.cpp:105] Iteration 31100, lr = 0.01
I0617 13:55:06.757176  4950 solver.cpp:218] Iteration 31150 (0.852103 iter/s, 58.6783s/50 iters), loss = 0.00876654
I0617 13:55:06.757306  4950 solver.cpp:237]     Train net output #0: loss = 0.00876655 (* 1 = 0.00876655 loss)
I0617 13:55:06.757335  4950 sgd_solver.cpp:105] Iteration 31150, lr = 0.01
I0617 13:55:23.257230  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 13:56:05.428215  4950 solver.cpp:218] Iteration 31200 (0.85222 iter/s, 58.6703s/50 iters), loss = 0.00973797
I0617 13:56:05.428352  4950 solver.cpp:237]     Train net output #0: loss = 0.00973798 (* 1 = 0.00973798 loss)
I0617 13:56:05.428376  4950 sgd_solver.cpp:105] Iteration 31200, lr = 0.01
I0617 13:57:04.093888  4950 solver.cpp:218] Iteration 31250 (0.852298 iter/s, 58.6649s/50 iters), loss = 0.0115436
I0617 13:57:04.094017  4950 solver.cpp:237]     Train net output #0: loss = 0.0115436 (* 1 = 0.0115436 loss)
I0617 13:57:04.094046  4950 sgd_solver.cpp:105] Iteration 31250, lr = 0.01
I0617 13:57:44.080124  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 13:58:02.755426  4950 solver.cpp:218] Iteration 31300 (0.852358 iter/s, 58.6608s/50 iters), loss = 0.00850725
I0617 13:58:02.755524  4950 solver.cpp:237]     Train net output #0: loss = 0.00850725 (* 1 = 0.00850725 loss)
I0617 13:58:02.755550  4950 sgd_solver.cpp:105] Iteration 31300, lr = 0.01
I0617 13:59:01.413631  4950 solver.cpp:218] Iteration 31350 (0.852406 iter/s, 58.6575s/50 iters), loss = 0.0119382
I0617 13:59:01.413767  4950 solver.cpp:237]     Train net output #0: loss = 0.0119382 (* 1 = 0.0119382 loss)
I0617 13:59:01.413791  4950 sgd_solver.cpp:105] Iteration 31350, lr = 0.01
I0617 14:00:00.078529  4950 solver.cpp:218] Iteration 31400 (0.85231 iter/s, 58.6641s/50 iters), loss = 0.0128915
I0617 14:00:00.078709  4950 solver.cpp:237]     Train net output #0: loss = 0.0128915 (* 1 = 0.0128915 loss)
I0617 14:00:00.078735  4950 sgd_solver.cpp:105] Iteration 31400, lr = 0.01
I0617 14:00:04.834619  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 14:00:58.739739  4950 solver.cpp:218] Iteration 31450 (0.852365 iter/s, 58.6603s/50 iters), loss = 0.0117172
I0617 14:00:58.739874  4950 solver.cpp:237]     Train net output #0: loss = 0.0117172 (* 1 = 0.0117172 loss)
I0617 14:00:58.739897  4950 sgd_solver.cpp:105] Iteration 31450, lr = 0.01
I0617 14:01:57.404980  4950 solver.cpp:218] Iteration 31500 (0.852306 iter/s, 58.6644s/50 iters), loss = 0.0098025
I0617 14:01:57.405131  4950 solver.cpp:237]     Train net output #0: loss = 0.00980251 (* 1 = 0.00980251 loss)
I0617 14:01:57.405154  4950 sgd_solver.cpp:105] Iteration 31500, lr = 0.01
I0617 14:02:25.650568  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 14:02:56.068290  4950 solver.cpp:218] Iteration 31550 (0.852334 iter/s, 58.6625s/50 iters), loss = 0.0105028
I0617 14:02:56.068449  4950 solver.cpp:237]     Train net output #0: loss = 0.0105028 (* 1 = 0.0105028 loss)
I0617 14:02:56.068475  4950 sgd_solver.cpp:105] Iteration 31550, lr = 0.01
I0617 14:03:54.737782  4950 solver.cpp:218] Iteration 31600 (0.852244 iter/s, 58.6686s/50 iters), loss = 0.00880811
I0617 14:03:54.737938  4950 solver.cpp:237]     Train net output #0: loss = 0.00880811 (* 1 = 0.00880811 loss)
I0617 14:03:54.737962  4950 sgd_solver.cpp:105] Iteration 31600, lr = 0.01
I0617 14:04:46.416031  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 14:04:53.401702  4950 solver.cpp:218] Iteration 31650 (0.852325 iter/s, 58.6631s/50 iters), loss = 0.010108
I0617 14:04:53.401813  4950 solver.cpp:237]     Train net output #0: loss = 0.010108 (* 1 = 0.010108 loss)
I0617 14:04:53.401834  4950 sgd_solver.cpp:105] Iteration 31650, lr = 0.01
I0617 14:05:52.066776  4950 solver.cpp:218] Iteration 31700 (0.852307 iter/s, 58.6643s/50 iters), loss = 0.00863476
I0617 14:05:52.066916  4950 solver.cpp:237]     Train net output #0: loss = 0.00863477 (* 1 = 0.00863477 loss)
I0617 14:05:52.066941  4950 sgd_solver.cpp:105] Iteration 31700, lr = 0.01
I0617 14:06:50.737414  4950 solver.cpp:218] Iteration 31750 (0.852227 iter/s, 58.6698s/50 iters), loss = 0.0101191
I0617 14:06:50.737561  4950 solver.cpp:237]     Train net output #0: loss = 0.0101191 (* 1 = 0.0101191 loss)
I0617 14:06:50.737587  4950 sgd_solver.cpp:105] Iteration 31750, lr = 0.01
I0617 14:07:07.240762  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 14:07:49.401057  4950 solver.cpp:218] Iteration 31800 (0.852329 iter/s, 58.6628s/50 iters), loss = 0.0108115
I0617 14:07:49.401183  4950 solver.cpp:237]     Train net output #0: loss = 0.0108115 (* 1 = 0.0108115 loss)
I0617 14:07:49.401207  4950 sgd_solver.cpp:105] Iteration 31800, lr = 0.01
I0617 14:08:48.046212  4950 solver.cpp:218] Iteration 31850 (0.852597 iter/s, 58.6443s/50 iters), loss = 0.0122102
I0617 14:08:48.046335  4950 solver.cpp:237]     Train net output #0: loss = 0.0122102 (* 1 = 0.0122102 loss)
I0617 14:08:48.046360  4950 sgd_solver.cpp:105] Iteration 31850, lr = 0.01
I0617 14:09:28.005985  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 14:09:46.710911  4950 solver.cpp:218] Iteration 31900 (0.852313 iter/s, 58.6639s/50 iters), loss = 0.0114475
I0617 14:09:46.711016  4950 solver.cpp:237]     Train net output #0: loss = 0.0114475 (* 1 = 0.0114475 loss)
I0617 14:09:46.711040  4950 sgd_solver.cpp:105] Iteration 31900, lr = 0.01
I0617 14:10:45.371727  4950 solver.cpp:218] Iteration 31950 (0.852369 iter/s, 58.66s/50 iters), loss = 0.00916819
I0617 14:10:45.371866  4950 solver.cpp:237]     Train net output #0: loss = 0.0091682 (* 1 = 0.0091682 loss)
I0617 14:10:45.371891  4950 sgd_solver.cpp:105] Iteration 31950, lr = 0.01
I0617 14:11:44.031582  4950 solver.cpp:218] Iteration 32000 (0.852384 iter/s, 58.659s/50 iters), loss = 0.0103805
I0617 14:11:44.031746  4950 solver.cpp:237]     Train net output #0: loss = 0.0103805 (* 1 = 0.0103805 loss)
I0617 14:11:44.031771  4950 sgd_solver.cpp:105] Iteration 32000, lr = 0.01
I0617 14:11:47.657153  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 14:12:42.688606  4950 solver.cpp:218] Iteration 32050 (0.852425 iter/s, 58.6562s/50 iters), loss = 0.00813259
I0617 14:12:42.688752  4950 solver.cpp:237]     Train net output #0: loss = 0.0081326 (* 1 = 0.0081326 loss)
I0617 14:12:42.688776  4950 sgd_solver.cpp:105] Iteration 32050, lr = 0.01
I0617 14:13:41.348814  4950 solver.cpp:218] Iteration 32100 (0.852379 iter/s, 58.6594s/50 iters), loss = 0.00986227
I0617 14:13:41.348953  4950 solver.cpp:237]     Train net output #0: loss = 0.00986228 (* 1 = 0.00986228 loss)
I0617 14:13:41.348978  4950 sgd_solver.cpp:105] Iteration 32100, lr = 0.01
I0617 14:14:08.413930  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 14:14:40.018591  4950 solver.cpp:218] Iteration 32150 (0.85224 iter/s, 58.6689s/50 iters), loss = 0.0138642
I0617 14:14:40.018725  4950 solver.cpp:237]     Train net output #0: loss = 0.0138642 (* 1 = 0.0138642 loss)
I0617 14:14:40.018752  4950 sgd_solver.cpp:105] Iteration 32150, lr = 0.01
I0617 14:15:38.677568  4950 solver.cpp:218] Iteration 32200 (0.852396 iter/s, 58.6582s/50 iters), loss = 0.00821551
I0617 14:15:38.677719  4950 solver.cpp:237]     Train net output #0: loss = 0.00821552 (* 1 = 0.00821552 loss)
I0617 14:15:38.677743  4950 sgd_solver.cpp:105] Iteration 32200, lr = 0.01
I0617 14:16:29.206992  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 14:16:37.356662  4950 solver.cpp:218] Iteration 32250 (0.852104 iter/s, 58.6783s/50 iters), loss = 0.00994147
I0617 14:16:37.356758  4950 solver.cpp:237]     Train net output #0: loss = 0.00994148 (* 1 = 0.00994148 loss)
I0617 14:16:37.356794  4950 sgd_solver.cpp:105] Iteration 32250, lr = 0.01
I0617 14:17:36.009389  4950 solver.cpp:218] Iteration 32300 (0.852487 iter/s, 58.6519s/50 iters), loss = 0.00761851
I0617 14:17:36.009536  4950 solver.cpp:237]     Train net output #0: loss = 0.00761852 (* 1 = 0.00761852 loss)
I0617 14:17:36.009560  4950 sgd_solver.cpp:105] Iteration 32300, lr = 0.01
I0617 14:18:34.667341  4950 solver.cpp:218] Iteration 32350 (0.852411 iter/s, 58.6571s/50 iters), loss = 0.0101046
I0617 14:18:34.667487  4950 solver.cpp:237]     Train net output #0: loss = 0.0101046 (* 1 = 0.0101046 loss)
I0617 14:18:34.667511  4950 sgd_solver.cpp:105] Iteration 32350, lr = 0.01
I0617 14:18:50.009640  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 14:19:33.327706  4950 solver.cpp:218] Iteration 32400 (0.852376 iter/s, 58.6595s/50 iters), loss = 0.0100743
I0617 14:19:33.327841  4950 solver.cpp:237]     Train net output #0: loss = 0.0100743 (* 1 = 0.0100743 loss)
I0617 14:19:33.327865  4950 sgd_solver.cpp:105] Iteration 32400, lr = 0.01
I0617 14:20:31.989194  4950 solver.cpp:218] Iteration 32450 (0.85236 iter/s, 58.6607s/50 iters), loss = 0.00821092
I0617 14:20:31.989315  4950 solver.cpp:237]     Train net output #0: loss = 0.00821093 (* 1 = 0.00821093 loss)
I0617 14:20:31.989337  4950 sgd_solver.cpp:105] Iteration 32450, lr = 0.01
I0617 14:21:10.795871  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 14:21:30.653403  4950 solver.cpp:218] Iteration 32500 (0.85232 iter/s, 58.6634s/50 iters), loss = 0.0106428
I0617 14:21:30.653506  4950 solver.cpp:237]     Train net output #0: loss = 0.0106428 (* 1 = 0.0106428 loss)
I0617 14:21:30.653542  4950 sgd_solver.cpp:105] Iteration 32500, lr = 0.01
I0617 14:22:29.316192  4950 solver.cpp:218] Iteration 32550 (0.852341 iter/s, 58.662s/50 iters), loss = 0.00848605
I0617 14:22:29.316331  4950 solver.cpp:237]     Train net output #0: loss = 0.00848606 (* 1 = 0.00848606 loss)
I0617 14:22:29.316356  4950 sgd_solver.cpp:105] Iteration 32550, lr = 0.01
I0617 14:23:27.981942  4950 solver.cpp:218] Iteration 32600 (0.852298 iter/s, 58.6649s/50 iters), loss = 0.0101074
I0617 14:23:27.982141  4950 solver.cpp:237]     Train net output #0: loss = 0.0101074 (* 1 = 0.0101074 loss)
I0617 14:23:27.982165  4950 sgd_solver.cpp:105] Iteration 32600, lr = 0.01
I0617 14:23:31.561671  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 14:24:26.640425  4950 solver.cpp:218] Iteration 32650 (0.852405 iter/s, 58.6576s/50 iters), loss = 0.00903422
I0617 14:24:26.640580  4950 solver.cpp:237]     Train net output #0: loss = 0.00903423 (* 1 = 0.00903423 loss)
I0617 14:24:26.640604  4950 sgd_solver.cpp:105] Iteration 32650, lr = 0.01
I0617 14:25:25.301690  4950 solver.cpp:218] Iteration 32700 (0.852363 iter/s, 58.6604s/50 iters), loss = 0.010563
I0617 14:25:25.301820  4950 solver.cpp:237]     Train net output #0: loss = 0.0105631 (* 1 = 0.0105631 loss)
I0617 14:25:25.301843  4950 sgd_solver.cpp:105] Iteration 32700, lr = 0.01
I0617 14:25:52.345072  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 14:26:23.962613  4950 solver.cpp:218] Iteration 32750 (0.852368 iter/s, 58.6601s/50 iters), loss = 0.00848619
I0617 14:26:23.962715  4950 solver.cpp:237]     Train net output #0: loss = 0.0084862 (* 1 = 0.0084862 loss)
I0617 14:26:23.962739  4950 sgd_solver.cpp:105] Iteration 32750, lr = 0.01
I0617 14:27:22.623939  4950 solver.cpp:218] Iteration 32800 (0.852362 iter/s, 58.6605s/50 iters), loss = 0.00834866
I0617 14:27:22.624076  4950 solver.cpp:237]     Train net output #0: loss = 0.00834866 (* 1 = 0.00834866 loss)
I0617 14:27:22.624100  4950 sgd_solver.cpp:105] Iteration 32800, lr = 0.01
I0617 14:28:13.156474  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 14:28:21.295825  4950 solver.cpp:218] Iteration 32850 (0.852209 iter/s, 58.671s/50 iters), loss = 0.00888987
I0617 14:28:21.295922  4950 solver.cpp:237]     Train net output #0: loss = 0.00888988 (* 1 = 0.00888988 loss)
I0617 14:28:21.295949  4950 sgd_solver.cpp:105] Iteration 32850, lr = 0.01
I0617 14:29:19.977716  4950 solver.cpp:218] Iteration 32900 (0.852063 iter/s, 58.6811s/50 iters), loss = 0.00990577
I0617 14:29:19.977859  4950 solver.cpp:237]     Train net output #0: loss = 0.00990577 (* 1 = 0.00990577 loss)
I0617 14:29:19.977885  4950 sgd_solver.cpp:105] Iteration 32900, lr = 0.01
I0617 14:30:18.637737  4950 solver.cpp:218] Iteration 32950 (0.852382 iter/s, 58.6592s/50 iters), loss = 0.0122761
I0617 14:30:18.637873  4950 solver.cpp:237]     Train net output #0: loss = 0.0122762 (* 1 = 0.0122762 loss)
I0617 14:30:18.637897  4950 sgd_solver.cpp:105] Iteration 32950, lr = 0.01
I0617 14:30:32.821787  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 14:31:17.303304  4950 solver.cpp:218] Iteration 33000 (0.852301 iter/s, 58.6647s/50 iters), loss = 0.00934559
I0617 14:31:17.303454  4950 solver.cpp:237]     Train net output #0: loss = 0.0093456 (* 1 = 0.0093456 loss)
I0617 14:31:17.303478  4950 sgd_solver.cpp:105] Iteration 33000, lr = 0.01
I0617 14:32:15.976850  4950 solver.cpp:218] Iteration 33050 (0.852185 iter/s, 58.6727s/50 iters), loss = 0.00884856
I0617 14:32:15.977017  4950 solver.cpp:237]     Train net output #0: loss = 0.00884857 (* 1 = 0.00884857 loss)
I0617 14:32:15.977051  4950 sgd_solver.cpp:105] Iteration 33050, lr = 0.01
I0617 14:32:53.625809  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 14:33:14.640632  4950 solver.cpp:218] Iteration 33100 (0.852327 iter/s, 58.6629s/50 iters), loss = 0.0105395
I0617 14:33:14.640734  4950 solver.cpp:237]     Train net output #0: loss = 0.0105395 (* 1 = 0.0105395 loss)
I0617 14:33:14.640758  4950 sgd_solver.cpp:105] Iteration 33100, lr = 0.01
I0617 14:34:13.290969  4950 solver.cpp:218] Iteration 33150 (0.852522 iter/s, 58.6495s/50 iters), loss = 0.0117128
I0617 14:34:13.291111  4950 solver.cpp:237]     Train net output #0: loss = 0.0117128 (* 1 = 0.0117128 loss)
I0617 14:34:13.291137  4950 sgd_solver.cpp:105] Iteration 33150, lr = 0.01
I0617 14:35:11.963112  4950 solver.cpp:218] Iteration 33200 (0.852206 iter/s, 58.6712s/50 iters), loss = 0.00986164
I0617 14:35:11.963322  4950 solver.cpp:237]     Train net output #0: loss = 0.00986165 (* 1 = 0.00986165 loss)
I0617 14:35:11.963348  4950 sgd_solver.cpp:105] Iteration 33200, lr = 0.01
I0617 14:35:14.380753  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 14:36:10.626143  4950 solver.cpp:218] Iteration 33250 (0.85234 iter/s, 58.6621s/50 iters), loss = 0.0106555
I0617 14:36:10.626279  4950 solver.cpp:237]     Train net output #0: loss = 0.0106555 (* 1 = 0.0106555 loss)
I0617 14:36:10.626302  4950 sgd_solver.cpp:105] Iteration 33250, lr = 0.01
I0617 14:37:09.297257  4950 solver.cpp:218] Iteration 33300 (0.852221 iter/s, 58.6702s/50 iters), loss = 0.0103518
I0617 14:37:09.297418  4950 solver.cpp:237]     Train net output #0: loss = 0.0103518 (* 1 = 0.0103518 loss)
I0617 14:37:09.297443  4950 sgd_solver.cpp:105] Iteration 33300, lr = 0.01
I0617 14:37:35.198720  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 14:38:07.950702  4950 solver.cpp:218] Iteration 33350 (0.852478 iter/s, 58.6525s/50 iters), loss = 0.0082406
I0617 14:38:07.951205  4950 solver.cpp:237]     Train net output #0: loss = 0.0082406 (* 1 = 0.0082406 loss)
I0617 14:38:07.951233  4950 sgd_solver.cpp:105] Iteration 33350, lr = 0.01
I0617 14:39:06.624673  4950 solver.cpp:218] Iteration 33400 (0.852185 iter/s, 58.6727s/50 iters), loss = 0.0111299
I0617 14:39:06.624817  4950 solver.cpp:237]     Train net output #0: loss = 0.0111299 (* 1 = 0.0111299 loss)
I0617 14:39:06.624842  4950 sgd_solver.cpp:105] Iteration 33400, lr = 0.01
I0617 14:39:55.989506  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 14:40:05.289150  4950 solver.cpp:218] Iteration 33450 (0.852318 iter/s, 58.6636s/50 iters), loss = 0.0115409
I0617 14:40:05.289255  4950 solver.cpp:237]     Train net output #0: loss = 0.0115409 (* 1 = 0.0115409 loss)
I0617 14:40:05.289278  4950 sgd_solver.cpp:105] Iteration 33450, lr = 0.01
I0617 14:41:03.967736  4950 solver.cpp:218] Iteration 33500 (0.852112 iter/s, 58.6777s/50 iters), loss = 0.00969681
I0617 14:41:03.967890  4950 solver.cpp:237]     Train net output #0: loss = 0.00969682 (* 1 = 0.00969682 loss)
I0617 14:41:03.967916  4950 sgd_solver.cpp:105] Iteration 33500, lr = 0.01
I0617 14:42:02.639430  4950 solver.cpp:218] Iteration 33550 (0.852213 iter/s, 58.6708s/50 iters), loss = 0.0121547
I0617 14:42:02.639605  4950 solver.cpp:237]     Train net output #0: loss = 0.0121548 (* 1 = 0.0121548 loss)
I0617 14:42:02.639632  4950 sgd_solver.cpp:105] Iteration 33550, lr = 0.01
I0617 14:42:16.800590  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 14:43:01.305932  4950 solver.cpp:218] Iteration 33600 (0.852289 iter/s, 58.6656s/50 iters), loss = 0.0113754
I0617 14:43:01.306172  4950 solver.cpp:237]     Train net output #0: loss = 0.0113754 (* 1 = 0.0113754 loss)
I0617 14:43:01.306196  4950 sgd_solver.cpp:105] Iteration 33600, lr = 0.01
I0617 14:43:59.975612  4950 solver.cpp:218] Iteration 33650 (0.852243 iter/s, 58.6687s/50 iters), loss = 0.00833531
I0617 14:43:59.975766  4950 solver.cpp:237]     Train net output #0: loss = 0.00833532 (* 1 = 0.00833532 loss)
I0617 14:43:59.975790  4950 sgd_solver.cpp:105] Iteration 33650, lr = 0.01
I0617 14:44:37.581434  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 14:44:58.645712  4950 solver.cpp:218] Iteration 33700 (0.852236 iter/s, 58.6692s/50 iters), loss = 0.00955438
I0617 14:44:58.645809  4950 solver.cpp:237]     Train net output #0: loss = 0.00955439 (* 1 = 0.00955439 loss)
I0617 14:44:58.645833  4950 sgd_solver.cpp:105] Iteration 33700, lr = 0.01
I0617 14:45:57.314993  4950 solver.cpp:218] Iteration 33750 (0.852247 iter/s, 58.6684s/50 iters), loss = 0.010788
I0617 14:45:57.315156  4950 solver.cpp:237]     Train net output #0: loss = 0.010788 (* 1 = 0.010788 loss)
I0617 14:45:57.315181  4950 sgd_solver.cpp:105] Iteration 33750, lr = 0.01
I0617 14:46:55.986079  4950 solver.cpp:218] Iteration 33800 (0.852222 iter/s, 58.6702s/50 iters), loss = 0.0101929
I0617 14:46:55.986219  4950 solver.cpp:237]     Train net output #0: loss = 0.0101929 (* 1 = 0.0101929 loss)
I0617 14:46:55.986248  4950 sgd_solver.cpp:105] Iteration 33800, lr = 0.01
I0617 14:46:58.408272  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 14:47:54.646605  4950 solver.cpp:218] Iteration 33850 (0.852375 iter/s, 58.6596s/50 iters), loss = 0.0106938
I0617 14:47:54.646841  4950 solver.cpp:237]     Train net output #0: loss = 0.0106938 (* 1 = 0.0106938 loss)
I0617 14:47:54.646864  4950 sgd_solver.cpp:105] Iteration 33850, lr = 0.01
I0617 14:48:53.319820  4950 solver.cpp:218] Iteration 33900 (0.852192 iter/s, 58.6722s/50 iters), loss = 0.00846562
I0617 14:48:53.319973  4950 solver.cpp:237]     Train net output #0: loss = 0.00846563 (* 1 = 0.00846563 loss)
I0617 14:48:53.319996  4950 sgd_solver.cpp:105] Iteration 33900, lr = 0.01
I0617 14:49:19.201547  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 14:49:51.987807  4950 solver.cpp:218] Iteration 33950 (0.852267 iter/s, 58.6671s/50 iters), loss = 0.930791
I0617 14:49:51.987948  4950 solver.cpp:237]     Train net output #0: loss = 0.930791 (* 1 = 0.930791 loss)
I0617 14:49:51.987972  4950 sgd_solver.cpp:105] Iteration 33950, lr = 0.01
I0617 14:50:50.655266  4950 solver.cpp:218] Iteration 34000 (0.852274 iter/s, 58.6666s/50 iters), loss = 2.94451
I0617 14:50:50.655396  4950 solver.cpp:237]     Train net output #0: loss = 2.94451 (* 1 = 2.94451 loss)
I0617 14:50:50.655421  4950 sgd_solver.cpp:105] Iteration 34000, lr = 0.01
I0617 14:51:38.843688  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 14:51:49.328171  4950 solver.cpp:218] Iteration 34050 (0.852195 iter/s, 58.672s/50 iters), loss = 1.78056
I0617 14:51:49.328263  4950 solver.cpp:237]     Train net output #0: loss = 1.78056 (* 1 = 1.78056 loss)
I0617 14:51:49.328284  4950 sgd_solver.cpp:105] Iteration 34050, lr = 0.01
I0617 14:52:48.001579  4950 solver.cpp:218] Iteration 34100 (0.852193 iter/s, 58.6721s/50 iters), loss = 1.4045
I0617 14:52:48.001734  4950 solver.cpp:237]     Train net output #0: loss = 1.4045 (* 1 = 1.4045 loss)
I0617 14:52:48.001758  4950 sgd_solver.cpp:105] Iteration 34100, lr = 0.01
I0617 14:53:46.689026  4950 solver.cpp:218] Iteration 34150 (0.851984 iter/s, 58.6865s/50 iters), loss = 1.47346
I0617 14:53:46.689160  4950 solver.cpp:237]     Train net output #0: loss = 1.47346 (* 1 = 1.47346 loss)
I0617 14:53:46.689189  4950 sgd_solver.cpp:105] Iteration 34150, lr = 0.01
I0617 14:53:59.695231  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 14:54:45.359081  4950 solver.cpp:218] Iteration 34200 (0.852236 iter/s, 58.6692s/50 iters), loss = 1.13635
I0617 14:54:45.359218  4950 solver.cpp:237]     Train net output #0: loss = 1.13635 (* 1 = 1.13635 loss)
I0617 14:54:45.359243  4950 sgd_solver.cpp:105] Iteration 34200, lr = 0.01
I0617 14:55:44.027765  4950 solver.cpp:218] Iteration 34250 (0.852256 iter/s, 58.6678s/50 iters), loss = 0.99231
I0617 14:55:44.027890  4950 solver.cpp:237]     Train net output #0: loss = 0.99231 (* 1 = 0.99231 loss)
I0617 14:55:44.027914  4950 sgd_solver.cpp:105] Iteration 34250, lr = 0.01
I0617 14:56:20.497308  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 14:56:42.693254  4950 solver.cpp:218] Iteration 34300 (0.852302 iter/s, 58.6646s/50 iters), loss = 0.818779
I0617 14:56:42.693343  4950 solver.cpp:237]     Train net output #0: loss = 0.818779 (* 1 = 0.818779 loss)
I0617 14:56:42.693366  4950 sgd_solver.cpp:105] Iteration 34300, lr = 0.01
I0617 14:57:41.324154  4950 solver.cpp:218] Iteration 34350 (0.852805 iter/s, 58.63s/50 iters), loss = 0.895954
I0617 14:57:41.324317  4950 solver.cpp:237]     Train net output #0: loss = 0.895954 (* 1 = 0.895954 loss)
I0617 14:57:41.324342  4950 sgd_solver.cpp:105] Iteration 34350, lr = 0.01
I0617 14:58:39.963924  4950 solver.cpp:218] Iteration 34400 (0.852676 iter/s, 58.6389s/50 iters), loss = 0.587031
I0617 14:58:39.964275  4950 solver.cpp:237]     Train net output #0: loss = 0.587031 (* 1 = 0.587031 loss)
I0617 14:58:39.964304  4950 sgd_solver.cpp:105] Iteration 34400, lr = 0.01
I0617 14:58:41.205441  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 14:59:38.596137  4950 solver.cpp:218] Iteration 34450 (0.852789 iter/s, 58.6311s/50 iters), loss = 0.747955
I0617 14:59:38.596316  4950 solver.cpp:237]     Train net output #0: loss = 0.747955 (* 1 = 0.747955 loss)
I0617 14:59:38.596338  4950 sgd_solver.cpp:105] Iteration 34450, lr = 0.01
I0617 15:00:37.223913  4950 solver.cpp:218] Iteration 34500 (0.852851 iter/s, 58.6269s/50 iters), loss = 0.764471
I0617 15:00:37.224054  4950 solver.cpp:237]     Train net output #0: loss = 0.764471 (* 1 = 0.764471 loss)
I0617 15:00:37.224078  4950 sgd_solver.cpp:105] Iteration 34500, lr = 0.01
I0617 15:01:01.908643  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 15:01:35.857440  4950 solver.cpp:218] Iteration 34550 (0.852767 iter/s, 58.6326s/50 iters), loss = 0.488667
I0617 15:01:35.857543  4950 solver.cpp:237]     Train net output #0: loss = 0.488667 (* 1 = 0.488667 loss)
I0617 15:01:35.857571  4950 sgd_solver.cpp:105] Iteration 34550, lr = 0.01
I0617 15:02:34.493043  4950 solver.cpp:218] Iteration 34600 (0.852736 iter/s, 58.6348s/50 iters), loss = 0.490425
I0617 15:02:34.493175  4950 solver.cpp:237]     Train net output #0: loss = 0.490425 (* 1 = 0.490425 loss)
I0617 15:02:34.493198  4950 sgd_solver.cpp:105] Iteration 34600, lr = 0.01
I0617 15:03:22.658077  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 15:03:33.128974  4950 solver.cpp:218] Iteration 34650 (0.852732 iter/s, 58.6351s/50 iters), loss = 0.514182
I0617 15:03:33.129061  4950 solver.cpp:237]     Train net output #0: loss = 0.514182 (* 1 = 0.514182 loss)
I0617 15:03:33.129082  4950 sgd_solver.cpp:105] Iteration 34650, lr = 0.01
I0617 15:04:31.759352  4950 solver.cpp:218] Iteration 34700 (0.852812 iter/s, 58.6296s/50 iters), loss = 0.443693
I0617 15:04:31.759485  4950 solver.cpp:237]     Train net output #0: loss = 0.443693 (* 1 = 0.443693 loss)
I0617 15:04:31.759521  4950 sgd_solver.cpp:105] Iteration 34700, lr = 0.01
I0617 15:05:30.407570  4950 solver.cpp:218] Iteration 34750 (0.852553 iter/s, 58.6474s/50 iters), loss = 0.468291
I0617 15:05:30.407752  4950 solver.cpp:237]     Train net output #0: loss = 0.468291 (* 1 = 0.468291 loss)
I0617 15:05:30.407773  4950 sgd_solver.cpp:105] Iteration 34750, lr = 0.01
I0617 15:05:43.366953  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 15:06:29.051426  4950 solver.cpp:218] Iteration 34800 (0.852618 iter/s, 58.6429s/50 iters), loss = 0.322078
I0617 15:06:29.051566  4950 solver.cpp:237]     Train net output #0: loss = 0.322078 (* 1 = 0.322078 loss)
I0617 15:06:29.051595  4950 sgd_solver.cpp:105] Iteration 34800, lr = 0.01
I0617 15:07:27.694265  4950 solver.cpp:218] Iteration 34850 (0.852631 iter/s, 58.642s/50 iters), loss = 0.232269
I0617 15:07:27.694396  4950 solver.cpp:237]     Train net output #0: loss = 0.232269 (* 1 = 0.232269 loss)
I0617 15:07:27.694416  4950 sgd_solver.cpp:105] Iteration 34850, lr = 0.01
I0617 15:08:04.119879  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 15:08:26.326791  4950 solver.cpp:218] Iteration 34900 (0.852781 iter/s, 58.6317s/50 iters), loss = 0.336888
I0617 15:08:26.326874  4950 solver.cpp:237]     Train net output #0: loss = 0.336888 (* 1 = 0.336888 loss)
I0617 15:08:26.326896  4950 sgd_solver.cpp:105] Iteration 34900, lr = 0.01
I0617 15:09:24.970340  4950 solver.cpp:218] Iteration 34950 (0.85262 iter/s, 58.6428s/50 iters), loss = 0.211937
I0617 15:09:24.970463  4950 solver.cpp:237]     Train net output #0: loss = 0.211937 (* 1 = 0.211937 loss)
I0617 15:09:24.970484  4950 sgd_solver.cpp:105] Iteration 34950, lr = 0.01
I0617 15:10:23.603632  4950 solver.cpp:218] Iteration 35000 (0.852769 iter/s, 58.6325s/50 iters), loss = 0.20896
I0617 15:10:23.603780  4950 solver.cpp:237]     Train net output #0: loss = 0.20896 (* 1 = 0.20896 loss)
I0617 15:10:23.603803  4950 sgd_solver.cpp:105] Iteration 35000, lr = 0.01
I0617 15:10:23.684341  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 15:11:22.294623  4950 solver.cpp:218] Iteration 35050 (0.851932 iter/s, 58.6901s/50 iters), loss = 0.217851
I0617 15:11:22.294857  4950 solver.cpp:237]     Train net output #0: loss = 0.217851 (* 1 = 0.217851 loss)
I0617 15:11:22.294881  4950 sgd_solver.cpp:105] Iteration 35050, lr = 0.01
I0617 15:12:20.966153  4950 solver.cpp:218] Iteration 35100 (0.852215 iter/s, 58.6706s/50 iters), loss = 0.144083
I0617 15:12:20.966300  4950 solver.cpp:237]     Train net output #0: loss = 0.144083 (* 1 = 0.144083 loss)
I0617 15:12:20.966322  4950 sgd_solver.cpp:105] Iteration 35100, lr = 0.01
I0617 15:12:44.534772  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 15:13:19.665568  4950 solver.cpp:218] Iteration 35150 (0.85181 iter/s, 58.6985s/50 iters), loss = 0.10495
I0617 15:13:19.665771  4950 solver.cpp:237]     Train net output #0: loss = 0.10495 (* 1 = 0.10495 loss)
I0617 15:13:19.665799  4950 sgd_solver.cpp:105] Iteration 35150, lr = 0.01
I0617 15:14:18.383867  4950 solver.cpp:218] Iteration 35200 (0.851537 iter/s, 58.7174s/50 iters), loss = 0.15983
I0617 15:14:18.384059  4950 solver.cpp:237]     Train net output #0: loss = 0.15983 (* 1 = 0.15983 loss)
I0617 15:14:18.384093  4950 sgd_solver.cpp:105] Iteration 35200, lr = 0.01
I0617 15:15:05.443753  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 15:15:17.096308  4950 solver.cpp:218] Iteration 35250 (0.851621 iter/s, 58.7115s/50 iters), loss = 0.130193
I0617 15:15:17.096441  4950 solver.cpp:237]     Train net output #0: loss = 0.130193 (* 1 = 0.130193 loss)
I0617 15:15:17.096463  4950 sgd_solver.cpp:105] Iteration 35250, lr = 0.01
I0617 15:16:15.812363  4950 solver.cpp:218] Iteration 35300 (0.851568 iter/s, 58.7152s/50 iters), loss = 0.140239
I0617 15:16:15.812571  4950 solver.cpp:237]     Train net output #0: loss = 0.140239 (* 1 = 0.140239 loss)
I0617 15:16:15.812607  4950 sgd_solver.cpp:105] Iteration 35300, lr = 0.01
I0617 15:17:14.528684  4950 solver.cpp:218] Iteration 35350 (0.851565 iter/s, 58.7154s/50 iters), loss = 0.0687483
I0617 15:17:14.528889  4950 solver.cpp:237]     Train net output #0: loss = 0.0687483 (* 1 = 0.0687483 loss)
I0617 15:17:14.528915  4950 sgd_solver.cpp:105] Iteration 35350, lr = 0.01
I0617 15:17:26.330569  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 15:18:13.242352  4950 solver.cpp:218] Iteration 35400 (0.851604 iter/s, 58.7128s/50 iters), loss = 0.0655246
I0617 15:18:13.242488  4950 solver.cpp:237]     Train net output #0: loss = 0.0655246 (* 1 = 0.0655246 loss)
I0617 15:18:13.242522  4950 sgd_solver.cpp:105] Iteration 35400, lr = 0.01
I0617 15:19:11.910537  4950 solver.cpp:218] Iteration 35450 (0.852263 iter/s, 58.6674s/50 iters), loss = 0.060733
I0617 15:19:11.910670  4950 solver.cpp:237]     Train net output #0: loss = 0.060733 (* 1 = 0.060733 loss)
I0617 15:19:11.910693  4950 sgd_solver.cpp:105] Iteration 35450, lr = 0.01
I0617 15:19:47.164736  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 15:20:10.568681  4950 solver.cpp:218] Iteration 35500 (0.852408 iter/s, 58.6573s/50 iters), loss = 0.0513249
I0617 15:20:10.568774  4950 solver.cpp:237]     Train net output #0: loss = 0.0513249 (* 1 = 0.0513249 loss)
I0617 15:20:10.568795  4950 sgd_solver.cpp:105] Iteration 35500, lr = 0.01
I0617 15:21:09.229744  4950 solver.cpp:218] Iteration 35550 (0.852365 iter/s, 58.6603s/50 iters), loss = 0.0326853
I0617 15:21:09.229869  4950 solver.cpp:237]     Train net output #0: loss = 0.0326853 (* 1 = 0.0326853 loss)
I0617 15:21:09.229893  4950 sgd_solver.cpp:105] Iteration 35550, lr = 0.01
I0617 15:22:07.896114  4950 solver.cpp:218] Iteration 35600 (0.852289 iter/s, 58.6656s/50 iters), loss = 0.0219616
I0617 15:22:07.896257  4950 solver.cpp:237]     Train net output #0: loss = 0.0219616 (* 1 = 0.0219616 loss)
I0617 15:22:07.896281  4950 sgd_solver.cpp:105] Iteration 35600, lr = 0.01
I0617 15:22:07.978180  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 15:23:06.554949  4950 solver.cpp:218] Iteration 35650 (0.852399 iter/s, 58.658s/50 iters), loss = 0.0765918
I0617 15:23:06.555176  4950 solver.cpp:237]     Train net output #0: loss = 0.0765918 (* 1 = 0.0765918 loss)
I0617 15:23:06.555200  4950 sgd_solver.cpp:105] Iteration 35650, lr = 0.01
I0617 15:24:05.217360  4950 solver.cpp:218] Iteration 35700 (0.852348 iter/s, 58.6615s/50 iters), loss = 0.0493322
I0617 15:24:05.217522  4950 solver.cpp:237]     Train net output #0: loss = 0.0493322 (* 1 = 0.0493322 loss)
I0617 15:24:05.217550  4950 sgd_solver.cpp:105] Iteration 35700, lr = 0.01
I0617 15:24:28.762459  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 15:25:03.878149  4950 solver.cpp:218] Iteration 35750 (0.85237 iter/s, 58.66s/50 iters), loss = 0.0317689
I0617 15:25:03.878293  4950 solver.cpp:237]     Train net output #0: loss = 0.0317689 (* 1 = 0.0317689 loss)
I0617 15:25:03.878319  4950 sgd_solver.cpp:105] Iteration 35750, lr = 0.01
I0617 15:26:02.546907  4950 solver.cpp:218] Iteration 35800 (0.852254 iter/s, 58.6679s/50 iters), loss = 0.045037
I0617 15:26:02.547057  4950 solver.cpp:237]     Train net output #0: loss = 0.045037 (* 1 = 0.045037 loss)
I0617 15:26:02.547082  4950 sgd_solver.cpp:105] Iteration 35800, lr = 0.01
I0617 15:26:49.533001  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 15:27:01.198457  4950 solver.cpp:218] Iteration 35850 (0.852505 iter/s, 58.6507s/50 iters), loss = 0.0313052
I0617 15:27:01.198565  4950 solver.cpp:237]     Train net output #0: loss = 0.0313052 (* 1 = 0.0313052 loss)
I0617 15:27:01.198588  4950 sgd_solver.cpp:105] Iteration 35850, lr = 0.01
I0617 15:27:59.856976  4950 solver.cpp:218] Iteration 35900 (0.852403 iter/s, 58.6577s/50 iters), loss = 0.0346874
I0617 15:27:59.857105  4950 solver.cpp:237]     Train net output #0: loss = 0.0346874 (* 1 = 0.0346874 loss)
I0617 15:27:59.857127  4950 sgd_solver.cpp:105] Iteration 35900, lr = 0.01
I0617 15:28:58.518400  4950 solver.cpp:218] Iteration 35950 (0.852361 iter/s, 58.6606s/50 iters), loss = 0.0213943
I0617 15:28:58.518563  4950 solver.cpp:237]     Train net output #0: loss = 0.0213943 (* 1 = 0.0213943 loss)
I0617 15:28:58.518594  4950 sgd_solver.cpp:105] Iteration 35950, lr = 0.01
I0617 15:29:09.189471  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 15:29:57.189918  4950 solver.cpp:218] Iteration 36000 (0.852215 iter/s, 58.6707s/50 iters), loss = 0.0219408
I0617 15:29:57.190125  4950 solver.cpp:237]     Train net output #0: loss = 0.0219408 (* 1 = 0.0219408 loss)
I0617 15:29:57.190150  4950 sgd_solver.cpp:105] Iteration 36000, lr = 0.01
I0617 15:30:55.873250  4950 solver.cpp:218] Iteration 36050 (0.852044 iter/s, 58.6824s/50 iters), loss = 0.0129271
I0617 15:30:55.873381  4950 solver.cpp:237]     Train net output #0: loss = 0.012927 (* 1 = 0.012927 loss)
I0617 15:30:55.873404  4950 sgd_solver.cpp:105] Iteration 36050, lr = 0.01
I0617 15:31:29.988951  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 15:31:54.524866  4950 solver.cpp:218] Iteration 36100 (0.852503 iter/s, 58.6508s/50 iters), loss = 0.00838033
I0617 15:31:54.524958  4950 solver.cpp:237]     Train net output #0: loss = 0.0083803 (* 1 = 0.0083803 loss)
I0617 15:31:54.524982  4950 sgd_solver.cpp:105] Iteration 36100, lr = 0.01
I0617 15:32:53.178858  4950 solver.cpp:218] Iteration 36150 (0.852468 iter/s, 58.6532s/50 iters), loss = 0.0193402
I0617 15:32:53.178997  4950 solver.cpp:237]     Train net output #0: loss = 0.0193402 (* 1 = 0.0193402 loss)
I0617 15:32:53.179020  4950 sgd_solver.cpp:105] Iteration 36150, lr = 0.01
I0617 15:33:50.765944  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 15:33:51.840395  4950 solver.cpp:218] Iteration 36200 (0.85236 iter/s, 58.6607s/50 iters), loss = 0.0173964
I0617 15:33:51.840497  4950 solver.cpp:237]     Train net output #0: loss = 0.0173964 (* 1 = 0.0173964 loss)
I0617 15:33:51.840530  4950 sgd_solver.cpp:105] Iteration 36200, lr = 0.01
I0617 15:34:50.514827  4950 solver.cpp:218] Iteration 36250 (0.852171 iter/s, 58.6736s/50 iters), loss = 0.00775498
I0617 15:34:50.514981  4950 solver.cpp:237]     Train net output #0: loss = 0.00775495 (* 1 = 0.00775495 loss)
I0617 15:34:50.515003  4950 sgd_solver.cpp:105] Iteration 36250, lr = 0.01
I0617 15:35:49.177708  4950 solver.cpp:218] Iteration 36300 (0.85234 iter/s, 58.662s/50 iters), loss = 0.00954929
I0617 15:35:49.177886  4950 solver.cpp:237]     Train net output #0: loss = 0.00954926 (* 1 = 0.00954926 loss)
I0617 15:35:49.177909  4950 sgd_solver.cpp:105] Iteration 36300, lr = 0.01
I0617 15:36:11.559028  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 15:36:47.833629  4950 solver.cpp:218] Iteration 36350 (0.852441 iter/s, 58.6551s/50 iters), loss = 0.00833629
I0617 15:36:47.833786  4950 solver.cpp:237]     Train net output #0: loss = 0.00833626 (* 1 = 0.00833626 loss)
I0617 15:36:47.833811  4950 sgd_solver.cpp:105] Iteration 36350, lr = 0.01
I0617 15:37:46.497251  4950 solver.cpp:218] Iteration 36400 (0.852329 iter/s, 58.6628s/50 iters), loss = 0.0103044
I0617 15:37:46.497378  4950 solver.cpp:237]     Train net output #0: loss = 0.0103044 (* 1 = 0.0103044 loss)
I0617 15:37:46.497402  4950 sgd_solver.cpp:105] Iteration 36400, lr = 0.01
I0617 15:38:32.325620  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 15:38:45.176401  4950 solver.cpp:218] Iteration 36450 (0.852104 iter/s, 58.6783s/50 iters), loss = 0.00671256
I0617 15:38:45.176529  4950 solver.cpp:237]     Train net output #0: loss = 0.00671253 (* 1 = 0.00671253 loss)
I0617 15:38:45.176554  4950 sgd_solver.cpp:105] Iteration 36450, lr = 0.01
I0617 15:39:43.892328  4950 solver.cpp:218] Iteration 36500 (0.85157 iter/s, 58.7151s/50 iters), loss = 0.00704347
I0617 15:39:43.892499  4950 solver.cpp:237]     Train net output #0: loss = 0.00704344 (* 1 = 0.00704344 loss)
I0617 15:39:43.892530  4950 sgd_solver.cpp:105] Iteration 36500, lr = 0.01
I0617 15:40:42.606307  4950 solver.cpp:218] Iteration 36550 (0.851599 iter/s, 58.7131s/50 iters), loss = 0.00678935
I0617 15:40:42.606494  4950 solver.cpp:237]     Train net output #0: loss = 0.00678932 (* 1 = 0.00678932 loss)
I0617 15:40:42.606549  4950 sgd_solver.cpp:105] Iteration 36550, lr = 0.01
I0617 15:40:53.234452  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 15:41:41.325968  4950 solver.cpp:218] Iteration 36600 (0.851516 iter/s, 58.7188s/50 iters), loss = 0.00516159
I0617 15:41:41.326146  4950 solver.cpp:237]     Train net output #0: loss = 0.00516156 (* 1 = 0.00516156 loss)
I0617 15:41:41.326171  4950 sgd_solver.cpp:105] Iteration 36600, lr = 0.01
I0617 15:42:40.041026  4950 solver.cpp:218] Iteration 36650 (0.851583 iter/s, 58.7142s/50 iters), loss = 0.00701077
I0617 15:42:40.041194  4950 solver.cpp:237]     Train net output #0: loss = 0.00701074 (* 1 = 0.00701074 loss)
I0617 15:42:40.041218  4950 sgd_solver.cpp:105] Iteration 36650, lr = 0.01
I0617 15:43:14.159214  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 15:43:38.765862  4950 solver.cpp:218] Iteration 36700 (0.851441 iter/s, 58.724s/50 iters), loss = 0.0197453
I0617 15:43:38.765988  4950 solver.cpp:237]     Train net output #0: loss = 0.0197453 (* 1 = 0.0197453 loss)
I0617 15:43:38.766011  4950 sgd_solver.cpp:105] Iteration 36700, lr = 0.01
I0617 15:44:37.478791  4950 solver.cpp:218] Iteration 36750 (0.851613 iter/s, 58.7121s/50 iters), loss = 0.00679709
I0617 15:44:37.478983  4950 solver.cpp:237]     Train net output #0: loss = 0.00679706 (* 1 = 0.00679706 loss)
I0617 15:44:37.479009  4950 sgd_solver.cpp:105] Iteration 36750, lr = 0.01
I0617 15:45:35.061095  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 15:45:36.195085  4950 solver.cpp:218] Iteration 36800 (0.851565 iter/s, 58.7154s/50 iters), loss = 0.0163433
I0617 15:45:36.195215  4950 solver.cpp:237]     Train net output #0: loss = 0.0163432 (* 1 = 0.0163432 loss)
I0617 15:45:36.195238  4950 sgd_solver.cpp:105] Iteration 36800, lr = 0.01
I0617 15:46:34.910737  4950 solver.cpp:218] Iteration 36850 (0.851573 iter/s, 58.7149s/50 iters), loss = 0.00872662
I0617 15:46:34.910876  4950 solver.cpp:237]     Train net output #0: loss = 0.00872659 (* 1 = 0.00872659 loss)
I0617 15:46:34.910898  4950 sgd_solver.cpp:105] Iteration 36850, lr = 0.01
I0617 15:47:33.629326  4950 solver.cpp:218] Iteration 36900 (0.851531 iter/s, 58.7178s/50 iters), loss = 0.0119868
I0617 15:47:33.629568  4950 solver.cpp:237]     Train net output #0: loss = 0.0119867 (* 1 = 0.0119867 loss)
I0617 15:47:33.629597  4950 sgd_solver.cpp:105] Iteration 36900, lr = 0.01
I0617 15:47:55.982878  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 15:48:32.325006  4950 solver.cpp:218] Iteration 36950 (0.851865 iter/s, 58.6948s/50 iters), loss = 0.0067738
I0617 15:48:32.325150  4950 solver.cpp:237]     Train net output #0: loss = 0.00677377 (* 1 = 0.00677377 loss)
I0617 15:48:32.325178  4950 sgd_solver.cpp:105] Iteration 36950, lr = 0.01
I0617 15:49:30.973232  4950 solver.cpp:218] Iteration 37000 (0.852552 iter/s, 58.6474s/50 iters), loss = 0.00625271
I0617 15:49:30.973377  4950 solver.cpp:237]     Train net output #0: loss = 0.00625268 (* 1 = 0.00625268 loss)
I0617 15:49:30.973407  4950 sgd_solver.cpp:105] Iteration 37000, lr = 0.01
I0617 15:50:15.653040  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 15:50:29.631709  4950 solver.cpp:218] Iteration 37050 (0.852403 iter/s, 58.6577s/50 iters), loss = 0.00486419
I0617 15:50:29.631804  4950 solver.cpp:237]     Train net output #0: loss = 0.00486416 (* 1 = 0.00486416 loss)
I0617 15:50:29.631825  4950 sgd_solver.cpp:105] Iteration 37050, lr = 0.01
I0617 15:51:28.288136  4950 solver.cpp:218] Iteration 37100 (0.852433 iter/s, 58.6557s/50 iters), loss = 0.00677735
I0617 15:51:28.288285  4950 solver.cpp:237]     Train net output #0: loss = 0.00677732 (* 1 = 0.00677732 loss)
I0617 15:51:28.288307  4950 sgd_solver.cpp:105] Iteration 37100, lr = 0.01
I0617 15:52:26.951961  4950 solver.cpp:218] Iteration 37150 (0.852326 iter/s, 58.663s/50 iters), loss = 0.00429891
I0617 15:52:26.952116  4950 solver.cpp:237]     Train net output #0: loss = 0.00429888 (* 1 = 0.00429888 loss)
I0617 15:52:26.952154  4950 sgd_solver.cpp:105] Iteration 37150, lr = 0.01
I0617 15:52:36.409538  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 15:53:25.623497  4950 solver.cpp:218] Iteration 37200 (0.852214 iter/s, 58.6707s/50 iters), loss = 0.00629522
I0617 15:53:25.623641  4950 solver.cpp:237]     Train net output #0: loss = 0.00629519 (* 1 = 0.00629519 loss)
I0617 15:53:25.623667  4950 sgd_solver.cpp:105] Iteration 37200, lr = 0.01
I0617 15:54:24.283246  4950 solver.cpp:218] Iteration 37250 (0.852385 iter/s, 58.6589s/50 iters), loss = 0.00588533
I0617 15:54:24.283385  4950 solver.cpp:237]     Train net output #0: loss = 0.0058853 (* 1 = 0.0058853 loss)
I0617 15:54:24.283414  4950 sgd_solver.cpp:105] Iteration 37250, lr = 0.01
I0617 15:54:57.200929  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 15:55:22.959167  4950 solver.cpp:218] Iteration 37300 (0.85215 iter/s, 58.6751s/50 iters), loss = 0.00781565
I0617 15:55:22.959297  4950 solver.cpp:237]     Train net output #0: loss = 0.00781562 (* 1 = 0.00781562 loss)
I0617 15:55:22.959321  4950 sgd_solver.cpp:105] Iteration 37300, lr = 0.01
I0617 15:56:21.612143  4950 solver.cpp:218] Iteration 37350 (0.852483 iter/s, 58.6522s/50 iters), loss = 0.00562492
I0617 15:56:21.612277  4950 solver.cpp:237]     Train net output #0: loss = 0.00562489 (* 1 = 0.00562489 loss)
I0617 15:56:21.612301  4950 sgd_solver.cpp:105] Iteration 37350, lr = 0.01
I0617 15:57:18.020961  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 15:57:20.273746  4950 solver.cpp:218] Iteration 37400 (0.852358 iter/s, 58.6608s/50 iters), loss = 0.00661975
I0617 15:57:20.273838  4950 solver.cpp:237]     Train net output #0: loss = 0.00661972 (* 1 = 0.00661972 loss)
I0617 15:57:20.273860  4950 sgd_solver.cpp:105] Iteration 37400, lr = 0.01
I0617 15:58:18.932914  4950 solver.cpp:218] Iteration 37450 (0.852393 iter/s, 58.6584s/50 iters), loss = 0.00554252
I0617 15:58:18.933056  4950 solver.cpp:237]     Train net output #0: loss = 0.00554249 (* 1 = 0.00554249 loss)
I0617 15:58:18.933079  4950 sgd_solver.cpp:105] Iteration 37450, lr = 0.01
I0617 15:59:17.594290  4950 solver.cpp:218] Iteration 37500 (0.852362 iter/s, 58.6605s/50 iters), loss = 0.00487873
I0617 15:59:17.594496  4950 solver.cpp:237]     Train net output #0: loss = 0.0048787 (* 1 = 0.0048787 loss)
I0617 15:59:17.594527  4950 sgd_solver.cpp:105] Iteration 37500, lr = 0.01
I0617 15:59:38.775634  4967 data_layer.cpp:73] Restarting data prefetching from start.
I0617 16:00:16.264092  4950 solver.cpp:218] Iteration 37550 (0.85224 iter/s, 58.6689s/50 iters), loss = 0.00491076
I0617 16:00:16.264250  4950 solver.cpp:237]     Train net output #0: loss = 0.00491073 (* 1 = 0.00491073 loss)
I0617 16:00:16.264276  4950 sgd_solver.cpp:105] Iteration 37550, lr = 0.01
train_cub.sh: line 1:  4950 Killed                  ../../build/tools/caffe.bin train -solver=mobilenet/solver_cub.prototxt -weights=mobilenet/mobilenet.caffemodel -gpu=1
I0617 16:00:32.625591  8058 caffe.cpp:218] Using GPUs 0
I0617 16:00:32.775248  8058 caffe.cpp:223] GPU 0: Tesla K40m
I0617 16:00:33.134968  8058 solver.cpp:44] Initializing solver from parameters: 
base_lr: 0.01
display: 50
max_iter: 200000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 50000
snapshot: 10000
snapshot_prefix: "mobilenet/mobile_cub"
solver_mode: GPU
device_id: 0
net: "/home/xingzhaolong/caffe_project/caffe_mobile/models/oxford/mobilenet/mobilenet_cub.prototxt"
train_state {
  level: 0
  stage: ""
}
I0617 16:00:33.135291  8058 solver.cpp:87] Creating training net from net file: /home/xingzhaolong/caffe_project/caffe_mobile/models/oxford/mobilenet/mobilenet_cub.prototxt
I0617 16:00:33.137908  8058 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/xingzhaolong/caffe_project/caffe_mobile/models/oxford/mobilenet/mobilenet_cub.prototxt
I0617 16:00:33.137936  8058 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0617 16:00:33.138224  8058 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0617 16:00:33.139281  8058 net.cpp:51] Initializing net from parameters: 
name: "MOBILENET"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_file: "/home/xingzhaolong/Dataset/CUB_200_2011/lmdb/mean.binaryproto"
  }
  data_param {
    source: "/home/xingzhaolong/Dataset/CUB_200_2011/lmdb/train"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv1/bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1/scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2_1/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv1"
  top: "conv2_1/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 32
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv2_1/dw"
  top: "conv2_1/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_1/dw/scale"
  type: "Scale"
  bottom: "conv2_1/dw"
  top: "conv2_1/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_1/dw"
  type: "ReLU"
  bottom: "conv2_1/dw"
  top: "conv2_1/dw"
}
layer {
  name: "conv2_1/sep"
  type: "Convolution"
  bottom: "conv2_1/dw"
  top: "conv2_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv2_1/sep"
  top: "conv2_1/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_1/sep/scale"
  type: "Scale"
  bottom: "conv2_1/sep"
  top: "conv2_1/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_1/sep"
  type: "ReLU"
  bottom: "conv2_1/sep"
  top: "conv2_1/sep"
}
layer {
  name: "conv2_2/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv2_1/sep"
  top: "conv2_2/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 64
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv2_2/dw"
  top: "conv2_2/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_2/dw/scale"
  type: "Scale"
  bottom: "conv2_2/dw"
  top: "conv2_2/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_2/dw"
  type: "ReLU"
  bottom: "conv2_2/dw"
  top: "conv2_2/dw"
}
layer {
  name: "conv2_2/sep"
  type: "Convolution"
  bottom: "conv2_2/dw"
  top: "conv2_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv2_2/sep"
  top: "conv2_2/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_2/sep/scale"
  type: "Scale"
  bottom: "conv2_2/sep"
  top: "conv2_2/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_2/sep"
  type: "ReLU"
  bottom: "conv2_2/sep"
  top: "conv2_2/sep"
}
layer {
  name: "conv3_1/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv2_2/sep"
  top: "conv3_1/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv3_1/dw"
  top: "conv3_1/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_1/dw/scale"
  type: "Scale"
  bottom: "conv3_1/dw"
  top: "conv3_1/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_1/dw"
  type: "ReLU"
  bottom: "conv3_1/dw"
  top: "conv3_1/dw"
}
layer {
  name: "conv3_1/sep"
  type: "Convolution"
  bottom: "conv3_1/dw"
  top: "conv3_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv3_1/sep"
  top: "conv3_1/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_1/sep/scale"
  type: "Scale"
  bottom: "conv3_1/sep"
  top: "conv3_1/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_1/sep"
  type: "ReLU"
  bottom: "conv3_1/sep"
  top: "conv3_1/sep"
}
layer {
  name: "conv3_2/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv3_1/sep"
  top: "conv3_2/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv3_2/dw"
  top: "conv3_2/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_2/dw/scale"
  type: "Scale"
  bottom: "conv3_2/dw"
  top: "conv3_2/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_2/dw"
  type: "ReLU"
  bottom: "conv3_2/dw"
  top: "conv3_2/dw"
}
layer {
  name: "conv3_2/sep"
  type: "Convolution"
  bottom: "conv3_2/dw"
  top: "conv3_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv3_2/sep"
  top: "conv3_2/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_2/sep/scale"
  type: "Scale"
  bottom: "conv3_2/sep"
  top: "conv3_2/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_2/sep"
  type: "ReLU"
  bottom: "conv3_2/sep"
  top: "conv3_2/sep"
}
layer {
  name: "conv4_1/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv3_2/sep"
  top: "conv4_1/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv4_1/dw"
  top: "conv4_1/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv4_1/dw/scale"
  type: "Scale"
  bottom: "conv4_1/dw"
  top: "conv4_1/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu4_1/dw"
  type: "ReLU"
  bottom: "conv4_1/dw"
  top: "conv4_1/dw"
}
layer {
  name: "conv4_1/sep"
  type: "Convolution"
  bottom: "conv4_1/dw"
  top: "conv4_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv4_1/sep"
  top: "conv4_1/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv4_1/sep/scale"
  type: "Scale"
  bottom: "conv4_1/sep"
  top: "conv4_1/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu4_1/sep"
  type: "ReLU"
  bottom: "conv4_1/sep"
  top: "conv4_1/sep"
}
layer {
  name: "conv4_2/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv4_1/sep"
  top: "conv4_2/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv4_2/dw"
  top: "conv4_2/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv4_2/dw/scale"
  type: "Scale"
  bottom: "conv4_2/dw"
  top: "conv4_2/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu4_2/dw"
  type: "ReLU"
  bottom: "conv4_2/dw"
  top: "conv4_2/dw"
}
layer {
  name: "conv4_2/sep"
  type: "Convolution"
  bottom: "conv4_2/dw"
  top: "conv4_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv4_2/sep"
  top: "conv4_2/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv4_2/sep/scale"
  type: "Scale"
  bottom: "conv4_2/sep"
  top: "conv4_2/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu4_2/sep"
  type: "ReLU"
  bottom: "conv4_2/sep"
  top: "conv4_2/sep"
}
layer {
  name: "conv5_1/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv4_2/sep"
  top: "conv5_1/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_1/dw"
  top: "conv5_1/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_1/dw/scale"
  type: "Scale"
  bottom: "conv5_1/dw"
  top: "conv5_1/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_1/dw"
  type: "ReLU"
  bottom: "conv5_1/dw"
  top: "conv5_1/dw"
}
layer {
  name: "conv5_1/sep"
  type: "Convolution"
  bottom: "conv5_1/dw"
  top: "conv5_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_1/sep"
  top: "conv5_1/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_1/sep/scale"
  type: "Scale"
  bottom: "conv5_1/sep"
  top: "conv5_1/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_1/sep"
  type: "ReLU"
  bottom: "conv5_1/sep"
  top: "conv5_1/sep"
}
layer {
  name: "conv5_2/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_1/sep"
  top: "conv5_2/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_2/dw"
  top: "conv5_2/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_2/dw/scale"
  type: "Scale"
  bottom: "conv5_2/dw"
  top: "conv5_2/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_2/dw"
  type: "ReLU"
  bottom: "conv5_2/dw"
  top: "conv5_2/dw"
}
layer {
  name: "conv5_2/sep"
  type: "Convolution"
  bottom: "conv5_2/dw"
  top: "conv5_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_2/sep"
  top: "conv5_2/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_2/sep/scale"
  type: "Scale"
  bottom: "conv5_2/sep"
  top: "conv5_2/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_2/sep"
  type: "ReLU"
  bottom: "conv5_2/sep"
  top: "conv5_2/sep"
}
layer {
  name: "conv5_3/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_2/sep"
  top: "conv5_3/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_3/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_3/dw"
  top: "conv5_3/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_3/dw/scale"
  type: "Scale"
  bottom: "conv5_3/dw"
  top: "conv5_3/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_3/dw"
  type: "ReLU"
  bottom: "conv5_3/dw"
  top: "conv5_3/dw"
}
layer {
  name: "conv5_3/sep"
  type: "Convolution"
  bottom: "conv5_3/dw"
  top: "conv5_3/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_3/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_3/sep"
  top: "conv5_3/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_3/sep/scale"
  type: "Scale"
  bottom: "conv5_3/sep"
  top: "conv5_3/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_3/sep"
  type: "ReLU"
  bottom: "conv5_3/sep"
  top: "conv5_3/sep"
}
layer {
  name: "conv5_4/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_3/sep"
  top: "conv5_4/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_4/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_4/dw"
  top: "conv5_4/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_4/dw/scale"
  type: "Scale"
  bottom: "conv5_4/dw"
  top: "conv5_4/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_4/dw"
  type: "ReLU"
  bottom: "conv5_4/dw"
  top: "conv5_4/dw"
}
layer {
  name: "conv5_4/sep"
  type: "Convolution"
  bottom: "conv5_4/dw"
  top: "conv5_4/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_4/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_4/sep"
  top: "conv5_4/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_4/sep/scale"
  type: "Scale"
  bottom: "conv5_4/sep"
  top: "conv5_4/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_4/sep"
  type: "ReLU"
  bottom: "conv5_4/sep"
  top: "conv5_4/sep"
}
layer {
  name: "conv5_5/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_4/sep"
  top: "conv5_5/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_5/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_5/dw"
  top: "conv5_5/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_5/dw/scale"
  type: "Scale"
  bottom: "conv5_5/dw"
  top: "conv5_5/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_5/dw"
  type: "ReLU"
  bottom: "conv5_5/dw"
  top: "conv5_5/dw"
}
layer {
  name: "conv5_5/sep"
  type: "Convolution"
  bottom: "conv5_5/dw"
  top: "conv5_5/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_5/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_5/sep"
  top: "conv5_5/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_5/sep/scale"
  type: "Scale"
  bottom: "conv5_5/sep"
  top: "conv5_5/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_5/sep"
  type: "ReLU"
  bottom: "conv5_5/sep"
  top: "conv5_5/sep"
}
layer {
  name: "conv5_6/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_5/sep"
  top: "conv5_6/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_6/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_6/dw"
  top: "conv5_6/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_6/dw/scale"
  type: "Scale"
  bottom: "conv5_6/dw"
  top: "conv5_6/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_6/dw"
  type: "ReLU"
  bottom: "conv5_6/dw"
  top: "conv5_6/dw"
}
layer {
  name: "conv5_6/sep"
  type: "Convolution"
  bottom: "conv5_6/dw"
  top: "conv5_6/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_6/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_6/sep"
  top: "conv5_6/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_6/sep/scale"
  type: "Scale"
  bottom: "conv5_6/sep"
  top: "conv5_6/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_6/sep"
  type: "ReLU"
  bottom: "conv5_6/sep"
  top: "conv5_6/sep"
}
layer {
  name: "conv6/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_6/sep"
  top: "conv6/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 1024
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv6/dw/bn"
  type: "BatchNorm"
  bottom: "conv6/dw"
  top: "conv6/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv6/dw/scale"
  type: "Scale"
  bottom: "conv6/dw"
  top: "conv6/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu6/dw"
  type: "ReLU"
  bottom: "conv6/dw"
  top: "conv6/dw"
}
layer {
  name: "conv6/sep"
  type: "Convolution"
  bottom: "conv6/dw"
  top: "conv6/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv6/sep/bn"
  type: "BatchNorm"
  bottom: "conv6/sep"
  top: "conv6/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv6/sep/scale"
  type: "Scale"
  bottom: "conv6/sep"
  top: "conv6/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu6/sep"
  type: "ReLU"
  bottom: "conv6/sep"
  top: "conv6/sep"
}
layer {
  name: "pool6"
  type: "Pooling"
  bottom: "conv6/sep"
  top: "pool6"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc7_oxford"
  type: "Convolution"
  bottom: "pool6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 200
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc7"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc7"
  bottom: "label"
  top: "loss"
}
I0617 16:00:33.139868  8058 layer_factory.hpp:77] Creating layer data
I0617 16:00:33.140120  8058 db_lmdb.cpp:35] Opened lmdb /home/xingzhaolong/Dataset/CUB_200_2011/lmdb/train
I0617 16:00:33.140187  8058 net.cpp:84] Creating Layer data
I0617 16:00:33.140211  8058 net.cpp:380] data -> data
I0617 16:00:33.140254  8058 net.cpp:380] data -> label
I0617 16:00:33.140288  8058 data_transformer.cpp:25] Loading mean file from: /home/xingzhaolong/Dataset/CUB_200_2011/lmdb/mean.binaryproto
I0617 16:00:33.145572  8058 data_layer.cpp:45] output data size: 50,3,224,224
I0617 16:00:33.254274  8058 net.cpp:122] Setting up data
I0617 16:00:33.254344  8058 net.cpp:129] Top shape: 50 3 224 224 (7526400)
I0617 16:00:33.254359  8058 net.cpp:129] Top shape: 50 (50)
I0617 16:00:33.254367  8058 net.cpp:137] Memory required for data: 30105800
I0617 16:00:33.254390  8058 layer_factory.hpp:77] Creating layer label_data_1_split
I0617 16:00:33.254415  8058 net.cpp:84] Creating Layer label_data_1_split
I0617 16:00:33.254429  8058 net.cpp:406] label_data_1_split <- label
I0617 16:00:33.254464  8058 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0617 16:00:33.254487  8058 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0617 16:00:33.254566  8058 net.cpp:122] Setting up label_data_1_split
I0617 16:00:33.254585  8058 net.cpp:129] Top shape: 50 (50)
I0617 16:00:33.254595  8058 net.cpp:129] Top shape: 50 (50)
I0617 16:00:33.254602  8058 net.cpp:137] Memory required for data: 30106200
I0617 16:00:33.254611  8058 layer_factory.hpp:77] Creating layer conv1
I0617 16:00:33.254644  8058 net.cpp:84] Creating Layer conv1
I0617 16:00:33.254655  8058 net.cpp:406] conv1 <- data
I0617 16:00:33.254669  8058 net.cpp:380] conv1 -> conv1
I0617 16:00:33.501797  8058 net.cpp:122] Setting up conv1
I0617 16:00:33.501854  8058 net.cpp:129] Top shape: 50 32 112 112 (20070400)
I0617 16:00:33.501865  8058 net.cpp:137] Memory required for data: 110387800
I0617 16:00:33.501901  8058 layer_factory.hpp:77] Creating layer conv1/bn
I0617 16:00:33.501926  8058 net.cpp:84] Creating Layer conv1/bn
I0617 16:00:33.501938  8058 net.cpp:406] conv1/bn <- conv1
I0617 16:00:33.501951  8058 net.cpp:367] conv1/bn -> conv1 (in-place)
I0617 16:00:33.503034  8058 net.cpp:122] Setting up conv1/bn
I0617 16:00:33.503057  8058 net.cpp:129] Top shape: 50 32 112 112 (20070400)
I0617 16:00:33.503067  8058 net.cpp:137] Memory required for data: 190669400
I0617 16:00:33.503088  8058 layer_factory.hpp:77] Creating layer conv1/scale
I0617 16:00:33.503110  8058 net.cpp:84] Creating Layer conv1/scale
I0617 16:00:33.503121  8058 net.cpp:406] conv1/scale <- conv1
I0617 16:00:33.503132  8058 net.cpp:367] conv1/scale -> conv1 (in-place)
I0617 16:00:33.503199  8058 layer_factory.hpp:77] Creating layer conv1/scale
I0617 16:00:33.503355  8058 net.cpp:122] Setting up conv1/scale
I0617 16:00:33.503373  8058 net.cpp:129] Top shape: 50 32 112 112 (20070400)
I0617 16:00:33.503382  8058 net.cpp:137] Memory required for data: 270951000
I0617 16:00:33.503398  8058 layer_factory.hpp:77] Creating layer relu1
I0617 16:00:33.503414  8058 net.cpp:84] Creating Layer relu1
I0617 16:00:33.503423  8058 net.cpp:406] relu1 <- conv1
I0617 16:00:33.503434  8058 net.cpp:367] relu1 -> conv1 (in-place)
I0617 16:00:33.503859  8058 net.cpp:122] Setting up relu1
I0617 16:00:33.503882  8058 net.cpp:129] Top shape: 50 32 112 112 (20070400)
I0617 16:00:33.503891  8058 net.cpp:137] Memory required for data: 351232600
I0617 16:00:33.503921  8058 layer_factory.hpp:77] Creating layer conv2_1/dw
I0617 16:00:33.503942  8058 net.cpp:84] Creating Layer conv2_1/dw
I0617 16:00:33.503952  8058 net.cpp:406] conv2_1/dw <- conv1
I0617 16:00:33.503964  8058 net.cpp:380] conv2_1/dw -> conv2_1/dw
I0617 16:00:33.506420  8058 net.cpp:122] Setting up conv2_1/dw
I0617 16:00:33.506444  8058 net.cpp:129] Top shape: 50 32 112 112 (20070400)
I0617 16:00:33.506454  8058 net.cpp:137] Memory required for data: 431514200
I0617 16:00:33.506465  8058 layer_factory.hpp:77] Creating layer conv2_1/dw/bn
I0617 16:00:33.506479  8058 net.cpp:84] Creating Layer conv2_1/dw/bn
I0617 16:00:33.506487  8058 net.cpp:406] conv2_1/dw/bn <- conv2_1/dw
I0617 16:00:33.506500  8058 net.cpp:367] conv2_1/dw/bn -> conv2_1/dw (in-place)
I0617 16:00:33.506728  8058 net.cpp:122] Setting up conv2_1/dw/bn
I0617 16:00:33.506748  8058 net.cpp:129] Top shape: 50 32 112 112 (20070400)
I0617 16:00:33.506757  8058 net.cpp:137] Memory required for data: 511795800
I0617 16:00:33.506774  8058 layer_factory.hpp:77] Creating layer conv2_1/dw/scale
I0617 16:00:33.506803  8058 net.cpp:84] Creating Layer conv2_1/dw/scale
I0617 16:00:33.506814  8058 net.cpp:406] conv2_1/dw/scale <- conv2_1/dw
I0617 16:00:33.506825  8058 net.cpp:367] conv2_1/dw/scale -> conv2_1/dw (in-place)
I0617 16:00:33.506878  8058 layer_factory.hpp:77] Creating layer conv2_1/dw/scale
I0617 16:00:33.507021  8058 net.cpp:122] Setting up conv2_1/dw/scale
I0617 16:00:33.507040  8058 net.cpp:129] Top shape: 50 32 112 112 (20070400)
I0617 16:00:33.507047  8058 net.cpp:137] Memory required for data: 592077400
I0617 16:00:33.507061  8058 layer_factory.hpp:77] Creating layer relu2_1/dw
I0617 16:00:33.507072  8058 net.cpp:84] Creating Layer relu2_1/dw
I0617 16:00:33.507081  8058 net.cpp:406] relu2_1/dw <- conv2_1/dw
I0617 16:00:33.507092  8058 net.cpp:367] relu2_1/dw -> conv2_1/dw (in-place)
I0617 16:00:33.507298  8058 net.cpp:122] Setting up relu2_1/dw
I0617 16:00:33.507318  8058 net.cpp:129] Top shape: 50 32 112 112 (20070400)
I0617 16:00:33.507326  8058 net.cpp:137] Memory required for data: 672359000
I0617 16:00:33.507334  8058 layer_factory.hpp:77] Creating layer conv2_1/sep
I0617 16:00:33.507350  8058 net.cpp:84] Creating Layer conv2_1/sep
I0617 16:00:33.507360  8058 net.cpp:406] conv2_1/sep <- conv2_1/dw
I0617 16:00:33.507372  8058 net.cpp:380] conv2_1/sep -> conv2_1/sep
I0617 16:00:33.509425  8058 net.cpp:122] Setting up conv2_1/sep
I0617 16:00:33.509449  8058 net.cpp:129] Top shape: 50 64 112 112 (40140800)
I0617 16:00:33.509459  8058 net.cpp:137] Memory required for data: 832922200
I0617 16:00:33.509470  8058 layer_factory.hpp:77] Creating layer conv2_1/sep/bn
I0617 16:00:33.509485  8058 net.cpp:84] Creating Layer conv2_1/sep/bn
I0617 16:00:33.509493  8058 net.cpp:406] conv2_1/sep/bn <- conv2_1/sep
I0617 16:00:33.509505  8058 net.cpp:367] conv2_1/sep/bn -> conv2_1/sep (in-place)
I0617 16:00:33.509737  8058 net.cpp:122] Setting up conv2_1/sep/bn
I0617 16:00:33.509757  8058 net.cpp:129] Top shape: 50 64 112 112 (40140800)
I0617 16:00:33.509765  8058 net.cpp:137] Memory required for data: 993485400
I0617 16:00:33.509780  8058 layer_factory.hpp:77] Creating layer conv2_1/sep/scale
I0617 16:00:33.509794  8058 net.cpp:84] Creating Layer conv2_1/sep/scale
I0617 16:00:33.509804  8058 net.cpp:406] conv2_1/sep/scale <- conv2_1/sep
I0617 16:00:33.509814  8058 net.cpp:367] conv2_1/sep/scale -> conv2_1/sep (in-place)
I0617 16:00:33.509867  8058 layer_factory.hpp:77] Creating layer conv2_1/sep/scale
I0617 16:00:33.510012  8058 net.cpp:122] Setting up conv2_1/sep/scale
I0617 16:00:33.510030  8058 net.cpp:129] Top shape: 50 64 112 112 (40140800)
I0617 16:00:33.510038  8058 net.cpp:137] Memory required for data: 1154048600
I0617 16:00:33.510056  8058 layer_factory.hpp:77] Creating layer relu2_1/sep
I0617 16:00:33.510068  8058 net.cpp:84] Creating Layer relu2_1/sep
I0617 16:00:33.510077  8058 net.cpp:406] relu2_1/sep <- conv2_1/sep
I0617 16:00:33.510087  8058 net.cpp:367] relu2_1/sep -> conv2_1/sep (in-place)
I0617 16:00:33.510489  8058 net.cpp:122] Setting up relu2_1/sep
I0617 16:00:33.510530  8058 net.cpp:129] Top shape: 50 64 112 112 (40140800)
I0617 16:00:33.510542  8058 net.cpp:137] Memory required for data: 1314611800
I0617 16:00:33.510550  8058 layer_factory.hpp:77] Creating layer conv2_2/dw
I0617 16:00:33.510565  8058 net.cpp:84] Creating Layer conv2_2/dw
I0617 16:00:33.510574  8058 net.cpp:406] conv2_2/dw <- conv2_1/sep
I0617 16:00:33.510587  8058 net.cpp:380] conv2_2/dw -> conv2_2/dw
I0617 16:00:33.511633  8058 net.cpp:122] Setting up conv2_2/dw
I0617 16:00:33.511656  8058 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0617 16:00:33.511665  8058 net.cpp:137] Memory required for data: 1354752600
I0617 16:00:33.511677  8058 layer_factory.hpp:77] Creating layer conv2_2/dw/bn
I0617 16:00:33.511690  8058 net.cpp:84] Creating Layer conv2_2/dw/bn
I0617 16:00:33.511699  8058 net.cpp:406] conv2_2/dw/bn <- conv2_2/dw
I0617 16:00:33.511711  8058 net.cpp:367] conv2_2/dw/bn -> conv2_2/dw (in-place)
I0617 16:00:33.511929  8058 net.cpp:122] Setting up conv2_2/dw/bn
I0617 16:00:33.511955  8058 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0617 16:00:33.511963  8058 net.cpp:137] Memory required for data: 1394893400
I0617 16:00:33.511977  8058 layer_factory.hpp:77] Creating layer conv2_2/dw/scale
I0617 16:00:33.511994  8058 net.cpp:84] Creating Layer conv2_2/dw/scale
I0617 16:00:33.512003  8058 net.cpp:406] conv2_2/dw/scale <- conv2_2/dw
I0617 16:00:33.512015  8058 net.cpp:367] conv2_2/dw/scale -> conv2_2/dw (in-place)
I0617 16:00:33.512068  8058 layer_factory.hpp:77] Creating layer conv2_2/dw/scale
I0617 16:00:33.512210  8058 net.cpp:122] Setting up conv2_2/dw/scale
I0617 16:00:33.512228  8058 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0617 16:00:33.512235  8058 net.cpp:137] Memory required for data: 1435034200
I0617 16:00:33.512248  8058 layer_factory.hpp:77] Creating layer relu2_2/dw
I0617 16:00:33.512260  8058 net.cpp:84] Creating Layer relu2_2/dw
I0617 16:00:33.512269  8058 net.cpp:406] relu2_2/dw <- conv2_2/dw
I0617 16:00:33.512279  8058 net.cpp:367] relu2_2/dw -> conv2_2/dw (in-place)
I0617 16:00:33.512485  8058 net.cpp:122] Setting up relu2_2/dw
I0617 16:00:33.512504  8058 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0617 16:00:33.512521  8058 net.cpp:137] Memory required for data: 1475175000
I0617 16:00:33.512531  8058 layer_factory.hpp:77] Creating layer conv2_2/sep
I0617 16:00:33.512548  8058 net.cpp:84] Creating Layer conv2_2/sep
I0617 16:00:33.512557  8058 net.cpp:406] conv2_2/sep <- conv2_2/dw
I0617 16:00:33.512570  8058 net.cpp:380] conv2_2/sep -> conv2_2/sep
I0617 16:00:33.513918  8058 net.cpp:122] Setting up conv2_2/sep
I0617 16:00:33.513945  8058 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0617 16:00:33.513955  8058 net.cpp:137] Memory required for data: 1555456600
I0617 16:00:33.513967  8058 layer_factory.hpp:77] Creating layer conv2_2/sep/bn
I0617 16:00:33.513979  8058 net.cpp:84] Creating Layer conv2_2/sep/bn
I0617 16:00:33.513988  8058 net.cpp:406] conv2_2/sep/bn <- conv2_2/sep
I0617 16:00:33.514003  8058 net.cpp:367] conv2_2/sep/bn -> conv2_2/sep (in-place)
I0617 16:00:33.514235  8058 net.cpp:122] Setting up conv2_2/sep/bn
I0617 16:00:33.514253  8058 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0617 16:00:33.514261  8058 net.cpp:137] Memory required for data: 1635738200
I0617 16:00:33.514276  8058 layer_factory.hpp:77] Creating layer conv2_2/sep/scale
I0617 16:00:33.514288  8058 net.cpp:84] Creating Layer conv2_2/sep/scale
I0617 16:00:33.514297  8058 net.cpp:406] conv2_2/sep/scale <- conv2_2/sep
I0617 16:00:33.514308  8058 net.cpp:367] conv2_2/sep/scale -> conv2_2/sep (in-place)
I0617 16:00:33.514364  8058 layer_factory.hpp:77] Creating layer conv2_2/sep/scale
I0617 16:00:33.514513  8058 net.cpp:122] Setting up conv2_2/sep/scale
I0617 16:00:33.514546  8058 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0617 16:00:33.514555  8058 net.cpp:137] Memory required for data: 1716019800
I0617 16:00:33.514567  8058 layer_factory.hpp:77] Creating layer relu2_2/sep
I0617 16:00:33.514580  8058 net.cpp:84] Creating Layer relu2_2/sep
I0617 16:00:33.514588  8058 net.cpp:406] relu2_2/sep <- conv2_2/sep
I0617 16:00:33.514612  8058 net.cpp:367] relu2_2/sep -> conv2_2/sep (in-place)
I0617 16:00:33.514842  8058 net.cpp:122] Setting up relu2_2/sep
I0617 16:00:33.514861  8058 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0617 16:00:33.514870  8058 net.cpp:137] Memory required for data: 1796301400
I0617 16:00:33.514878  8058 layer_factory.hpp:77] Creating layer conv3_1/dw
I0617 16:00:33.514895  8058 net.cpp:84] Creating Layer conv3_1/dw
I0617 16:00:33.514905  8058 net.cpp:406] conv3_1/dw <- conv2_2/sep
I0617 16:00:33.514917  8058 net.cpp:380] conv3_1/dw -> conv3_1/dw
I0617 16:00:33.515964  8058 net.cpp:122] Setting up conv3_1/dw
I0617 16:00:33.515986  8058 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0617 16:00:33.515995  8058 net.cpp:137] Memory required for data: 1876583000
I0617 16:00:33.516005  8058 layer_factory.hpp:77] Creating layer conv3_1/dw/bn
I0617 16:00:33.516022  8058 net.cpp:84] Creating Layer conv3_1/dw/bn
I0617 16:00:33.516032  8058 net.cpp:406] conv3_1/dw/bn <- conv3_1/dw
I0617 16:00:33.516053  8058 net.cpp:367] conv3_1/dw/bn -> conv3_1/dw (in-place)
I0617 16:00:33.516275  8058 net.cpp:122] Setting up conv3_1/dw/bn
I0617 16:00:33.516293  8058 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0617 16:00:33.516300  8058 net.cpp:137] Memory required for data: 1956864600
I0617 16:00:33.516320  8058 layer_factory.hpp:77] Creating layer conv3_1/dw/scale
I0617 16:00:33.516340  8058 net.cpp:84] Creating Layer conv3_1/dw/scale
I0617 16:00:33.516350  8058 net.cpp:406] conv3_1/dw/scale <- conv3_1/dw
I0617 16:00:33.516361  8058 net.cpp:367] conv3_1/dw/scale -> conv3_1/dw (in-place)
I0617 16:00:33.516419  8058 layer_factory.hpp:77] Creating layer conv3_1/dw/scale
I0617 16:00:33.516585  8058 net.cpp:122] Setting up conv3_1/dw/scale
I0617 16:00:33.516604  8058 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0617 16:00:33.516613  8058 net.cpp:137] Memory required for data: 2037146200
I0617 16:00:33.516624  8058 layer_factory.hpp:77] Creating layer relu3_1/dw
I0617 16:00:33.516636  8058 net.cpp:84] Creating Layer relu3_1/dw
I0617 16:00:33.516645  8058 net.cpp:406] relu3_1/dw <- conv3_1/dw
I0617 16:00:33.516659  8058 net.cpp:367] relu3_1/dw -> conv3_1/dw (in-place)
I0617 16:00:33.517088  8058 net.cpp:122] Setting up relu3_1/dw
I0617 16:00:33.517109  8058 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0617 16:00:33.517118  8058 net.cpp:137] Memory required for data: 2117427800
I0617 16:00:33.517127  8058 layer_factory.hpp:77] Creating layer conv3_1/sep
I0617 16:00:33.517148  8058 net.cpp:84] Creating Layer conv3_1/sep
I0617 16:00:33.517158  8058 net.cpp:406] conv3_1/sep <- conv3_1/dw
I0617 16:00:33.517174  8058 net.cpp:380] conv3_1/sep -> conv3_1/sep
I0617 16:00:33.518960  8058 net.cpp:122] Setting up conv3_1/sep
I0617 16:00:33.518985  8058 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0617 16:00:33.518995  8058 net.cpp:137] Memory required for data: 2197709400
I0617 16:00:33.519006  8058 layer_factory.hpp:77] Creating layer conv3_1/sep/bn
I0617 16:00:33.519021  8058 net.cpp:84] Creating Layer conv3_1/sep/bn
I0617 16:00:33.519032  8058 net.cpp:406] conv3_1/sep/bn <- conv3_1/sep
I0617 16:00:33.519043  8058 net.cpp:367] conv3_1/sep/bn -> conv3_1/sep (in-place)
I0617 16:00:33.519285  8058 net.cpp:122] Setting up conv3_1/sep/bn
I0617 16:00:33.519302  8058 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0617 16:00:33.519311  8058 net.cpp:137] Memory required for data: 2277991000
I0617 16:00:33.519325  8058 layer_factory.hpp:77] Creating layer conv3_1/sep/scale
I0617 16:00:33.519342  8058 net.cpp:84] Creating Layer conv3_1/sep/scale
I0617 16:00:33.519352  8058 net.cpp:406] conv3_1/sep/scale <- conv3_1/sep
I0617 16:00:33.519363  8058 net.cpp:367] conv3_1/sep/scale -> conv3_1/sep (in-place)
I0617 16:00:33.519421  8058 layer_factory.hpp:77] Creating layer conv3_1/sep/scale
I0617 16:00:33.519588  8058 net.cpp:122] Setting up conv3_1/sep/scale
I0617 16:00:33.519608  8058 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0617 16:00:33.519615  8058 net.cpp:137] Memory required for data: 2358272600
I0617 16:00:33.519639  8058 layer_factory.hpp:77] Creating layer relu3_1/sep
I0617 16:00:33.519652  8058 net.cpp:84] Creating Layer relu3_1/sep
I0617 16:00:33.519661  8058 net.cpp:406] relu3_1/sep <- conv3_1/sep
I0617 16:00:33.519675  8058 net.cpp:367] relu3_1/sep -> conv3_1/sep (in-place)
I0617 16:00:33.519907  8058 net.cpp:122] Setting up relu3_1/sep
I0617 16:00:33.519927  8058 net.cpp:129] Top shape: 50 128 56 56 (20070400)
I0617 16:00:33.519935  8058 net.cpp:137] Memory required for data: 2438554200
I0617 16:00:33.519943  8058 layer_factory.hpp:77] Creating layer conv3_2/dw
I0617 16:00:33.519960  8058 net.cpp:84] Creating Layer conv3_2/dw
I0617 16:00:33.519970  8058 net.cpp:406] conv3_2/dw <- conv3_1/sep
I0617 16:00:33.519985  8058 net.cpp:380] conv3_2/dw -> conv3_2/dw
I0617 16:00:33.520956  8058 net.cpp:122] Setting up conv3_2/dw
I0617 16:00:33.520980  8058 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0617 16:00:33.520989  8058 net.cpp:137] Memory required for data: 2458624600
I0617 16:00:33.521000  8058 layer_factory.hpp:77] Creating layer conv3_2/dw/bn
I0617 16:00:33.521020  8058 net.cpp:84] Creating Layer conv3_2/dw/bn
I0617 16:00:33.521030  8058 net.cpp:406] conv3_2/dw/bn <- conv3_2/dw
I0617 16:00:33.521044  8058 net.cpp:367] conv3_2/dw/bn -> conv3_2/dw (in-place)
I0617 16:00:33.521281  8058 net.cpp:122] Setting up conv3_2/dw/bn
I0617 16:00:33.521298  8058 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0617 16:00:33.521306  8058 net.cpp:137] Memory required for data: 2478695000
I0617 16:00:33.521320  8058 layer_factory.hpp:77] Creating layer conv3_2/dw/scale
I0617 16:00:33.521337  8058 net.cpp:84] Creating Layer conv3_2/dw/scale
I0617 16:00:33.521347  8058 net.cpp:406] conv3_2/dw/scale <- conv3_2/dw
I0617 16:00:33.521358  8058 net.cpp:367] conv3_2/dw/scale -> conv3_2/dw (in-place)
I0617 16:00:33.521421  8058 layer_factory.hpp:77] Creating layer conv3_2/dw/scale
I0617 16:00:33.521584  8058 net.cpp:122] Setting up conv3_2/dw/scale
I0617 16:00:33.521601  8058 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0617 16:00:33.521610  8058 net.cpp:137] Memory required for data: 2498765400
I0617 16:00:33.521622  8058 layer_factory.hpp:77] Creating layer relu3_2/dw
I0617 16:00:33.521634  8058 net.cpp:84] Creating Layer relu3_2/dw
I0617 16:00:33.521646  8058 net.cpp:406] relu3_2/dw <- conv3_2/dw
I0617 16:00:33.521657  8058 net.cpp:367] relu3_2/dw -> conv3_2/dw (in-place)
I0617 16:00:33.522099  8058 net.cpp:122] Setting up relu3_2/dw
I0617 16:00:33.522120  8058 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0617 16:00:33.522130  8058 net.cpp:137] Memory required for data: 2518835800
I0617 16:00:33.522138  8058 layer_factory.hpp:77] Creating layer conv3_2/sep
I0617 16:00:33.522157  8058 net.cpp:84] Creating Layer conv3_2/sep
I0617 16:00:33.522167  8058 net.cpp:406] conv3_2/sep <- conv3_2/dw
I0617 16:00:33.522183  8058 net.cpp:380] conv3_2/sep -> conv3_2/sep
I0617 16:00:33.524118  8058 net.cpp:122] Setting up conv3_2/sep
I0617 16:00:33.524144  8058 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0617 16:00:33.524153  8058 net.cpp:137] Memory required for data: 2558976600
I0617 16:00:33.524164  8058 layer_factory.hpp:77] Creating layer conv3_2/sep/bn
I0617 16:00:33.524181  8058 net.cpp:84] Creating Layer conv3_2/sep/bn
I0617 16:00:33.524191  8058 net.cpp:406] conv3_2/sep/bn <- conv3_2/sep
I0617 16:00:33.524204  8058 net.cpp:367] conv3_2/sep/bn -> conv3_2/sep (in-place)
I0617 16:00:33.524440  8058 net.cpp:122] Setting up conv3_2/sep/bn
I0617 16:00:33.524457  8058 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0617 16:00:33.524466  8058 net.cpp:137] Memory required for data: 2599117400
I0617 16:00:33.524479  8058 layer_factory.hpp:77] Creating layer conv3_2/sep/scale
I0617 16:00:33.524497  8058 net.cpp:84] Creating Layer conv3_2/sep/scale
I0617 16:00:33.524507  8058 net.cpp:406] conv3_2/sep/scale <- conv3_2/sep
I0617 16:00:33.524525  8058 net.cpp:367] conv3_2/sep/scale -> conv3_2/sep (in-place)
I0617 16:00:33.524590  8058 layer_factory.hpp:77] Creating layer conv3_2/sep/scale
I0617 16:00:33.524741  8058 net.cpp:122] Setting up conv3_2/sep/scale
I0617 16:00:33.524770  8058 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0617 16:00:33.524778  8058 net.cpp:137] Memory required for data: 2639258200
I0617 16:00:33.524791  8058 layer_factory.hpp:77] Creating layer relu3_2/sep
I0617 16:00:33.524806  8058 net.cpp:84] Creating Layer relu3_2/sep
I0617 16:00:33.524816  8058 net.cpp:406] relu3_2/sep <- conv3_2/sep
I0617 16:00:33.524827  8058 net.cpp:367] relu3_2/sep -> conv3_2/sep (in-place)
I0617 16:00:33.525048  8058 net.cpp:122] Setting up relu3_2/sep
I0617 16:00:33.525066  8058 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0617 16:00:33.525075  8058 net.cpp:137] Memory required for data: 2679399000
I0617 16:00:33.525084  8058 layer_factory.hpp:77] Creating layer conv4_1/dw
I0617 16:00:33.525101  8058 net.cpp:84] Creating Layer conv4_1/dw
I0617 16:00:33.525111  8058 net.cpp:406] conv4_1/dw <- conv3_2/sep
I0617 16:00:33.525128  8058 net.cpp:380] conv4_1/dw -> conv4_1/dw
I0617 16:00:33.525315  8058 net.cpp:122] Setting up conv4_1/dw
I0617 16:00:33.525341  8058 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0617 16:00:33.525351  8058 net.cpp:137] Memory required for data: 2719539800
I0617 16:00:33.525362  8058 layer_factory.hpp:77] Creating layer conv4_1/dw/bn
I0617 16:00:33.525377  8058 net.cpp:84] Creating Layer conv4_1/dw/bn
I0617 16:00:33.525387  8058 net.cpp:406] conv4_1/dw/bn <- conv4_1/dw
I0617 16:00:33.525400  8058 net.cpp:367] conv4_1/dw/bn -> conv4_1/dw (in-place)
I0617 16:00:33.525640  8058 net.cpp:122] Setting up conv4_1/dw/bn
I0617 16:00:33.525658  8058 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0617 16:00:33.525666  8058 net.cpp:137] Memory required for data: 2759680600
I0617 16:00:33.525679  8058 layer_factory.hpp:77] Creating layer conv4_1/dw/scale
I0617 16:00:33.525692  8058 net.cpp:84] Creating Layer conv4_1/dw/scale
I0617 16:00:33.525701  8058 net.cpp:406] conv4_1/dw/scale <- conv4_1/dw
I0617 16:00:33.525717  8058 net.cpp:367] conv4_1/dw/scale -> conv4_1/dw (in-place)
I0617 16:00:33.525770  8058 layer_factory.hpp:77] Creating layer conv4_1/dw/scale
I0617 16:00:33.525924  8058 net.cpp:122] Setting up conv4_1/dw/scale
I0617 16:00:33.525944  8058 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0617 16:00:33.525954  8058 net.cpp:137] Memory required for data: 2799821400
I0617 16:00:33.525965  8058 layer_factory.hpp:77] Creating layer relu4_1/dw
I0617 16:00:33.525977  8058 net.cpp:84] Creating Layer relu4_1/dw
I0617 16:00:33.525985  8058 net.cpp:406] relu4_1/dw <- conv4_1/dw
I0617 16:00:33.525996  8058 net.cpp:367] relu4_1/dw -> conv4_1/dw (in-place)
I0617 16:00:33.526433  8058 net.cpp:122] Setting up relu4_1/dw
I0617 16:00:33.526454  8058 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0617 16:00:33.526463  8058 net.cpp:137] Memory required for data: 2839962200
I0617 16:00:33.526471  8058 layer_factory.hpp:77] Creating layer conv4_1/sep
I0617 16:00:33.526490  8058 net.cpp:84] Creating Layer conv4_1/sep
I0617 16:00:33.526504  8058 net.cpp:406] conv4_1/sep <- conv4_1/dw
I0617 16:00:33.526525  8058 net.cpp:380] conv4_1/sep -> conv4_1/sep
I0617 16:00:33.528784  8058 net.cpp:122] Setting up conv4_1/sep
I0617 16:00:33.528807  8058 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0617 16:00:33.528817  8058 net.cpp:137] Memory required for data: 2880103000
I0617 16:00:33.528828  8058 layer_factory.hpp:77] Creating layer conv4_1/sep/bn
I0617 16:00:33.528846  8058 net.cpp:84] Creating Layer conv4_1/sep/bn
I0617 16:00:33.528856  8058 net.cpp:406] conv4_1/sep/bn <- conv4_1/sep
I0617 16:00:33.528867  8058 net.cpp:367] conv4_1/sep/bn -> conv4_1/sep (in-place)
I0617 16:00:33.529111  8058 net.cpp:122] Setting up conv4_1/sep/bn
I0617 16:00:33.529129  8058 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0617 16:00:33.529137  8058 net.cpp:137] Memory required for data: 2920243800
I0617 16:00:33.529151  8058 layer_factory.hpp:77] Creating layer conv4_1/sep/scale
I0617 16:00:33.529168  8058 net.cpp:84] Creating Layer conv4_1/sep/scale
I0617 16:00:33.529178  8058 net.cpp:406] conv4_1/sep/scale <- conv4_1/sep
I0617 16:00:33.529189  8058 net.cpp:367] conv4_1/sep/scale -> conv4_1/sep (in-place)
I0617 16:00:33.529271  8058 layer_factory.hpp:77] Creating layer conv4_1/sep/scale
I0617 16:00:33.529424  8058 net.cpp:122] Setting up conv4_1/sep/scale
I0617 16:00:33.529443  8058 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0617 16:00:33.529450  8058 net.cpp:137] Memory required for data: 2960384600
I0617 16:00:33.529477  8058 layer_factory.hpp:77] Creating layer relu4_1/sep
I0617 16:00:33.529491  8058 net.cpp:84] Creating Layer relu4_1/sep
I0617 16:00:33.529500  8058 net.cpp:406] relu4_1/sep <- conv4_1/sep
I0617 16:00:33.529521  8058 net.cpp:367] relu4_1/sep -> conv4_1/sep (in-place)
I0617 16:00:33.529960  8058 net.cpp:122] Setting up relu4_1/sep
I0617 16:00:33.529981  8058 net.cpp:129] Top shape: 50 256 28 28 (10035200)
I0617 16:00:33.529990  8058 net.cpp:137] Memory required for data: 3000525400
I0617 16:00:33.529999  8058 layer_factory.hpp:77] Creating layer conv4_2/dw
I0617 16:00:33.530016  8058 net.cpp:84] Creating Layer conv4_2/dw
I0617 16:00:33.530035  8058 net.cpp:406] conv4_2/dw <- conv4_1/sep
I0617 16:00:33.530050  8058 net.cpp:380] conv4_2/dw -> conv4_2/dw
I0617 16:00:33.530215  8058 net.cpp:122] Setting up conv4_2/dw
I0617 16:00:33.530232  8058 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0617 16:00:33.530241  8058 net.cpp:137] Memory required for data: 3010560600
I0617 16:00:33.530252  8058 layer_factory.hpp:77] Creating layer conv4_2/dw/bn
I0617 16:00:33.530268  8058 net.cpp:84] Creating Layer conv4_2/dw/bn
I0617 16:00:33.530277  8058 net.cpp:406] conv4_2/dw/bn <- conv4_2/dw
I0617 16:00:33.530292  8058 net.cpp:367] conv4_2/dw/bn -> conv4_2/dw (in-place)
I0617 16:00:33.530539  8058 net.cpp:122] Setting up conv4_2/dw/bn
I0617 16:00:33.530557  8058 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0617 16:00:33.530565  8058 net.cpp:137] Memory required for data: 3020595800
I0617 16:00:33.530580  8058 layer_factory.hpp:77] Creating layer conv4_2/dw/scale
I0617 16:00:33.530593  8058 net.cpp:84] Creating Layer conv4_2/dw/scale
I0617 16:00:33.530602  8058 net.cpp:406] conv4_2/dw/scale <- conv4_2/dw
I0617 16:00:33.530618  8058 net.cpp:367] conv4_2/dw/scale -> conv4_2/dw (in-place)
I0617 16:00:33.530679  8058 layer_factory.hpp:77] Creating layer conv4_2/dw/scale
I0617 16:00:33.530830  8058 net.cpp:122] Setting up conv4_2/dw/scale
I0617 16:00:33.530848  8058 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0617 16:00:33.530855  8058 net.cpp:137] Memory required for data: 3030631000
I0617 16:00:33.530867  8058 layer_factory.hpp:77] Creating layer relu4_2/dw
I0617 16:00:33.530879  8058 net.cpp:84] Creating Layer relu4_2/dw
I0617 16:00:33.530889  8058 net.cpp:406] relu4_2/dw <- conv4_2/dw
I0617 16:00:33.530899  8058 net.cpp:367] relu4_2/dw -> conv4_2/dw (in-place)
I0617 16:00:33.531319  8058 net.cpp:122] Setting up relu4_2/dw
I0617 16:00:33.531340  8058 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0617 16:00:33.531349  8058 net.cpp:137] Memory required for data: 3040666200
I0617 16:00:33.531358  8058 layer_factory.hpp:77] Creating layer conv4_2/sep
I0617 16:00:33.531378  8058 net.cpp:84] Creating Layer conv4_2/sep
I0617 16:00:33.531388  8058 net.cpp:406] conv4_2/sep <- conv4_2/dw
I0617 16:00:33.531405  8058 net.cpp:380] conv4_2/sep -> conv4_2/sep
I0617 16:00:33.535456  8058 net.cpp:122] Setting up conv4_2/sep
I0617 16:00:33.535485  8058 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 16:00:33.535493  8058 net.cpp:137] Memory required for data: 3060736600
I0617 16:00:33.535504  8058 layer_factory.hpp:77] Creating layer conv4_2/sep/bn
I0617 16:00:33.535529  8058 net.cpp:84] Creating Layer conv4_2/sep/bn
I0617 16:00:33.535542  8058 net.cpp:406] conv4_2/sep/bn <- conv4_2/sep
I0617 16:00:33.535554  8058 net.cpp:367] conv4_2/sep/bn -> conv4_2/sep (in-place)
I0617 16:00:33.535816  8058 net.cpp:122] Setting up conv4_2/sep/bn
I0617 16:00:33.535835  8058 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 16:00:33.535842  8058 net.cpp:137] Memory required for data: 3080807000
I0617 16:00:33.535857  8058 layer_factory.hpp:77] Creating layer conv4_2/sep/scale
I0617 16:00:33.535882  8058 net.cpp:84] Creating Layer conv4_2/sep/scale
I0617 16:00:33.535892  8058 net.cpp:406] conv4_2/sep/scale <- conv4_2/sep
I0617 16:00:33.535903  8058 net.cpp:367] conv4_2/sep/scale -> conv4_2/sep (in-place)
I0617 16:00:33.535961  8058 layer_factory.hpp:77] Creating layer conv4_2/sep/scale
I0617 16:00:33.536118  8058 net.cpp:122] Setting up conv4_2/sep/scale
I0617 16:00:33.536134  8058 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 16:00:33.536142  8058 net.cpp:137] Memory required for data: 3100877400
I0617 16:00:33.536155  8058 layer_factory.hpp:77] Creating layer relu4_2/sep
I0617 16:00:33.536170  8058 net.cpp:84] Creating Layer relu4_2/sep
I0617 16:00:33.536180  8058 net.cpp:406] relu4_2/sep <- conv4_2/sep
I0617 16:00:33.536190  8058 net.cpp:367] relu4_2/sep -> conv4_2/sep (in-place)
I0617 16:00:33.536626  8058 net.cpp:122] Setting up relu4_2/sep
I0617 16:00:33.536654  8058 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 16:00:33.536664  8058 net.cpp:137] Memory required for data: 3120947800
I0617 16:00:33.536680  8058 layer_factory.hpp:77] Creating layer conv5_1/dw
I0617 16:00:33.536695  8058 net.cpp:84] Creating Layer conv5_1/dw
I0617 16:00:33.536705  8058 net.cpp:406] conv5_1/dw <- conv4_2/sep
I0617 16:00:33.536720  8058 net.cpp:380] conv5_1/dw -> conv5_1/dw
I0617 16:00:33.536931  8058 net.cpp:122] Setting up conv5_1/dw
I0617 16:00:33.536950  8058 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 16:00:33.536958  8058 net.cpp:137] Memory required for data: 3141018200
I0617 16:00:33.536969  8058 layer_factory.hpp:77] Creating layer conv5_1/dw/bn
I0617 16:00:33.536983  8058 net.cpp:84] Creating Layer conv5_1/dw/bn
I0617 16:00:33.536991  8058 net.cpp:406] conv5_1/dw/bn <- conv5_1/dw
I0617 16:00:33.537005  8058 net.cpp:367] conv5_1/dw/bn -> conv5_1/dw (in-place)
I0617 16:00:33.537246  8058 net.cpp:122] Setting up conv5_1/dw/bn
I0617 16:00:33.537264  8058 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 16:00:33.537272  8058 net.cpp:137] Memory required for data: 3161088600
I0617 16:00:33.537286  8058 layer_factory.hpp:77] Creating layer conv5_1/dw/scale
I0617 16:00:33.537300  8058 net.cpp:84] Creating Layer conv5_1/dw/scale
I0617 16:00:33.537309  8058 net.cpp:406] conv5_1/dw/scale <- conv5_1/dw
I0617 16:00:33.537320  8058 net.cpp:367] conv5_1/dw/scale -> conv5_1/dw (in-place)
I0617 16:00:33.537376  8058 layer_factory.hpp:77] Creating layer conv5_1/dw/scale
I0617 16:00:33.537544  8058 net.cpp:122] Setting up conv5_1/dw/scale
I0617 16:00:33.537564  8058 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 16:00:33.537571  8058 net.cpp:137] Memory required for data: 3181159000
I0617 16:00:33.537583  8058 layer_factory.hpp:77] Creating layer relu5_1/dw
I0617 16:00:33.537595  8058 net.cpp:84] Creating Layer relu5_1/dw
I0617 16:00:33.537605  8058 net.cpp:406] relu5_1/dw <- conv5_1/dw
I0617 16:00:33.537617  8058 net.cpp:367] relu5_1/dw -> conv5_1/dw (in-place)
I0617 16:00:33.537847  8058 net.cpp:122] Setting up relu5_1/dw
I0617 16:00:33.537866  8058 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 16:00:33.537875  8058 net.cpp:137] Memory required for data: 3201229400
I0617 16:00:33.537883  8058 layer_factory.hpp:77] Creating layer conv5_1/sep
I0617 16:00:33.537902  8058 net.cpp:84] Creating Layer conv5_1/sep
I0617 16:00:33.537912  8058 net.cpp:406] conv5_1/sep <- conv5_1/dw
I0617 16:00:33.537925  8058 net.cpp:380] conv5_1/sep -> conv5_1/sep
I0617 16:00:33.543905  8058 net.cpp:122] Setting up conv5_1/sep
I0617 16:00:33.543931  8058 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 16:00:33.543941  8058 net.cpp:137] Memory required for data: 3221299800
I0617 16:00:33.543951  8058 layer_factory.hpp:77] Creating layer conv5_1/sep/bn
I0617 16:00:33.543968  8058 net.cpp:84] Creating Layer conv5_1/sep/bn
I0617 16:00:33.543978  8058 net.cpp:406] conv5_1/sep/bn <- conv5_1/sep
I0617 16:00:33.543992  8058 net.cpp:367] conv5_1/sep/bn -> conv5_1/sep (in-place)
I0617 16:00:33.544250  8058 net.cpp:122] Setting up conv5_1/sep/bn
I0617 16:00:33.544267  8058 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 16:00:33.544287  8058 net.cpp:137] Memory required for data: 3241370200
I0617 16:00:33.544302  8058 layer_factory.hpp:77] Creating layer conv5_1/sep/scale
I0617 16:00:33.544317  8058 net.cpp:84] Creating Layer conv5_1/sep/scale
I0617 16:00:33.544325  8058 net.cpp:406] conv5_1/sep/scale <- conv5_1/sep
I0617 16:00:33.544339  8058 net.cpp:367] conv5_1/sep/scale -> conv5_1/sep (in-place)
I0617 16:00:33.544396  8058 layer_factory.hpp:77] Creating layer conv5_1/sep/scale
I0617 16:00:33.544564  8058 net.cpp:122] Setting up conv5_1/sep/scale
I0617 16:00:33.544586  8058 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 16:00:33.544595  8058 net.cpp:137] Memory required for data: 3261440600
I0617 16:00:33.544606  8058 layer_factory.hpp:77] Creating layer relu5_1/sep
I0617 16:00:33.544618  8058 net.cpp:84] Creating Layer relu5_1/sep
I0617 16:00:33.544627  8058 net.cpp:406] relu5_1/sep <- conv5_1/sep
I0617 16:00:33.544637  8058 net.cpp:367] relu5_1/sep -> conv5_1/sep (in-place)
I0617 16:00:33.545078  8058 net.cpp:122] Setting up relu5_1/sep
I0617 16:00:33.545106  8058 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 16:00:33.545116  8058 net.cpp:137] Memory required for data: 3281511000
I0617 16:00:33.545125  8058 layer_factory.hpp:77] Creating layer conv5_2/dw
I0617 16:00:33.545141  8058 net.cpp:84] Creating Layer conv5_2/dw
I0617 16:00:33.545152  8058 net.cpp:406] conv5_2/dw <- conv5_1/sep
I0617 16:00:33.545167  8058 net.cpp:380] conv5_2/dw -> conv5_2/dw
I0617 16:00:33.545379  8058 net.cpp:122] Setting up conv5_2/dw
I0617 16:00:33.545398  8058 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 16:00:33.545406  8058 net.cpp:137] Memory required for data: 3301581400
I0617 16:00:33.545416  8058 layer_factory.hpp:77] Creating layer conv5_2/dw/bn
I0617 16:00:33.545433  8058 net.cpp:84] Creating Layer conv5_2/dw/bn
I0617 16:00:33.545442  8058 net.cpp:406] conv5_2/dw/bn <- conv5_2/dw
I0617 16:00:33.545456  8058 net.cpp:367] conv5_2/dw/bn -> conv5_2/dw (in-place)
I0617 16:00:33.545704  8058 net.cpp:122] Setting up conv5_2/dw/bn
I0617 16:00:33.545723  8058 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 16:00:33.545732  8058 net.cpp:137] Memory required for data: 3321651800
I0617 16:00:33.545745  8058 layer_factory.hpp:77] Creating layer conv5_2/dw/scale
I0617 16:00:33.545773  8058 net.cpp:84] Creating Layer conv5_2/dw/scale
I0617 16:00:33.545784  8058 net.cpp:406] conv5_2/dw/scale <- conv5_2/dw
I0617 16:00:33.545796  8058 net.cpp:367] conv5_2/dw/scale -> conv5_2/dw (in-place)
I0617 16:00:33.545858  8058 layer_factory.hpp:77] Creating layer conv5_2/dw/scale
I0617 16:00:33.546020  8058 net.cpp:122] Setting up conv5_2/dw/scale
I0617 16:00:33.546037  8058 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 16:00:33.546046  8058 net.cpp:137] Memory required for data: 3341722200
I0617 16:00:33.546059  8058 layer_factory.hpp:77] Creating layer relu5_2/dw
I0617 16:00:33.546074  8058 net.cpp:84] Creating Layer relu5_2/dw
I0617 16:00:33.546083  8058 net.cpp:406] relu5_2/dw <- conv5_2/dw
I0617 16:00:33.546094  8058 net.cpp:367] relu5_2/dw -> conv5_2/dw (in-place)
I0617 16:00:33.546319  8058 net.cpp:122] Setting up relu5_2/dw
I0617 16:00:33.546337  8058 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 16:00:33.546345  8058 net.cpp:137] Memory required for data: 3361792600
I0617 16:00:33.546355  8058 layer_factory.hpp:77] Creating layer conv5_2/sep
I0617 16:00:33.546375  8058 net.cpp:84] Creating Layer conv5_2/sep
I0617 16:00:33.546385  8058 net.cpp:406] conv5_2/sep <- conv5_2/dw
I0617 16:00:33.546397  8058 net.cpp:380] conv5_2/sep -> conv5_2/sep
I0617 16:00:33.552199  8058 net.cpp:122] Setting up conv5_2/sep
I0617 16:00:33.552225  8058 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 16:00:33.552235  8058 net.cpp:137] Memory required for data: 3381863000
I0617 16:00:33.552247  8058 layer_factory.hpp:77] Creating layer conv5_2/sep/bn
I0617 16:00:33.552263  8058 net.cpp:84] Creating Layer conv5_2/sep/bn
I0617 16:00:33.552273  8058 net.cpp:406] conv5_2/sep/bn <- conv5_2/sep
I0617 16:00:33.552285  8058 net.cpp:367] conv5_2/sep/bn -> conv5_2/sep (in-place)
I0617 16:00:33.552572  8058 net.cpp:122] Setting up conv5_2/sep/bn
I0617 16:00:33.552590  8058 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 16:00:33.552599  8058 net.cpp:137] Memory required for data: 3401933400
I0617 16:00:33.552613  8058 layer_factory.hpp:77] Creating layer conv5_2/sep/scale
I0617 16:00:33.552626  8058 net.cpp:84] Creating Layer conv5_2/sep/scale
I0617 16:00:33.552635  8058 net.cpp:406] conv5_2/sep/scale <- conv5_2/sep
I0617 16:00:33.552650  8058 net.cpp:367] conv5_2/sep/scale -> conv5_2/sep (in-place)
I0617 16:00:33.552706  8058 layer_factory.hpp:77] Creating layer conv5_2/sep/scale
I0617 16:00:33.552865  8058 net.cpp:122] Setting up conv5_2/sep/scale
I0617 16:00:33.552886  8058 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 16:00:33.552894  8058 net.cpp:137] Memory required for data: 3422003800
I0617 16:00:33.552906  8058 layer_factory.hpp:77] Creating layer relu5_2/sep
I0617 16:00:33.552918  8058 net.cpp:84] Creating Layer relu5_2/sep
I0617 16:00:33.552935  8058 net.cpp:406] relu5_2/sep <- conv5_2/sep
I0617 16:00:33.552947  8058 net.cpp:367] relu5_2/sep -> conv5_2/sep (in-place)
I0617 16:00:33.553392  8058 net.cpp:122] Setting up relu5_2/sep
I0617 16:00:33.553413  8058 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 16:00:33.553422  8058 net.cpp:137] Memory required for data: 3442074200
I0617 16:00:33.553431  8058 layer_factory.hpp:77] Creating layer conv5_3/dw
I0617 16:00:33.553448  8058 net.cpp:84] Creating Layer conv5_3/dw
I0617 16:00:33.553458  8058 net.cpp:406] conv5_3/dw <- conv5_2/sep
I0617 16:00:33.553474  8058 net.cpp:380] conv5_3/dw -> conv5_3/dw
I0617 16:00:33.553699  8058 net.cpp:122] Setting up conv5_3/dw
I0617 16:00:33.553717  8058 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 16:00:33.553726  8058 net.cpp:137] Memory required for data: 3462144600
I0617 16:00:33.553736  8058 layer_factory.hpp:77] Creating layer conv5_3/dw/bn
I0617 16:00:33.553752  8058 net.cpp:84] Creating Layer conv5_3/dw/bn
I0617 16:00:33.553762  8058 net.cpp:406] conv5_3/dw/bn <- conv5_3/dw
I0617 16:00:33.553776  8058 net.cpp:367] conv5_3/dw/bn -> conv5_3/dw (in-place)
I0617 16:00:33.554020  8058 net.cpp:122] Setting up conv5_3/dw/bn
I0617 16:00:33.554038  8058 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 16:00:33.554045  8058 net.cpp:137] Memory required for data: 3482215000
I0617 16:00:33.554059  8058 layer_factory.hpp:77] Creating layer conv5_3/dw/scale
I0617 16:00:33.554072  8058 net.cpp:84] Creating Layer conv5_3/dw/scale
I0617 16:00:33.554081  8058 net.cpp:406] conv5_3/dw/scale <- conv5_3/dw
I0617 16:00:33.554095  8058 net.cpp:367] conv5_3/dw/scale -> conv5_3/dw (in-place)
I0617 16:00:33.554150  8058 layer_factory.hpp:77] Creating layer conv5_3/dw/scale
I0617 16:00:33.554319  8058 net.cpp:122] Setting up conv5_3/dw/scale
I0617 16:00:33.554337  8058 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 16:00:33.554345  8058 net.cpp:137] Memory required for data: 3502285400
I0617 16:00:33.554358  8058 layer_factory.hpp:77] Creating layer relu5_3/dw
I0617 16:00:33.554368  8058 net.cpp:84] Creating Layer relu5_3/dw
I0617 16:00:33.554378  8058 net.cpp:406] relu5_3/dw <- conv5_3/dw
I0617 16:00:33.554388  8058 net.cpp:367] relu5_3/dw -> conv5_3/dw (in-place)
I0617 16:00:33.554630  8058 net.cpp:122] Setting up relu5_3/dw
I0617 16:00:33.554651  8058 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 16:00:33.554658  8058 net.cpp:137] Memory required for data: 3522355800
I0617 16:00:33.554666  8058 layer_factory.hpp:77] Creating layer conv5_3/sep
I0617 16:00:33.554685  8058 net.cpp:84] Creating Layer conv5_3/sep
I0617 16:00:33.554695  8058 net.cpp:406] conv5_3/sep <- conv5_3/dw
I0617 16:00:33.554708  8058 net.cpp:380] conv5_3/sep -> conv5_3/sep
I0617 16:00:33.560457  8058 net.cpp:122] Setting up conv5_3/sep
I0617 16:00:33.560482  8058 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 16:00:33.560492  8058 net.cpp:137] Memory required for data: 3542426200
I0617 16:00:33.560503  8058 layer_factory.hpp:77] Creating layer conv5_3/sep/bn
I0617 16:00:33.560539  8058 net.cpp:84] Creating Layer conv5_3/sep/bn
I0617 16:00:33.560549  8058 net.cpp:406] conv5_3/sep/bn <- conv5_3/sep
I0617 16:00:33.560564  8058 net.cpp:367] conv5_3/sep/bn -> conv5_3/sep (in-place)
I0617 16:00:33.560830  8058 net.cpp:122] Setting up conv5_3/sep/bn
I0617 16:00:33.560848  8058 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 16:00:33.560858  8058 net.cpp:137] Memory required for data: 3562496600
I0617 16:00:33.560871  8058 layer_factory.hpp:77] Creating layer conv5_3/sep/scale
I0617 16:00:33.560884  8058 net.cpp:84] Creating Layer conv5_3/sep/scale
I0617 16:00:33.560894  8058 net.cpp:406] conv5_3/sep/scale <- conv5_3/sep
I0617 16:00:33.560905  8058 net.cpp:367] conv5_3/sep/scale -> conv5_3/sep (in-place)
I0617 16:00:33.560964  8058 layer_factory.hpp:77] Creating layer conv5_3/sep/scale
I0617 16:00:33.561127  8058 net.cpp:122] Setting up conv5_3/sep/scale
I0617 16:00:33.561144  8058 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 16:00:33.561152  8058 net.cpp:137] Memory required for data: 3582567000
I0617 16:00:33.561172  8058 layer_factory.hpp:77] Creating layer relu5_3/sep
I0617 16:00:33.561185  8058 net.cpp:84] Creating Layer relu5_3/sep
I0617 16:00:33.561194  8058 net.cpp:406] relu5_3/sep <- conv5_3/sep
I0617 16:00:33.561208  8058 net.cpp:367] relu5_3/sep -> conv5_3/sep (in-place)
I0617 16:00:33.561449  8058 net.cpp:122] Setting up relu5_3/sep
I0617 16:00:33.561467  8058 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 16:00:33.561476  8058 net.cpp:137] Memory required for data: 3602637400
I0617 16:00:33.561484  8058 layer_factory.hpp:77] Creating layer conv5_4/dw
I0617 16:00:33.561501  8058 net.cpp:84] Creating Layer conv5_4/dw
I0617 16:00:33.561512  8058 net.cpp:406] conv5_4/dw <- conv5_3/sep
I0617 16:00:33.561535  8058 net.cpp:380] conv5_4/dw -> conv5_4/dw
I0617 16:00:33.561750  8058 net.cpp:122] Setting up conv5_4/dw
I0617 16:00:33.561769  8058 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 16:00:33.561777  8058 net.cpp:137] Memory required for data: 3622707800
I0617 16:00:33.561787  8058 layer_factory.hpp:77] Creating layer conv5_4/dw/bn
I0617 16:00:33.561803  8058 net.cpp:84] Creating Layer conv5_4/dw/bn
I0617 16:00:33.561812  8058 net.cpp:406] conv5_4/dw/bn <- conv5_4/dw
I0617 16:00:33.561823  8058 net.cpp:367] conv5_4/dw/bn -> conv5_4/dw (in-place)
I0617 16:00:33.562077  8058 net.cpp:122] Setting up conv5_4/dw/bn
I0617 16:00:33.562094  8058 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 16:00:33.562103  8058 net.cpp:137] Memory required for data: 3642778200
I0617 16:00:33.562116  8058 layer_factory.hpp:77] Creating layer conv5_4/dw/scale
I0617 16:00:33.562134  8058 net.cpp:84] Creating Layer conv5_4/dw/scale
I0617 16:00:33.562142  8058 net.cpp:406] conv5_4/dw/scale <- conv5_4/dw
I0617 16:00:33.562153  8058 net.cpp:367] conv5_4/dw/scale -> conv5_4/dw (in-place)
I0617 16:00:33.562213  8058 layer_factory.hpp:77] Creating layer conv5_4/dw/scale
I0617 16:00:33.562376  8058 net.cpp:122] Setting up conv5_4/dw/scale
I0617 16:00:33.562393  8058 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 16:00:33.562402  8058 net.cpp:137] Memory required for data: 3662848600
I0617 16:00:33.562413  8058 layer_factory.hpp:77] Creating layer relu5_4/dw
I0617 16:00:33.562429  8058 net.cpp:84] Creating Layer relu5_4/dw
I0617 16:00:33.562438  8058 net.cpp:406] relu5_4/dw <- conv5_4/dw
I0617 16:00:33.562448  8058 net.cpp:367] relu5_4/dw -> conv5_4/dw (in-place)
I0617 16:00:33.562885  8058 net.cpp:122] Setting up relu5_4/dw
I0617 16:00:33.562908  8058 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 16:00:33.562917  8058 net.cpp:137] Memory required for data: 3682919000
I0617 16:00:33.562925  8058 layer_factory.hpp:77] Creating layer conv5_4/sep
I0617 16:00:33.562944  8058 net.cpp:84] Creating Layer conv5_4/sep
I0617 16:00:33.562954  8058 net.cpp:406] conv5_4/sep <- conv5_4/dw
I0617 16:00:33.562975  8058 net.cpp:380] conv5_4/sep -> conv5_4/sep
I0617 16:00:33.568764  8058 net.cpp:122] Setting up conv5_4/sep
I0617 16:00:33.568789  8058 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 16:00:33.568810  8058 net.cpp:137] Memory required for data: 3702989400
I0617 16:00:33.568822  8058 layer_factory.hpp:77] Creating layer conv5_4/sep/bn
I0617 16:00:33.568840  8058 net.cpp:84] Creating Layer conv5_4/sep/bn
I0617 16:00:33.568850  8058 net.cpp:406] conv5_4/sep/bn <- conv5_4/sep
I0617 16:00:33.568861  8058 net.cpp:367] conv5_4/sep/bn -> conv5_4/sep (in-place)
I0617 16:00:33.569123  8058 net.cpp:122] Setting up conv5_4/sep/bn
I0617 16:00:33.569141  8058 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 16:00:33.569149  8058 net.cpp:137] Memory required for data: 3723059800
I0617 16:00:33.569164  8058 layer_factory.hpp:77] Creating layer conv5_4/sep/scale
I0617 16:00:33.569180  8058 net.cpp:84] Creating Layer conv5_4/sep/scale
I0617 16:00:33.569190  8058 net.cpp:406] conv5_4/sep/scale <- conv5_4/sep
I0617 16:00:33.569201  8058 net.cpp:367] conv5_4/sep/scale -> conv5_4/sep (in-place)
I0617 16:00:33.569260  8058 layer_factory.hpp:77] Creating layer conv5_4/sep/scale
I0617 16:00:33.569424  8058 net.cpp:122] Setting up conv5_4/sep/scale
I0617 16:00:33.569448  8058 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 16:00:33.569458  8058 net.cpp:137] Memory required for data: 3743130200
I0617 16:00:33.569469  8058 layer_factory.hpp:77] Creating layer relu5_4/sep
I0617 16:00:33.569485  8058 net.cpp:84] Creating Layer relu5_4/sep
I0617 16:00:33.569494  8058 net.cpp:406] relu5_4/sep <- conv5_4/sep
I0617 16:00:33.569505  8058 net.cpp:367] relu5_4/sep -> conv5_4/sep (in-place)
I0617 16:00:33.569753  8058 net.cpp:122] Setting up relu5_4/sep
I0617 16:00:33.569774  8058 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 16:00:33.569783  8058 net.cpp:137] Memory required for data: 3763200600
I0617 16:00:33.569792  8058 layer_factory.hpp:77] Creating layer conv5_5/dw
I0617 16:00:33.569808  8058 net.cpp:84] Creating Layer conv5_5/dw
I0617 16:00:33.569818  8058 net.cpp:406] conv5_5/dw <- conv5_4/sep
I0617 16:00:33.569833  8058 net.cpp:380] conv5_5/dw -> conv5_5/dw
I0617 16:00:33.570050  8058 net.cpp:122] Setting up conv5_5/dw
I0617 16:00:33.570067  8058 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 16:00:33.570075  8058 net.cpp:137] Memory required for data: 3783271000
I0617 16:00:33.570086  8058 layer_factory.hpp:77] Creating layer conv5_5/dw/bn
I0617 16:00:33.570102  8058 net.cpp:84] Creating Layer conv5_5/dw/bn
I0617 16:00:33.570112  8058 net.cpp:406] conv5_5/dw/bn <- conv5_5/dw
I0617 16:00:33.570127  8058 net.cpp:367] conv5_5/dw/bn -> conv5_5/dw (in-place)
I0617 16:00:33.570374  8058 net.cpp:122] Setting up conv5_5/dw/bn
I0617 16:00:33.570391  8058 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 16:00:33.570399  8058 net.cpp:137] Memory required for data: 3803341400
I0617 16:00:33.570439  8058 layer_factory.hpp:77] Creating layer conv5_5/dw/scale
I0617 16:00:33.570462  8058 net.cpp:84] Creating Layer conv5_5/dw/scale
I0617 16:00:33.570473  8058 net.cpp:406] conv5_5/dw/scale <- conv5_5/dw
I0617 16:00:33.570485  8058 net.cpp:367] conv5_5/dw/scale -> conv5_5/dw (in-place)
I0617 16:00:33.570557  8058 layer_factory.hpp:77] Creating layer conv5_5/dw/scale
I0617 16:00:33.570720  8058 net.cpp:122] Setting up conv5_5/dw/scale
I0617 16:00:33.570737  8058 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 16:00:33.570745  8058 net.cpp:137] Memory required for data: 3823411800
I0617 16:00:33.570757  8058 layer_factory.hpp:77] Creating layer relu5_5/dw
I0617 16:00:33.570770  8058 net.cpp:84] Creating Layer relu5_5/dw
I0617 16:00:33.570778  8058 net.cpp:406] relu5_5/dw <- conv5_5/dw
I0617 16:00:33.570788  8058 net.cpp:367] relu5_5/dw -> conv5_5/dw (in-place)
I0617 16:00:33.571235  8058 net.cpp:122] Setting up relu5_5/dw
I0617 16:00:33.571256  8058 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 16:00:33.571265  8058 net.cpp:137] Memory required for data: 3843482200
I0617 16:00:33.571274  8058 layer_factory.hpp:77] Creating layer conv5_5/sep
I0617 16:00:33.571293  8058 net.cpp:84] Creating Layer conv5_5/sep
I0617 16:00:33.571305  8058 net.cpp:406] conv5_5/sep <- conv5_5/dw
I0617 16:00:33.571326  8058 net.cpp:380] conv5_5/sep -> conv5_5/sep
I0617 16:00:33.577142  8058 net.cpp:122] Setting up conv5_5/sep
I0617 16:00:33.577167  8058 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 16:00:33.577177  8058 net.cpp:137] Memory required for data: 3863552600
I0617 16:00:33.577188  8058 layer_factory.hpp:77] Creating layer conv5_5/sep/bn
I0617 16:00:33.577204  8058 net.cpp:84] Creating Layer conv5_5/sep/bn
I0617 16:00:33.577214  8058 net.cpp:406] conv5_5/sep/bn <- conv5_5/sep
I0617 16:00:33.577225  8058 net.cpp:367] conv5_5/sep/bn -> conv5_5/sep (in-place)
I0617 16:00:33.577495  8058 net.cpp:122] Setting up conv5_5/sep/bn
I0617 16:00:33.577520  8058 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 16:00:33.577531  8058 net.cpp:137] Memory required for data: 3883623000
I0617 16:00:33.577545  8058 layer_factory.hpp:77] Creating layer conv5_5/sep/scale
I0617 16:00:33.577559  8058 net.cpp:84] Creating Layer conv5_5/sep/scale
I0617 16:00:33.577569  8058 net.cpp:406] conv5_5/sep/scale <- conv5_5/sep
I0617 16:00:33.577587  8058 net.cpp:367] conv5_5/sep/scale -> conv5_5/sep (in-place)
I0617 16:00:33.577651  8058 layer_factory.hpp:77] Creating layer conv5_5/sep/scale
I0617 16:00:33.577814  8058 net.cpp:122] Setting up conv5_5/sep/scale
I0617 16:00:33.577831  8058 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 16:00:33.577841  8058 net.cpp:137] Memory required for data: 3903693400
I0617 16:00:33.577852  8058 layer_factory.hpp:77] Creating layer relu5_5/sep
I0617 16:00:33.577867  8058 net.cpp:84] Creating Layer relu5_5/sep
I0617 16:00:33.577877  8058 net.cpp:406] relu5_5/sep <- conv5_5/sep
I0617 16:00:33.577888  8058 net.cpp:367] relu5_5/sep -> conv5_5/sep (in-place)
I0617 16:00:33.578150  8058 net.cpp:122] Setting up relu5_5/sep
I0617 16:00:33.578169  8058 net.cpp:129] Top shape: 50 512 14 14 (5017600)
I0617 16:00:33.578177  8058 net.cpp:137] Memory required for data: 3923763800
I0617 16:00:33.578186  8058 layer_factory.hpp:77] Creating layer conv5_6/dw
I0617 16:00:33.578202  8058 net.cpp:84] Creating Layer conv5_6/dw
I0617 16:00:33.578213  8058 net.cpp:406] conv5_6/dw <- conv5_5/sep
I0617 16:00:33.578228  8058 net.cpp:380] conv5_6/dw -> conv5_6/dw
I0617 16:00:33.578440  8058 net.cpp:122] Setting up conv5_6/dw
I0617 16:00:33.578459  8058 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0617 16:00:33.578466  8058 net.cpp:137] Memory required for data: 3928781400
I0617 16:00:33.578477  8058 layer_factory.hpp:77] Creating layer conv5_6/dw/bn
I0617 16:00:33.578493  8058 net.cpp:84] Creating Layer conv5_6/dw/bn
I0617 16:00:33.578503  8058 net.cpp:406] conv5_6/dw/bn <- conv5_6/dw
I0617 16:00:33.578521  8058 net.cpp:367] conv5_6/dw/bn -> conv5_6/dw (in-place)
I0617 16:00:33.578786  8058 net.cpp:122] Setting up conv5_6/dw/bn
I0617 16:00:33.578804  8058 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0617 16:00:33.578811  8058 net.cpp:137] Memory required for data: 3933799000
I0617 16:00:33.578825  8058 layer_factory.hpp:77] Creating layer conv5_6/dw/scale
I0617 16:00:33.578838  8058 net.cpp:84] Creating Layer conv5_6/dw/scale
I0617 16:00:33.578847  8058 net.cpp:406] conv5_6/dw/scale <- conv5_6/dw
I0617 16:00:33.578858  8058 net.cpp:367] conv5_6/dw/scale -> conv5_6/dw (in-place)
I0617 16:00:33.578917  8058 layer_factory.hpp:77] Creating layer conv5_6/dw/scale
I0617 16:00:33.579083  8058 net.cpp:122] Setting up conv5_6/dw/scale
I0617 16:00:33.579100  8058 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0617 16:00:33.579108  8058 net.cpp:137] Memory required for data: 3938816600
I0617 16:00:33.579120  8058 layer_factory.hpp:77] Creating layer relu5_6/dw
I0617 16:00:33.579135  8058 net.cpp:84] Creating Layer relu5_6/dw
I0617 16:00:33.579144  8058 net.cpp:406] relu5_6/dw <- conv5_6/dw
I0617 16:00:33.579154  8058 net.cpp:367] relu5_6/dw -> conv5_6/dw (in-place)
I0617 16:00:33.579608  8058 net.cpp:122] Setting up relu5_6/dw
I0617 16:00:33.579635  8058 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0617 16:00:33.579645  8058 net.cpp:137] Memory required for data: 3943834200
I0617 16:00:33.579654  8058 layer_factory.hpp:77] Creating layer conv5_6/sep
I0617 16:00:33.579680  8058 net.cpp:84] Creating Layer conv5_6/sep
I0617 16:00:33.579691  8058 net.cpp:406] conv5_6/sep <- conv5_6/dw
I0617 16:00:33.579710  8058 net.cpp:380] conv5_6/sep -> conv5_6/sep
I0617 16:00:33.590677  8058 net.cpp:122] Setting up conv5_6/sep
I0617 16:00:33.590737  8058 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0617 16:00:33.590749  8058 net.cpp:137] Memory required for data: 3953869400
I0617 16:00:33.590764  8058 layer_factory.hpp:77] Creating layer conv5_6/sep/bn
I0617 16:00:33.590788  8058 net.cpp:84] Creating Layer conv5_6/sep/bn
I0617 16:00:33.590801  8058 net.cpp:406] conv5_6/sep/bn <- conv5_6/sep
I0617 16:00:33.590817  8058 net.cpp:367] conv5_6/sep/bn -> conv5_6/sep (in-place)
I0617 16:00:33.591105  8058 net.cpp:122] Setting up conv5_6/sep/bn
I0617 16:00:33.591123  8058 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0617 16:00:33.591131  8058 net.cpp:137] Memory required for data: 3963904600
I0617 16:00:33.591146  8058 layer_factory.hpp:77] Creating layer conv5_6/sep/scale
I0617 16:00:33.591176  8058 net.cpp:84] Creating Layer conv5_6/sep/scale
I0617 16:00:33.591186  8058 net.cpp:406] conv5_6/sep/scale <- conv5_6/sep
I0617 16:00:33.591203  8058 net.cpp:367] conv5_6/sep/scale -> conv5_6/sep (in-place)
I0617 16:00:33.591267  8058 layer_factory.hpp:77] Creating layer conv5_6/sep/scale
I0617 16:00:33.591440  8058 net.cpp:122] Setting up conv5_6/sep/scale
I0617 16:00:33.591461  8058 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0617 16:00:33.591470  8058 net.cpp:137] Memory required for data: 3973939800
I0617 16:00:33.591482  8058 layer_factory.hpp:77] Creating layer relu5_6/sep
I0617 16:00:33.591495  8058 net.cpp:84] Creating Layer relu5_6/sep
I0617 16:00:33.591505  8058 net.cpp:406] relu5_6/sep <- conv5_6/sep
I0617 16:00:33.591536  8058 net.cpp:367] relu5_6/sep -> conv5_6/sep (in-place)
I0617 16:00:33.591792  8058 net.cpp:122] Setting up relu5_6/sep
I0617 16:00:33.591815  8058 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0617 16:00:33.591825  8058 net.cpp:137] Memory required for data: 3983975000
I0617 16:00:33.591833  8058 layer_factory.hpp:77] Creating layer conv6/dw
I0617 16:00:33.591850  8058 net.cpp:84] Creating Layer conv6/dw
I0617 16:00:33.591859  8058 net.cpp:406] conv6/dw <- conv5_6/sep
I0617 16:00:33.591874  8058 net.cpp:380] conv6/dw -> conv6/dw
I0617 16:00:33.592181  8058 net.cpp:122] Setting up conv6/dw
I0617 16:00:33.592200  8058 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0617 16:00:33.592208  8058 net.cpp:137] Memory required for data: 3994010200
I0617 16:00:33.592219  8058 layer_factory.hpp:77] Creating layer conv6/dw/bn
I0617 16:00:33.592232  8058 net.cpp:84] Creating Layer conv6/dw/bn
I0617 16:00:33.592242  8058 net.cpp:406] conv6/dw/bn <- conv6/dw
I0617 16:00:33.592255  8058 net.cpp:367] conv6/dw/bn -> conv6/dw (in-place)
I0617 16:00:33.592538  8058 net.cpp:122] Setting up conv6/dw/bn
I0617 16:00:33.592557  8058 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0617 16:00:33.592566  8058 net.cpp:137] Memory required for data: 4004045400
I0617 16:00:33.592581  8058 layer_factory.hpp:77] Creating layer conv6/dw/scale
I0617 16:00:33.592593  8058 net.cpp:84] Creating Layer conv6/dw/scale
I0617 16:00:33.592602  8058 net.cpp:406] conv6/dw/scale <- conv6/dw
I0617 16:00:33.592613  8058 net.cpp:367] conv6/dw/scale -> conv6/dw (in-place)
I0617 16:00:33.592676  8058 layer_factory.hpp:77] Creating layer conv6/dw/scale
I0617 16:00:33.592854  8058 net.cpp:122] Setting up conv6/dw/scale
I0617 16:00:33.592872  8058 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0617 16:00:33.592880  8058 net.cpp:137] Memory required for data: 4014080600
I0617 16:00:33.592892  8058 layer_factory.hpp:77] Creating layer relu6/dw
I0617 16:00:33.592905  8058 net.cpp:84] Creating Layer relu6/dw
I0617 16:00:33.592913  8058 net.cpp:406] relu6/dw <- conv6/dw
I0617 16:00:33.592927  8058 net.cpp:367] relu6/dw -> conv6/dw (in-place)
I0617 16:00:33.593387  8058 net.cpp:122] Setting up relu6/dw
I0617 16:00:33.593408  8058 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0617 16:00:33.593417  8058 net.cpp:137] Memory required for data: 4024115800
I0617 16:00:33.593446  8058 layer_factory.hpp:77] Creating layer conv6/sep
I0617 16:00:33.593468  8058 net.cpp:84] Creating Layer conv6/sep
I0617 16:00:33.593478  8058 net.cpp:406] conv6/sep <- conv6/dw
I0617 16:00:33.593492  8058 net.cpp:380] conv6/sep -> conv6/sep
I0617 16:00:33.612289  8058 net.cpp:122] Setting up conv6/sep
I0617 16:00:33.612337  8058 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0617 16:00:33.612347  8058 net.cpp:137] Memory required for data: 4034151000
I0617 16:00:33.612361  8058 layer_factory.hpp:77] Creating layer conv6/sep/bn
I0617 16:00:33.612382  8058 net.cpp:84] Creating Layer conv6/sep/bn
I0617 16:00:33.612395  8058 net.cpp:406] conv6/sep/bn <- conv6/sep
I0617 16:00:33.612411  8058 net.cpp:367] conv6/sep/bn -> conv6/sep (in-place)
I0617 16:00:33.613828  8058 net.cpp:122] Setting up conv6/sep/bn
I0617 16:00:33.613870  8058 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0617 16:00:33.613880  8058 net.cpp:137] Memory required for data: 4044186200
I0617 16:00:33.613907  8058 layer_factory.hpp:77] Creating layer conv6/sep/scale
I0617 16:00:33.613929  8058 net.cpp:84] Creating Layer conv6/sep/scale
I0617 16:00:33.613940  8058 net.cpp:406] conv6/sep/scale <- conv6/sep
I0617 16:00:33.613955  8058 net.cpp:367] conv6/sep/scale -> conv6/sep (in-place)
I0617 16:00:33.614024  8058 layer_factory.hpp:77] Creating layer conv6/sep/scale
I0617 16:00:33.614202  8058 net.cpp:122] Setting up conv6/sep/scale
I0617 16:00:33.614218  8058 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0617 16:00:33.614228  8058 net.cpp:137] Memory required for data: 4054221400
I0617 16:00:33.614239  8058 layer_factory.hpp:77] Creating layer relu6/sep
I0617 16:00:33.614251  8058 net.cpp:84] Creating Layer relu6/sep
I0617 16:00:33.614260  8058 net.cpp:406] relu6/sep <- conv6/sep
I0617 16:00:33.614271  8058 net.cpp:367] relu6/sep -> conv6/sep (in-place)
I0617 16:00:33.614843  8058 net.cpp:122] Setting up relu6/sep
I0617 16:00:33.614866  8058 net.cpp:129] Top shape: 50 1024 7 7 (2508800)
I0617 16:00:33.614876  8058 net.cpp:137] Memory required for data: 4064256600
I0617 16:00:33.614884  8058 layer_factory.hpp:77] Creating layer pool6
I0617 16:00:33.614900  8058 net.cpp:84] Creating Layer pool6
I0617 16:00:33.614910  8058 net.cpp:406] pool6 <- conv6/sep
I0617 16:00:33.614924  8058 net.cpp:380] pool6 -> pool6
I0617 16:00:33.615239  8058 net.cpp:122] Setting up pool6
I0617 16:00:33.615259  8058 net.cpp:129] Top shape: 50 1024 1 1 (51200)
I0617 16:00:33.615268  8058 net.cpp:137] Memory required for data: 4064461400
I0617 16:00:33.615276  8058 layer_factory.hpp:77] Creating layer fc7_oxford
I0617 16:00:33.615298  8058 net.cpp:84] Creating Layer fc7_oxford
I0617 16:00:33.615309  8058 net.cpp:406] fc7_oxford <- pool6
I0617 16:00:33.615324  8058 net.cpp:380] fc7_oxford -> fc7
I0617 16:00:33.620420  8058 net.cpp:122] Setting up fc7_oxford
I0617 16:00:33.620447  8058 net.cpp:129] Top shape: 50 200 1 1 (10000)
I0617 16:00:33.620456  8058 net.cpp:137] Memory required for data: 4064501400
I0617 16:00:33.620471  8058 layer_factory.hpp:77] Creating layer fc7_fc7_oxford_0_split
I0617 16:00:33.620483  8058 net.cpp:84] Creating Layer fc7_fc7_oxford_0_split
I0617 16:00:33.620492  8058 net.cpp:406] fc7_fc7_oxford_0_split <- fc7
I0617 16:00:33.620507  8058 net.cpp:380] fc7_fc7_oxford_0_split -> fc7_fc7_oxford_0_split_0
I0617 16:00:33.620532  8058 net.cpp:380] fc7_fc7_oxford_0_split -> fc7_fc7_oxford_0_split_1
I0617 16:00:33.620597  8058 net.cpp:122] Setting up fc7_fc7_oxford_0_split
I0617 16:00:33.620615  8058 net.cpp:129] Top shape: 50 200 1 1 (10000)
I0617 16:00:33.620625  8058 net.cpp:129] Top shape: 50 200 1 1 (10000)
I0617 16:00:33.620632  8058 net.cpp:137] Memory required for data: 4064581400
I0617 16:00:33.620641  8058 layer_factory.hpp:77] Creating layer accuracy
I0617 16:00:33.620659  8058 net.cpp:84] Creating Layer accuracy
I0617 16:00:33.620669  8058 net.cpp:406] accuracy <- fc7_fc7_oxford_0_split_0
I0617 16:00:33.620679  8058 net.cpp:406] accuracy <- label_data_1_split_0
I0617 16:00:33.620693  8058 net.cpp:380] accuracy -> accuracy
I0617 16:00:33.620730  8058 net.cpp:122] Setting up accuracy
I0617 16:00:33.620743  8058 net.cpp:129] Top shape: (1)
I0617 16:00:33.620751  8058 net.cpp:137] Memory required for data: 4064581404
I0617 16:00:33.620759  8058 layer_factory.hpp:77] Creating layer loss
I0617 16:00:33.620774  8058 net.cpp:84] Creating Layer loss
I0617 16:00:33.620782  8058 net.cpp:406] loss <- fc7_fc7_oxford_0_split_1
I0617 16:00:33.620791  8058 net.cpp:406] loss <- label_data_1_split_1
I0617 16:00:33.620802  8058 net.cpp:380] loss -> loss
I0617 16:00:33.620821  8058 layer_factory.hpp:77] Creating layer loss
I0617 16:00:33.621450  8058 net.cpp:122] Setting up loss
I0617 16:00:33.621472  8058 net.cpp:129] Top shape: (1)
I0617 16:00:33.621481  8058 net.cpp:132]     with loss weight 1
I0617 16:00:33.621546  8058 net.cpp:137] Memory required for data: 4064581408
I0617 16:00:33.621556  8058 net.cpp:198] loss needs backward computation.
I0617 16:00:33.621567  8058 net.cpp:200] accuracy does not need backward computation.
I0617 16:00:33.621582  8058 net.cpp:198] fc7_fc7_oxford_0_split needs backward computation.
I0617 16:00:33.621592  8058 net.cpp:198] fc7_oxford needs backward computation.
I0617 16:00:33.621599  8058 net.cpp:198] pool6 needs backward computation.
I0617 16:00:33.621608  8058 net.cpp:198] relu6/sep needs backward computation.
I0617 16:00:33.621615  8058 net.cpp:198] conv6/sep/scale needs backward computation.
I0617 16:00:33.621623  8058 net.cpp:198] conv6/sep/bn needs backward computation.
I0617 16:00:33.621631  8058 net.cpp:198] conv6/sep needs backward computation.
I0617 16:00:33.621639  8058 net.cpp:198] relu6/dw needs backward computation.
I0617 16:00:33.621647  8058 net.cpp:198] conv6/dw/scale needs backward computation.
I0617 16:00:33.621656  8058 net.cpp:198] conv6/dw/bn needs backward computation.
I0617 16:00:33.621664  8058 net.cpp:198] conv6/dw needs backward computation.
I0617 16:00:33.621671  8058 net.cpp:198] relu5_6/sep needs backward computation.
I0617 16:00:33.621680  8058 net.cpp:198] conv5_6/sep/scale needs backward computation.
I0617 16:00:33.621687  8058 net.cpp:198] conv5_6/sep/bn needs backward computation.
I0617 16:00:33.621695  8058 net.cpp:198] conv5_6/sep needs backward computation.
I0617 16:00:33.621703  8058 net.cpp:198] relu5_6/dw needs backward computation.
I0617 16:00:33.621712  8058 net.cpp:198] conv5_6/dw/scale needs backward computation.
I0617 16:00:33.621721  8058 net.cpp:198] conv5_6/dw/bn needs backward computation.
I0617 16:00:33.621727  8058 net.cpp:198] conv5_6/dw needs backward computation.
I0617 16:00:33.621736  8058 net.cpp:198] relu5_5/sep needs backward computation.
I0617 16:00:33.621743  8058 net.cpp:198] conv5_5/sep/scale needs backward computation.
I0617 16:00:33.621752  8058 net.cpp:198] conv5_5/sep/bn needs backward computation.
I0617 16:00:33.621759  8058 net.cpp:198] conv5_5/sep needs backward computation.
I0617 16:00:33.621767  8058 net.cpp:198] relu5_5/dw needs backward computation.
I0617 16:00:33.621775  8058 net.cpp:198] conv5_5/dw/scale needs backward computation.
I0617 16:00:33.621783  8058 net.cpp:198] conv5_5/dw/bn needs backward computation.
I0617 16:00:33.621790  8058 net.cpp:198] conv5_5/dw needs backward computation.
I0617 16:00:33.621798  8058 net.cpp:198] relu5_4/sep needs backward computation.
I0617 16:00:33.621806  8058 net.cpp:198] conv5_4/sep/scale needs backward computation.
I0617 16:00:33.621814  8058 net.cpp:198] conv5_4/sep/bn needs backward computation.
I0617 16:00:33.621822  8058 net.cpp:198] conv5_4/sep needs backward computation.
I0617 16:00:33.621830  8058 net.cpp:198] relu5_4/dw needs backward computation.
I0617 16:00:33.621839  8058 net.cpp:198] conv5_4/dw/scale needs backward computation.
I0617 16:00:33.621846  8058 net.cpp:198] conv5_4/dw/bn needs backward computation.
I0617 16:00:33.621853  8058 net.cpp:198] conv5_4/dw needs backward computation.
I0617 16:00:33.621861  8058 net.cpp:198] relu5_3/sep needs backward computation.
I0617 16:00:33.621870  8058 net.cpp:198] conv5_3/sep/scale needs backward computation.
I0617 16:00:33.621887  8058 net.cpp:198] conv5_3/sep/bn needs backward computation.
I0617 16:00:33.621896  8058 net.cpp:198] conv5_3/sep needs backward computation.
I0617 16:00:33.621904  8058 net.cpp:198] relu5_3/dw needs backward computation.
I0617 16:00:33.621912  8058 net.cpp:198] conv5_3/dw/scale needs backward computation.
I0617 16:00:33.621920  8058 net.cpp:198] conv5_3/dw/bn needs backward computation.
I0617 16:00:33.621928  8058 net.cpp:198] conv5_3/dw needs backward computation.
I0617 16:00:33.621937  8058 net.cpp:198] relu5_2/sep needs backward computation.
I0617 16:00:33.621944  8058 net.cpp:198] conv5_2/sep/scale needs backward computation.
I0617 16:00:33.621953  8058 net.cpp:198] conv5_2/sep/bn needs backward computation.
I0617 16:00:33.621960  8058 net.cpp:198] conv5_2/sep needs backward computation.
I0617 16:00:33.621968  8058 net.cpp:198] relu5_2/dw needs backward computation.
I0617 16:00:33.621976  8058 net.cpp:198] conv5_2/dw/scale needs backward computation.
I0617 16:00:33.621984  8058 net.cpp:198] conv5_2/dw/bn needs backward computation.
I0617 16:00:33.621997  8058 net.cpp:198] conv5_2/dw needs backward computation.
I0617 16:00:33.622005  8058 net.cpp:198] relu5_1/sep needs backward computation.
I0617 16:00:33.622014  8058 net.cpp:198] conv5_1/sep/scale needs backward computation.
I0617 16:00:33.622021  8058 net.cpp:198] conv5_1/sep/bn needs backward computation.
I0617 16:00:33.622030  8058 net.cpp:198] conv5_1/sep needs backward computation.
I0617 16:00:33.622037  8058 net.cpp:198] relu5_1/dw needs backward computation.
I0617 16:00:33.622045  8058 net.cpp:198] conv5_1/dw/scale needs backward computation.
I0617 16:00:33.622053  8058 net.cpp:198] conv5_1/dw/bn needs backward computation.
I0617 16:00:33.622061  8058 net.cpp:198] conv5_1/dw needs backward computation.
I0617 16:00:33.622069  8058 net.cpp:198] relu4_2/sep needs backward computation.
I0617 16:00:33.622077  8058 net.cpp:198] conv4_2/sep/scale needs backward computation.
I0617 16:00:33.622084  8058 net.cpp:198] conv4_2/sep/bn needs backward computation.
I0617 16:00:33.622092  8058 net.cpp:198] conv4_2/sep needs backward computation.
I0617 16:00:33.622102  8058 net.cpp:198] relu4_2/dw needs backward computation.
I0617 16:00:33.622108  8058 net.cpp:198] conv4_2/dw/scale needs backward computation.
I0617 16:00:33.622117  8058 net.cpp:198] conv4_2/dw/bn needs backward computation.
I0617 16:00:33.622124  8058 net.cpp:198] conv4_2/dw needs backward computation.
I0617 16:00:33.622133  8058 net.cpp:198] relu4_1/sep needs backward computation.
I0617 16:00:33.622140  8058 net.cpp:198] conv4_1/sep/scale needs backward computation.
I0617 16:00:33.622148  8058 net.cpp:198] conv4_1/sep/bn needs backward computation.
I0617 16:00:33.622155  8058 net.cpp:198] conv4_1/sep needs backward computation.
I0617 16:00:33.622164  8058 net.cpp:198] relu4_1/dw needs backward computation.
I0617 16:00:33.622171  8058 net.cpp:198] conv4_1/dw/scale needs backward computation.
I0617 16:00:33.622179  8058 net.cpp:198] conv4_1/dw/bn needs backward computation.
I0617 16:00:33.622186  8058 net.cpp:198] conv4_1/dw needs backward computation.
I0617 16:00:33.622195  8058 net.cpp:198] relu3_2/sep needs backward computation.
I0617 16:00:33.622202  8058 net.cpp:198] conv3_2/sep/scale needs backward computation.
I0617 16:00:33.622210  8058 net.cpp:198] conv3_2/sep/bn needs backward computation.
I0617 16:00:33.622217  8058 net.cpp:198] conv3_2/sep needs backward computation.
I0617 16:00:33.622225  8058 net.cpp:198] relu3_2/dw needs backward computation.
I0617 16:00:33.622233  8058 net.cpp:198] conv3_2/dw/scale needs backward computation.
I0617 16:00:33.622241  8058 net.cpp:198] conv3_2/dw/bn needs backward computation.
I0617 16:00:33.622248  8058 net.cpp:198] conv3_2/dw needs backward computation.
I0617 16:00:33.622256  8058 net.cpp:198] relu3_1/sep needs backward computation.
I0617 16:00:33.622264  8058 net.cpp:198] conv3_1/sep/scale needs backward computation.
I0617 16:00:33.622272  8058 net.cpp:198] conv3_1/sep/bn needs backward computation.
I0617 16:00:33.622280  8058 net.cpp:198] conv3_1/sep needs backward computation.
I0617 16:00:33.622297  8058 net.cpp:198] relu3_1/dw needs backward computation.
I0617 16:00:33.622304  8058 net.cpp:198] conv3_1/dw/scale needs backward computation.
I0617 16:00:33.622313  8058 net.cpp:198] conv3_1/dw/bn needs backward computation.
I0617 16:00:33.622320  8058 net.cpp:198] conv3_1/dw needs backward computation.
I0617 16:00:33.622328  8058 net.cpp:198] relu2_2/sep needs backward computation.
I0617 16:00:33.622336  8058 net.cpp:198] conv2_2/sep/scale needs backward computation.
I0617 16:00:33.622344  8058 net.cpp:198] conv2_2/sep/bn needs backward computation.
I0617 16:00:33.622351  8058 net.cpp:198] conv2_2/sep needs backward computation.
I0617 16:00:33.622359  8058 net.cpp:198] relu2_2/dw needs backward computation.
I0617 16:00:33.622367  8058 net.cpp:198] conv2_2/dw/scale needs backward computation.
I0617 16:00:33.622375  8058 net.cpp:198] conv2_2/dw/bn needs backward computation.
I0617 16:00:33.622382  8058 net.cpp:198] conv2_2/dw needs backward computation.
I0617 16:00:33.622401  8058 net.cpp:198] relu2_1/sep needs backward computation.
I0617 16:00:33.622411  8058 net.cpp:198] conv2_1/sep/scale needs backward computation.
I0617 16:00:33.622418  8058 net.cpp:198] conv2_1/sep/bn needs backward computation.
I0617 16:00:33.622426  8058 net.cpp:198] conv2_1/sep needs backward computation.
I0617 16:00:33.622434  8058 net.cpp:198] relu2_1/dw needs backward computation.
I0617 16:00:33.622442  8058 net.cpp:198] conv2_1/dw/scale needs backward computation.
I0617 16:00:33.622450  8058 net.cpp:198] conv2_1/dw/bn needs backward computation.
I0617 16:00:33.622458  8058 net.cpp:198] conv2_1/dw needs backward computation.
I0617 16:00:33.622467  8058 net.cpp:198] relu1 needs backward computation.
I0617 16:00:33.622474  8058 net.cpp:198] conv1/scale needs backward computation.
I0617 16:00:33.622481  8058 net.cpp:198] conv1/bn needs backward computation.
I0617 16:00:33.622489  8058 net.cpp:198] conv1 needs backward computation.
I0617 16:00:33.622498  8058 net.cpp:200] label_data_1_split does not need backward computation.
I0617 16:00:33.622508  8058 net.cpp:200] data does not need backward computation.
I0617 16:00:33.622520  8058 net.cpp:242] This network produces output accuracy
I0617 16:00:33.622530  8058 net.cpp:242] This network produces output loss
I0617 16:00:33.622606  8058 net.cpp:255] Network initialization done.
I0617 16:00:33.622952  8058 solver.cpp:56] Solver scaffolding done.
I0617 16:00:33.630630  8058 caffe.cpp:248] Starting Optimization
I0617 16:00:33.630651  8058 solver.cpp:272] Solving MOBILENET
I0617 16:00:33.630659  8058 solver.cpp:273] Learning Rate Policy: step
I0617 16:00:34.846998  8058 solver.cpp:218] Iteration 0 (0 iter/s, 1.21624s/50 iters), loss = 5.34938
I0617 16:00:34.847232  8058 solver.cpp:237]     Train net output #0: accuracy = 0.02
I0617 16:00:34.847266  8058 solver.cpp:237]     Train net output #1: loss = 5.34938 (* 1 = 5.34938 loss)
I0617 16:00:34.847337  8058 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I0617 16:01:32.673558  8058 solver.cpp:218] Iteration 50 (0.864661 iter/s, 57.8261s/50 iters), loss = 5.30214
I0617 16:01:32.673769  8058 solver.cpp:237]     Train net output #0: accuracy = 0.02
I0617 16:01:32.673806  8058 solver.cpp:237]     Train net output #1: loss = 5.30214 (* 1 = 5.30214 loss)
I0617 16:01:32.673827  8058 sgd_solver.cpp:105] Iteration 50, lr = 0.01
I0617 16:02:30.483428  8058 solver.cpp:218] Iteration 100 (0.864914 iter/s, 57.8092s/50 iters), loss = 5.3697
I0617 16:02:30.483613  8058 solver.cpp:237]     Train net output #0: accuracy = 0.02
I0617 16:02:30.483651  8058 solver.cpp:237]     Train net output #1: loss = 5.3697 (* 1 = 5.3697 loss)
I0617 16:02:30.483676  8058 sgd_solver.cpp:105] Iteration 100, lr = 0.01
I0617 16:02:47.933343  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 16:03:28.274590  8058 solver.cpp:218] Iteration 150 (0.865195 iter/s, 57.7905s/50 iters), loss = 5.26319
I0617 16:03:28.274808  8058 solver.cpp:237]     Train net output #0: accuracy = 0
I0617 16:03:28.274845  8058 solver.cpp:237]     Train net output #1: loss = 5.26319 (* 1 = 5.26319 loss)
I0617 16:03:28.274863  8058 sgd_solver.cpp:105] Iteration 150, lr = 0.01
I0617 16:04:26.053823  8058 solver.cpp:218] Iteration 200 (0.865374 iter/s, 57.7785s/50 iters), loss = 5.431
I0617 16:04:26.053956  8058 solver.cpp:237]     Train net output #0: accuracy = 0
I0617 16:04:26.053995  8058 solver.cpp:237]     Train net output #1: loss = 5.431 (* 1 = 5.431 loss)
I0617 16:04:26.054018  8058 sgd_solver.cpp:105] Iteration 200, lr = 0.01
I0617 16:05:06.594698  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 16:05:23.826584  8058 solver.cpp:218] Iteration 250 (0.86547 iter/s, 57.7721s/50 iters), loss = 5.24427
I0617 16:05:23.826673  8058 solver.cpp:237]     Train net output #0: accuracy = 0
I0617 16:05:23.826701  8058 solver.cpp:237]     Train net output #1: loss = 5.24427 (* 1 = 5.24427 loss)
I0617 16:05:23.826721  8058 sgd_solver.cpp:105] Iteration 250, lr = 0.01
I0617 16:06:21.602105  8058 solver.cpp:218] Iteration 300 (0.865428 iter/s, 57.7749s/50 iters), loss = 5.10806
I0617 16:06:21.602260  8058 solver.cpp:237]     Train net output #0: accuracy = 0.02
I0617 16:06:21.602291  8058 solver.cpp:237]     Train net output #1: loss = 5.10806 (* 1 = 5.10806 loss)
I0617 16:06:21.602311  8058 sgd_solver.cpp:105] Iteration 300, lr = 0.01
I0617 16:07:19.376408  8058 solver.cpp:218] Iteration 350 (0.865447 iter/s, 57.7736s/50 iters), loss = 5.1351
I0617 16:07:19.376601  8058 solver.cpp:237]     Train net output #0: accuracy = 0.02
I0617 16:07:19.376638  8058 solver.cpp:237]     Train net output #1: loss = 5.1351 (* 1 = 5.1351 loss)
I0617 16:07:19.376662  8058 sgd_solver.cpp:105] Iteration 350, lr = 0.01
I0617 16:07:25.220896  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 16:08:17.175894  8058 solver.cpp:218] Iteration 400 (0.865071 iter/s, 57.7987s/50 iters), loss = 4.94309
I0617 16:08:17.176017  8058 solver.cpp:237]     Train net output #0: accuracy = 0.04
I0617 16:08:17.176051  8058 solver.cpp:237]     Train net output #1: loss = 4.94309 (* 1 = 4.94309 loss)
I0617 16:08:17.176071  8058 sgd_solver.cpp:105] Iteration 400, lr = 0.01
I0617 16:09:14.953902  8058 solver.cpp:218] Iteration 450 (0.865391 iter/s, 57.7773s/50 iters), loss = 4.99059
I0617 16:09:14.954044  8058 solver.cpp:237]     Train net output #0: accuracy = 0
I0617 16:09:14.954078  8058 solver.cpp:237]     Train net output #1: loss = 4.99059 (* 1 = 4.99059 loss)
I0617 16:09:14.954099  8058 sgd_solver.cpp:105] Iteration 450, lr = 0.01
I0617 16:09:43.930930  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 16:10:12.724422  8058 solver.cpp:218] Iteration 500 (0.865504 iter/s, 57.7698s/50 iters), loss = 5.17223
I0617 16:10:12.724553  8058 solver.cpp:237]     Train net output #0: accuracy = 0
I0617 16:10:12.724588  8058 solver.cpp:237]     Train net output #1: loss = 5.17223 (* 1 = 5.17223 loss)
I0617 16:10:12.724609  8058 sgd_solver.cpp:105] Iteration 500, lr = 0.01
I0617 16:11:10.506294  8058 solver.cpp:218] Iteration 550 (0.865334 iter/s, 57.7812s/50 iters), loss = 4.96427
I0617 16:11:10.506438  8058 solver.cpp:237]     Train net output #0: accuracy = 0.02
I0617 16:11:10.506474  8058 solver.cpp:237]     Train net output #1: loss = 4.96427 (* 1 = 4.96427 loss)
I0617 16:11:10.506498  8058 sgd_solver.cpp:105] Iteration 550, lr = 0.01
I0617 16:12:02.587996  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 16:12:08.277611  8058 solver.cpp:218] Iteration 600 (0.865492 iter/s, 57.7706s/50 iters), loss = 4.86742
I0617 16:12:08.277698  8058 solver.cpp:237]     Train net output #0: accuracy = 0.06
I0617 16:12:08.277727  8058 solver.cpp:237]     Train net output #1: loss = 4.86742 (* 1 = 4.86742 loss)
I0617 16:12:08.277747  8058 sgd_solver.cpp:105] Iteration 600, lr = 0.01
I0617 16:13:06.057245  8058 solver.cpp:218] Iteration 650 (0.865367 iter/s, 57.779s/50 iters), loss = 4.93774
I0617 16:13:06.057454  8058 solver.cpp:237]     Train net output #0: accuracy = 0.06
I0617 16:13:06.057489  8058 solver.cpp:237]     Train net output #1: loss = 4.93774 (* 1 = 4.93774 loss)
I0617 16:13:06.057510  8058 sgd_solver.cpp:105] Iteration 650, lr = 0.01
I0617 16:14:03.816797  8058 solver.cpp:218] Iteration 700 (0.865669 iter/s, 57.7588s/50 iters), loss = 4.77204
I0617 16:14:03.816926  8058 solver.cpp:237]     Train net output #0: accuracy = 0.04
I0617 16:14:03.816962  8058 solver.cpp:237]     Train net output #1: loss = 4.77204 (* 1 = 4.77204 loss)
I0617 16:14:03.816982  8058 sgd_solver.cpp:105] Iteration 700, lr = 0.01
I0617 16:14:21.233785  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 16:15:01.584471  8058 solver.cpp:218] Iteration 750 (0.865547 iter/s, 57.767s/50 iters), loss = 4.77616
I0617 16:15:01.593803  8058 solver.cpp:237]     Train net output #0: accuracy = 0.02
I0617 16:15:01.593842  8058 solver.cpp:237]     Train net output #1: loss = 4.77616 (* 1 = 4.77616 loss)
I0617 16:15:01.593864  8058 sgd_solver.cpp:105] Iteration 750, lr = 0.01
I0617 16:15:59.353374  8058 solver.cpp:218] Iteration 800 (0.865665 iter/s, 57.7591s/50 iters), loss = 4.58131
I0617 16:15:59.353536  8058 solver.cpp:237]     Train net output #0: accuracy = 0.04
I0617 16:15:59.353571  8058 solver.cpp:237]     Train net output #1: loss = 4.58131 (* 1 = 4.58131 loss)
I0617 16:15:59.353591  8058 sgd_solver.cpp:105] Iteration 800, lr = 0.01
I0617 16:16:39.842711  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 16:16:57.117943  8058 solver.cpp:218] Iteration 850 (0.865592 iter/s, 57.7639s/50 iters), loss = 4.58403
I0617 16:16:57.118041  8058 solver.cpp:237]     Train net output #0: accuracy = 0.08
I0617 16:16:57.118073  8058 solver.cpp:237]     Train net output #1: loss = 4.58403 (* 1 = 4.58403 loss)
I0617 16:16:57.118094  8058 sgd_solver.cpp:105] Iteration 850, lr = 0.01
I0617 16:17:54.890357  8058 solver.cpp:218] Iteration 900 (0.865473 iter/s, 57.7719s/50 iters), loss = 4.57408
I0617 16:17:54.890481  8058 solver.cpp:237]     Train net output #0: accuracy = 0.02
I0617 16:17:54.890512  8058 solver.cpp:237]     Train net output #1: loss = 4.57408 (* 1 = 4.57408 loss)
I0617 16:17:54.890539  8058 sgd_solver.cpp:105] Iteration 900, lr = 0.01
I0617 16:18:52.648746  8058 solver.cpp:218] Iteration 950 (0.865684 iter/s, 57.7578s/50 iters), loss = 4.42764
I0617 16:18:52.648876  8058 solver.cpp:237]     Train net output #0: accuracy = 0.1
I0617 16:18:52.648906  8058 solver.cpp:237]     Train net output #1: loss = 4.42764 (* 1 = 4.42764 loss)
I0617 16:18:52.648926  8058 sgd_solver.cpp:105] Iteration 950, lr = 0.01
I0617 16:18:58.502879  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 16:19:50.416419  8058 solver.cpp:218] Iteration 1000 (0.865545 iter/s, 57.7671s/50 iters), loss = 4.3463
I0617 16:19:50.416564  8058 solver.cpp:237]     Train net output #0: accuracy = 0.04
I0617 16:19:50.416599  8058 solver.cpp:237]     Train net output #1: loss = 4.3463 (* 1 = 4.3463 loss)
I0617 16:19:50.416620  8058 sgd_solver.cpp:105] Iteration 1000, lr = 0.01
I0617 16:20:48.186533  8058 solver.cpp:218] Iteration 1050 (0.865509 iter/s, 57.7695s/50 iters), loss = 4.32009
I0617 16:20:48.186650  8058 solver.cpp:237]     Train net output #0: accuracy = 0.06
I0617 16:20:48.186683  8058 solver.cpp:237]     Train net output #1: loss = 4.32009 (* 1 = 4.32009 loss)
I0617 16:20:48.186703  8058 sgd_solver.cpp:105] Iteration 1050, lr = 0.01
I0617 16:21:15.997736  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 16:21:45.955364  8058 solver.cpp:218] Iteration 1100 (0.865527 iter/s, 57.7682s/50 iters), loss = 4.51819
I0617 16:21:45.955523  8058 solver.cpp:237]     Train net output #0: accuracy = 0.04
I0617 16:21:45.955560  8058 solver.cpp:237]     Train net output #1: loss = 4.51819 (* 1 = 4.51819 loss)
I0617 16:21:45.955580  8058 sgd_solver.cpp:105] Iteration 1100, lr = 0.01
I0617 16:22:43.735821  8058 solver.cpp:218] Iteration 1150 (0.865354 iter/s, 57.7798s/50 iters), loss = 4.61918
I0617 16:22:43.736023  8058 solver.cpp:237]     Train net output #0: accuracy = 0.02
I0617 16:22:43.736059  8058 solver.cpp:237]     Train net output #1: loss = 4.61918 (* 1 = 4.61918 loss)
I0617 16:22:43.736079  8058 sgd_solver.cpp:105] Iteration 1150, lr = 0.01
I0617 16:23:34.673595  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 16:23:41.506295  8058 solver.cpp:218] Iteration 1200 (0.865504 iter/s, 57.7698s/50 iters), loss = 4.4189
I0617 16:23:41.506395  8058 solver.cpp:237]     Train net output #0: accuracy = 0.12
I0617 16:23:41.506428  8058 solver.cpp:237]     Train net output #1: loss = 4.4189 (* 1 = 4.4189 loss)
I0617 16:23:41.506448  8058 sgd_solver.cpp:105] Iteration 1200, lr = 0.01
I0617 16:24:39.269207  8058 solver.cpp:218] Iteration 1250 (0.865616 iter/s, 57.7623s/50 iters), loss = 3.92917
I0617 16:24:39.269295  8058 solver.cpp:237]     Train net output #0: accuracy = 0.18
I0617 16:24:39.269325  8058 solver.cpp:237]     Train net output #1: loss = 3.92917 (* 1 = 3.92917 loss)
I0617 16:24:39.269343  8058 sgd_solver.cpp:105] Iteration 1250, lr = 0.01
I0617 16:25:37.037145  8058 solver.cpp:218] Iteration 1300 (0.86554 iter/s, 57.7674s/50 iters), loss = 4.38048
I0617 16:25:37.037293  8058 solver.cpp:237]     Train net output #0: accuracy = 0.04
I0617 16:25:37.037328  8058 solver.cpp:237]     Train net output #1: loss = 4.38048 (* 1 = 4.38048 loss)
I0617 16:25:37.037348  8058 sgd_solver.cpp:105] Iteration 1300, lr = 0.01
I0617 16:25:53.304553  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 16:26:34.796701  8058 solver.cpp:218] Iteration 1350 (0.865667 iter/s, 57.7589s/50 iters), loss = 4.04294
I0617 16:26:34.796834  8058 solver.cpp:237]     Train net output #0: accuracy = 0.12
I0617 16:26:34.796869  8058 solver.cpp:237]     Train net output #1: loss = 4.04294 (* 1 = 4.04294 loss)
I0617 16:26:34.796888  8058 sgd_solver.cpp:105] Iteration 1350, lr = 0.01
I0617 16:27:32.563987  8058 solver.cpp:218] Iteration 1400 (0.865551 iter/s, 57.7667s/50 iters), loss = 4.36048
I0617 16:27:32.564142  8058 solver.cpp:237]     Train net output #0: accuracy = 0.04
I0617 16:27:32.564177  8058 solver.cpp:237]     Train net output #1: loss = 4.36048 (* 1 = 4.36048 loss)
I0617 16:27:32.564196  8058 sgd_solver.cpp:105] Iteration 1400, lr = 0.01
I0617 16:28:11.937867  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 16:28:30.326488  8058 solver.cpp:218] Iteration 1450 (0.865623 iter/s, 57.7619s/50 iters), loss = 3.88325
I0617 16:28:30.326584  8058 solver.cpp:237]     Train net output #0: accuracy = 0.1
I0617 16:28:30.326614  8058 solver.cpp:237]     Train net output #1: loss = 3.88325 (* 1 = 3.88325 loss)
I0617 16:28:30.326634  8058 sgd_solver.cpp:105] Iteration 1450, lr = 0.01
I0617 16:29:28.100071  8058 solver.cpp:218] Iteration 1500 (0.865456 iter/s, 57.773s/50 iters), loss = 4.1163
I0617 16:29:28.100203  8058 solver.cpp:237]     Train net output #0: accuracy = 0.08
I0617 16:29:28.100239  8058 solver.cpp:237]     Train net output #1: loss = 4.1163 (* 1 = 4.1163 loss)
I0617 16:29:28.100257  8058 sgd_solver.cpp:105] Iteration 1500, lr = 0.01
I0617 16:30:25.879194  8058 solver.cpp:218] Iteration 1550 (0.865374 iter/s, 57.7785s/50 iters), loss = 4.20891
I0617 16:30:25.879323  8058 solver.cpp:237]     Train net output #0: accuracy = 0.08
I0617 16:30:25.879359  8058 solver.cpp:237]     Train net output #1: loss = 4.20891 (* 1 = 4.20891 loss)
I0617 16:30:25.879379  8058 sgd_solver.cpp:105] Iteration 1550, lr = 0.01
I0617 16:30:30.566504  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 16:31:23.653532  8058 solver.cpp:218] Iteration 1600 (0.865445 iter/s, 57.7737s/50 iters), loss = 3.82844
I0617 16:31:23.653674  8058 solver.cpp:237]     Train net output #0: accuracy = 0.06
I0617 16:31:23.653709  8058 solver.cpp:237]     Train net output #1: loss = 3.82844 (* 1 = 3.82844 loss)
I0617 16:31:23.653730  8058 sgd_solver.cpp:105] Iteration 1600, lr = 0.01
I0617 16:32:21.433573  8058 solver.cpp:218] Iteration 1650 (0.86536 iter/s, 57.7794s/50 iters), loss = 3.85097
I0617 16:32:21.433782  8058 solver.cpp:237]     Train net output #0: accuracy = 0.06
I0617 16:32:21.433817  8058 solver.cpp:237]     Train net output #1: loss = 3.85097 (* 1 = 3.85097 loss)
I0617 16:32:21.433837  8058 sgd_solver.cpp:105] Iteration 1650, lr = 0.01
I0617 16:32:49.236790  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 16:33:19.216871  8058 solver.cpp:218] Iteration 1700 (0.865312 iter/s, 57.7826s/50 iters), loss = 3.66653
I0617 16:33:19.217008  8058 solver.cpp:237]     Train net output #0: accuracy = 0.16
I0617 16:33:19.217043  8058 solver.cpp:237]     Train net output #1: loss = 3.66653 (* 1 = 3.66653 loss)
I0617 16:33:19.217064  8058 sgd_solver.cpp:105] Iteration 1700, lr = 0.01
I0617 16:34:16.989073  8058 solver.cpp:218] Iteration 1750 (0.865477 iter/s, 57.7716s/50 iters), loss = 4.01971
I0617 16:34:16.989228  8058 solver.cpp:237]     Train net output #0: accuracy = 0.08
I0617 16:34:16.989264  8058 solver.cpp:237]     Train net output #1: loss = 4.01971 (* 1 = 4.01971 loss)
I0617 16:34:16.989286  8058 sgd_solver.cpp:105] Iteration 1750, lr = 0.01
I0617 16:35:07.904479  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 16:35:14.760908  8058 solver.cpp:218] Iteration 1800 (0.865483 iter/s, 57.7712s/50 iters), loss = 3.81658
I0617 16:35:14.761004  8058 solver.cpp:237]     Train net output #0: accuracy = 0.16
I0617 16:35:14.761034  8058 solver.cpp:237]     Train net output #1: loss = 3.81658 (* 1 = 3.81658 loss)
I0617 16:35:14.761055  8058 sgd_solver.cpp:105] Iteration 1800, lr = 0.01
I0617 16:36:12.534940  8058 solver.cpp:218] Iteration 1850 (0.865449 iter/s, 57.7734s/50 iters), loss = 3.73009
I0617 16:36:12.535081  8058 solver.cpp:237]     Train net output #0: accuracy = 0.12
I0617 16:36:12.535115  8058 solver.cpp:237]     Train net output #1: loss = 3.73009 (* 1 = 3.73009 loss)
I0617 16:36:12.535136  8058 sgd_solver.cpp:105] Iteration 1850, lr = 0.01
I0617 16:37:10.320078  8058 solver.cpp:218] Iteration 1900 (0.865284 iter/s, 57.7845s/50 iters), loss = 4.01844
I0617 16:37:10.320192  8058 solver.cpp:237]     Train net output #0: accuracy = 0.04
I0617 16:37:10.320224  8058 solver.cpp:237]     Train net output #1: loss = 4.01844 (* 1 = 4.01844 loss)
I0617 16:37:10.320243  8058 sgd_solver.cpp:105] Iteration 1900, lr = 0.01
I0617 16:37:26.553072  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 16:38:08.092483  8058 solver.cpp:218] Iteration 1950 (0.865474 iter/s, 57.7718s/50 iters), loss = 3.60789
I0617 16:38:08.092609  8058 solver.cpp:237]     Train net output #0: accuracy = 0.22
I0617 16:38:08.092643  8058 solver.cpp:237]     Train net output #1: loss = 3.60789 (* 1 = 3.60789 loss)
I0617 16:38:08.092664  8058 sgd_solver.cpp:105] Iteration 1950, lr = 0.01
I0617 16:39:05.856463  8058 solver.cpp:218] Iteration 2000 (0.865601 iter/s, 57.7634s/50 iters), loss = 3.61015
I0617 16:39:05.856600  8058 solver.cpp:237]     Train net output #0: accuracy = 0.22
I0617 16:39:05.856634  8058 solver.cpp:237]     Train net output #1: loss = 3.61015 (* 1 = 3.61015 loss)
I0617 16:39:05.856654  8058 sgd_solver.cpp:105] Iteration 2000, lr = 0.01
I0617 16:39:44.091861  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 16:40:03.620699  8058 solver.cpp:218] Iteration 2050 (0.865597 iter/s, 57.7636s/50 iters), loss = 3.48948
I0617 16:40:03.620787  8058 solver.cpp:237]     Train net output #0: accuracy = 0.18
I0617 16:40:03.620816  8058 solver.cpp:237]     Train net output #1: loss = 3.48948 (* 1 = 3.48948 loss)
I0617 16:40:03.620836  8058 sgd_solver.cpp:105] Iteration 2050, lr = 0.01
I0617 16:41:01.385691  8058 solver.cpp:218] Iteration 2100 (0.865585 iter/s, 57.7644s/50 iters), loss = 3.42497
I0617 16:41:01.385810  8058 solver.cpp:237]     Train net output #0: accuracy = 0.12
I0617 16:41:01.385844  8058 solver.cpp:237]     Train net output #1: loss = 3.42497 (* 1 = 3.42497 loss)
I0617 16:41:01.385865  8058 sgd_solver.cpp:105] Iteration 2100, lr = 0.01
I0617 16:41:59.151026  8058 solver.cpp:218] Iteration 2150 (0.86558 iter/s, 57.7647s/50 iters), loss = 3.4007
I0617 16:41:59.151525  8058 solver.cpp:237]     Train net output #0: accuracy = 0.2
I0617 16:41:59.151561  8058 solver.cpp:237]     Train net output #1: loss = 3.4007 (* 1 = 3.4007 loss)
I0617 16:41:59.151584  8058 sgd_solver.cpp:105] Iteration 2150, lr = 0.01
I0617 16:42:02.724845  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 16:42:56.917335  8058 solver.cpp:218] Iteration 2200 (0.865571 iter/s, 57.7653s/50 iters), loss = 3.20299
I0617 16:42:56.917469  8058 solver.cpp:237]     Train net output #0: accuracy = 0.28
I0617 16:42:56.917501  8058 solver.cpp:237]     Train net output #1: loss = 3.20299 (* 1 = 3.20299 loss)
I0617 16:42:56.917528  8058 sgd_solver.cpp:105] Iteration 2200, lr = 0.01
I0617 16:43:54.682307  8058 solver.cpp:218] Iteration 2250 (0.865586 iter/s, 57.7644s/50 iters), loss = 3.28976
I0617 16:43:54.682417  8058 solver.cpp:237]     Train net output #0: accuracy = 0.16
I0617 16:43:54.682451  8058 solver.cpp:237]     Train net output #1: loss = 3.28976 (* 1 = 3.28976 loss)
I0617 16:43:54.682469  8058 sgd_solver.cpp:105] Iteration 2250, lr = 0.01
I0617 16:44:21.330916  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 16:44:52.458281  8058 solver.cpp:218] Iteration 2300 (0.865421 iter/s, 57.7754s/50 iters), loss = 3.68548
I0617 16:44:52.458427  8058 solver.cpp:237]     Train net output #0: accuracy = 0.1
I0617 16:44:52.458461  8058 solver.cpp:237]     Train net output #1: loss = 3.68548 (* 1 = 3.68548 loss)
I0617 16:44:52.458482  8058 sgd_solver.cpp:105] Iteration 2300, lr = 0.01
I0617 16:45:50.222664  8058 solver.cpp:218] Iteration 2350 (0.865595 iter/s, 57.7637s/50 iters), loss = 3.32518
I0617 16:45:50.222823  8058 solver.cpp:237]     Train net output #0: accuracy = 0.28
I0617 16:45:50.222857  8058 solver.cpp:237]     Train net output #1: loss = 3.32518 (* 1 = 3.32518 loss)
I0617 16:45:50.222877  8058 sgd_solver.cpp:105] Iteration 2350, lr = 0.01
I0617 16:46:39.967496  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 16:46:47.988638  8058 solver.cpp:218] Iteration 2400 (0.865571 iter/s, 57.7653s/50 iters), loss = 3.32697
I0617 16:46:47.988735  8058 solver.cpp:237]     Train net output #0: accuracy = 0.22
I0617 16:46:47.988765  8058 solver.cpp:237]     Train net output #1: loss = 3.32697 (* 1 = 3.32697 loss)
I0617 16:46:47.988785  8058 sgd_solver.cpp:105] Iteration 2400, lr = 0.01
I0617 16:47:45.750864  8058 solver.cpp:218] Iteration 2450 (0.865627 iter/s, 57.7616s/50 iters), loss = 3.15748
I0617 16:47:45.750995  8058 solver.cpp:237]     Train net output #0: accuracy = 0.26
I0617 16:47:45.751025  8058 solver.cpp:237]     Train net output #1: loss = 3.15748 (* 1 = 3.15748 loss)
I0617 16:47:45.751045  8058 sgd_solver.cpp:105] Iteration 2450, lr = 0.01
I0617 16:48:43.529341  8058 solver.cpp:218] Iteration 2500 (0.865384 iter/s, 57.7778s/50 iters), loss = 3.22124
I0617 16:48:43.529511  8058 solver.cpp:237]     Train net output #0: accuracy = 0.18
I0617 16:48:43.529552  8058 solver.cpp:237]     Train net output #1: loss = 3.22124 (* 1 = 3.22124 loss)
I0617 16:48:43.529573  8058 sgd_solver.cpp:105] Iteration 2500, lr = 0.01
I0617 16:48:58.639492  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 16:49:41.328171  8058 solver.cpp:218] Iteration 2550 (0.865079 iter/s, 57.7982s/50 iters), loss = 3.20002
I0617 16:49:41.328310  8058 solver.cpp:237]     Train net output #0: accuracy = 0.24
I0617 16:49:41.328343  8058 solver.cpp:237]     Train net output #1: loss = 3.20002 (* 1 = 3.20002 loss)
I0617 16:49:41.328364  8058 sgd_solver.cpp:105] Iteration 2550, lr = 0.01
I0617 16:50:39.129768  8058 solver.cpp:218] Iteration 2600 (0.865037 iter/s, 57.801s/50 iters), loss = 3.08669
I0617 16:50:39.129915  8058 solver.cpp:237]     Train net output #0: accuracy = 0.28
I0617 16:50:39.129948  8058 solver.cpp:237]     Train net output #1: loss = 3.08669 (* 1 = 3.08669 loss)
I0617 16:50:39.129968  8058 sgd_solver.cpp:105] Iteration 2600, lr = 0.01
I0617 16:51:17.364085  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 16:51:36.933779  8058 solver.cpp:218] Iteration 2650 (0.865001 iter/s, 57.8034s/50 iters), loss = 3.20279
I0617 16:51:36.933897  8058 solver.cpp:237]     Train net output #0: accuracy = 0.26
I0617 16:51:36.933929  8058 solver.cpp:237]     Train net output #1: loss = 3.20279 (* 1 = 3.20279 loss)
I0617 16:51:36.933950  8058 sgd_solver.cpp:105] Iteration 2650, lr = 0.01
I0617 16:52:34.735536  8058 solver.cpp:218] Iteration 2700 (0.865034 iter/s, 57.8012s/50 iters), loss = 2.78771
I0617 16:52:34.735662  8058 solver.cpp:237]     Train net output #0: accuracy = 0.3
I0617 16:52:34.735697  8058 solver.cpp:237]     Train net output #1: loss = 2.78771 (* 1 = 2.78771 loss)
I0617 16:52:34.735720  8058 sgd_solver.cpp:105] Iteration 2700, lr = 0.01
I0617 16:53:32.554122  8058 solver.cpp:218] Iteration 2750 (0.864783 iter/s, 57.818s/50 iters), loss = 2.93341
I0617 16:53:32.554306  8058 solver.cpp:237]     Train net output #0: accuracy = 0.24
I0617 16:53:32.554342  8058 solver.cpp:237]     Train net output #1: loss = 2.93341 (* 1 = 2.93341 loss)
I0617 16:53:32.554363  8058 sgd_solver.cpp:105] Iteration 2750, lr = 0.01
I0617 16:53:36.087318  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 16:54:30.358314  8058 solver.cpp:218] Iteration 2800 (0.864999 iter/s, 57.8036s/50 iters), loss = 2.84807
I0617 16:54:30.358443  8058 solver.cpp:237]     Train net output #0: accuracy = 0.32
I0617 16:54:30.358475  8058 solver.cpp:237]     Train net output #1: loss = 2.84807 (* 1 = 2.84807 loss)
I0617 16:54:30.358496  8058 sgd_solver.cpp:105] Iteration 2800, lr = 0.01
I0617 16:55:28.151825  8058 solver.cpp:218] Iteration 2850 (0.865158 iter/s, 57.7929s/50 iters), loss = 2.44112
I0617 16:55:28.151993  8058 solver.cpp:237]     Train net output #0: accuracy = 0.32
I0617 16:55:28.152027  8058 solver.cpp:237]     Train net output #1: loss = 2.44112 (* 1 = 2.44112 loss)
I0617 16:55:28.152047  8058 sgd_solver.cpp:105] Iteration 2850, lr = 0.01
I0617 16:55:54.780319  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 16:56:25.947614  8058 solver.cpp:218] Iteration 2900 (0.865124 iter/s, 57.7952s/50 iters), loss = 2.74783
I0617 16:56:25.947770  8058 solver.cpp:237]     Train net output #0: accuracy = 0.22
I0617 16:56:25.947808  8058 solver.cpp:237]     Train net output #1: loss = 2.74783 (* 1 = 2.74783 loss)
I0617 16:56:25.947830  8058 sgd_solver.cpp:105] Iteration 2900, lr = 0.01
I0617 16:57:23.759930  8058 solver.cpp:218] Iteration 2950 (0.864877 iter/s, 57.8117s/50 iters), loss = 2.65672
I0617 16:57:23.760095  8058 solver.cpp:237]     Train net output #0: accuracy = 0.36
I0617 16:57:23.760128  8058 solver.cpp:237]     Train net output #1: loss = 2.65672 (* 1 = 2.65672 loss)
I0617 16:57:23.760149  8058 sgd_solver.cpp:105] Iteration 2950, lr = 0.01
I0617 16:58:12.417078  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 16:58:21.563218  8058 solver.cpp:218] Iteration 3000 (0.865012 iter/s, 57.8027s/50 iters), loss = 2.66676
I0617 16:58:21.563344  8058 solver.cpp:237]     Train net output #0: accuracy = 0.36
I0617 16:58:21.563376  8058 solver.cpp:237]     Train net output #1: loss = 2.66676 (* 1 = 2.66676 loss)
I0617 16:58:21.563397  8058 sgd_solver.cpp:105] Iteration 3000, lr = 0.01
I0617 16:59:19.392727  8058 solver.cpp:218] Iteration 3050 (0.864619 iter/s, 57.8289s/50 iters), loss = 2.89906
I0617 16:59:19.392874  8058 solver.cpp:237]     Train net output #0: accuracy = 0.28
I0617 16:59:19.392906  8058 solver.cpp:237]     Train net output #1: loss = 2.89906 (* 1 = 2.89906 loss)
I0617 16:59:19.392928  8058 sgd_solver.cpp:105] Iteration 3050, lr = 0.01
I0617 17:00:17.219347  8058 solver.cpp:218] Iteration 3100 (0.864663 iter/s, 57.826s/50 iters), loss = 2.92926
I0617 17:00:17.219490  8058 solver.cpp:237]     Train net output #0: accuracy = 0.26
I0617 17:00:17.219532  8058 solver.cpp:237]     Train net output #1: loss = 2.92926 (* 1 = 2.92926 loss)
I0617 17:00:17.219558  8058 sgd_solver.cpp:105] Iteration 3100, lr = 0.01
I0617 17:00:31.179404  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 17:01:15.048266  8058 solver.cpp:218] Iteration 3150 (0.864628 iter/s, 57.8283s/50 iters), loss = 2.39031
I0617 17:01:15.048504  8058 solver.cpp:237]     Train net output #0: accuracy = 0.46
I0617 17:01:15.048547  8058 solver.cpp:237]     Train net output #1: loss = 2.39031 (* 1 = 2.39031 loss)
I0617 17:01:15.048568  8058 sgd_solver.cpp:105] Iteration 3150, lr = 0.01
I0617 17:02:12.874719  8058 solver.cpp:218] Iteration 3200 (0.864667 iter/s, 57.8257s/50 iters), loss = 2.60986
I0617 17:02:12.874882  8058 solver.cpp:237]     Train net output #0: accuracy = 0.32
I0617 17:02:12.874915  8058 solver.cpp:237]     Train net output #1: loss = 2.60986 (* 1 = 2.60986 loss)
I0617 17:02:12.874936  8058 sgd_solver.cpp:105] Iteration 3200, lr = 0.01
I0617 17:02:49.975055  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 17:03:10.694980  8058 solver.cpp:218] Iteration 3250 (0.864758 iter/s, 57.8196s/50 iters), loss = 2.61023
I0617 17:03:10.695099  8058 solver.cpp:237]     Train net output #0: accuracy = 0.34
I0617 17:03:10.695132  8058 solver.cpp:237]     Train net output #1: loss = 2.61023 (* 1 = 2.61023 loss)
I0617 17:03:10.695152  8058 sgd_solver.cpp:105] Iteration 3250, lr = 0.01
I0617 17:04:08.521667  8058 solver.cpp:218] Iteration 3300 (0.864662 iter/s, 57.8261s/50 iters), loss = 2.37315
I0617 17:04:08.521836  8058 solver.cpp:237]     Train net output #0: accuracy = 0.36
I0617 17:04:08.521870  8058 solver.cpp:237]     Train net output #1: loss = 2.37315 (* 1 = 2.37315 loss)
I0617 17:04:08.521891  8058 sgd_solver.cpp:105] Iteration 3300, lr = 0.01
I0617 17:05:06.346454  8058 solver.cpp:218] Iteration 3350 (0.864691 iter/s, 57.8242s/50 iters), loss = 2.74907
I0617 17:05:06.346626  8058 solver.cpp:237]     Train net output #0: accuracy = 0.22
I0617 17:05:06.346660  8058 solver.cpp:237]     Train net output #1: loss = 2.74907 (* 1 = 2.74907 loss)
I0617 17:05:06.346681  8058 sgd_solver.cpp:105] Iteration 3350, lr = 0.01
I0617 17:05:08.749984  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 17:06:04.173086  8058 solver.cpp:218] Iteration 3400 (0.864663 iter/s, 57.826s/50 iters), loss = 2.47556
I0617 17:06:04.173249  8058 solver.cpp:237]     Train net output #0: accuracy = 0.36
I0617 17:06:04.173285  8058 solver.cpp:237]     Train net output #1: loss = 2.47556 (* 1 = 2.47556 loss)
I0617 17:06:04.173306  8058 sgd_solver.cpp:105] Iteration 3400, lr = 0.01
I0617 17:07:01.994482  8058 solver.cpp:218] Iteration 3450 (0.864741 iter/s, 57.8208s/50 iters), loss = 2.20586
I0617 17:07:01.994644  8058 solver.cpp:237]     Train net output #0: accuracy = 0.44
I0617 17:07:01.994679  8058 solver.cpp:237]     Train net output #1: loss = 2.20586 (* 1 = 2.20586 loss)
I0617 17:07:01.994701  8058 sgd_solver.cpp:105] Iteration 3450, lr = 0.01
I0617 17:07:27.508224  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 17:07:59.833930  8058 solver.cpp:218] Iteration 3500 (0.864471 iter/s, 57.8388s/50 iters), loss = 2.07897
I0617 17:07:59.834182  8058 solver.cpp:237]     Train net output #0: accuracy = 0.46
I0617 17:07:59.834216  8058 solver.cpp:237]     Train net output #1: loss = 2.07897 (* 1 = 2.07897 loss)
I0617 17:07:59.834237  8058 sgd_solver.cpp:105] Iteration 3500, lr = 0.01
I0617 17:08:57.614790  8058 solver.cpp:218] Iteration 3550 (0.865349 iter/s, 57.7801s/50 iters), loss = 2.23526
I0617 17:08:57.614931  8058 solver.cpp:237]     Train net output #0: accuracy = 0.36
I0617 17:08:57.614965  8058 solver.cpp:237]     Train net output #1: loss = 2.23526 (* 1 = 2.23526 loss)
I0617 17:08:57.614986  8058 sgd_solver.cpp:105] Iteration 3550, lr = 0.01
I0617 17:09:46.236523  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 17:09:55.387707  8058 solver.cpp:218] Iteration 3600 (0.865466 iter/s, 57.7723s/50 iters), loss = 2.31677
I0617 17:09:55.387794  8058 solver.cpp:237]     Train net output #0: accuracy = 0.4
I0617 17:09:55.387825  8058 solver.cpp:237]     Train net output #1: loss = 2.31677 (* 1 = 2.31677 loss)
I0617 17:09:55.387845  8058 sgd_solver.cpp:105] Iteration 3600, lr = 0.01
I0617 17:10:53.154557  8058 solver.cpp:218] Iteration 3650 (0.865556 iter/s, 57.7663s/50 iters), loss = 2.1455
I0617 17:10:53.154723  8058 solver.cpp:237]     Train net output #0: accuracy = 0.54
I0617 17:10:53.154757  8058 solver.cpp:237]     Train net output #1: loss = 2.1455 (* 1 = 2.1455 loss)
I0617 17:10:53.154778  8058 sgd_solver.cpp:105] Iteration 3650, lr = 0.01
I0617 17:11:50.918213  8058 solver.cpp:218] Iteration 3700 (0.865605 iter/s, 57.763s/50 iters), loss = 1.92372
I0617 17:11:50.918344  8058 solver.cpp:237]     Train net output #0: accuracy = 0.48
I0617 17:11:50.918380  8058 solver.cpp:237]     Train net output #1: loss = 1.92372 (* 1 = 1.92372 loss)
I0617 17:11:50.918398  8058 sgd_solver.cpp:105] Iteration 3700, lr = 0.01
I0617 17:12:04.864809  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 17:12:48.688958  8058 solver.cpp:218] Iteration 3750 (0.865499 iter/s, 57.7702s/50 iters), loss = 1.72499
I0617 17:12:48.689077  8058 solver.cpp:237]     Train net output #0: accuracy = 0.58
I0617 17:12:48.689111  8058 solver.cpp:237]     Train net output #1: loss = 1.72499 (* 1 = 1.72499 loss)
I0617 17:12:48.689131  8058 sgd_solver.cpp:105] Iteration 3750, lr = 0.01
I0617 17:13:46.451632  8058 solver.cpp:218] Iteration 3800 (0.86562 iter/s, 57.7621s/50 iters), loss = 2.07053
I0617 17:13:46.451795  8058 solver.cpp:237]     Train net output #0: accuracy = 0.5
I0617 17:13:46.451830  8058 solver.cpp:237]     Train net output #1: loss = 2.07053 (* 1 = 2.07053 loss)
I0617 17:13:46.451850  8058 sgd_solver.cpp:105] Iteration 3800, lr = 0.01
I0617 17:14:23.478020  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 17:14:44.209211  8058 solver.cpp:218] Iteration 3850 (0.865697 iter/s, 57.757s/50 iters), loss = 2.42325
I0617 17:14:44.209298  8058 solver.cpp:237]     Train net output #0: accuracy = 0.46
I0617 17:14:44.209327  8058 solver.cpp:237]     Train net output #1: loss = 2.42325 (* 1 = 2.42325 loss)
I0617 17:14:44.209347  8058 sgd_solver.cpp:105] Iteration 3850, lr = 0.01
I0617 17:15:41.969660  8058 solver.cpp:218] Iteration 3900 (0.865653 iter/s, 57.7599s/50 iters), loss = 1.78783
I0617 17:15:41.969781  8058 solver.cpp:237]     Train net output #0: accuracy = 0.52
I0617 17:15:41.969810  8058 solver.cpp:237]     Train net output #1: loss = 1.78783 (* 1 = 1.78783 loss)
I0617 17:15:41.969830  8058 sgd_solver.cpp:105] Iteration 3900, lr = 0.01
I0617 17:16:39.739797  8058 solver.cpp:218] Iteration 3950 (0.865508 iter/s, 57.7696s/50 iters), loss = 1.95922
I0617 17:16:39.741236  8058 solver.cpp:237]     Train net output #0: accuracy = 0.48
I0617 17:16:39.741272  8058 solver.cpp:237]     Train net output #1: loss = 1.95922 (* 1 = 1.95922 loss)
I0617 17:16:39.741291  8058 sgd_solver.cpp:105] Iteration 3950, lr = 0.01
I0617 17:16:42.129117  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 17:17:37.498761  8058 solver.cpp:218] Iteration 4000 (0.865695 iter/s, 57.7571s/50 iters), loss = 1.64142
I0617 17:17:37.500035  8058 solver.cpp:237]     Train net output #0: accuracy = 0.58
I0617 17:17:37.500067  8058 solver.cpp:237]     Train net output #1: loss = 1.64142 (* 1 = 1.64142 loss)
I0617 17:17:37.500087  8058 sgd_solver.cpp:105] Iteration 4000, lr = 0.01
I0617 17:18:35.261965  8058 solver.cpp:218] Iteration 4050 (0.865629 iter/s, 57.7615s/50 iters), loss = 2.1454
I0617 17:18:35.262082  8058 solver.cpp:237]     Train net output #0: accuracy = 0.46
I0617 17:18:35.262118  8058 solver.cpp:237]     Train net output #1: loss = 2.1454 (* 1 = 2.1454 loss)
I0617 17:18:35.262140  8058 sgd_solver.cpp:105] Iteration 4050, lr = 0.01
I0617 17:18:59.634791  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 17:19:33.025887  8058 solver.cpp:218] Iteration 4100 (0.865601 iter/s, 57.7633s/50 iters), loss = 1.43197
I0617 17:19:33.026007  8058 solver.cpp:237]     Train net output #0: accuracy = 0.66
I0617 17:19:33.026037  8058 solver.cpp:237]     Train net output #1: loss = 1.43197 (* 1 = 1.43197 loss)
I0617 17:19:33.026057  8058 sgd_solver.cpp:105] Iteration 4100, lr = 0.01
I0617 17:20:30.774307  8058 solver.cpp:218] Iteration 4150 (0.865833 iter/s, 57.7478s/50 iters), loss = 1.64552
I0617 17:20:30.774495  8058 solver.cpp:237]     Train net output #0: accuracy = 0.6
I0617 17:20:30.774536  8058 solver.cpp:237]     Train net output #1: loss = 1.64552 (* 1 = 1.64552 loss)
I0617 17:20:30.774559  8058 sgd_solver.cpp:105] Iteration 4150, lr = 0.01
I0617 17:21:18.240523  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 17:21:28.538818  8058 solver.cpp:218] Iteration 4200 (0.865593 iter/s, 57.7638s/50 iters), loss = 1.86265
I0617 17:21:28.538910  8058 solver.cpp:237]     Train net output #0: accuracy = 0.52
I0617 17:21:28.538942  8058 solver.cpp:237]     Train net output #1: loss = 1.86265 (* 1 = 1.86265 loss)
I0617 17:21:28.538962  8058 sgd_solver.cpp:105] Iteration 4200, lr = 0.01
I0617 17:22:26.316486  8058 solver.cpp:218] Iteration 4250 (0.865395 iter/s, 57.7771s/50 iters), loss = 1.51493
I0617 17:22:26.316603  8058 solver.cpp:237]     Train net output #0: accuracy = 0.64
I0617 17:22:26.316638  8058 solver.cpp:237]     Train net output #1: loss = 1.51493 (* 1 = 1.51493 loss)
I0617 17:22:26.316656  8058 sgd_solver.cpp:105] Iteration 4250, lr = 0.01
I0617 17:23:24.078416  8058 solver.cpp:218] Iteration 4300 (0.865631 iter/s, 57.7613s/50 iters), loss = 1.72949
I0617 17:23:24.078539  8058 solver.cpp:237]     Train net output #0: accuracy = 0.54
I0617 17:23:24.078575  8058 solver.cpp:237]     Train net output #1: loss = 1.72949 (* 1 = 1.72949 loss)
I0617 17:23:24.078595  8058 sgd_solver.cpp:105] Iteration 4300, lr = 0.01
I0617 17:23:36.859733  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 17:24:21.837433  8058 solver.cpp:218] Iteration 4350 (0.865675 iter/s, 57.7584s/50 iters), loss = 1.54433
I0617 17:24:21.837570  8058 solver.cpp:237]     Train net output #0: accuracy = 0.6
I0617 17:24:21.837607  8058 solver.cpp:237]     Train net output #1: loss = 1.54433 (* 1 = 1.54433 loss)
I0617 17:24:21.837630  8058 sgd_solver.cpp:105] Iteration 4350, lr = 0.01
I0617 17:25:19.587618  8058 solver.cpp:218] Iteration 4400 (0.865807 iter/s, 57.7496s/50 iters), loss = 1.50419
I0617 17:25:19.587743  8058 solver.cpp:237]     Train net output #0: accuracy = 0.64
I0617 17:25:19.587777  8058 solver.cpp:237]     Train net output #1: loss = 1.50419 (* 1 = 1.50419 loss)
I0617 17:25:19.587797  8058 sgd_solver.cpp:105] Iteration 4400, lr = 0.01
I0617 17:25:55.492967  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 17:26:17.349284  8058 solver.cpp:218] Iteration 4450 (0.865635 iter/s, 57.7611s/50 iters), loss = 1.98512
I0617 17:26:17.349366  8058 solver.cpp:237]     Train net output #0: accuracy = 0.48
I0617 17:26:17.349395  8058 solver.cpp:237]     Train net output #1: loss = 1.98512 (* 1 = 1.98512 loss)
I0617 17:26:17.349414  8058 sgd_solver.cpp:105] Iteration 4450, lr = 0.01
I0617 17:27:15.121140  8058 solver.cpp:218] Iteration 4500 (0.865482 iter/s, 57.7713s/50 iters), loss = 1.54928
I0617 17:27:15.121265  8058 solver.cpp:237]     Train net output #0: accuracy = 0.56
I0617 17:27:15.121299  8058 solver.cpp:237]     Train net output #1: loss = 1.54928 (* 1 = 1.54928 loss)
I0617 17:27:15.121318  8058 sgd_solver.cpp:105] Iteration 4500, lr = 0.01
I0617 17:28:12.879595  8058 solver.cpp:218] Iteration 4550 (0.865683 iter/s, 57.7578s/50 iters), loss = 1.39878
I0617 17:28:12.879721  8058 solver.cpp:237]     Train net output #0: accuracy = 0.56
I0617 17:28:12.879755  8058 solver.cpp:237]     Train net output #1: loss = 1.39878 (* 1 = 1.39878 loss)
I0617 17:28:12.879776  8058 sgd_solver.cpp:105] Iteration 4550, lr = 0.01
I0617 17:28:14.125010  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 17:29:10.646571  8058 solver.cpp:218] Iteration 4600 (0.865556 iter/s, 57.7664s/50 iters), loss = 1.39412
I0617 17:29:10.646837  8058 solver.cpp:237]     Train net output #0: accuracy = 0.66
I0617 17:29:10.646869  8058 solver.cpp:237]     Train net output #1: loss = 1.39412 (* 1 = 1.39412 loss)
I0617 17:29:10.646889  8058 sgd_solver.cpp:105] Iteration 4600, lr = 0.01
I0617 17:30:08.408560  8058 solver.cpp:218] Iteration 4650 (0.865632 iter/s, 57.7612s/50 iters), loss = 1.45436
I0617 17:30:08.408742  8058 solver.cpp:237]     Train net output #0: accuracy = 0.68
I0617 17:30:08.408778  8058 solver.cpp:237]     Train net output #1: loss = 1.45436 (* 1 = 1.45436 loss)
I0617 17:30:08.408798  8058 sgd_solver.cpp:105] Iteration 4650, lr = 0.01
I0617 17:30:32.752688  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 17:31:06.175127  8058 solver.cpp:218] Iteration 4700 (0.865563 iter/s, 57.7659s/50 iters), loss = 1.1315
I0617 17:31:06.175256  8058 solver.cpp:237]     Train net output #0: accuracy = 0.8
I0617 17:31:06.175289  8058 solver.cpp:237]     Train net output #1: loss = 1.1315 (* 1 = 1.1315 loss)
I0617 17:31:06.175309  8058 sgd_solver.cpp:105] Iteration 4700, lr = 0.01
I0617 17:32:03.942178  8058 solver.cpp:218] Iteration 4750 (0.865555 iter/s, 57.7664s/50 iters), loss = 1.39841
I0617 17:32:03.942296  8058 solver.cpp:237]     Train net output #0: accuracy = 0.7
I0617 17:32:03.942325  8058 solver.cpp:237]     Train net output #1: loss = 1.39841 (* 1 = 1.39841 loss)
I0617 17:32:03.942345  8058 sgd_solver.cpp:105] Iteration 4750, lr = 0.01
I0617 17:32:51.403373  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 17:33:01.717746  8058 solver.cpp:218] Iteration 4800 (0.865427 iter/s, 57.775s/50 iters), loss = 1.19595
I0617 17:33:01.717836  8058 solver.cpp:237]     Train net output #0: accuracy = 0.68
I0617 17:33:01.717865  8058 solver.cpp:237]     Train net output #1: loss = 1.19595 (* 1 = 1.19595 loss)
I0617 17:33:01.717885  8058 sgd_solver.cpp:105] Iteration 4800, lr = 0.01
I0617 17:33:59.490620  8058 solver.cpp:218] Iteration 4850 (0.865467 iter/s, 57.7723s/50 iters), loss = 1.16841
I0617 17:33:59.490742  8058 solver.cpp:237]     Train net output #0: accuracy = 0.72
I0617 17:33:59.490772  8058 solver.cpp:237]     Train net output #1: loss = 1.16841 (* 1 = 1.16841 loss)
I0617 17:33:59.490792  8058 sgd_solver.cpp:105] Iteration 4850, lr = 0.01
I0617 17:34:57.260056  8058 solver.cpp:218] Iteration 4900 (0.865519 iter/s, 57.7688s/50 iters), loss = 0.82692
I0617 17:34:57.260185  8058 solver.cpp:237]     Train net output #0: accuracy = 0.74
I0617 17:34:57.260220  8058 solver.cpp:237]     Train net output #1: loss = 0.82692 (* 1 = 0.82692 loss)
I0617 17:34:57.260239  8058 sgd_solver.cpp:105] Iteration 4900, lr = 0.01
I0617 17:35:10.043092  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 17:35:55.028236  8058 solver.cpp:218] Iteration 4950 (0.865538 iter/s, 57.7676s/50 iters), loss = 1.03734
I0617 17:35:55.028363  8058 solver.cpp:237]     Train net output #0: accuracy = 0.76
I0617 17:35:55.028399  8058 solver.cpp:237]     Train net output #1: loss = 1.03734 (* 1 = 1.03734 loss)
I0617 17:35:55.028422  8058 sgd_solver.cpp:105] Iteration 4950, lr = 0.01
I0617 17:36:52.793879  8058 solver.cpp:218] Iteration 5000 (0.865576 iter/s, 57.765s/50 iters), loss = 0.988139
I0617 17:36:52.794003  8058 solver.cpp:237]     Train net output #0: accuracy = 0.78
I0617 17:36:52.794036  8058 solver.cpp:237]     Train net output #1: loss = 0.988139 (* 1 = 0.988139 loss)
I0617 17:36:52.794056  8058 sgd_solver.cpp:105] Iteration 5000, lr = 0.01
I0617 17:37:27.550931  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 17:37:50.553596  8058 solver.cpp:218] Iteration 5050 (0.865665 iter/s, 57.7591s/50 iters), loss = 1.09022
I0617 17:37:50.553694  8058 solver.cpp:237]     Train net output #0: accuracy = 0.74
I0617 17:37:50.553727  8058 solver.cpp:237]     Train net output #1: loss = 1.09022 (* 1 = 1.09022 loss)
I0617 17:37:50.553748  8058 sgd_solver.cpp:105] Iteration 5050, lr = 0.01
I0617 17:38:48.324354  8058 solver.cpp:218] Iteration 5100 (0.865499 iter/s, 57.7702s/50 iters), loss = 1.101
I0617 17:38:48.324481  8058 solver.cpp:237]     Train net output #0: accuracy = 0.72
I0617 17:38:48.324522  8058 solver.cpp:237]     Train net output #1: loss = 1.101 (* 1 = 1.101 loss)
I0617 17:38:48.324548  8058 sgd_solver.cpp:105] Iteration 5100, lr = 0.01
I0617 17:39:46.085738  8058 solver.cpp:218] Iteration 5150 (0.865639 iter/s, 57.7608s/50 iters), loss = 1.05779
I0617 17:39:46.085909  8058 solver.cpp:237]     Train net output #0: accuracy = 0.78
I0617 17:39:46.085943  8058 solver.cpp:237]     Train net output #1: loss = 1.05779 (* 1 = 1.05779 loss)
I0617 17:39:46.085963  8058 sgd_solver.cpp:105] Iteration 5150, lr = 0.01
I0617 17:39:46.192772  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 17:40:43.845315  8058 solver.cpp:218] Iteration 5200 (0.865667 iter/s, 57.7589s/50 iters), loss = 0.96239
I0617 17:40:43.845441  8058 solver.cpp:237]     Train net output #0: accuracy = 0.8
I0617 17:40:43.845474  8058 solver.cpp:237]     Train net output #1: loss = 0.96239 (* 1 = 0.96239 loss)
I0617 17:40:43.845494  8058 sgd_solver.cpp:105] Iteration 5200, lr = 0.01
I0617 17:41:41.605125  8058 solver.cpp:218] Iteration 5250 (0.865663 iter/s, 57.7592s/50 iters), loss = 1.10962
I0617 17:41:41.605252  8058 solver.cpp:237]     Train net output #0: accuracy = 0.72
I0617 17:41:41.605286  8058 solver.cpp:237]     Train net output #1: loss = 1.10962 (* 1 = 1.10962 loss)
I0617 17:41:41.605306  8058 sgd_solver.cpp:105] Iteration 5250, lr = 0.01
I0617 17:42:04.795249  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 17:42:39.369982  8058 solver.cpp:218] Iteration 5300 (0.865588 iter/s, 57.7642s/50 iters), loss = 0.881758
I0617 17:42:39.370090  8058 solver.cpp:237]     Train net output #0: accuracy = 0.74
I0617 17:42:39.370124  8058 solver.cpp:237]     Train net output #1: loss = 0.881758 (* 1 = 0.881758 loss)
I0617 17:42:39.370144  8058 sgd_solver.cpp:105] Iteration 5300, lr = 0.01
I0617 17:43:37.128994  8058 solver.cpp:218] Iteration 5350 (0.865675 iter/s, 57.7584s/50 iters), loss = 1.07326
I0617 17:43:37.129115  8058 solver.cpp:237]     Train net output #0: accuracy = 0.66
I0617 17:43:37.129149  8058 solver.cpp:237]     Train net output #1: loss = 1.07326 (* 1 = 1.07326 loss)
I0617 17:43:37.129168  8058 sgd_solver.cpp:105] Iteration 5350, lr = 0.01
I0617 17:44:23.433877  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 17:44:34.885622  8058 solver.cpp:218] Iteration 5400 (0.865711 iter/s, 57.756s/50 iters), loss = 1.19777
I0617 17:44:34.885699  8058 solver.cpp:237]     Train net output #0: accuracy = 0.68
I0617 17:44:34.885732  8058 solver.cpp:237]     Train net output #1: loss = 1.19777 (* 1 = 1.19777 loss)
I0617 17:44:34.885751  8058 sgd_solver.cpp:105] Iteration 5400, lr = 0.01
I0617 17:45:32.641057  8058 solver.cpp:218] Iteration 5450 (0.865728 iter/s, 57.7548s/50 iters), loss = 0.841079
I0617 17:45:32.641177  8058 solver.cpp:237]     Train net output #0: accuracy = 0.76
I0617 17:45:32.641209  8058 solver.cpp:237]     Train net output #1: loss = 0.841079 (* 1 = 0.841079 loss)
I0617 17:45:32.641229  8058 sgd_solver.cpp:105] Iteration 5450, lr = 0.01
I0617 17:46:30.414079  8058 solver.cpp:218] Iteration 5500 (0.865465 iter/s, 57.7724s/50 iters), loss = 0.772355
I0617 17:46:30.414206  8058 solver.cpp:237]     Train net output #0: accuracy = 0.84
I0617 17:46:30.414240  8058 solver.cpp:237]     Train net output #1: loss = 0.772355 (* 1 = 0.772355 loss)
I0617 17:46:30.414260  8058 sgd_solver.cpp:105] Iteration 5500, lr = 0.01
I0617 17:46:42.062716  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 17:47:28.182118  8058 solver.cpp:218] Iteration 5550 (0.86554 iter/s, 57.7674s/50 iters), loss = 0.782197
I0617 17:47:28.182229  8058 solver.cpp:237]     Train net output #0: accuracy = 0.8
I0617 17:47:28.182262  8058 solver.cpp:237]     Train net output #1: loss = 0.782197 (* 1 = 0.782197 loss)
I0617 17:47:28.182282  8058 sgd_solver.cpp:105] Iteration 5550, lr = 0.01
I0617 17:48:25.955730  8058 solver.cpp:218] Iteration 5600 (0.865456 iter/s, 57.773s/50 iters), loss = 0.814022
I0617 17:48:25.955878  8058 solver.cpp:237]     Train net output #0: accuracy = 0.76
I0617 17:48:25.955911  8058 solver.cpp:237]     Train net output #1: loss = 0.814022 (* 1 = 0.814022 loss)
I0617 17:48:25.955931  8058 sgd_solver.cpp:105] Iteration 5600, lr = 0.01
I0617 17:49:00.698078  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 17:49:23.734146  8058 solver.cpp:218] Iteration 5650 (0.865385 iter/s, 57.7778s/50 iters), loss = 0.704032
I0617 17:49:23.734238  8058 solver.cpp:237]     Train net output #0: accuracy = 0.84
I0617 17:49:23.734272  8058 solver.cpp:237]     Train net output #1: loss = 0.704032 (* 1 = 0.704032 loss)
I0617 17:49:23.734294  8058 sgd_solver.cpp:105] Iteration 5650, lr = 0.01
I0617 17:50:21.488131  8058 solver.cpp:218] Iteration 5700 (0.86575 iter/s, 57.7534s/50 iters), loss = 0.687359
I0617 17:50:21.488364  8058 solver.cpp:237]     Train net output #0: accuracy = 0.82
I0617 17:50:21.488399  8058 solver.cpp:237]     Train net output #1: loss = 0.687359 (* 1 = 0.687359 loss)
I0617 17:50:21.488418  8058 sgd_solver.cpp:105] Iteration 5700, lr = 0.01
I0617 17:51:19.266379  8058 solver.cpp:218] Iteration 5750 (0.865389 iter/s, 57.7775s/50 iters), loss = 0.71863
I0617 17:51:19.266469  8058 solver.cpp:237]     Train net output #0: accuracy = 0.82
I0617 17:51:19.266499  8058 solver.cpp:237]     Train net output #1: loss = 0.71863 (* 1 = 0.71863 loss)
I0617 17:51:19.266535  8058 sgd_solver.cpp:105] Iteration 5750, lr = 0.01
I0617 17:51:19.350095  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 17:52:17.022794  8058 solver.cpp:218] Iteration 5800 (0.865714 iter/s, 57.7558s/50 iters), loss = 0.747639
I0617 17:52:17.022917  8058 solver.cpp:237]     Train net output #0: accuracy = 0.8
I0617 17:52:17.022951  8058 solver.cpp:237]     Train net output #1: loss = 0.747639 (* 1 = 0.747639 loss)
I0617 17:52:17.022971  8058 sgd_solver.cpp:105] Iteration 5800, lr = 0.01
I0617 17:53:14.791913  8058 solver.cpp:218] Iteration 5850 (0.865524 iter/s, 57.7685s/50 iters), loss = 0.498566
I0617 17:53:14.792033  8058 solver.cpp:237]     Train net output #0: accuracy = 0.92
I0617 17:53:14.792069  8058 solver.cpp:237]     Train net output #1: loss = 0.498566 (* 1 = 0.498566 loss)
I0617 17:53:14.792093  8058 sgd_solver.cpp:105] Iteration 5850, lr = 0.01
I0617 17:53:37.960186  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 17:54:12.557696  8058 solver.cpp:218] Iteration 5900 (0.865574 iter/s, 57.7652s/50 iters), loss = 0.662011
I0617 17:54:12.557828  8058 solver.cpp:237]     Train net output #0: accuracy = 0.82
I0617 17:54:12.557862  8058 solver.cpp:237]     Train net output #1: loss = 0.662011 (* 1 = 0.662011 loss)
I0617 17:54:12.557881  8058 sgd_solver.cpp:105] Iteration 5900, lr = 0.01
I0617 17:55:10.318392  8058 solver.cpp:218] Iteration 5950 (0.86565 iter/s, 57.7601s/50 iters), loss = 0.601674
I0617 17:55:10.318528  8058 solver.cpp:237]     Train net output #0: accuracy = 0.82
I0617 17:55:10.318563  8058 solver.cpp:237]     Train net output #1: loss = 0.601674 (* 1 = 0.601674 loss)
I0617 17:55:10.318583  8058 sgd_solver.cpp:105] Iteration 5950, lr = 0.01
I0617 17:55:55.457845  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 17:56:08.081480  8058 solver.cpp:218] Iteration 6000 (0.865614 iter/s, 57.7624s/50 iters), loss = 0.599328
I0617 17:56:08.081568  8058 solver.cpp:237]     Train net output #0: accuracy = 0.9
I0617 17:56:08.081598  8058 solver.cpp:237]     Train net output #1: loss = 0.599328 (* 1 = 0.599328 loss)
I0617 17:56:08.081617  8058 sgd_solver.cpp:105] Iteration 6000, lr = 0.01
I0617 17:57:05.849851  8058 solver.cpp:218] Iteration 6050 (0.865535 iter/s, 57.7678s/50 iters), loss = 0.561944
I0617 17:57:05.849972  8058 solver.cpp:237]     Train net output #0: accuracy = 0.84
I0617 17:57:05.850006  8058 solver.cpp:237]     Train net output #1: loss = 0.561944 (* 1 = 0.561944 loss)
I0617 17:57:05.850026  8058 sgd_solver.cpp:105] Iteration 6050, lr = 0.01
I0617 17:58:03.616416  8058 solver.cpp:218] Iteration 6100 (0.865562 iter/s, 57.7659s/50 iters), loss = 0.522287
I0617 17:58:03.616549  8058 solver.cpp:237]     Train net output #0: accuracy = 0.94
I0617 17:58:03.616585  8058 solver.cpp:237]     Train net output #1: loss = 0.522287 (* 1 = 0.522287 loss)
I0617 17:58:03.616603  8058 sgd_solver.cpp:105] Iteration 6100, lr = 0.01
I0617 17:58:14.091157  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 17:59:01.428658  8058 solver.cpp:218] Iteration 6150 (0.864877 iter/s, 57.8117s/50 iters), loss = 0.607081
I0617 17:59:01.428876  8058 solver.cpp:237]     Train net output #0: accuracy = 0.86
I0617 17:59:01.428911  8058 solver.cpp:237]     Train net output #1: loss = 0.607081 (* 1 = 0.607081 loss)
I0617 17:59:01.428932  8058 sgd_solver.cpp:105] Iteration 6150, lr = 0.01
I0617 17:59:59.248265  8058 solver.cpp:218] Iteration 6200 (0.864768 iter/s, 57.819s/50 iters), loss = 0.472699
I0617 17:59:59.248410  8058 solver.cpp:237]     Train net output #0: accuracy = 0.94
I0617 17:59:59.248445  8058 solver.cpp:237]     Train net output #1: loss = 0.472699 (* 1 = 0.472699 loss)
I0617 17:59:59.248466  8058 sgd_solver.cpp:105] Iteration 6200, lr = 0.01
I0617 18:00:32.861155  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 18:00:57.068424  8058 solver.cpp:218] Iteration 6250 (0.864759 iter/s, 57.8196s/50 iters), loss = 0.471753
I0617 18:00:57.068538  8058 solver.cpp:237]     Train net output #0: accuracy = 0.86
I0617 18:00:57.068588  8058 solver.cpp:237]     Train net output #1: loss = 0.471753 (* 1 = 0.471753 loss)
I0617 18:00:57.068609  8058 sgd_solver.cpp:105] Iteration 6250, lr = 0.01
I0617 18:01:54.871831  8058 solver.cpp:218] Iteration 6300 (0.865009 iter/s, 57.8029s/50 iters), loss = 0.473613
I0617 18:01:54.871989  8058 solver.cpp:237]     Train net output #0: accuracy = 0.84
I0617 18:01:54.872025  8058 solver.cpp:237]     Train net output #1: loss = 0.473613 (* 1 = 0.473613 loss)
I0617 18:01:54.872045  8058 sgd_solver.cpp:105] Iteration 6300, lr = 0.01
I0617 18:02:51.586369  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 18:02:52.681319  8058 solver.cpp:218] Iteration 6350 (0.864918 iter/s, 57.8089s/50 iters), loss = 0.629011
I0617 18:02:52.681433  8058 solver.cpp:237]     Train net output #0: accuracy = 0.76
I0617 18:02:52.681465  8058 solver.cpp:237]     Train net output #1: loss = 0.629011 (* 1 = 0.629011 loss)
I0617 18:02:52.681485  8058 sgd_solver.cpp:105] Iteration 6350, lr = 0.01
I0617 18:03:50.492622  8058 solver.cpp:218] Iteration 6400 (0.864891 iter/s, 57.8108s/50 iters), loss = 0.49593
I0617 18:03:50.492808  8058 solver.cpp:237]     Train net output #0: accuracy = 0.92
I0617 18:03:50.492843  8058 solver.cpp:237]     Train net output #1: loss = 0.49593 (* 1 = 0.49593 loss)
I0617 18:03:50.492864  8058 sgd_solver.cpp:105] Iteration 6400, lr = 0.01
I0617 18:04:48.311043  8058 solver.cpp:218] Iteration 6450 (0.864785 iter/s, 57.8178s/50 iters), loss = 0.392233
I0617 18:04:48.311206  8058 solver.cpp:237]     Train net output #0: accuracy = 0.94
I0617 18:04:48.311239  8058 solver.cpp:237]     Train net output #1: loss = 0.392233 (* 1 = 0.392233 loss)
I0617 18:04:48.311259  8058 sgd_solver.cpp:105] Iteration 6450, lr = 0.01
I0617 18:05:10.351541  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 18:05:46.124924  8058 solver.cpp:218] Iteration 6500 (0.864853 iter/s, 57.8133s/50 iters), loss = 0.344394
I0617 18:05:46.125079  8058 solver.cpp:237]     Train net output #0: accuracy = 0.96
I0617 18:05:46.125113  8058 solver.cpp:237]     Train net output #1: loss = 0.344394 (* 1 = 0.344394 loss)
I0617 18:05:46.125133  8058 sgd_solver.cpp:105] Iteration 6500, lr = 0.01
I0617 18:06:43.941434  8058 solver.cpp:218] Iteration 6550 (0.864814 iter/s, 57.8159s/50 iters), loss = 0.56213
I0617 18:06:43.941608  8058 solver.cpp:237]     Train net output #0: accuracy = 0.84
I0617 18:06:43.941644  8058 solver.cpp:237]     Train net output #1: loss = 0.56213 (* 1 = 0.56213 loss)
I0617 18:06:43.941665  8058 sgd_solver.cpp:105] Iteration 6550, lr = 0.01
I0617 18:07:29.094647  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 18:07:41.754894  8058 solver.cpp:218] Iteration 6600 (0.86486 iter/s, 57.8129s/50 iters), loss = 0.371435
I0617 18:07:41.755015  8058 solver.cpp:237]     Train net output #0: accuracy = 0.9
I0617 18:07:41.755048  8058 solver.cpp:237]     Train net output #1: loss = 0.371435 (* 1 = 0.371435 loss)
I0617 18:07:41.755067  8058 sgd_solver.cpp:105] Iteration 6600, lr = 0.01
I0617 18:08:39.538147  8058 solver.cpp:218] Iteration 6650 (0.865311 iter/s, 57.7827s/50 iters), loss = 0.33743
I0617 18:08:39.538332  8058 solver.cpp:237]     Train net output #0: accuracy = 0.94
I0617 18:08:39.538368  8058 solver.cpp:237]     Train net output #1: loss = 0.33743 (* 1 = 0.33743 loss)
I0617 18:08:39.538388  8058 sgd_solver.cpp:105] Iteration 6650, lr = 0.01
I0617 18:09:37.295508  8058 solver.cpp:218] Iteration 6700 (0.8657 iter/s, 57.7568s/50 iters), loss = 0.317654
I0617 18:09:37.295630  8058 solver.cpp:237]     Train net output #0: accuracy = 0.96
I0617 18:09:37.295665  8058 solver.cpp:237]     Train net output #1: loss = 0.317654 (* 1 = 0.317654 loss)
I0617 18:09:37.295684  8058 sgd_solver.cpp:105] Iteration 6700, lr = 0.01
I0617 18:09:47.784588  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 18:10:35.068408  8058 solver.cpp:218] Iteration 6750 (0.865466 iter/s, 57.7724s/50 iters), loss = 0.346635
I0617 18:10:35.068545  8058 solver.cpp:237]     Train net output #0: accuracy = 0.96
I0617 18:10:35.068593  8058 solver.cpp:237]     Train net output #1: loss = 0.346635 (* 1 = 0.346635 loss)
I0617 18:10:35.068614  8058 sgd_solver.cpp:105] Iteration 6750, lr = 0.01
I0617 18:11:32.840589  8058 solver.cpp:218] Iteration 6800 (0.865477 iter/s, 57.7716s/50 iters), loss = 0.31826
I0617 18:11:32.840724  8058 solver.cpp:237]     Train net output #0: accuracy = 0.94
I0617 18:11:32.840759  8058 solver.cpp:237]     Train net output #1: loss = 0.31826 (* 1 = 0.31826 loss)
I0617 18:11:32.840777  8058 sgd_solver.cpp:105] Iteration 6800, lr = 0.01
I0617 18:12:06.420406  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 18:12:30.604452  8058 solver.cpp:218] Iteration 6850 (0.865602 iter/s, 57.7633s/50 iters), loss = 0.283494
I0617 18:12:30.604560  8058 solver.cpp:237]     Train net output #0: accuracy = 0.94
I0617 18:12:30.604593  8058 solver.cpp:237]     Train net output #1: loss = 0.283494 (* 1 = 0.283494 loss)
I0617 18:12:30.604614  8058 sgd_solver.cpp:105] Iteration 6850, lr = 0.01
I0617 18:13:28.365214  8058 solver.cpp:218] Iteration 6900 (0.865647 iter/s, 57.7602s/50 iters), loss = 0.427497
I0617 18:13:28.365347  8058 solver.cpp:237]     Train net output #0: accuracy = 0.86
I0617 18:13:28.365381  8058 solver.cpp:237]     Train net output #1: loss = 0.427497 (* 1 = 0.427497 loss)
I0617 18:13:28.365401  8058 sgd_solver.cpp:105] Iteration 6900, lr = 0.01
I0617 18:14:25.022265  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 18:14:26.129321  8058 solver.cpp:218] Iteration 6950 (0.865598 iter/s, 57.7636s/50 iters), loss = 0.242779
I0617 18:14:26.129402  8058 solver.cpp:237]     Train net output #0: accuracy = 0.98
I0617 18:14:26.129431  8058 solver.cpp:237]     Train net output #1: loss = 0.242779 (* 1 = 0.242779 loss)
I0617 18:14:26.129451  8058 sgd_solver.cpp:105] Iteration 6950, lr = 0.01
I0617 18:15:23.895707  8058 solver.cpp:218] Iteration 7000 (0.865563 iter/s, 57.7659s/50 iters), loss = 0.400234
I0617 18:15:23.895833  8058 solver.cpp:237]     Train net output #0: accuracy = 0.92
I0617 18:15:23.895864  8058 solver.cpp:237]     Train net output #1: loss = 0.400234 (* 1 = 0.400234 loss)
I0617 18:15:23.895884  8058 sgd_solver.cpp:105] Iteration 7000, lr = 0.01
I0617 18:16:21.646592  8058 solver.cpp:218] Iteration 7050 (0.865796 iter/s, 57.7503s/50 iters), loss = 0.258333
I0617 18:16:21.646723  8058 solver.cpp:237]     Train net output #0: accuracy = 0.94
I0617 18:16:21.646756  8058 solver.cpp:237]     Train net output #1: loss = 0.258333 (* 1 = 0.258333 loss)
I0617 18:16:21.646776  8058 sgd_solver.cpp:105] Iteration 7050, lr = 0.01
I0617 18:16:42.545306  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 18:17:19.390683  8058 solver.cpp:218] Iteration 7100 (0.865898 iter/s, 57.7435s/50 iters), loss = 0.343262
I0617 18:17:19.390827  8058 solver.cpp:237]     Train net output #0: accuracy = 0.9
I0617 18:17:19.390862  8058 solver.cpp:237]     Train net output #1: loss = 0.343262 (* 1 = 0.343262 loss)
I0617 18:17:19.390882  8058 sgd_solver.cpp:105] Iteration 7100, lr = 0.01
I0617 18:18:17.150648  8058 solver.cpp:218] Iteration 7150 (0.86566 iter/s, 57.7594s/50 iters), loss = 0.171286
I0617 18:18:17.150779  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 18:18:17.150812  8058 solver.cpp:237]     Train net output #1: loss = 0.171286 (* 1 = 0.171286 loss)
I0617 18:18:17.150833  8058 sgd_solver.cpp:105] Iteration 7150, lr = 0.01
I0617 18:19:01.139394  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 18:19:14.916828  8058 solver.cpp:218] Iteration 7200 (0.865567 iter/s, 57.7656s/50 iters), loss = 0.158253
I0617 18:19:14.916923  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 18:19:14.916959  8058 solver.cpp:237]     Train net output #1: loss = 0.158253 (* 1 = 0.158253 loss)
I0617 18:19:14.916981  8058 sgd_solver.cpp:105] Iteration 7200, lr = 0.01
I0617 18:20:12.685169  8058 solver.cpp:218] Iteration 7250 (0.865534 iter/s, 57.7678s/50 iters), loss = 0.202384
I0617 18:20:12.685293  8058 solver.cpp:237]     Train net output #0: accuracy = 0.98
I0617 18:20:12.685328  8058 solver.cpp:237]     Train net output #1: loss = 0.202384 (* 1 = 0.202384 loss)
I0617 18:20:12.685348  8058 sgd_solver.cpp:105] Iteration 7250, lr = 0.01
I0617 18:21:10.460584  8058 solver.cpp:218] Iteration 7300 (0.865429 iter/s, 57.7748s/50 iters), loss = 0.130022
I0617 18:21:10.460712  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 18:21:10.460742  8058 solver.cpp:237]     Train net output #1: loss = 0.130022 (* 1 = 0.130022 loss)
I0617 18:21:10.460763  8058 sgd_solver.cpp:105] Iteration 7300, lr = 0.01
I0617 18:21:19.779789  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 18:22:08.221230  8058 solver.cpp:218] Iteration 7350 (0.86565 iter/s, 57.7601s/50 iters), loss = 0.169198
I0617 18:22:08.221357  8058 solver.cpp:237]     Train net output #0: accuracy = 0.98
I0617 18:22:08.221391  8058 solver.cpp:237]     Train net output #1: loss = 0.169198 (* 1 = 0.169198 loss)
I0617 18:22:08.221412  8058 sgd_solver.cpp:105] Iteration 7350, lr = 0.01
I0617 18:23:05.992619  8058 solver.cpp:218] Iteration 7400 (0.865489 iter/s, 57.7708s/50 iters), loss = 0.188766
I0617 18:23:05.992750  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 18:23:05.992787  8058 solver.cpp:237]     Train net output #1: loss = 0.188766 (* 1 = 0.188766 loss)
I0617 18:23:05.992810  8058 sgd_solver.cpp:105] Iteration 7400, lr = 0.01
I0617 18:23:38.448369  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 18:24:03.778234  8058 solver.cpp:218] Iteration 7450 (0.865276 iter/s, 57.785s/50 iters), loss = 0.216567
I0617 18:24:03.778327  8058 solver.cpp:237]     Train net output #0: accuracy = 0.98
I0617 18:24:03.778357  8058 solver.cpp:237]     Train net output #1: loss = 0.216567 (* 1 = 0.216567 loss)
I0617 18:24:03.778375  8058 sgd_solver.cpp:105] Iteration 7450, lr = 0.01
I0617 18:25:01.540746  8058 solver.cpp:218] Iteration 7500 (0.865621 iter/s, 57.762s/50 iters), loss = 0.130587
I0617 18:25:01.540879  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 18:25:01.540912  8058 solver.cpp:237]     Train net output #1: loss = 0.130587 (* 1 = 0.130587 loss)
I0617 18:25:01.540932  8058 sgd_solver.cpp:105] Iteration 7500, lr = 0.01
I0617 18:25:57.077368  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 18:25:59.299901  8058 solver.cpp:218] Iteration 7550 (0.865672 iter/s, 57.7586s/50 iters), loss = 0.155224
I0617 18:25:59.299980  8058 solver.cpp:237]     Train net output #0: accuracy = 0.98
I0617 18:25:59.300009  8058 solver.cpp:237]     Train net output #1: loss = 0.155224 (* 1 = 0.155224 loss)
I0617 18:25:59.300029  8058 sgd_solver.cpp:105] Iteration 7550, lr = 0.01
I0617 18:26:57.078372  8058 solver.cpp:218] Iteration 7600 (0.865382 iter/s, 57.7779s/50 iters), loss = 0.115118
I0617 18:26:57.078569  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 18:26:57.078606  8058 solver.cpp:237]     Train net output #1: loss = 0.115118 (* 1 = 0.115118 loss)
I0617 18:26:57.078630  8058 sgd_solver.cpp:105] Iteration 7600, lr = 0.01
I0617 18:27:54.838346  8058 solver.cpp:218] Iteration 7650 (0.865661 iter/s, 57.7593s/50 iters), loss = 0.21581
I0617 18:27:54.838459  8058 solver.cpp:237]     Train net output #0: accuracy = 0.98
I0617 18:27:54.838490  8058 solver.cpp:237]     Train net output #1: loss = 0.21581 (* 1 = 0.21581 loss)
I0617 18:27:54.838510  8058 sgd_solver.cpp:105] Iteration 7650, lr = 0.01
I0617 18:28:15.723883  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 18:28:52.618489  8058 solver.cpp:218] Iteration 7700 (0.865358 iter/s, 57.7796s/50 iters), loss = 0.15808
I0617 18:28:52.618650  8058 solver.cpp:237]     Train net output #0: accuracy = 0.96
I0617 18:28:52.618685  8058 solver.cpp:237]     Train net output #1: loss = 0.15808 (* 1 = 0.15808 loss)
I0617 18:28:52.618705  8058 sgd_solver.cpp:105] Iteration 7700, lr = 0.01
I0617 18:29:50.425812  8058 solver.cpp:218] Iteration 7750 (0.864952 iter/s, 57.8067s/50 iters), loss = 0.219918
I0617 18:29:50.425987  8058 solver.cpp:237]     Train net output #0: accuracy = 0.98
I0617 18:29:50.426021  8058 solver.cpp:237]     Train net output #1: loss = 0.219918 (* 1 = 0.219918 loss)
I0617 18:29:50.426041  8058 sgd_solver.cpp:105] Iteration 7750, lr = 0.01
I0617 18:30:34.425616  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 18:30:48.216982  8058 solver.cpp:218] Iteration 7800 (0.865193 iter/s, 57.7905s/50 iters), loss = 0.136997
I0617 18:30:48.217068  8058 solver.cpp:237]     Train net output #0: accuracy = 0.98
I0617 18:30:48.217097  8058 solver.cpp:237]     Train net output #1: loss = 0.136997 (* 1 = 0.136997 loss)
I0617 18:30:48.217118  8058 sgd_solver.cpp:105] Iteration 7800, lr = 0.01
I0617 18:31:45.993111  8058 solver.cpp:218] Iteration 7850 (0.865418 iter/s, 57.7755s/50 iters), loss = 0.192427
I0617 18:31:45.993252  8058 solver.cpp:237]     Train net output #0: accuracy = 0.98
I0617 18:31:45.993290  8058 solver.cpp:237]     Train net output #1: loss = 0.192427 (* 1 = 0.192427 loss)
I0617 18:31:45.993311  8058 sgd_solver.cpp:105] Iteration 7850, lr = 0.01
I0617 18:32:43.756443  8058 solver.cpp:218] Iteration 7900 (0.86561 iter/s, 57.7627s/50 iters), loss = 0.178773
I0617 18:32:43.756568  8058 solver.cpp:237]     Train net output #0: accuracy = 0.96
I0617 18:32:43.756603  8058 solver.cpp:237]     Train net output #1: loss = 0.178773 (* 1 = 0.178773 loss)
I0617 18:32:43.756621  8058 sgd_solver.cpp:105] Iteration 7900, lr = 0.01
I0617 18:32:53.048604  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 18:33:41.516824  8058 solver.cpp:218] Iteration 7950 (0.865654 iter/s, 57.7598s/50 iters), loss = 0.12724
I0617 18:33:41.516958  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 18:33:41.516995  8058 solver.cpp:237]     Train net output #1: loss = 0.12724 (* 1 = 0.12724 loss)
I0617 18:33:41.517019  8058 sgd_solver.cpp:105] Iteration 7950, lr = 0.01
I0617 18:34:39.283538  8058 solver.cpp:218] Iteration 8000 (0.865559 iter/s, 57.7661s/50 iters), loss = 0.143137
I0617 18:34:39.283638  8058 solver.cpp:237]     Train net output #0: accuracy = 0.98
I0617 18:34:39.283670  8058 solver.cpp:237]     Train net output #1: loss = 0.143137 (* 1 = 0.143137 loss)
I0617 18:34:39.283694  8058 sgd_solver.cpp:105] Iteration 8000, lr = 0.01
I0617 18:35:10.559195  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 18:35:37.049383  8058 solver.cpp:218] Iteration 8050 (0.865572 iter/s, 57.7653s/50 iters), loss = 0.128572
I0617 18:35:37.049466  8058 solver.cpp:237]     Train net output #0: accuracy = 0.98
I0617 18:35:37.049497  8058 solver.cpp:237]     Train net output #1: loss = 0.128572 (* 1 = 0.128572 loss)
I0617 18:35:37.049521  8058 sgd_solver.cpp:105] Iteration 8050, lr = 0.01
I0617 18:36:34.823309  8058 solver.cpp:218] Iteration 8100 (0.86545 iter/s, 57.7734s/50 iters), loss = 0.12235
I0617 18:36:34.823487  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 18:36:34.823528  8058 solver.cpp:237]     Train net output #1: loss = 0.12235 (* 1 = 0.12235 loss)
I0617 18:36:34.823550  8058 sgd_solver.cpp:105] Iteration 8100, lr = 0.01
I0617 18:37:29.218402  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 18:37:32.582015  8058 solver.cpp:218] Iteration 8150 (0.86568 iter/s, 57.7581s/50 iters), loss = 0.0817597
I0617 18:37:32.582113  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 18:37:32.582145  8058 solver.cpp:237]     Train net output #1: loss = 0.0817597 (* 1 = 0.0817597 loss)
I0617 18:37:32.582166  8058 sgd_solver.cpp:105] Iteration 8150, lr = 0.01
I0617 18:38:30.337369  8058 solver.cpp:218] Iteration 8200 (0.865729 iter/s, 57.7548s/50 iters), loss = 0.114234
I0617 18:38:30.337489  8058 solver.cpp:237]     Train net output #0: accuracy = 0.98
I0617 18:38:30.337534  8058 solver.cpp:237]     Train net output #1: loss = 0.114234 (* 1 = 0.114234 loss)
I0617 18:38:30.337560  8058 sgd_solver.cpp:105] Iteration 8200, lr = 0.01
I0617 18:39:28.095439  8058 solver.cpp:218] Iteration 8250 (0.865689 iter/s, 57.7575s/50 iters), loss = 0.0977011
I0617 18:39:28.095572  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 18:39:28.095605  8058 solver.cpp:237]     Train net output #1: loss = 0.0977011 (* 1 = 0.0977011 loss)
I0617 18:39:28.095625  8058 sgd_solver.cpp:105] Iteration 8250, lr = 0.01
I0617 18:39:47.834069  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 18:40:25.852769  8058 solver.cpp:218] Iteration 8300 (0.8657 iter/s, 57.7567s/50 iters), loss = 0.0808231
I0617 18:40:25.852886  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 18:40:25.852916  8058 solver.cpp:237]     Train net output #1: loss = 0.0808231 (* 1 = 0.0808231 loss)
I0617 18:40:25.852934  8058 sgd_solver.cpp:105] Iteration 8300, lr = 0.01
I0617 18:41:23.606806  8058 solver.cpp:218] Iteration 8350 (0.865749 iter/s, 57.7535s/50 iters), loss = 0.096528
I0617 18:41:23.606917  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 18:41:23.606950  8058 solver.cpp:237]     Train net output #1: loss = 0.096528 (* 1 = 0.096528 loss)
I0617 18:41:23.606971  8058 sgd_solver.cpp:105] Iteration 8350, lr = 0.01
I0617 18:42:06.429180  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 18:42:21.367980  8058 solver.cpp:218] Iteration 8400 (0.865642 iter/s, 57.7606s/50 iters), loss = 0.0774636
I0617 18:42:21.368060  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 18:42:21.368088  8058 solver.cpp:237]     Train net output #1: loss = 0.0774636 (* 1 = 0.0774636 loss)
I0617 18:42:21.368108  8058 sgd_solver.cpp:105] Iteration 8400, lr = 0.01
I0617 18:43:19.129631  8058 solver.cpp:218] Iteration 8450 (0.865634 iter/s, 57.7611s/50 iters), loss = 0.0521022
I0617 18:43:19.129742  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 18:43:19.129776  8058 solver.cpp:237]     Train net output #1: loss = 0.0521022 (* 1 = 0.0521022 loss)
I0617 18:43:19.129796  8058 sgd_solver.cpp:105] Iteration 8450, lr = 0.01
I0617 18:44:16.892539  8058 solver.cpp:218] Iteration 8500 (0.865616 iter/s, 57.7623s/50 iters), loss = 0.0826773
I0617 18:44:16.892704  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 18:44:16.892738  8058 solver.cpp:237]     Train net output #1: loss = 0.0826773 (* 1 = 0.0826773 loss)
I0617 18:44:16.892758  8058 sgd_solver.cpp:105] Iteration 8500, lr = 0.01
I0617 18:44:25.031541  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 18:45:14.665166  8058 solver.cpp:218] Iteration 8550 (0.865471 iter/s, 57.772s/50 iters), loss = 0.0760375
I0617 18:45:14.665288  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 18:45:14.665318  8058 solver.cpp:237]     Train net output #1: loss = 0.0760375 (* 1 = 0.0760375 loss)
I0617 18:45:14.665336  8058 sgd_solver.cpp:105] Iteration 8550, lr = 0.01
I0617 18:46:12.432827  8058 solver.cpp:218] Iteration 8600 (0.865545 iter/s, 57.7671s/50 iters), loss = 0.0516739
I0617 18:46:12.433009  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 18:46:12.433045  8058 solver.cpp:237]     Train net output #1: loss = 0.051674 (* 1 = 0.051674 loss)
I0617 18:46:12.433065  8058 sgd_solver.cpp:105] Iteration 8600, lr = 0.01
I0617 18:46:43.693611  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 18:47:10.205170  8058 solver.cpp:218] Iteration 8650 (0.865476 iter/s, 57.7717s/50 iters), loss = 0.0823433
I0617 18:47:10.205257  8058 solver.cpp:237]     Train net output #0: accuracy = 0.98
I0617 18:47:10.205291  8058 solver.cpp:237]     Train net output #1: loss = 0.0823433 (* 1 = 0.0823433 loss)
I0617 18:47:10.205310  8058 sgd_solver.cpp:105] Iteration 8650, lr = 0.01
I0617 18:48:07.972180  8058 solver.cpp:218] Iteration 8700 (0.865554 iter/s, 57.7665s/50 iters), loss = 0.0811835
I0617 18:48:07.972302  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 18:48:07.972335  8058 solver.cpp:237]     Train net output #1: loss = 0.0811835 (* 1 = 0.0811835 loss)
I0617 18:48:07.972355  8058 sgd_solver.cpp:105] Iteration 8700, lr = 0.01
I0617 18:49:02.468346  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 18:49:05.907572  8058 solver.cpp:218] Iteration 8750 (0.86304 iter/s, 57.9348s/50 iters), loss = 0.0917919
I0617 18:49:05.907696  8058 solver.cpp:237]     Train net output #0: accuracy = 0.98
I0617 18:49:05.907728  8058 solver.cpp:237]     Train net output #1: loss = 0.0917919 (* 1 = 0.0917919 loss)
I0617 18:49:05.907747  8058 sgd_solver.cpp:105] Iteration 8750, lr = 0.01
I0617 18:50:04.351625  8058 solver.cpp:218] Iteration 8800 (0.855531 iter/s, 58.4433s/50 iters), loss = 0.14243
I0617 18:50:04.352660  8058 solver.cpp:237]     Train net output #0: accuracy = 0.98
I0617 18:50:04.352707  8058 solver.cpp:237]     Train net output #1: loss = 0.14243 (* 1 = 0.14243 loss)
I0617 18:50:04.352731  8058 sgd_solver.cpp:105] Iteration 8800, lr = 0.01
I0617 18:51:02.739610  8058 solver.cpp:218] Iteration 8850 (0.856365 iter/s, 58.3863s/50 iters), loss = 0.112163
I0617 18:51:02.741603  8058 solver.cpp:237]     Train net output #0: accuracy = 0.98
I0617 18:51:02.741641  8058 solver.cpp:237]     Train net output #1: loss = 0.112163 (* 1 = 0.112163 loss)
I0617 18:51:02.741659  8058 sgd_solver.cpp:105] Iteration 8850, lr = 0.01
I0617 18:51:22.564697  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 18:52:00.672466  8058 solver.cpp:218] Iteration 8900 (0.863107 iter/s, 57.9302s/50 iters), loss = 0.0650989
I0617 18:52:00.672659  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 18:52:00.672693  8058 solver.cpp:237]     Train net output #1: loss = 0.0650989 (* 1 = 0.0650989 loss)
I0617 18:52:00.672714  8058 sgd_solver.cpp:105] Iteration 8900, lr = 0.01
I0617 18:52:58.451342  8058 solver.cpp:218] Iteration 8950 (0.86538 iter/s, 57.7781s/50 iters), loss = 0.0715912
I0617 18:52:58.451489  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 18:52:58.451534  8058 solver.cpp:237]     Train net output #1: loss = 0.0715912 (* 1 = 0.0715912 loss)
I0617 18:52:58.451557  8058 sgd_solver.cpp:105] Iteration 8950, lr = 0.01
I0617 18:53:40.168594  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 18:53:56.232074  8058 solver.cpp:218] Iteration 9000 (0.865352 iter/s, 57.78s/50 iters), loss = 0.0768681
I0617 18:53:56.232156  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 18:53:56.232184  8058 solver.cpp:237]     Train net output #1: loss = 0.0768681 (* 1 = 0.0768681 loss)
I0617 18:53:56.232204  8058 sgd_solver.cpp:105] Iteration 9000, lr = 0.01
I0617 18:54:54.006045  8058 solver.cpp:218] Iteration 9050 (0.865452 iter/s, 57.7733s/50 iters), loss = 0.0680475
I0617 18:54:54.006223  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 18:54:54.006260  8058 solver.cpp:237]     Train net output #1: loss = 0.0680475 (* 1 = 0.0680475 loss)
I0617 18:54:54.006284  8058 sgd_solver.cpp:105] Iteration 9050, lr = 0.01
I0617 18:55:51.770876  8058 solver.cpp:218] Iteration 9100 (0.86559 iter/s, 57.764s/50 iters), loss = 0.0522091
I0617 18:55:51.771067  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 18:55:51.771101  8058 solver.cpp:237]     Train net output #1: loss = 0.0522091 (* 1 = 0.0522091 loss)
I0617 18:55:51.771122  8058 sgd_solver.cpp:105] Iteration 9100, lr = 0.01
I0617 18:55:58.784445  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 18:56:49.536530  8058 solver.cpp:218] Iteration 9150 (0.865578 iter/s, 57.7649s/50 iters), loss = 0.0708583
I0617 18:56:49.536659  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 18:56:49.536694  8058 solver.cpp:237]     Train net output #1: loss = 0.0708583 (* 1 = 0.0708583 loss)
I0617 18:56:49.536715  8058 sgd_solver.cpp:105] Iteration 9150, lr = 0.01
I0617 18:57:47.305677  8058 solver.cpp:218] Iteration 9200 (0.865525 iter/s, 57.7684s/50 iters), loss = 0.0750895
I0617 18:57:47.305811  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 18:57:47.305843  8058 solver.cpp:237]     Train net output #1: loss = 0.0750895 (* 1 = 0.0750895 loss)
I0617 18:57:47.305863  8058 sgd_solver.cpp:105] Iteration 9200, lr = 0.01
I0617 18:58:17.447645  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 18:58:45.097601  8058 solver.cpp:218] Iteration 9250 (0.865184 iter/s, 57.7912s/50 iters), loss = 0.0406768
I0617 18:58:45.097692  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 18:58:45.097721  8058 solver.cpp:237]     Train net output #1: loss = 0.0406768 (* 1 = 0.0406768 loss)
I0617 18:58:45.097741  8058 sgd_solver.cpp:105] Iteration 9250, lr = 0.01
I0617 18:59:42.862042  8058 solver.cpp:218] Iteration 9300 (0.865595 iter/s, 57.7637s/50 iters), loss = 0.0970551
I0617 18:59:42.862190  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 18:59:42.862221  8058 solver.cpp:237]     Train net output #1: loss = 0.0970551 (* 1 = 0.0970551 loss)
I0617 18:59:42.862239  8058 sgd_solver.cpp:105] Iteration 9300, lr = 0.01
I0617 19:00:36.073459  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 19:00:40.631193  8058 solver.cpp:218] Iteration 9350 (0.865525 iter/s, 57.7684s/50 iters), loss = 0.0518337
I0617 19:00:40.631273  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 19:00:40.631304  8058 solver.cpp:237]     Train net output #1: loss = 0.0518337 (* 1 = 0.0518337 loss)
I0617 19:00:40.631325  8058 sgd_solver.cpp:105] Iteration 9350, lr = 0.01
I0617 19:01:38.410264  8058 solver.cpp:218] Iteration 9400 (0.865375 iter/s, 57.7784s/50 iters), loss = 0.0528152
I0617 19:01:38.410392  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 19:01:38.410425  8058 solver.cpp:237]     Train net output #1: loss = 0.0528152 (* 1 = 0.0528152 loss)
I0617 19:01:38.410445  8058 sgd_solver.cpp:105] Iteration 9400, lr = 0.01
I0617 19:02:36.170805  8058 solver.cpp:218] Iteration 9450 (0.865654 iter/s, 57.7598s/50 iters), loss = 0.0559889
I0617 19:02:36.170922  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 19:02:36.170953  8058 solver.cpp:237]     Train net output #1: loss = 0.0559889 (* 1 = 0.0559889 loss)
I0617 19:02:36.170972  8058 sgd_solver.cpp:105] Iteration 9450, lr = 0.01
I0617 19:02:54.744477  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 19:03:33.931169  8058 solver.cpp:218] Iteration 9500 (0.865656 iter/s, 57.7596s/50 iters), loss = 0.0392072
I0617 19:03:33.931301  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 19:03:33.931331  8058 solver.cpp:237]     Train net output #1: loss = 0.0392072 (* 1 = 0.0392072 loss)
I0617 19:03:33.931351  8058 sgd_solver.cpp:105] Iteration 9500, lr = 0.01
I0617 19:04:31.692920  8058 solver.cpp:218] Iteration 9550 (0.865636 iter/s, 57.761s/50 iters), loss = 0.0506304
I0617 19:04:31.693061  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 19:04:31.693096  8058 solver.cpp:237]     Train net output #1: loss = 0.0506304 (* 1 = 0.0506304 loss)
I0617 19:04:31.693116  8058 sgd_solver.cpp:105] Iteration 9550, lr = 0.01
I0617 19:05:13.358386  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 19:05:29.444764  8058 solver.cpp:218] Iteration 9600 (0.865784 iter/s, 57.7511s/50 iters), loss = 0.0639657
I0617 19:05:29.444846  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 19:05:29.444875  8058 solver.cpp:237]     Train net output #1: loss = 0.0639657 (* 1 = 0.0639657 loss)
I0617 19:05:29.444895  8058 sgd_solver.cpp:105] Iteration 9600, lr = 0.01
I0617 19:06:27.208873  8058 solver.cpp:218] Iteration 9650 (0.865599 iter/s, 57.7635s/50 iters), loss = 0.0378453
I0617 19:06:27.208999  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 19:06:27.209030  8058 solver.cpp:237]     Train net output #1: loss = 0.0378453 (* 1 = 0.0378453 loss)
I0617 19:06:27.209050  8058 sgd_solver.cpp:105] Iteration 9650, lr = 0.01
I0617 19:07:25.031924  8058 solver.cpp:218] Iteration 9700 (0.864716 iter/s, 57.8225s/50 iters), loss = 0.0256261
I0617 19:07:25.032043  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 19:07:25.032074  8058 solver.cpp:237]     Train net output #1: loss = 0.0256261 (* 1 = 0.0256261 loss)
I0617 19:07:25.032094  8058 sgd_solver.cpp:105] Iteration 9700, lr = 0.01
I0617 19:07:32.041806  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 19:08:22.793645  8058 solver.cpp:218] Iteration 9750 (0.865634 iter/s, 57.7611s/50 iters), loss = 0.0609437
I0617 19:08:22.793824  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 19:08:22.793859  8058 solver.cpp:237]     Train net output #1: loss = 0.0609437 (* 1 = 0.0609437 loss)
I0617 19:08:22.793879  8058 sgd_solver.cpp:105] Iteration 9750, lr = 0.01
I0617 19:09:20.609946  8058 solver.cpp:218] Iteration 9800 (0.864818 iter/s, 57.8156s/50 iters), loss = 0.0420293
I0617 19:09:20.610100  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 19:09:20.610132  8058 solver.cpp:237]     Train net output #1: loss = 0.0420293 (* 1 = 0.0420293 loss)
I0617 19:09:20.610153  8058 sgd_solver.cpp:105] Iteration 9800, lr = 0.01
I0617 19:09:50.725410  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 19:10:18.416229  8058 solver.cpp:218] Iteration 9850 (0.864967 iter/s, 57.8056s/50 iters), loss = 0.0457413
I0617 19:10:18.416365  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 19:10:18.416404  8058 solver.cpp:237]     Train net output #1: loss = 0.0457413 (* 1 = 0.0457413 loss)
I0617 19:10:18.416429  8058 sgd_solver.cpp:105] Iteration 9850, lr = 0.01
I0617 19:11:16.223815  8058 solver.cpp:218] Iteration 9900 (0.864947 iter/s, 57.807s/50 iters), loss = 0.0568682
I0617 19:11:16.223960  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 19:11:16.223992  8058 solver.cpp:237]     Train net output #1: loss = 0.0568682 (* 1 = 0.0568682 loss)
I0617 19:11:16.224012  8058 sgd_solver.cpp:105] Iteration 9900, lr = 0.01
I0617 19:12:09.479812  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 19:12:14.034662  8058 solver.cpp:218] Iteration 9950 (0.864899 iter/s, 57.8102s/50 iters), loss = 0.04122
I0617 19:12:14.034788  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 19:12:14.034821  8058 solver.cpp:237]     Train net output #1: loss = 0.04122 (* 1 = 0.04122 loss)
I0617 19:12:14.034842  8058 sgd_solver.cpp:105] Iteration 9950, lr = 0.01
I0617 19:13:10.700283  8058 solver.cpp:447] Snapshotting to binary proto file mobilenet/mobile_cub_iter_10000.caffemodel
I0617 19:13:10.809836  8058 sgd_solver.cpp:273] Snapshotting solver state to binary proto file mobilenet/mobile_cub_iter_10000.solverstate
I0617 19:13:11.992877  8058 solver.cpp:218] Iteration 10000 (0.8627 iter/s, 57.9576s/50 iters), loss = 0.0334606
I0617 19:13:11.992985  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 19:13:11.993016  8058 solver.cpp:237]     Train net output #1: loss = 0.0334606 (* 1 = 0.0334606 loss)
I0617 19:13:11.993036  8058 sgd_solver.cpp:105] Iteration 10000, lr = 0.01
I0617 19:14:09.804332  8058 solver.cpp:218] Iteration 10050 (0.86489 iter/s, 57.8109s/50 iters), loss = 0.0324008
I0617 19:14:09.804576  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 19:14:09.804615  8058 solver.cpp:237]     Train net output #1: loss = 0.0324008 (* 1 = 0.0324008 loss)
I0617 19:14:09.804638  8058 sgd_solver.cpp:105] Iteration 10050, lr = 0.01
I0617 19:14:27.233103  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 19:15:07.622073  8058 solver.cpp:218] Iteration 10100 (0.864798 iter/s, 57.817s/50 iters), loss = 0.050486
I0617 19:15:07.622246  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 19:15:07.622284  8058 solver.cpp:237]     Train net output #1: loss = 0.050486 (* 1 = 0.050486 loss)
I0617 19:15:07.622309  8058 sgd_solver.cpp:105] Iteration 10100, lr = 0.01
I0617 19:16:05.440390  8058 solver.cpp:218] Iteration 10150 (0.864788 iter/s, 57.8177s/50 iters), loss = 0.0385511
I0617 19:16:05.440524  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 19:16:05.440559  8058 solver.cpp:237]     Train net output #1: loss = 0.0385511 (* 1 = 0.0385511 loss)
I0617 19:16:05.440582  8058 sgd_solver.cpp:105] Iteration 10150, lr = 0.01
I0617 19:16:45.985982  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 19:17:03.241749  8058 solver.cpp:218] Iteration 10200 (0.865041 iter/s, 57.8007s/50 iters), loss = 0.0371866
I0617 19:17:03.241871  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 19:17:03.241904  8058 solver.cpp:237]     Train net output #1: loss = 0.0371866 (* 1 = 0.0371866 loss)
I0617 19:17:03.241925  8058 sgd_solver.cpp:105] Iteration 10200, lr = 0.01
I0617 19:18:01.046928  8058 solver.cpp:218] Iteration 10250 (0.864983 iter/s, 57.8046s/50 iters), loss = 0.0453698
I0617 19:18:01.047062  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 19:18:01.047096  8058 solver.cpp:237]     Train net output #1: loss = 0.0453698 (* 1 = 0.0453698 loss)
I0617 19:18:01.047116  8058 sgd_solver.cpp:105] Iteration 10250, lr = 0.01
I0617 19:18:58.833108  8058 solver.cpp:218] Iteration 10300 (0.865268 iter/s, 57.7856s/50 iters), loss = 0.0317189
I0617 19:18:58.833268  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 19:18:58.833302  8058 solver.cpp:237]     Train net output #1: loss = 0.0317189 (* 1 = 0.0317189 loss)
I0617 19:18:58.833324  8058 sgd_solver.cpp:105] Iteration 10300, lr = 0.01
I0617 19:19:04.702884  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 19:19:56.605231  8058 solver.cpp:218] Iteration 10350 (0.865479 iter/s, 57.7715s/50 iters), loss = 0.0552851
I0617 19:19:56.605360  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 19:19:56.605392  8058 solver.cpp:237]     Train net output #1: loss = 0.0552851 (* 1 = 0.0552851 loss)
I0617 19:19:56.605414  8058 sgd_solver.cpp:105] Iteration 10350, lr = 0.01
I0617 19:20:54.359892  8058 solver.cpp:218] Iteration 10400 (0.86574 iter/s, 57.7541s/50 iters), loss = 0.029247
I0617 19:20:54.360025  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 19:20:54.360059  8058 solver.cpp:237]     Train net output #1: loss = 0.029247 (* 1 = 0.029247 loss)
I0617 19:20:54.360080  8058 sgd_solver.cpp:105] Iteration 10400, lr = 0.01
I0617 19:21:23.307621  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 19:21:52.120342  8058 solver.cpp:218] Iteration 10450 (0.865654 iter/s, 57.7598s/50 iters), loss = 0.0416602
I0617 19:21:52.120471  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 19:21:52.120508  8058 solver.cpp:237]     Train net output #1: loss = 0.0416602 (* 1 = 0.0416602 loss)
I0617 19:21:52.120539  8058 sgd_solver.cpp:105] Iteration 10450, lr = 0.01
I0617 19:22:49.887679  8058 solver.cpp:218] Iteration 10500 (0.86555 iter/s, 57.7667s/50 iters), loss = 0.0331268
I0617 19:22:49.887814  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 19:22:49.887848  8058 solver.cpp:237]     Train net output #1: loss = 0.0331268 (* 1 = 0.0331268 loss)
I0617 19:22:49.887871  8058 sgd_solver.cpp:105] Iteration 10500, lr = 0.01
I0617 19:23:42.014467  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 19:23:47.702527  8058 solver.cpp:218] Iteration 10550 (0.864839 iter/s, 57.8142s/50 iters), loss = 0.0336074
I0617 19:23:47.702621  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 19:23:47.702656  8058 solver.cpp:237]     Train net output #1: loss = 0.0336074 (* 1 = 0.0336074 loss)
I0617 19:23:47.702682  8058 sgd_solver.cpp:105] Iteration 10550, lr = 0.01
I0617 19:24:45.471544  8058 solver.cpp:218] Iteration 10600 (0.865525 iter/s, 57.7684s/50 iters), loss = 0.0281089
I0617 19:24:45.471674  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 19:24:45.471707  8058 solver.cpp:237]     Train net output #1: loss = 0.0281089 (* 1 = 0.0281089 loss)
I0617 19:24:45.471729  8058 sgd_solver.cpp:105] Iteration 10600, lr = 0.01
I0617 19:25:43.242112  8058 solver.cpp:218] Iteration 10650 (0.865502 iter/s, 57.77s/50 iters), loss = 0.0272842
I0617 19:25:43.242244  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 19:25:43.242277  8058 solver.cpp:237]     Train net output #1: loss = 0.0272842 (* 1 = 0.0272842 loss)
I0617 19:25:43.242300  8058 sgd_solver.cpp:105] Iteration 10650, lr = 0.01
I0617 19:26:00.641198  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 19:26:41.018671  8058 solver.cpp:218] Iteration 10700 (0.865412 iter/s, 57.7759s/50 iters), loss = 0.0290853
I0617 19:26:41.018798  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 19:26:41.018836  8058 solver.cpp:237]     Train net output #1: loss = 0.0290853 (* 1 = 0.0290853 loss)
I0617 19:26:41.018862  8058 sgd_solver.cpp:105] Iteration 10700, lr = 0.01
I0617 19:27:38.779383  8058 solver.cpp:218] Iteration 10750 (0.86565 iter/s, 57.7601s/50 iters), loss = 0.0267452
I0617 19:27:38.779510  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 19:27:38.779551  8058 solver.cpp:237]     Train net output #1: loss = 0.0267452 (* 1 = 0.0267452 loss)
I0617 19:27:38.779573  8058 sgd_solver.cpp:105] Iteration 10750, lr = 0.01
I0617 19:28:19.319084  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 19:28:36.598620  8058 solver.cpp:218] Iteration 10800 (0.864773 iter/s, 57.8186s/50 iters), loss = 0.0358355
I0617 19:28:36.598708  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 19:28:36.598742  8058 solver.cpp:237]     Train net output #1: loss = 0.0358355 (* 1 = 0.0358355 loss)
I0617 19:28:36.598762  8058 sgd_solver.cpp:105] Iteration 10800, lr = 0.01
I0617 19:29:34.379104  8058 solver.cpp:218] Iteration 10850 (0.865353 iter/s, 57.7799s/50 iters), loss = 0.0273169
I0617 19:29:34.379228  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 19:29:34.379262  8058 solver.cpp:237]     Train net output #1: loss = 0.0273169 (* 1 = 0.0273169 loss)
I0617 19:29:34.379286  8058 sgd_solver.cpp:105] Iteration 10850, lr = 0.01
I0617 19:30:32.138825  8058 solver.cpp:218] Iteration 10900 (0.865665 iter/s, 57.7591s/50 iters), loss = 0.026227
I0617 19:30:32.138955  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 19:30:32.138993  8058 solver.cpp:237]     Train net output #1: loss = 0.026227 (* 1 = 0.026227 loss)
I0617 19:30:32.139017  8058 sgd_solver.cpp:105] Iteration 10900, lr = 0.01
I0617 19:30:37.965250  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 19:31:29.899945  8058 solver.cpp:218] Iteration 10950 (0.865643 iter/s, 57.7605s/50 iters), loss = 0.0264497
I0617 19:31:29.900086  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 19:31:29.900120  8058 solver.cpp:237]     Train net output #1: loss = 0.0264497 (* 1 = 0.0264497 loss)
I0617 19:31:29.900142  8058 sgd_solver.cpp:105] Iteration 10950, lr = 0.01
I0617 19:32:27.662459  8058 solver.cpp:218] Iteration 11000 (0.865623 iter/s, 57.7619s/50 iters), loss = 0.0265238
I0617 19:32:27.662583  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 19:32:27.662617  8058 solver.cpp:237]     Train net output #1: loss = 0.0265238 (* 1 = 0.0265238 loss)
I0617 19:32:27.662637  8058 sgd_solver.cpp:105] Iteration 11000, lr = 0.01
I0617 19:32:55.506641  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 19:33:25.435843  8058 solver.cpp:218] Iteration 11050 (0.86546 iter/s, 57.7728s/50 iters), loss = 0.0276852
I0617 19:33:25.436012  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 19:33:25.436045  8058 solver.cpp:237]     Train net output #1: loss = 0.0276852 (* 1 = 0.0276852 loss)
I0617 19:33:25.436067  8058 sgd_solver.cpp:105] Iteration 11050, lr = 0.01
I0617 19:34:23.196672  8058 solver.cpp:218] Iteration 11100 (0.865649 iter/s, 57.7601s/50 iters), loss = 0.0378196
I0617 19:34:23.196825  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 19:34:23.196862  8058 solver.cpp:237]     Train net output #1: loss = 0.0378196 (* 1 = 0.0378196 loss)
I0617 19:34:23.196887  8058 sgd_solver.cpp:105] Iteration 11100, lr = 0.01
I0617 19:35:14.112761  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 19:35:20.958420  8058 solver.cpp:218] Iteration 11150 (0.865635 iter/s, 57.7611s/50 iters), loss = 0.0317115
I0617 19:35:20.958503  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 19:35:20.958544  8058 solver.cpp:237]     Train net output #1: loss = 0.0317115 (* 1 = 0.0317115 loss)
I0617 19:35:20.958580  8058 sgd_solver.cpp:105] Iteration 11150, lr = 0.01
I0617 19:36:18.725877  8058 solver.cpp:218] Iteration 11200 (0.865548 iter/s, 57.7669s/50 iters), loss = 0.0236081
I0617 19:36:18.726011  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 19:36:18.726043  8058 solver.cpp:237]     Train net output #1: loss = 0.0236081 (* 1 = 0.0236081 loss)
I0617 19:36:18.726063  8058 sgd_solver.cpp:105] Iteration 11200, lr = 0.01
I0617 19:37:16.552217  8058 solver.cpp:218] Iteration 11250 (0.864668 iter/s, 57.8257s/50 iters), loss = 0.0434941
I0617 19:37:16.553009  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 19:37:16.553042  8058 solver.cpp:237]     Train net output #1: loss = 0.0434941 (* 1 = 0.0434941 loss)
I0617 19:37:16.553064  8058 sgd_solver.cpp:105] Iteration 11250, lr = 0.01
I0617 19:37:32.847854  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 19:38:14.380957  8058 solver.cpp:218] Iteration 11300 (0.864641 iter/s, 57.8274s/50 iters), loss = 0.0251552
I0617 19:38:14.381106  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 19:38:14.381141  8058 solver.cpp:237]     Train net output #1: loss = 0.0251552 (* 1 = 0.0251552 loss)
I0617 19:38:14.381161  8058 sgd_solver.cpp:105] Iteration 11300, lr = 0.01
I0617 19:39:12.197628  8058 solver.cpp:218] Iteration 11350 (0.864812 iter/s, 57.816s/50 iters), loss = 0.0321787
I0617 19:39:12.197782  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 19:39:12.197814  8058 solver.cpp:237]     Train net output #1: loss = 0.0321787 (* 1 = 0.0321787 loss)
I0617 19:39:12.197836  8058 sgd_solver.cpp:105] Iteration 11350, lr = 0.01
I0617 19:39:51.568140  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 19:40:10.016681  8058 solver.cpp:218] Iteration 11400 (0.864777 iter/s, 57.8184s/50 iters), loss = 0.0268872
I0617 19:40:10.016798  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 19:40:10.016834  8058 solver.cpp:237]     Train net output #1: loss = 0.0268872 (* 1 = 0.0268872 loss)
I0617 19:40:10.016858  8058 sgd_solver.cpp:105] Iteration 11400, lr = 0.01
I0617 19:41:07.837611  8058 solver.cpp:218] Iteration 11450 (0.864749 iter/s, 57.8202s/50 iters), loss = 0.0344754
I0617 19:41:07.837805  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 19:41:07.837837  8058 solver.cpp:237]     Train net output #1: loss = 0.0344754 (* 1 = 0.0344754 loss)
I0617 19:41:07.837857  8058 sgd_solver.cpp:105] Iteration 11450, lr = 0.01
I0617 19:42:05.664925  8058 solver.cpp:218] Iteration 11500 (0.864655 iter/s, 57.8265s/50 iters), loss = 0.034493
I0617 19:42:05.665149  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 19:42:05.665184  8058 solver.cpp:237]     Train net output #1: loss = 0.034493 (* 1 = 0.034493 loss)
I0617 19:42:05.665205  8058 sgd_solver.cpp:105] Iteration 11500, lr = 0.01
I0617 19:42:10.345629  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 19:43:03.460865  8058 solver.cpp:218] Iteration 11550 (0.865125 iter/s, 57.7951s/50 iters), loss = 0.0226203
I0617 19:43:03.461091  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 19:43:03.461124  8058 solver.cpp:237]     Train net output #1: loss = 0.0226203 (* 1 = 0.0226203 loss)
I0617 19:43:03.461146  8058 sgd_solver.cpp:105] Iteration 11550, lr = 0.01
I0617 19:44:01.247150  8058 solver.cpp:218] Iteration 11600 (0.86527 iter/s, 57.7855s/50 iters), loss = 0.0375984
I0617 19:44:01.247920  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 19:44:01.247977  8058 solver.cpp:237]     Train net output #1: loss = 0.0375984 (* 1 = 0.0375984 loss)
I0617 19:44:01.248004  8058 sgd_solver.cpp:105] Iteration 11600, lr = 0.01
I0617 19:44:29.065320  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 19:44:59.053517  8058 solver.cpp:218] Iteration 11650 (0.864977 iter/s, 57.805s/50 iters), loss = 0.0383714
I0617 19:44:59.053688  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 19:44:59.053738  8058 solver.cpp:237]     Train net output #1: loss = 0.0383714 (* 1 = 0.0383714 loss)
I0617 19:44:59.053761  8058 sgd_solver.cpp:105] Iteration 11650, lr = 0.01
I0617 19:45:56.860988  8058 solver.cpp:218] Iteration 11700 (0.864952 iter/s, 57.8067s/50 iters), loss = 0.0236012
I0617 19:45:56.861176  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 19:45:56.861217  8058 solver.cpp:237]     Train net output #1: loss = 0.0236012 (* 1 = 0.0236012 loss)
I0617 19:45:56.861240  8058 sgd_solver.cpp:105] Iteration 11700, lr = 0.01
I0617 19:46:47.811619  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 19:46:54.663655  8058 solver.cpp:218] Iteration 11750 (0.865024 iter/s, 57.8019s/50 iters), loss = 0.0275344
I0617 19:46:54.663754  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 19:46:54.663794  8058 solver.cpp:237]     Train net output #1: loss = 0.0275343 (* 1 = 0.0275343 loss)
I0617 19:46:54.663825  8058 sgd_solver.cpp:105] Iteration 11750, lr = 0.01
I0617 19:47:52.439594  8058 solver.cpp:218] Iteration 11800 (0.865422 iter/s, 57.7753s/50 iters), loss = 0.0228939
I0617 19:47:52.439724  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 19:47:52.439759  8058 solver.cpp:237]     Train net output #1: loss = 0.0228939 (* 1 = 0.0228939 loss)
I0617 19:47:52.439776  8058 sgd_solver.cpp:105] Iteration 11800, lr = 0.01
I0617 19:48:50.224500  8058 solver.cpp:218] Iteration 11850 (0.865289 iter/s, 57.7842s/50 iters), loss = 0.030236
I0617 19:48:50.226521  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 19:48:50.226555  8058 solver.cpp:237]     Train net output #1: loss = 0.030236 (* 1 = 0.030236 loss)
I0617 19:48:50.226577  8058 sgd_solver.cpp:105] Iteration 11850, lr = 0.01
I0617 19:49:06.457769  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 19:49:48.014120  8058 solver.cpp:218] Iteration 11900 (0.865246 iter/s, 57.787s/50 iters), loss = 0.0225562
I0617 19:49:48.014255  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 19:49:48.014286  8058 solver.cpp:237]     Train net output #1: loss = 0.0225562 (* 1 = 0.0225562 loss)
I0617 19:49:48.014307  8058 sgd_solver.cpp:105] Iteration 11900, lr = 0.01
I0617 19:50:45.781467  8058 solver.cpp:218] Iteration 11950 (0.865551 iter/s, 57.7666s/50 iters), loss = 0.0281662
I0617 19:50:45.781605  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 19:50:45.781641  8058 solver.cpp:237]     Train net output #1: loss = 0.0281662 (* 1 = 0.0281662 loss)
I0617 19:50:45.781661  8058 sgd_solver.cpp:105] Iteration 11950, lr = 0.01
I0617 19:51:23.993149  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 19:51:43.547348  8058 solver.cpp:218] Iteration 12000 (0.865574 iter/s, 57.7652s/50 iters), loss = 0.0208729
I0617 19:51:43.547433  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 19:51:43.547464  8058 solver.cpp:237]     Train net output #1: loss = 0.0208729 (* 1 = 0.0208729 loss)
I0617 19:51:43.547484  8058 sgd_solver.cpp:105] Iteration 12000, lr = 0.01
I0617 19:52:41.307404  8058 solver.cpp:218] Iteration 12050 (0.86566 iter/s, 57.7594s/50 iters), loss = 0.0235715
I0617 19:52:41.307623  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 19:52:41.307663  8058 solver.cpp:237]     Train net output #1: loss = 0.0235715 (* 1 = 0.0235715 loss)
I0617 19:52:41.307687  8058 sgd_solver.cpp:105] Iteration 12050, lr = 0.01
I0617 19:53:39.614603  8058 solver.cpp:218] Iteration 12100 (0.857544 iter/s, 58.306s/50 iters), loss = 0.028896
I0617 19:53:39.618600  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 19:53:39.618638  8058 solver.cpp:237]     Train net output #1: loss = 0.028896 (* 1 = 0.028896 loss)
I0617 19:53:39.618656  8058 sgd_solver.cpp:105] Iteration 12100, lr = 0.01
I0617 19:53:43.185365  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 19:54:37.726011  8058 solver.cpp:218] Iteration 12150 (0.860484 iter/s, 58.1068s/50 iters), loss = 0.0273986
I0617 19:54:37.726272  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 19:54:37.726303  8058 solver.cpp:237]     Train net output #1: loss = 0.0273986 (* 1 = 0.0273986 loss)
I0617 19:54:37.726322  8058 sgd_solver.cpp:105] Iteration 12150, lr = 0.01
I0617 19:55:35.675603  8058 solver.cpp:218] Iteration 12200 (0.862832 iter/s, 57.9487s/50 iters), loss = 0.022996
I0617 19:55:35.675887  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 19:55:35.675920  8058 solver.cpp:237]     Train net output #1: loss = 0.022996 (* 1 = 0.022996 loss)
I0617 19:55:35.675937  8058 sgd_solver.cpp:105] Iteration 12200, lr = 0.01
I0617 19:56:02.557682  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 19:56:33.807706  8058 solver.cpp:218] Iteration 12250 (0.860124 iter/s, 58.1312s/50 iters), loss = 0.0256325
I0617 19:56:33.807950  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 19:56:33.807982  8058 solver.cpp:237]     Train net output #1: loss = 0.0256325 (* 1 = 0.0256325 loss)
I0617 19:56:33.808002  8058 sgd_solver.cpp:105] Iteration 12250, lr = 0.01
I0617 19:57:32.058346  8058 solver.cpp:218] Iteration 12300 (0.858372 iter/s, 58.2498s/50 iters), loss = 0.0311912
I0617 19:57:32.061801  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 19:57:32.061851  8058 solver.cpp:237]     Train net output #1: loss = 0.0311912 (* 1 = 0.0311912 loss)
I0617 19:57:32.061873  8058 sgd_solver.cpp:105] Iteration 12300, lr = 0.01
I0617 19:58:22.357489  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 19:58:30.330821  8058 solver.cpp:218] Iteration 12350 (0.858098 iter/s, 58.2684s/50 iters), loss = 0.0265351
I0617 19:58:30.330940  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 19:58:30.330970  8058 solver.cpp:237]     Train net output #1: loss = 0.0265351 (* 1 = 0.0265351 loss)
I0617 19:58:30.330989  8058 sgd_solver.cpp:105] Iteration 12350, lr = 0.01
I0617 19:59:28.683642  8058 solver.cpp:218] Iteration 12400 (0.856914 iter/s, 58.3489s/50 iters), loss = 0.0207376
I0617 19:59:28.687625  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 19:59:28.687671  8058 solver.cpp:237]     Train net output #1: loss = 0.0207376 (* 1 = 0.0207376 loss)
I0617 19:59:28.687690  8058 sgd_solver.cpp:105] Iteration 12400, lr = 0.01
I0617 20:00:27.009928  8058 solver.cpp:218] Iteration 12450 (0.857314 iter/s, 58.3217s/50 iters), loss = 0.0198069
I0617 20:00:27.013604  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 20:00:27.013648  8058 solver.cpp:237]     Train net output #1: loss = 0.0198069 (* 1 = 0.0198069 loss)
I0617 20:00:27.013671  8058 sgd_solver.cpp:105] Iteration 12450, lr = 0.01
I0617 20:00:42.155602  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 20:01:24.882784  8058 solver.cpp:218] Iteration 12500 (0.864026 iter/s, 57.8686s/50 iters), loss = 0.0282995
I0617 20:01:24.883066  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 20:01:24.883100  8058 solver.cpp:237]     Train net output #1: loss = 0.0282995 (* 1 = 0.0282995 loss)
I0617 20:01:24.883121  8058 sgd_solver.cpp:105] Iteration 12500, lr = 0.01
I0617 20:02:22.734928  8058 solver.cpp:218] Iteration 12550 (0.864285 iter/s, 57.8513s/50 iters), loss = 0.0274818
I0617 20:02:22.735106  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 20:02:22.735139  8058 solver.cpp:237]     Train net output #1: loss = 0.0274818 (* 1 = 0.0274818 loss)
I0617 20:02:22.735160  8058 sgd_solver.cpp:105] Iteration 12550, lr = 0.01
I0617 20:03:00.941028  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 20:03:20.544965  8058 solver.cpp:218] Iteration 12600 (0.864913 iter/s, 57.8093s/50 iters), loss = 0.0212706
I0617 20:03:20.545068  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 20:03:20.545099  8058 solver.cpp:237]     Train net output #1: loss = 0.0212706 (* 1 = 0.0212706 loss)
I0617 20:03:20.545116  8058 sgd_solver.cpp:105] Iteration 12600, lr = 0.01
I0617 20:04:18.368139  8058 solver.cpp:218] Iteration 12650 (0.864716 iter/s, 57.8225s/50 iters), loss = 0.0212552
I0617 20:04:18.371407  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 20:04:18.371445  8058 solver.cpp:237]     Train net output #1: loss = 0.0212552 (* 1 = 0.0212552 loss)
I0617 20:04:18.371467  8058 sgd_solver.cpp:105] Iteration 12650, lr = 0.01
I0617 20:05:16.204041  8058 solver.cpp:218] Iteration 12700 (0.864573 iter/s, 57.832s/50 iters), loss = 0.0263154
I0617 20:05:16.204268  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 20:05:16.204303  8058 solver.cpp:237]     Train net output #1: loss = 0.0263154 (* 1 = 0.0263154 loss)
I0617 20:05:16.204322  8058 sgd_solver.cpp:105] Iteration 12700, lr = 0.01
I0617 20:05:19.840067  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 20:06:14.078142  8058 solver.cpp:218] Iteration 12750 (0.863957 iter/s, 57.8733s/50 iters), loss = 0.0255251
I0617 20:06:14.078407  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 20:06:14.078444  8058 solver.cpp:237]     Train net output #1: loss = 0.0255251 (* 1 = 0.0255251 loss)
I0617 20:06:14.078465  8058 sgd_solver.cpp:105] Iteration 12750, lr = 0.01
I0617 20:07:11.973572  8058 solver.cpp:218] Iteration 12800 (0.863639 iter/s, 57.8946s/50 iters), loss = 0.0250389
I0617 20:07:11.973801  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 20:07:11.973835  8058 solver.cpp:237]     Train net output #1: loss = 0.0250389 (* 1 = 0.0250389 loss)
I0617 20:07:11.973857  8058 sgd_solver.cpp:105] Iteration 12800, lr = 0.01
I0617 20:07:38.786306  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 20:08:09.860054  8058 solver.cpp:218] Iteration 12850 (0.863772 iter/s, 57.8857s/50 iters), loss = 0.0271554
I0617 20:08:09.860286  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 20:08:09.860319  8058 solver.cpp:237]     Train net output #1: loss = 0.0271554 (* 1 = 0.0271554 loss)
I0617 20:08:09.860339  8058 sgd_solver.cpp:105] Iteration 12850, lr = 0.01
I0617 20:09:07.729634  8058 solver.cpp:218] Iteration 12900 (0.864024 iter/s, 57.8688s/50 iters), loss = 0.0291434
I0617 20:09:07.731446  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 20:09:07.731501  8058 solver.cpp:237]     Train net output #1: loss = 0.0291433 (* 1 = 0.0291433 loss)
I0617 20:09:07.731529  8058 sgd_solver.cpp:105] Iteration 12900, lr = 0.01
I0617 20:09:57.502481  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 20:10:05.537230  8058 solver.cpp:218] Iteration 12950 (0.864974 iter/s, 57.8052s/50 iters), loss = 0.0198519
I0617 20:10:05.537329  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 20:10:05.537361  8058 solver.cpp:237]     Train net output #1: loss = 0.0198519 (* 1 = 0.0198519 loss)
I0617 20:10:05.537382  8058 sgd_solver.cpp:105] Iteration 12950, lr = 0.01
I0617 20:11:03.319463  8058 solver.cpp:218] Iteration 13000 (0.865328 iter/s, 57.7816s/50 iters), loss = 0.0282365
I0617 20:11:03.319625  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 20:11:03.319659  8058 solver.cpp:237]     Train net output #1: loss = 0.0282365 (* 1 = 0.0282365 loss)
I0617 20:11:03.319679  8058 sgd_solver.cpp:105] Iteration 13000, lr = 0.01
I0617 20:12:01.107784  8058 solver.cpp:218] Iteration 13050 (0.865238 iter/s, 57.7876s/50 iters), loss = 0.0284372
I0617 20:12:01.107880  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 20:12:01.107913  8058 solver.cpp:237]     Train net output #1: loss = 0.0284372 (* 1 = 0.0284372 loss)
I0617 20:12:01.107934  8058 sgd_solver.cpp:105] Iteration 13050, lr = 0.01
I0617 20:12:15.060827  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 20:12:58.891769  8058 solver.cpp:218] Iteration 13100 (0.865303 iter/s, 57.7832s/50 iters), loss = 0.0224401
I0617 20:12:58.891949  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 20:12:58.891989  8058 solver.cpp:237]     Train net output #1: loss = 0.0224401 (* 1 = 0.0224401 loss)
I0617 20:12:58.892014  8058 sgd_solver.cpp:105] Iteration 13100, lr = 0.01
I0617 20:13:56.700352  8058 solver.cpp:218] Iteration 13150 (0.864935 iter/s, 57.8078s/50 iters), loss = 0.0350551
I0617 20:13:56.700532  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 20:13:56.700565  8058 solver.cpp:237]     Train net output #1: loss = 0.0350551 (* 1 = 0.0350551 loss)
I0617 20:13:56.700584  8058 sgd_solver.cpp:105] Iteration 13150, lr = 0.01
I0617 20:14:33.789062  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 20:14:54.686934  8058 solver.cpp:218] Iteration 13200 (0.86228 iter/s, 57.9858s/50 iters), loss = 0.0272811
I0617 20:14:54.688974  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 20:14:54.689021  8058 solver.cpp:237]     Train net output #1: loss = 0.0272811 (* 1 = 0.0272811 loss)
I0617 20:14:54.689043  8058 sgd_solver.cpp:105] Iteration 13200, lr = 0.01
I0617 20:15:54.055703  8058 solver.cpp:218] Iteration 13250 (0.842231 iter/s, 59.3661s/50 iters), loss = 0.0212381
I0617 20:15:54.055992  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 20:15:54.056026  8058 solver.cpp:237]     Train net output #1: loss = 0.0212381 (* 1 = 0.0212381 loss)
I0617 20:15:54.056046  8058 sgd_solver.cpp:105] Iteration 13250, lr = 0.01
I0617 20:16:53.136749  8058 solver.cpp:218] Iteration 13300 (0.846309 iter/s, 59.0801s/50 iters), loss = 0.0226359
I0617 20:16:53.137015  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 20:16:53.137508  8058 solver.cpp:237]     Train net output #1: loss = 0.0226359 (* 1 = 0.0226359 loss)
I0617 20:16:53.137554  8058 sgd_solver.cpp:105] Iteration 13300, lr = 0.01
I0617 20:16:55.729746  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 20:17:51.524415  8058 solver.cpp:218] Iteration 13350 (0.856359 iter/s, 58.3868s/50 iters), loss = 0.022701
I0617 20:17:51.525010  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 20:17:51.525053  8058 solver.cpp:237]     Train net output #1: loss = 0.0227009 (* 1 = 0.0227009 loss)
I0617 20:17:51.525085  8058 sgd_solver.cpp:105] Iteration 13350, lr = 0.01
I0617 20:18:49.778659  8058 solver.cpp:218] Iteration 13400 (0.858324 iter/s, 58.2531s/50 iters), loss = 0.0285063
I0617 20:18:49.778861  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 20:18:49.778897  8058 solver.cpp:237]     Train net output #1: loss = 0.0285063 (* 1 = 0.0285063 loss)
I0617 20:18:49.778918  8058 sgd_solver.cpp:105] Iteration 13400, lr = 0.01
I0617 20:19:15.646304  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 20:19:48.097658  8058 solver.cpp:218] Iteration 13450 (0.857386 iter/s, 58.3168s/50 iters), loss = 0.0247508
I0617 20:19:48.101598  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 20:19:48.101635  8058 solver.cpp:237]     Train net output #1: loss = 0.0247508 (* 1 = 0.0247508 loss)
I0617 20:19:48.101657  8058 sgd_solver.cpp:105] Iteration 13450, lr = 0.01
I0617 20:20:46.412672  8058 solver.cpp:218] Iteration 13500 (0.857479 iter/s, 58.3105s/50 iters), loss = 0.0252555
I0617 20:20:46.412890  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 20:20:46.412948  8058 solver.cpp:237]     Train net output #1: loss = 0.0252555 (* 1 = 0.0252555 loss)
I0617 20:20:46.412976  8058 sgd_solver.cpp:105] Iteration 13500, lr = 0.01
I0617 20:21:35.476799  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 20:21:44.676504  8058 solver.cpp:218] Iteration 13550 (0.858177 iter/s, 58.263s/50 iters), loss = 0.0375946
I0617 20:21:44.676628  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 20:21:44.676657  8058 solver.cpp:237]     Train net output #1: loss = 0.0375946 (* 1 = 0.0375946 loss)
I0617 20:21:44.676678  8058 sgd_solver.cpp:105] Iteration 13550, lr = 0.01
I0617 20:22:43.180245  8058 solver.cpp:218] Iteration 13600 (0.854657 iter/s, 58.503s/50 iters), loss = 0.0221471
I0617 20:22:43.183621  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 20:22:43.183663  8058 solver.cpp:237]     Train net output #1: loss = 0.0221471 (* 1 = 0.0221471 loss)
I0617 20:22:43.183681  8058 sgd_solver.cpp:105] Iteration 13600, lr = 0.01
I0617 20:23:41.466584  8058 solver.cpp:218] Iteration 13650 (0.857892 iter/s, 58.2824s/50 iters), loss = 0.0298456
I0617 20:23:41.469799  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 20:23:41.469842  8058 solver.cpp:237]     Train net output #1: loss = 0.0298456 (* 1 = 0.0298456 loss)
I0617 20:23:41.469864  8058 sgd_solver.cpp:105] Iteration 13650, lr = 0.01
I0617 20:23:55.476228  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 20:24:39.542053  8058 solver.cpp:218] Iteration 13700 (0.861005 iter/s, 58.0717s/50 iters), loss = 0.0242477
I0617 20:24:39.542212  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 20:24:39.542253  8058 solver.cpp:237]     Train net output #1: loss = 0.0242477 (* 1 = 0.0242477 loss)
I0617 20:24:39.542275  8058 sgd_solver.cpp:105] Iteration 13700, lr = 0.01
I0617 20:25:37.322301  8058 solver.cpp:218] Iteration 13750 (0.865359 iter/s, 57.7795s/50 iters), loss = 0.0258979
I0617 20:25:37.322456  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 20:25:37.322492  8058 solver.cpp:237]     Train net output #1: loss = 0.0258979 (* 1 = 0.0258979 loss)
I0617 20:25:37.322518  8058 sgd_solver.cpp:105] Iteration 13750, lr = 0.01
I0617 20:26:14.372108  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 20:26:35.110853  8058 solver.cpp:218] Iteration 13800 (0.865234 iter/s, 57.7878s/50 iters), loss = 0.0212768
I0617 20:26:35.110955  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 20:26:35.110983  8058 solver.cpp:237]     Train net output #1: loss = 0.0212768 (* 1 = 0.0212768 loss)
I0617 20:26:35.110999  8058 sgd_solver.cpp:105] Iteration 13800, lr = 0.01
I0617 20:27:33.277154  8058 solver.cpp:218] Iteration 13850 (0.859614 iter/s, 58.1656s/50 iters), loss = 0.0320461
I0617 20:27:33.277345  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 20:27:33.277376  8058 solver.cpp:237]     Train net output #1: loss = 0.0320461 (* 1 = 0.0320461 loss)
I0617 20:27:33.277400  8058 sgd_solver.cpp:105] Iteration 13850, lr = 0.01
I0617 20:28:31.311290  8058 solver.cpp:218] Iteration 13900 (0.861574 iter/s, 58.0333s/50 iters), loss = 0.033161
I0617 20:28:31.311722  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 20:28:31.311758  8058 solver.cpp:237]     Train net output #1: loss = 0.0331609 (* 1 = 0.0331609 loss)
I0617 20:28:31.311779  8058 sgd_solver.cpp:105] Iteration 13900, lr = 0.01
I0617 20:28:33.678062  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 20:29:29.382611  8058 solver.cpp:218] Iteration 13950 (0.861025 iter/s, 58.0703s/50 iters), loss = 0.0270033
I0617 20:29:29.382804  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 20:29:29.382834  8058 solver.cpp:237]     Train net output #1: loss = 0.0270033 (* 1 = 0.0270033 loss)
I0617 20:29:29.382853  8058 sgd_solver.cpp:105] Iteration 13950, lr = 0.01
I0617 20:30:27.547005  8058 solver.cpp:218] Iteration 14000 (0.859644 iter/s, 58.1636s/50 iters), loss = 0.0254145
I0617 20:30:27.550604  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 20:30:27.550642  8058 solver.cpp:237]     Train net output #1: loss = 0.0254145 (* 1 = 0.0254145 loss)
I0617 20:30:27.550660  8058 sgd_solver.cpp:105] Iteration 14000, lr = 0.01
I0617 20:30:52.363461  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 20:31:25.756181  8058 solver.cpp:218] Iteration 14050 (0.859033 iter/s, 58.205s/50 iters), loss = 0.0374897
I0617 20:31:25.759618  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 20:31:25.759654  8058 solver.cpp:237]     Train net output #1: loss = 0.0374897 (* 1 = 0.0374897 loss)
I0617 20:31:25.759673  8058 sgd_solver.cpp:105] Iteration 14050, lr = 0.01
I0617 20:32:23.689005  8058 solver.cpp:218] Iteration 14100 (0.863129 iter/s, 57.9288s/50 iters), loss = 0.0208807
I0617 20:32:23.689147  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 20:32:23.689182  8058 solver.cpp:237]     Train net output #1: loss = 0.0208807 (* 1 = 0.0208807 loss)
I0617 20:32:23.689213  8058 sgd_solver.cpp:105] Iteration 14100, lr = 0.01
I0617 20:33:11.162247  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 20:33:21.456909  8058 solver.cpp:218] Iteration 14150 (0.865543 iter/s, 57.7672s/50 iters), loss = 0.0353671
I0617 20:33:21.456992  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 20:33:21.457033  8058 solver.cpp:237]     Train net output #1: loss = 0.0353671 (* 1 = 0.0353671 loss)
I0617 20:33:21.457058  8058 sgd_solver.cpp:105] Iteration 14150, lr = 0.01
I0617 20:34:19.239181  8058 solver.cpp:218] Iteration 14200 (0.865327 iter/s, 57.7816s/50 iters), loss = 0.0299029
I0617 20:34:19.239382  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 20:34:19.239411  8058 solver.cpp:237]     Train net output #1: loss = 0.0299029 (* 1 = 0.0299029 loss)
I0617 20:34:19.239428  8058 sgd_solver.cpp:105] Iteration 14200, lr = 0.01
I0617 20:35:16.992647  8058 solver.cpp:218] Iteration 14250 (0.86576 iter/s, 57.7527s/50 iters), loss = 0.0217154
I0617 20:35:16.992841  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 20:35:16.992872  8058 solver.cpp:237]     Train net output #1: loss = 0.0217154 (* 1 = 0.0217154 loss)
I0617 20:35:16.992892  8058 sgd_solver.cpp:105] Iteration 14250, lr = 0.01
I0617 20:35:29.805436  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 20:36:14.755049  8058 solver.cpp:218] Iteration 14300 (0.865626 iter/s, 57.7617s/50 iters), loss = 0.0235481
I0617 20:36:14.755177  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 20:36:14.755204  8058 solver.cpp:237]     Train net output #1: loss = 0.0235481 (* 1 = 0.0235481 loss)
I0617 20:36:14.755220  8058 sgd_solver.cpp:105] Iteration 14300, lr = 0.01
I0617 20:37:12.510020  8058 solver.cpp:218] Iteration 14350 (0.865737 iter/s, 57.7543s/50 iters), loss = 0.020577
I0617 20:37:12.510140  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 20:37:12.510167  8058 solver.cpp:237]     Train net output #1: loss = 0.020577 (* 1 = 0.020577 loss)
I0617 20:37:12.510185  8058 sgd_solver.cpp:105] Iteration 14350, lr = 0.01
I0617 20:37:48.413660  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 20:38:10.269040  8058 solver.cpp:218] Iteration 14400 (0.865676 iter/s, 57.7583s/50 iters), loss = 0.0325606
I0617 20:38:10.269119  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 20:38:10.269147  8058 solver.cpp:237]     Train net output #1: loss = 0.0325606 (* 1 = 0.0325606 loss)
I0617 20:38:10.269163  8058 sgd_solver.cpp:105] Iteration 14400, lr = 0.01
I0617 20:39:08.044905  8058 solver.cpp:218] Iteration 14450 (0.865424 iter/s, 57.7752s/50 iters), loss = 0.0266249
I0617 20:39:08.045079  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 20:39:08.045114  8058 solver.cpp:237]     Train net output #1: loss = 0.0266249 (* 1 = 0.0266249 loss)
I0617 20:39:08.045135  8058 sgd_solver.cpp:105] Iteration 14450, lr = 0.01
I0617 20:40:05.824393  8058 solver.cpp:218] Iteration 14500 (0.86537 iter/s, 57.7787s/50 iters), loss = 0.0261952
I0617 20:40:05.824599  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 20:40:05.824630  8058 solver.cpp:237]     Train net output #1: loss = 0.0261952 (* 1 = 0.0261952 loss)
I0617 20:40:05.824646  8058 sgd_solver.cpp:105] Iteration 14500, lr = 0.01
I0617 20:40:07.040499  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 20:41:04.018170  8058 solver.cpp:218] Iteration 14550 (0.859213 iter/s, 58.1928s/50 iters), loss = 0.0225996
I0617 20:41:04.018556  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 20:41:04.018610  8058 solver.cpp:237]     Train net output #1: loss = 0.0225996 (* 1 = 0.0225996 loss)
I0617 20:41:04.018649  8058 sgd_solver.cpp:105] Iteration 14550, lr = 0.01
I0617 20:42:02.115320  8058 solver.cpp:218] Iteration 14600 (0.860641 iter/s, 58.0962s/50 iters), loss = 0.0294836
I0617 20:42:02.115555  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 20:42:02.115599  8058 solver.cpp:237]     Train net output #1: loss = 0.0294836 (* 1 = 0.0294836 loss)
I0617 20:42:02.115617  8058 sgd_solver.cpp:105] Iteration 14600, lr = 0.01
I0617 20:42:26.618170  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 20:43:00.121912  8058 solver.cpp:218] Iteration 14650 (0.861983 iter/s, 58.0058s/50 iters), loss = 0.0255398
I0617 20:43:00.122195  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 20:43:00.122225  8058 solver.cpp:237]     Train net output #1: loss = 0.0255398 (* 1 = 0.0255398 loss)
I0617 20:43:00.122244  8058 sgd_solver.cpp:105] Iteration 14650, lr = 0.01
I0617 20:43:58.422581  8058 solver.cpp:218] Iteration 14700 (0.857636 iter/s, 58.2998s/50 iters), loss = 0.0227846
I0617 20:43:58.426604  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 20:43:58.426643  8058 solver.cpp:237]     Train net output #1: loss = 0.0227846 (* 1 = 0.0227846 loss)
I0617 20:43:58.426661  8058 sgd_solver.cpp:105] Iteration 14700, lr = 0.01
I0617 20:44:46.283215  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 20:44:56.780073  8058 solver.cpp:218] Iteration 14750 (0.856856 iter/s, 58.3529s/50 iters), loss = 0.0212443
I0617 20:44:56.780184  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 20:44:56.780211  8058 solver.cpp:237]     Train net output #1: loss = 0.0212443 (* 1 = 0.0212443 loss)
I0617 20:44:56.780230  8058 sgd_solver.cpp:105] Iteration 14750, lr = 0.01
I0617 20:45:55.098914  8058 solver.cpp:218] Iteration 14800 (0.857366 iter/s, 58.3181s/50 iters), loss = 0.0229177
I0617 20:45:55.101388  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 20:45:55.101425  8058 solver.cpp:237]     Train net output #1: loss = 0.0229177 (* 1 = 0.0229177 loss)
I0617 20:45:55.101444  8058 sgd_solver.cpp:105] Iteration 14800, lr = 0.01
I0617 20:46:52.942102  8058 solver.cpp:218] Iteration 14850 (0.864452 iter/s, 57.8401s/50 iters), loss = 0.0279816
I0617 20:46:52.942255  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 20:46:52.942293  8058 solver.cpp:237]     Train net output #1: loss = 0.0279816 (* 1 = 0.0279816 loss)
I0617 20:46:52.942319  8058 sgd_solver.cpp:105] Iteration 14850, lr = 0.01
I0617 20:47:05.711868  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 20:47:50.745420  8058 solver.cpp:218] Iteration 14900 (0.865013 iter/s, 57.8026s/50 iters), loss = 0.0265108
I0617 20:47:50.745591  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 20:47:50.745621  8058 solver.cpp:237]     Train net output #1: loss = 0.0265108 (* 1 = 0.0265108 loss)
I0617 20:47:50.745637  8058 sgd_solver.cpp:105] Iteration 14900, lr = 0.01
I0617 20:48:48.513097  8058 solver.cpp:218] Iteration 14950 (0.865546 iter/s, 57.767s/50 iters), loss = 0.0290614
I0617 20:48:48.513257  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 20:48:48.513286  8058 solver.cpp:237]     Train net output #1: loss = 0.0290614 (* 1 = 0.0290614 loss)
I0617 20:48:48.513304  8058 sgd_solver.cpp:105] Iteration 14950, lr = 0.01
I0617 20:49:23.281385  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 20:49:46.276083  8058 solver.cpp:218] Iteration 15000 (0.865616 iter/s, 57.7623s/50 iters), loss = 0.0246421
I0617 20:49:46.276171  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 20:49:46.276198  8058 solver.cpp:237]     Train net output #1: loss = 0.0246421 (* 1 = 0.0246421 loss)
I0617 20:49:46.276216  8058 sgd_solver.cpp:105] Iteration 15000, lr = 0.01
I0617 20:50:44.049046  8058 solver.cpp:218] Iteration 15050 (0.865466 iter/s, 57.7724s/50 iters), loss = 0.0183401
I0617 20:50:44.049168  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 20:50:44.049198  8058 solver.cpp:237]     Train net output #1: loss = 0.0183401 (* 1 = 0.0183401 loss)
I0617 20:50:44.049216  8058 sgd_solver.cpp:105] Iteration 15050, lr = 0.01
I0617 20:51:41.823328  8058 solver.cpp:218] Iteration 15100 (0.865446 iter/s, 57.7737s/50 iters), loss = 0.0221239
I0617 20:51:41.823451  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 20:51:41.823495  8058 solver.cpp:237]     Train net output #1: loss = 0.0221239 (* 1 = 0.0221239 loss)
I0617 20:51:41.823518  8058 sgd_solver.cpp:105] Iteration 15100, lr = 0.01
I0617 20:51:41.931517  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 20:52:39.584683  8058 solver.cpp:218] Iteration 15150 (0.86564 iter/s, 57.7607s/50 iters), loss = 0.0268774
I0617 20:52:39.584811  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 20:52:39.584839  8058 solver.cpp:237]     Train net output #1: loss = 0.0268774 (* 1 = 0.0268774 loss)
I0617 20:52:39.584857  8058 sgd_solver.cpp:105] Iteration 15150, lr = 0.01
I0617 20:53:37.350570  8058 solver.cpp:218] Iteration 15200 (0.865572 iter/s, 57.7653s/50 iters), loss = 0.0316209
I0617 20:53:37.350710  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 20:53:37.350740  8058 solver.cpp:237]     Train net output #1: loss = 0.0316209 (* 1 = 0.0316209 loss)
I0617 20:53:37.350760  8058 sgd_solver.cpp:105] Iteration 15200, lr = 0.01
I0617 20:54:00.558002  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 20:54:35.118355  8058 solver.cpp:218] Iteration 15250 (0.865544 iter/s, 57.7671s/50 iters), loss = 0.0216367
I0617 20:54:35.118470  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 20:54:35.118499  8058 solver.cpp:237]     Train net output #1: loss = 0.0216367 (* 1 = 0.0216367 loss)
I0617 20:54:35.118522  8058 sgd_solver.cpp:105] Iteration 15250, lr = 0.01
I0617 20:55:32.901757  8058 solver.cpp:218] Iteration 15300 (0.86531 iter/s, 57.7828s/50 iters), loss = 0.0236367
I0617 20:55:32.901885  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 20:55:32.901912  8058 solver.cpp:237]     Train net output #1: loss = 0.0236366 (* 1 = 0.0236366 loss)
I0617 20:55:32.901929  8058 sgd_solver.cpp:105] Iteration 15300, lr = 0.01
I0617 20:56:19.179503  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 20:56:30.671130  8058 solver.cpp:218] Iteration 15350 (0.86552 iter/s, 57.7687s/50 iters), loss = 0.0243536
I0617 20:56:30.671216  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 20:56:30.671243  8058 solver.cpp:237]     Train net output #1: loss = 0.0243536 (* 1 = 0.0243536 loss)
I0617 20:56:30.671262  8058 sgd_solver.cpp:105] Iteration 15350, lr = 0.01
I0617 20:57:28.438100  8058 solver.cpp:218] Iteration 15400 (0.865556 iter/s, 57.7663s/50 iters), loss = 0.0228736
I0617 20:57:28.438261  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 20:57:28.438299  8058 solver.cpp:237]     Train net output #1: loss = 0.0228736 (* 1 = 0.0228736 loss)
I0617 20:57:28.438318  8058 sgd_solver.cpp:105] Iteration 15400, lr = 0.01
I0617 20:58:26.215803  8058 solver.cpp:218] Iteration 15450 (0.865396 iter/s, 57.777s/50 iters), loss = 0.0229568
I0617 20:58:26.215951  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 20:58:26.215982  8058 solver.cpp:237]     Train net output #1: loss = 0.0229568 (* 1 = 0.0229568 loss)
I0617 20:58:26.216001  8058 sgd_solver.cpp:105] Iteration 15450, lr = 0.01
I0617 20:58:37.861294  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 20:59:24.002895  8058 solver.cpp:218] Iteration 15500 (0.865256 iter/s, 57.7864s/50 iters), loss = 0.0250308
I0617 20:59:24.003098  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 20:59:24.003135  8058 solver.cpp:237]     Train net output #1: loss = 0.0250308 (* 1 = 0.0250308 loss)
I0617 20:59:24.003154  8058 sgd_solver.cpp:105] Iteration 15500, lr = 0.01
I0617 21:00:21.775754  8058 solver.cpp:218] Iteration 15550 (0.865469 iter/s, 57.7721s/50 iters), loss = 0.0211006
I0617 21:00:21.775887  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 21:00:21.775919  8058 solver.cpp:237]     Train net output #1: loss = 0.0211006 (* 1 = 0.0211006 loss)
I0617 21:00:21.775940  8058 sgd_solver.cpp:105] Iteration 15550, lr = 0.01
I0617 21:00:56.522794  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 21:01:19.545172  8058 solver.cpp:218] Iteration 15600 (0.865519 iter/s, 57.7688s/50 iters), loss = 0.02511
I0617 21:01:19.545260  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 21:01:19.545287  8058 solver.cpp:237]     Train net output #1: loss = 0.02511 (* 1 = 0.02511 loss)
I0617 21:01:19.545305  8058 sgd_solver.cpp:105] Iteration 15600, lr = 0.01
I0617 21:02:17.318843  8058 solver.cpp:218] Iteration 15650 (0.865455 iter/s, 57.7731s/50 iters), loss = 0.0288957
I0617 21:02:17.319000  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 21:02:17.319030  8058 solver.cpp:237]     Train net output #1: loss = 0.0288957 (* 1 = 0.0288957 loss)
I0617 21:02:17.319046  8058 sgd_solver.cpp:105] Iteration 15650, lr = 0.01
I0617 21:03:15.082273  8058 solver.cpp:218] Iteration 15700 (0.86561 iter/s, 57.7628s/50 iters), loss = 0.034327
I0617 21:03:15.082397  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 21:03:15.082427  8058 solver.cpp:237]     Train net output #1: loss = 0.034327 (* 1 = 0.034327 loss)
I0617 21:03:15.082442  8058 sgd_solver.cpp:105] Iteration 15700, lr = 0.01
I0617 21:03:15.138792  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 21:04:12.855412  8058 solver.cpp:218] Iteration 15750 (0.865464 iter/s, 57.7725s/50 iters), loss = 0.028891
I0617 21:04:12.855564  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 21:04:12.855592  8058 solver.cpp:237]     Train net output #1: loss = 0.028891 (* 1 = 0.028891 loss)
I0617 21:04:12.855609  8058 sgd_solver.cpp:105] Iteration 15750, lr = 0.01
I0617 21:05:10.620064  8058 solver.cpp:218] Iteration 15800 (0.865591 iter/s, 57.764s/50 iters), loss = 0.0238243
I0617 21:05:10.620187  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 21:05:10.620218  8058 solver.cpp:237]     Train net output #1: loss = 0.0238243 (* 1 = 0.0238243 loss)
I0617 21:05:10.620234  8058 sgd_solver.cpp:105] Iteration 15800, lr = 0.01
I0617 21:05:33.777849  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 21:06:08.383651  8058 solver.cpp:218] Iteration 15850 (0.865607 iter/s, 57.763s/50 iters), loss = 0.028337
I0617 21:06:08.383783  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 21:06:08.383812  8058 solver.cpp:237]     Train net output #1: loss = 0.028337 (* 1 = 0.028337 loss)
I0617 21:06:08.383831  8058 sgd_solver.cpp:105] Iteration 15850, lr = 0.01
I0617 21:07:06.157469  8058 solver.cpp:218] Iteration 15900 (0.865453 iter/s, 57.7732s/50 iters), loss = 0.0253392
I0617 21:07:06.157585  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 21:07:06.157615  8058 solver.cpp:237]     Train net output #1: loss = 0.0253392 (* 1 = 0.0253392 loss)
I0617 21:07:06.157631  8058 sgd_solver.cpp:105] Iteration 15900, lr = 0.01
I0617 21:07:52.426892  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 21:08:03.930047  8058 solver.cpp:218] Iteration 15950 (0.865472 iter/s, 57.772s/50 iters), loss = 0.0300469
I0617 21:08:03.930132  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 21:08:03.930160  8058 solver.cpp:237]     Train net output #1: loss = 0.0300469 (* 1 = 0.0300469 loss)
I0617 21:08:03.930177  8058 sgd_solver.cpp:105] Iteration 15950, lr = 0.01
I0617 21:09:01.700839  8058 solver.cpp:218] Iteration 16000 (0.865498 iter/s, 57.7702s/50 iters), loss = 0.0255303
I0617 21:09:01.700980  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 21:09:01.701012  8058 solver.cpp:237]     Train net output #1: loss = 0.0255303 (* 1 = 0.0255303 loss)
I0617 21:09:01.701032  8058 sgd_solver.cpp:105] Iteration 16000, lr = 0.01
I0617 21:09:59.489168  8058 solver.cpp:218] Iteration 16050 (0.865237 iter/s, 57.7876s/50 iters), loss = 0.02259
I0617 21:09:59.489562  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 21:09:59.489600  8058 solver.cpp:237]     Train net output #1: loss = 0.02259 (* 1 = 0.02259 loss)
I0617 21:09:59.489625  8058 sgd_solver.cpp:105] Iteration 16050, lr = 0.01
I0617 21:10:09.975396  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 21:10:57.283715  8058 solver.cpp:218] Iteration 16100 (0.865147 iter/s, 57.7937s/50 iters), loss = 0.0262324
I0617 21:10:57.283924  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 21:10:57.283954  8058 solver.cpp:237]     Train net output #1: loss = 0.0262324 (* 1 = 0.0262324 loss)
I0617 21:10:57.283972  8058 sgd_solver.cpp:105] Iteration 16100, lr = 0.01
I0617 21:11:55.089109  8058 solver.cpp:218] Iteration 16150 (0.864983 iter/s, 57.8046s/50 iters), loss = 0.0267807
I0617 21:11:55.089282  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 21:11:55.089320  8058 solver.cpp:237]     Train net output #1: loss = 0.0267806 (* 1 = 0.0267806 loss)
I0617 21:11:55.089345  8058 sgd_solver.cpp:105] Iteration 16150, lr = 0.01
I0617 21:12:28.686866  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 21:12:52.886212  8058 solver.cpp:218] Iteration 16200 (0.865105 iter/s, 57.7964s/50 iters), loss = 0.0243653
I0617 21:12:52.886303  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 21:12:52.886330  8058 solver.cpp:237]     Train net output #1: loss = 0.0243653 (* 1 = 0.0243653 loss)
I0617 21:12:52.886348  8058 sgd_solver.cpp:105] Iteration 16200, lr = 0.01
I0617 21:13:50.669680  8058 solver.cpp:218] Iteration 16250 (0.865309 iter/s, 57.7828s/50 iters), loss = 0.0221591
I0617 21:13:50.669822  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 21:13:50.669858  8058 solver.cpp:237]     Train net output #1: loss = 0.0221591 (* 1 = 0.0221591 loss)
I0617 21:13:50.669883  8058 sgd_solver.cpp:105] Iteration 16250, lr = 0.01
I0617 21:14:47.376682  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 21:14:48.434552  8058 solver.cpp:218] Iteration 16300 (0.865587 iter/s, 57.7643s/50 iters), loss = 0.0268991
I0617 21:14:48.434633  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 21:14:48.434660  8058 solver.cpp:237]     Train net output #1: loss = 0.0268991 (* 1 = 0.0268991 loss)
I0617 21:14:48.434676  8058 sgd_solver.cpp:105] Iteration 16300, lr = 0.01
I0617 21:15:46.192704  8058 solver.cpp:218] Iteration 16350 (0.865687 iter/s, 57.7576s/50 iters), loss = 0.0241961
I0617 21:15:46.192842  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 21:15:46.192873  8058 solver.cpp:237]     Train net output #1: loss = 0.0241961 (* 1 = 0.0241961 loss)
I0617 21:15:46.192890  8058 sgd_solver.cpp:105] Iteration 16350, lr = 0.01
I0617 21:16:43.957517  8058 solver.cpp:218] Iteration 16400 (0.865588 iter/s, 57.7642s/50 iters), loss = 0.0326734
I0617 21:16:43.957635  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 21:16:43.957664  8058 solver.cpp:237]     Train net output #1: loss = 0.0326734 (* 1 = 0.0326734 loss)
I0617 21:16:43.957680  8058 sgd_solver.cpp:105] Iteration 16400, lr = 0.01
I0617 21:17:06.001148  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 21:17:41.726500  8058 solver.cpp:218] Iteration 16450 (0.865525 iter/s, 57.7684s/50 iters), loss = 0.0203906
I0617 21:17:41.726670  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 21:17:41.726701  8058 solver.cpp:237]     Train net output #1: loss = 0.0203906 (* 1 = 0.0203906 loss)
I0617 21:17:41.726722  8058 sgd_solver.cpp:105] Iteration 16450, lr = 0.01
I0617 21:18:39.476940  8058 solver.cpp:218] Iteration 16500 (0.865804 iter/s, 57.7498s/50 iters), loss = 0.0239828
I0617 21:18:39.477056  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 21:18:39.477084  8058 solver.cpp:237]     Train net output #1: loss = 0.0239828 (* 1 = 0.0239828 loss)
I0617 21:18:39.477100  8058 sgd_solver.cpp:105] Iteration 16500, lr = 0.01
I0617 21:19:24.599369  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 21:19:37.239959  8058 solver.cpp:218] Iteration 16550 (0.865615 iter/s, 57.7624s/50 iters), loss = 0.01862
I0617 21:19:37.240038  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 21:19:37.240064  8058 solver.cpp:237]     Train net output #1: loss = 0.01862 (* 1 = 0.01862 loss)
I0617 21:19:37.240093  8058 sgd_solver.cpp:105] Iteration 16550, lr = 0.01
I0617 21:20:35.005694  8058 solver.cpp:218] Iteration 16600 (0.865574 iter/s, 57.7652s/50 iters), loss = 0.0206854
I0617 21:20:35.005810  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 21:20:35.005839  8058 solver.cpp:237]     Train net output #1: loss = 0.0206854 (* 1 = 0.0206854 loss)
I0617 21:20:35.005856  8058 sgd_solver.cpp:105] Iteration 16600, lr = 0.01
I0617 21:21:32.767722  8058 solver.cpp:218] Iteration 16650 (0.86563 iter/s, 57.7614s/50 iters), loss = 0.0264762
I0617 21:21:32.767827  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 21:21:32.767858  8058 solver.cpp:237]     Train net output #1: loss = 0.0264762 (* 1 = 0.0264762 loss)
I0617 21:21:32.767879  8058 sgd_solver.cpp:105] Iteration 16650, lr = 0.01
I0617 21:21:43.230656  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 21:22:30.523165  8058 solver.cpp:218] Iteration 16700 (0.865728 iter/s, 57.7548s/50 iters), loss = 0.020409
I0617 21:22:30.523294  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 21:22:30.523322  8058 solver.cpp:237]     Train net output #1: loss = 0.020409 (* 1 = 0.020409 loss)
I0617 21:22:30.523339  8058 sgd_solver.cpp:105] Iteration 16700, lr = 0.01
I0617 21:23:28.286847  8058 solver.cpp:218] Iteration 16750 (0.865605 iter/s, 57.763s/50 iters), loss = 0.0225918
I0617 21:23:28.286979  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 21:23:28.287009  8058 solver.cpp:237]     Train net output #1: loss = 0.0225918 (* 1 = 0.0225918 loss)
I0617 21:23:28.287025  8058 sgd_solver.cpp:105] Iteration 16750, lr = 0.01
I0617 21:24:01.853111  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 21:24:26.065557  8058 solver.cpp:218] Iteration 16800 (0.86538 iter/s, 57.7781s/50 iters), loss = 0.0232207
I0617 21:24:26.065642  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 21:24:26.065670  8058 solver.cpp:237]     Train net output #1: loss = 0.0232207 (* 1 = 0.0232207 loss)
I0617 21:24:26.065685  8058 sgd_solver.cpp:105] Iteration 16800, lr = 0.01
I0617 21:25:23.820436  8058 solver.cpp:218] Iteration 16850 (0.865737 iter/s, 57.7543s/50 iters), loss = 0.0284862
I0617 21:25:23.820562  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 21:25:23.820595  8058 solver.cpp:237]     Train net output #1: loss = 0.0284862 (* 1 = 0.0284862 loss)
I0617 21:25:23.820616  8058 sgd_solver.cpp:105] Iteration 16850, lr = 0.01
I0617 21:26:20.479171  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 21:26:21.586589  8058 solver.cpp:218] Iteration 16900 (0.865568 iter/s, 57.7655s/50 iters), loss = 0.0206668
I0617 21:26:21.586661  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 21:26:21.586688  8058 solver.cpp:237]     Train net output #1: loss = 0.0206668 (* 1 = 0.0206668 loss)
I0617 21:26:21.586704  8058 sgd_solver.cpp:105] Iteration 16900, lr = 0.01
I0617 21:27:19.352711  8058 solver.cpp:218] Iteration 16950 (0.865568 iter/s, 57.7655s/50 iters), loss = 0.0311613
I0617 21:27:19.352870  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 21:27:19.352900  8058 solver.cpp:237]     Train net output #1: loss = 0.0311613 (* 1 = 0.0311613 loss)
I0617 21:27:19.352918  8058 sgd_solver.cpp:105] Iteration 16950, lr = 0.01
I0617 21:28:17.119290  8058 solver.cpp:218] Iteration 17000 (0.865562 iter/s, 57.7659s/50 iters), loss = 0.0244173
I0617 21:28:17.119421  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 21:28:17.119449  8058 solver.cpp:237]     Train net output #1: loss = 0.0244173 (* 1 = 0.0244173 loss)
I0617 21:28:17.119465  8058 sgd_solver.cpp:105] Iteration 17000, lr = 0.01
I0617 21:28:38.020359  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 21:29:14.890148  8058 solver.cpp:218] Iteration 17050 (0.865498 iter/s, 57.7702s/50 iters), loss = 0.0257802
I0617 21:29:14.890286  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 21:29:14.890316  8058 solver.cpp:237]     Train net output #1: loss = 0.0257802 (* 1 = 0.0257802 loss)
I0617 21:29:14.890343  8058 sgd_solver.cpp:105] Iteration 17050, lr = 0.01
I0617 21:30:12.656675  8058 solver.cpp:218] Iteration 17100 (0.865563 iter/s, 57.7659s/50 iters), loss = 0.0186917
I0617 21:30:12.656814  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 21:30:12.656850  8058 solver.cpp:237]     Train net output #1: loss = 0.0186917 (* 1 = 0.0186917 loss)
I0617 21:30:12.656870  8058 sgd_solver.cpp:105] Iteration 17100, lr = 0.01
I0617 21:30:56.633934  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 21:31:10.411504  8058 solver.cpp:218] Iteration 17150 (0.865738 iter/s, 57.7542s/50 iters), loss = 0.0278686
I0617 21:31:10.411586  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 21:31:10.411612  8058 solver.cpp:237]     Train net output #1: loss = 0.0278686 (* 1 = 0.0278686 loss)
I0617 21:31:10.411629  8058 sgd_solver.cpp:105] Iteration 17150, lr = 0.01
I0617 21:32:08.166592  8058 solver.cpp:218] Iteration 17200 (0.865733 iter/s, 57.7545s/50 iters), loss = 0.0251252
I0617 21:32:08.166708  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 21:32:08.166738  8058 solver.cpp:237]     Train net output #1: loss = 0.0251252 (* 1 = 0.0251252 loss)
I0617 21:32:08.166754  8058 sgd_solver.cpp:105] Iteration 17200, lr = 0.01
I0617 21:33:05.917865  8058 solver.cpp:218] Iteration 17250 (0.865791 iter/s, 57.7507s/50 iters), loss = 0.0208708
I0617 21:33:05.917992  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 21:33:05.918020  8058 solver.cpp:237]     Train net output #1: loss = 0.0208708 (* 1 = 0.0208708 loss)
I0617 21:33:05.918038  8058 sgd_solver.cpp:105] Iteration 17250, lr = 0.01
I0617 21:33:15.251891  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 21:34:03.674337  8058 solver.cpp:218] Iteration 17300 (0.865713 iter/s, 57.7558s/50 iters), loss = 0.0195911
I0617 21:34:03.674448  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 21:34:03.674477  8058 solver.cpp:237]     Train net output #1: loss = 0.0195911 (* 1 = 0.0195911 loss)
I0617 21:34:03.674494  8058 sgd_solver.cpp:105] Iteration 17300, lr = 0.01
I0617 21:35:01.430436  8058 solver.cpp:218] Iteration 17350 (0.865719 iter/s, 57.7555s/50 iters), loss = 0.0307691
I0617 21:35:01.430582  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 21:35:01.430609  8058 solver.cpp:237]     Train net output #1: loss = 0.0307691 (* 1 = 0.0307691 loss)
I0617 21:35:01.430629  8058 sgd_solver.cpp:105] Iteration 17350, lr = 0.01
I0617 21:35:33.868057  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 21:35:59.193967  8058 solver.cpp:218] Iteration 17400 (0.865608 iter/s, 57.7629s/50 iters), loss = 0.0233629
I0617 21:35:59.194061  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 21:35:59.194092  8058 solver.cpp:237]     Train net output #1: loss = 0.0233629 (* 1 = 0.0233629 loss)
I0617 21:35:59.194113  8058 sgd_solver.cpp:105] Iteration 17400, lr = 0.01
I0617 21:36:56.979625  8058 solver.cpp:218] Iteration 17450 (0.865276 iter/s, 57.7851s/50 iters), loss = 0.02264
I0617 21:36:56.979818  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 21:36:56.979848  8058 solver.cpp:237]     Train net output #1: loss = 0.02264 (* 1 = 0.02264 loss)
I0617 21:36:56.979866  8058 sgd_solver.cpp:105] Iteration 17450, lr = 0.01
I0617 21:37:52.505861  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 21:37:54.751703  8058 solver.cpp:218] Iteration 17500 (0.865481 iter/s, 57.7714s/50 iters), loss = 0.02877
I0617 21:37:54.751785  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 21:37:54.751816  8058 solver.cpp:237]     Train net output #1: loss = 0.02877 (* 1 = 0.02877 loss)
I0617 21:37:54.751835  8058 sgd_solver.cpp:105] Iteration 17500, lr = 0.01
I0617 21:38:52.527771  8058 solver.cpp:218] Iteration 17550 (0.865419 iter/s, 57.7755s/50 iters), loss = 0.0733971
I0617 21:38:52.527899  8058 solver.cpp:237]     Train net output #0: accuracy = 0.98
I0617 21:38:52.527940  8058 solver.cpp:237]     Train net output #1: loss = 0.0733971 (* 1 = 0.0733971 loss)
I0617 21:38:52.527957  8058 sgd_solver.cpp:105] Iteration 17550, lr = 0.01
I0617 21:39:50.574388  8058 solver.cpp:218] Iteration 17600 (0.861387 iter/s, 58.0459s/50 iters), loss = 0.0962923
I0617 21:39:50.574851  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 21:39:50.574882  8058 solver.cpp:237]     Train net output #1: loss = 0.0962923 (* 1 = 0.0962923 loss)
I0617 21:39:50.574899  8058 sgd_solver.cpp:105] Iteration 17600, lr = 0.01
I0617 21:40:11.546596  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 21:40:48.762651  8058 solver.cpp:218] Iteration 17650 (0.859295 iter/s, 58.1872s/50 iters), loss = 0.257722
I0617 21:40:48.762886  8058 solver.cpp:237]     Train net output #0: accuracy = 0.96
I0617 21:40:48.762923  8058 solver.cpp:237]     Train net output #1: loss = 0.257722 (* 1 = 0.257722 loss)
I0617 21:40:48.762948  8058 sgd_solver.cpp:105] Iteration 17650, lr = 0.01
I0617 21:41:46.996143  8058 solver.cpp:218] Iteration 17700 (0.858624 iter/s, 58.2327s/50 iters), loss = 1.29866
I0617 21:41:46.996471  8058 solver.cpp:237]     Train net output #0: accuracy = 0.6
I0617 21:41:46.996503  8058 solver.cpp:237]     Train net output #1: loss = 1.29866 (* 1 = 1.29866 loss)
I0617 21:41:46.996526  8058 sgd_solver.cpp:105] Iteration 17700, lr = 0.01
I0617 21:42:31.089275  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 21:42:44.897444  8058 solver.cpp:218] Iteration 17750 (0.863551 iter/s, 57.9004s/50 iters), loss = 1.17021
I0617 21:42:44.897549  8058 solver.cpp:237]     Train net output #0: accuracy = 0.66
I0617 21:42:44.897579  8058 solver.cpp:237]     Train net output #1: loss = 1.17021 (* 1 = 1.17021 loss)
I0617 21:42:44.897598  8058 sgd_solver.cpp:105] Iteration 17750, lr = 0.01
I0617 21:43:42.695718  8058 solver.cpp:218] Iteration 17800 (0.865088 iter/s, 57.7976s/50 iters), loss = 0.986596
I0617 21:43:42.695933  8058 solver.cpp:237]     Train net output #0: accuracy = 0.7
I0617 21:43:42.695968  8058 solver.cpp:237]     Train net output #1: loss = 0.986596 (* 1 = 0.986596 loss)
I0617 21:43:42.695986  8058 sgd_solver.cpp:105] Iteration 17800, lr = 0.01
I0617 21:44:40.505069  8058 solver.cpp:218] Iteration 17850 (0.864923 iter/s, 57.8086s/50 iters), loss = 0.827592
I0617 21:44:40.505187  8058 solver.cpp:237]     Train net output #0: accuracy = 0.78
I0617 21:44:40.505215  8058 solver.cpp:237]     Train net output #1: loss = 0.827592 (* 1 = 0.827592 loss)
I0617 21:44:40.505234  8058 sgd_solver.cpp:105] Iteration 17850, lr = 0.01
I0617 21:44:49.800653  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 21:45:38.284493  8058 solver.cpp:218] Iteration 17900 (0.86537 iter/s, 57.7787s/50 iters), loss = 0.83424
I0617 21:45:38.284715  8058 solver.cpp:237]     Train net output #0: accuracy = 0.76
I0617 21:45:38.284747  8058 solver.cpp:237]     Train net output #1: loss = 0.83424 (* 1 = 0.83424 loss)
I0617 21:45:38.284765  8058 sgd_solver.cpp:105] Iteration 17900, lr = 0.01
I0617 21:46:36.051090  8058 solver.cpp:218] Iteration 17950 (0.865564 iter/s, 57.7658s/50 iters), loss = 0.458201
I0617 21:46:36.051220  8058 solver.cpp:237]     Train net output #0: accuracy = 0.94
I0617 21:46:36.051249  8058 solver.cpp:237]     Train net output #1: loss = 0.458201 (* 1 = 0.458201 loss)
I0617 21:46:36.051267  8058 sgd_solver.cpp:105] Iteration 17950, lr = 0.01
I0617 21:47:07.339726  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 21:47:33.823426  8058 solver.cpp:218] Iteration 18000 (0.865477 iter/s, 57.7716s/50 iters), loss = 0.420133
I0617 21:47:33.823535  8058 solver.cpp:237]     Train net output #0: accuracy = 0.9
I0617 21:47:33.823577  8058 solver.cpp:237]     Train net output #1: loss = 0.420133 (* 1 = 0.420133 loss)
I0617 21:47:33.823599  8058 sgd_solver.cpp:105] Iteration 18000, lr = 0.01
I0617 21:48:31.601898  8058 solver.cpp:218] Iteration 18050 (0.865384 iter/s, 57.7778s/50 iters), loss = 0.3844
I0617 21:48:31.602154  8058 solver.cpp:237]     Train net output #0: accuracy = 0.94
I0617 21:48:31.602193  8058 solver.cpp:237]     Train net output #1: loss = 0.3844 (* 1 = 0.3844 loss)
I0617 21:48:31.602211  8058 sgd_solver.cpp:105] Iteration 18050, lr = 0.01
I0617 21:49:25.986362  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 21:49:29.371455  8058 solver.cpp:218] Iteration 18100 (0.86552 iter/s, 57.7688s/50 iters), loss = 0.351123
I0617 21:49:29.371541  8058 solver.cpp:237]     Train net output #0: accuracy = 0.92
I0617 21:49:29.371570  8058 solver.cpp:237]     Train net output #1: loss = 0.351123 (* 1 = 0.351123 loss)
I0617 21:49:29.371587  8058 sgd_solver.cpp:105] Iteration 18100, lr = 0.01
I0617 21:50:27.152715  8058 solver.cpp:218] Iteration 18150 (0.865342 iter/s, 57.7806s/50 iters), loss = 0.167875
I0617 21:50:27.152843  8058 solver.cpp:237]     Train net output #0: accuracy = 0.98
I0617 21:50:27.152871  8058 solver.cpp:237]     Train net output #1: loss = 0.167875 (* 1 = 0.167875 loss)
I0617 21:50:27.152889  8058 sgd_solver.cpp:105] Iteration 18150, lr = 0.01
I0617 21:51:24.921911  8058 solver.cpp:218] Iteration 18200 (0.865523 iter/s, 57.7685s/50 iters), loss = 0.291725
I0617 21:51:24.922034  8058 solver.cpp:237]     Train net output #0: accuracy = 0.94
I0617 21:51:24.922062  8058 solver.cpp:237]     Train net output #1: loss = 0.291725 (* 1 = 0.291725 loss)
I0617 21:51:24.922078  8058 sgd_solver.cpp:105] Iteration 18200, lr = 0.01
I0617 21:51:44.649195  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 21:52:22.690353  8058 solver.cpp:218] Iteration 18250 (0.865535 iter/s, 57.7678s/50 iters), loss = 0.233952
I0617 21:52:22.690493  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 21:52:22.690532  8058 solver.cpp:237]     Train net output #1: loss = 0.233952 (* 1 = 0.233952 loss)
I0617 21:52:22.690554  8058 sgd_solver.cpp:105] Iteration 18250, lr = 0.01
I0617 21:53:20.442873  8058 solver.cpp:218] Iteration 18300 (0.865774 iter/s, 57.7518s/50 iters), loss = 0.141037
I0617 21:53:20.443008  8058 solver.cpp:237]     Train net output #0: accuracy = 0.98
I0617 21:53:20.443037  8058 solver.cpp:237]     Train net output #1: loss = 0.141037 (* 1 = 0.141037 loss)
I0617 21:53:20.443054  8058 sgd_solver.cpp:105] Iteration 18300, lr = 0.01
I0617 21:54:03.576766  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 21:54:18.494086  8058 solver.cpp:218] Iteration 18350 (0.86132 iter/s, 58.0504s/50 iters), loss = 0.126135
I0617 21:54:18.494231  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 21:54:18.494264  8058 solver.cpp:237]     Train net output #1: loss = 0.126135 (* 1 = 0.126135 loss)
I0617 21:54:18.494285  8058 sgd_solver.cpp:105] Iteration 18350, lr = 0.01
I0617 21:55:16.641865  8058 solver.cpp:218] Iteration 18400 (0.859889 iter/s, 58.147s/50 iters), loss = 0.115378
I0617 21:55:16.645750  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 21:55:16.645805  8058 solver.cpp:237]     Train net output #1: loss = 0.115378 (* 1 = 0.115378 loss)
I0617 21:55:16.645825  8058 sgd_solver.cpp:105] Iteration 18400, lr = 0.01
I0617 21:56:14.815246  8058 solver.cpp:218] Iteration 18450 (0.859565 iter/s, 58.1689s/50 iters), loss = 0.0956083
I0617 21:56:14.819648  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 21:56:14.819684  8058 solver.cpp:237]     Train net output #1: loss = 0.0956083 (* 1 = 0.0956083 loss)
I0617 21:56:14.819702  8058 sgd_solver.cpp:105] Iteration 18450, lr = 0.01
I0617 21:56:23.628163  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 21:57:12.780279  8058 solver.cpp:218] Iteration 18500 (0.862663 iter/s, 57.9601s/50 iters), loss = 0.0915799
I0617 21:57:12.780422  8058 solver.cpp:237]     Train net output #0: accuracy = 0.98
I0617 21:57:12.780452  8058 solver.cpp:237]     Train net output #1: loss = 0.09158 (* 1 = 0.09158 loss)
I0617 21:57:12.780469  8058 sgd_solver.cpp:105] Iteration 18500, lr = 0.01
I0617 21:58:10.548346  8058 solver.cpp:218] Iteration 18550 (0.86554 iter/s, 57.7674s/50 iters), loss = 0.125863
I0617 21:58:10.548461  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 21:58:10.548491  8058 solver.cpp:237]     Train net output #1: loss = 0.125863 (* 1 = 0.125863 loss)
I0617 21:58:10.548511  8058 sgd_solver.cpp:105] Iteration 18550, lr = 0.01
I0617 21:58:41.810078  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 21:59:08.310386  8058 solver.cpp:218] Iteration 18600 (0.86563 iter/s, 57.7614s/50 iters), loss = 0.0616256
I0617 21:59:08.310468  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 21:59:08.310497  8058 solver.cpp:237]     Train net output #1: loss = 0.0616257 (* 1 = 0.0616257 loss)
I0617 21:59:08.310518  8058 sgd_solver.cpp:105] Iteration 18600, lr = 0.01
I0617 22:00:06.097765  8058 solver.cpp:218] Iteration 18650 (0.86525 iter/s, 57.7867s/50 iters), loss = 0.0573055
I0617 22:00:06.097908  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 22:00:06.097937  8058 solver.cpp:237]     Train net output #1: loss = 0.0573056 (* 1 = 0.0573056 loss)
I0617 22:00:06.097955  8058 sgd_solver.cpp:105] Iteration 18650, lr = 0.01
I0617 22:01:00.448504  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 22:01:03.857688  8058 solver.cpp:218] Iteration 18700 (0.865663 iter/s, 57.7592s/50 iters), loss = 0.0504119
I0617 22:01:03.857792  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 22:01:03.857827  8058 solver.cpp:237]     Train net output #1: loss = 0.050412 (* 1 = 0.050412 loss)
I0617 22:01:03.857849  8058 sgd_solver.cpp:105] Iteration 18700, lr = 0.01
I0617 22:02:01.625121  8058 solver.cpp:218] Iteration 18750 (0.865549 iter/s, 57.7668s/50 iters), loss = 0.0446526
I0617 22:02:01.625236  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 22:02:01.625265  8058 solver.cpp:237]     Train net output #1: loss = 0.0446526 (* 1 = 0.0446526 loss)
I0617 22:02:01.625284  8058 sgd_solver.cpp:105] Iteration 18750, lr = 0.01
I0617 22:02:59.418213  8058 solver.cpp:218] Iteration 18800 (0.865176 iter/s, 57.7917s/50 iters), loss = 0.0687072
I0617 22:02:59.418371  8058 solver.cpp:237]     Train net output #0: accuracy = 0.98
I0617 22:02:59.418406  8058 solver.cpp:237]     Train net output #1: loss = 0.0687072 (* 1 = 0.0687072 loss)
I0617 22:02:59.418423  8058 sgd_solver.cpp:105] Iteration 18800, lr = 0.01
I0617 22:03:19.120903  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 22:03:57.187199  8058 solver.cpp:218] Iteration 18850 (0.865527 iter/s, 57.7683s/50 iters), loss = 0.0474671
I0617 22:03:57.188616  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 22:03:57.188654  8058 solver.cpp:237]     Train net output #1: loss = 0.0474672 (* 1 = 0.0474672 loss)
I0617 22:03:57.188674  8058 sgd_solver.cpp:105] Iteration 18850, lr = 0.01
I0617 22:04:54.955080  8058 solver.cpp:218] Iteration 18900 (0.865562 iter/s, 57.7659s/50 iters), loss = 0.0333371
I0617 22:04:54.955272  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 22:04:54.955302  8058 solver.cpp:237]     Train net output #1: loss = 0.0333371 (* 1 = 0.0333371 loss)
I0617 22:04:54.955320  8058 sgd_solver.cpp:105] Iteration 18900, lr = 0.01
I0617 22:05:37.758363  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 22:05:52.721961  8058 solver.cpp:218] Iteration 18950 (0.865559 iter/s, 57.7661s/50 iters), loss = 0.0424175
I0617 22:05:52.722045  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 22:05:52.722074  8058 solver.cpp:237]     Train net output #1: loss = 0.0424175 (* 1 = 0.0424175 loss)
I0617 22:05:52.722090  8058 sgd_solver.cpp:105] Iteration 18950, lr = 0.01
I0617 22:06:50.496637  8058 solver.cpp:218] Iteration 19000 (0.865441 iter/s, 57.774s/50 iters), loss = 0.0423659
I0617 22:06:50.496755  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 22:06:50.496784  8058 solver.cpp:237]     Train net output #1: loss = 0.0423659 (* 1 = 0.0423659 loss)
I0617 22:06:50.496801  8058 sgd_solver.cpp:105] Iteration 19000, lr = 0.01
I0617 22:07:48.279558  8058 solver.cpp:218] Iteration 19050 (0.865318 iter/s, 57.7823s/50 iters), loss = 0.0215388
I0617 22:07:48.279690  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 22:07:48.279718  8058 solver.cpp:237]     Train net output #1: loss = 0.0215389 (* 1 = 0.0215389 loss)
I0617 22:07:48.279737  8058 sgd_solver.cpp:105] Iteration 19050, lr = 0.01
I0617 22:07:55.320566  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 22:08:46.048543  8058 solver.cpp:218] Iteration 19100 (0.865527 iter/s, 57.7683s/50 iters), loss = 0.0245254
I0617 22:08:46.048693  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 22:08:46.048723  8058 solver.cpp:237]     Train net output #1: loss = 0.0245255 (* 1 = 0.0245255 loss)
I0617 22:08:46.048740  8058 sgd_solver.cpp:105] Iteration 19100, lr = 0.01
I0617 22:09:43.815587  8058 solver.cpp:218] Iteration 19150 (0.865556 iter/s, 57.7663s/50 iters), loss = 0.0303411
I0617 22:09:43.816943  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 22:09:43.816978  8058 solver.cpp:237]     Train net output #1: loss = 0.0303411 (* 1 = 0.0303411 loss)
I0617 22:09:43.816998  8058 sgd_solver.cpp:105] Iteration 19150, lr = 0.01
I0617 22:10:13.933033  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 22:10:41.593250  8058 solver.cpp:218] Iteration 19200 (0.865415 iter/s, 57.7758s/50 iters), loss = 0.030791
I0617 22:10:41.593324  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 22:10:41.593353  8058 solver.cpp:237]     Train net output #1: loss = 0.030791 (* 1 = 0.030791 loss)
I0617 22:10:41.593369  8058 sgd_solver.cpp:105] Iteration 19200, lr = 0.01
I0617 22:11:39.364507  8058 solver.cpp:218] Iteration 19250 (0.865492 iter/s, 57.7706s/50 iters), loss = 0.0261869
I0617 22:11:39.364629  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 22:11:39.364656  8058 solver.cpp:237]     Train net output #1: loss = 0.0261869 (* 1 = 0.0261869 loss)
I0617 22:11:39.364675  8058 sgd_solver.cpp:105] Iteration 19250, lr = 0.01
I0617 22:12:32.617902  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 22:12:37.139037  8058 solver.cpp:218] Iteration 19300 (0.865443 iter/s, 57.7739s/50 iters), loss = 0.0477419
I0617 22:12:37.139116  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 22:12:37.139142  8058 solver.cpp:237]     Train net output #1: loss = 0.047742 (* 1 = 0.047742 loss)
I0617 22:12:37.139159  8058 sgd_solver.cpp:105] Iteration 19300, lr = 0.01
I0617 22:13:34.902699  8058 solver.cpp:218] Iteration 19350 (0.865606 iter/s, 57.763s/50 iters), loss = 0.0192104
I0617 22:13:34.902851  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 22:13:34.902880  8058 solver.cpp:237]     Train net output #1: loss = 0.0192104 (* 1 = 0.0192104 loss)
I0617 22:13:34.902899  8058 sgd_solver.cpp:105] Iteration 19350, lr = 0.01
I0617 22:14:32.672564  8058 solver.cpp:218] Iteration 19400 (0.865514 iter/s, 57.7691s/50 iters), loss = 0.0183873
I0617 22:14:32.672783  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 22:14:32.672813  8058 solver.cpp:237]     Train net output #1: loss = 0.0183873 (* 1 = 0.0183873 loss)
I0617 22:14:32.672832  8058 sgd_solver.cpp:105] Iteration 19400, lr = 0.01
I0617 22:14:51.231801  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 22:15:30.469018  8058 solver.cpp:218] Iteration 19450 (0.865117 iter/s, 57.7956s/50 iters), loss = 0.0188793
I0617 22:15:30.469161  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 22:15:30.469197  8058 solver.cpp:237]     Train net output #1: loss = 0.0188794 (* 1 = 0.0188794 loss)
I0617 22:15:30.469223  8058 sgd_solver.cpp:105] Iteration 19450, lr = 0.01
I0617 22:16:28.244325  8058 solver.cpp:218] Iteration 19500 (0.865432 iter/s, 57.7746s/50 iters), loss = 0.0226111
I0617 22:16:28.244458  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 22:16:28.244488  8058 solver.cpp:237]     Train net output #1: loss = 0.0226112 (* 1 = 0.0226112 loss)
I0617 22:16:28.244504  8058 sgd_solver.cpp:105] Iteration 19500, lr = 0.01
I0617 22:17:09.900205  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 22:17:26.008124  8058 solver.cpp:218] Iteration 19550 (0.865605 iter/s, 57.7631s/50 iters), loss = 0.0163599
I0617 22:17:26.008213  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 22:17:26.008247  8058 solver.cpp:237]     Train net output #1: loss = 0.0163599 (* 1 = 0.0163599 loss)
I0617 22:17:26.008272  8058 sgd_solver.cpp:105] Iteration 19550, lr = 0.01
I0617 22:18:23.775799  8058 solver.cpp:218] Iteration 19600 (0.865546 iter/s, 57.767s/50 iters), loss = 0.026423
I0617 22:18:23.775929  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 22:18:23.775959  8058 solver.cpp:237]     Train net output #1: loss = 0.026423 (* 1 = 0.026423 loss)
I0617 22:18:23.775976  8058 sgd_solver.cpp:105] Iteration 19600, lr = 0.01
I0617 22:19:21.546986  8058 solver.cpp:218] Iteration 19650 (0.865494 iter/s, 57.7705s/50 iters), loss = 0.0140672
I0617 22:19:21.547097  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 22:19:21.547127  8058 solver.cpp:237]     Train net output #1: loss = 0.0140673 (* 1 = 0.0140673 loss)
I0617 22:19:21.547144  8058 sgd_solver.cpp:105] Iteration 19650, lr = 0.01
I0617 22:19:28.563484  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 22:20:19.317148  8058 solver.cpp:218] Iteration 19700 (0.865509 iter/s, 57.7695s/50 iters), loss = 0.0204753
I0617 22:20:19.317273  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 22:20:19.317303  8058 solver.cpp:237]     Train net output #1: loss = 0.0204753 (* 1 = 0.0204753 loss)
I0617 22:20:19.317319  8058 sgd_solver.cpp:105] Iteration 19700, lr = 0.01
I0617 22:21:17.082274  8058 solver.cpp:218] Iteration 19750 (0.865584 iter/s, 57.7644s/50 iters), loss = 0.018988
I0617 22:21:17.082403  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 22:21:17.082432  8058 solver.cpp:237]     Train net output #1: loss = 0.018988 (* 1 = 0.018988 loss)
I0617 22:21:17.082450  8058 sgd_solver.cpp:105] Iteration 19750, lr = 0.01
I0617 22:21:47.196347  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 22:22:14.855199  8058 solver.cpp:218] Iteration 19800 (0.865468 iter/s, 57.7722s/50 iters), loss = 0.0162489
I0617 22:22:14.855307  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 22:22:14.855340  8058 solver.cpp:237]     Train net output #1: loss = 0.016249 (* 1 = 0.016249 loss)
I0617 22:22:14.855361  8058 sgd_solver.cpp:105] Iteration 19800, lr = 0.01
I0617 22:23:12.633539  8058 solver.cpp:218] Iteration 19850 (0.865386 iter/s, 57.7777s/50 iters), loss = 0.0157867
I0617 22:23:12.633647  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 22:23:12.633675  8058 solver.cpp:237]     Train net output #1: loss = 0.0157868 (* 1 = 0.0157868 loss)
I0617 22:23:12.633692  8058 sgd_solver.cpp:105] Iteration 19850, lr = 0.01
I0617 22:24:05.852619  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 22:24:10.399881  8058 solver.cpp:218] Iteration 19900 (0.865566 iter/s, 57.7657s/50 iters), loss = 0.0171272
I0617 22:24:10.399950  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 22:24:10.399983  8058 solver.cpp:237]     Train net output #1: loss = 0.0171273 (* 1 = 0.0171273 loss)
I0617 22:24:10.400002  8058 sgd_solver.cpp:105] Iteration 19900, lr = 0.01
I0617 22:25:08.162088  8058 solver.cpp:218] Iteration 19950 (0.865627 iter/s, 57.7616s/50 iters), loss = 0.0123197
I0617 22:25:08.162220  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 22:25:08.162250  8058 solver.cpp:237]     Train net output #1: loss = 0.0123198 (* 1 = 0.0123198 loss)
I0617 22:25:08.162266  8058 sgd_solver.cpp:105] Iteration 19950, lr = 0.01
I0617 22:26:04.773938  8058 solver.cpp:447] Snapshotting to binary proto file mobilenet/mobile_cub_iter_20000.caffemodel
I0617 22:26:04.871556  8058 sgd_solver.cpp:273] Snapshotting solver state to binary proto file mobilenet/mobile_cub_iter_20000.solverstate
I0617 22:26:06.055559  8058 solver.cpp:218] Iteration 20000 (0.863665 iter/s, 57.8928s/50 iters), loss = 0.0181676
I0617 22:26:06.055640  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 22:26:06.055665  8058 solver.cpp:237]     Train net output #1: loss = 0.0181677 (* 1 = 0.0181677 loss)
I0617 22:26:06.055680  8058 sgd_solver.cpp:105] Iteration 20000, lr = 0.01
I0617 22:26:23.491600  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 22:27:03.823235  8058 solver.cpp:218] Iteration 20050 (0.865546 iter/s, 57.767s/50 iters), loss = 0.0169626
I0617 22:27:03.823367  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 22:27:03.823396  8058 solver.cpp:237]     Train net output #1: loss = 0.0169627 (* 1 = 0.0169627 loss)
I0617 22:27:03.823415  8058 sgd_solver.cpp:105] Iteration 20050, lr = 0.01
I0617 22:28:01.594048  8058 solver.cpp:218] Iteration 20100 (0.865499 iter/s, 57.7701s/50 iters), loss = 0.0192491
I0617 22:28:01.594156  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 22:28:01.594183  8058 solver.cpp:237]     Train net output #1: loss = 0.0192491 (* 1 = 0.0192491 loss)
I0617 22:28:01.594202  8058 sgd_solver.cpp:105] Iteration 20100, lr = 0.01
I0617 22:28:42.112437  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 22:28:59.377219  8058 solver.cpp:218] Iteration 20150 (0.865314 iter/s, 57.7825s/50 iters), loss = 0.0139353
I0617 22:28:59.377328  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 22:28:59.377359  8058 solver.cpp:237]     Train net output #1: loss = 0.0139353 (* 1 = 0.0139353 loss)
I0617 22:28:59.377380  8058 sgd_solver.cpp:105] Iteration 20150, lr = 0.01
I0617 22:29:57.169112  8058 solver.cpp:218] Iteration 20200 (0.865183 iter/s, 57.7912s/50 iters), loss = 0.0213701
I0617 22:29:57.169267  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 22:29:57.169296  8058 solver.cpp:237]     Train net output #1: loss = 0.0213701 (* 1 = 0.0213701 loss)
I0617 22:29:57.169312  8058 sgd_solver.cpp:105] Iteration 20200, lr = 0.01
I0617 22:30:54.941220  8058 solver.cpp:218] Iteration 20250 (0.86548 iter/s, 57.7714s/50 iters), loss = 0.012157
I0617 22:30:54.941375  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 22:30:54.941403  8058 solver.cpp:237]     Train net output #1: loss = 0.012157 (* 1 = 0.012157 loss)
I0617 22:30:54.941421  8058 sgd_solver.cpp:105] Iteration 20250, lr = 0.01
I0617 22:31:00.795768  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 22:31:52.712384  8058 solver.cpp:218] Iteration 20300 (0.865494 iter/s, 57.7704s/50 iters), loss = 0.0233238
I0617 22:31:52.712628  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 22:31:52.712656  8058 solver.cpp:237]     Train net output #1: loss = 0.0233239 (* 1 = 0.0233239 loss)
I0617 22:31:52.712674  8058 sgd_solver.cpp:105] Iteration 20300, lr = 0.01
I0617 22:32:50.514345  8058 solver.cpp:218] Iteration 20350 (0.865035 iter/s, 57.8011s/50 iters), loss = 0.0170538
I0617 22:32:50.514554  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 22:32:50.514592  8058 solver.cpp:237]     Train net output #1: loss = 0.0170539 (* 1 = 0.0170539 loss)
I0617 22:32:50.514613  8058 sgd_solver.cpp:105] Iteration 20350, lr = 0.01
I0617 22:33:19.487042  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 22:33:48.320755  8058 solver.cpp:218] Iteration 20400 (0.864968 iter/s, 57.8056s/50 iters), loss = 0.0183366
I0617 22:33:48.320916  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 22:33:48.320945  8058 solver.cpp:237]     Train net output #1: loss = 0.0183367 (* 1 = 0.0183367 loss)
I0617 22:33:48.320962  8058 sgd_solver.cpp:105] Iteration 20400, lr = 0.01
I0617 22:34:46.108788  8058 solver.cpp:218] Iteration 20450 (0.865242 iter/s, 57.7873s/50 iters), loss = 0.0153188
I0617 22:34:46.108909  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 22:34:46.108938  8058 solver.cpp:237]     Train net output #1: loss = 0.0153188 (* 1 = 0.0153188 loss)
I0617 22:34:46.108955  8058 sgd_solver.cpp:105] Iteration 20450, lr = 0.01
I0617 22:35:38.187678  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 22:35:43.899941  8058 solver.cpp:218] Iteration 20500 (0.865195 iter/s, 57.7905s/50 iters), loss = 0.015414
I0617 22:35:43.900043  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 22:35:43.900068  8058 solver.cpp:237]     Train net output #1: loss = 0.015414 (* 1 = 0.015414 loss)
I0617 22:35:43.900086  8058 sgd_solver.cpp:105] Iteration 20500, lr = 0.01
I0617 22:36:41.693644  8058 solver.cpp:218] Iteration 20550 (0.865157 iter/s, 57.793s/50 iters), loss = 0.0186328
I0617 22:36:41.693785  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 22:36:41.693820  8058 solver.cpp:237]     Train net output #1: loss = 0.0186328 (* 1 = 0.0186328 loss)
I0617 22:36:41.693841  8058 sgd_solver.cpp:105] Iteration 20550, lr = 0.01
I0617 22:37:39.488510  8058 solver.cpp:218] Iteration 20600 (0.865139 iter/s, 57.7942s/50 iters), loss = 0.0178707
I0617 22:37:39.488631  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 22:37:39.488657  8058 solver.cpp:237]     Train net output #1: loss = 0.0178707 (* 1 = 0.0178707 loss)
I0617 22:37:39.488674  8058 sgd_solver.cpp:105] Iteration 20600, lr = 0.01
I0617 22:37:56.896404  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 22:38:37.285204  8058 solver.cpp:218] Iteration 20650 (0.865111 iter/s, 57.796s/50 iters), loss = 0.0220665
I0617 22:38:37.285318  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 22:38:37.285347  8058 solver.cpp:237]     Train net output #1: loss = 0.0220665 (* 1 = 0.0220665 loss)
I0617 22:38:37.285365  8058 sgd_solver.cpp:105] Iteration 20650, lr = 0.01
I0617 22:39:35.047343  8058 solver.cpp:218] Iteration 20700 (0.865629 iter/s, 57.7615s/50 iters), loss = 0.0136791
I0617 22:39:35.047461  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 22:39:35.047488  8058 solver.cpp:237]     Train net output #1: loss = 0.0136791 (* 1 = 0.0136791 loss)
I0617 22:39:35.047505  8058 sgd_solver.cpp:105] Iteration 20700, lr = 0.01
I0617 22:40:15.536451  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 22:40:32.810103  8058 solver.cpp:218] Iteration 20750 (0.86562 iter/s, 57.762s/50 iters), loss = 0.015246
I0617 22:40:32.810199  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 22:40:32.810231  8058 solver.cpp:237]     Train net output #1: loss = 0.015246 (* 1 = 0.015246 loss)
I0617 22:40:32.810251  8058 sgd_solver.cpp:105] Iteration 20750, lr = 0.01
I0617 22:41:30.580665  8058 solver.cpp:218] Iteration 20800 (0.865502 iter/s, 57.7699s/50 iters), loss = 0.0117654
I0617 22:41:30.580752  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 22:41:30.580780  8058 solver.cpp:237]     Train net output #1: loss = 0.0117654 (* 1 = 0.0117654 loss)
I0617 22:41:30.580798  8058 sgd_solver.cpp:105] Iteration 20800, lr = 0.01
I0617 22:42:28.345885  8058 solver.cpp:218] Iteration 20850 (0.865582 iter/s, 57.7646s/50 iters), loss = 0.0174456
I0617 22:42:28.346036  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 22:42:28.346066  8058 solver.cpp:237]     Train net output #1: loss = 0.0174456 (* 1 = 0.0174456 loss)
I0617 22:42:28.346084  8058 sgd_solver.cpp:105] Iteration 20850, lr = 0.01
I0617 22:42:34.182703  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 22:43:26.119638  8058 solver.cpp:218] Iteration 20900 (0.865456 iter/s, 57.773s/50 iters), loss = 0.0130352
I0617 22:43:26.119771  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 22:43:26.119803  8058 solver.cpp:237]     Train net output #1: loss = 0.0130353 (* 1 = 0.0130353 loss)
I0617 22:43:26.119823  8058 sgd_solver.cpp:105] Iteration 20900, lr = 0.01
I0617 22:44:23.871047  8058 solver.cpp:218] Iteration 20950 (0.86579 iter/s, 57.7507s/50 iters), loss = 0.0144339
I0617 22:44:23.871187  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 22:44:23.871217  8058 solver.cpp:237]     Train net output #1: loss = 0.0144339 (* 1 = 0.0144339 loss)
I0617 22:44:23.871245  8058 sgd_solver.cpp:105] Iteration 20950, lr = 0.01
I0617 22:44:51.679358  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 22:45:21.629627  8058 solver.cpp:218] Iteration 21000 (0.865683 iter/s, 57.7579s/50 iters), loss = 0.0164607
I0617 22:45:21.629750  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 22:45:21.629779  8058 solver.cpp:237]     Train net output #1: loss = 0.0164608 (* 1 = 0.0164608 loss)
I0617 22:45:21.629799  8058 sgd_solver.cpp:105] Iteration 21000, lr = 0.01
I0617 22:46:19.390488  8058 solver.cpp:218] Iteration 21050 (0.865648 iter/s, 57.7602s/50 iters), loss = 0.0137105
I0617 22:46:19.390607  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 22:46:19.390635  8058 solver.cpp:237]     Train net output #1: loss = 0.0137105 (* 1 = 0.0137105 loss)
I0617 22:46:19.390652  8058 sgd_solver.cpp:105] Iteration 21050, lr = 0.01
I0617 22:47:10.332337  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 22:47:17.156711  8058 solver.cpp:218] Iteration 21100 (0.865568 iter/s, 57.7655s/50 iters), loss = 0.0207291
I0617 22:47:17.156790  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 22:47:17.156816  8058 solver.cpp:237]     Train net output #1: loss = 0.0207292 (* 1 = 0.0207292 loss)
I0617 22:47:17.156832  8058 sgd_solver.cpp:105] Iteration 21100, lr = 0.01
I0617 22:48:14.909312  8058 solver.cpp:218] Iteration 21150 (0.865771 iter/s, 57.752s/50 iters), loss = 0.0161186
I0617 22:48:14.909411  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 22:48:14.909440  8058 solver.cpp:237]     Train net output #1: loss = 0.0161186 (* 1 = 0.0161186 loss)
I0617 22:48:14.909457  8058 sgd_solver.cpp:105] Iteration 21150, lr = 0.01
I0617 22:49:12.666730  8058 solver.cpp:218] Iteration 21200 (0.865698 iter/s, 57.7569s/50 iters), loss = 0.0198079
I0617 22:49:12.666841  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 22:49:12.666868  8058 solver.cpp:237]     Train net output #1: loss = 0.0198079 (* 1 = 0.0198079 loss)
I0617 22:49:12.666885  8058 sgd_solver.cpp:105] Iteration 21200, lr = 0.01
I0617 22:49:28.933974  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 22:50:10.421712  8058 solver.cpp:218] Iteration 21250 (0.865735 iter/s, 57.7544s/50 iters), loss = 0.0215347
I0617 22:50:10.421830  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 22:50:10.421859  8058 solver.cpp:237]     Train net output #1: loss = 0.0215348 (* 1 = 0.0215348 loss)
I0617 22:50:10.421876  8058 sgd_solver.cpp:105] Iteration 21250, lr = 0.01
I0617 22:51:08.184067  8058 solver.cpp:218] Iteration 21300 (0.865624 iter/s, 57.7618s/50 iters), loss = 0.0162613
I0617 22:51:08.184186  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 22:51:08.184214  8058 solver.cpp:237]     Train net output #1: loss = 0.0162613 (* 1 = 0.0162613 loss)
I0617 22:51:08.184232  8058 sgd_solver.cpp:105] Iteration 21300, lr = 0.01
I0617 22:51:47.557457  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 22:52:05.959229  8058 solver.cpp:218] Iteration 21350 (0.865433 iter/s, 57.7746s/50 iters), loss = 0.0215037
I0617 22:52:05.959306  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 22:52:05.959331  8058 solver.cpp:237]     Train net output #1: loss = 0.0215038 (* 1 = 0.0215038 loss)
I0617 22:52:05.959349  8058 sgd_solver.cpp:105] Iteration 21350, lr = 0.01
I0617 22:53:03.720302  8058 solver.cpp:218] Iteration 21400 (0.865643 iter/s, 57.7605s/50 iters), loss = 0.021448
I0617 22:53:03.720432  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 22:53:03.720463  8058 solver.cpp:237]     Train net output #1: loss = 0.021448 (* 1 = 0.021448 loss)
I0617 22:53:03.720484  8058 sgd_solver.cpp:105] Iteration 21400, lr = 0.01
I0617 22:54:01.480890  8058 solver.cpp:218] Iteration 21450 (0.865651 iter/s, 57.76s/50 iters), loss = 0.0151621
I0617 22:54:01.481011  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 22:54:01.481040  8058 solver.cpp:237]     Train net output #1: loss = 0.0151621 (* 1 = 0.0151621 loss)
I0617 22:54:01.481070  8058 sgd_solver.cpp:105] Iteration 21450, lr = 0.01
I0617 22:54:06.169988  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 22:54:59.242527  8058 solver.cpp:218] Iteration 21500 (0.865635 iter/s, 57.761s/50 iters), loss = 0.0129933
I0617 22:54:59.242683  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 22:54:59.242712  8058 solver.cpp:237]     Train net output #1: loss = 0.0129933 (* 1 = 0.0129933 loss)
I0617 22:54:59.242729  8058 sgd_solver.cpp:105] Iteration 21500, lr = 0.01
I0617 22:55:57.014725  8058 solver.cpp:218] Iteration 21550 (0.865477 iter/s, 57.7716s/50 iters), loss = 0.016696
I0617 22:55:57.014842  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 22:55:57.014871  8058 solver.cpp:237]     Train net output #1: loss = 0.016696 (* 1 = 0.016696 loss)
I0617 22:55:57.014889  8058 sgd_solver.cpp:105] Iteration 21550, lr = 0.01
I0617 22:56:24.807804  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 22:56:54.766543  8058 solver.cpp:218] Iteration 21600 (0.865783 iter/s, 57.7512s/50 iters), loss = 0.0184723
I0617 22:56:54.766664  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 22:56:54.766693  8058 solver.cpp:237]     Train net output #1: loss = 0.0184723 (* 1 = 0.0184723 loss)
I0617 22:56:54.766713  8058 sgd_solver.cpp:105] Iteration 21600, lr = 0.01
I0617 22:57:52.520120  8058 solver.cpp:218] Iteration 21650 (0.865756 iter/s, 57.753s/50 iters), loss = 0.0132774
I0617 22:57:52.520236  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 22:57:52.520262  8058 solver.cpp:237]     Train net output #1: loss = 0.0132774 (* 1 = 0.0132774 loss)
I0617 22:57:52.520280  8058 sgd_solver.cpp:105] Iteration 21650, lr = 0.01
I0617 22:58:43.414608  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 22:58:50.297000  8058 solver.cpp:218] Iteration 21700 (0.865407 iter/s, 57.7763s/50 iters), loss = 0.0132656
I0617 22:58:50.297112  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 22:58:50.297139  8058 solver.cpp:237]     Train net output #1: loss = 0.0132657 (* 1 = 0.0132657 loss)
I0617 22:58:50.297158  8058 sgd_solver.cpp:105] Iteration 21700, lr = 0.01
I0617 22:59:48.105734  8058 solver.cpp:218] Iteration 21750 (0.86493 iter/s, 57.8081s/50 iters), loss = 0.0123957
I0617 22:59:48.109828  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 22:59:48.109870  8058 solver.cpp:237]     Train net output #1: loss = 0.0123957 (* 1 = 0.0123957 loss)
I0617 22:59:48.109889  8058 sgd_solver.cpp:105] Iteration 21750, lr = 0.01
I0617 23:00:45.913607  8058 solver.cpp:218] Iteration 21800 (0.865003 iter/s, 57.8033s/50 iters), loss = 0.0146615
I0617 23:00:45.913872  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 23:00:45.913908  8058 solver.cpp:237]     Train net output #1: loss = 0.0146616 (* 1 = 0.0146616 loss)
I0617 23:00:45.913928  8058 sgd_solver.cpp:105] Iteration 21800, lr = 0.01
I0617 23:01:02.152053  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 23:01:43.714293  8058 solver.cpp:218] Iteration 21850 (0.865053 iter/s, 57.7999s/50 iters), loss = 0.0197913
I0617 23:01:43.714520  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 23:01:43.714552  8058 solver.cpp:237]     Train net output #1: loss = 0.0197913 (* 1 = 0.0197913 loss)
I0617 23:01:43.714571  8058 sgd_solver.cpp:105] Iteration 21850, lr = 0.01
I0617 23:02:41.511106  8058 solver.cpp:218] Iteration 21900 (0.86511 iter/s, 57.7961s/50 iters), loss = 0.0175972
I0617 23:02:41.511262  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 23:02:41.511291  8058 solver.cpp:237]     Train net output #1: loss = 0.0175973 (* 1 = 0.0175973 loss)
I0617 23:02:41.511308  8058 sgd_solver.cpp:105] Iteration 21900, lr = 0.01
I0617 23:03:20.852900  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 23:03:39.307390  8058 solver.cpp:218] Iteration 21950 (0.865117 iter/s, 57.7956s/50 iters), loss = 0.0177883
I0617 23:03:39.307499  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 23:03:39.307533  8058 solver.cpp:237]     Train net output #1: loss = 0.0177884 (* 1 = 0.0177884 loss)
I0617 23:03:39.307551  8058 sgd_solver.cpp:105] Iteration 21950, lr = 0.01
I0617 23:04:37.107842  8058 solver.cpp:218] Iteration 22000 (0.865054 iter/s, 57.7999s/50 iters), loss = 0.0152622
I0617 23:04:37.107983  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 23:04:37.108012  8058 solver.cpp:237]     Train net output #1: loss = 0.0152622 (* 1 = 0.0152622 loss)
I0617 23:04:37.108029  8058 sgd_solver.cpp:105] Iteration 22000, lr = 0.01
I0617 23:05:34.911085  8058 solver.cpp:218] Iteration 22050 (0.865013 iter/s, 57.8026s/50 iters), loss = 0.0180709
I0617 23:05:34.911213  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 23:05:34.911242  8058 solver.cpp:237]     Train net output #1: loss = 0.0180709 (* 1 = 0.0180709 loss)
I0617 23:05:34.911259  8058 sgd_solver.cpp:105] Iteration 22050, lr = 0.01
I0617 23:05:38.466536  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 23:06:32.714481  8058 solver.cpp:218] Iteration 22100 (0.86501 iter/s, 57.8028s/50 iters), loss = 0.010679
I0617 23:06:32.714645  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 23:06:32.714674  8058 solver.cpp:237]     Train net output #1: loss = 0.010679 (* 1 = 0.010679 loss)
I0617 23:06:32.714691  8058 sgd_solver.cpp:105] Iteration 22100, lr = 0.01
I0617 23:07:30.519632  8058 solver.cpp:218] Iteration 22150 (0.864985 iter/s, 57.8045s/50 iters), loss = 0.0146431
I0617 23:07:30.519793  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 23:07:30.519822  8058 solver.cpp:237]     Train net output #1: loss = 0.0146431 (* 1 = 0.0146431 loss)
I0617 23:07:30.519840  8058 sgd_solver.cpp:105] Iteration 22150, lr = 0.01
I0617 23:07:57.188415  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 23:08:28.299402  8058 solver.cpp:218] Iteration 22200 (0.865364 iter/s, 57.7791s/50 iters), loss = 0.0259749
I0617 23:08:28.299530  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 23:08:28.299561  8058 solver.cpp:237]     Train net output #1: loss = 0.025975 (* 1 = 0.025975 loss)
I0617 23:08:28.299578  8058 sgd_solver.cpp:105] Iteration 22200, lr = 0.01
I0617 23:09:26.071305  8058 solver.cpp:218] Iteration 22250 (0.865482 iter/s, 57.7713s/50 iters), loss = 0.022068
I0617 23:09:26.071426  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 23:09:26.071455  8058 solver.cpp:237]     Train net output #1: loss = 0.022068 (* 1 = 0.022068 loss)
I0617 23:09:26.071472  8058 sgd_solver.cpp:105] Iteration 22250, lr = 0.01
I0617 23:10:15.827664  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 23:10:23.843760  8058 solver.cpp:218] Iteration 22300 (0.865473 iter/s, 57.7718s/50 iters), loss = 0.0174944
I0617 23:10:23.843849  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 23:10:23.843875  8058 solver.cpp:237]     Train net output #1: loss = 0.0174944 (* 1 = 0.0174944 loss)
I0617 23:10:23.843894  8058 sgd_solver.cpp:105] Iteration 22300, lr = 0.01
I0617 23:11:21.623427  8058 solver.cpp:218] Iteration 22350 (0.865365 iter/s, 57.7791s/50 iters), loss = 0.0185937
I0617 23:11:21.623587  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 23:11:21.623623  8058 solver.cpp:237]     Train net output #1: loss = 0.0185937 (* 1 = 0.0185937 loss)
I0617 23:11:21.623643  8058 sgd_solver.cpp:105] Iteration 22350, lr = 0.01
I0617 23:12:19.392151  8058 solver.cpp:218] Iteration 22400 (0.86553 iter/s, 57.7681s/50 iters), loss = 0.0170865
I0617 23:12:19.392271  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 23:12:19.392299  8058 solver.cpp:237]     Train net output #1: loss = 0.0170865 (* 1 = 0.0170865 loss)
I0617 23:12:19.392316  8058 sgd_solver.cpp:105] Iteration 22400, lr = 0.01
I0617 23:12:34.484794  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 23:13:17.153650  8058 solver.cpp:218] Iteration 22450 (0.865637 iter/s, 57.7609s/50 iters), loss = 0.0165847
I0617 23:13:17.153785  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 23:13:17.153815  8058 solver.cpp:237]     Train net output #1: loss = 0.0165847 (* 1 = 0.0165847 loss)
I0617 23:13:17.153832  8058 sgd_solver.cpp:105] Iteration 22450, lr = 0.01
I0617 23:14:14.920030  8058 solver.cpp:218] Iteration 22500 (0.865565 iter/s, 57.7658s/50 iters), loss = 0.020106
I0617 23:14:14.920193  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 23:14:14.920222  8058 solver.cpp:237]     Train net output #1: loss = 0.020106 (* 1 = 0.020106 loss)
I0617 23:14:14.920239  8058 sgd_solver.cpp:105] Iteration 22500, lr = 0.01
I0617 23:14:53.113756  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 23:15:12.685833  8058 solver.cpp:218] Iteration 22550 (0.865574 iter/s, 57.7652s/50 iters), loss = 0.0147894
I0617 23:15:12.685914  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 23:15:12.685943  8058 solver.cpp:237]     Train net output #1: loss = 0.0147895 (* 1 = 0.0147895 loss)
I0617 23:15:12.685963  8058 sgd_solver.cpp:105] Iteration 22550, lr = 0.01
I0617 23:16:10.451099  8058 solver.cpp:218] Iteration 22600 (0.86558 iter/s, 57.7647s/50 iters), loss = 0.0132113
I0617 23:16:10.451217  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 23:16:10.451246  8058 solver.cpp:237]     Train net output #1: loss = 0.0132114 (* 1 = 0.0132114 loss)
I0617 23:16:10.451262  8058 sgd_solver.cpp:105] Iteration 22600, lr = 0.01
I0617 23:17:08.234077  8058 solver.cpp:218] Iteration 22650 (0.865316 iter/s, 57.7824s/50 iters), loss = 0.0200893
I0617 23:17:08.234202  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 23:17:08.234232  8058 solver.cpp:237]     Train net output #1: loss = 0.0200894 (* 1 = 0.0200894 loss)
I0617 23:17:08.234251  8058 sgd_solver.cpp:105] Iteration 22650, lr = 0.01
I0617 23:17:11.759452  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 23:18:05.997037  8058 solver.cpp:218] Iteration 22700 (0.865616 iter/s, 57.7624s/50 iters), loss = 0.0135704
I0617 23:18:05.997200  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 23:18:05.997228  8058 solver.cpp:237]     Train net output #1: loss = 0.0135704 (* 1 = 0.0135704 loss)
I0617 23:18:05.997246  8058 sgd_solver.cpp:105] Iteration 22700, lr = 0.01
I0617 23:19:03.775825  8058 solver.cpp:218] Iteration 22750 (0.865379 iter/s, 57.7781s/50 iters), loss = 0.0147613
I0617 23:19:03.775979  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 23:19:03.776012  8058 solver.cpp:237]     Train net output #1: loss = 0.0147613 (* 1 = 0.0147613 loss)
I0617 23:19:03.776031  8058 sgd_solver.cpp:105] Iteration 22750, lr = 0.01
I0617 23:19:30.408973  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 23:20:01.539543  8058 solver.cpp:218] Iteration 22800 (0.865605 iter/s, 57.7631s/50 iters), loss = 0.016739
I0617 23:20:01.539706  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 23:20:01.539737  8058 solver.cpp:237]     Train net output #1: loss = 0.016739 (* 1 = 0.016739 loss)
I0617 23:20:01.539753  8058 sgd_solver.cpp:105] Iteration 22800, lr = 0.01
I0617 23:20:59.304973  8058 solver.cpp:218] Iteration 22850 (0.865579 iter/s, 57.7648s/50 iters), loss = 0.0189414
I0617 23:20:59.305100  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 23:20:59.305129  8058 solver.cpp:237]     Train net output #1: loss = 0.0189414 (* 1 = 0.0189414 loss)
I0617 23:20:59.305146  8058 sgd_solver.cpp:105] Iteration 22850, lr = 0.01
I0617 23:21:49.035616  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 23:21:57.068416  8058 solver.cpp:218] Iteration 22900 (0.865609 iter/s, 57.7628s/50 iters), loss = 0.0178139
I0617 23:21:57.068498  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 23:21:57.068531  8058 solver.cpp:237]     Train net output #1: loss = 0.0178139 (* 1 = 0.0178139 loss)
I0617 23:21:57.068549  8058 sgd_solver.cpp:105] Iteration 22900, lr = 0.01
I0617 23:22:55.006539  8058 solver.cpp:218] Iteration 22950 (0.862998 iter/s, 57.9375s/50 iters), loss = 0.0163433
I0617 23:22:55.006705  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 23:22:55.006736  8058 solver.cpp:237]     Train net output #1: loss = 0.0163433 (* 1 = 0.0163433 loss)
I0617 23:22:55.006755  8058 sgd_solver.cpp:105] Iteration 22950, lr = 0.01
I0617 23:23:53.061537  8058 solver.cpp:218] Iteration 23000 (0.861263 iter/s, 58.0543s/50 iters), loss = 0.0149503
I0617 23:23:53.061713  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 23:23:53.061750  8058 solver.cpp:237]     Train net output #1: loss = 0.0149503 (* 1 = 0.0149503 loss)
I0617 23:23:53.061776  8058 sgd_solver.cpp:105] Iteration 23000, lr = 0.01
I0617 23:24:07.126886  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 23:24:51.113229  8058 solver.cpp:218] Iteration 23050 (0.861311 iter/s, 58.051s/50 iters), loss = 0.0161705
I0617 23:24:51.113524  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 23:24:51.113559  8058 solver.cpp:237]     Train net output #1: loss = 0.0161706 (* 1 = 0.0161706 loss)
I0617 23:24:51.113579  8058 sgd_solver.cpp:105] Iteration 23050, lr = 0.01
I0617 23:25:49.229087  8058 solver.cpp:218] Iteration 23100 (0.860362 iter/s, 58.1151s/50 iters), loss = 0.0164515
I0617 23:25:49.229363  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 23:25:49.229395  8058 solver.cpp:237]     Train net output #1: loss = 0.0164516 (* 1 = 0.0164516 loss)
I0617 23:25:49.229414  8058 sgd_solver.cpp:105] Iteration 23100, lr = 0.01
I0617 23:26:26.593179  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 23:26:47.642626  8058 solver.cpp:218] Iteration 23150 (0.856016 iter/s, 58.4101s/50 iters), loss = 0.0174302
I0617 23:26:47.642742  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 23:26:47.642771  8058 solver.cpp:237]     Train net output #1: loss = 0.0174303 (* 1 = 0.0174303 loss)
I0617 23:26:47.642789  8058 sgd_solver.cpp:105] Iteration 23150, lr = 0.01
I0617 23:27:45.551385  8058 solver.cpp:218] Iteration 23200 (0.863437 iter/s, 57.9081s/50 iters), loss = 0.0141535
I0617 23:27:45.551560  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 23:27:45.551597  8058 solver.cpp:237]     Train net output #1: loss = 0.0141535 (* 1 = 0.0141535 loss)
I0617 23:27:45.551623  8058 sgd_solver.cpp:105] Iteration 23200, lr = 0.01
I0617 23:28:43.310348  8058 solver.cpp:218] Iteration 23250 (0.865676 iter/s, 57.7583s/50 iters), loss = 0.0186179
I0617 23:28:43.310464  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 23:28:43.310493  8058 solver.cpp:237]     Train net output #1: loss = 0.0186179 (* 1 = 0.0186179 loss)
I0617 23:28:43.310510  8058 sgd_solver.cpp:105] Iteration 23250, lr = 0.01
I0617 23:28:45.720810  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 23:29:41.078706  8058 solver.cpp:218] Iteration 23300 (0.865534 iter/s, 57.7678s/50 iters), loss = 0.0157674
I0617 23:29:41.078949  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 23:29:41.078980  8058 solver.cpp:237]     Train net output #1: loss = 0.0157675 (* 1 = 0.0157675 loss)
I0617 23:29:41.078999  8058 sgd_solver.cpp:105] Iteration 23300, lr = 0.01
I0617 23:30:38.847627  8058 solver.cpp:218] Iteration 23350 (0.865528 iter/s, 57.7682s/50 iters), loss = 0.0161237
I0617 23:30:38.847762  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 23:30:38.847796  8058 solver.cpp:237]     Train net output #1: loss = 0.0161237 (* 1 = 0.0161237 loss)
I0617 23:30:38.847816  8058 sgd_solver.cpp:105] Iteration 23350, lr = 0.01
I0617 23:31:04.337707  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 23:31:36.612206  8058 solver.cpp:218] Iteration 23400 (0.865591 iter/s, 57.764s/50 iters), loss = 0.0159133
I0617 23:31:36.612319  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 23:31:36.612346  8058 solver.cpp:237]     Train net output #1: loss = 0.0159133 (* 1 = 0.0159133 loss)
I0617 23:31:36.612365  8058 sgd_solver.cpp:105] Iteration 23400, lr = 0.01
I0617 23:32:34.377830  8058 solver.cpp:218] Iteration 23450 (0.865575 iter/s, 57.765s/50 iters), loss = 0.0180218
I0617 23:32:34.377939  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 23:32:34.377967  8058 solver.cpp:237]     Train net output #1: loss = 0.0180218 (* 1 = 0.0180218 loss)
I0617 23:32:34.377985  8058 sgd_solver.cpp:105] Iteration 23450, lr = 0.01
I0617 23:33:22.992727  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 23:33:32.144881  8058 solver.cpp:218] Iteration 23500 (0.865554 iter/s, 57.7665s/50 iters), loss = 0.0170531
I0617 23:33:32.144951  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 23:33:32.144978  8058 solver.cpp:237]     Train net output #1: loss = 0.0170531 (* 1 = 0.0170531 loss)
I0617 23:33:32.144994  8058 sgd_solver.cpp:105] Iteration 23500, lr = 0.01
I0617 23:34:29.915802  8058 solver.cpp:218] Iteration 23550 (0.865496 iter/s, 57.7704s/50 iters), loss = 0.0160895
I0617 23:34:29.915935  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 23:34:29.915964  8058 solver.cpp:237]     Train net output #1: loss = 0.0160896 (* 1 = 0.0160896 loss)
I0617 23:34:29.915982  8058 sgd_solver.cpp:105] Iteration 23550, lr = 0.01
I0617 23:35:27.673110  8058 solver.cpp:218] Iteration 23600 (0.865701 iter/s, 57.7567s/50 iters), loss = 0.0174509
I0617 23:35:27.673280  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 23:35:27.673308  8058 solver.cpp:237]     Train net output #1: loss = 0.017451 (* 1 = 0.017451 loss)
I0617 23:35:27.673326  8058 sgd_solver.cpp:105] Iteration 23600, lr = 0.01
I0617 23:35:41.624689  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 23:36:25.446512  8058 solver.cpp:218] Iteration 23650 (0.86546 iter/s, 57.7728s/50 iters), loss = 0.014419
I0617 23:36:25.446635  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 23:36:25.446663  8058 solver.cpp:237]     Train net output #1: loss = 0.014419 (* 1 = 0.014419 loss)
I0617 23:36:25.446681  8058 sgd_solver.cpp:105] Iteration 23650, lr = 0.01
I0617 23:37:23.206326  8058 solver.cpp:218] Iteration 23700 (0.865663 iter/s, 57.7592s/50 iters), loss = 0.015759
I0617 23:37:23.206455  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 23:37:23.206485  8058 solver.cpp:237]     Train net output #1: loss = 0.015759 (* 1 = 0.015759 loss)
I0617 23:37:23.206501  8058 sgd_solver.cpp:105] Iteration 23700, lr = 0.01
I0617 23:38:00.222784  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 23:38:20.961241  8058 solver.cpp:218] Iteration 23750 (0.865736 iter/s, 57.7543s/50 iters), loss = 0.0145722
I0617 23:38:20.961333  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 23:38:20.961360  8058 solver.cpp:237]     Train net output #1: loss = 0.0145722 (* 1 = 0.0145722 loss)
I0617 23:38:20.961379  8058 sgd_solver.cpp:105] Iteration 23750, lr = 0.01
I0617 23:39:18.719029  8058 solver.cpp:218] Iteration 23800 (0.865693 iter/s, 57.7572s/50 iters), loss = 0.0198743
I0617 23:39:18.719213  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 23:39:18.719243  8058 solver.cpp:237]     Train net output #1: loss = 0.0198743 (* 1 = 0.0198743 loss)
I0617 23:39:18.719260  8058 sgd_solver.cpp:105] Iteration 23800, lr = 0.01
I0617 23:40:16.480350  8058 solver.cpp:218] Iteration 23850 (0.86564 iter/s, 57.7607s/50 iters), loss = 0.0155426
I0617 23:40:16.480482  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 23:40:16.480518  8058 solver.cpp:237]     Train net output #1: loss = 0.0155427 (* 1 = 0.0155427 loss)
I0617 23:40:16.480540  8058 sgd_solver.cpp:105] Iteration 23850, lr = 0.01
I0617 23:40:18.870731  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 23:41:14.247318  8058 solver.cpp:218] Iteration 23900 (0.865555 iter/s, 57.7664s/50 iters), loss = 0.0159151
I0617 23:41:14.247459  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 23:41:14.247498  8058 solver.cpp:237]     Train net output #1: loss = 0.0159151 (* 1 = 0.0159151 loss)
I0617 23:41:14.247545  8058 sgd_solver.cpp:105] Iteration 23900, lr = 0.01
I0617 23:42:12.027209  8058 solver.cpp:218] Iteration 23950 (0.865362 iter/s, 57.7793s/50 iters), loss = 0.0135628
I0617 23:42:12.027340  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 23:42:12.027370  8058 solver.cpp:237]     Train net output #1: loss = 0.0135628 (* 1 = 0.0135628 loss)
I0617 23:42:12.027390  8058 sgd_solver.cpp:105] Iteration 23950, lr = 0.01
I0617 23:42:36.413508  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 23:43:09.815704  8058 solver.cpp:218] Iteration 24000 (0.865232 iter/s, 57.7879s/50 iters), loss = 0.0172283
I0617 23:43:09.815842  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 23:43:09.815872  8058 solver.cpp:237]     Train net output #1: loss = 0.0172283 (* 1 = 0.0172283 loss)
I0617 23:43:09.815889  8058 sgd_solver.cpp:105] Iteration 24000, lr = 0.01
I0617 23:44:07.582437  8058 solver.cpp:218] Iteration 24050 (0.865558 iter/s, 57.7662s/50 iters), loss = 0.0173209
I0617 23:44:07.582554  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 23:44:07.582584  8058 solver.cpp:237]     Train net output #1: loss = 0.017321 (* 1 = 0.017321 loss)
I0617 23:44:07.582602  8058 sgd_solver.cpp:105] Iteration 24050, lr = 0.01
I0617 23:44:55.031971  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 23:45:05.348204  8058 solver.cpp:218] Iteration 24100 (0.865573 iter/s, 57.7652s/50 iters), loss = 0.0162572
I0617 23:45:05.348294  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 23:45:05.348325  8058 solver.cpp:237]     Train net output #1: loss = 0.0162572 (* 1 = 0.0162572 loss)
I0617 23:45:05.348346  8058 sgd_solver.cpp:105] Iteration 24100, lr = 0.01
I0617 23:46:03.112859  8058 solver.cpp:218] Iteration 24150 (0.865589 iter/s, 57.7641s/50 iters), loss = 0.0164136
I0617 23:46:03.112994  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 23:46:03.113024  8058 solver.cpp:237]     Train net output #1: loss = 0.0164136 (* 1 = 0.0164136 loss)
I0617 23:46:03.113042  8058 sgd_solver.cpp:105] Iteration 24150, lr = 0.01
I0617 23:47:00.880126  8058 solver.cpp:218] Iteration 24200 (0.865551 iter/s, 57.7667s/50 iters), loss = 0.0158037
I0617 23:47:00.880292  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 23:47:00.880322  8058 solver.cpp:237]     Train net output #1: loss = 0.0158037 (* 1 = 0.0158037 loss)
I0617 23:47:00.880340  8058 sgd_solver.cpp:105] Iteration 24200, lr = 0.01
I0617 23:47:13.689669  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 23:47:58.646983  8058 solver.cpp:218] Iteration 24250 (0.865557 iter/s, 57.7663s/50 iters), loss = 0.0152683
I0617 23:47:58.647109  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 23:47:58.647138  8058 solver.cpp:237]     Train net output #1: loss = 0.0152683 (* 1 = 0.0152683 loss)
I0617 23:47:58.647156  8058 sgd_solver.cpp:105] Iteration 24250, lr = 0.01
I0617 23:48:56.428776  8058 solver.cpp:218] Iteration 24300 (0.865333 iter/s, 57.7812s/50 iters), loss = 0.0164828
I0617 23:48:56.428999  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 23:48:56.429034  8058 solver.cpp:237]     Train net output #1: loss = 0.0164828 (* 1 = 0.0164828 loss)
I0617 23:48:56.429055  8058 sgd_solver.cpp:105] Iteration 24300, lr = 0.01
I0617 23:49:32.330510  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 23:49:54.228991  8058 solver.cpp:218] Iteration 24350 (0.865059 iter/s, 57.7996s/50 iters), loss = 0.0184473
I0617 23:49:54.229105  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 23:49:54.229133  8058 solver.cpp:237]     Train net output #1: loss = 0.0184473 (* 1 = 0.0184473 loss)
I0617 23:49:54.229152  8058 sgd_solver.cpp:105] Iteration 24350, lr = 0.01
I0617 23:50:52.024845  8058 solver.cpp:218] Iteration 24400 (0.865122 iter/s, 57.7953s/50 iters), loss = 0.0155491
I0617 23:50:52.024994  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 23:50:52.025023  8058 solver.cpp:237]     Train net output #1: loss = 0.0155491 (* 1 = 0.0155491 loss)
I0617 23:50:52.025054  8058 sgd_solver.cpp:105] Iteration 24400, lr = 0.01
I0617 23:51:49.820051  8058 solver.cpp:218] Iteration 24450 (0.865132 iter/s, 57.7946s/50 iters), loss = 0.0185501
I0617 23:51:49.820190  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 23:51:49.820220  8058 solver.cpp:237]     Train net output #1: loss = 0.0185502 (* 1 = 0.0185502 loss)
I0617 23:51:49.820238  8058 sgd_solver.cpp:105] Iteration 24450, lr = 0.01
I0617 23:51:51.033136  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 23:52:47.609939  8058 solver.cpp:218] Iteration 24500 (0.865212 iter/s, 57.7893s/50 iters), loss = 0.0168608
I0617 23:52:47.610062  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 23:52:47.610095  8058 solver.cpp:237]     Train net output #1: loss = 0.0168608 (* 1 = 0.0168608 loss)
I0617 23:52:47.610116  8058 sgd_solver.cpp:105] Iteration 24500, lr = 0.01
I0617 23:53:45.411135  8058 solver.cpp:218] Iteration 24550 (0.865042 iter/s, 57.8006s/50 iters), loss = 0.0184648
I0617 23:53:45.411247  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 23:53:45.411278  8058 solver.cpp:237]     Train net output #1: loss = 0.0184648 (* 1 = 0.0184648 loss)
I0617 23:53:45.411295  8058 sgd_solver.cpp:105] Iteration 24550, lr = 0.01
I0617 23:54:09.747748  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 23:54:43.218847  8058 solver.cpp:218] Iteration 24600 (0.864945 iter/s, 57.8071s/50 iters), loss = 0.0175536
I0617 23:54:43.219010  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 23:54:43.219040  8058 solver.cpp:237]     Train net output #1: loss = 0.0175536 (* 1 = 0.0175536 loss)
I0617 23:54:43.219059  8058 sgd_solver.cpp:105] Iteration 24600, lr = 0.01
I0617 23:55:41.023679  8058 solver.cpp:218] Iteration 24650 (0.864989 iter/s, 57.8042s/50 iters), loss = 0.0166141
I0617 23:55:41.023838  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 23:55:41.023869  8058 solver.cpp:237]     Train net output #1: loss = 0.0166142 (* 1 = 0.0166142 loss)
I0617 23:55:41.023888  8058 sgd_solver.cpp:105] Iteration 24650, lr = 0.01
I0617 23:56:28.482529  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 23:56:38.826581  8058 solver.cpp:218] Iteration 24700 (0.865018 iter/s, 57.8023s/50 iters), loss = 0.0165704
I0617 23:56:38.826705  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 23:56:38.826735  8058 solver.cpp:237]     Train net output #1: loss = 0.0165704 (* 1 = 0.0165704 loss)
I0617 23:56:38.826752  8058 sgd_solver.cpp:105] Iteration 24700, lr = 0.01
I0617 23:57:36.630820  8058 solver.cpp:218] Iteration 24750 (0.864997 iter/s, 57.8037s/50 iters), loss = 0.0156404
I0617 23:57:36.630957  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 23:57:36.630987  8058 solver.cpp:237]     Train net output #1: loss = 0.0156404 (* 1 = 0.0156404 loss)
I0617 23:57:36.631006  8058 sgd_solver.cpp:105] Iteration 24750, lr = 0.01
I0617 23:58:34.436393  8058 solver.cpp:218] Iteration 24800 (0.864977 iter/s, 57.805s/50 iters), loss = 0.0185267
I0617 23:58:34.436617  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 23:58:34.436648  8058 solver.cpp:237]     Train net output #1: loss = 0.0185268 (* 1 = 0.0185268 loss)
I0617 23:58:34.436666  8058 sgd_solver.cpp:105] Iteration 24800, lr = 0.01
I0617 23:58:47.203171  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0617 23:59:32.210002  8058 solver.cpp:218] Iteration 24850 (0.865457 iter/s, 57.7729s/50 iters), loss = 0.0187386
I0617 23:59:32.210124  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0617 23:59:32.210155  8058 solver.cpp:237]     Train net output #1: loss = 0.0187387 (* 1 = 0.0187387 loss)
I0617 23:59:32.210172  8058 sgd_solver.cpp:105] Iteration 24850, lr = 0.01
I0618 00:00:29.986959  8058 solver.cpp:218] Iteration 24900 (0.865405 iter/s, 57.7764s/50 iters), loss = 0.019675
I0618 00:00:29.987088  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 00:00:29.987129  8058 solver.cpp:237]     Train net output #1: loss = 0.0196751 (* 1 = 0.0196751 loss)
I0618 00:00:29.987148  8058 sgd_solver.cpp:105] Iteration 24900, lr = 0.01
I0618 00:01:05.886382  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 00:01:27.767037  8058 solver.cpp:218] Iteration 24950 (0.865359 iter/s, 57.7795s/50 iters), loss = 0.0181462
I0618 00:01:27.767140  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 00:01:27.767168  8058 solver.cpp:237]     Train net output #1: loss = 0.0181463 (* 1 = 0.0181463 loss)
I0618 00:01:27.767186  8058 sgd_solver.cpp:105] Iteration 24950, lr = 0.01
I0618 00:02:25.544818  8058 solver.cpp:218] Iteration 25000 (0.865393 iter/s, 57.7772s/50 iters), loss = 0.0171907
I0618 00:02:25.544946  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 00:02:25.544975  8058 solver.cpp:237]     Train net output #1: loss = 0.0171907 (* 1 = 0.0171907 loss)
I0618 00:02:25.544994  8058 sgd_solver.cpp:105] Iteration 25000, lr = 0.01
I0618 00:03:23.315192  8058 solver.cpp:218] Iteration 25050 (0.865504 iter/s, 57.7698s/50 iters), loss = 0.0157776
I0618 00:03:23.315309  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 00:03:23.315338  8058 solver.cpp:237]     Train net output #1: loss = 0.0157777 (* 1 = 0.0157777 loss)
I0618 00:03:23.315356  8058 sgd_solver.cpp:105] Iteration 25050, lr = 0.01
I0618 00:03:23.422574  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 00:04:21.091183  8058 solver.cpp:218] Iteration 25100 (0.86542 iter/s, 57.7754s/50 iters), loss = 0.0155736
I0618 00:04:21.091307  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 00:04:21.091336  8058 solver.cpp:237]     Train net output #1: loss = 0.0155737 (* 1 = 0.0155737 loss)
I0618 00:04:21.091353  8058 sgd_solver.cpp:105] Iteration 25100, lr = 0.01
I0618 00:05:18.867837  8058 solver.cpp:218] Iteration 25150 (0.86541 iter/s, 57.7761s/50 iters), loss = 0.020594
I0618 00:05:18.868098  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 00:05:18.868127  8058 solver.cpp:237]     Train net output #1: loss = 0.0205941 (* 1 = 0.0205941 loss)
I0618 00:05:18.868146  8058 sgd_solver.cpp:105] Iteration 25150, lr = 0.01
I0618 00:05:42.082506  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 00:06:16.635740  8058 solver.cpp:218] Iteration 25200 (0.865543 iter/s, 57.7672s/50 iters), loss = 0.0160309
I0618 00:06:16.635884  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 00:06:16.635913  8058 solver.cpp:237]     Train net output #1: loss = 0.016031 (* 1 = 0.016031 loss)
I0618 00:06:16.635931  8058 sgd_solver.cpp:105] Iteration 25200, lr = 0.01
I0618 00:07:14.429612  8058 solver.cpp:218] Iteration 25250 (0.865153 iter/s, 57.7933s/50 iters), loss = 0.016835
I0618 00:07:14.429843  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 00:07:14.429885  8058 solver.cpp:237]     Train net output #1: loss = 0.016835 (* 1 = 0.016835 loss)
I0618 00:07:14.429908  8058 sgd_solver.cpp:105] Iteration 25250, lr = 0.01
I0618 00:08:00.724011  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 00:08:12.200358  8058 solver.cpp:218] Iteration 25300 (0.8655 iter/s, 57.7701s/50 iters), loss = 0.0197149
I0618 00:08:12.200453  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 00:08:12.200480  8058 solver.cpp:237]     Train net output #1: loss = 0.0197149 (* 1 = 0.0197149 loss)
I0618 00:08:12.200498  8058 sgd_solver.cpp:105] Iteration 25300, lr = 0.01
I0618 00:09:09.979168  8058 solver.cpp:218] Iteration 25350 (0.865377 iter/s, 57.7783s/50 iters), loss = 0.0231726
I0618 00:09:09.979301  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 00:09:09.979329  8058 solver.cpp:237]     Train net output #1: loss = 0.0231726 (* 1 = 0.0231726 loss)
I0618 00:09:09.979347  8058 sgd_solver.cpp:105] Iteration 25350, lr = 0.01
I0618 00:10:07.733942  8058 solver.cpp:218] Iteration 25400 (0.865739 iter/s, 57.7541s/50 iters), loss = 0.0180844
I0618 00:10:07.734304  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 00:10:07.734339  8058 solver.cpp:237]     Train net output #1: loss = 0.0180844 (* 1 = 0.0180844 loss)
I0618 00:10:07.734364  8058 sgd_solver.cpp:105] Iteration 25400, lr = 0.01
I0618 00:10:19.346699  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 00:11:05.501689  8058 solver.cpp:218] Iteration 25450 (0.865547 iter/s, 57.7669s/50 iters), loss = 0.0175259
I0618 00:11:05.501814  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 00:11:05.501843  8058 solver.cpp:237]     Train net output #1: loss = 0.017526 (* 1 = 0.017526 loss)
I0618 00:11:05.501860  8058 sgd_solver.cpp:105] Iteration 25450, lr = 0.01
I0618 00:12:03.271634  8058 solver.cpp:218] Iteration 25500 (0.865511 iter/s, 57.7694s/50 iters), loss = 0.0170381
I0618 00:12:03.271764  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 00:12:03.271792  8058 solver.cpp:237]     Train net output #1: loss = 0.0170381 (* 1 = 0.0170381 loss)
I0618 00:12:03.271809  8058 sgd_solver.cpp:105] Iteration 25500, lr = 0.01
I0618 00:12:37.996615  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 00:13:01.036397  8058 solver.cpp:218] Iteration 25550 (0.865588 iter/s, 57.7642s/50 iters), loss = 0.0169564
I0618 00:13:01.036490  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 00:13:01.036523  8058 solver.cpp:237]     Train net output #1: loss = 0.0169564 (* 1 = 0.0169564 loss)
I0618 00:13:01.036543  8058 sgd_solver.cpp:105] Iteration 25550, lr = 0.01
I0618 00:13:58.799085  8058 solver.cpp:218] Iteration 25600 (0.865619 iter/s, 57.7621s/50 iters), loss = 0.0187708
I0618 00:13:58.799213  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 00:13:58.799242  8058 solver.cpp:237]     Train net output #1: loss = 0.0187708 (* 1 = 0.0187708 loss)
I0618 00:13:58.799259  8058 sgd_solver.cpp:105] Iteration 25600, lr = 0.01
I0618 00:14:56.561056  8058 solver.cpp:218] Iteration 25650 (0.86563 iter/s, 57.7614s/50 iters), loss = 0.0205398
I0618 00:14:56.561170  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 00:14:56.561199  8058 solver.cpp:237]     Train net output #1: loss = 0.0205399 (* 1 = 0.0205399 loss)
I0618 00:14:56.561216  8058 sgd_solver.cpp:105] Iteration 25650, lr = 0.01
I0618 00:14:56.630511  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 00:15:54.325839  8058 solver.cpp:218] Iteration 25700 (0.865588 iter/s, 57.7642s/50 iters), loss = 0.0200742
I0618 00:15:54.325969  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 00:15:54.325999  8058 solver.cpp:237]     Train net output #1: loss = 0.0200742 (* 1 = 0.0200742 loss)
I0618 00:15:54.326015  8058 sgd_solver.cpp:105] Iteration 25700, lr = 0.01
I0618 00:16:52.084826  8058 solver.cpp:218] Iteration 25750 (0.865675 iter/s, 57.7584s/50 iters), loss = 0.0190432
I0618 00:16:52.085014  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 00:16:52.085044  8058 solver.cpp:237]     Train net output #1: loss = 0.0190432 (* 1 = 0.0190432 loss)
I0618 00:16:52.085062  8058 sgd_solver.cpp:105] Iteration 25750, lr = 0.01
I0618 00:17:15.243140  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 00:17:49.856621  8058 solver.cpp:218] Iteration 25800 (0.865484 iter/s, 57.7711s/50 iters), loss = 0.0178075
I0618 00:17:49.856787  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 00:17:49.856815  8058 solver.cpp:237]     Train net output #1: loss = 0.0178076 (* 1 = 0.0178076 loss)
I0618 00:17:49.856832  8058 sgd_solver.cpp:105] Iteration 25800, lr = 0.01
I0618 00:18:47.617933  8058 solver.cpp:218] Iteration 25850 (0.865641 iter/s, 57.7607s/50 iters), loss = 0.0147603
I0618 00:18:47.618053  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 00:18:47.618083  8058 solver.cpp:237]     Train net output #1: loss = 0.0147604 (* 1 = 0.0147604 loss)
I0618 00:18:47.618099  8058 sgd_solver.cpp:105] Iteration 25850, lr = 0.01
I0618 00:19:33.891738  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 00:19:45.399179  8058 solver.cpp:218] Iteration 25900 (0.865341 iter/s, 57.7807s/50 iters), loss = 0.0216837
I0618 00:19:45.399255  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 00:19:45.399281  8058 solver.cpp:237]     Train net output #1: loss = 0.0216837 (* 1 = 0.0216837 loss)
I0618 00:19:45.399299  8058 sgd_solver.cpp:105] Iteration 25900, lr = 0.01
I0618 00:20:43.181571  8058 solver.cpp:218] Iteration 25950 (0.865324 iter/s, 57.7819s/50 iters), loss = 0.0179619
I0618 00:20:43.181687  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 00:20:43.181716  8058 solver.cpp:237]     Train net output #1: loss = 0.0179619 (* 1 = 0.0179619 loss)
I0618 00:20:43.181735  8058 sgd_solver.cpp:105] Iteration 25950, lr = 0.01
I0618 00:21:40.952522  8058 solver.cpp:218] Iteration 26000 (0.865496 iter/s, 57.7704s/50 iters), loss = 0.0130802
I0618 00:21:40.952677  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 00:21:40.952705  8058 solver.cpp:237]     Train net output #1: loss = 0.0130802 (* 1 = 0.0130802 loss)
I0618 00:21:40.952723  8058 sgd_solver.cpp:105] Iteration 26000, lr = 0.01
I0618 00:21:51.426409  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 00:22:38.711086  8058 solver.cpp:218] Iteration 26050 (0.865682 iter/s, 57.7579s/50 iters), loss = 0.0204299
I0618 00:22:38.711207  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 00:22:38.711236  8058 solver.cpp:237]     Train net output #1: loss = 0.0204299 (* 1 = 0.0204299 loss)
I0618 00:22:38.711253  8058 sgd_solver.cpp:105] Iteration 26050, lr = 0.01
I0618 00:23:36.470576  8058 solver.cpp:218] Iteration 26100 (0.865667 iter/s, 57.7589s/50 iters), loss = 0.0163287
I0618 00:23:36.470703  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 00:23:36.470732  8058 solver.cpp:237]     Train net output #1: loss = 0.0163287 (* 1 = 0.0163287 loss)
I0618 00:23:36.470752  8058 sgd_solver.cpp:105] Iteration 26100, lr = 0.01
I0618 00:24:10.076131  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 00:24:34.235412  8058 solver.cpp:218] Iteration 26150 (0.865587 iter/s, 57.7643s/50 iters), loss = 0.0205642
I0618 00:24:34.235487  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 00:24:34.235522  8058 solver.cpp:237]     Train net output #1: loss = 0.0205643 (* 1 = 0.0205643 loss)
I0618 00:24:34.235543  8058 sgd_solver.cpp:105] Iteration 26150, lr = 0.01
I0618 00:25:32.005362  8058 solver.cpp:218] Iteration 26200 (0.86551 iter/s, 57.7694s/50 iters), loss = 0.01696
I0618 00:25:32.005478  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 00:25:32.005507  8058 solver.cpp:237]     Train net output #1: loss = 0.0169601 (* 1 = 0.0169601 loss)
I0618 00:25:32.005533  8058 sgd_solver.cpp:105] Iteration 26200, lr = 0.01
I0618 00:26:28.691010  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 00:26:29.766070  8058 solver.cpp:218] Iteration 26250 (0.865649 iter/s, 57.7601s/50 iters), loss = 0.0157134
I0618 00:26:29.766141  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 00:26:29.766167  8058 solver.cpp:237]     Train net output #1: loss = 0.0157134 (* 1 = 0.0157134 loss)
I0618 00:26:29.766185  8058 sgd_solver.cpp:105] Iteration 26250, lr = 0.01
I0618 00:27:27.529080  8058 solver.cpp:218] Iteration 26300 (0.865614 iter/s, 57.7625s/50 iters), loss = 0.020336
I0618 00:27:27.529216  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 00:27:27.529247  8058 solver.cpp:237]     Train net output #1: loss = 0.0203361 (* 1 = 0.0203361 loss)
I0618 00:27:27.529268  8058 sgd_solver.cpp:105] Iteration 26300, lr = 0.01
I0618 00:28:25.306129  8058 solver.cpp:218] Iteration 26350 (0.865404 iter/s, 57.7765s/50 iters), loss = 0.0160773
I0618 00:28:25.306308  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 00:28:25.306337  8058 solver.cpp:237]     Train net output #1: loss = 0.0160773 (* 1 = 0.0160773 loss)
I0618 00:28:25.306355  8058 sgd_solver.cpp:105] Iteration 26350, lr = 0.01
I0618 00:28:47.343257  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 00:29:23.102728  8058 solver.cpp:218] Iteration 26400 (0.865113 iter/s, 57.7959s/50 iters), loss = 0.0158158
I0618 00:29:23.102941  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 00:29:23.102972  8058 solver.cpp:237]     Train net output #1: loss = 0.0158159 (* 1 = 0.0158159 loss)
I0618 00:29:23.102990  8058 sgd_solver.cpp:105] Iteration 26400, lr = 0.01
I0618 00:30:21.316073  8058 solver.cpp:218] Iteration 26450 (0.858921 iter/s, 58.2126s/50 iters), loss = 0.0182508
I0618 00:30:21.317229  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 00:30:21.317265  8058 solver.cpp:237]     Train net output #1: loss = 0.0182509 (* 1 = 0.0182509 loss)
I0618 00:30:21.317286  8058 sgd_solver.cpp:105] Iteration 26450, lr = 0.01
I0618 00:31:06.908138  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 00:31:19.543819  8058 solver.cpp:218] Iteration 26500 (0.85872 iter/s, 58.2262s/50 iters), loss = 0.0196552
I0618 00:31:19.543952  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 00:31:19.543987  8058 solver.cpp:237]     Train net output #1: loss = 0.0196552 (* 1 = 0.0196552 loss)
I0618 00:31:19.544008  8058 sgd_solver.cpp:105] Iteration 26500, lr = 0.01
I0618 00:32:17.698532  8058 solver.cpp:218] Iteration 26550 (0.859784 iter/s, 58.1541s/50 iters), loss = 0.024667
I0618 00:32:17.698742  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 00:32:17.698786  8058 solver.cpp:237]     Train net output #1: loss = 0.024667 (* 1 = 0.024667 loss)
I0618 00:32:17.698813  8058 sgd_solver.cpp:105] Iteration 26550, lr = 0.01
I0618 00:33:15.499668  8058 solver.cpp:218] Iteration 26600 (0.865044 iter/s, 57.8006s/50 iters), loss = 0.045665
I0618 00:33:15.499799  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 00:33:15.499830  8058 solver.cpp:237]     Train net output #1: loss = 0.0456651 (* 1 = 0.0456651 loss)
I0618 00:33:15.499847  8058 sgd_solver.cpp:105] Iteration 26600, lr = 0.01
I0618 00:33:25.979673  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 00:34:13.265051  8058 solver.cpp:218] Iteration 26650 (0.865578 iter/s, 57.7649s/50 iters), loss = 0.195264
I0618 00:34:13.265185  8058 solver.cpp:237]     Train net output #0: accuracy = 0.96
I0618 00:34:13.265215  8058 solver.cpp:237]     Train net output #1: loss = 0.195264 (* 1 = 0.195264 loss)
I0618 00:34:13.265233  8058 sgd_solver.cpp:105] Iteration 26650, lr = 0.01
I0618 00:35:11.031433  8058 solver.cpp:218] Iteration 26700 (0.865563 iter/s, 57.7659s/50 iters), loss = 1.76503
I0618 00:35:11.031563  8058 solver.cpp:237]     Train net output #0: accuracy = 0.52
I0618 00:35:11.031594  8058 solver.cpp:237]     Train net output #1: loss = 1.76503 (* 1 = 1.76503 loss)
I0618 00:35:11.031610  8058 sgd_solver.cpp:105] Iteration 26700, lr = 0.01
I0618 00:35:44.607547  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 00:36:08.788774  8058 solver.cpp:218] Iteration 26750 (0.865698 iter/s, 57.7568s/50 iters), loss = 1.74457
I0618 00:36:08.788861  8058 solver.cpp:237]     Train net output #0: accuracy = 0.54
I0618 00:36:08.788888  8058 solver.cpp:237]     Train net output #1: loss = 1.74457 (* 1 = 1.74457 loss)
I0618 00:36:08.788907  8058 sgd_solver.cpp:105] Iteration 26750, lr = 0.01
I0618 00:37:06.561283  8058 solver.cpp:218] Iteration 26800 (0.86547 iter/s, 57.772s/50 iters), loss = 1.35998
I0618 00:37:06.561420  8058 solver.cpp:237]     Train net output #0: accuracy = 0.66
I0618 00:37:06.561450  8058 solver.cpp:237]     Train net output #1: loss = 1.35998 (* 1 = 1.35998 loss)
I0618 00:37:06.561467  8058 sgd_solver.cpp:105] Iteration 26800, lr = 0.01
I0618 00:38:03.248100  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 00:38:04.325170  8058 solver.cpp:218] Iteration 26850 (0.8656 iter/s, 57.7634s/50 iters), loss = 1.28378
I0618 00:38:04.325253  8058 solver.cpp:237]     Train net output #0: accuracy = 0.7
I0618 00:38:04.325280  8058 solver.cpp:237]     Train net output #1: loss = 1.28378 (* 1 = 1.28378 loss)
I0618 00:38:04.325314  8058 sgd_solver.cpp:105] Iteration 26850, lr = 0.01
I0618 00:39:02.087932  8058 solver.cpp:218] Iteration 26900 (0.865617 iter/s, 57.7623s/50 iters), loss = 0.927317
I0618 00:39:02.088059  8058 solver.cpp:237]     Train net output #0: accuracy = 0.76
I0618 00:39:02.088089  8058 solver.cpp:237]     Train net output #1: loss = 0.927317 (* 1 = 0.927317 loss)
I0618 00:39:02.088107  8058 sgd_solver.cpp:105] Iteration 26900, lr = 0.01
I0618 00:39:59.855231  8058 solver.cpp:218] Iteration 26950 (0.865549 iter/s, 57.7668s/50 iters), loss = 0.806207
I0618 00:39:59.855551  8058 solver.cpp:237]     Train net output #0: accuracy = 0.84
I0618 00:39:59.855583  8058 solver.cpp:237]     Train net output #1: loss = 0.806207 (* 1 = 0.806207 loss)
I0618 00:39:59.855603  8058 sgd_solver.cpp:105] Iteration 26950, lr = 0.01
I0618 00:40:20.765414  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 00:40:57.612717  8058 solver.cpp:218] Iteration 27000 (0.865699 iter/s, 57.7568s/50 iters), loss = 0.706117
I0618 00:40:57.612828  8058 solver.cpp:237]     Train net output #0: accuracy = 0.78
I0618 00:40:57.612859  8058 solver.cpp:237]     Train net output #1: loss = 0.706117 (* 1 = 0.706117 loss)
I0618 00:40:57.612876  8058 sgd_solver.cpp:105] Iteration 27000, lr = 0.01
I0618 00:41:55.371569  8058 solver.cpp:218] Iteration 27050 (0.865676 iter/s, 57.7584s/50 iters), loss = 0.552643
I0618 00:41:55.371687  8058 solver.cpp:237]     Train net output #0: accuracy = 0.88
I0618 00:41:55.371716  8058 solver.cpp:237]     Train net output #1: loss = 0.552643 (* 1 = 0.552643 loss)
I0618 00:41:55.371734  8058 sgd_solver.cpp:105] Iteration 27050, lr = 0.01
I0618 00:42:39.377430  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 00:42:53.137934  8058 solver.cpp:218] Iteration 27100 (0.865563 iter/s, 57.7659s/50 iters), loss = 0.663655
I0618 00:42:53.138011  8058 solver.cpp:237]     Train net output #0: accuracy = 0.88
I0618 00:42:53.138039  8058 solver.cpp:237]     Train net output #1: loss = 0.663655 (* 1 = 0.663655 loss)
I0618 00:42:53.138056  8058 sgd_solver.cpp:105] Iteration 27100, lr = 0.01
I0618 00:43:50.905771  8058 solver.cpp:218] Iteration 27150 (0.865541 iter/s, 57.7674s/50 iters), loss = 0.413675
I0618 00:43:50.906078  8058 solver.cpp:237]     Train net output #0: accuracy = 0.92
I0618 00:43:50.906110  8058 solver.cpp:237]     Train net output #1: loss = 0.413675 (* 1 = 0.413675 loss)
I0618 00:43:50.906127  8058 sgd_solver.cpp:105] Iteration 27150, lr = 0.01
I0618 00:44:48.670650  8058 solver.cpp:218] Iteration 27200 (0.865588 iter/s, 57.7642s/50 iters), loss = 0.386831
I0618 00:44:48.670774  8058 solver.cpp:237]     Train net output #0: accuracy = 0.92
I0618 00:44:48.670804  8058 solver.cpp:237]     Train net output #1: loss = 0.386831 (* 1 = 0.386831 loss)
I0618 00:44:48.670822  8058 sgd_solver.cpp:105] Iteration 27200, lr = 0.01
I0618 00:44:57.976907  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 00:45:46.443238  8058 solver.cpp:218] Iteration 27250 (0.86547 iter/s, 57.7721s/50 iters), loss = 0.485201
I0618 00:45:46.443425  8058 solver.cpp:237]     Train net output #0: accuracy = 0.9
I0618 00:45:46.443457  8058 solver.cpp:237]     Train net output #1: loss = 0.485201 (* 1 = 0.485201 loss)
I0618 00:45:46.443475  8058 sgd_solver.cpp:105] Iteration 27250, lr = 0.01
I0618 00:46:44.217193  8058 solver.cpp:218] Iteration 27300 (0.865451 iter/s, 57.7734s/50 iters), loss = 0.383723
I0618 00:46:44.217327  8058 solver.cpp:237]     Train net output #0: accuracy = 0.92
I0618 00:46:44.217357  8058 solver.cpp:237]     Train net output #1: loss = 0.383723 (* 1 = 0.383723 loss)
I0618 00:46:44.217375  8058 sgd_solver.cpp:105] Iteration 27300, lr = 0.01
I0618 00:47:16.660259  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 00:47:41.984256  8058 solver.cpp:218] Iteration 27350 (0.865553 iter/s, 57.7665s/50 iters), loss = 0.420463
I0618 00:47:41.984344  8058 solver.cpp:237]     Train net output #0: accuracy = 0.88
I0618 00:47:41.984387  8058 solver.cpp:237]     Train net output #1: loss = 0.420463 (* 1 = 0.420463 loss)
I0618 00:47:41.984405  8058 sgd_solver.cpp:105] Iteration 27350, lr = 0.01
I0618 00:48:39.753525  8058 solver.cpp:218] Iteration 27400 (0.86552 iter/s, 57.7688s/50 iters), loss = 0.362071
I0618 00:48:39.753695  8058 solver.cpp:237]     Train net output #0: accuracy = 0.92
I0618 00:48:39.753726  8058 solver.cpp:237]     Train net output #1: loss = 0.362071 (* 1 = 0.362071 loss)
I0618 00:48:39.753744  8058 sgd_solver.cpp:105] Iteration 27400, lr = 0.01
I0618 00:49:35.325130  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 00:49:37.576939  8058 solver.cpp:218] Iteration 27450 (0.86471 iter/s, 57.8228s/50 iters), loss = 0.171564
I0618 00:49:37.577049  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 00:49:37.577075  8058 solver.cpp:237]     Train net output #1: loss = 0.171564 (* 1 = 0.171564 loss)
I0618 00:49:37.577095  8058 sgd_solver.cpp:105] Iteration 27450, lr = 0.01
I0618 00:50:35.398929  8058 solver.cpp:218] Iteration 27500 (0.864731 iter/s, 57.8215s/50 iters), loss = 0.307144
I0618 00:50:35.399098  8058 solver.cpp:237]     Train net output #0: accuracy = 0.94
I0618 00:50:35.399128  8058 solver.cpp:237]     Train net output #1: loss = 0.307144 (* 1 = 0.307144 loss)
I0618 00:50:35.399147  8058 sgd_solver.cpp:105] Iteration 27500, lr = 0.01
I0618 00:51:33.223417  8058 solver.cpp:218] Iteration 27550 (0.864694 iter/s, 57.8239s/50 iters), loss = 0.436582
I0618 00:51:33.223582  8058 solver.cpp:237]     Train net output #0: accuracy = 0.9
I0618 00:51:33.223610  8058 solver.cpp:237]     Train net output #1: loss = 0.436582 (* 1 = 0.436582 loss)
I0618 00:51:33.223629  8058 sgd_solver.cpp:105] Iteration 27550, lr = 0.01
I0618 00:51:54.095352  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 00:52:31.055266  8058 solver.cpp:218] Iteration 27600 (0.864584 iter/s, 57.8313s/50 iters), loss = 0.183906
I0618 00:52:31.055424  8058 solver.cpp:237]     Train net output #0: accuracy = 0.96
I0618 00:52:31.055454  8058 solver.cpp:237]     Train net output #1: loss = 0.183906 (* 1 = 0.183906 loss)
I0618 00:52:31.055474  8058 sgd_solver.cpp:105] Iteration 27600, lr = 0.01
I0618 00:53:28.888661  8058 solver.cpp:218] Iteration 27650 (0.864561 iter/s, 57.8328s/50 iters), loss = 0.155954
I0618 00:53:28.888833  8058 solver.cpp:237]     Train net output #0: accuracy = 0.98
I0618 00:53:28.888862  8058 solver.cpp:237]     Train net output #1: loss = 0.155954 (* 1 = 0.155954 loss)
I0618 00:53:28.888881  8058 sgd_solver.cpp:105] Iteration 27650, lr = 0.01
I0618 00:54:12.898205  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 00:54:26.724520  8058 solver.cpp:218] Iteration 27700 (0.864524 iter/s, 57.8353s/50 iters), loss = 0.178397
I0618 00:54:26.724644  8058 solver.cpp:237]     Train net output #0: accuracy = 0.96
I0618 00:54:26.724673  8058 solver.cpp:237]     Train net output #1: loss = 0.178397 (* 1 = 0.178397 loss)
I0618 00:54:26.724692  8058 sgd_solver.cpp:105] Iteration 27700, lr = 0.01
I0618 00:55:24.537472  8058 solver.cpp:218] Iteration 27750 (0.864866 iter/s, 57.8124s/50 iters), loss = 0.154966
I0618 00:55:24.537714  8058 solver.cpp:237]     Train net output #0: accuracy = 0.98
I0618 00:55:24.537750  8058 solver.cpp:237]     Train net output #1: loss = 0.154966 (* 1 = 0.154966 loss)
I0618 00:55:24.537771  8058 sgd_solver.cpp:105] Iteration 27750, lr = 0.01
I0618 00:56:22.371963  8058 solver.cpp:218] Iteration 27800 (0.864546 iter/s, 57.8338s/50 iters), loss = 0.121632
I0618 00:56:22.372133  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 00:56:22.372162  8058 solver.cpp:237]     Train net output #1: loss = 0.121632 (* 1 = 0.121632 loss)
I0618 00:56:22.372181  8058 sgd_solver.cpp:105] Iteration 27800, lr = 0.01
I0618 00:56:31.679944  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 00:57:20.211784  8058 solver.cpp:218] Iteration 27850 (0.864465 iter/s, 57.8392s/50 iters), loss = 0.0742815
I0618 00:57:20.212028  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 00:57:20.212076  8058 solver.cpp:237]     Train net output #1: loss = 0.0742815 (* 1 = 0.0742815 loss)
I0618 00:57:20.212096  8058 sgd_solver.cpp:105] Iteration 27850, lr = 0.01
I0618 00:58:18.043910  8058 solver.cpp:218] Iteration 27900 (0.864581 iter/s, 57.8315s/50 iters), loss = 0.0724083
I0618 00:58:18.044061  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 00:58:18.044091  8058 solver.cpp:237]     Train net output #1: loss = 0.0724083 (* 1 = 0.0724083 loss)
I0618 00:58:18.044111  8058 sgd_solver.cpp:105] Iteration 27900, lr = 0.01
I0618 00:58:50.475141  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 00:59:15.821055  8058 solver.cpp:218] Iteration 27950 (0.865403 iter/s, 57.7766s/50 iters), loss = 0.0995818
I0618 00:59:15.821154  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 00:59:15.821187  8058 solver.cpp:237]     Train net output #1: loss = 0.0995818 (* 1 = 0.0995818 loss)
I0618 00:59:15.821208  8058 sgd_solver.cpp:105] Iteration 27950, lr = 0.01
I0618 01:00:13.587079  8058 solver.cpp:218] Iteration 28000 (0.865568 iter/s, 57.7655s/50 iters), loss = 0.0750303
I0618 01:00:13.587195  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 01:00:13.587224  8058 solver.cpp:237]     Train net output #1: loss = 0.0750303 (* 1 = 0.0750303 loss)
I0618 01:00:13.587241  8058 sgd_solver.cpp:105] Iteration 28000, lr = 0.01
I0618 01:01:07.983592  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 01:01:11.342458  8058 solver.cpp:218] Iteration 28050 (0.865728 iter/s, 57.7549s/50 iters), loss = 0.0542274
I0618 01:01:11.342533  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 01:01:11.342563  8058 solver.cpp:237]     Train net output #1: loss = 0.0542274 (* 1 = 0.0542274 loss)
I0618 01:01:11.342581  8058 sgd_solver.cpp:105] Iteration 28050, lr = 0.01
I0618 01:02:09.106570  8058 solver.cpp:218] Iteration 28100 (0.865597 iter/s, 57.7636s/50 iters), loss = 0.0276779
I0618 01:02:09.106706  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 01:02:09.106736  8058 solver.cpp:237]     Train net output #1: loss = 0.0276779 (* 1 = 0.0276779 loss)
I0618 01:02:09.106755  8058 sgd_solver.cpp:105] Iteration 28100, lr = 0.01
I0618 01:03:06.866719  8058 solver.cpp:218] Iteration 28150 (0.865657 iter/s, 57.7596s/50 iters), loss = 0.0284074
I0618 01:03:06.866833  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 01:03:06.866863  8058 solver.cpp:237]     Train net output #1: loss = 0.0284075 (* 1 = 0.0284075 loss)
I0618 01:03:06.866883  8058 sgd_solver.cpp:105] Iteration 28150, lr = 0.01
I0618 01:03:26.610283  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 01:04:04.627395  8058 solver.cpp:218] Iteration 28200 (0.865649 iter/s, 57.7602s/50 iters), loss = 0.0297861
I0618 01:04:04.627549  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 01:04:04.627580  8058 solver.cpp:237]     Train net output #1: loss = 0.0297861 (* 1 = 0.0297861 loss)
I0618 01:04:04.627599  8058 sgd_solver.cpp:105] Iteration 28200, lr = 0.01
I0618 01:05:02.393280  8058 solver.cpp:218] Iteration 28250 (0.865571 iter/s, 57.7654s/50 iters), loss = 0.0426906
I0618 01:05:02.393406  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 01:05:02.393436  8058 solver.cpp:237]     Train net output #1: loss = 0.0426906 (* 1 = 0.0426906 loss)
I0618 01:05:02.393455  8058 sgd_solver.cpp:105] Iteration 28250, lr = 0.01
I0618 01:05:45.243010  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 01:06:00.166363  8058 solver.cpp:218] Iteration 28300 (0.865462 iter/s, 57.7726s/50 iters), loss = 0.0273191
I0618 01:06:00.166442  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 01:06:00.166471  8058 solver.cpp:237]     Train net output #1: loss = 0.0273191 (* 1 = 0.0273191 loss)
I0618 01:06:00.166488  8058 sgd_solver.cpp:105] Iteration 28300, lr = 0.01
I0618 01:06:57.931471  8058 solver.cpp:218] Iteration 28350 (0.865581 iter/s, 57.7647s/50 iters), loss = 0.0228137
I0618 01:06:57.931607  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 01:06:57.931637  8058 solver.cpp:237]     Train net output #1: loss = 0.0228137 (* 1 = 0.0228137 loss)
I0618 01:06:57.931654  8058 sgd_solver.cpp:105] Iteration 28350, lr = 0.01
I0618 01:07:55.693332  8058 solver.cpp:218] Iteration 28400 (0.86563 iter/s, 57.7614s/50 iters), loss = 0.0227192
I0618 01:07:55.693454  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 01:07:55.693483  8058 solver.cpp:237]     Train net output #1: loss = 0.0227192 (* 1 = 0.0227192 loss)
I0618 01:07:55.693501  8058 sgd_solver.cpp:105] Iteration 28400, lr = 0.01
I0618 01:08:03.859380  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 01:08:53.474467  8058 solver.cpp:218] Iteration 28450 (0.865341 iter/s, 57.7807s/50 iters), loss = 0.038454
I0618 01:08:53.474701  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 01:08:53.474731  8058 solver.cpp:237]     Train net output #1: loss = 0.038454 (* 1 = 0.038454 loss)
I0618 01:08:53.474750  8058 sgd_solver.cpp:105] Iteration 28450, lr = 0.01
I0618 01:09:51.270347  8058 solver.cpp:218] Iteration 28500 (0.865122 iter/s, 57.7953s/50 iters), loss = 0.0493947
I0618 01:09:51.270463  8058 solver.cpp:237]     Train net output #0: accuracy = 0.98
I0618 01:09:51.270493  8058 solver.cpp:237]     Train net output #1: loss = 0.0493947 (* 1 = 0.0493947 loss)
I0618 01:09:51.270511  8058 sgd_solver.cpp:105] Iteration 28500, lr = 0.01
I0618 01:10:22.564874  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 01:10:49.041545  8058 solver.cpp:218] Iteration 28550 (0.86549 iter/s, 57.7707s/50 iters), loss = 0.0372685
I0618 01:10:49.041621  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 01:10:49.041649  8058 solver.cpp:237]     Train net output #1: loss = 0.0372686 (* 1 = 0.0372686 loss)
I0618 01:10:49.041667  8058 sgd_solver.cpp:105] Iteration 28550, lr = 0.01
I0618 01:11:46.803774  8058 solver.cpp:218] Iteration 28600 (0.865624 iter/s, 57.7618s/50 iters), loss = 0.0233586
I0618 01:11:46.803889  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 01:11:46.803918  8058 solver.cpp:237]     Train net output #1: loss = 0.0233587 (* 1 = 0.0233587 loss)
I0618 01:11:46.803936  8058 sgd_solver.cpp:105] Iteration 28600, lr = 0.01
I0618 01:12:41.186404  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 01:12:44.567827  8058 solver.cpp:218] Iteration 28650 (0.865597 iter/s, 57.7636s/50 iters), loss = 0.0196561
I0618 01:12:44.567909  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 01:12:44.567936  8058 solver.cpp:237]     Train net output #1: loss = 0.0196561 (* 1 = 0.0196561 loss)
I0618 01:12:44.567955  8058 sgd_solver.cpp:105] Iteration 28650, lr = 0.01
I0618 01:13:42.331418  8058 solver.cpp:218] Iteration 28700 (0.865604 iter/s, 57.7632s/50 iters), loss = 0.016897
I0618 01:13:42.331600  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 01:13:42.331630  8058 solver.cpp:237]     Train net output #1: loss = 0.016897 (* 1 = 0.016897 loss)
I0618 01:13:42.331648  8058 sgd_solver.cpp:105] Iteration 28700, lr = 0.01
I0618 01:14:40.097945  8058 solver.cpp:218] Iteration 28750 (0.865561 iter/s, 57.766s/50 iters), loss = 0.0182587
I0618 01:14:40.098107  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 01:14:40.098139  8058 solver.cpp:237]     Train net output #1: loss = 0.0182587 (* 1 = 0.0182587 loss)
I0618 01:14:40.098157  8058 sgd_solver.cpp:105] Iteration 28750, lr = 0.01
I0618 01:14:59.817581  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 01:15:37.845978  8058 solver.cpp:218] Iteration 28800 (0.865838 iter/s, 57.7475s/50 iters), loss = 0.0168601
I0618 01:15:37.846101  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 01:15:37.846129  8058 solver.cpp:237]     Train net output #1: loss = 0.0168601 (* 1 = 0.0168601 loss)
I0618 01:15:37.846148  8058 sgd_solver.cpp:105] Iteration 28800, lr = 0.01
I0618 01:16:35.600899  8058 solver.cpp:218] Iteration 28850 (0.865734 iter/s, 57.7545s/50 iters), loss = 0.015131
I0618 01:16:35.601030  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 01:16:35.601060  8058 solver.cpp:237]     Train net output #1: loss = 0.015131 (* 1 = 0.015131 loss)
I0618 01:16:35.601078  8058 sgd_solver.cpp:105] Iteration 28850, lr = 0.01
I0618 01:17:18.425099  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 01:17:33.371603  8058 solver.cpp:218] Iteration 28900 (0.865498 iter/s, 57.7702s/50 iters), loss = 0.0164194
I0618 01:17:33.371688  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 01:17:33.371716  8058 solver.cpp:237]     Train net output #1: loss = 0.0164194 (* 1 = 0.0164194 loss)
I0618 01:17:33.371733  8058 sgd_solver.cpp:105] Iteration 28900, lr = 0.01
I0618 01:18:31.129853  8058 solver.cpp:218] Iteration 28950 (0.865684 iter/s, 57.7578s/50 iters), loss = 0.0129016
I0618 01:18:31.130012  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 01:18:31.130043  8058 solver.cpp:237]     Train net output #1: loss = 0.0129016 (* 1 = 0.0129016 loss)
I0618 01:18:31.130060  8058 sgd_solver.cpp:105] Iteration 28950, lr = 0.01
I0618 01:19:28.894732  8058 solver.cpp:218] Iteration 29000 (0.865586 iter/s, 57.7644s/50 iters), loss = 0.0124352
I0618 01:19:28.894850  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 01:19:28.894879  8058 solver.cpp:237]     Train net output #1: loss = 0.0124352 (* 1 = 0.0124352 loss)
I0618 01:19:28.894897  8058 sgd_solver.cpp:105] Iteration 29000, lr = 0.01
I0618 01:19:35.928902  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 01:20:26.656148  8058 solver.cpp:218] Iteration 29050 (0.865637 iter/s, 57.761s/50 iters), loss = 0.0143238
I0618 01:20:26.656246  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 01:20:26.656275  8058 solver.cpp:237]     Train net output #1: loss = 0.0143239 (* 1 = 0.0143239 loss)
I0618 01:20:26.656293  8058 sgd_solver.cpp:105] Iteration 29050, lr = 0.01
I0618 01:21:24.418191  8058 solver.cpp:218] Iteration 29100 (0.865627 iter/s, 57.7616s/50 iters), loss = 0.014369
I0618 01:21:24.418328  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 01:21:24.418356  8058 solver.cpp:237]     Train net output #1: loss = 0.014369 (* 1 = 0.014369 loss)
I0618 01:21:24.418373  8058 sgd_solver.cpp:105] Iteration 29100, lr = 0.01
I0618 01:21:54.544972  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 01:22:22.199477  8058 solver.cpp:218] Iteration 29150 (0.865341 iter/s, 57.7807s/50 iters), loss = 0.0149399
I0618 01:22:22.199563  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 01:22:22.199589  8058 solver.cpp:237]     Train net output #1: loss = 0.0149399 (* 1 = 0.0149399 loss)
I0618 01:22:22.199607  8058 sgd_solver.cpp:105] Iteration 29150, lr = 0.01
I0618 01:23:19.960559  8058 solver.cpp:218] Iteration 29200 (0.865643 iter/s, 57.7605s/50 iters), loss = 0.0143229
I0618 01:23:19.960738  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 01:23:19.960768  8058 solver.cpp:237]     Train net output #1: loss = 0.0143229 (* 1 = 0.0143229 loss)
I0618 01:23:19.960786  8058 sgd_solver.cpp:105] Iteration 29200, lr = 0.01
I0618 01:24:13.190790  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 01:24:17.706264  8058 solver.cpp:218] Iteration 29250 (0.865875 iter/s, 57.7451s/50 iters), loss = 0.0125742
I0618 01:24:17.706346  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 01:24:17.706373  8058 solver.cpp:237]     Train net output #1: loss = 0.0125742 (* 1 = 0.0125742 loss)
I0618 01:24:17.706392  8058 sgd_solver.cpp:105] Iteration 29250, lr = 0.01
I0618 01:25:15.474184  8058 solver.cpp:218] Iteration 29300 (0.86554 iter/s, 57.7674s/50 iters), loss = 0.0133859
I0618 01:25:15.474305  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 01:25:15.474335  8058 solver.cpp:237]     Train net output #1: loss = 0.0133859 (* 1 = 0.0133859 loss)
I0618 01:25:15.474354  8058 sgd_solver.cpp:105] Iteration 29300, lr = 0.01
I0618 01:26:13.226068  8058 solver.cpp:218] Iteration 29350 (0.865781 iter/s, 57.7513s/50 iters), loss = 0.0128189
I0618 01:26:13.226191  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 01:26:13.226222  8058 solver.cpp:237]     Train net output #1: loss = 0.0128189 (* 1 = 0.0128189 loss)
I0618 01:26:13.226239  8058 sgd_solver.cpp:105] Iteration 29350, lr = 0.01
I0618 01:26:31.808079  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 01:27:10.997944  8058 solver.cpp:218] Iteration 29400 (0.865482 iter/s, 57.7713s/50 iters), loss = 0.0085944
I0618 01:27:10.998064  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 01:27:10.998093  8058 solver.cpp:237]     Train net output #1: loss = 0.00859442 (* 1 = 0.00859442 loss)
I0618 01:27:10.998114  8058 sgd_solver.cpp:105] Iteration 29400, lr = 0.01
I0618 01:28:08.763291  8058 solver.cpp:218] Iteration 29450 (0.865579 iter/s, 57.7648s/50 iters), loss = 0.0131595
I0618 01:28:08.763406  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 01:28:08.763434  8058 solver.cpp:237]     Train net output #1: loss = 0.0131595 (* 1 = 0.0131595 loss)
I0618 01:28:08.763453  8058 sgd_solver.cpp:105] Iteration 29450, lr = 0.01
I0618 01:28:50.421720  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 01:29:06.528064  8058 solver.cpp:218] Iteration 29500 (0.865588 iter/s, 57.7642s/50 iters), loss = 0.00802297
I0618 01:29:06.528147  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 01:29:06.528175  8058 solver.cpp:237]     Train net output #1: loss = 0.00802298 (* 1 = 0.00802298 loss)
I0618 01:29:06.528193  8058 sgd_solver.cpp:105] Iteration 29500, lr = 0.01
I0618 01:30:04.289057  8058 solver.cpp:218] Iteration 29550 (0.865644 iter/s, 57.7605s/50 iters), loss = 0.0104277
I0618 01:30:04.289166  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 01:30:04.289196  8058 solver.cpp:237]     Train net output #1: loss = 0.0104277 (* 1 = 0.0104277 loss)
I0618 01:30:04.289214  8058 sgd_solver.cpp:105] Iteration 29550, lr = 0.01
I0618 01:31:02.054095  8058 solver.cpp:218] Iteration 29600 (0.865584 iter/s, 57.7645s/50 iters), loss = 0.0134758
I0618 01:31:02.054214  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 01:31:02.054246  8058 solver.cpp:237]     Train net output #1: loss = 0.0134758 (* 1 = 0.0134758 loss)
I0618 01:31:02.054267  8058 sgd_solver.cpp:105] Iteration 29600, lr = 0.01
I0618 01:31:09.068864  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 01:31:59.816081  8058 solver.cpp:218] Iteration 29650 (0.86563 iter/s, 57.7614s/50 iters), loss = 0.00886375
I0618 01:31:59.816897  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 01:31:59.816927  8058 solver.cpp:237]     Train net output #1: loss = 0.00886376 (* 1 = 0.00886376 loss)
I0618 01:31:59.816946  8058 sgd_solver.cpp:105] Iteration 29650, lr = 0.01
I0618 01:32:57.571002  8058 solver.cpp:218] Iteration 29700 (0.865746 iter/s, 57.7537s/50 iters), loss = 0.00961673
I0618 01:32:57.571197  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 01:32:57.571228  8058 solver.cpp:237]     Train net output #1: loss = 0.00961674 (* 1 = 0.00961674 loss)
I0618 01:32:57.571245  8058 sgd_solver.cpp:105] Iteration 29700, lr = 0.01
I0618 01:33:27.650842  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 01:33:55.325592  8058 solver.cpp:218] Iteration 29750 (0.865742 iter/s, 57.7539s/50 iters), loss = 0.0147723
I0618 01:33:55.325687  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 01:33:55.325716  8058 solver.cpp:237]     Train net output #1: loss = 0.0147724 (* 1 = 0.0147724 loss)
I0618 01:33:55.325733  8058 sgd_solver.cpp:105] Iteration 29750, lr = 0.01
I0618 01:34:53.093818  8058 solver.cpp:218] Iteration 29800 (0.865536 iter/s, 57.7677s/50 iters), loss = 0.0102788
I0618 01:34:53.093948  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 01:34:53.093978  8058 solver.cpp:237]     Train net output #1: loss = 0.0102788 (* 1 = 0.0102788 loss)
I0618 01:34:53.094009  8058 sgd_solver.cpp:105] Iteration 29800, lr = 0.01
I0618 01:35:46.290451  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 01:35:50.849158  8058 solver.cpp:218] Iteration 29850 (0.865729 iter/s, 57.7548s/50 iters), loss = 0.0143481
I0618 01:35:50.849234  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 01:35:50.849261  8058 solver.cpp:237]     Train net output #1: loss = 0.0143481 (* 1 = 0.0143481 loss)
I0618 01:35:50.849278  8058 sgd_solver.cpp:105] Iteration 29850, lr = 0.01
I0618 01:36:48.609237  8058 solver.cpp:218] Iteration 29900 (0.865658 iter/s, 57.7596s/50 iters), loss = 0.0131872
I0618 01:36:48.609360  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 01:36:48.609390  8058 solver.cpp:237]     Train net output #1: loss = 0.0131872 (* 1 = 0.0131872 loss)
I0618 01:36:48.609407  8058 sgd_solver.cpp:105] Iteration 29900, lr = 0.01
I0618 01:37:46.381124  8058 solver.cpp:218] Iteration 29950 (0.865481 iter/s, 57.7713s/50 iters), loss = 0.0107178
I0618 01:37:46.381254  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 01:37:46.381283  8058 solver.cpp:237]     Train net output #1: loss = 0.0107178 (* 1 = 0.0107178 loss)
I0618 01:37:46.381302  8058 sgd_solver.cpp:105] Iteration 29950, lr = 0.01
I0618 01:38:03.822855  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 01:38:42.996254  8058 solver.cpp:447] Snapshotting to binary proto file mobilenet/mobile_cub_iter_30000.caffemodel
I0618 01:38:43.085247  8058 sgd_solver.cpp:273] Snapshotting solver state to binary proto file mobilenet/mobile_cub_iter_30000.solverstate
I0618 01:38:44.269747  8058 solver.cpp:218] Iteration 30000 (0.863736 iter/s, 57.8881s/50 iters), loss = 0.00999772
I0618 01:38:44.269817  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 01:38:44.269840  8058 solver.cpp:237]     Train net output #1: loss = 0.00999772 (* 1 = 0.00999772 loss)
I0618 01:38:44.269857  8058 sgd_solver.cpp:105] Iteration 30000, lr = 0.01
I0618 01:39:42.027990  8058 solver.cpp:218] Iteration 30050 (0.865685 iter/s, 57.7577s/50 iters), loss = 0.0136768
I0618 01:39:42.028118  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 01:39:42.028147  8058 solver.cpp:237]     Train net output #1: loss = 0.0136768 (* 1 = 0.0136768 loss)
I0618 01:39:42.028163  8058 sgd_solver.cpp:105] Iteration 30050, lr = 0.01
I0618 01:40:22.572290  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 01:40:39.795840  8058 solver.cpp:218] Iteration 30100 (0.865542 iter/s, 57.7673s/50 iters), loss = 0.0122114
I0618 01:40:39.795933  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 01:40:39.795961  8058 solver.cpp:237]     Train net output #1: loss = 0.0122114 (* 1 = 0.0122114 loss)
I0618 01:40:39.795979  8058 sgd_solver.cpp:105] Iteration 30100, lr = 0.01
I0618 01:41:37.571789  8058 solver.cpp:218] Iteration 30150 (0.86542 iter/s, 57.7754s/50 iters), loss = 0.0095307
I0618 01:41:37.571990  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 01:41:37.572018  8058 solver.cpp:237]     Train net output #1: loss = 0.00953071 (* 1 = 0.00953071 loss)
I0618 01:41:37.572036  8058 sgd_solver.cpp:105] Iteration 30150, lr = 0.01
I0618 01:42:35.341305  8058 solver.cpp:218] Iteration 30200 (0.865518 iter/s, 57.7689s/50 iters), loss = 0.00772393
I0618 01:42:35.341431  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 01:42:35.341461  8058 solver.cpp:237]     Train net output #1: loss = 0.00772393 (* 1 = 0.00772393 loss)
I0618 01:42:35.341480  8058 sgd_solver.cpp:105] Iteration 30200, lr = 0.01
I0618 01:42:41.218976  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 01:43:33.109951  8058 solver.cpp:218] Iteration 30250 (0.86553 iter/s, 57.7681s/50 iters), loss = 0.011602
I0618 01:43:33.110070  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 01:43:33.110100  8058 solver.cpp:237]     Train net output #1: loss = 0.011602 (* 1 = 0.011602 loss)
I0618 01:43:33.110116  8058 sgd_solver.cpp:105] Iteration 30250, lr = 0.01
I0618 01:44:30.885957  8058 solver.cpp:218] Iteration 30300 (0.86542 iter/s, 57.7754s/50 iters), loss = 0.00874276
I0618 01:44:30.886092  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 01:44:30.886121  8058 solver.cpp:237]     Train net output #1: loss = 0.00874276 (* 1 = 0.00874276 loss)
I0618 01:44:30.886139  8058 sgd_solver.cpp:105] Iteration 30300, lr = 0.01
I0618 01:44:59.862294  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 01:45:28.652765  8058 solver.cpp:218] Iteration 30350 (0.865558 iter/s, 57.7662s/50 iters), loss = 0.00924055
I0618 01:45:28.652879  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 01:45:28.652909  8058 solver.cpp:237]     Train net output #1: loss = 0.00924056 (* 1 = 0.00924056 loss)
I0618 01:45:28.652925  8058 sgd_solver.cpp:105] Iteration 30350, lr = 0.01
I0618 01:46:26.427631  8058 solver.cpp:218] Iteration 30400 (0.865437 iter/s, 57.7743s/50 iters), loss = 0.0098772
I0618 01:46:26.427754  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 01:46:26.427784  8058 solver.cpp:237]     Train net output #1: loss = 0.00987721 (* 1 = 0.00987721 loss)
I0618 01:46:26.427805  8058 sgd_solver.cpp:105] Iteration 30400, lr = 0.01
I0618 01:47:18.530194  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 01:47:24.212635  8058 solver.cpp:218] Iteration 30450 (0.865285 iter/s, 57.7844s/50 iters), loss = 0.0118962
I0618 01:47:24.212708  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 01:47:24.212736  8058 solver.cpp:237]     Train net output #1: loss = 0.0118962 (* 1 = 0.0118962 loss)
I0618 01:47:24.212754  8058 sgd_solver.cpp:105] Iteration 30450, lr = 0.01
I0618 01:48:21.988747  8058 solver.cpp:218] Iteration 30500 (0.865417 iter/s, 57.7756s/50 iters), loss = 0.0135618
I0618 01:48:21.988880  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 01:48:21.988910  8058 solver.cpp:237]     Train net output #1: loss = 0.0135618 (* 1 = 0.0135618 loss)
I0618 01:48:21.988929  8058 sgd_solver.cpp:105] Iteration 30500, lr = 0.01
I0618 01:49:19.753727  8058 solver.cpp:218] Iteration 30550 (0.865585 iter/s, 57.7644s/50 iters), loss = 0.0114041
I0618 01:49:19.753849  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 01:49:19.753878  8058 solver.cpp:237]     Train net output #1: loss = 0.0114041 (* 1 = 0.0114041 loss)
I0618 01:49:19.753895  8058 sgd_solver.cpp:105] Iteration 30550, lr = 0.01
I0618 01:49:37.171965  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 01:50:17.513249  8058 solver.cpp:218] Iteration 30600 (0.865667 iter/s, 57.7589s/50 iters), loss = 0.0112154
I0618 01:50:17.513383  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 01:50:17.513417  8058 solver.cpp:237]     Train net output #1: loss = 0.0112154 (* 1 = 0.0112154 loss)
I0618 01:50:17.513437  8058 sgd_solver.cpp:105] Iteration 30600, lr = 0.01
I0618 01:51:15.285789  8058 solver.cpp:218] Iteration 30650 (0.865472 iter/s, 57.772s/50 iters), loss = 0.011518
I0618 01:51:15.285972  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 01:51:15.286002  8058 solver.cpp:237]     Train net output #1: loss = 0.0115181 (* 1 = 0.0115181 loss)
I0618 01:51:15.286020  8058 sgd_solver.cpp:105] Iteration 30650, lr = 0.01
I0618 01:51:55.801419  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 01:52:13.047535  8058 solver.cpp:218] Iteration 30700 (0.865634 iter/s, 57.7611s/50 iters), loss = 0.0115114
I0618 01:52:13.047615  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 01:52:13.047641  8058 solver.cpp:237]     Train net output #1: loss = 0.0115114 (* 1 = 0.0115114 loss)
I0618 01:52:13.047659  8058 sgd_solver.cpp:105] Iteration 30700, lr = 0.01
I0618 01:53:10.806911  8058 solver.cpp:218] Iteration 30750 (0.865668 iter/s, 57.7589s/50 iters), loss = 0.0151076
I0618 01:53:10.807051  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 01:53:10.807081  8058 solver.cpp:237]     Train net output #1: loss = 0.0151076 (* 1 = 0.0151076 loss)
I0618 01:53:10.807111  8058 sgd_solver.cpp:105] Iteration 30750, lr = 0.01
I0618 01:54:08.568001  8058 solver.cpp:218] Iteration 30800 (0.865644 iter/s, 57.7605s/50 iters), loss = 0.010537
I0618 01:54:08.568125  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 01:54:08.568156  8058 solver.cpp:237]     Train net output #1: loss = 0.010537 (* 1 = 0.010537 loss)
I0618 01:54:08.568176  8058 sgd_solver.cpp:105] Iteration 30800, lr = 0.01
I0618 01:54:14.420406  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 01:55:06.333724  8058 solver.cpp:218] Iteration 30850 (0.865574 iter/s, 57.7652s/50 iters), loss = 0.00957654
I0618 01:55:06.333837  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 01:55:06.333865  8058 solver.cpp:237]     Train net output #1: loss = 0.00957655 (* 1 = 0.00957655 loss)
I0618 01:55:06.333883  8058 sgd_solver.cpp:105] Iteration 30850, lr = 0.01
I0618 01:56:04.095324  8058 solver.cpp:218] Iteration 30900 (0.865635 iter/s, 57.761s/50 iters), loss = 0.00894196
I0618 01:56:04.095444  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 01:56:04.095473  8058 solver.cpp:237]     Train net output #1: loss = 0.00894197 (* 1 = 0.00894197 loss)
I0618 01:56:04.095491  8058 sgd_solver.cpp:105] Iteration 30900, lr = 0.01
I0618 01:56:33.025355  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 01:57:01.863611  8058 solver.cpp:218] Iteration 30950 (0.865535 iter/s, 57.7677s/50 iters), loss = 0.0106845
I0618 01:57:01.863737  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 01:57:01.863766  8058 solver.cpp:237]     Train net output #1: loss = 0.0106845 (* 1 = 0.0106845 loss)
I0618 01:57:01.863785  8058 sgd_solver.cpp:105] Iteration 30950, lr = 0.01
I0618 01:57:59.619104  8058 solver.cpp:218] Iteration 31000 (0.865727 iter/s, 57.7549s/50 iters), loss = 0.0124192
I0618 01:57:59.619244  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 01:57:59.619274  8058 solver.cpp:237]     Train net output #1: loss = 0.0124192 (* 1 = 0.0124192 loss)
I0618 01:57:59.619293  8058 sgd_solver.cpp:105] Iteration 31000, lr = 0.01
I0618 01:58:50.550374  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 01:58:57.411705  8058 solver.cpp:218] Iteration 31050 (0.865172 iter/s, 57.792s/50 iters), loss = 0.012885
I0618 01:58:57.411819  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 01:58:57.411846  8058 solver.cpp:237]     Train net output #1: loss = 0.012885 (* 1 = 0.012885 loss)
I0618 01:58:57.411864  8058 sgd_solver.cpp:105] Iteration 31050, lr = 0.01
I0618 01:59:55.236567  8058 solver.cpp:218] Iteration 31100 (0.864689 iter/s, 57.8243s/50 iters), loss = 0.00998885
I0618 01:59:55.236732  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 01:59:55.236762  8058 solver.cpp:237]     Train net output #1: loss = 0.00998885 (* 1 = 0.00998885 loss)
I0618 01:59:55.236779  8058 sgd_solver.cpp:105] Iteration 31100, lr = 0.01
I0618 02:00:53.056905  8058 solver.cpp:218] Iteration 31150 (0.864757 iter/s, 57.8197s/50 iters), loss = 0.0115932
I0618 02:00:53.057126  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 02:00:53.057157  8058 solver.cpp:237]     Train net output #1: loss = 0.0115932 (* 1 = 0.0115932 loss)
I0618 02:00:53.057173  8058 sgd_solver.cpp:105] Iteration 31150, lr = 0.01
I0618 02:01:09.324980  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 02:01:50.867012  8058 solver.cpp:218] Iteration 31200 (0.864911 iter/s, 57.8094s/50 iters), loss = 0.0149572
I0618 02:01:50.867182  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 02:01:50.867213  8058 solver.cpp:237]     Train net output #1: loss = 0.0149572 (* 1 = 0.0149572 loss)
I0618 02:01:50.867230  8058 sgd_solver.cpp:105] Iteration 31200, lr = 0.01
I0618 02:02:48.687893  8058 solver.cpp:218] Iteration 31250 (0.864749 iter/s, 57.8203s/50 iters), loss = 0.0138289
I0618 02:02:48.688060  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 02:02:48.688107  8058 solver.cpp:237]     Train net output #1: loss = 0.0138289 (* 1 = 0.0138289 loss)
I0618 02:02:48.688124  8058 sgd_solver.cpp:105] Iteration 31250, lr = 0.01
I0618 02:03:28.074759  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 02:03:46.498777  8058 solver.cpp:218] Iteration 31300 (0.864898 iter/s, 57.8103s/50 iters), loss = 0.0136573
I0618 02:03:46.498899  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 02:03:46.498927  8058 solver.cpp:237]     Train net output #1: loss = 0.0136573 (* 1 = 0.0136573 loss)
I0618 02:03:46.498946  8058 sgd_solver.cpp:105] Iteration 31300, lr = 0.01
I0618 02:04:44.315559  8058 solver.cpp:218] Iteration 31350 (0.86481 iter/s, 57.8162s/50 iters), loss = 0.0122484
I0618 02:04:44.315724  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 02:04:44.315754  8058 solver.cpp:237]     Train net output #1: loss = 0.0122485 (* 1 = 0.0122485 loss)
I0618 02:04:44.315771  8058 sgd_solver.cpp:105] Iteration 31350, lr = 0.01
I0618 02:05:42.131157  8058 solver.cpp:218] Iteration 31400 (0.864828 iter/s, 57.815s/50 iters), loss = 0.0127672
I0618 02:05:42.131314  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 02:05:42.131342  8058 solver.cpp:237]     Train net output #1: loss = 0.0127672 (* 1 = 0.0127672 loss)
I0618 02:05:42.131361  8058 sgd_solver.cpp:105] Iteration 31400, lr = 0.01
I0618 02:05:46.831372  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 02:06:39.952836  8058 solver.cpp:218] Iteration 31450 (0.864737 iter/s, 57.8211s/50 iters), loss = 0.0129454
I0618 02:06:39.953004  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 02:06:39.953033  8058 solver.cpp:237]     Train net output #1: loss = 0.0129454 (* 1 = 0.0129454 loss)
I0618 02:06:39.953052  8058 sgd_solver.cpp:105] Iteration 31450, lr = 0.01
I0618 02:07:37.770432  8058 solver.cpp:218] Iteration 31500 (0.864798 iter/s, 57.817s/50 iters), loss = 0.0105778
I0618 02:07:37.770577  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 02:07:37.770606  8058 solver.cpp:237]     Train net output #1: loss = 0.0105778 (* 1 = 0.0105778 loss)
I0618 02:07:37.770623  8058 sgd_solver.cpp:105] Iteration 31500, lr = 0.01
I0618 02:08:05.592955  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 02:08:35.583461  8058 solver.cpp:218] Iteration 31550 (0.864866 iter/s, 57.8124s/50 iters), loss = 0.0120893
I0618 02:08:35.583621  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 02:08:35.583649  8058 solver.cpp:237]     Train net output #1: loss = 0.0120893 (* 1 = 0.0120893 loss)
I0618 02:08:35.583667  8058 sgd_solver.cpp:105] Iteration 31550, lr = 0.01
I0618 02:09:33.412777  8058 solver.cpp:218] Iteration 31600 (0.864623 iter/s, 57.8287s/50 iters), loss = 0.00911247
I0618 02:09:33.412981  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 02:09:33.413013  8058 solver.cpp:237]     Train net output #1: loss = 0.00911248 (* 1 = 0.00911248 loss)
I0618 02:09:33.413033  8058 sgd_solver.cpp:105] Iteration 31600, lr = 0.01
I0618 02:10:24.350051  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 02:10:31.236235  8058 solver.cpp:218] Iteration 31650 (0.864711 iter/s, 57.8228s/50 iters), loss = 0.0111014
I0618 02:10:31.236353  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 02:10:31.236382  8058 solver.cpp:237]     Train net output #1: loss = 0.0111014 (* 1 = 0.0111014 loss)
I0618 02:10:31.236399  8058 sgd_solver.cpp:105] Iteration 31650, lr = 0.01
I0618 02:11:29.070354  8058 solver.cpp:218] Iteration 31700 (0.86455 iter/s, 57.8335s/50 iters), loss = 0.01193
I0618 02:11:29.070502  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 02:11:29.070538  8058 solver.cpp:237]     Train net output #1: loss = 0.01193 (* 1 = 0.01193 loss)
I0618 02:11:29.070559  8058 sgd_solver.cpp:105] Iteration 31700, lr = 0.01
I0618 02:12:26.902462  8058 solver.cpp:218] Iteration 31750 (0.864581 iter/s, 57.8315s/50 iters), loss = 0.0124668
I0618 02:12:26.902648  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 02:12:26.902701  8058 solver.cpp:237]     Train net output #1: loss = 0.0124668 (* 1 = 0.0124668 loss)
I0618 02:12:26.902724  8058 sgd_solver.cpp:105] Iteration 31750, lr = 0.01
I0618 02:12:43.146767  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 02:13:24.732902  8058 solver.cpp:218] Iteration 31800 (0.864607 iter/s, 57.8297s/50 iters), loss = 0.0113126
I0618 02:13:24.733067  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 02:13:24.733095  8058 solver.cpp:237]     Train net output #1: loss = 0.0113127 (* 1 = 0.0113127 loss)
I0618 02:13:24.733114  8058 sgd_solver.cpp:105] Iteration 31800, lr = 0.01
I0618 02:14:22.562713  8058 solver.cpp:218] Iteration 31850 (0.864617 iter/s, 57.8291s/50 iters), loss = 0.0159272
I0618 02:14:22.562877  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 02:14:22.562906  8058 solver.cpp:237]     Train net output #1: loss = 0.0159272 (* 1 = 0.0159272 loss)
I0618 02:14:22.562923  8058 sgd_solver.cpp:105] Iteration 31850, lr = 0.01
I0618 02:15:01.955458  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 02:15:20.388247  8058 solver.cpp:218] Iteration 31900 (0.864681 iter/s, 57.8248s/50 iters), loss = 0.0136396
I0618 02:15:20.388351  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 02:15:20.388380  8058 solver.cpp:237]     Train net output #1: loss = 0.0136396 (* 1 = 0.0136396 loss)
I0618 02:15:20.388398  8058 sgd_solver.cpp:105] Iteration 31900, lr = 0.01
I0618 02:16:18.205435  8058 solver.cpp:218] Iteration 31950 (0.864805 iter/s, 57.8165s/50 iters), loss = 0.012132
I0618 02:16:18.205610  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 02:16:18.205641  8058 solver.cpp:237]     Train net output #1: loss = 0.012132 (* 1 = 0.012132 loss)
I0618 02:16:18.205657  8058 sgd_solver.cpp:105] Iteration 31950, lr = 0.01
I0618 02:17:16.032688  8058 solver.cpp:218] Iteration 32000 (0.864655 iter/s, 57.8265s/50 iters), loss = 0.014131
I0618 02:17:16.032858  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 02:17:16.032889  8058 solver.cpp:237]     Train net output #1: loss = 0.014131 (* 1 = 0.014131 loss)
I0618 02:17:16.032908  8058 sgd_solver.cpp:105] Iteration 32000, lr = 0.01
I0618 02:17:19.581035  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 02:18:13.858122  8058 solver.cpp:218] Iteration 32050 (0.864683 iter/s, 57.8247s/50 iters), loss = 0.00951898
I0618 02:18:13.858302  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 02:18:13.858333  8058 solver.cpp:237]     Train net output #1: loss = 0.00951899 (* 1 = 0.00951899 loss)
I0618 02:18:13.858355  8058 sgd_solver.cpp:105] Iteration 32050, lr = 0.01
I0618 02:19:11.648612  8058 solver.cpp:218] Iteration 32100 (0.865205 iter/s, 57.7898s/50 iters), loss = 0.0115585
I0618 02:19:11.648777  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 02:19:11.648808  8058 solver.cpp:237]     Train net output #1: loss = 0.0115585 (* 1 = 0.0115585 loss)
I0618 02:19:11.648828  8058 sgd_solver.cpp:105] Iteration 32100, lr = 0.01
I0618 02:19:38.292053  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 02:20:09.436713  8058 solver.cpp:218] Iteration 32150 (0.865241 iter/s, 57.7874s/50 iters), loss = 0.0155154
I0618 02:20:09.436852  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 02:20:09.436890  8058 solver.cpp:237]     Train net output #1: loss = 0.0155154 (* 1 = 0.0155154 loss)
I0618 02:20:09.436908  8058 sgd_solver.cpp:105] Iteration 32150, lr = 0.01
I0618 02:21:07.228169  8058 solver.cpp:218] Iteration 32200 (0.86519 iter/s, 57.7908s/50 iters), loss = 0.0140643
I0618 02:21:07.228291  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 02:21:07.228320  8058 solver.cpp:237]     Train net output #1: loss = 0.0140643 (* 1 = 0.0140643 loss)
I0618 02:21:07.228341  8058 sgd_solver.cpp:105] Iteration 32200, lr = 0.01
I0618 02:21:56.980139  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 02:22:04.992005  8058 solver.cpp:218] Iteration 32250 (0.865604 iter/s, 57.7631s/50 iters), loss = 0.0151172
I0618 02:22:04.992111  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 02:22:04.992139  8058 solver.cpp:237]     Train net output #1: loss = 0.0151172 (* 1 = 0.0151172 loss)
I0618 02:22:04.992156  8058 sgd_solver.cpp:105] Iteration 32250, lr = 0.01
I0618 02:23:02.764077  8058 solver.cpp:218] Iteration 32300 (0.86548 iter/s, 57.7714s/50 iters), loss = 0.0106146
I0618 02:23:02.764205  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 02:23:02.764233  8058 solver.cpp:237]     Train net output #1: loss = 0.0106146 (* 1 = 0.0106146 loss)
I0618 02:23:02.764251  8058 sgd_solver.cpp:105] Iteration 32300, lr = 0.01
I0618 02:24:00.558416  8058 solver.cpp:218] Iteration 32350 (0.865147 iter/s, 57.7937s/50 iters), loss = 0.0118838
I0618 02:24:00.558559  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 02:24:00.558588  8058 solver.cpp:237]     Train net output #1: loss = 0.0118838 (* 1 = 0.0118838 loss)
I0618 02:24:00.558605  8058 sgd_solver.cpp:105] Iteration 32350, lr = 0.01
I0618 02:24:15.651744  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 02:24:58.330898  8058 solver.cpp:218] Iteration 32400 (0.865474 iter/s, 57.7718s/50 iters), loss = 0.0137741
I0618 02:24:58.331017  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 02:24:58.331045  8058 solver.cpp:237]     Train net output #1: loss = 0.0137742 (* 1 = 0.0137742 loss)
I0618 02:24:58.331063  8058 sgd_solver.cpp:105] Iteration 32400, lr = 0.01
I0618 02:25:56.091238  8058 solver.cpp:218] Iteration 32450 (0.865656 iter/s, 57.7597s/50 iters), loss = 0.0128379
I0618 02:25:56.091357  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 02:25:56.091389  8058 solver.cpp:237]     Train net output #1: loss = 0.0128379 (* 1 = 0.0128379 loss)
I0618 02:25:56.091409  8058 sgd_solver.cpp:105] Iteration 32450, lr = 0.01
I0618 02:26:34.289614  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 02:26:53.867740  8058 solver.cpp:218] Iteration 32500 (0.865414 iter/s, 57.7758s/50 iters), loss = 0.0123504
I0618 02:26:53.867835  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 02:26:53.867862  8058 solver.cpp:237]     Train net output #1: loss = 0.0123504 (* 1 = 0.0123504 loss)
I0618 02:26:53.867880  8058 sgd_solver.cpp:105] Iteration 32500, lr = 0.01
I0618 02:27:51.641888  8058 solver.cpp:218] Iteration 32550 (0.865449 iter/s, 57.7735s/50 iters), loss = 0.0102129
I0618 02:27:51.642004  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 02:27:51.642033  8058 solver.cpp:237]     Train net output #1: loss = 0.0102129 (* 1 = 0.0102129 loss)
I0618 02:27:51.642050  8058 sgd_solver.cpp:105] Iteration 32550, lr = 0.01
I0618 02:28:49.405620  8058 solver.cpp:218] Iteration 32600 (0.865605 iter/s, 57.7631s/50 iters), loss = 0.0140303
I0618 02:28:49.405791  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 02:28:49.405820  8058 solver.cpp:237]     Train net output #1: loss = 0.0140303 (* 1 = 0.0140303 loss)
I0618 02:28:49.405838  8058 sgd_solver.cpp:105] Iteration 32600, lr = 0.01
I0618 02:28:52.933074  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 02:29:47.171851  8058 solver.cpp:218] Iteration 32650 (0.865568 iter/s, 57.7655s/50 iters), loss = 0.0117777
I0618 02:29:47.171988  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 02:29:47.172019  8058 solver.cpp:237]     Train net output #1: loss = 0.0117777 (* 1 = 0.0117777 loss)
I0618 02:29:47.172035  8058 sgd_solver.cpp:105] Iteration 32650, lr = 0.01
I0618 02:30:44.932399  8058 solver.cpp:218] Iteration 32700 (0.865653 iter/s, 57.7598s/50 iters), loss = 0.0142848
I0618 02:30:44.932536  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 02:30:44.932566  8058 solver.cpp:237]     Train net output #1: loss = 0.0142848 (* 1 = 0.0142848 loss)
I0618 02:30:44.932584  8058 sgd_solver.cpp:105] Iteration 32700, lr = 0.01
I0618 02:31:11.559378  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 02:31:42.696480  8058 solver.cpp:218] Iteration 32750 (0.8656 iter/s, 57.7634s/50 iters), loss = 0.0170082
I0618 02:31:42.696610  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 02:31:42.696640  8058 solver.cpp:237]     Train net output #1: loss = 0.0170082 (* 1 = 0.0170082 loss)
I0618 02:31:42.696655  8058 sgd_solver.cpp:105] Iteration 32750, lr = 0.01
I0618 02:32:40.456864  8058 solver.cpp:218] Iteration 32800 (0.865656 iter/s, 57.7597s/50 iters), loss = 0.0104993
I0618 02:32:40.456967  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 02:32:40.456995  8058 solver.cpp:237]     Train net output #1: loss = 0.0104993 (* 1 = 0.0104993 loss)
I0618 02:32:40.457013  8058 sgd_solver.cpp:105] Iteration 32800, lr = 0.01
I0618 02:33:30.193488  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 02:33:38.228857  8058 solver.cpp:218] Iteration 32850 (0.865481 iter/s, 57.7713s/50 iters), loss = 0.0105487
I0618 02:33:38.228935  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 02:33:38.228960  8058 solver.cpp:237]     Train net output #1: loss = 0.0105487 (* 1 = 0.0105487 loss)
I0618 02:33:38.228976  8058 sgd_solver.cpp:105] Iteration 32850, lr = 0.01
I0618 02:34:35.994750  8058 solver.cpp:218] Iteration 32900 (0.865572 iter/s, 57.7652s/50 iters), loss = 0.0113179
I0618 02:34:35.994866  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 02:34:35.994894  8058 solver.cpp:237]     Train net output #1: loss = 0.0113179 (* 1 = 0.0113179 loss)
I0618 02:34:35.994912  8058 sgd_solver.cpp:105] Iteration 32900, lr = 0.01
I0618 02:35:33.757079  8058 solver.cpp:218] Iteration 32950 (0.865626 iter/s, 57.7617s/50 iters), loss = 0.0150475
I0618 02:35:33.757194  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 02:35:33.757222  8058 solver.cpp:237]     Train net output #1: loss = 0.0150475 (* 1 = 0.0150475 loss)
I0618 02:35:33.757238  8058 sgd_solver.cpp:105] Iteration 32950, lr = 0.01
I0618 02:35:47.731808  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 02:36:31.537215  8058 solver.cpp:218] Iteration 33000 (0.86536 iter/s, 57.7794s/50 iters), loss = 0.0153265
I0618 02:36:31.537348  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 02:36:31.537377  8058 solver.cpp:237]     Train net output #1: loss = 0.0153266 (* 1 = 0.0153266 loss)
I0618 02:36:31.537395  8058 sgd_solver.cpp:105] Iteration 33000, lr = 0.01
I0618 02:37:29.317936  8058 solver.cpp:218] Iteration 33050 (0.865351 iter/s, 57.78s/50 iters), loss = 0.0163318
I0618 02:37:29.318053  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 02:37:29.318084  8058 solver.cpp:237]     Train net output #1: loss = 0.0163318 (* 1 = 0.0163318 loss)
I0618 02:37:29.318101  8058 sgd_solver.cpp:105] Iteration 33050, lr = 0.01
I0618 02:38:06.406297  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 02:38:27.096806  8058 solver.cpp:218] Iteration 33100 (0.865378 iter/s, 57.7782s/50 iters), loss = 0.0123996
I0618 02:38:27.096885  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 02:38:27.096912  8058 solver.cpp:237]     Train net output #1: loss = 0.0123996 (* 1 = 0.0123996 loss)
I0618 02:38:27.096930  8058 sgd_solver.cpp:105] Iteration 33100, lr = 0.01
I0618 02:39:24.873203  8058 solver.cpp:218] Iteration 33150 (0.865415 iter/s, 57.7757s/50 iters), loss = 0.0168997
I0618 02:39:24.873354  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 02:39:24.873383  8058 solver.cpp:237]     Train net output #1: loss = 0.0168997 (* 1 = 0.0168997 loss)
I0618 02:39:24.873399  8058 sgd_solver.cpp:105] Iteration 33150, lr = 0.01
I0618 02:40:22.640353  8058 solver.cpp:218] Iteration 33200 (0.865554 iter/s, 57.7664s/50 iters), loss = 0.0142624
I0618 02:40:22.640477  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 02:40:22.640506  8058 solver.cpp:237]     Train net output #1: loss = 0.0142624 (* 1 = 0.0142624 loss)
I0618 02:40:22.640530  8058 sgd_solver.cpp:105] Iteration 33200, lr = 0.01
I0618 02:40:25.027626  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 02:41:20.418402  8058 solver.cpp:218] Iteration 33250 (0.865391 iter/s, 57.7774s/50 iters), loss = 0.0139896
I0618 02:41:20.418529  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 02:41:20.418560  8058 solver.cpp:237]     Train net output #1: loss = 0.0139896 (* 1 = 0.0139896 loss)
I0618 02:41:20.418576  8058 sgd_solver.cpp:105] Iteration 33250, lr = 0.01
I0618 02:42:18.189107  8058 solver.cpp:218] Iteration 33300 (0.865501 iter/s, 57.77s/50 iters), loss = 0.0132504
I0618 02:42:18.189234  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 02:42:18.189261  8058 solver.cpp:237]     Train net output #1: loss = 0.0132504 (* 1 = 0.0132504 loss)
I0618 02:42:18.189280  8058 sgd_solver.cpp:105] Iteration 33300, lr = 0.01
I0618 02:42:43.717939  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 02:43:15.990105  8058 solver.cpp:218] Iteration 33350 (0.865048 iter/s, 57.8003s/50 iters), loss = 0.0125298
I0618 02:43:15.990332  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 02:43:15.990363  8058 solver.cpp:237]     Train net output #1: loss = 0.0125298 (* 1 = 0.0125298 loss)
I0618 02:43:15.990381  8058 sgd_solver.cpp:105] Iteration 33350, lr = 0.01
I0618 02:44:04.546162  8058 solver.cpp:447] Snapshotting to binary proto file mobilenet/mobile_cub_iter_33393.caffemodel
I0618 02:44:04.632083  8058 sgd_solver.cpp:273] Snapshotting solver state to binary proto file mobilenet/mobile_cub_iter_33393.solverstate
I0618 02:44:13.913019  8058 solver.cpp:218] Iteration 33400 (0.863228 iter/s, 57.9221s/50 iters), loss = 0.0130235
I0618 02:44:13.913134  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 02:44:13.913166  8058 solver.cpp:237]     Train net output #1: loss = 0.0130235 (* 1 = 0.0130235 loss)
I0618 02:44:13.913204  8058 sgd_solver.cpp:105] Iteration 33400, lr = 0.01
I0618 02:45:02.526661  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 02:45:11.703301  8058 solver.cpp:218] Iteration 33450 (0.865208 iter/s, 57.7896s/50 iters), loss = 0.0180629
I0618 02:45:11.703418  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 02:45:11.703444  8058 solver.cpp:237]     Train net output #1: loss = 0.0180629 (* 1 = 0.0180629 loss)
I0618 02:45:11.703464  8058 sgd_solver.cpp:105] Iteration 33450, lr = 0.01
I0618 02:46:09.508030  8058 solver.cpp:218] Iteration 33500 (0.864992 iter/s, 57.804s/50 iters), loss = 0.0171825
I0618 02:46:09.508211  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 02:46:09.508246  8058 solver.cpp:237]     Train net output #1: loss = 0.0171825 (* 1 = 0.0171825 loss)
I0618 02:46:09.508267  8058 sgd_solver.cpp:105] Iteration 33500, lr = 0.01
I0618 02:47:07.312820  8058 solver.cpp:218] Iteration 33550 (0.864991 iter/s, 57.8041s/50 iters), loss = 0.0166903
I0618 02:47:07.313015  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 02:47:07.313045  8058 solver.cpp:237]     Train net output #1: loss = 0.0166903 (* 1 = 0.0166903 loss)
I0618 02:47:07.313063  8058 sgd_solver.cpp:105] Iteration 33550, lr = 0.01
I0618 02:47:21.250574  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 02:48:05.129117  8058 solver.cpp:218] Iteration 33600 (0.864818 iter/s, 57.8156s/50 iters), loss = 0.012631
I0618 02:48:05.129269  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 02:48:05.129303  8058 solver.cpp:237]     Train net output #1: loss = 0.012631 (* 1 = 0.012631 loss)
I0618 02:48:05.129324  8058 sgd_solver.cpp:105] Iteration 33600, lr = 0.01
I0618 02:49:02.932742  8058 solver.cpp:218] Iteration 33650 (0.865006 iter/s, 57.803s/50 iters), loss = 0.013173
I0618 02:49:02.932891  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 02:49:02.932921  8058 solver.cpp:237]     Train net output #1: loss = 0.013173 (* 1 = 0.013173 loss)
I0618 02:49:02.932940  8058 sgd_solver.cpp:105] Iteration 33650, lr = 0.01
I0618 02:49:39.976450  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 02:50:00.717857  8058 solver.cpp:218] Iteration 33700 (0.865283 iter/s, 57.7845s/50 iters), loss = 0.0148583
I0618 02:50:00.717955  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 02:50:00.717983  8058 solver.cpp:237]     Train net output #1: loss = 0.0148583 (* 1 = 0.0148583 loss)
I0618 02:50:00.718001  8058 sgd_solver.cpp:105] Iteration 33700, lr = 0.01
I0618 02:50:58.503201  8058 solver.cpp:218] Iteration 33750 (0.865279 iter/s, 57.7848s/50 iters), loss = 0.0148625
I0618 02:50:58.503324  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 02:50:58.503352  8058 solver.cpp:237]     Train net output #1: loss = 0.0148625 (* 1 = 0.0148625 loss)
I0618 02:50:58.503371  8058 sgd_solver.cpp:105] Iteration 33750, lr = 0.01
I0618 02:51:56.291257  8058 solver.cpp:218] Iteration 33800 (0.865239 iter/s, 57.7875s/50 iters), loss = 0.0152448
I0618 02:51:56.291395  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 02:51:56.291429  8058 solver.cpp:237]     Train net output #1: loss = 0.0152448 (* 1 = 0.0152448 loss)
I0618 02:51:56.291450  8058 sgd_solver.cpp:105] Iteration 33800, lr = 0.01
I0618 02:51:58.680887  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 02:52:54.064755  8058 solver.cpp:218] Iteration 33850 (0.865457 iter/s, 57.7729s/50 iters), loss = 0.0145353
I0618 02:52:54.064888  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 02:52:54.064918  8058 solver.cpp:237]     Train net output #1: loss = 0.0145353 (* 1 = 0.0145353 loss)
I0618 02:52:54.064935  8058 sgd_solver.cpp:105] Iteration 33850, lr = 0.01
I0618 02:53:51.845000  8058 solver.cpp:218] Iteration 33900 (0.865356 iter/s, 57.7797s/50 iters), loss = 0.0118644
I0618 02:53:51.845126  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 02:53:51.845155  8058 solver.cpp:237]     Train net output #1: loss = 0.0118644 (* 1 = 0.0118644 loss)
I0618 02:53:51.845173  8058 sgd_solver.cpp:105] Iteration 33900, lr = 0.01
I0618 02:54:17.329434  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 02:54:49.620319  8058 solver.cpp:218] Iteration 33950 (0.86543 iter/s, 57.7748s/50 iters), loss = 0.0158994
I0618 02:54:49.620455  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 02:54:49.620484  8058 solver.cpp:237]     Train net output #1: loss = 0.0158994 (* 1 = 0.0158994 loss)
I0618 02:54:49.620502  8058 sgd_solver.cpp:105] Iteration 33950, lr = 0.01
I0618 02:55:47.405768  8058 solver.cpp:218] Iteration 34000 (0.865278 iter/s, 57.7849s/50 iters), loss = 0.015067
I0618 02:55:47.405906  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 02:55:47.405936  8058 solver.cpp:237]     Train net output #1: loss = 0.015067 (* 1 = 0.015067 loss)
I0618 02:55:47.405953  8058 sgd_solver.cpp:105] Iteration 34000, lr = 0.01
I0618 02:56:34.884604  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 02:56:45.179173  8058 solver.cpp:218] Iteration 34050 (0.865459 iter/s, 57.7728s/50 iters), loss = 0.0133568
I0618 02:56:45.179267  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 02:56:45.179294  8058 solver.cpp:237]     Train net output #1: loss = 0.0133569 (* 1 = 0.0133569 loss)
I0618 02:56:45.179312  8058 sgd_solver.cpp:105] Iteration 34050, lr = 0.01
I0618 02:57:42.950433  8058 solver.cpp:218] Iteration 34100 (0.86549 iter/s, 57.7707s/50 iters), loss = 0.0145789
I0618 02:57:42.950592  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 02:57:42.950621  8058 solver.cpp:237]     Train net output #1: loss = 0.0145789 (* 1 = 0.0145789 loss)
I0618 02:57:42.950640  8058 sgd_solver.cpp:105] Iteration 34100, lr = 0.01
I0618 02:58:40.725347  8058 solver.cpp:218] Iteration 34150 (0.865436 iter/s, 57.7743s/50 iters), loss = 0.0137202
I0618 02:58:40.725463  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 02:58:40.725492  8058 solver.cpp:237]     Train net output #1: loss = 0.0137202 (* 1 = 0.0137202 loss)
I0618 02:58:40.725510  8058 sgd_solver.cpp:105] Iteration 34150, lr = 0.01
I0618 02:58:53.539464  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 02:59:38.494288  8058 solver.cpp:218] Iteration 34200 (0.865525 iter/s, 57.7684s/50 iters), loss = 0.0178765
I0618 02:59:38.494398  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 02:59:38.494426  8058 solver.cpp:237]     Train net output #1: loss = 0.0178765 (* 1 = 0.0178765 loss)
I0618 02:59:38.494444  8058 sgd_solver.cpp:105] Iteration 34200, lr = 0.01
I0618 03:00:36.258163  8058 solver.cpp:218] Iteration 34250 (0.865601 iter/s, 57.7633s/50 iters), loss = 0.0114961
I0618 03:00:36.258289  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 03:00:36.258318  8058 solver.cpp:237]     Train net output #1: loss = 0.0114961 (* 1 = 0.0114961 loss)
I0618 03:00:36.258337  8058 sgd_solver.cpp:105] Iteration 34250, lr = 0.01
I0618 03:01:12.178629  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 03:01:34.030684  8058 solver.cpp:218] Iteration 34300 (0.865472 iter/s, 57.772s/50 iters), loss = 0.0196372
I0618 03:01:34.030777  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 03:01:34.030804  8058 solver.cpp:237]     Train net output #1: loss = 0.0196372 (* 1 = 0.0196372 loss)
I0618 03:01:34.030822  8058 sgd_solver.cpp:105] Iteration 34300, lr = 0.01
I0618 03:02:31.793859  8058 solver.cpp:218] Iteration 34350 (0.865611 iter/s, 57.7626s/50 iters), loss = 0.0135539
I0618 03:02:31.793982  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 03:02:31.794011  8058 solver.cpp:237]     Train net output #1: loss = 0.0135539 (* 1 = 0.0135539 loss)
I0618 03:02:31.794029  8058 sgd_solver.cpp:105] Iteration 34350, lr = 0.01
I0618 03:03:29.552290  8058 solver.cpp:218] Iteration 34400 (0.865683 iter/s, 57.7579s/50 iters), loss = 0.0148723
I0618 03:03:29.552402  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 03:03:29.552429  8058 solver.cpp:237]     Train net output #1: loss = 0.0148723 (* 1 = 0.0148723 loss)
I0618 03:03:29.552448  8058 sgd_solver.cpp:105] Iteration 34400, lr = 0.01
I0618 03:03:30.800611  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 03:04:27.320711  8058 solver.cpp:218] Iteration 34450 (0.865533 iter/s, 57.7679s/50 iters), loss = 0.0151846
I0618 03:04:27.320830  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 03:04:27.320858  8058 solver.cpp:237]     Train net output #1: loss = 0.0151846 (* 1 = 0.0151846 loss)
I0618 03:04:27.320878  8058 sgd_solver.cpp:105] Iteration 34450, lr = 0.01
I0618 03:05:25.082329  8058 solver.cpp:218] Iteration 34500 (0.865635 iter/s, 57.7611s/50 iters), loss = 0.016614
I0618 03:05:25.082445  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 03:05:25.082473  8058 solver.cpp:237]     Train net output #1: loss = 0.016614 (* 1 = 0.016614 loss)
I0618 03:05:25.082491  8058 sgd_solver.cpp:105] Iteration 34500, lr = 0.01
I0618 03:05:49.433677  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 03:06:22.845451  8058 solver.cpp:218] Iteration 34550 (0.865613 iter/s, 57.7626s/50 iters), loss = 0.0143346
I0618 03:06:22.845659  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 03:06:22.845690  8058 solver.cpp:237]     Train net output #1: loss = 0.0143346 (* 1 = 0.0143346 loss)
I0618 03:06:22.845708  8058 sgd_solver.cpp:105] Iteration 34550, lr = 0.01
I0618 03:07:20.612507  8058 solver.cpp:218] Iteration 34600 (0.865555 iter/s, 57.7664s/50 iters), loss = 0.0121526
I0618 03:07:20.612637  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 03:07:20.612669  8058 solver.cpp:237]     Train net output #1: loss = 0.0121526 (* 1 = 0.0121526 loss)
I0618 03:07:20.612689  8058 sgd_solver.cpp:105] Iteration 34600, lr = 0.01
I0618 03:08:08.067006  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 03:08:18.381444  8058 solver.cpp:218] Iteration 34650 (0.865526 iter/s, 57.7684s/50 iters), loss = 0.0176656
I0618 03:08:18.381530  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 03:08:18.381558  8058 solver.cpp:237]     Train net output #1: loss = 0.0176656 (* 1 = 0.0176656 loss)
I0618 03:08:18.381588  8058 sgd_solver.cpp:105] Iteration 34650, lr = 0.01
I0618 03:09:16.150305  8058 solver.cpp:218] Iteration 34700 (0.865526 iter/s, 57.7683s/50 iters), loss = 0.0125917
I0618 03:09:16.150421  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 03:09:16.150449  8058 solver.cpp:237]     Train net output #1: loss = 0.0125918 (* 1 = 0.0125918 loss)
I0618 03:09:16.150466  8058 sgd_solver.cpp:105] Iteration 34700, lr = 0.01
I0618 03:10:13.909737  8058 solver.cpp:218] Iteration 34750 (0.865668 iter/s, 57.7589s/50 iters), loss = 0.0136845
I0618 03:10:13.909901  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 03:10:13.909930  8058 solver.cpp:237]     Train net output #1: loss = 0.0136845 (* 1 = 0.0136845 loss)
I0618 03:10:13.909950  8058 sgd_solver.cpp:105] Iteration 34750, lr = 0.01
I0618 03:10:26.701325  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 03:11:11.675101  8058 solver.cpp:218] Iteration 34800 (0.86558 iter/s, 57.7648s/50 iters), loss = 0.0132839
I0618 03:11:11.675230  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 03:11:11.675262  8058 solver.cpp:237]     Train net output #1: loss = 0.013284 (* 1 = 0.013284 loss)
I0618 03:11:11.675282  8058 sgd_solver.cpp:105] Iteration 34800, lr = 0.01
I0618 03:12:09.453527  8058 solver.cpp:218] Iteration 34850 (0.865384 iter/s, 57.7778s/50 iters), loss = 0.0192892
I0618 03:12:09.453687  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 03:12:09.453722  8058 solver.cpp:237]     Train net output #1: loss = 0.0192892 (* 1 = 0.0192892 loss)
I0618 03:12:09.453740  8058 sgd_solver.cpp:105] Iteration 34850, lr = 0.01
I0618 03:12:45.336977  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 03:13:07.237844  8058 solver.cpp:218] Iteration 34900 (0.865296 iter/s, 57.7837s/50 iters), loss = 0.0139368
I0618 03:13:07.237929  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 03:13:07.237969  8058 solver.cpp:237]     Train net output #1: loss = 0.0139368 (* 1 = 0.0139368 loss)
I0618 03:13:07.237995  8058 sgd_solver.cpp:105] Iteration 34900, lr = 0.01
I0618 03:14:05.025669  8058 solver.cpp:218] Iteration 34950 (0.865242 iter/s, 57.7873s/50 iters), loss = 0.0119529
I0618 03:14:05.025784  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 03:14:05.025811  8058 solver.cpp:237]     Train net output #1: loss = 0.0119529 (* 1 = 0.0119529 loss)
I0618 03:14:05.025830  8058 sgd_solver.cpp:105] Iteration 34950, lr = 0.01
I0618 03:15:02.786660  8058 solver.cpp:218] Iteration 35000 (0.865645 iter/s, 57.7604s/50 iters), loss = 0.0157857
I0618 03:15:02.786792  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 03:15:02.786828  8058 solver.cpp:237]     Train net output #1: loss = 0.0157858 (* 1 = 0.0157858 loss)
I0618 03:15:02.786854  8058 sgd_solver.cpp:105] Iteration 35000, lr = 0.01
I0618 03:15:02.897873  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 03:16:00.545711  8058 solver.cpp:218] Iteration 35050 (0.865674 iter/s, 57.7585s/50 iters), loss = 0.0142455
I0618 03:16:00.545892  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 03:16:00.545922  8058 solver.cpp:237]     Train net output #1: loss = 0.0142455 (* 1 = 0.0142455 loss)
I0618 03:16:00.545940  8058 sgd_solver.cpp:105] Iteration 35050, lr = 0.01
I0618 03:16:58.310046  8058 solver.cpp:218] Iteration 35100 (0.865595 iter/s, 57.7637s/50 iters), loss = 0.0133987
I0618 03:16:58.310163  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 03:16:58.310194  8058 solver.cpp:237]     Train net output #1: loss = 0.0133987 (* 1 = 0.0133987 loss)
I0618 03:16:58.310210  8058 sgd_solver.cpp:105] Iteration 35100, lr = 0.01
I0618 03:17:21.514161  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 03:17:56.080368  8058 solver.cpp:218] Iteration 35150 (0.865505 iter/s, 57.7698s/50 iters), loss = 0.0142781
I0618 03:17:56.080492  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 03:17:56.080541  8058 solver.cpp:237]     Train net output #1: loss = 0.0142781 (* 1 = 0.0142781 loss)
I0618 03:17:56.080564  8058 sgd_solver.cpp:105] Iteration 35150, lr = 0.01
I0618 03:18:53.870975  8058 solver.cpp:218] Iteration 35200 (0.865201 iter/s, 57.79s/50 iters), loss = 0.0124216
I0618 03:18:53.871151  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 03:18:53.871181  8058 solver.cpp:237]     Train net output #1: loss = 0.0124217 (* 1 = 0.0124217 loss)
I0618 03:18:53.871199  8058 sgd_solver.cpp:105] Iteration 35200, lr = 0.01
I0618 03:19:40.185250  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 03:19:51.685287  8058 solver.cpp:218] Iteration 35250 (0.864847 iter/s, 57.8137s/50 iters), loss = 0.0130798
I0618 03:19:51.685406  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 03:19:51.685434  8058 solver.cpp:237]     Train net output #1: loss = 0.0130798 (* 1 = 0.0130798 loss)
I0618 03:19:51.685452  8058 sgd_solver.cpp:105] Iteration 35250, lr = 0.01
I0618 03:20:49.501487  8058 solver.cpp:218] Iteration 35300 (0.864818 iter/s, 57.8156s/50 iters), loss = 0.0182104
I0618 03:20:49.501648  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 03:20:49.501677  8058 solver.cpp:237]     Train net output #1: loss = 0.0182104 (* 1 = 0.0182104 loss)
I0618 03:20:49.501695  8058 sgd_solver.cpp:105] Iteration 35300, lr = 0.01
I0618 03:21:47.316936  8058 solver.cpp:218] Iteration 35350 (0.864831 iter/s, 57.8148s/50 iters), loss = 0.0155395
I0618 03:21:47.317112  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 03:21:47.317142  8058 solver.cpp:237]     Train net output #1: loss = 0.0155395 (* 1 = 0.0155395 loss)
I0618 03:21:47.317160  8058 sgd_solver.cpp:105] Iteration 35350, lr = 0.01
I0618 03:21:58.943032  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 03:22:45.126161  8058 solver.cpp:218] Iteration 35400 (0.864925 iter/s, 57.8085s/50 iters), loss = 0.0177025
I0618 03:22:45.126330  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 03:22:45.126360  8058 solver.cpp:237]     Train net output #1: loss = 0.0177025 (* 1 = 0.0177025 loss)
I0618 03:22:45.126379  8058 sgd_solver.cpp:105] Iteration 35400, lr = 0.01
I0618 03:23:42.939757  8058 solver.cpp:218] Iteration 35450 (0.864859 iter/s, 57.8129s/50 iters), loss = 0.0146078
I0618 03:23:42.939967  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 03:23:42.939997  8058 solver.cpp:237]     Train net output #1: loss = 0.0146078 (* 1 = 0.0146078 loss)
I0618 03:23:42.940016  8058 sgd_solver.cpp:105] Iteration 35450, lr = 0.01
I0618 03:24:17.696774  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 03:24:40.754895  8058 solver.cpp:218] Iteration 35500 (0.864837 iter/s, 57.8144s/50 iters), loss = 0.0149813
I0618 03:24:40.755015  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 03:24:40.755043  8058 solver.cpp:237]     Train net output #1: loss = 0.0149813 (* 1 = 0.0149813 loss)
I0618 03:24:40.755061  8058 sgd_solver.cpp:105] Iteration 35500, lr = 0.01
I0618 03:25:38.573673  8058 solver.cpp:218] Iteration 35550 (0.864781 iter/s, 57.8181s/50 iters), loss = 0.0118901
I0618 03:25:38.573887  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 03:25:38.573918  8058 solver.cpp:237]     Train net output #1: loss = 0.0118902 (* 1 = 0.0118902 loss)
I0618 03:25:38.573936  8058 sgd_solver.cpp:105] Iteration 35550, lr = 0.01
I0618 03:26:36.396972  8058 solver.cpp:218] Iteration 35600 (0.864715 iter/s, 57.8225s/50 iters), loss = 0.0156925
I0618 03:26:36.397166  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 03:26:36.397199  8058 solver.cpp:237]     Train net output #1: loss = 0.0156925 (* 1 = 0.0156925 loss)
I0618 03:26:36.397222  8058 sgd_solver.cpp:105] Iteration 35600, lr = 0.01
I0618 03:26:36.453284  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 03:27:34.211529  8058 solver.cpp:218] Iteration 35650 (0.864845 iter/s, 57.8138s/50 iters), loss = 0.0184336
I0618 03:27:34.211721  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 03:27:34.211750  8058 solver.cpp:237]     Train net output #1: loss = 0.0184336 (* 1 = 0.0184336 loss)
I0618 03:27:34.211768  8058 sgd_solver.cpp:105] Iteration 35650, lr = 0.01
I0618 03:28:32.035369  8058 solver.cpp:218] Iteration 35700 (0.864707 iter/s, 57.8231s/50 iters), loss = 0.0145997
I0618 03:28:32.035548  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 03:28:32.035580  8058 solver.cpp:237]     Train net output #1: loss = 0.0145997 (* 1 = 0.0145997 loss)
I0618 03:28:32.035598  8058 sgd_solver.cpp:105] Iteration 35700, lr = 0.01
I0618 03:28:55.223052  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 03:29:29.793253  8058 solver.cpp:218] Iteration 35750 (0.865693 iter/s, 57.7572s/50 iters), loss = 0.0134309
I0618 03:29:29.803578  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 03:29:29.803608  8058 solver.cpp:237]     Train net output #1: loss = 0.0134309 (* 1 = 0.0134309 loss)
I0618 03:29:29.803625  8058 sgd_solver.cpp:105] Iteration 35750, lr = 0.01
I0618 03:30:27.571182  8058 solver.cpp:218] Iteration 35800 (0.865545 iter/s, 57.7671s/50 iters), loss = 0.0130772
I0618 03:30:27.571318  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 03:30:27.571346  8058 solver.cpp:237]     Train net output #1: loss = 0.0130772 (* 1 = 0.0130772 loss)
I0618 03:30:27.571364  8058 sgd_solver.cpp:105] Iteration 35800, lr = 0.01
I0618 03:31:13.860708  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 03:31:25.335412  8058 solver.cpp:218] Iteration 35850 (0.865598 iter/s, 57.7636s/50 iters), loss = 0.0257252
I0618 03:31:25.335489  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 03:31:25.335520  8058 solver.cpp:237]     Train net output #1: loss = 0.0257252 (* 1 = 0.0257252 loss)
I0618 03:31:25.335541  8058 sgd_solver.cpp:105] Iteration 35850, lr = 0.01
I0618 03:32:23.099793  8058 solver.cpp:218] Iteration 35900 (0.865594 iter/s, 57.7638s/50 iters), loss = 0.015707
I0618 03:32:23.099916  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 03:32:23.099944  8058 solver.cpp:237]     Train net output #1: loss = 0.015707 (* 1 = 0.015707 loss)
I0618 03:32:23.099963  8058 sgd_solver.cpp:105] Iteration 35900, lr = 0.01
I0618 03:33:20.863975  8058 solver.cpp:218] Iteration 35950 (0.865598 iter/s, 57.7635s/50 iters), loss = 0.0109405
I0618 03:33:20.864089  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 03:33:20.864116  8058 solver.cpp:237]     Train net output #1: loss = 0.0109405 (* 1 = 0.0109405 loss)
I0618 03:33:20.864135  8058 sgd_solver.cpp:105] Iteration 35950, lr = 0.01
I0618 03:33:31.344280  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 03:34:18.625620  8058 solver.cpp:218] Iteration 36000 (0.865636 iter/s, 57.761s/50 iters), loss = 0.0151773
I0618 03:34:18.625797  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 03:34:18.625828  8058 solver.cpp:237]     Train net output #1: loss = 0.0151773 (* 1 = 0.0151773 loss)
I0618 03:34:18.625845  8058 sgd_solver.cpp:105] Iteration 36000, lr = 0.01
I0618 03:35:16.381536  8058 solver.cpp:218] Iteration 36050 (0.865723 iter/s, 57.7552s/50 iters), loss = 0.0153261
I0618 03:35:16.381667  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 03:35:16.381696  8058 solver.cpp:237]     Train net output #1: loss = 0.0153261 (* 1 = 0.0153261 loss)
I0618 03:35:16.381714  8058 sgd_solver.cpp:105] Iteration 36050, lr = 0.01
I0618 03:35:49.992070  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 03:36:14.141764  8058 solver.cpp:218] Iteration 36100 (0.865658 iter/s, 57.7596s/50 iters), loss = 0.0137465
I0618 03:36:14.141847  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 03:36:14.141875  8058 solver.cpp:237]     Train net output #1: loss = 0.0137465 (* 1 = 0.0137465 loss)
I0618 03:36:14.141892  8058 sgd_solver.cpp:105] Iteration 36100, lr = 0.01
I0618 03:37:11.908148  8058 solver.cpp:218] Iteration 36150 (0.865565 iter/s, 57.7658s/50 iters), loss = 0.0120959
I0618 03:37:11.908298  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 03:37:11.908326  8058 solver.cpp:237]     Train net output #1: loss = 0.0120959 (* 1 = 0.0120959 loss)
I0618 03:37:11.908344  8058 sgd_solver.cpp:105] Iteration 36150, lr = 0.01
I0618 03:38:08.593405  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 03:38:09.674636  8058 solver.cpp:218] Iteration 36200 (0.865564 iter/s, 57.7658s/50 iters), loss = 0.0127923
I0618 03:38:09.674715  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 03:38:09.674742  8058 solver.cpp:237]     Train net output #1: loss = 0.0127923 (* 1 = 0.0127923 loss)
I0618 03:38:09.674762  8058 sgd_solver.cpp:105] Iteration 36200, lr = 0.01
I0618 03:39:07.451750  8058 solver.cpp:218] Iteration 36250 (0.865404 iter/s, 57.7765s/50 iters), loss = 0.0142576
I0618 03:39:07.451870  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 03:39:07.451903  8058 solver.cpp:237]     Train net output #1: loss = 0.0142576 (* 1 = 0.0142576 loss)
I0618 03:39:07.451925  8058 sgd_solver.cpp:105] Iteration 36250, lr = 0.01
I0618 03:40:05.216112  8058 solver.cpp:218] Iteration 36300 (0.865595 iter/s, 57.7637s/50 iters), loss = 0.0183923
I0618 03:40:05.216239  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 03:40:05.216269  8058 solver.cpp:237]     Train net output #1: loss = 0.0183923 (* 1 = 0.0183923 loss)
I0618 03:40:05.216286  8058 sgd_solver.cpp:105] Iteration 36300, lr = 0.01
I0618 03:40:27.264148  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 03:41:02.985198  8058 solver.cpp:218] Iteration 36350 (0.865525 iter/s, 57.7684s/50 iters), loss = 0.0154295
I0618 03:41:02.985330  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 03:41:02.985359  8058 solver.cpp:237]     Train net output #1: loss = 0.0154295 (* 1 = 0.0154295 loss)
I0618 03:41:02.985378  8058 sgd_solver.cpp:105] Iteration 36350, lr = 0.01
I0618 03:42:00.744316  8058 solver.cpp:218] Iteration 36400 (0.865674 iter/s, 57.7585s/50 iters), loss = 0.0132448
I0618 03:42:00.745115  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 03:42:00.745144  8058 solver.cpp:237]     Train net output #1: loss = 0.0132448 (* 1 = 0.0132448 loss)
I0618 03:42:00.745162  8058 sgd_solver.cpp:105] Iteration 36400, lr = 0.01
I0618 03:42:45.898031  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 03:42:58.511884  8058 solver.cpp:218] Iteration 36450 (0.865558 iter/s, 57.7662s/50 iters), loss = 0.0143948
I0618 03:42:58.511966  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 03:42:58.511998  8058 solver.cpp:237]     Train net output #1: loss = 0.0143948 (* 1 = 0.0143948 loss)
I0618 03:42:58.512019  8058 sgd_solver.cpp:105] Iteration 36450, lr = 0.01
I0618 03:43:56.287704  8058 solver.cpp:218] Iteration 36500 (0.865423 iter/s, 57.7752s/50 iters), loss = 0.0129115
I0618 03:43:56.287848  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 03:43:56.287879  8058 solver.cpp:237]     Train net output #1: loss = 0.0129115 (* 1 = 0.0129115 loss)
I0618 03:43:56.287897  8058 sgd_solver.cpp:105] Iteration 36500, lr = 0.01
I0618 03:44:54.069126  8058 solver.cpp:218] Iteration 36550 (0.86534 iter/s, 57.7808s/50 iters), loss = 0.0133603
I0618 03:44:54.069252  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 03:44:54.069280  8058 solver.cpp:237]     Train net output #1: loss = 0.0133603 (* 1 = 0.0133603 loss)
I0618 03:44:54.069298  8058 sgd_solver.cpp:105] Iteration 36550, lr = 0.01
I0618 03:45:04.553144  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 03:45:51.833592  8058 solver.cpp:218] Iteration 36600 (0.865594 iter/s, 57.7638s/50 iters), loss = 0.0165169
I0618 03:45:51.833726  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 03:45:51.833756  8058 solver.cpp:237]     Train net output #1: loss = 0.0165169 (* 1 = 0.0165169 loss)
I0618 03:45:51.833775  8058 sgd_solver.cpp:105] Iteration 36600, lr = 0.01
I0618 03:46:49.593379  8058 solver.cpp:218] Iteration 36650 (0.865664 iter/s, 57.7591s/50 iters), loss = 0.0147665
I0618 03:46:49.593498  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 03:46:49.593536  8058 solver.cpp:237]     Train net output #1: loss = 0.0147665 (* 1 = 0.0147665 loss)
I0618 03:46:49.593556  8058 sgd_solver.cpp:105] Iteration 36650, lr = 0.01
I0618 03:47:23.179960  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 03:47:47.360508  8058 solver.cpp:218] Iteration 36700 (0.865554 iter/s, 57.7665s/50 iters), loss = 0.0144673
I0618 03:47:47.360599  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 03:47:47.360626  8058 solver.cpp:237]     Train net output #1: loss = 0.0144673 (* 1 = 0.0144673 loss)
I0618 03:47:47.360643  8058 sgd_solver.cpp:105] Iteration 36700, lr = 0.01
I0618 03:48:45.133045  8058 solver.cpp:218] Iteration 36750 (0.865473 iter/s, 57.7719s/50 iters), loss = 0.0123189
I0618 03:48:45.133206  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 03:48:45.133239  8058 solver.cpp:237]     Train net output #1: loss = 0.0123189 (* 1 = 0.0123189 loss)
I0618 03:48:45.133261  8058 sgd_solver.cpp:105] Iteration 36750, lr = 0.01
I0618 03:49:41.826028  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 03:49:42.940220  8058 solver.cpp:218] Iteration 36800 (0.864955 iter/s, 57.8065s/50 iters), loss = 0.0153689
I0618 03:49:42.940311  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 03:49:42.940337  8058 solver.cpp:237]     Train net output #1: loss = 0.0153689 (* 1 = 0.0153689 loss)
I0618 03:49:42.940356  8058 sgd_solver.cpp:105] Iteration 36800, lr = 0.01
I0618 03:50:40.754086  8058 solver.cpp:218] Iteration 36850 (0.864854 iter/s, 57.8132s/50 iters), loss = 0.0167189
I0618 03:50:40.754240  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 03:50:40.754269  8058 solver.cpp:237]     Train net output #1: loss = 0.0167189 (* 1 = 0.0167189 loss)
I0618 03:50:40.754288  8058 sgd_solver.cpp:105] Iteration 36850, lr = 0.01
I0618 03:51:38.550521  8058 solver.cpp:218] Iteration 36900 (0.865116 iter/s, 57.7957s/50 iters), loss = 0.0111507
I0618 03:51:38.550750  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 03:51:38.550778  8058 solver.cpp:237]     Train net output #1: loss = 0.0111507 (* 1 = 0.0111507 loss)
I0618 03:51:38.550796  8058 sgd_solver.cpp:105] Iteration 36900, lr = 0.01
I0618 03:52:00.560073  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 03:52:36.337082  8058 solver.cpp:218] Iteration 36950 (0.865265 iter/s, 57.7858s/50 iters), loss = 0.0140272
I0618 03:52:36.337255  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 03:52:36.337282  8058 solver.cpp:237]     Train net output #1: loss = 0.0140272 (* 1 = 0.0140272 loss)
I0618 03:52:36.337301  8058 sgd_solver.cpp:105] Iteration 36950, lr = 0.01
I0618 03:53:34.129568  8058 solver.cpp:218] Iteration 37000 (0.865175 iter/s, 57.7918s/50 iters), loss = 0.0143372
I0618 03:53:34.129820  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 03:53:34.129851  8058 solver.cpp:237]     Train net output #1: loss = 0.0143372 (* 1 = 0.0143372 loss)
I0618 03:53:34.129869  8058 sgd_solver.cpp:105] Iteration 37000, lr = 0.01
I0618 03:54:18.169325  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 03:54:31.929859  8058 solver.cpp:218] Iteration 37050 (0.865059 iter/s, 57.7995s/50 iters), loss = 0.0143182
I0618 03:54:31.929975  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 03:54:31.930003  8058 solver.cpp:237]     Train net output #1: loss = 0.0143183 (* 1 = 0.0143183 loss)
I0618 03:54:31.930023  8058 sgd_solver.cpp:105] Iteration 37050, lr = 0.01
I0618 03:55:29.730736  8058 solver.cpp:218] Iteration 37100 (0.865049 iter/s, 57.8002s/50 iters), loss = 0.0158278
I0618 03:55:29.730872  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 03:55:29.730901  8058 solver.cpp:237]     Train net output #1: loss = 0.0158278 (* 1 = 0.0158278 loss)
I0618 03:55:29.730933  8058 sgd_solver.cpp:105] Iteration 37100, lr = 0.01
I0618 03:56:27.531620  8058 solver.cpp:218] Iteration 37150 (0.86505 iter/s, 57.8001s/50 iters), loss = 0.0129953
I0618 03:56:27.531795  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 03:56:27.531824  8058 solver.cpp:237]     Train net output #1: loss = 0.0129953 (* 1 = 0.0129953 loss)
I0618 03:56:27.531842  8058 sgd_solver.cpp:105] Iteration 37150, lr = 0.01
I0618 03:56:36.858350  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 03:57:25.326978  8058 solver.cpp:218] Iteration 37200 (0.865133 iter/s, 57.7946s/50 iters), loss = 0.019035
I0618 03:57:25.327128  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 03:57:25.327158  8058 solver.cpp:237]     Train net output #1: loss = 0.019035 (* 1 = 0.019035 loss)
I0618 03:57:25.327177  8058 sgd_solver.cpp:105] Iteration 37200, lr = 0.01
I0618 03:58:23.125759  8058 solver.cpp:218] Iteration 37250 (0.865082 iter/s, 57.798s/50 iters), loss = 0.103444
I0618 03:58:23.125932  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 03:58:23.125962  8058 solver.cpp:237]     Train net output #1: loss = 0.103444 (* 1 = 0.103444 loss)
I0618 03:58:23.125979  8058 sgd_solver.cpp:105] Iteration 37250, lr = 0.01
I0618 03:58:55.554857  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 03:59:20.901274  8058 solver.cpp:218] Iteration 37300 (0.86543 iter/s, 57.7747s/50 iters), loss = 1.77972
I0618 03:59:20.901362  8058 solver.cpp:237]     Train net output #0: accuracy = 0.58
I0618 03:59:20.901391  8058 solver.cpp:237]     Train net output #1: loss = 1.77972 (* 1 = 1.77972 loss)
I0618 03:59:20.901409  8058 sgd_solver.cpp:105] Iteration 37300, lr = 0.01
I0618 04:00:18.666304  8058 solver.cpp:218] Iteration 37350 (0.865586 iter/s, 57.7643s/50 iters), loss = 2.26875
I0618 04:00:18.666446  8058 solver.cpp:237]     Train net output #0: accuracy = 0.44
I0618 04:00:18.666476  8058 solver.cpp:237]     Train net output #1: loss = 2.26875 (* 1 = 2.26875 loss)
I0618 04:00:18.666493  8058 sgd_solver.cpp:105] Iteration 37350, lr = 0.01
I0618 04:01:14.216480  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 04:01:16.431036  8058 solver.cpp:218] Iteration 37400 (0.865591 iter/s, 57.764s/50 iters), loss = 1.69258
I0618 04:01:16.431107  8058 solver.cpp:237]     Train net output #0: accuracy = 0.58
I0618 04:01:16.431135  8058 solver.cpp:237]     Train net output #1: loss = 1.69258 (* 1 = 1.69258 loss)
I0618 04:01:16.431152  8058 sgd_solver.cpp:105] Iteration 37400, lr = 0.01
I0618 04:02:14.198704  8058 solver.cpp:218] Iteration 37450 (0.865546 iter/s, 57.767s/50 iters), loss = 1.76262
I0618 04:02:14.198822  8058 solver.cpp:237]     Train net output #0: accuracy = 0.54
I0618 04:02:14.198851  8058 solver.cpp:237]     Train net output #1: loss = 1.76262 (* 1 = 1.76262 loss)
I0618 04:02:14.198868  8058 sgd_solver.cpp:105] Iteration 37450, lr = 0.01
I0618 04:03:11.979689  8058 solver.cpp:218] Iteration 37500 (0.865347 iter/s, 57.7803s/50 iters), loss = 1.36469
I0618 04:03:11.979882  8058 solver.cpp:237]     Train net output #0: accuracy = 0.62
I0618 04:03:11.979917  8058 solver.cpp:237]     Train net output #1: loss = 1.36469 (* 1 = 1.36469 loss)
I0618 04:03:11.979936  8058 sgd_solver.cpp:105] Iteration 37500, lr = 0.01
I0618 04:03:32.872298  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 04:04:09.751260  8058 solver.cpp:218] Iteration 37550 (0.865489 iter/s, 57.7708s/50 iters), loss = 0.977223
I0618 04:04:09.751389  8058 solver.cpp:237]     Train net output #0: accuracy = 0.78
I0618 04:04:09.751418  8058 solver.cpp:237]     Train net output #1: loss = 0.977223 (* 1 = 0.977223 loss)
I0618 04:04:09.751436  8058 sgd_solver.cpp:105] Iteration 37550, lr = 0.01
I0618 04:05:07.525797  8058 solver.cpp:218] Iteration 37600 (0.865444 iter/s, 57.7738s/50 iters), loss = 0.876319
I0618 04:05:07.525930  8058 solver.cpp:237]     Train net output #0: accuracy = 0.76
I0618 04:05:07.525960  8058 solver.cpp:237]     Train net output #1: loss = 0.876319 (* 1 = 0.876319 loss)
I0618 04:05:07.525990  8058 sgd_solver.cpp:105] Iteration 37600, lr = 0.01
I0618 04:05:51.516157  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 04:06:05.295116  8058 solver.cpp:218] Iteration 37650 (0.865522 iter/s, 57.7686s/50 iters), loss = 0.801939
I0618 04:06:05.295202  8058 solver.cpp:237]     Train net output #0: accuracy = 0.74
I0618 04:06:05.295229  8058 solver.cpp:237]     Train net output #1: loss = 0.801939 (* 1 = 0.801939 loss)
I0618 04:06:05.295248  8058 sgd_solver.cpp:105] Iteration 37650, lr = 0.01
I0618 04:07:03.055461  8058 solver.cpp:218] Iteration 37700 (0.865656 iter/s, 57.7597s/50 iters), loss = 0.932871
I0618 04:07:03.055589  8058 solver.cpp:237]     Train net output #0: accuracy = 0.76
I0618 04:07:03.055621  8058 solver.cpp:237]     Train net output #1: loss = 0.932871 (* 1 = 0.932871 loss)
I0618 04:07:03.055642  8058 sgd_solver.cpp:105] Iteration 37700, lr = 0.01
I0618 04:08:00.819489  8058 solver.cpp:218] Iteration 37750 (0.865601 iter/s, 57.7633s/50 iters), loss = 0.721649
I0618 04:08:00.819622  8058 solver.cpp:237]     Train net output #0: accuracy = 0.76
I0618 04:08:00.819651  8058 solver.cpp:237]     Train net output #1: loss = 0.721649 (* 1 = 0.721649 loss)
I0618 04:08:00.819669  8058 sgd_solver.cpp:105] Iteration 37750, lr = 0.01
I0618 04:08:10.117720  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 04:08:58.585785  8058 solver.cpp:218] Iteration 37800 (0.865567 iter/s, 57.7656s/50 iters), loss = 0.578537
I0618 04:08:58.585909  8058 solver.cpp:237]     Train net output #0: accuracy = 0.9
I0618 04:08:58.585938  8058 solver.cpp:237]     Train net output #1: loss = 0.578537 (* 1 = 0.578537 loss)
I0618 04:08:58.585957  8058 sgd_solver.cpp:105] Iteration 37800, lr = 0.01
I0618 04:09:56.360108  8058 solver.cpp:218] Iteration 37850 (0.865447 iter/s, 57.7736s/50 iters), loss = 0.699775
I0618 04:09:56.360237  8058 solver.cpp:237]     Train net output #0: accuracy = 0.84
I0618 04:09:56.360271  8058 solver.cpp:237]     Train net output #1: loss = 0.699775 (* 1 = 0.699775 loss)
I0618 04:09:56.360291  8058 sgd_solver.cpp:105] Iteration 37850, lr = 0.01
I0618 04:10:28.755481  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 04:10:54.120424  8058 solver.cpp:218] Iteration 37900 (0.865657 iter/s, 57.7596s/50 iters), loss = 0.407147
I0618 04:10:54.120507  8058 solver.cpp:237]     Train net output #0: accuracy = 0.92
I0618 04:10:54.120543  8058 solver.cpp:237]     Train net output #1: loss = 0.407147 (* 1 = 0.407147 loss)
I0618 04:10:54.120563  8058 sgd_solver.cpp:105] Iteration 37900, lr = 0.01
I0618 04:11:51.889874  8058 solver.cpp:218] Iteration 37950 (0.865519 iter/s, 57.7688s/50 iters), loss = 0.54981
I0618 04:11:51.890025  8058 solver.cpp:237]     Train net output #0: accuracy = 0.86
I0618 04:11:51.890059  8058 solver.cpp:237]     Train net output #1: loss = 0.54981 (* 1 = 0.54981 loss)
I0618 04:11:51.890080  8058 sgd_solver.cpp:105] Iteration 37950, lr = 0.01
I0618 04:12:46.287935  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 04:12:49.666494  8058 solver.cpp:218] Iteration 38000 (0.865413 iter/s, 57.7759s/50 iters), loss = 0.370225
I0618 04:12:49.666573  8058 solver.cpp:237]     Train net output #0: accuracy = 0.98
I0618 04:12:49.666599  8058 solver.cpp:237]     Train net output #1: loss = 0.370225 (* 1 = 0.370225 loss)
I0618 04:12:49.666615  8058 sgd_solver.cpp:105] Iteration 38000, lr = 0.01
I0618 04:13:47.431833  8058 solver.cpp:218] Iteration 38050 (0.865581 iter/s, 57.7647s/50 iters), loss = 0.364726
I0618 04:13:47.431964  8058 solver.cpp:237]     Train net output #0: accuracy = 0.92
I0618 04:13:47.431993  8058 solver.cpp:237]     Train net output #1: loss = 0.364726 (* 1 = 0.364726 loss)
I0618 04:13:47.432013  8058 sgd_solver.cpp:105] Iteration 38050, lr = 0.01
I0618 04:14:45.195042  8058 solver.cpp:218] Iteration 38100 (0.865613 iter/s, 57.7625s/50 iters), loss = 0.351361
I0618 04:14:45.195149  8058 solver.cpp:237]     Train net output #0: accuracy = 0.92
I0618 04:14:45.195189  8058 solver.cpp:237]     Train net output #1: loss = 0.351361 (* 1 = 0.351361 loss)
I0618 04:14:45.195209  8058 sgd_solver.cpp:105] Iteration 38100, lr = 0.01
I0618 04:15:04.947391  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 04:15:42.964280  8058 solver.cpp:218] Iteration 38150 (0.865523 iter/s, 57.7685s/50 iters), loss = 0.298567
I0618 04:15:42.964407  8058 solver.cpp:237]     Train net output #0: accuracy = 0.96
I0618 04:15:42.964442  8058 solver.cpp:237]     Train net output #1: loss = 0.298567 (* 1 = 0.298567 loss)
I0618 04:15:42.964463  8058 sgd_solver.cpp:105] Iteration 38150, lr = 0.01
I0618 04:16:40.722638  8058 solver.cpp:218] Iteration 38200 (0.865686 iter/s, 57.7577s/50 iters), loss = 0.370205
I0618 04:16:40.722755  8058 solver.cpp:237]     Train net output #0: accuracy = 0.94
I0618 04:16:40.722784  8058 solver.cpp:237]     Train net output #1: loss = 0.370205 (* 1 = 0.370205 loss)
I0618 04:16:40.722801  8058 sgd_solver.cpp:105] Iteration 38200, lr = 0.01
I0618 04:17:23.577106  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 04:17:38.499017  8058 solver.cpp:218] Iteration 38250 (0.865416 iter/s, 57.7757s/50 iters), loss = 0.259566
I0618 04:17:38.499100  8058 solver.cpp:237]     Train net output #0: accuracy = 0.98
I0618 04:17:38.499126  8058 solver.cpp:237]     Train net output #1: loss = 0.259566 (* 1 = 0.259566 loss)
I0618 04:17:38.499145  8058 sgd_solver.cpp:105] Iteration 38250, lr = 0.01
I0618 04:18:36.267761  8058 solver.cpp:218] Iteration 38300 (0.86553 iter/s, 57.7681s/50 iters), loss = 0.320163
I0618 04:18:36.267882  8058 solver.cpp:237]     Train net output #0: accuracy = 0.94
I0618 04:18:36.267910  8058 solver.cpp:237]     Train net output #1: loss = 0.320163 (* 1 = 0.320163 loss)
I0618 04:18:36.267928  8058 sgd_solver.cpp:105] Iteration 38300, lr = 0.01
I0618 04:19:34.085088  8058 solver.cpp:218] Iteration 38350 (0.864804 iter/s, 57.8166s/50 iters), loss = 0.171453
I0618 04:19:34.085265  8058 solver.cpp:237]     Train net output #0: accuracy = 0.98
I0618 04:19:34.085300  8058 solver.cpp:237]     Train net output #1: loss = 0.171453 (* 1 = 0.171453 loss)
I0618 04:19:34.085322  8058 sgd_solver.cpp:105] Iteration 38350, lr = 0.01
I0618 04:19:42.275215  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 04:20:31.899154  8058 solver.cpp:218] Iteration 38400 (0.864853 iter/s, 57.8133s/50 iters), loss = 0.196773
I0618 04:20:31.899312  8058 solver.cpp:237]     Train net output #0: accuracy = 0.98
I0618 04:20:31.899341  8058 solver.cpp:237]     Train net output #1: loss = 0.196773 (* 1 = 0.196773 loss)
I0618 04:20:31.899359  8058 sgd_solver.cpp:105] Iteration 38400, lr = 0.01
I0618 04:21:29.715692  8058 solver.cpp:218] Iteration 38450 (0.864816 iter/s, 57.8158s/50 iters), loss = 0.151339
I0618 04:21:29.715908  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 04:21:29.715939  8058 solver.cpp:237]     Train net output #1: loss = 0.151339 (* 1 = 0.151339 loss)
I0618 04:21:29.715957  8058 sgd_solver.cpp:105] Iteration 38450, lr = 0.01
I0618 04:22:01.006435  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 04:22:27.532101  8058 solver.cpp:218] Iteration 38500 (0.864818 iter/s, 57.8156s/50 iters), loss = 0.186611
I0618 04:22:27.532219  8058 solver.cpp:237]     Train net output #0: accuracy = 0.96
I0618 04:22:27.532248  8058 solver.cpp:237]     Train net output #1: loss = 0.186611 (* 1 = 0.186611 loss)
I0618 04:22:27.532266  8058 sgd_solver.cpp:105] Iteration 38500, lr = 0.01
I0618 04:23:25.346410  8058 solver.cpp:218] Iteration 38550 (0.864848 iter/s, 57.8136s/50 iters), loss = 0.1305
I0618 04:23:25.346575  8058 solver.cpp:237]     Train net output #0: accuracy = 0.98
I0618 04:23:25.346606  8058 solver.cpp:237]     Train net output #1: loss = 0.1305 (* 1 = 0.1305 loss)
I0618 04:23:25.346623  8058 sgd_solver.cpp:105] Iteration 38550, lr = 0.01
I0618 04:24:19.753409  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 04:24:23.168267  8058 solver.cpp:218] Iteration 38600 (0.864736 iter/s, 57.8211s/50 iters), loss = 0.0843515
I0618 04:24:23.168398  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 04:24:23.168426  8058 solver.cpp:237]     Train net output #1: loss = 0.0843516 (* 1 = 0.0843516 loss)
I0618 04:24:23.168443  8058 sgd_solver.cpp:105] Iteration 38600, lr = 0.01
I0618 04:25:20.981520  8058 solver.cpp:218] Iteration 38650 (0.864864 iter/s, 57.8125s/50 iters), loss = 0.0811807
I0618 04:25:20.981678  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 04:25:20.981706  8058 solver.cpp:237]     Train net output #1: loss = 0.0811807 (* 1 = 0.0811807 loss)
I0618 04:25:20.981725  8058 sgd_solver.cpp:105] Iteration 38650, lr = 0.01
I0618 04:26:18.795713  8058 solver.cpp:218] Iteration 38700 (0.86485 iter/s, 57.8135s/50 iters), loss = 0.0695251
I0618 04:26:18.795892  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 04:26:18.795922  8058 solver.cpp:237]     Train net output #1: loss = 0.0695251 (* 1 = 0.0695251 loss)
I0618 04:26:18.795941  8058 sgd_solver.cpp:105] Iteration 38700, lr = 0.01
I0618 04:26:38.514120  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 04:27:16.624702  8058 solver.cpp:218] Iteration 38750 (0.86463 iter/s, 57.8282s/50 iters), loss = 0.0551477
I0618 04:27:16.624868  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 04:27:16.624897  8058 solver.cpp:237]     Train net output #1: loss = 0.0551477 (* 1 = 0.0551477 loss)
I0618 04:27:16.624915  8058 sgd_solver.cpp:105] Iteration 38750, lr = 0.01
I0618 04:28:14.450002  8058 solver.cpp:218] Iteration 38800 (0.864685 iter/s, 57.8246s/50 iters), loss = 0.061551
I0618 04:28:14.450157  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 04:28:14.450186  8058 solver.cpp:237]     Train net output #1: loss = 0.061551 (* 1 = 0.061551 loss)
I0618 04:28:14.450206  8058 sgd_solver.cpp:105] Iteration 38800, lr = 0.01
I0618 04:28:57.297818  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 04:29:12.244132  8058 solver.cpp:218] Iteration 38850 (0.86515 iter/s, 57.7934s/50 iters), loss = 0.0900805
I0618 04:29:12.244217  8058 solver.cpp:237]     Train net output #0: accuracy = 0.98
I0618 04:29:12.244244  8058 solver.cpp:237]     Train net output #1: loss = 0.0900805 (* 1 = 0.0900805 loss)
I0618 04:29:12.244261  8058 sgd_solver.cpp:105] Iteration 38850, lr = 0.01
I0618 04:30:10.034054  8058 solver.cpp:218] Iteration 38900 (0.865212 iter/s, 57.7893s/50 iters), loss = 0.0788039
I0618 04:30:10.034183  8058 solver.cpp:237]     Train net output #0: accuracy = 0.98
I0618 04:30:10.034211  8058 solver.cpp:237]     Train net output #1: loss = 0.0788039 (* 1 = 0.0788039 loss)
I0618 04:30:10.034229  8058 sgd_solver.cpp:105] Iteration 38900, lr = 0.01
I0618 04:31:07.800024  8058 solver.cpp:218] Iteration 38950 (0.865572 iter/s, 57.7653s/50 iters), loss = 0.0418987
I0618 04:31:07.800230  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 04:31:07.800266  8058 solver.cpp:237]     Train net output #1: loss = 0.0418987 (* 1 = 0.0418987 loss)
I0618 04:31:07.800285  8058 sgd_solver.cpp:105] Iteration 38950, lr = 0.01
I0618 04:31:14.845067  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 04:32:05.573390  8058 solver.cpp:218] Iteration 39000 (0.865462 iter/s, 57.7726s/50 iters), loss = 0.0356861
I0618 04:32:05.573511  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 04:32:05.573549  8058 solver.cpp:237]     Train net output #1: loss = 0.0356861 (* 1 = 0.0356861 loss)
I0618 04:32:05.573566  8058 sgd_solver.cpp:105] Iteration 39000, lr = 0.01
I0618 04:33:03.345809  8058 solver.cpp:218] Iteration 39050 (0.865475 iter/s, 57.7718s/50 iters), loss = 0.0299469
I0618 04:33:03.345940  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 04:33:03.345974  8058 solver.cpp:237]     Train net output #1: loss = 0.0299469 (* 1 = 0.0299469 loss)
I0618 04:33:03.345994  8058 sgd_solver.cpp:105] Iteration 39050, lr = 0.01
I0618 04:33:33.496075  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 04:34:01.123028  8058 solver.cpp:218] Iteration 39100 (0.865403 iter/s, 57.7766s/50 iters), loss = 0.0413942
I0618 04:34:01.123102  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 04:34:01.123131  8058 solver.cpp:237]     Train net output #1: loss = 0.0413942 (* 1 = 0.0413942 loss)
I0618 04:34:01.123148  8058 sgd_solver.cpp:105] Iteration 39100, lr = 0.01
I0618 04:34:58.892213  8058 solver.cpp:218] Iteration 39150 (0.865522 iter/s, 57.7686s/50 iters), loss = 0.021838
I0618 04:34:58.901587  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 04:34:58.901614  8058 solver.cpp:237]     Train net output #1: loss = 0.021838 (* 1 = 0.021838 loss)
I0618 04:34:58.901633  8058 sgd_solver.cpp:105] Iteration 39150, lr = 0.01
I0618 04:35:52.146248  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 04:35:56.663038  8058 solver.cpp:218] Iteration 39200 (0.865637 iter/s, 57.7609s/50 iters), loss = 0.0178322
I0618 04:35:56.663115  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 04:35:56.663142  8058 solver.cpp:237]     Train net output #1: loss = 0.0178322 (* 1 = 0.0178322 loss)
I0618 04:35:56.663161  8058 sgd_solver.cpp:105] Iteration 39200, lr = 0.01
I0618 04:36:54.430510  8058 solver.cpp:218] Iteration 39250 (0.865548 iter/s, 57.7669s/50 iters), loss = 0.0179496
I0618 04:36:54.430631  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 04:36:54.430660  8058 solver.cpp:237]     Train net output #1: loss = 0.0179496 (* 1 = 0.0179496 loss)
I0618 04:36:54.430678  8058 sgd_solver.cpp:105] Iteration 39250, lr = 0.01
I0618 04:37:52.204488  8058 solver.cpp:218] Iteration 39300 (0.865451 iter/s, 57.7733s/50 iters), loss = 0.0170993
I0618 04:37:52.204615  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 04:37:52.204644  8058 solver.cpp:237]     Train net output #1: loss = 0.0170993 (* 1 = 0.0170993 loss)
I0618 04:37:52.204665  8058 sgd_solver.cpp:105] Iteration 39300, lr = 0.01
I0618 04:38:10.789921  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 04:38:49.988363  8058 solver.cpp:218] Iteration 39350 (0.865303 iter/s, 57.7832s/50 iters), loss = 0.0115154
I0618 04:38:49.988544  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 04:38:49.988575  8058 solver.cpp:237]     Train net output #1: loss = 0.0115153 (* 1 = 0.0115153 loss)
I0618 04:38:49.988593  8058 sgd_solver.cpp:105] Iteration 39350, lr = 0.01
I0618 04:39:47.817723  8058 solver.cpp:218] Iteration 39400 (0.864624 iter/s, 57.8286s/50 iters), loss = 0.0137883
I0618 04:39:47.817931  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 04:39:47.817960  8058 solver.cpp:237]     Train net output #1: loss = 0.0137883 (* 1 = 0.0137883 loss)
I0618 04:39:47.817980  8058 sgd_solver.cpp:105] Iteration 39400, lr = 0.01
I0618 04:40:29.540431  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 04:40:45.637440  8058 solver.cpp:218] Iteration 39450 (0.864768 iter/s, 57.819s/50 iters), loss = 0.0146703
I0618 04:40:45.637559  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 04:40:45.637588  8058 solver.cpp:237]     Train net output #1: loss = 0.0146703 (* 1 = 0.0146703 loss)
I0618 04:40:45.637606  8058 sgd_solver.cpp:105] Iteration 39450, lr = 0.01
I0618 04:41:43.468868  8058 solver.cpp:218] Iteration 39500 (0.864592 iter/s, 57.8308s/50 iters), loss = 0.0128388
I0618 04:41:43.469028  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 04:41:43.469058  8058 solver.cpp:237]     Train net output #1: loss = 0.0128388 (* 1 = 0.0128388 loss)
I0618 04:41:43.469076  8058 sgd_solver.cpp:105] Iteration 39500, lr = 0.01
I0618 04:42:41.302923  8058 solver.cpp:218] Iteration 39550 (0.864553 iter/s, 57.8333s/50 iters), loss = 0.0101704
I0618 04:42:41.303095  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 04:42:41.303124  8058 solver.cpp:237]     Train net output #1: loss = 0.0101704 (* 1 = 0.0101704 loss)
I0618 04:42:41.303143  8058 sgd_solver.cpp:105] Iteration 39550, lr = 0.01
I0618 04:42:48.289916  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 04:43:39.127120  8058 solver.cpp:218] Iteration 39600 (0.864701 iter/s, 57.8235s/50 iters), loss = 0.0221391
I0618 04:43:39.127274  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 04:43:39.127302  8058 solver.cpp:237]     Train net output #1: loss = 0.0221391 (* 1 = 0.0221391 loss)
I0618 04:43:39.127321  8058 sgd_solver.cpp:105] Iteration 39600, lr = 0.01
I0618 04:44:36.954399  8058 solver.cpp:218] Iteration 39650 (0.864654 iter/s, 57.8266s/50 iters), loss = 0.0105222
I0618 04:44:36.954581  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 04:44:36.954612  8058 solver.cpp:237]     Train net output #1: loss = 0.0105222 (* 1 = 0.0105222 loss)
I0618 04:44:36.954629  8058 sgd_solver.cpp:105] Iteration 39650, lr = 0.01
I0618 04:45:07.079226  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 04:45:34.777791  8058 solver.cpp:218] Iteration 39700 (0.864713 iter/s, 57.8227s/50 iters), loss = 0.00840009
I0618 04:45:34.777912  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 04:45:34.777945  8058 solver.cpp:237]     Train net output #1: loss = 0.00840007 (* 1 = 0.00840007 loss)
I0618 04:45:34.777966  8058 sgd_solver.cpp:105] Iteration 39700, lr = 0.01
I0618 04:46:32.587108  8058 solver.cpp:218] Iteration 39750 (0.864922 iter/s, 57.8087s/50 iters), loss = 0.0140071
I0618 04:46:32.587255  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 04:46:32.587285  8058 solver.cpp:237]     Train net output #1: loss = 0.0140071 (* 1 = 0.0140071 loss)
I0618 04:46:32.587307  8058 sgd_solver.cpp:105] Iteration 39750, lr = 0.01
I0618 04:47:25.842401  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 04:47:30.407949  8058 solver.cpp:218] Iteration 39800 (0.86475 iter/s, 57.8202s/50 iters), loss = 0.0146919
I0618 04:47:30.408048  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 04:47:30.408074  8058 solver.cpp:237]     Train net output #1: loss = 0.0146919 (* 1 = 0.0146919 loss)
I0618 04:47:30.408092  8058 sgd_solver.cpp:105] Iteration 39800, lr = 0.01
I0618 04:48:28.233943  8058 solver.cpp:218] Iteration 39850 (0.864673 iter/s, 57.8254s/50 iters), loss = 0.0111924
I0618 04:48:28.234114  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 04:48:28.234144  8058 solver.cpp:237]     Train net output #1: loss = 0.0111924 (* 1 = 0.0111924 loss)
I0618 04:48:28.234163  8058 sgd_solver.cpp:105] Iteration 39850, lr = 0.01
I0618 04:49:26.020442  8058 solver.cpp:218] Iteration 39900 (0.865265 iter/s, 57.7858s/50 iters), loss = 0.00786658
I0618 04:49:26.020592  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 04:49:26.020622  8058 solver.cpp:237]     Train net output #1: loss = 0.00786656 (* 1 = 0.00786656 loss)
I0618 04:49:26.020639  8058 sgd_solver.cpp:105] Iteration 39900, lr = 0.01
I0618 04:49:44.584017  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 04:50:23.786792  8058 solver.cpp:218] Iteration 39950 (0.865566 iter/s, 57.7657s/50 iters), loss = 0.0100565
I0618 04:50:23.786979  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 04:50:23.787014  8058 solver.cpp:237]     Train net output #1: loss = 0.0100565 (* 1 = 0.0100565 loss)
I0618 04:50:23.787035  8058 sgd_solver.cpp:105] Iteration 39950, lr = 0.01
I0618 04:51:20.401588  8058 solver.cpp:447] Snapshotting to binary proto file mobilenet/mobile_cub_iter_40000.caffemodel
I0618 04:51:20.485213  8058 sgd_solver.cpp:273] Snapshotting solver state to binary proto file mobilenet/mobile_cub_iter_40000.solverstate
I0618 04:51:21.667562  8058 solver.cpp:218] Iteration 40000 (0.863855 iter/s, 57.8801s/50 iters), loss = 0.00854755
I0618 04:51:21.667637  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 04:51:21.667661  8058 solver.cpp:237]     Train net output #1: loss = 0.00854754 (* 1 = 0.00854754 loss)
I0618 04:51:21.667677  8058 sgd_solver.cpp:105] Iteration 40000, lr = 0.01
I0618 04:52:02.216416  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 04:52:19.438841  8058 solver.cpp:218] Iteration 40050 (0.865491 iter/s, 57.7707s/50 iters), loss = 0.00862147
I0618 04:52:19.438920  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 04:52:19.438946  8058 solver.cpp:237]     Train net output #1: loss = 0.00862146 (* 1 = 0.00862146 loss)
I0618 04:52:19.438964  8058 sgd_solver.cpp:105] Iteration 40050, lr = 0.01
I0618 04:53:17.218281  8058 solver.cpp:218] Iteration 40100 (0.865369 iter/s, 57.7788s/50 iters), loss = 0.00581702
I0618 04:53:17.218401  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 04:53:17.218430  8058 solver.cpp:237]     Train net output #1: loss = 0.00581701 (* 1 = 0.00581701 loss)
I0618 04:53:17.218448  8058 sgd_solver.cpp:105] Iteration 40100, lr = 0.01
I0618 04:54:14.986299  8058 solver.cpp:218] Iteration 40150 (0.865541 iter/s, 57.7673s/50 iters), loss = 0.0100429
I0618 04:54:14.986435  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 04:54:14.986471  8058 solver.cpp:237]     Train net output #1: loss = 0.0100429 (* 1 = 0.0100429 loss)
I0618 04:54:14.986500  8058 sgd_solver.cpp:105] Iteration 40150, lr = 0.01
I0618 04:54:20.865113  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 04:55:12.767273  8058 solver.cpp:218] Iteration 40200 (0.865347 iter/s, 57.7803s/50 iters), loss = 0.00792867
I0618 04:55:12.767395  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 04:55:12.767424  8058 solver.cpp:237]     Train net output #1: loss = 0.00792865 (* 1 = 0.00792865 loss)
I0618 04:55:12.767442  8058 sgd_solver.cpp:105] Iteration 40200, lr = 0.01
I0618 04:56:10.536690  8058 solver.cpp:218] Iteration 40250 (0.86552 iter/s, 57.7688s/50 iters), loss = 0.00728269
I0618 04:56:10.536808  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 04:56:10.536837  8058 solver.cpp:237]     Train net output #1: loss = 0.00728268 (* 1 = 0.00728268 loss)
I0618 04:56:10.536855  8058 sgd_solver.cpp:105] Iteration 40250, lr = 0.01
I0618 04:56:39.497999  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 04:57:08.298308  8058 solver.cpp:218] Iteration 40300 (0.865636 iter/s, 57.761s/50 iters), loss = 0.00900492
I0618 04:57:08.298421  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 04:57:08.298450  8058 solver.cpp:237]     Train net output #1: loss = 0.00900491 (* 1 = 0.00900491 loss)
I0618 04:57:08.298468  8058 sgd_solver.cpp:105] Iteration 40300, lr = 0.01
I0618 04:58:06.059661  8058 solver.cpp:218] Iteration 40350 (0.86564 iter/s, 57.7607s/50 iters), loss = 0.00966436
I0618 04:58:06.059770  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 04:58:06.059798  8058 solver.cpp:237]     Train net output #1: loss = 0.00966435 (* 1 = 0.00966435 loss)
I0618 04:58:06.059816  8058 sgd_solver.cpp:105] Iteration 40350, lr = 0.01
I0618 04:58:58.137670  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 04:59:03.829399  8058 solver.cpp:218] Iteration 40400 (0.865515 iter/s, 57.7691s/50 iters), loss = 0.00714841
I0618 04:59:03.829490  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 04:59:03.829524  8058 solver.cpp:237]     Train net output #1: loss = 0.0071484 (* 1 = 0.0071484 loss)
I0618 04:59:03.829546  8058 sgd_solver.cpp:105] Iteration 40400, lr = 0.01
I0618 05:00:01.621230  8058 solver.cpp:218] Iteration 40450 (0.865184 iter/s, 57.7912s/50 iters), loss = 0.0104237
I0618 05:00:01.621386  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:00:01.621414  8058 solver.cpp:237]     Train net output #1: loss = 0.0104237 (* 1 = 0.0104237 loss)
I0618 05:00:01.621433  8058 sgd_solver.cpp:105] Iteration 40450, lr = 0.01
I0618 05:00:59.418107  8058 solver.cpp:218] Iteration 40500 (0.865109 iter/s, 57.7962s/50 iters), loss = 0.00818846
I0618 05:00:59.418226  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:00:59.418254  8058 solver.cpp:237]     Train net output #1: loss = 0.00818845 (* 1 = 0.00818845 loss)
I0618 05:00:59.418272  8058 sgd_solver.cpp:105] Iteration 40500, lr = 0.01
I0618 05:01:16.838830  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 05:01:57.185570  8058 solver.cpp:218] Iteration 40550 (0.865549 iter/s, 57.7668s/50 iters), loss = 0.00904711
I0618 05:01:57.185734  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:01:57.185762  8058 solver.cpp:237]     Train net output #1: loss = 0.0090471 (* 1 = 0.0090471 loss)
I0618 05:01:57.185780  8058 sgd_solver.cpp:105] Iteration 40550, lr = 0.01
I0618 05:02:54.962363  8058 solver.cpp:218] Iteration 40600 (0.86541 iter/s, 57.7761s/50 iters), loss = 0.0129143
I0618 05:02:54.962498  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:02:54.962533  8058 solver.cpp:237]     Train net output #1: loss = 0.0129142 (* 1 = 0.0129142 loss)
I0618 05:02:54.962553  8058 sgd_solver.cpp:105] Iteration 40600, lr = 0.01
I0618 05:03:35.487984  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 05:03:52.746238  8058 solver.cpp:218] Iteration 40650 (0.865303 iter/s, 57.7832s/50 iters), loss = 0.00832741
I0618 05:03:52.746325  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:03:52.746356  8058 solver.cpp:237]     Train net output #1: loss = 0.0083274 (* 1 = 0.0083274 loss)
I0618 05:03:52.746376  8058 sgd_solver.cpp:105] Iteration 40650, lr = 0.01
I0618 05:04:50.523002  8058 solver.cpp:218] Iteration 40700 (0.865409 iter/s, 57.7762s/50 iters), loss = 0.00773484
I0618 05:04:50.523118  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:04:50.523145  8058 solver.cpp:237]     Train net output #1: loss = 0.00773483 (* 1 = 0.00773483 loss)
I0618 05:04:50.523164  8058 sgd_solver.cpp:105] Iteration 40700, lr = 0.01
I0618 05:05:48.294824  8058 solver.cpp:218] Iteration 40750 (0.865483 iter/s, 57.7712s/50 iters), loss = 0.00875502
I0618 05:05:48.294957  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:05:48.294986  8058 solver.cpp:237]     Train net output #1: loss = 0.008755 (* 1 = 0.008755 loss)
I0618 05:05:48.295002  8058 sgd_solver.cpp:105] Iteration 40750, lr = 0.01
I0618 05:05:54.148908  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 05:06:46.072576  8058 solver.cpp:218] Iteration 40800 (0.865395 iter/s, 57.7771s/50 iters), loss = 0.00687492
I0618 05:06:46.072690  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:06:46.072717  8058 solver.cpp:237]     Train net output #1: loss = 0.00687491 (* 1 = 0.00687491 loss)
I0618 05:06:46.072734  8058 sgd_solver.cpp:105] Iteration 40800, lr = 0.01
I0618 05:07:43.849741  8058 solver.cpp:218] Iteration 40850 (0.865404 iter/s, 57.7765s/50 iters), loss = 0.0081285
I0618 05:07:43.849915  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:07:43.849948  8058 solver.cpp:237]     Train net output #1: loss = 0.00812849 (* 1 = 0.00812849 loss)
I0618 05:07:43.849969  8058 sgd_solver.cpp:105] Iteration 40850, lr = 0.01
I0618 05:08:12.767040  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 05:08:41.642480  8058 solver.cpp:218] Iteration 40900 (0.865171 iter/s, 57.7921s/50 iters), loss = 0.00653137
I0618 05:08:41.642633  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:08:41.642664  8058 solver.cpp:237]     Train net output #1: loss = 0.00653135 (* 1 = 0.00653135 loss)
I0618 05:08:41.642683  8058 sgd_solver.cpp:105] Iteration 40900, lr = 0.01
I0618 05:09:39.407027  8058 solver.cpp:218] Iteration 40950 (0.865593 iter/s, 57.7639s/50 iters), loss = 0.0117374
I0618 05:09:39.407152  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:09:39.407181  8058 solver.cpp:237]     Train net output #1: loss = 0.0117374 (* 1 = 0.0117374 loss)
I0618 05:09:39.407198  8058 sgd_solver.cpp:105] Iteration 40950, lr = 0.01
I0618 05:10:30.348422  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 05:10:37.171537  8058 solver.cpp:218] Iteration 41000 (0.865593 iter/s, 57.7639s/50 iters), loss = 0.00806538
I0618 05:10:37.171607  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:10:37.171633  8058 solver.cpp:237]     Train net output #1: loss = 0.00806537 (* 1 = 0.00806537 loss)
I0618 05:10:37.171663  8058 sgd_solver.cpp:105] Iteration 41000, lr = 0.01
I0618 05:11:34.933820  8058 solver.cpp:218] Iteration 41050 (0.865626 iter/s, 57.7617s/50 iters), loss = 0.00809724
I0618 05:11:34.933961  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:11:34.933990  8058 solver.cpp:237]     Train net output #1: loss = 0.00809723 (* 1 = 0.00809723 loss)
I0618 05:11:34.934007  8058 sgd_solver.cpp:105] Iteration 41050, lr = 0.01
I0618 05:12:32.690632  8058 solver.cpp:218] Iteration 41100 (0.865709 iter/s, 57.7562s/50 iters), loss = 0.00962403
I0618 05:12:32.690752  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:12:32.690779  8058 solver.cpp:237]     Train net output #1: loss = 0.00962402 (* 1 = 0.00962402 loss)
I0618 05:12:32.690798  8058 sgd_solver.cpp:105] Iteration 41100, lr = 0.01
I0618 05:12:48.959805  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 05:13:30.444236  8058 solver.cpp:218] Iteration 41150 (0.865756 iter/s, 57.753s/50 iters), loss = 0.00820231
I0618 05:13:30.444350  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:13:30.444378  8058 solver.cpp:237]     Train net output #1: loss = 0.0082023 (* 1 = 0.0082023 loss)
I0618 05:13:30.444396  8058 sgd_solver.cpp:105] Iteration 41150, lr = 0.01
I0618 05:14:28.200198  8058 solver.cpp:218] Iteration 41200 (0.865721 iter/s, 57.7553s/50 iters), loss = 0.0120972
I0618 05:14:28.200351  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:14:28.200381  8058 solver.cpp:237]     Train net output #1: loss = 0.0120972 (* 1 = 0.0120972 loss)
I0618 05:14:28.200398  8058 sgd_solver.cpp:105] Iteration 41200, lr = 0.01
I0618 05:15:07.572605  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 05:15:25.956980  8058 solver.cpp:218] Iteration 41250 (0.865709 iter/s, 57.7561s/50 iters), loss = 0.00860598
I0618 05:15:25.957060  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:15:25.957087  8058 solver.cpp:237]     Train net output #1: loss = 0.00860596 (* 1 = 0.00860596 loss)
I0618 05:15:25.957103  8058 sgd_solver.cpp:105] Iteration 41250, lr = 0.01
I0618 05:16:23.715333  8058 solver.cpp:218] Iteration 41300 (0.865685 iter/s, 57.7578s/50 iters), loss = 0.00841484
I0618 05:16:23.715466  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:16:23.715494  8058 solver.cpp:237]     Train net output #1: loss = 0.00841483 (* 1 = 0.00841483 loss)
I0618 05:16:23.715518  8058 sgd_solver.cpp:105] Iteration 41300, lr = 0.01
I0618 05:17:21.485954  8058 solver.cpp:218] Iteration 41350 (0.865502 iter/s, 57.77s/50 iters), loss = 0.00869074
I0618 05:17:21.486063  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:17:21.486090  8058 solver.cpp:237]     Train net output #1: loss = 0.00869073 (* 1 = 0.00869073 loss)
I0618 05:17:21.486107  8058 sgd_solver.cpp:105] Iteration 41350, lr = 0.01
I0618 05:17:26.201669  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 05:18:19.247784  8058 solver.cpp:218] Iteration 41400 (0.865633 iter/s, 57.7612s/50 iters), loss = 0.0123364
I0618 05:18:19.247928  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:18:19.247959  8058 solver.cpp:237]     Train net output #1: loss = 0.0123364 (* 1 = 0.0123364 loss)
I0618 05:18:19.247977  8058 sgd_solver.cpp:105] Iteration 41400, lr = 0.01
I0618 05:19:17.044646  8058 solver.cpp:218] Iteration 41450 (0.865109 iter/s, 57.7962s/50 iters), loss = 0.0100171
I0618 05:19:17.044795  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:19:17.044823  8058 solver.cpp:237]     Train net output #1: loss = 0.0100171 (* 1 = 0.0100171 loss)
I0618 05:19:17.044842  8058 sgd_solver.cpp:105] Iteration 41450, lr = 0.01
I0618 05:19:44.852285  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 05:20:14.877336  8058 solver.cpp:218] Iteration 41500 (0.864573 iter/s, 57.832s/50 iters), loss = 0.0118493
I0618 05:20:14.877529  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:20:14.877578  8058 solver.cpp:237]     Train net output #1: loss = 0.0118493 (* 1 = 0.0118493 loss)
I0618 05:20:14.877599  8058 sgd_solver.cpp:105] Iteration 41500, lr = 0.01
I0618 05:21:12.694993  8058 solver.cpp:218] Iteration 41550 (0.864798 iter/s, 57.817s/50 iters), loss = 0.0086572
I0618 05:21:12.695273  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:21:12.695302  8058 solver.cpp:237]     Train net output #1: loss = 0.00865719 (* 1 = 0.00865719 loss)
I0618 05:21:12.695320  8058 sgd_solver.cpp:105] Iteration 41550, lr = 0.01
I0618 05:22:03.637678  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 05:22:10.516911  8058 solver.cpp:218] Iteration 41600 (0.864736 iter/s, 57.8211s/50 iters), loss = 0.00858248
I0618 05:22:10.517007  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:22:10.517035  8058 solver.cpp:237]     Train net output #1: loss = 0.00858247 (* 1 = 0.00858247 loss)
I0618 05:22:10.517055  8058 sgd_solver.cpp:105] Iteration 41600, lr = 0.01
I0618 05:23:08.339381  8058 solver.cpp:218] Iteration 41650 (0.864725 iter/s, 57.8219s/50 iters), loss = 0.00644324
I0618 05:23:08.339556  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:23:08.339586  8058 solver.cpp:237]     Train net output #1: loss = 0.00644323 (* 1 = 0.00644323 loss)
I0618 05:23:08.339603  8058 sgd_solver.cpp:105] Iteration 41650, lr = 0.01
I0618 05:24:06.161556  8058 solver.cpp:218] Iteration 41700 (0.86473 iter/s, 57.8215s/50 iters), loss = 0.0099712
I0618 05:24:06.161725  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:24:06.161756  8058 solver.cpp:237]     Train net output #1: loss = 0.00997118 (* 1 = 0.00997118 loss)
I0618 05:24:06.161774  8058 sgd_solver.cpp:105] Iteration 41700, lr = 0.01
I0618 05:24:22.416980  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 05:25:03.998791  8058 solver.cpp:218] Iteration 41750 (0.864505 iter/s, 57.8366s/50 iters), loss = 0.00820632
I0618 05:25:03.998960  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:25:03.998988  8058 solver.cpp:237]     Train net output #1: loss = 0.0082063 (* 1 = 0.0082063 loss)
I0618 05:25:03.999006  8058 sgd_solver.cpp:105] Iteration 41750, lr = 0.01
I0618 05:26:01.832304  8058 solver.cpp:218] Iteration 41800 (0.864561 iter/s, 57.8328s/50 iters), loss = 0.0083454
I0618 05:26:01.832476  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:26:01.832507  8058 solver.cpp:237]     Train net output #1: loss = 0.00834539 (* 1 = 0.00834539 loss)
I0618 05:26:01.832533  8058 sgd_solver.cpp:105] Iteration 41800, lr = 0.01
I0618 05:26:41.202728  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 05:26:59.658123  8058 solver.cpp:218] Iteration 41850 (0.864676 iter/s, 57.8251s/50 iters), loss = 0.0101729
I0618 05:26:59.658236  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:26:59.658267  8058 solver.cpp:237]     Train net output #1: loss = 0.0101729 (* 1 = 0.0101729 loss)
I0618 05:26:59.658288  8058 sgd_solver.cpp:105] Iteration 41850, lr = 0.01
I0618 05:27:57.489711  8058 solver.cpp:218] Iteration 41900 (0.864589 iter/s, 57.831s/50 iters), loss = 0.00715323
I0618 05:27:57.489948  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:27:57.489977  8058 solver.cpp:237]     Train net output #1: loss = 0.00715322 (* 1 = 0.00715322 loss)
I0618 05:27:57.489996  8058 sgd_solver.cpp:105] Iteration 41900, lr = 0.01
I0618 05:28:55.298498  8058 solver.cpp:218] Iteration 41950 (0.864931 iter/s, 57.8081s/50 iters), loss = 0.0104533
I0618 05:28:55.298606  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:28:55.298635  8058 solver.cpp:237]     Train net output #1: loss = 0.0104533 (* 1 = 0.0104533 loss)
I0618 05:28:55.298651  8058 sgd_solver.cpp:105] Iteration 41950, lr = 0.01
I0618 05:28:58.876613  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 05:29:53.071434  8058 solver.cpp:218] Iteration 42000 (0.865466 iter/s, 57.7723s/50 iters), loss = 0.00852297
I0618 05:29:53.071585  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:29:53.071615  8058 solver.cpp:237]     Train net output #1: loss = 0.00852296 (* 1 = 0.00852296 loss)
I0618 05:29:53.071632  8058 sgd_solver.cpp:105] Iteration 42000, lr = 0.01
I0618 05:30:50.828173  8058 solver.cpp:218] Iteration 42050 (0.86571 iter/s, 57.7561s/50 iters), loss = 0.00888213
I0618 05:30:50.828287  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:30:50.828320  8058 solver.cpp:237]     Train net output #1: loss = 0.00888211 (* 1 = 0.00888211 loss)
I0618 05:30:50.828341  8058 sgd_solver.cpp:105] Iteration 42050, lr = 0.01
I0618 05:31:17.505167  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 05:31:48.595003  8058 solver.cpp:218] Iteration 42100 (0.865558 iter/s, 57.7662s/50 iters), loss = 0.0116833
I0618 05:31:48.595108  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:31:48.595137  8058 solver.cpp:237]     Train net output #1: loss = 0.0116833 (* 1 = 0.0116833 loss)
I0618 05:31:48.595155  8058 sgd_solver.cpp:105] Iteration 42100, lr = 0.01
I0618 05:32:46.375279  8058 solver.cpp:218] Iteration 42150 (0.865356 iter/s, 57.7797s/50 iters), loss = 0.0104855
I0618 05:32:46.375401  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:32:46.375428  8058 solver.cpp:237]     Train net output #1: loss = 0.0104855 (* 1 = 0.0104855 loss)
I0618 05:32:46.375447  8058 sgd_solver.cpp:105] Iteration 42150, lr = 0.01
I0618 05:33:36.150252  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 05:33:44.141175  8058 solver.cpp:218] Iteration 42200 (0.865572 iter/s, 57.7653s/50 iters), loss = 0.00864917
I0618 05:33:44.141252  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:33:44.141279  8058 solver.cpp:237]     Train net output #1: loss = 0.00864916 (* 1 = 0.00864916 loss)
I0618 05:33:44.141296  8058 sgd_solver.cpp:105] Iteration 42200, lr = 0.01
I0618 05:34:41.905503  8058 solver.cpp:218] Iteration 42250 (0.865595 iter/s, 57.7637s/50 iters), loss = 0.00831951
I0618 05:34:41.905642  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:34:41.905674  8058 solver.cpp:237]     Train net output #1: loss = 0.00831949 (* 1 = 0.00831949 loss)
I0618 05:34:41.905694  8058 sgd_solver.cpp:105] Iteration 42250, lr = 0.01
I0618 05:35:39.673882  8058 solver.cpp:218] Iteration 42300 (0.865535 iter/s, 57.7678s/50 iters), loss = 0.0104043
I0618 05:35:39.674005  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:35:39.674034  8058 solver.cpp:237]     Train net output #1: loss = 0.0104043 (* 1 = 0.0104043 loss)
I0618 05:35:39.674052  8058 sgd_solver.cpp:105] Iteration 42300, lr = 0.01
I0618 05:35:54.788734  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 05:36:37.438413  8058 solver.cpp:218] Iteration 42350 (0.865592 iter/s, 57.7639s/50 iters), loss = 0.010838
I0618 05:36:37.438575  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:36:37.438603  8058 solver.cpp:237]     Train net output #1: loss = 0.010838 (* 1 = 0.010838 loss)
I0618 05:36:37.438621  8058 sgd_solver.cpp:105] Iteration 42350, lr = 0.01
I0618 05:37:35.206796  8058 solver.cpp:218] Iteration 42400 (0.865535 iter/s, 57.7677s/50 iters), loss = 0.0115468
I0618 05:37:35.206940  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:37:35.206969  8058 solver.cpp:237]     Train net output #1: loss = 0.0115468 (* 1 = 0.0115468 loss)
I0618 05:37:35.206987  8058 sgd_solver.cpp:105] Iteration 42400, lr = 0.01
I0618 05:38:13.420974  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 05:38:32.972856  8058 solver.cpp:218] Iteration 42450 (0.86557 iter/s, 57.7654s/50 iters), loss = 0.0122031
I0618 05:38:32.972934  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:38:32.972960  8058 solver.cpp:237]     Train net output #1: loss = 0.0122031 (* 1 = 0.0122031 loss)
I0618 05:38:32.972976  8058 sgd_solver.cpp:105] Iteration 42450, lr = 0.01
I0618 05:39:30.788952  8058 solver.cpp:218] Iteration 42500 (0.86482 iter/s, 57.8155s/50 iters), loss = 0.0103507
I0618 05:39:30.789108  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:39:30.789135  8058 solver.cpp:237]     Train net output #1: loss = 0.0103507 (* 1 = 0.0103507 loss)
I0618 05:39:30.789153  8058 sgd_solver.cpp:105] Iteration 42500, lr = 0.01
I0618 05:40:28.615123  8058 solver.cpp:218] Iteration 42550 (0.86467 iter/s, 57.8255s/50 iters), loss = 0.0113123
I0618 05:40:28.615285  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:40:28.615314  8058 solver.cpp:237]     Train net output #1: loss = 0.0113123 (* 1 = 0.0113123 loss)
I0618 05:40:28.615331  8058 sgd_solver.cpp:105] Iteration 42550, lr = 0.01
I0618 05:40:32.152010  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 05:41:26.445840  8058 solver.cpp:218] Iteration 42600 (0.864602 iter/s, 57.8301s/50 iters), loss = 0.00861097
I0618 05:41:26.446069  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:41:26.446099  8058 solver.cpp:237]     Train net output #1: loss = 0.00861096 (* 1 = 0.00861096 loss)
I0618 05:41:26.446116  8058 sgd_solver.cpp:105] Iteration 42600, lr = 0.01
I0618 05:42:24.271765  8058 solver.cpp:218] Iteration 42650 (0.864675 iter/s, 57.8252s/50 iters), loss = 0.00912248
I0618 05:42:24.271914  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:42:24.271944  8058 solver.cpp:237]     Train net output #1: loss = 0.00912247 (* 1 = 0.00912247 loss)
I0618 05:42:24.271961  8058 sgd_solver.cpp:105] Iteration 42650, lr = 0.01
I0618 05:42:50.920459  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 05:43:22.100554  8058 solver.cpp:218] Iteration 42700 (0.864631 iter/s, 57.8281s/50 iters), loss = 0.0120451
I0618 05:43:22.100716  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:43:22.100745  8058 solver.cpp:237]     Train net output #1: loss = 0.0120451 (* 1 = 0.0120451 loss)
I0618 05:43:22.100764  8058 sgd_solver.cpp:105] Iteration 42700, lr = 0.01
I0618 05:44:19.928524  8058 solver.cpp:218] Iteration 42750 (0.864644 iter/s, 57.8273s/50 iters), loss = 0.00800383
I0618 05:44:19.928690  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:44:19.928719  8058 solver.cpp:237]     Train net output #1: loss = 0.00800382 (* 1 = 0.00800382 loss)
I0618 05:44:19.928737  8058 sgd_solver.cpp:105] Iteration 42750, lr = 0.01
I0618 05:45:09.714839  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 05:45:17.751197  8058 solver.cpp:218] Iteration 42800 (0.864723 iter/s, 57.822s/50 iters), loss = 0.0104896
I0618 05:45:17.751294  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:45:17.751322  8058 solver.cpp:237]     Train net output #1: loss = 0.0104895 (* 1 = 0.0104895 loss)
I0618 05:45:17.751343  8058 sgd_solver.cpp:105] Iteration 42800, lr = 0.01
I0618 05:46:15.575042  8058 solver.cpp:218] Iteration 42850 (0.864704 iter/s, 57.8232s/50 iters), loss = 0.0102107
I0618 05:46:15.575289  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:46:15.575318  8058 solver.cpp:237]     Train net output #1: loss = 0.0102107 (* 1 = 0.0102107 loss)
I0618 05:46:15.575336  8058 sgd_solver.cpp:105] Iteration 42850, lr = 0.01
I0618 05:47:13.404469  8058 solver.cpp:218] Iteration 42900 (0.864623 iter/s, 57.8287s/50 iters), loss = 0.0135796
I0618 05:47:13.404732  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:47:13.404762  8058 solver.cpp:237]     Train net output #1: loss = 0.0135796 (* 1 = 0.0135796 loss)
I0618 05:47:13.404780  8058 sgd_solver.cpp:105] Iteration 42900, lr = 0.01
I0618 05:47:28.480227  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 05:48:11.225695  8058 solver.cpp:218] Iteration 42950 (0.864746 iter/s, 57.8205s/50 iters), loss = 0.0133214
I0618 05:48:11.225854  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:48:11.225883  8058 solver.cpp:237]     Train net output #1: loss = 0.0133214 (* 1 = 0.0133214 loss)
I0618 05:48:11.225914  8058 sgd_solver.cpp:105] Iteration 42950, lr = 0.01
I0618 05:49:09.016312  8058 solver.cpp:218] Iteration 43000 (0.865202 iter/s, 57.79s/50 iters), loss = 0.00863582
I0618 05:49:09.016443  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:49:09.016470  8058 solver.cpp:237]     Train net output #1: loss = 0.00863581 (* 1 = 0.00863581 loss)
I0618 05:49:09.016491  8058 sgd_solver.cpp:105] Iteration 43000, lr = 0.01
I0618 05:49:46.071624  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 05:50:06.777070  8058 solver.cpp:218] Iteration 43050 (0.865649 iter/s, 57.7601s/50 iters), loss = 0.0105154
I0618 05:50:06.777146  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:50:06.777173  8058 solver.cpp:237]     Train net output #1: loss = 0.0105153 (* 1 = 0.0105153 loss)
I0618 05:50:06.777191  8058 sgd_solver.cpp:105] Iteration 43050, lr = 0.01
I0618 05:51:04.535969  8058 solver.cpp:218] Iteration 43100 (0.865676 iter/s, 57.7583s/50 iters), loss = 0.0121491
I0618 05:51:04.536093  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:51:04.536123  8058 solver.cpp:237]     Train net output #1: loss = 0.0121491 (* 1 = 0.0121491 loss)
I0618 05:51:04.536139  8058 sgd_solver.cpp:105] Iteration 43100, lr = 0.01
I0618 05:52:02.307153  8058 solver.cpp:218] Iteration 43150 (0.865493 iter/s, 57.7706s/50 iters), loss = 0.00889558
I0618 05:52:02.307266  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:52:02.307294  8058 solver.cpp:237]     Train net output #1: loss = 0.00889557 (* 1 = 0.00889557 loss)
I0618 05:52:02.307312  8058 sgd_solver.cpp:105] Iteration 43150, lr = 0.01
I0618 05:52:04.716058  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 05:53:00.063576  8058 solver.cpp:218] Iteration 43200 (0.865714 iter/s, 57.7558s/50 iters), loss = 0.0114551
I0618 05:53:00.063699  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:53:00.063731  8058 solver.cpp:237]     Train net output #1: loss = 0.0114551 (* 1 = 0.0114551 loss)
I0618 05:53:00.063751  8058 sgd_solver.cpp:105] Iteration 43200, lr = 0.01
I0618 05:53:57.843585  8058 solver.cpp:218] Iteration 43250 (0.86536 iter/s, 57.7794s/50 iters), loss = 0.0116571
I0618 05:53:57.843701  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:53:57.843730  8058 solver.cpp:237]     Train net output #1: loss = 0.0116571 (* 1 = 0.0116571 loss)
I0618 05:53:57.843749  8058 sgd_solver.cpp:105] Iteration 43250, lr = 0.01
I0618 05:54:23.347326  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 05:54:55.621328  8058 solver.cpp:218] Iteration 43300 (0.865394 iter/s, 57.7771s/50 iters), loss = 0.0117231
I0618 05:54:55.621444  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:54:55.621474  8058 solver.cpp:237]     Train net output #1: loss = 0.0117231 (* 1 = 0.0117231 loss)
I0618 05:54:55.621490  8058 sgd_solver.cpp:105] Iteration 43300, lr = 0.01
I0618 05:55:53.384532  8058 solver.cpp:218] Iteration 43350 (0.865615 iter/s, 57.7624s/50 iters), loss = 0.0131293
I0618 05:55:53.384678  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:55:53.384708  8058 solver.cpp:237]     Train net output #1: loss = 0.0131293 (* 1 = 0.0131293 loss)
I0618 05:55:53.384727  8058 sgd_solver.cpp:105] Iteration 43350, lr = 0.01
I0618 05:56:41.996809  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 05:56:51.147495  8058 solver.cpp:218] Iteration 43400 (0.865619 iter/s, 57.7621s/50 iters), loss = 0.0126836
I0618 05:56:51.147593  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:56:51.147627  8058 solver.cpp:237]     Train net output #1: loss = 0.0126835 (* 1 = 0.0126835 loss)
I0618 05:56:51.147649  8058 sgd_solver.cpp:105] Iteration 43400, lr = 0.01
I0618 05:57:48.908488  8058 solver.cpp:218] Iteration 43450 (0.865647 iter/s, 57.7603s/50 iters), loss = 0.0137794
I0618 05:57:48.908614  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:57:48.908643  8058 solver.cpp:237]     Train net output #1: loss = 0.0137793 (* 1 = 0.0137793 loss)
I0618 05:57:48.908671  8058 sgd_solver.cpp:105] Iteration 43450, lr = 0.01
I0618 05:58:46.668552  8058 solver.cpp:218] Iteration 43500 (0.865662 iter/s, 57.7593s/50 iters), loss = 0.0103342
I0618 05:58:46.668694  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:58:46.668722  8058 solver.cpp:237]     Train net output #1: loss = 0.0103342 (* 1 = 0.0103342 loss)
I0618 05:58:46.668740  8058 sgd_solver.cpp:105] Iteration 43500, lr = 0.01
I0618 05:59:00.617689  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 05:59:44.444610  8058 solver.cpp:218] Iteration 43550 (0.865422 iter/s, 57.7753s/50 iters), loss = 0.00802185
I0618 05:59:44.444751  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 05:59:44.444779  8058 solver.cpp:237]     Train net output #1: loss = 0.00802184 (* 1 = 0.00802184 loss)
I0618 05:59:44.444797  8058 sgd_solver.cpp:105] Iteration 43550, lr = 0.01
I0618 06:00:42.218129  8058 solver.cpp:218] Iteration 43600 (0.86546 iter/s, 57.7727s/50 iters), loss = 0.0108146
I0618 06:00:42.218264  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 06:00:42.218293  8058 solver.cpp:237]     Train net output #1: loss = 0.0108146 (* 1 = 0.0108146 loss)
I0618 06:00:42.218310  8058 sgd_solver.cpp:105] Iteration 43600, lr = 0.01
I0618 06:01:19.279253  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 06:01:39.988785  8058 solver.cpp:218] Iteration 43650 (0.865503 iter/s, 57.7699s/50 iters), loss = 0.00972277
I0618 06:01:39.988867  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 06:01:39.988893  8058 solver.cpp:237]     Train net output #1: loss = 0.00972276 (* 1 = 0.00972276 loss)
I0618 06:01:39.988910  8058 sgd_solver.cpp:105] Iteration 43650, lr = 0.01
I0618 06:02:37.758919  8058 solver.cpp:218] Iteration 43700 (0.86551 iter/s, 57.7694s/50 iters), loss = 0.0117398
I0618 06:02:37.759042  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 06:02:37.759070  8058 solver.cpp:237]     Train net output #1: loss = 0.0117398 (* 1 = 0.0117398 loss)
I0618 06:02:37.759088  8058 sgd_solver.cpp:105] Iteration 43700, lr = 0.01
I0618 06:03:35.528924  8058 solver.cpp:218] Iteration 43750 (0.865513 iter/s, 57.7692s/50 iters), loss = 0.0115238
I0618 06:03:35.529053  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 06:03:35.529081  8058 solver.cpp:237]     Train net output #1: loss = 0.0115238 (* 1 = 0.0115238 loss)
I0618 06:03:35.529098  8058 sgd_solver.cpp:105] Iteration 43750, lr = 0.01
I0618 06:03:37.892704  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 06:04:33.297972  8058 solver.cpp:218] Iteration 43800 (0.865527 iter/s, 57.7683s/50 iters), loss = 0.0127926
I0618 06:04:33.298094  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 06:04:33.298122  8058 solver.cpp:237]     Train net output #1: loss = 0.0127926 (* 1 = 0.0127926 loss)
I0618 06:04:33.298140  8058 sgd_solver.cpp:105] Iteration 43800, lr = 0.01
I0618 06:05:31.077708  8058 solver.cpp:218] Iteration 43850 (0.865367 iter/s, 57.779s/50 iters), loss = 0.00939842
I0618 06:05:31.077891  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 06:05:31.077922  8058 solver.cpp:237]     Train net output #1: loss = 0.00939841 (* 1 = 0.00939841 loss)
I0618 06:05:31.077939  8058 sgd_solver.cpp:105] Iteration 43850, lr = 0.01
I0618 06:05:56.550143  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 06:06:28.862435  8058 solver.cpp:218] Iteration 43900 (0.865293 iter/s, 57.7839s/50 iters), loss = 0.00816893
I0618 06:06:28.862607  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 06:06:28.862635  8058 solver.cpp:237]     Train net output #1: loss = 0.00816892 (* 1 = 0.00816892 loss)
I0618 06:06:28.862653  8058 sgd_solver.cpp:105] Iteration 43900, lr = 0.01
I0618 06:07:26.634897  8058 solver.cpp:218] Iteration 43950 (0.865477 iter/s, 57.7716s/50 iters), loss = 0.0147113
I0618 06:07:26.635051  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 06:07:26.635097  8058 solver.cpp:237]     Train net output #1: loss = 0.0147113 (* 1 = 0.0147113 loss)
I0618 06:07:26.635118  8058 sgd_solver.cpp:105] Iteration 43950, lr = 0.01
I0618 06:08:14.094238  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 06:08:24.400204  8058 solver.cpp:218] Iteration 44000 (0.865583 iter/s, 57.7645s/50 iters), loss = 0.0117828
I0618 06:08:24.400285  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 06:08:24.400311  8058 solver.cpp:237]     Train net output #1: loss = 0.0117828 (* 1 = 0.0117828 loss)
I0618 06:08:24.400329  8058 sgd_solver.cpp:105] Iteration 44000, lr = 0.01
I0618 06:09:22.188035  8058 solver.cpp:218] Iteration 44050 (0.865245 iter/s, 57.7871s/50 iters), loss = 0.0112906
I0618 06:09:22.188158  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 06:09:22.188186  8058 solver.cpp:237]     Train net output #1: loss = 0.0112906 (* 1 = 0.0112906 loss)
I0618 06:09:22.188205  8058 sgd_solver.cpp:105] Iteration 44050, lr = 0.01
I0618 06:10:19.972136  8058 solver.cpp:218] Iteration 44100 (0.865301 iter/s, 57.7833s/50 iters), loss = 0.00838066
I0618 06:10:19.972254  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 06:10:19.972283  8058 solver.cpp:237]     Train net output #1: loss = 0.00838065 (* 1 = 0.00838065 loss)
I0618 06:10:19.972301  8058 sgd_solver.cpp:105] Iteration 44100, lr = 0.01
I0618 06:10:32.767065  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 06:11:17.744284  8058 solver.cpp:218] Iteration 44150 (0.86548 iter/s, 57.7714s/50 iters), loss = 0.0144455
I0618 06:11:17.744416  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 06:11:17.744444  8058 solver.cpp:237]     Train net output #1: loss = 0.0144455 (* 1 = 0.0144455 loss)
I0618 06:11:17.744462  8058 sgd_solver.cpp:105] Iteration 44150, lr = 0.01
I0618 06:12:15.514875  8058 solver.cpp:218] Iteration 44200 (0.865504 iter/s, 57.7698s/50 iters), loss = 0.0140343
I0618 06:12:15.515018  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 06:12:15.515048  8058 solver.cpp:237]     Train net output #1: loss = 0.0140343 (* 1 = 0.0140343 loss)
I0618 06:12:15.515065  8058 sgd_solver.cpp:105] Iteration 44200, lr = 0.01
I0618 06:12:51.418799  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 06:13:13.287292  8058 solver.cpp:218] Iteration 44250 (0.865476 iter/s, 57.7717s/50 iters), loss = 0.0109773
I0618 06:13:13.287375  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 06:13:13.287402  8058 solver.cpp:237]     Train net output #1: loss = 0.0109773 (* 1 = 0.0109773 loss)
I0618 06:13:13.287420  8058 sgd_solver.cpp:105] Iteration 44250, lr = 0.01
I0618 06:14:11.062767  8058 solver.cpp:218] Iteration 44300 (0.86543 iter/s, 57.7748s/50 iters), loss = 0.0126781
I0618 06:14:11.062954  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 06:14:11.062988  8058 solver.cpp:237]     Train net output #1: loss = 0.0126781 (* 1 = 0.0126781 loss)
I0618 06:14:11.063009  8058 sgd_solver.cpp:105] Iteration 44300, lr = 0.01
I0618 06:15:08.845160  8058 solver.cpp:218] Iteration 44350 (0.865328 iter/s, 57.7816s/50 iters), loss = 0.0102453
I0618 06:15:08.845296  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 06:15:08.845325  8058 solver.cpp:237]     Train net output #1: loss = 0.0102453 (* 1 = 0.0102453 loss)
I0618 06:15:08.845342  8058 sgd_solver.cpp:105] Iteration 44350, lr = 0.01
I0618 06:15:10.076334  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 06:16:06.602464  8058 solver.cpp:218] Iteration 44400 (0.865703 iter/s, 57.7565s/50 iters), loss = 0.00978461
I0618 06:16:06.602601  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 06:16:06.602630  8058 solver.cpp:237]     Train net output #1: loss = 0.0097846 (* 1 = 0.0097846 loss)
I0618 06:16:06.602648  8058 sgd_solver.cpp:105] Iteration 44400, lr = 0.01
I0618 06:17:04.366576  8058 solver.cpp:218] Iteration 44450 (0.865601 iter/s, 57.7634s/50 iters), loss = 0.015121
I0618 06:17:04.366706  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 06:17:04.366734  8058 solver.cpp:237]     Train net output #1: loss = 0.015121 (* 1 = 0.015121 loss)
I0618 06:17:04.366750  8058 sgd_solver.cpp:105] Iteration 44450, lr = 0.01
I0618 06:17:28.698385  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 06:18:02.131712  8058 solver.cpp:218] Iteration 44500 (0.865585 iter/s, 57.7644s/50 iters), loss = 0.0130253
I0618 06:18:02.131842  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 06:18:02.131876  8058 solver.cpp:237]     Train net output #1: loss = 0.0130253 (* 1 = 0.0130253 loss)
I0618 06:18:02.131897  8058 sgd_solver.cpp:105] Iteration 44500, lr = 0.01
I0618 06:18:59.896347  8058 solver.cpp:218] Iteration 44550 (0.865593 iter/s, 57.7639s/50 iters), loss = 0.0113644
I0618 06:18:59.896469  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 06:18:59.896497  8058 solver.cpp:237]     Train net output #1: loss = 0.0113644 (* 1 = 0.0113644 loss)
I0618 06:18:59.896520  8058 sgd_solver.cpp:105] Iteration 44550, lr = 0.01
I0618 06:19:47.319485  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 06:19:57.660557  8058 solver.cpp:218] Iteration 44600 (0.865599 iter/s, 57.7635s/50 iters), loss = 0.0107717
I0618 06:19:57.660631  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 06:19:57.660657  8058 solver.cpp:237]     Train net output #1: loss = 0.0107717 (* 1 = 0.0107717 loss)
I0618 06:19:57.660676  8058 sgd_solver.cpp:105] Iteration 44600, lr = 0.01
I0618 06:20:55.414017  8058 solver.cpp:218] Iteration 44650 (0.865759 iter/s, 57.7528s/50 iters), loss = 0.011712
I0618 06:20:55.414131  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 06:20:55.414158  8058 solver.cpp:237]     Train net output #1: loss = 0.0117119 (* 1 = 0.0117119 loss)
I0618 06:20:55.414175  8058 sgd_solver.cpp:105] Iteration 44650, lr = 0.01
I0618 06:21:53.179970  8058 solver.cpp:218] Iteration 44700 (0.865573 iter/s, 57.7652s/50 iters), loss = 0.0101245
I0618 06:21:53.180088  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 06:21:53.180120  8058 solver.cpp:237]     Train net output #1: loss = 0.0101245 (* 1 = 0.0101245 loss)
I0618 06:21:53.180140  8058 sgd_solver.cpp:105] Iteration 44700, lr = 0.01
I0618 06:22:05.960501  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 06:22:50.943346  8058 solver.cpp:218] Iteration 44750 (0.865611 iter/s, 57.7627s/50 iters), loss = 0.0121823
I0618 06:22:50.943472  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 06:22:50.943500  8058 solver.cpp:237]     Train net output #1: loss = 0.0121823 (* 1 = 0.0121823 loss)
I0618 06:22:50.943524  8058 sgd_solver.cpp:105] Iteration 44750, lr = 0.01
I0618 06:23:48.696029  8058 solver.cpp:218] Iteration 44800 (0.865772 iter/s, 57.752s/50 iters), loss = 0.0126504
I0618 06:23:48.696192  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 06:23:48.696223  8058 solver.cpp:237]     Train net output #1: loss = 0.0126504 (* 1 = 0.0126504 loss)
I0618 06:23:48.696239  8058 sgd_solver.cpp:105] Iteration 44800, lr = 0.01
I0618 06:24:24.576882  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 06:24:46.454136  8058 solver.cpp:218] Iteration 44850 (0.865691 iter/s, 57.7573s/50 iters), loss = 0.0135501
I0618 06:24:46.454216  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 06:24:46.454242  8058 solver.cpp:237]     Train net output #1: loss = 0.0135501 (* 1 = 0.0135501 loss)
I0618 06:24:46.454259  8058 sgd_solver.cpp:105] Iteration 44850, lr = 0.01
I0618 06:25:44.217540  8058 solver.cpp:218] Iteration 44900 (0.86561 iter/s, 57.7627s/50 iters), loss = 0.0102694
I0618 06:25:44.217648  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 06:25:44.217676  8058 solver.cpp:237]     Train net output #1: loss = 0.0102694 (* 1 = 0.0102694 loss)
I0618 06:25:44.217694  8058 sgd_solver.cpp:105] Iteration 44900, lr = 0.01
I0618 06:26:41.973634  8058 solver.cpp:218] Iteration 44950 (0.86572 iter/s, 57.7554s/50 iters), loss = 0.0114262
I0618 06:26:41.973757  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 06:26:41.973784  8058 solver.cpp:237]     Train net output #1: loss = 0.0114262 (* 1 = 0.0114262 loss)
I0618 06:26:41.973801  8058 sgd_solver.cpp:105] Iteration 44950, lr = 0.01
I0618 06:26:42.064183  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 06:27:39.735064  8058 solver.cpp:218] Iteration 45000 (0.86564 iter/s, 57.7607s/50 iters), loss = 0.0118914
I0618 06:27:39.735177  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 06:27:39.735204  8058 solver.cpp:237]     Train net output #1: loss = 0.0118914 (* 1 = 0.0118914 loss)
I0618 06:27:39.735221  8058 sgd_solver.cpp:105] Iteration 45000, lr = 0.01
I0618 06:28:37.495152  8058 solver.cpp:218] Iteration 45050 (0.86566 iter/s, 57.7594s/50 iters), loss = 0.0124732
I0618 06:28:37.495265  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 06:28:37.495293  8058 solver.cpp:237]     Train net output #1: loss = 0.0124731 (* 1 = 0.0124731 loss)
I0618 06:28:37.495311  8058 sgd_solver.cpp:105] Iteration 45050, lr = 0.01
I0618 06:29:00.680833  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 06:29:35.260396  8058 solver.cpp:218] Iteration 45100 (0.865583 iter/s, 57.7645s/50 iters), loss = 0.0116204
I0618 06:29:35.260510  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 06:29:35.260546  8058 solver.cpp:237]     Train net output #1: loss = 0.0116204 (* 1 = 0.0116204 loss)
I0618 06:29:35.260565  8058 sgd_solver.cpp:105] Iteration 45100, lr = 0.01
I0618 06:30:33.019968  8058 solver.cpp:218] Iteration 45150 (0.865668 iter/s, 57.7589s/50 iters), loss = 0.00976699
I0618 06:30:33.020086  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 06:30:33.020112  8058 solver.cpp:237]     Train net output #1: loss = 0.00976698 (* 1 = 0.00976698 loss)
I0618 06:30:33.020130  8058 sgd_solver.cpp:105] Iteration 45150, lr = 0.01
I0618 06:31:19.319593  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 06:31:30.771929  8058 solver.cpp:218] Iteration 45200 (0.865782 iter/s, 57.7512s/50 iters), loss = 0.0107865
I0618 06:31:30.772004  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 06:31:30.772030  8058 solver.cpp:237]     Train net output #1: loss = 0.0107865 (* 1 = 0.0107865 loss)
I0618 06:31:30.772048  8058 sgd_solver.cpp:105] Iteration 45200, lr = 0.01
I0618 06:32:28.547871  8058 solver.cpp:218] Iteration 45250 (0.865422 iter/s, 57.7753s/50 iters), loss = 0.0116365
I0618 06:32:28.547986  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 06:32:28.548013  8058 solver.cpp:237]     Train net output #1: loss = 0.0116365 (* 1 = 0.0116365 loss)
I0618 06:32:28.548030  8058 sgd_solver.cpp:105] Iteration 45250, lr = 0.01
I0618 06:33:26.317770  8058 solver.cpp:218] Iteration 45300 (0.865513 iter/s, 57.7692s/50 iters), loss = 0.0120993
I0618 06:33:26.317924  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 06:33:26.317955  8058 solver.cpp:237]     Train net output #1: loss = 0.0120993 (* 1 = 0.0120993 loss)
I0618 06:33:26.317972  8058 sgd_solver.cpp:105] Iteration 45300, lr = 0.01
I0618 06:33:37.966903  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 06:34:24.095162  8058 solver.cpp:218] Iteration 45350 (0.865402 iter/s, 57.7766s/50 iters), loss = 0.0145879
I0618 06:34:24.095286  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 06:34:24.095314  8058 solver.cpp:237]     Train net output #1: loss = 0.0145879 (* 1 = 0.0145879 loss)
I0618 06:34:24.095331  8058 sgd_solver.cpp:105] Iteration 45350, lr = 0.01
I0618 06:35:21.853039  8058 solver.cpp:218] Iteration 45400 (0.865694 iter/s, 57.7571s/50 iters), loss = 0.011444
I0618 06:35:21.853160  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 06:35:21.853191  8058 solver.cpp:237]     Train net output #1: loss = 0.011444 (* 1 = 0.011444 loss)
I0618 06:35:21.853211  8058 sgd_solver.cpp:105] Iteration 45400, lr = 0.01
I0618 06:35:56.595638  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 06:36:19.610924  8058 solver.cpp:218] Iteration 45450 (0.865693 iter/s, 57.7572s/50 iters), loss = 0.0134685
I0618 06:36:19.610994  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 06:36:19.611021  8058 solver.cpp:237]     Train net output #1: loss = 0.0134685 (* 1 = 0.0134685 loss)
I0618 06:36:19.611037  8058 sgd_solver.cpp:105] Iteration 45450, lr = 0.01
I0618 06:37:17.365861  8058 solver.cpp:218] Iteration 45500 (0.865737 iter/s, 57.7543s/50 iters), loss = 0.0106088
I0618 06:37:17.365965  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 06:37:17.365993  8058 solver.cpp:237]     Train net output #1: loss = 0.0106088 (* 1 = 0.0106088 loss)
I0618 06:37:17.366010  8058 sgd_solver.cpp:105] Iteration 45500, lr = 0.01
I0618 06:38:15.123234  8058 solver.cpp:218] Iteration 45550 (0.865701 iter/s, 57.7567s/50 iters), loss = 0.0123445
I0618 06:38:15.123337  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 06:38:15.123364  8058 solver.cpp:237]     Train net output #1: loss = 0.0123445 (* 1 = 0.0123445 loss)
I0618 06:38:15.123383  8058 sgd_solver.cpp:105] Iteration 45550, lr = 0.01
I0618 06:38:15.189398  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 06:39:12.891669  8058 solver.cpp:218] Iteration 45600 (0.865535 iter/s, 57.7677s/50 iters), loss = 0.0129267
I0618 06:39:12.891806  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 06:39:12.891836  8058 solver.cpp:237]     Train net output #1: loss = 0.0129267 (* 1 = 0.0129267 loss)
I0618 06:39:12.891855  8058 sgd_solver.cpp:105] Iteration 45600, lr = 0.01
I0618 06:40:10.672971  8058 solver.cpp:218] Iteration 45650 (0.865343 iter/s, 57.7806s/50 iters), loss = 0.0150433
I0618 06:40:10.673092  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 06:40:10.673120  8058 solver.cpp:237]     Train net output #1: loss = 0.0150433 (* 1 = 0.0150433 loss)
I0618 06:40:10.673138  8058 sgd_solver.cpp:105] Iteration 45650, lr = 0.01
I0618 06:40:33.843717  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 06:41:08.442414  8058 solver.cpp:218] Iteration 45700 (0.86552 iter/s, 57.7687s/50 iters), loss = 0.0102014
I0618 06:41:08.442548  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 06:41:08.442577  8058 solver.cpp:237]     Train net output #1: loss = 0.0102014 (* 1 = 0.0102014 loss)
I0618 06:41:08.442596  8058 sgd_solver.cpp:105] Iteration 45700, lr = 0.01
I0618 06:42:06.219894  8058 solver.cpp:218] Iteration 45750 (0.8654 iter/s, 57.7767s/50 iters), loss = 0.0122848
I0618 06:42:06.220012  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 06:42:06.220041  8058 solver.cpp:237]     Train net output #1: loss = 0.0122848 (* 1 = 0.0122848 loss)
I0618 06:42:06.220057  8058 sgd_solver.cpp:105] Iteration 45750, lr = 0.01
I0618 06:42:52.517107  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 06:43:04.002156  8058 solver.cpp:218] Iteration 45800 (0.865328 iter/s, 57.7816s/50 iters), loss = 0.0163476
I0618 06:43:04.002234  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 06:43:04.002260  8058 solver.cpp:237]     Train net output #1: loss = 0.0163476 (* 1 = 0.0163476 loss)
I0618 06:43:04.002279  8058 sgd_solver.cpp:105] Iteration 45800, lr = 0.01
I0618 06:44:01.778226  8058 solver.cpp:218] Iteration 45850 (0.865421 iter/s, 57.7754s/50 iters), loss = 0.0124707
I0618 06:44:01.778372  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 06:44:01.778405  8058 solver.cpp:237]     Train net output #1: loss = 0.0124707 (* 1 = 0.0124707 loss)
I0618 06:44:01.778426  8058 sgd_solver.cpp:105] Iteration 45850, lr = 0.01
I0618 06:44:59.546402  8058 solver.cpp:218] Iteration 45900 (0.865539 iter/s, 57.7674s/50 iters), loss = 0.0126095
I0618 06:44:59.546535  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 06:44:59.546566  8058 solver.cpp:237]     Train net output #1: loss = 0.0126095 (* 1 = 0.0126095 loss)
I0618 06:44:59.546597  8058 sgd_solver.cpp:105] Iteration 45900, lr = 0.01
I0618 06:45:11.172133  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 06:45:57.310952  8058 solver.cpp:218] Iteration 45950 (0.865594 iter/s, 57.7638s/50 iters), loss = 0.0147894
I0618 06:45:57.311069  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 06:45:57.311096  8058 solver.cpp:237]     Train net output #1: loss = 0.0147894 (* 1 = 0.0147894 loss)
I0618 06:45:57.311115  8058 sgd_solver.cpp:105] Iteration 45950, lr = 0.01
I0618 06:46:55.102077  8058 solver.cpp:218] Iteration 46000 (0.865191 iter/s, 57.7907s/50 iters), loss = 0.0123628
I0618 06:46:55.102198  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 06:46:55.102226  8058 solver.cpp:237]     Train net output #1: loss = 0.0123628 (* 1 = 0.0123628 loss)
I0618 06:46:55.102244  8058 sgd_solver.cpp:105] Iteration 46000, lr = 0.01
I0618 06:47:28.693477  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 06:47:52.871809  8058 solver.cpp:218] Iteration 46050 (0.865511 iter/s, 57.7693s/50 iters), loss = 0.0110706
I0618 06:47:52.871896  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 06:47:52.871922  8058 solver.cpp:237]     Train net output #1: loss = 0.0110705 (* 1 = 0.0110705 loss)
I0618 06:47:52.871939  8058 sgd_solver.cpp:105] Iteration 46050, lr = 0.01
I0618 06:48:50.642174  8058 solver.cpp:218] Iteration 46100 (0.865501 iter/s, 57.77s/50 iters), loss = 0.0137964
I0618 06:48:50.642292  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 06:48:50.642320  8058 solver.cpp:237]     Train net output #1: loss = 0.0137964 (* 1 = 0.0137964 loss)
I0618 06:48:50.642338  8058 sgd_solver.cpp:105] Iteration 46100, lr = 0.01
I0618 06:49:47.325009  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 06:49:48.396061  8058 solver.cpp:218] Iteration 46150 (0.865748 iter/s, 57.7535s/50 iters), loss = 0.0124942
I0618 06:49:48.396131  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 06:49:48.396157  8058 solver.cpp:237]     Train net output #1: loss = 0.0124942 (* 1 = 0.0124942 loss)
I0618 06:49:48.396174  8058 sgd_solver.cpp:105] Iteration 46150, lr = 0.01
I0618 06:50:46.154654  8058 solver.cpp:218] Iteration 46200 (0.865677 iter/s, 57.7582s/50 iters), loss = 0.0121367
I0618 06:50:46.154755  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 06:50:46.154783  8058 solver.cpp:237]     Train net output #1: loss = 0.0121367 (* 1 = 0.0121367 loss)
I0618 06:50:46.154801  8058 sgd_solver.cpp:105] Iteration 46200, lr = 0.01
I0618 06:51:43.915457  8058 solver.cpp:218] Iteration 46250 (0.865645 iter/s, 57.7604s/50 iters), loss = 0.01219
I0618 06:51:43.915740  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 06:51:43.915767  8058 solver.cpp:237]     Train net output #1: loss = 0.01219 (* 1 = 0.01219 loss)
I0618 06:51:43.915784  8058 sgd_solver.cpp:105] Iteration 46250, lr = 0.01
I0618 06:52:05.947365  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 06:52:41.673633  8058 solver.cpp:218] Iteration 46300 (0.865687 iter/s, 57.7576s/50 iters), loss = 0.0109444
I0618 06:52:41.673789  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 06:52:41.673818  8058 solver.cpp:237]     Train net output #1: loss = 0.0109444 (* 1 = 0.0109444 loss)
I0618 06:52:41.673836  8058 sgd_solver.cpp:105] Iteration 46300, lr = 0.01
I0618 06:53:39.433774  8058 solver.cpp:218] Iteration 46350 (0.865655 iter/s, 57.7597s/50 iters), loss = 0.00998958
I0618 06:53:39.433902  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 06:53:39.433930  8058 solver.cpp:237]     Train net output #1: loss = 0.00998957 (* 1 = 0.00998957 loss)
I0618 06:53:39.433948  8058 sgd_solver.cpp:105] Iteration 46350, lr = 0.01
I0618 06:54:24.569875  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 06:54:37.183774  8058 solver.cpp:218] Iteration 46400 (0.865807 iter/s, 57.7496s/50 iters), loss = 0.0136801
I0618 06:54:37.183851  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 06:54:37.183892  8058 solver.cpp:237]     Train net output #1: loss = 0.0136801 (* 1 = 0.0136801 loss)
I0618 06:54:37.183909  8058 sgd_solver.cpp:105] Iteration 46400, lr = 0.01
I0618 06:55:34.941020  8058 solver.cpp:218] Iteration 46450 (0.865698 iter/s, 57.7569s/50 iters), loss = 0.0105624
I0618 06:55:34.941144  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 06:55:34.941171  8058 solver.cpp:237]     Train net output #1: loss = 0.0105624 (* 1 = 0.0105624 loss)
I0618 06:55:34.941190  8058 sgd_solver.cpp:105] Iteration 46450, lr = 0.01
I0618 06:56:32.699926  8058 solver.cpp:218] Iteration 46500 (0.865674 iter/s, 57.7585s/50 iters), loss = 0.0110508
I0618 06:56:32.700048  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 06:56:32.700078  8058 solver.cpp:237]     Train net output #1: loss = 0.0110508 (* 1 = 0.0110508 loss)
I0618 06:56:32.700095  8058 sgd_solver.cpp:105] Iteration 46500, lr = 0.01
I0618 06:56:43.159174  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 06:57:30.459559  8058 solver.cpp:218] Iteration 46550 (0.865663 iter/s, 57.7592s/50 iters), loss = 0.0117696
I0618 06:57:30.459683  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 06:57:30.459712  8058 solver.cpp:237]     Train net output #1: loss = 0.0117696 (* 1 = 0.0117696 loss)
I0618 06:57:30.459728  8058 sgd_solver.cpp:105] Iteration 46550, lr = 0.01
I0618 06:58:28.222292  8058 solver.cpp:218] Iteration 46600 (0.865616 iter/s, 57.7623s/50 iters), loss = 0.0143954
I0618 06:58:28.222417  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 06:58:28.222447  8058 solver.cpp:237]     Train net output #1: loss = 0.0143954 (* 1 = 0.0143954 loss)
I0618 06:58:28.222467  8058 sgd_solver.cpp:105] Iteration 46600, lr = 0.01
I0618 06:59:01.782438  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 06:59:26.010761  8058 solver.cpp:218] Iteration 46650 (0.865231 iter/s, 57.788s/50 iters), loss = 0.0103088
I0618 06:59:26.010845  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 06:59:26.010872  8058 solver.cpp:237]     Train net output #1: loss = 0.0103088 (* 1 = 0.0103088 loss)
I0618 06:59:26.010890  8058 sgd_solver.cpp:105] Iteration 46650, lr = 0.01
I0618 07:00:23.779954  8058 solver.cpp:218] Iteration 46700 (0.865519 iter/s, 57.7688s/50 iters), loss = 0.0124564
I0618 07:00:23.780071  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 07:00:23.780099  8058 solver.cpp:237]     Train net output #1: loss = 0.0124563 (* 1 = 0.0124563 loss)
I0618 07:00:23.780117  8058 sgd_solver.cpp:105] Iteration 46700, lr = 0.01
I0618 07:01:20.451366  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 07:01:21.553437  8058 solver.cpp:218] Iteration 46750 (0.865455 iter/s, 57.7731s/50 iters), loss = 0.0120123
I0618 07:01:21.553525  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 07:01:21.553555  8058 solver.cpp:237]     Train net output #1: loss = 0.0120123 (* 1 = 0.0120123 loss)
I0618 07:01:21.553571  8058 sgd_solver.cpp:105] Iteration 46750, lr = 0.01
I0618 07:02:19.330577  8058 solver.cpp:218] Iteration 46800 (0.8654 iter/s, 57.7767s/50 iters), loss = 0.0149441
I0618 07:02:19.330775  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 07:02:19.330809  8058 solver.cpp:237]     Train net output #1: loss = 0.0149441 (* 1 = 0.0149441 loss)
I0618 07:02:19.330831  8058 sgd_solver.cpp:105] Iteration 46800, lr = 0.01
I0618 07:03:17.101961  8058 solver.cpp:218] Iteration 46850 (0.865489 iter/s, 57.7708s/50 iters), loss = 0.0120765
I0618 07:03:17.102084  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 07:03:17.102113  8058 solver.cpp:237]     Train net output #1: loss = 0.0120765 (* 1 = 0.0120765 loss)
I0618 07:03:17.102130  8058 sgd_solver.cpp:105] Iteration 46850, lr = 0.01
I0618 07:03:39.105247  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 07:04:14.884155  8058 solver.cpp:218] Iteration 46900 (0.865328 iter/s, 57.7815s/50 iters), loss = 0.0141777
I0618 07:04:14.884291  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 07:04:14.884320  8058 solver.cpp:237]     Train net output #1: loss = 0.0141777 (* 1 = 0.0141777 loss)
I0618 07:04:14.884337  8058 sgd_solver.cpp:105] Iteration 46900, lr = 0.01
I0618 07:05:12.662704  8058 solver.cpp:218] Iteration 46950 (0.865383 iter/s, 57.7779s/50 iters), loss = 0.0108444
I0618 07:05:12.662822  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 07:05:12.662850  8058 solver.cpp:237]     Train net output #1: loss = 0.0108443 (* 1 = 0.0108443 loss)
I0618 07:05:12.662868  8058 sgd_solver.cpp:105] Iteration 46950, lr = 0.01
I0618 07:05:56.670675  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 07:06:10.428050  8058 solver.cpp:218] Iteration 47000 (0.865581 iter/s, 57.7647s/50 iters), loss = 0.0141982
I0618 07:06:10.428135  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 07:06:10.428167  8058 solver.cpp:237]     Train net output #1: loss = 0.0141982 (* 1 = 0.0141982 loss)
I0618 07:06:10.428189  8058 sgd_solver.cpp:105] Iteration 47000, lr = 0.01
I0618 07:07:08.196950  8058 solver.cpp:218] Iteration 47050 (0.865527 iter/s, 57.7683s/50 iters), loss = 0.0121053
I0618 07:07:08.197082  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 07:07:08.197110  8058 solver.cpp:237]     Train net output #1: loss = 0.0121053 (* 1 = 0.0121053 loss)
I0618 07:07:08.197129  8058 sgd_solver.cpp:105] Iteration 47050, lr = 0.01
I0618 07:08:05.974503  8058 solver.cpp:218] Iteration 47100 (0.865398 iter/s, 57.7769s/50 iters), loss = 0.012168
I0618 07:08:05.974627  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 07:08:05.974656  8058 solver.cpp:237]     Train net output #1: loss = 0.012168 (* 1 = 0.012168 loss)
I0618 07:08:05.974674  8058 sgd_solver.cpp:105] Iteration 47100, lr = 0.01
I0618 07:08:15.316946  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 07:09:03.742494  8058 solver.cpp:218] Iteration 47150 (0.865541 iter/s, 57.7673s/50 iters), loss = 0.0108205
I0618 07:09:03.742689  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 07:09:03.742718  8058 solver.cpp:237]     Train net output #1: loss = 0.0108205 (* 1 = 0.0108205 loss)
I0618 07:09:03.742736  8058 sgd_solver.cpp:105] Iteration 47150, lr = 0.01
I0618 07:10:01.511390  8058 solver.cpp:218] Iteration 47200 (0.865529 iter/s, 57.7682s/50 iters), loss = 0.0135523
I0618 07:10:01.511713  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 07:10:01.511744  8058 solver.cpp:237]     Train net output #1: loss = 0.0135523 (* 1 = 0.0135523 loss)
I0618 07:10:01.511760  8058 sgd_solver.cpp:105] Iteration 47200, lr = 0.01
I0618 07:10:33.920490  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 07:10:59.282579  8058 solver.cpp:218] Iteration 47250 (0.865496 iter/s, 57.7703s/50 iters), loss = 0.0128629
I0618 07:10:59.282661  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 07:10:59.282688  8058 solver.cpp:237]     Train net output #1: loss = 0.0128629 (* 1 = 0.0128629 loss)
I0618 07:10:59.282706  8058 sgd_solver.cpp:105] Iteration 47250, lr = 0.01
I0618 07:11:57.049917  8058 solver.cpp:218] Iteration 47300 (0.86555 iter/s, 57.7667s/50 iters), loss = 0.0149287
I0618 07:11:57.050076  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 07:11:57.050107  8058 solver.cpp:237]     Train net output #1: loss = 0.0149287 (* 1 = 0.0149287 loss)
I0618 07:11:57.050123  8058 sgd_solver.cpp:105] Iteration 47300, lr = 0.01
I0618 07:12:52.594723  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 07:12:54.812685  8058 solver.cpp:218] Iteration 47350 (0.86562 iter/s, 57.7621s/50 iters), loss = 0.0127712
I0618 07:12:54.812757  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 07:12:54.812783  8058 solver.cpp:237]     Train net output #1: loss = 0.0127711 (* 1 = 0.0127711 loss)
I0618 07:12:54.812799  8058 sgd_solver.cpp:105] Iteration 47350, lr = 0.01
I0618 07:13:52.567631  8058 solver.cpp:218] Iteration 47400 (0.865736 iter/s, 57.7543s/50 iters), loss = 0.0171387
I0618 07:13:52.572580  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 07:13:52.572612  8058 solver.cpp:237]     Train net output #1: loss = 0.0171387 (* 1 = 0.0171387 loss)
I0618 07:13:52.572628  8058 sgd_solver.cpp:105] Iteration 47400, lr = 0.01
I0618 07:14:50.337898  8058 solver.cpp:218] Iteration 47450 (0.865579 iter/s, 57.7648s/50 iters), loss = 0.0156896
I0618 07:14:50.338011  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 07:14:50.338040  8058 solver.cpp:237]     Train net output #1: loss = 0.0156896 (* 1 = 0.0156896 loss)
I0618 07:14:50.338062  8058 sgd_solver.cpp:105] Iteration 47450, lr = 0.01
I0618 07:15:11.224339  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 07:15:48.100097  8058 solver.cpp:218] Iteration 47500 (0.865628 iter/s, 57.7616s/50 iters), loss = 0.235292
I0618 07:15:48.100230  8058 solver.cpp:237]     Train net output #0: accuracy = 0.96
I0618 07:15:48.100260  8058 solver.cpp:237]     Train net output #1: loss = 0.235292 (* 1 = 0.235292 loss)
I0618 07:15:48.100277  8058 sgd_solver.cpp:105] Iteration 47500, lr = 0.01
I0618 07:16:45.859035  8058 solver.cpp:218] Iteration 47550 (0.865677 iter/s, 57.7583s/50 iters), loss = 1.71403
I0618 07:16:45.859233  8058 solver.cpp:237]     Train net output #0: accuracy = 0.54
I0618 07:16:45.859267  8058 solver.cpp:237]     Train net output #1: loss = 1.71403 (* 1 = 1.71403 loss)
I0618 07:16:45.859287  8058 sgd_solver.cpp:105] Iteration 47550, lr = 0.01
I0618 07:17:29.841930  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 07:17:43.612260  8058 solver.cpp:218] Iteration 47600 (0.865763 iter/s, 57.7525s/50 iters), loss = 1.94737
I0618 07:17:43.612330  8058 solver.cpp:237]     Train net output #0: accuracy = 0.48
I0618 07:17:43.612355  8058 solver.cpp:237]     Train net output #1: loss = 1.94737 (* 1 = 1.94737 loss)
I0618 07:17:43.612372  8058 sgd_solver.cpp:105] Iteration 47600, lr = 0.01
I0618 07:18:41.370544  8058 solver.cpp:218] Iteration 47650 (0.865686 iter/s, 57.7577s/50 iters), loss = 1.26584
I0618 07:18:41.370661  8058 solver.cpp:237]     Train net output #0: accuracy = 0.74
I0618 07:18:41.370689  8058 solver.cpp:237]     Train net output #1: loss = 1.26584 (* 1 = 1.26584 loss)
I0618 07:18:41.370707  8058 sgd_solver.cpp:105] Iteration 47650, lr = 0.01
I0618 07:19:39.127540  8058 solver.cpp:218] Iteration 47700 (0.865706 iter/s, 57.7564s/50 iters), loss = 1.30887
I0618 07:19:39.127647  8058 solver.cpp:237]     Train net output #0: accuracy = 0.68
I0618 07:19:39.127676  8058 solver.cpp:237]     Train net output #1: loss = 1.30887 (* 1 = 1.30887 loss)
I0618 07:19:39.127693  8058 sgd_solver.cpp:105] Iteration 47700, lr = 0.01
I0618 07:19:48.428184  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 07:20:36.886783  8058 solver.cpp:218] Iteration 47750 (0.865672 iter/s, 57.7586s/50 iters), loss = 0.941157
I0618 07:20:36.886968  8058 solver.cpp:237]     Train net output #0: accuracy = 0.82
I0618 07:20:36.886998  8058 solver.cpp:237]     Train net output #1: loss = 0.941157 (* 1 = 0.941157 loss)
I0618 07:20:36.887017  8058 sgd_solver.cpp:105] Iteration 47750, lr = 0.01
I0618 07:21:34.652405  8058 solver.cpp:218] Iteration 47800 (0.865577 iter/s, 57.7649s/50 iters), loss = 1.01454
I0618 07:21:34.652519  8058 solver.cpp:237]     Train net output #0: accuracy = 0.74
I0618 07:21:34.652550  8058 solver.cpp:237]     Train net output #1: loss = 1.01454 (* 1 = 1.01454 loss)
I0618 07:21:34.652568  8058 sgd_solver.cpp:105] Iteration 47800, lr = 0.01
I0618 07:22:07.068781  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 07:22:32.410140  8058 solver.cpp:218] Iteration 47850 (0.865694 iter/s, 57.7571s/50 iters), loss = 0.844195
I0618 07:22:32.410217  8058 solver.cpp:237]     Train net output #0: accuracy = 0.78
I0618 07:22:32.410243  8058 solver.cpp:237]     Train net output #1: loss = 0.844195 (* 1 = 0.844195 loss)
I0618 07:22:32.410259  8058 sgd_solver.cpp:105] Iteration 47850, lr = 0.01
I0618 07:23:30.177981  8058 solver.cpp:218] Iteration 47900 (0.865542 iter/s, 57.7672s/50 iters), loss = 0.799124
I0618 07:23:30.178092  8058 solver.cpp:237]     Train net output #0: accuracy = 0.7
I0618 07:23:30.178122  8058 solver.cpp:237]     Train net output #1: loss = 0.799124 (* 1 = 0.799124 loss)
I0618 07:23:30.178140  8058 sgd_solver.cpp:105] Iteration 47900, lr = 0.01
I0618 07:24:24.568500  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 07:24:27.947365  8058 solver.cpp:218] Iteration 47950 (0.86552 iter/s, 57.7688s/50 iters), loss = 0.581794
I0618 07:24:27.947438  8058 solver.cpp:237]     Train net output #0: accuracy = 0.88
I0618 07:24:27.947465  8058 solver.cpp:237]     Train net output #1: loss = 0.581794 (* 1 = 0.581794 loss)
I0618 07:24:27.947482  8058 sgd_solver.cpp:105] Iteration 47950, lr = 0.01
I0618 07:25:25.706149  8058 solver.cpp:218] Iteration 48000 (0.865678 iter/s, 57.7582s/50 iters), loss = 0.532935
I0618 07:25:25.706264  8058 solver.cpp:237]     Train net output #0: accuracy = 0.84
I0618 07:25:25.706291  8058 solver.cpp:237]     Train net output #1: loss = 0.532935 (* 1 = 0.532935 loss)
I0618 07:25:25.706310  8058 sgd_solver.cpp:105] Iteration 48000, lr = 0.01
I0618 07:26:23.467141  8058 solver.cpp:218] Iteration 48050 (0.865646 iter/s, 57.7604s/50 iters), loss = 0.52681
I0618 07:26:23.467260  8058 solver.cpp:237]     Train net output #0: accuracy = 0.86
I0618 07:26:23.467293  8058 solver.cpp:237]     Train net output #1: loss = 0.52681 (* 1 = 0.52681 loss)
I0618 07:26:23.467311  8058 sgd_solver.cpp:105] Iteration 48050, lr = 0.01
I0618 07:26:43.185458  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 07:27:21.228076  8058 solver.cpp:218] Iteration 48100 (0.865646 iter/s, 57.7603s/50 iters), loss = 0.510768
I0618 07:27:21.228194  8058 solver.cpp:237]     Train net output #0: accuracy = 0.8
I0618 07:27:21.228224  8058 solver.cpp:237]     Train net output #1: loss = 0.510768 (* 1 = 0.510768 loss)
I0618 07:27:21.228241  8058 sgd_solver.cpp:105] Iteration 48100, lr = 0.01
I0618 07:28:18.988656  8058 solver.cpp:218] Iteration 48150 (0.865652 iter/s, 57.7599s/50 iters), loss = 0.465714
I0618 07:28:18.988778  8058 solver.cpp:237]     Train net output #0: accuracy = 0.94
I0618 07:28:18.988807  8058 solver.cpp:237]     Train net output #1: loss = 0.465714 (* 1 = 0.465714 loss)
I0618 07:28:18.988824  8058 sgd_solver.cpp:105] Iteration 48150, lr = 0.01
I0618 07:29:01.830319  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 07:29:16.747679  8058 solver.cpp:218] Iteration 48200 (0.865675 iter/s, 57.7584s/50 iters), loss = 0.318968
I0618 07:29:16.747755  8058 solver.cpp:237]     Train net output #0: accuracy = 0.96
I0618 07:29:16.747781  8058 solver.cpp:237]     Train net output #1: loss = 0.318968 (* 1 = 0.318968 loss)
I0618 07:29:16.747799  8058 sgd_solver.cpp:105] Iteration 48200, lr = 0.01
I0618 07:30:14.501556  8058 solver.cpp:218] Iteration 48250 (0.865752 iter/s, 57.7533s/50 iters), loss = 0.278011
I0618 07:30:14.501713  8058 solver.cpp:237]     Train net output #0: accuracy = 0.94
I0618 07:30:14.501746  8058 solver.cpp:237]     Train net output #1: loss = 0.278011 (* 1 = 0.278011 loss)
I0618 07:30:14.501765  8058 sgd_solver.cpp:105] Iteration 48250, lr = 0.01
I0618 07:31:12.264638  8058 solver.cpp:218] Iteration 48300 (0.865615 iter/s, 57.7624s/50 iters), loss = 0.179656
I0618 07:31:12.264758  8058 solver.cpp:237]     Train net output #0: accuracy = 0.98
I0618 07:31:12.264787  8058 solver.cpp:237]     Train net output #1: loss = 0.179656 (* 1 = 0.179656 loss)
I0618 07:31:12.264804  8058 sgd_solver.cpp:105] Iteration 48300, lr = 0.01
I0618 07:31:20.423585  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 07:32:10.023463  8058 solver.cpp:218] Iteration 48350 (0.865678 iter/s, 57.7582s/50 iters), loss = 0.305984
I0618 07:32:10.023558  8058 solver.cpp:237]     Train net output #0: accuracy = 0.92
I0618 07:32:10.023586  8058 solver.cpp:237]     Train net output #1: loss = 0.305984 (* 1 = 0.305984 loss)
I0618 07:32:10.023603  8058 sgd_solver.cpp:105] Iteration 48350, lr = 0.01
I0618 07:33:07.773087  8058 solver.cpp:218] Iteration 48400 (0.865816 iter/s, 57.749s/50 iters), loss = 0.221144
I0618 07:33:07.773211  8058 solver.cpp:237]     Train net output #0: accuracy = 0.94
I0618 07:33:07.773239  8058 solver.cpp:237]     Train net output #1: loss = 0.221144 (* 1 = 0.221144 loss)
I0618 07:33:07.773257  8058 sgd_solver.cpp:105] Iteration 48400, lr = 0.01
I0618 07:33:39.053279  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 07:34:05.528038  8058 solver.cpp:218] Iteration 48450 (0.865736 iter/s, 57.7543s/50 iters), loss = 0.272899
I0618 07:34:05.528108  8058 solver.cpp:237]     Train net output #0: accuracy = 0.92
I0618 07:34:05.528134  8058 solver.cpp:237]     Train net output #1: loss = 0.272899 (* 1 = 0.272899 loss)
I0618 07:34:05.528151  8058 sgd_solver.cpp:105] Iteration 48450, lr = 0.01
I0618 07:35:03.274137  8058 solver.cpp:218] Iteration 48500 (0.865868 iter/s, 57.7455s/50 iters), loss = 0.210751
I0618 07:35:03.274251  8058 solver.cpp:237]     Train net output #0: accuracy = 0.96
I0618 07:35:03.274279  8058 solver.cpp:237]     Train net output #1: loss = 0.210751 (* 1 = 0.210751 loss)
I0618 07:35:03.274297  8058 sgd_solver.cpp:105] Iteration 48500, lr = 0.01
I0618 07:35:57.636464  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 07:36:01.039930  8058 solver.cpp:218] Iteration 48550 (0.865574 iter/s, 57.7651s/50 iters), loss = 0.212376
I0618 07:36:01.040026  8058 solver.cpp:237]     Train net output #0: accuracy = 0.94
I0618 07:36:01.040058  8058 solver.cpp:237]     Train net output #1: loss = 0.212376 (* 1 = 0.212376 loss)
I0618 07:36:01.040078  8058 sgd_solver.cpp:105] Iteration 48550, lr = 0.01
I0618 07:36:58.805187  8058 solver.cpp:218] Iteration 48600 (0.865581 iter/s, 57.7647s/50 iters), loss = 0.0720705
I0618 07:36:58.805305  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 07:36:58.805333  8058 solver.cpp:237]     Train net output #1: loss = 0.0720705 (* 1 = 0.0720705 loss)
I0618 07:36:58.805351  8058 sgd_solver.cpp:105] Iteration 48600, lr = 0.01
I0618 07:37:56.561790  8058 solver.cpp:218] Iteration 48650 (0.865711 iter/s, 57.756s/50 iters), loss = 0.145615
I0618 07:37:56.561904  8058 solver.cpp:237]     Train net output #0: accuracy = 0.98
I0618 07:37:56.561933  8058 solver.cpp:237]     Train net output #1: loss = 0.145615 (* 1 = 0.145615 loss)
I0618 07:37:56.561949  8058 sgd_solver.cpp:105] Iteration 48650, lr = 0.01
I0618 07:38:16.277616  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 07:38:54.327317  8058 solver.cpp:218] Iteration 48700 (0.865577 iter/s, 57.7649s/50 iters), loss = 0.0842033
I0618 07:38:54.327448  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 07:38:54.327477  8058 solver.cpp:237]     Train net output #1: loss = 0.0842033 (* 1 = 0.0842033 loss)
I0618 07:38:54.327494  8058 sgd_solver.cpp:105] Iteration 48700, lr = 0.01
I0618 07:39:52.091820  8058 solver.cpp:218] Iteration 48750 (0.865593 iter/s, 57.7639s/50 iters), loss = 0.0896411
I0618 07:39:52.092000  8058 solver.cpp:237]     Train net output #0: accuracy = 0.98
I0618 07:39:52.092031  8058 solver.cpp:237]     Train net output #1: loss = 0.0896411 (* 1 = 0.0896411 loss)
I0618 07:39:52.092047  8058 sgd_solver.cpp:105] Iteration 48750, lr = 0.01
I0618 07:40:34.917520  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 07:40:49.853077  8058 solver.cpp:218] Iteration 48800 (0.865642 iter/s, 57.7606s/50 iters), loss = 0.0339531
I0618 07:40:49.853157  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 07:40:49.853183  8058 solver.cpp:237]     Train net output #1: loss = 0.0339531 (* 1 = 0.0339531 loss)
I0618 07:40:49.853200  8058 sgd_solver.cpp:105] Iteration 48800, lr = 0.01
I0618 07:41:47.620966  8058 solver.cpp:218] Iteration 48850 (0.865541 iter/s, 57.7673s/50 iters), loss = 0.0511696
I0618 07:41:47.621090  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 07:41:47.621119  8058 solver.cpp:237]     Train net output #1: loss = 0.0511696 (* 1 = 0.0511696 loss)
I0618 07:41:47.621150  8058 sgd_solver.cpp:105] Iteration 48850, lr = 0.01
I0618 07:42:45.389215  8058 solver.cpp:218] Iteration 48900 (0.865536 iter/s, 57.7677s/50 iters), loss = 0.0372561
I0618 07:42:45.389408  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 07:42:45.389437  8058 solver.cpp:237]     Train net output #1: loss = 0.0372561 (* 1 = 0.0372561 loss)
I0618 07:42:45.389456  8058 sgd_solver.cpp:105] Iteration 48900, lr = 0.01
I0618 07:42:53.547551  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 07:43:43.151610  8058 solver.cpp:218] Iteration 48950 (0.865625 iter/s, 57.7617s/50 iters), loss = 0.0461978
I0618 07:43:43.151741  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 07:43:43.151768  8058 solver.cpp:237]     Train net output #1: loss = 0.0461979 (* 1 = 0.0461979 loss)
I0618 07:43:43.151785  8058 sgd_solver.cpp:105] Iteration 48950, lr = 0.01
I0618 07:44:40.920284  8058 solver.cpp:218] Iteration 49000 (0.86553 iter/s, 57.7681s/50 iters), loss = 0.0682332
I0618 07:44:40.920424  8058 solver.cpp:237]     Train net output #0: accuracy = 0.98
I0618 07:44:40.920454  8058 solver.cpp:237]     Train net output #1: loss = 0.0682332 (* 1 = 0.0682332 loss)
I0618 07:44:40.920471  8058 sgd_solver.cpp:105] Iteration 49000, lr = 0.01
I0618 07:45:11.044517  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 07:45:38.683964  8058 solver.cpp:218] Iteration 49050 (0.865605 iter/s, 57.7631s/50 iters), loss = 0.0440551
I0618 07:45:38.684053  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 07:45:38.684080  8058 solver.cpp:237]     Train net output #1: loss = 0.0440551 (* 1 = 0.0440551 loss)
I0618 07:45:38.684098  8058 sgd_solver.cpp:105] Iteration 49050, lr = 0.01
I0618 07:46:36.450639  8058 solver.cpp:218] Iteration 49100 (0.865559 iter/s, 57.7661s/50 iters), loss = 0.0203082
I0618 07:46:36.450752  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 07:46:36.450781  8058 solver.cpp:237]     Train net output #1: loss = 0.0203083 (* 1 = 0.0203083 loss)
I0618 07:46:36.450798  8058 sgd_solver.cpp:105] Iteration 49100, lr = 0.01
I0618 07:47:29.675587  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 07:47:34.216033  8058 solver.cpp:218] Iteration 49150 (0.865579 iter/s, 57.7648s/50 iters), loss = 0.0237043
I0618 07:47:34.216123  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 07:47:34.216154  8058 solver.cpp:237]     Train net output #1: loss = 0.0237043 (* 1 = 0.0237043 loss)
I0618 07:47:34.216176  8058 sgd_solver.cpp:105] Iteration 49150, lr = 0.01
I0618 07:48:31.995249  8058 solver.cpp:218] Iteration 49200 (0.865371 iter/s, 57.7787s/50 iters), loss = 0.0240828
I0618 07:48:31.995368  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 07:48:31.995396  8058 solver.cpp:237]     Train net output #1: loss = 0.0240828 (* 1 = 0.0240828 loss)
I0618 07:48:31.995414  8058 sgd_solver.cpp:105] Iteration 49200, lr = 0.01
I0618 07:49:29.767144  8058 solver.cpp:218] Iteration 49250 (0.865481 iter/s, 57.7713s/50 iters), loss = 0.0411452
I0618 07:49:29.767308  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 07:49:29.767338  8058 solver.cpp:237]     Train net output #1: loss = 0.0411452 (* 1 = 0.0411452 loss)
I0618 07:49:29.767354  8058 sgd_solver.cpp:105] Iteration 49250, lr = 0.01
I0618 07:49:48.326959  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 07:50:27.523093  8058 solver.cpp:218] Iteration 49300 (0.865721 iter/s, 57.7553s/50 iters), loss = 0.0823639
I0618 07:50:27.523210  8058 solver.cpp:237]     Train net output #0: accuracy = 0.98
I0618 07:50:27.523238  8058 solver.cpp:237]     Train net output #1: loss = 0.082364 (* 1 = 0.082364 loss)
I0618 07:50:27.523257  8058 sgd_solver.cpp:105] Iteration 49300, lr = 0.01
I0618 07:51:25.289268  8058 solver.cpp:218] Iteration 49350 (0.865568 iter/s, 57.7656s/50 iters), loss = 0.0191714
I0618 07:51:25.289402  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 07:51:25.289446  8058 solver.cpp:237]     Train net output #1: loss = 0.0191714 (* 1 = 0.0191714 loss)
I0618 07:51:25.289468  8058 sgd_solver.cpp:105] Iteration 49350, lr = 0.01
I0618 07:52:06.921663  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 07:52:23.050933  8058 solver.cpp:218] Iteration 49400 (0.865635 iter/s, 57.7611s/50 iters), loss = 0.0264106
I0618 07:52:23.051010  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 07:52:23.051036  8058 solver.cpp:237]     Train net output #1: loss = 0.0264106 (* 1 = 0.0264106 loss)
I0618 07:52:23.051054  8058 sgd_solver.cpp:105] Iteration 49400, lr = 0.01
I0618 07:53:20.805413  8058 solver.cpp:218] Iteration 49450 (0.865742 iter/s, 57.7539s/50 iters), loss = 0.0109356
I0618 07:53:20.805524  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 07:53:20.805553  8058 solver.cpp:237]     Train net output #1: loss = 0.0109356 (* 1 = 0.0109356 loss)
I0618 07:53:20.805570  8058 sgd_solver.cpp:105] Iteration 49450, lr = 0.01
I0618 07:54:18.564386  8058 solver.cpp:218] Iteration 49500 (0.865675 iter/s, 57.7584s/50 iters), loss = 0.0103745
I0618 07:54:18.564504  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 07:54:18.564541  8058 solver.cpp:237]     Train net output #1: loss = 0.0103746 (* 1 = 0.0103746 loss)
I0618 07:54:18.564560  8058 sgd_solver.cpp:105] Iteration 49500, lr = 0.01
I0618 07:54:25.584628  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 07:55:16.327121  8058 solver.cpp:218] Iteration 49550 (0.865619 iter/s, 57.7621s/50 iters), loss = 0.00775858
I0618 07:55:16.327280  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 07:55:16.327308  8058 solver.cpp:237]     Train net output #1: loss = 0.00775861 (* 1 = 0.00775861 loss)
I0618 07:55:16.327325  8058 sgd_solver.cpp:105] Iteration 49550, lr = 0.01
I0618 07:56:14.091819  8058 solver.cpp:218] Iteration 49600 (0.86559 iter/s, 57.7641s/50 iters), loss = 0.0084949
I0618 07:56:14.091928  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 07:56:14.091956  8058 solver.cpp:237]     Train net output #1: loss = 0.00849493 (* 1 = 0.00849493 loss)
I0618 07:56:14.091974  8058 sgd_solver.cpp:105] Iteration 49600, lr = 0.01
I0618 07:56:44.206701  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 07:57:11.843698  8058 solver.cpp:218] Iteration 49650 (0.865781 iter/s, 57.7513s/50 iters), loss = 0.010402
I0618 07:57:11.843776  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 07:57:11.843803  8058 solver.cpp:237]     Train net output #1: loss = 0.010402 (* 1 = 0.010402 loss)
I0618 07:57:11.843821  8058 sgd_solver.cpp:105] Iteration 49650, lr = 0.01
I0618 07:58:09.601188  8058 solver.cpp:218] Iteration 49700 (0.865697 iter/s, 57.7569s/50 iters), loss = 0.0115523
I0618 07:58:09.601366  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 07:58:09.601397  8058 solver.cpp:237]     Train net output #1: loss = 0.0115524 (* 1 = 0.0115524 loss)
I0618 07:58:09.601414  8058 sgd_solver.cpp:105] Iteration 49700, lr = 0.01
I0618 07:59:02.818637  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 07:59:07.388789  8058 solver.cpp:218] Iteration 49750 (0.865247 iter/s, 57.7869s/50 iters), loss = 0.00854632
I0618 07:59:07.388902  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 07:59:07.388929  8058 solver.cpp:237]     Train net output #1: loss = 0.00854635 (* 1 = 0.00854635 loss)
I0618 07:59:07.388947  8058 sgd_solver.cpp:105] Iteration 49750, lr = 0.01
I0618 08:00:05.217574  8058 solver.cpp:218] Iteration 49800 (0.86463 iter/s, 57.8282s/50 iters), loss = 0.00871599
I0618 08:00:05.217736  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:00:05.217764  8058 solver.cpp:237]     Train net output #1: loss = 0.00871603 (* 1 = 0.00871603 loss)
I0618 08:00:05.217787  8058 sgd_solver.cpp:105] Iteration 49800, lr = 0.01
I0618 08:01:03.045799  8058 solver.cpp:218] Iteration 49850 (0.864639 iter/s, 57.8276s/50 iters), loss = 0.00725232
I0618 08:01:03.045958  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:01:03.046003  8058 solver.cpp:237]     Train net output #1: loss = 0.00725235 (* 1 = 0.00725235 loss)
I0618 08:01:03.046022  8058 sgd_solver.cpp:105] Iteration 49850, lr = 0.01
I0618 08:01:21.593335  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 08:02:00.877179  8058 solver.cpp:218] Iteration 49900 (0.864592 iter/s, 57.8307s/50 iters), loss = 0.00851471
I0618 08:02:00.881117  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:02:00.881162  8058 solver.cpp:237]     Train net output #1: loss = 0.00851474 (* 1 = 0.00851474 loss)
I0618 08:02:00.881181  8058 sgd_solver.cpp:105] Iteration 49900, lr = 0.01
I0618 08:02:58.711232  8058 solver.cpp:218] Iteration 49950 (0.864609 iter/s, 57.8296s/50 iters), loss = 0.0107845
I0618 08:02:58.711382  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:02:58.711410  8058 solver.cpp:237]     Train net output #1: loss = 0.0107845 (* 1 = 0.0107845 loss)
I0618 08:02:58.711428  8058 sgd_solver.cpp:105] Iteration 49950, lr = 0.01
I0618 08:03:39.268831  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 08:03:55.388097  8058 solver.cpp:447] Snapshotting to binary proto file mobilenet/mobile_cub_iter_50000.caffemodel
I0618 08:03:55.473027  8058 sgd_solver.cpp:273] Snapshotting solver state to binary proto file mobilenet/mobile_cub_iter_50000.solverstate
I0618 08:03:56.657115  8058 solver.cpp:218] Iteration 50000 (0.862883 iter/s, 57.9453s/50 iters), loss = 0.0104392
I0618 08:03:56.657218  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:03:56.657245  8058 solver.cpp:237]     Train net output #1: loss = 0.0104393 (* 1 = 0.0104393 loss)
I0618 08:03:56.657268  8058 sgd_solver.cpp:105] Iteration 50000, lr = 0.001
I0618 08:04:54.482725  8058 solver.cpp:218] Iteration 50050 (0.864678 iter/s, 57.825s/50 iters), loss = 0.00490933
I0618 08:04:54.482897  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:04:54.482925  8058 solver.cpp:237]     Train net output #1: loss = 0.00490936 (* 1 = 0.00490936 loss)
I0618 08:04:54.482942  8058 sgd_solver.cpp:105] Iteration 50050, lr = 0.001
I0618 08:05:52.312301  8058 solver.cpp:218] Iteration 50100 (0.864619 iter/s, 57.8289s/50 iters), loss = 0.00528478
I0618 08:05:52.312466  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:05:52.312495  8058 solver.cpp:237]     Train net output #1: loss = 0.00528481 (* 1 = 0.00528481 loss)
I0618 08:05:52.312511  8058 sgd_solver.cpp:105] Iteration 50100, lr = 0.001
I0618 08:05:58.167014  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 08:06:50.145743  8058 solver.cpp:218] Iteration 50150 (0.864561 iter/s, 57.8328s/50 iters), loss = 0.00844562
I0618 08:06:50.145896  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:06:50.145925  8058 solver.cpp:237]     Train net output #1: loss = 0.00844565 (* 1 = 0.00844565 loss)
I0618 08:06:50.145943  8058 sgd_solver.cpp:105] Iteration 50150, lr = 0.001
I0618 08:07:47.969907  8058 solver.cpp:218] Iteration 50200 (0.8647 iter/s, 57.8235s/50 iters), loss = 0.00566274
I0618 08:07:47.970149  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:07:47.970180  8058 solver.cpp:237]     Train net output #1: loss = 0.00566278 (* 1 = 0.00566278 loss)
I0618 08:07:47.970202  8058 sgd_solver.cpp:105] Iteration 50200, lr = 0.001
I0618 08:08:16.951699  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 08:08:45.790448  8058 solver.cpp:218] Iteration 50250 (0.864755 iter/s, 57.8198s/50 iters), loss = 0.00747748
I0618 08:08:45.790586  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:08:45.790616  8058 solver.cpp:237]     Train net output #1: loss = 0.00747751 (* 1 = 0.00747751 loss)
I0618 08:08:45.790635  8058 sgd_solver.cpp:105] Iteration 50250, lr = 0.001
I0618 08:09:43.566267  8058 solver.cpp:218] Iteration 50300 (0.865423 iter/s, 57.7752s/50 iters), loss = 0.0128511
I0618 08:09:43.566395  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:09:43.566437  8058 solver.cpp:237]     Train net output #1: loss = 0.0128511 (* 1 = 0.0128511 loss)
I0618 08:09:43.566452  8058 sgd_solver.cpp:105] Iteration 50300, lr = 0.001
I0618 08:10:35.627414  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 08:10:41.329741  8058 solver.cpp:218] Iteration 50350 (0.865608 iter/s, 57.7629s/50 iters), loss = 0.00652595
I0618 08:10:41.329823  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:10:41.329849  8058 solver.cpp:237]     Train net output #1: loss = 0.00652598 (* 1 = 0.00652598 loss)
I0618 08:10:41.329866  8058 sgd_solver.cpp:105] Iteration 50350, lr = 0.001
I0618 08:11:39.086508  8058 solver.cpp:218] Iteration 50400 (0.865708 iter/s, 57.7562s/50 iters), loss = 0.0062587
I0618 08:11:39.086637  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:11:39.086668  8058 solver.cpp:237]     Train net output #1: loss = 0.00625873 (* 1 = 0.00625873 loss)
I0618 08:11:39.086688  8058 sgd_solver.cpp:105] Iteration 50400, lr = 0.001
I0618 08:12:36.851068  8058 solver.cpp:218] Iteration 50450 (0.865592 iter/s, 57.764s/50 iters), loss = 0.00472421
I0618 08:12:36.851285  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:12:36.851313  8058 solver.cpp:237]     Train net output #1: loss = 0.00472424 (* 1 = 0.00472424 loss)
I0618 08:12:36.851331  8058 sgd_solver.cpp:105] Iteration 50450, lr = 0.001
I0618 08:12:54.241168  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 08:13:34.624126  8058 solver.cpp:218] Iteration 50500 (0.865466 iter/s, 57.7724s/50 iters), loss = 0.00804042
I0618 08:13:34.624264  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:13:34.624291  8058 solver.cpp:237]     Train net output #1: loss = 0.00804045 (* 1 = 0.00804045 loss)
I0618 08:13:34.624307  8058 sgd_solver.cpp:105] Iteration 50500, lr = 0.001
I0618 08:14:32.392855  8058 solver.cpp:218] Iteration 50550 (0.865529 iter/s, 57.7681s/50 iters), loss = 0.0068332
I0618 08:14:32.392976  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:14:32.393002  8058 solver.cpp:237]     Train net output #1: loss = 0.00683323 (* 1 = 0.00683323 loss)
I0618 08:14:32.393019  8058 sgd_solver.cpp:105] Iteration 50550, lr = 0.001
I0618 08:15:12.892352  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 08:15:30.159838  8058 solver.cpp:218] Iteration 50600 (0.865555 iter/s, 57.7664s/50 iters), loss = 0.00593247
I0618 08:15:30.159919  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:15:30.159948  8058 solver.cpp:237]     Train net output #1: loss = 0.0059325 (* 1 = 0.0059325 loss)
I0618 08:15:30.159968  8058 sgd_solver.cpp:105] Iteration 50600, lr = 0.001
I0618 08:16:27.921063  8058 solver.cpp:218] Iteration 50650 (0.865641 iter/s, 57.7607s/50 iters), loss = 0.00672377
I0618 08:16:27.921249  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:16:27.921278  8058 solver.cpp:237]     Train net output #1: loss = 0.00672381 (* 1 = 0.00672381 loss)
I0618 08:16:27.921296  8058 sgd_solver.cpp:105] Iteration 50650, lr = 0.001
I0618 08:17:25.679560  8058 solver.cpp:218] Iteration 50700 (0.865683 iter/s, 57.7578s/50 iters), loss = 0.00576525
I0618 08:17:25.679685  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:17:25.679713  8058 solver.cpp:237]     Train net output #1: loss = 0.00576528 (* 1 = 0.00576528 loss)
I0618 08:17:25.679729  8058 sgd_solver.cpp:105] Iteration 50700, lr = 0.001
I0618 08:17:31.517879  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 08:18:23.438268  8058 solver.cpp:218] Iteration 50750 (0.865679 iter/s, 57.7581s/50 iters), loss = 0.00714807
I0618 08:18:23.438391  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:18:23.438418  8058 solver.cpp:237]     Train net output #1: loss = 0.0071481 (* 1 = 0.0071481 loss)
I0618 08:18:23.438436  8058 sgd_solver.cpp:105] Iteration 50750, lr = 0.001
I0618 08:19:21.201696  8058 solver.cpp:218] Iteration 50800 (0.865608 iter/s, 57.7628s/50 iters), loss = 0.00446116
I0618 08:19:21.201828  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:19:21.201855  8058 solver.cpp:237]     Train net output #1: loss = 0.00446119 (* 1 = 0.00446119 loss)
I0618 08:19:21.201871  8058 sgd_solver.cpp:105] Iteration 50800, lr = 0.001
I0618 08:19:50.152768  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 08:20:18.955327  8058 solver.cpp:218] Iteration 50850 (0.865755 iter/s, 57.753s/50 iters), loss = 0.00601637
I0618 08:20:18.955438  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:20:18.955466  8058 solver.cpp:237]     Train net output #1: loss = 0.0060164 (* 1 = 0.0060164 loss)
I0618 08:20:18.955484  8058 sgd_solver.cpp:105] Iteration 50850, lr = 0.001
I0618 08:21:16.710043  8058 solver.cpp:218] Iteration 50900 (0.865739 iter/s, 57.7541s/50 iters), loss = 0.00696318
I0618 08:21:16.710175  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:21:16.710202  8058 solver.cpp:237]     Train net output #1: loss = 0.00696321 (* 1 = 0.00696321 loss)
I0618 08:21:16.710218  8058 sgd_solver.cpp:105] Iteration 50900, lr = 0.001
I0618 08:22:07.617869  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 08:22:14.470147  8058 solver.cpp:218] Iteration 50950 (0.865658 iter/s, 57.7595s/50 iters), loss = 0.00732667
I0618 08:22:14.470221  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:22:14.470247  8058 solver.cpp:237]     Train net output #1: loss = 0.0073267 (* 1 = 0.0073267 loss)
I0618 08:22:14.470264  8058 sgd_solver.cpp:105] Iteration 50950, lr = 0.001
I0618 08:23:12.219305  8058 solver.cpp:218] Iteration 51000 (0.865821 iter/s, 57.7486s/50 iters), loss = 0.00598293
I0618 08:23:12.219424  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:23:12.219452  8058 solver.cpp:237]     Train net output #1: loss = 0.00598296 (* 1 = 0.00598296 loss)
I0618 08:23:12.219467  8058 sgd_solver.cpp:105] Iteration 51000, lr = 0.001
I0618 08:24:09.966143  8058 solver.cpp:218] Iteration 51050 (0.865857 iter/s, 57.7463s/50 iters), loss = 0.00724389
I0618 08:24:09.966262  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:24:09.966289  8058 solver.cpp:237]     Train net output #1: loss = 0.00724393 (* 1 = 0.00724393 loss)
I0618 08:24:09.966307  8058 sgd_solver.cpp:105] Iteration 51050, lr = 0.001
I0618 08:24:26.239820  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 08:25:07.728992  8058 solver.cpp:218] Iteration 51100 (0.865617 iter/s, 57.7623s/50 iters), loss = 0.00737188
I0618 08:25:07.729529  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:25:07.729562  8058 solver.cpp:237]     Train net output #1: loss = 0.00737192 (* 1 = 0.00737192 loss)
I0618 08:25:07.729581  8058 sgd_solver.cpp:105] Iteration 51100, lr = 0.001
I0618 08:26:05.504411  8058 solver.cpp:218] Iteration 51150 (0.865435 iter/s, 57.7744s/50 iters), loss = 0.00965699
I0618 08:26:05.504591  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:26:05.504621  8058 solver.cpp:237]     Train net output #1: loss = 0.00965702 (* 1 = 0.00965702 loss)
I0618 08:26:05.504639  8058 sgd_solver.cpp:105] Iteration 51150, lr = 0.001
I0618 08:26:44.882869  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 08:27:03.263429  8058 solver.cpp:218] Iteration 51200 (0.865675 iter/s, 57.7584s/50 iters), loss = 0.00574448
I0618 08:27:03.263504  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:27:03.263537  8058 solver.cpp:237]     Train net output #1: loss = 0.00574451 (* 1 = 0.00574451 loss)
I0618 08:27:03.263555  8058 sgd_solver.cpp:105] Iteration 51200, lr = 0.001
I0618 08:28:01.031615  8058 solver.cpp:218] Iteration 51250 (0.865537 iter/s, 57.7676s/50 iters), loss = 0.00624921
I0618 08:28:01.031755  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:28:01.031790  8058 solver.cpp:237]     Train net output #1: loss = 0.00624924 (* 1 = 0.00624924 loss)
I0618 08:28:01.031810  8058 sgd_solver.cpp:105] Iteration 51250, lr = 0.001
I0618 08:28:58.792898  8058 solver.cpp:218] Iteration 51300 (0.865641 iter/s, 57.7607s/50 iters), loss = 0.00597832
I0618 08:28:58.799587  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:28:58.799618  8058 solver.cpp:237]     Train net output #1: loss = 0.00597835 (* 1 = 0.00597835 loss)
I0618 08:28:58.799633  8058 sgd_solver.cpp:105] Iteration 51300, lr = 0.001
I0618 08:29:03.497503  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 08:29:56.558375  8058 solver.cpp:218] Iteration 51350 (0.865676 iter/s, 57.7584s/50 iters), loss = 0.00627122
I0618 08:29:56.558506  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:29:56.558543  8058 solver.cpp:237]     Train net output #1: loss = 0.00627125 (* 1 = 0.00627125 loss)
I0618 08:29:56.558560  8058 sgd_solver.cpp:105] Iteration 51350, lr = 0.001
I0618 08:30:54.313263  8058 solver.cpp:218] Iteration 51400 (0.865736 iter/s, 57.7543s/50 iters), loss = 0.00803218
I0618 08:30:54.313372  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:30:54.313400  8058 solver.cpp:237]     Train net output #1: loss = 0.00803221 (* 1 = 0.00803221 loss)
I0618 08:30:54.313416  8058 sgd_solver.cpp:105] Iteration 51400, lr = 0.001
I0618 08:31:22.106209  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 08:31:52.070894  8058 solver.cpp:218] Iteration 51450 (0.865695 iter/s, 57.7571s/50 iters), loss = 0.0106124
I0618 08:31:52.071019  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:31:52.071048  8058 solver.cpp:237]     Train net output #1: loss = 0.0106125 (* 1 = 0.0106125 loss)
I0618 08:31:52.071064  8058 sgd_solver.cpp:105] Iteration 51450, lr = 0.001
I0618 08:32:49.817827  8058 solver.cpp:218] Iteration 51500 (0.865855 iter/s, 57.7464s/50 iters), loss = 0.00492831
I0618 08:32:49.817950  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:32:49.817978  8058 solver.cpp:237]     Train net output #1: loss = 0.00492834 (* 1 = 0.00492834 loss)
I0618 08:32:49.817994  8058 sgd_solver.cpp:105] Iteration 51500, lr = 0.001
I0618 08:33:40.707557  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 08:33:47.576969  8058 solver.cpp:218] Iteration 51550 (0.865672 iter/s, 57.7586s/50 iters), loss = 0.00646864
I0618 08:33:47.577049  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:33:47.577075  8058 solver.cpp:237]     Train net output #1: loss = 0.00646867 (* 1 = 0.00646867 loss)
I0618 08:33:47.577092  8058 sgd_solver.cpp:105] Iteration 51550, lr = 0.001
I0618 08:34:45.341071  8058 solver.cpp:218] Iteration 51600 (0.865597 iter/s, 57.7636s/50 iters), loss = 0.00631928
I0618 08:34:45.341188  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:34:45.341217  8058 solver.cpp:237]     Train net output #1: loss = 0.00631932 (* 1 = 0.00631932 loss)
I0618 08:34:45.341233  8058 sgd_solver.cpp:105] Iteration 51600, lr = 0.001
I0618 08:35:43.116765  8058 solver.cpp:218] Iteration 51650 (0.865424 iter/s, 57.7751s/50 iters), loss = 0.00631727
I0618 08:35:43.116933  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:35:43.116963  8058 solver.cpp:237]     Train net output #1: loss = 0.00631731 (* 1 = 0.00631731 loss)
I0618 08:35:43.116982  8058 sgd_solver.cpp:105] Iteration 51650, lr = 0.001
I0618 08:35:59.367385  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 08:36:40.867054  8058 solver.cpp:218] Iteration 51700 (0.865806 iter/s, 57.7497s/50 iters), loss = 0.00522063
I0618 08:36:40.867264  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:36:40.867293  8058 solver.cpp:237]     Train net output #1: loss = 0.00522067 (* 1 = 0.00522067 loss)
I0618 08:36:40.867311  8058 sgd_solver.cpp:105] Iteration 51700, lr = 0.001
I0618 08:37:38.627199  8058 solver.cpp:218] Iteration 51750 (0.865659 iter/s, 57.7595s/50 iters), loss = 0.00581834
I0618 08:37:38.627351  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:37:38.627378  8058 solver.cpp:237]     Train net output #1: loss = 0.00581837 (* 1 = 0.00581837 loss)
I0618 08:37:38.627409  8058 sgd_solver.cpp:105] Iteration 51750, lr = 0.001
I0618 08:38:17.965667  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 08:38:36.409045  8058 solver.cpp:218] Iteration 51800 (0.865333 iter/s, 57.7813s/50 iters), loss = 0.00844866
I0618 08:38:36.409126  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:38:36.409152  8058 solver.cpp:237]     Train net output #1: loss = 0.0084487 (* 1 = 0.0084487 loss)
I0618 08:38:36.409168  8058 sgd_solver.cpp:105] Iteration 51800, lr = 0.001
I0618 08:39:34.180832  8058 solver.cpp:218] Iteration 51850 (0.865482 iter/s, 57.7713s/50 iters), loss = 0.00770056
I0618 08:39:34.180946  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:39:34.180979  8058 solver.cpp:237]     Train net output #1: loss = 0.00770059 (* 1 = 0.00770059 loss)
I0618 08:39:34.180999  8058 sgd_solver.cpp:105] Iteration 51850, lr = 0.001
I0618 08:40:31.945605  8058 solver.cpp:218] Iteration 51900 (0.865588 iter/s, 57.7642s/50 iters), loss = 0.00536526
I0618 08:40:31.945745  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:40:31.945773  8058 solver.cpp:237]     Train net output #1: loss = 0.00536529 (* 1 = 0.00536529 loss)
I0618 08:40:31.945791  8058 sgd_solver.cpp:105] Iteration 51900, lr = 0.001
I0618 08:40:36.639129  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 08:41:29.712842  8058 solver.cpp:218] Iteration 51950 (0.865551 iter/s, 57.7667s/50 iters), loss = 0.00682911
I0618 08:41:29.712965  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:41:29.712994  8058 solver.cpp:237]     Train net output #1: loss = 0.00682914 (* 1 = 0.00682914 loss)
I0618 08:41:29.713011  8058 sgd_solver.cpp:105] Iteration 51950, lr = 0.001
I0618 08:42:27.465013  8058 solver.cpp:218] Iteration 52000 (0.865777 iter/s, 57.7516s/50 iters), loss = 0.00506108
I0618 08:42:27.465126  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:42:27.465154  8058 solver.cpp:237]     Train net output #1: loss = 0.00506111 (* 1 = 0.00506111 loss)
I0618 08:42:27.465171  8058 sgd_solver.cpp:105] Iteration 52000, lr = 0.001
I0618 08:42:54.124526  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 08:43:25.227912  8058 solver.cpp:218] Iteration 52050 (0.865616 iter/s, 57.7623s/50 iters), loss = 0.00581121
I0618 08:43:25.228046  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:43:25.228080  8058 solver.cpp:237]     Train net output #1: loss = 0.00581124 (* 1 = 0.00581124 loss)
I0618 08:43:25.228101  8058 sgd_solver.cpp:105] Iteration 52050, lr = 0.001
I0618 08:44:22.993407  8058 solver.cpp:218] Iteration 52100 (0.865577 iter/s, 57.7649s/50 iters), loss = 0.00607625
I0618 08:44:22.993542  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:44:22.993571  8058 solver.cpp:237]     Train net output #1: loss = 0.00607628 (* 1 = 0.00607628 loss)
I0618 08:44:22.993587  8058 sgd_solver.cpp:105] Iteration 52100, lr = 0.001
I0618 08:45:12.759754  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 08:45:20.749270  8058 solver.cpp:218] Iteration 52150 (0.865722 iter/s, 57.7553s/50 iters), loss = 0.00787624
I0618 08:45:20.749347  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:45:20.749374  8058 solver.cpp:237]     Train net output #1: loss = 0.00787628 (* 1 = 0.00787628 loss)
I0618 08:45:20.749392  8058 sgd_solver.cpp:105] Iteration 52150, lr = 0.001
I0618 08:46:18.517504  8058 solver.cpp:218] Iteration 52200 (0.865535 iter/s, 57.7677s/50 iters), loss = 0.00471561
I0618 08:46:18.517621  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:46:18.517650  8058 solver.cpp:237]     Train net output #1: loss = 0.00471565 (* 1 = 0.00471565 loss)
I0618 08:46:18.517666  8058 sgd_solver.cpp:105] Iteration 52200, lr = 0.001
I0618 08:47:16.266029  8058 solver.cpp:218] Iteration 52250 (0.865832 iter/s, 57.748s/50 iters), loss = 0.00565364
I0618 08:47:16.266137  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:47:16.266178  8058 solver.cpp:237]     Train net output #1: loss = 0.00565367 (* 1 = 0.00565367 loss)
I0618 08:47:16.266196  8058 sgd_solver.cpp:105] Iteration 52250, lr = 0.001
I0618 08:47:31.383972  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 08:48:14.027822  8058 solver.cpp:218] Iteration 52300 (0.865633 iter/s, 57.7612s/50 iters), loss = 0.00685856
I0618 08:48:14.027945  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:48:14.027973  8058 solver.cpp:237]     Train net output #1: loss = 0.00685859 (* 1 = 0.00685859 loss)
I0618 08:48:14.027990  8058 sgd_solver.cpp:105] Iteration 52300, lr = 0.001
I0618 08:49:11.788419  8058 solver.cpp:218] Iteration 52350 (0.865651 iter/s, 57.76s/50 iters), loss = 0.00645955
I0618 08:49:11.788532  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:49:11.788561  8058 solver.cpp:237]     Train net output #1: loss = 0.00645958 (* 1 = 0.00645958 loss)
I0618 08:49:11.788579  8058 sgd_solver.cpp:105] Iteration 52350, lr = 0.001
I0618 08:49:49.996526  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 08:50:09.546973  8058 solver.cpp:218] Iteration 52400 (0.865681 iter/s, 57.758s/50 iters), loss = 0.00732222
I0618 08:50:09.547055  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:50:09.547081  8058 solver.cpp:237]     Train net output #1: loss = 0.00732226 (* 1 = 0.00732226 loss)
I0618 08:50:09.547097  8058 sgd_solver.cpp:105] Iteration 52400, lr = 0.001
I0618 08:51:07.329977  8058 solver.cpp:218] Iteration 52450 (0.865314 iter/s, 57.7825s/50 iters), loss = 0.00361578
I0618 08:51:07.330097  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:51:07.330126  8058 solver.cpp:237]     Train net output #1: loss = 0.00361581 (* 1 = 0.00361581 loss)
I0618 08:51:07.330143  8058 sgd_solver.cpp:105] Iteration 52450, lr = 0.001
I0618 08:52:05.095784  8058 solver.cpp:218] Iteration 52500 (0.865573 iter/s, 57.7652s/50 iters), loss = 0.0087349
I0618 08:52:05.095912  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:52:05.095942  8058 solver.cpp:237]     Train net output #1: loss = 0.00873494 (* 1 = 0.00873494 loss)
I0618 08:52:05.095958  8058 sgd_solver.cpp:105] Iteration 52500, lr = 0.001
I0618 08:52:08.624330  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 08:53:02.860915  8058 solver.cpp:218] Iteration 52550 (0.865583 iter/s, 57.7645s/50 iters), loss = 0.00789186
I0618 08:53:02.861044  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:53:02.861073  8058 solver.cpp:237]     Train net output #1: loss = 0.00789189 (* 1 = 0.00789189 loss)
I0618 08:53:02.861089  8058 sgd_solver.cpp:105] Iteration 52550, lr = 0.001
I0618 08:54:00.629143  8058 solver.cpp:218] Iteration 52600 (0.865536 iter/s, 57.7676s/50 iters), loss = 0.00733207
I0618 08:54:00.629315  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:54:00.629345  8058 solver.cpp:237]     Train net output #1: loss = 0.0073321 (* 1 = 0.0073321 loss)
I0618 08:54:00.629361  8058 sgd_solver.cpp:105] Iteration 52600, lr = 0.001
I0618 08:54:27.280712  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 08:54:58.390038  8058 solver.cpp:218] Iteration 52650 (0.865647 iter/s, 57.7603s/50 iters), loss = 0.00723024
I0618 08:54:58.390161  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:54:58.390189  8058 solver.cpp:237]     Train net output #1: loss = 0.00723027 (* 1 = 0.00723027 loss)
I0618 08:54:58.390206  8058 sgd_solver.cpp:105] Iteration 52650, lr = 0.001
I0618 08:55:56.150846  8058 solver.cpp:218] Iteration 52700 (0.865647 iter/s, 57.7602s/50 iters), loss = 0.00491882
I0618 08:55:56.150957  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:55:56.150985  8058 solver.cpp:237]     Train net output #1: loss = 0.00491885 (* 1 = 0.00491885 loss)
I0618 08:55:56.151002  8058 sgd_solver.cpp:105] Iteration 52700, lr = 0.001
I0618 08:56:45.883134  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 08:56:53.912245  8058 solver.cpp:218] Iteration 52750 (0.865639 iter/s, 57.7608s/50 iters), loss = 0.00723235
I0618 08:56:53.912343  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:56:53.912369  8058 solver.cpp:237]     Train net output #1: loss = 0.00723238 (* 1 = 0.00723238 loss)
I0618 08:56:53.912387  8058 sgd_solver.cpp:105] Iteration 52750, lr = 0.001
I0618 08:57:51.673398  8058 solver.cpp:218] Iteration 52800 (0.865642 iter/s, 57.7606s/50 iters), loss = 0.0056949
I0618 08:57:51.673524  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:57:51.673557  8058 solver.cpp:237]     Train net output #1: loss = 0.00569494 (* 1 = 0.00569494 loss)
I0618 08:57:51.673576  8058 sgd_solver.cpp:105] Iteration 52800, lr = 0.001
I0618 08:58:49.486775  8058 solver.cpp:218] Iteration 52850 (0.864861 iter/s, 57.8128s/50 iters), loss = 0.00595741
I0618 08:58:49.487104  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:58:49.487134  8058 solver.cpp:237]     Train net output #1: loss = 0.00595744 (* 1 = 0.00595744 loss)
I0618 08:58:49.487154  8058 sgd_solver.cpp:105] Iteration 52850, lr = 0.001
I0618 08:59:04.576066  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 08:59:47.278971  8058 solver.cpp:218] Iteration 52900 (0.865181 iter/s, 57.7914s/50 iters), loss = 0.00718498
I0618 08:59:47.279106  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 08:59:47.279139  8058 solver.cpp:237]     Train net output #1: loss = 0.00718501 (* 1 = 0.00718501 loss)
I0618 08:59:47.279158  8058 sgd_solver.cpp:105] Iteration 52900, lr = 0.001
I0618 09:00:45.056948  8058 solver.cpp:218] Iteration 52950 (0.86539 iter/s, 57.7774s/50 iters), loss = 0.00595235
I0618 09:00:45.057066  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 09:00:45.057095  8058 solver.cpp:237]     Train net output #1: loss = 0.00595238 (* 1 = 0.00595238 loss)
I0618 09:00:45.057111  8058 sgd_solver.cpp:105] Iteration 52950, lr = 0.001
I0618 09:01:22.113718  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 09:01:42.826926  8058 solver.cpp:218] Iteration 53000 (0.86551 iter/s, 57.7694s/50 iters), loss = 0.00894322
I0618 09:01:42.827015  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 09:01:42.827041  8058 solver.cpp:237]     Train net output #1: loss = 0.00894325 (* 1 = 0.00894325 loss)
I0618 09:01:42.827057  8058 sgd_solver.cpp:105] Iteration 53000, lr = 0.001
I0618 09:02:40.602437  8058 solver.cpp:218] Iteration 53050 (0.865427 iter/s, 57.775s/50 iters), loss = 0.00765148
I0618 09:02:40.602558  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 09:02:40.602587  8058 solver.cpp:237]     Train net output #1: loss = 0.00765151 (* 1 = 0.00765151 loss)
I0618 09:02:40.602605  8058 sgd_solver.cpp:105] Iteration 53050, lr = 0.001
I0618 09:03:38.376142  8058 solver.cpp:218] Iteration 53100 (0.865455 iter/s, 57.7731s/50 iters), loss = 0.0079642
I0618 09:03:38.376328  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 09:03:38.376363  8058 solver.cpp:237]     Train net output #1: loss = 0.00796423 (* 1 = 0.00796423 loss)
I0618 09:03:38.376384  8058 sgd_solver.cpp:105] Iteration 53100, lr = 0.001
I0618 09:03:40.790706  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 09:04:36.136718  8058 solver.cpp:218] Iteration 53150 (0.865652 iter/s, 57.7599s/50 iters), loss = 0.00600955
I0618 09:04:36.136852  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 09:04:36.136881  8058 solver.cpp:237]     Train net output #1: loss = 0.00600959 (* 1 = 0.00600959 loss)
I0618 09:04:36.136898  8058 sgd_solver.cpp:105] Iteration 53150, lr = 0.001
I0618 09:05:33.899427  8058 solver.cpp:218] Iteration 53200 (0.865619 iter/s, 57.7621s/50 iters), loss = 0.00741324
I0618 09:05:33.899590  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 09:05:33.899619  8058 solver.cpp:237]     Train net output #1: loss = 0.00741328 (* 1 = 0.00741328 loss)
I0618 09:05:33.899636  8058 sgd_solver.cpp:105] Iteration 53200, lr = 0.001
I0618 09:05:59.382366  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 09:06:31.663458  8058 solver.cpp:218] Iteration 53250 (0.8656 iter/s, 57.7634s/50 iters), loss = 0.00591346
I0618 09:06:31.663597  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 09:06:31.663625  8058 solver.cpp:237]     Train net output #1: loss = 0.00591349 (* 1 = 0.00591349 loss)
I0618 09:06:31.663643  8058 sgd_solver.cpp:105] Iteration 53250, lr = 0.001
I0618 09:07:29.486943  8058 solver.cpp:218] Iteration 53300 (0.864709 iter/s, 57.8229s/50 iters), loss = 0.0085241
I0618 09:07:29.487057  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 09:07:29.487085  8058 solver.cpp:237]     Train net output #1: loss = 0.00852413 (* 1 = 0.00852413 loss)
I0618 09:07:29.487102  8058 sgd_solver.cpp:105] Iteration 53300, lr = 0.001
I0618 09:08:18.092664  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 09:08:27.267616  8058 solver.cpp:218] Iteration 53350 (0.86535 iter/s, 57.7801s/50 iters), loss = 0.00734652
I0618 09:08:27.267699  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 09:08:27.267726  8058 solver.cpp:237]     Train net output #1: loss = 0.00734655 (* 1 = 0.00734655 loss)
I0618 09:08:27.267742  8058 sgd_solver.cpp:105] Iteration 53350, lr = 0.001
I0618 09:09:25.020678  8058 solver.cpp:218] Iteration 53400 (0.865763 iter/s, 57.7525s/50 iters), loss = 0.00666623
I0618 09:09:25.020794  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 09:09:25.020822  8058 solver.cpp:237]     Train net output #1: loss = 0.00666626 (* 1 = 0.00666626 loss)
I0618 09:09:25.020838  8058 sgd_solver.cpp:105] Iteration 53400, lr = 0.001
I0618 09:10:22.774953  8058 solver.cpp:218] Iteration 53450 (0.865745 iter/s, 57.7537s/50 iters), loss = 0.0062836
I0618 09:10:22.775075  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 09:10:22.775108  8058 solver.cpp:237]     Train net output #1: loss = 0.00628363 (* 1 = 0.00628363 loss)
I0618 09:10:22.775127  8058 sgd_solver.cpp:105] Iteration 53450, lr = 0.001
I0618 09:10:36.724989  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 09:11:20.537179  8058 solver.cpp:218] Iteration 53500 (0.865626 iter/s, 57.7617s/50 iters), loss = 0.00553556
I0618 09:11:20.537276  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 09:11:20.537303  8058 solver.cpp:237]     Train net output #1: loss = 0.00553559 (* 1 = 0.00553559 loss)
I0618 09:11:20.537319  8058 sgd_solver.cpp:105] Iteration 53500, lr = 0.001
I0618 09:12:18.343744  8058 solver.cpp:218] Iteration 53550 (0.864962 iter/s, 57.806s/50 iters), loss = 0.00608343
I0618 09:12:18.343859  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 09:12:18.343886  8058 solver.cpp:237]     Train net output #1: loss = 0.00608346 (* 1 = 0.00608346 loss)
I0618 09:12:18.343904  8058 sgd_solver.cpp:105] Iteration 53550, lr = 0.001
I0618 09:12:55.372097  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 09:13:16.101701  8058 solver.cpp:218] Iteration 53600 (0.86569 iter/s, 57.7574s/50 iters), loss = 0.00552413
I0618 09:13:16.101778  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 09:13:16.101804  8058 solver.cpp:237]     Train net output #1: loss = 0.00552416 (* 1 = 0.00552416 loss)
I0618 09:13:16.101821  8058 sgd_solver.cpp:105] Iteration 53600, lr = 0.001
I0618 09:14:13.857468  8058 solver.cpp:218] Iteration 53650 (0.865722 iter/s, 57.7552s/50 iters), loss = 0.0100233
I0618 09:14:13.857614  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 09:14:13.857643  8058 solver.cpp:237]     Train net output #1: loss = 0.0100233 (* 1 = 0.0100233 loss)
I0618 09:14:13.857661  8058 sgd_solver.cpp:105] Iteration 53650, lr = 0.001
I0618 09:15:11.623371  8058 solver.cpp:218] Iteration 53700 (0.865571 iter/s, 57.7653s/50 iters), loss = 0.00710184
I0618 09:15:11.623457  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 09:15:11.623484  8058 solver.cpp:237]     Train net output #1: loss = 0.00710187 (* 1 = 0.00710187 loss)
I0618 09:15:11.623512  8058 sgd_solver.cpp:105] Iteration 53700, lr = 0.001
I0618 09:15:13.990944  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 09:16:09.394929  8058 solver.cpp:218] Iteration 53750 (0.865486 iter/s, 57.771s/50 iters), loss = 0.00705282
I0618 09:16:09.395042  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 09:16:09.395071  8058 solver.cpp:237]     Train net output #1: loss = 0.00705285 (* 1 = 0.00705285 loss)
I0618 09:16:09.395088  8058 sgd_solver.cpp:105] Iteration 53750, lr = 0.001
I0618 09:17:07.155535  8058 solver.cpp:218] Iteration 53800 (0.86565 iter/s, 57.76s/50 iters), loss = 0.00789039
I0618 09:17:07.155653  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 09:17:07.155681  8058 solver.cpp:237]     Train net output #1: loss = 0.00789042 (* 1 = 0.00789042 loss)
I0618 09:17:07.155699  8058 sgd_solver.cpp:105] Iteration 53800, lr = 0.001
I0618 09:17:32.631639  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 09:18:04.927011  8058 solver.cpp:218] Iteration 53850 (0.865488 iter/s, 57.7709s/50 iters), loss = 0.00571132
I0618 09:18:04.927178  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 09:18:04.927213  8058 solver.cpp:237]     Train net output #1: loss = 0.00571136 (* 1 = 0.00571136 loss)
I0618 09:18:04.927232  8058 sgd_solver.cpp:105] Iteration 53850, lr = 0.001
I0618 09:19:02.683028  8058 solver.cpp:218] Iteration 53900 (0.86572 iter/s, 57.7554s/50 iters), loss = 0.00720697
I0618 09:19:02.683151  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 09:19:02.683179  8058 solver.cpp:237]     Train net output #1: loss = 0.007207 (* 1 = 0.007207 loss)
I0618 09:19:02.683197  8058 sgd_solver.cpp:105] Iteration 53900, lr = 0.001
I0618 09:19:50.135610  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 09:20:00.446043  8058 solver.cpp:218] Iteration 53950 (0.865615 iter/s, 57.7624s/50 iters), loss = 0.00622558
I0618 09:20:00.446120  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 09:20:00.446146  8058 solver.cpp:237]     Train net output #1: loss = 0.00622561 (* 1 = 0.00622561 loss)
I0618 09:20:00.446162  8058 sgd_solver.cpp:105] Iteration 53950, lr = 0.001
I0618 09:20:58.208617  8058 solver.cpp:218] Iteration 54000 (0.86562 iter/s, 57.762s/50 iters), loss = 0.00649134
I0618 09:20:58.208736  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 09:20:58.208768  8058 solver.cpp:237]     Train net output #1: loss = 0.00649138 (* 1 = 0.00649138 loss)
I0618 09:20:58.208787  8058 sgd_solver.cpp:105] Iteration 54000, lr = 0.001
I0618 09:21:55.970369  8058 solver.cpp:218] Iteration 54050 (0.865633 iter/s, 57.7612s/50 iters), loss = 0.00526317
I0618 09:21:55.970489  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 09:21:55.970525  8058 solver.cpp:237]     Train net output #1: loss = 0.0052632 (* 1 = 0.0052632 loss)
I0618 09:21:55.970546  8058 sgd_solver.cpp:105] Iteration 54050, lr = 0.001
I0618 09:22:08.765871  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 09:22:53.733312  8058 solver.cpp:218] Iteration 54100 (0.865615 iter/s, 57.7624s/50 iters), loss = 0.00668063
I0618 09:22:53.733466  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 09:22:53.733495  8058 solver.cpp:237]     Train net output #1: loss = 0.00668067 (* 1 = 0.00668067 loss)
I0618 09:22:53.733511  8058 sgd_solver.cpp:105] Iteration 54100, lr = 0.001
I0618 09:23:51.487063  8058 solver.cpp:218] Iteration 54150 (0.865754 iter/s, 57.7531s/50 iters), loss = 0.00565796
I0618 09:23:51.487192  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 09:23:51.487221  8058 solver.cpp:237]     Train net output #1: loss = 0.005658 (* 1 = 0.005658 loss)
I0618 09:23:51.487238  8058 sgd_solver.cpp:105] Iteration 54150, lr = 0.001
I0618 09:24:27.366313  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 09:24:49.236383  8058 solver.cpp:218] Iteration 54200 (0.86582 iter/s, 57.7487s/50 iters), loss = 0.00676744
I0618 09:24:49.236471  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 09:24:49.236498  8058 solver.cpp:237]     Train net output #1: loss = 0.00676747 (* 1 = 0.00676747 loss)
I0618 09:24:49.236519  8058 sgd_solver.cpp:105] Iteration 54200, lr = 0.001
I0618 09:25:47.001109  8058 solver.cpp:218] Iteration 54250 (0.865588 iter/s, 57.7642s/50 iters), loss = 0.00644332
I0618 09:25:47.001258  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 09:25:47.001293  8058 solver.cpp:237]     Train net output #1: loss = 0.00644336 (* 1 = 0.00644336 loss)
I0618 09:25:47.001314  8058 sgd_solver.cpp:105] Iteration 54250, lr = 0.001
I0618 09:26:44.760485  8058 solver.cpp:218] Iteration 54300 (0.865669 iter/s, 57.7588s/50 iters), loss = 0.00513037
I0618 09:26:44.760608  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 09:26:44.760637  8058 solver.cpp:237]     Train net output #1: loss = 0.00513041 (* 1 = 0.00513041 loss)
I0618 09:26:44.760653  8058 sgd_solver.cpp:105] Iteration 54300, lr = 0.001
I0618 09:26:45.990103  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 09:27:42.528504  8058 solver.cpp:218] Iteration 54350 (0.865539 iter/s, 57.7674s/50 iters), loss = 0.00820828
I0618 09:27:42.528638  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 09:27:42.528667  8058 solver.cpp:237]     Train net output #1: loss = 0.00820831 (* 1 = 0.00820831 loss)
I0618 09:27:42.528684  8058 sgd_solver.cpp:105] Iteration 54350, lr = 0.001
I0618 09:28:40.292182  8058 solver.cpp:218] Iteration 54400 (0.865605 iter/s, 57.7631s/50 iters), loss = 0.00996785
I0618 09:28:40.292301  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 09:28:40.292333  8058 solver.cpp:237]     Train net output #1: loss = 0.00996788 (* 1 = 0.00996788 loss)
I0618 09:28:40.292353  8058 sgd_solver.cpp:105] Iteration 54400, lr = 0.001
I0618 09:29:04.624207  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 09:29:38.086426  8058 solver.cpp:218] Iteration 54450 (0.865147 iter/s, 57.7937s/50 iters), loss = 0.00592442
I0618 09:29:38.086560  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 09:29:38.086589  8058 solver.cpp:237]     Train net output #1: loss = 0.00592445 (* 1 = 0.00592445 loss)
I0618 09:29:38.086607  8058 sgd_solver.cpp:105] Iteration 54450, lr = 0.001
I0618 09:30:35.876669  8058 solver.cpp:218] Iteration 54500 (0.865207 iter/s, 57.7896s/50 iters), loss = 0.00436342
I0618 09:30:35.876844  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 09:30:35.876873  8058 solver.cpp:237]     Train net output #1: loss = 0.00436346 (* 1 = 0.00436346 loss)
I0618 09:30:35.876889  8058 sgd_solver.cpp:105] Iteration 54500, lr = 0.001
I0618 09:31:23.309207  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 09:31:33.660207  8058 solver.cpp:218] Iteration 54550 (0.865308 iter/s, 57.7829s/50 iters), loss = 0.00603734
I0618 09:31:33.660321  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 09:31:33.660349  8058 solver.cpp:237]     Train net output #1: loss = 0.00603738 (* 1 = 0.00603738 loss)
I0618 09:31:33.660367  8058 sgd_solver.cpp:105] Iteration 54550, lr = 0.001
I0618 09:32:31.439363  8058 solver.cpp:218] Iteration 54600 (0.865373 iter/s, 57.7785s/50 iters), loss = 0.00532956
I0618 09:32:31.439510  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 09:32:31.439553  8058 solver.cpp:237]     Train net output #1: loss = 0.00532959 (* 1 = 0.00532959 loss)
I0618 09:32:31.439574  8058 sgd_solver.cpp:105] Iteration 54600, lr = 0.001
I0618 09:33:29.229143  8058 solver.cpp:218] Iteration 54650 (0.865214 iter/s, 57.7892s/50 iters), loss = 0.00583636
I0618 09:33:29.229279  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 09:33:29.229308  8058 solver.cpp:237]     Train net output #1: loss = 0.00583639 (* 1 = 0.00583639 loss)
I0618 09:33:29.229326  8058 sgd_solver.cpp:105] Iteration 54650, lr = 0.001
I0618 09:33:42.001838  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 09:34:27.020730  8058 solver.cpp:218] Iteration 54700 (0.865187 iter/s, 57.791s/50 iters), loss = 0.00696997
I0618 09:34:27.020884  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 09:34:27.020912  8058 solver.cpp:237]     Train net output #1: loss = 0.00697 (* 1 = 0.00697 loss)
I0618 09:34:27.020929  8058 sgd_solver.cpp:105] Iteration 54700, lr = 0.001
I0618 09:35:24.801952  8058 solver.cpp:218] Iteration 54750 (0.865342 iter/s, 57.7806s/50 iters), loss = 0.00634204
I0618 09:35:24.802179  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 09:35:24.802207  8058 solver.cpp:237]     Train net output #1: loss = 0.00634207 (* 1 = 0.00634207 loss)
I0618 09:35:24.802225  8058 sgd_solver.cpp:105] Iteration 54750, lr = 0.001
I0618 09:36:00.689321  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 09:36:22.594557  8058 solver.cpp:218] Iteration 54800 (0.865173 iter/s, 57.7919s/50 iters), loss = 0.00665851
I0618 09:36:22.594667  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 09:36:22.594696  8058 solver.cpp:237]     Train net output #1: loss = 0.00665854 (* 1 = 0.00665854 loss)
I0618 09:36:22.594712  8058 sgd_solver.cpp:105] Iteration 54800, lr = 0.001
I0618 09:37:20.394574  8058 solver.cpp:218] Iteration 54850 (0.865061 iter/s, 57.7994s/50 iters), loss = 0.00532768
I0618 09:37:20.394690  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 09:37:20.394717  8058 solver.cpp:237]     Train net output #1: loss = 0.00532771 (* 1 = 0.00532771 loss)
I0618 09:37:20.394735  8058 sgd_solver.cpp:105] Iteration 54850, lr = 0.001
I0618 09:38:18.180752  8058 solver.cpp:218] Iteration 54900 (0.86527 iter/s, 57.7854s/50 iters), loss = 0.00710011
I0618 09:38:18.180915  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 09:38:18.180944  8058 solver.cpp:237]     Train net output #1: loss = 0.00710014 (* 1 = 0.00710014 loss)
I0618 09:38:18.180960  8058 sgd_solver.cpp:105] Iteration 54900, lr = 0.001
I0618 09:38:19.402267  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 09:39:15.953824  8058 solver.cpp:218] Iteration 54950 (0.865467 iter/s, 57.7723s/50 iters), loss = 0.00554157
I0618 09:39:15.953939  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 09:39:15.953966  8058 solver.cpp:237]     Train net output #1: loss = 0.00554161 (* 1 = 0.00554161 loss)
I0618 09:39:15.953984  8058 sgd_solver.cpp:105] Iteration 54950, lr = 0.001
I0618 09:40:13.720052  8058 solver.cpp:218] Iteration 55000 (0.865568 iter/s, 57.7655s/50 iters), loss = 0.00670446
I0618 09:40:13.720175  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 09:40:13.720203  8058 solver.cpp:237]     Train net output #1: loss = 0.00670449 (* 1 = 0.00670449 loss)
I0618 09:40:13.720219  8058 sgd_solver.cpp:105] Iteration 55000, lr = 0.001
I0618 09:40:36.909356  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 09:41:11.490656  8058 solver.cpp:218] Iteration 55050 (0.865503 iter/s, 57.7699s/50 iters), loss = 0.00516725
I0618 09:41:11.490823  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 09:41:11.490852  8058 solver.cpp:237]     Train net output #1: loss = 0.00516729 (* 1 = 0.00516729 loss)
I0618 09:41:11.490870  8058 sgd_solver.cpp:105] Iteration 55050, lr = 0.001
I0618 09:42:09.249284  8058 solver.cpp:218] Iteration 55100 (0.865683 iter/s, 57.7579s/50 iters), loss = 0.00673363
I0618 09:42:09.249408  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 09:42:09.249435  8058 solver.cpp:237]     Train net output #1: loss = 0.00673367 (* 1 = 0.00673367 loss)
I0618 09:42:09.249452  8058 sgd_solver.cpp:105] Iteration 55100, lr = 0.001
I0618 09:42:55.547683  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 09:43:06.999469  8058 solver.cpp:218] Iteration 55150 (0.865809 iter/s, 57.7495s/50 iters), loss = 0.00541792
I0618 09:43:06.999550  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 09:43:06.999578  8058 solver.cpp:237]     Train net output #1: loss = 0.00541795 (* 1 = 0.00541795 loss)
I0618 09:43:06.999608  8058 sgd_solver.cpp:105] Iteration 55150, lr = 0.001
I0618 09:44:04.759076  8058 solver.cpp:218] Iteration 55200 (0.865667 iter/s, 57.7589s/50 iters), loss = 0.00738618
I0618 09:44:04.759199  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 09:44:04.759227  8058 solver.cpp:237]     Train net output #1: loss = 0.00738621 (* 1 = 0.00738621 loss)
I0618 09:44:04.759243  8058 sgd_solver.cpp:105] Iteration 55200, lr = 0.001
I0618 09:45:02.517535  8058 solver.cpp:218] Iteration 55250 (0.865685 iter/s, 57.7577s/50 iters), loss = 0.00629839
I0618 09:45:02.517658  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 09:45:02.517691  8058 solver.cpp:237]     Train net output #1: loss = 0.00629842 (* 1 = 0.00629842 loss)
I0618 09:45:02.517711  8058 sgd_solver.cpp:105] Iteration 55250, lr = 0.001
I0618 09:45:14.156772  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 09:46:00.278048  8058 solver.cpp:218] Iteration 55300 (0.865654 iter/s, 57.7598s/50 iters), loss = 0.00713179
I0618 09:46:00.278173  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 09:46:00.278203  8058 solver.cpp:237]     Train net output #1: loss = 0.00713182 (* 1 = 0.00713182 loss)
I0618 09:46:00.278218  8058 sgd_solver.cpp:105] Iteration 55300, lr = 0.001
I0618 09:46:58.038240  8058 solver.cpp:218] Iteration 55350 (0.865659 iter/s, 57.7595s/50 iters), loss = 0.00553159
I0618 09:46:58.038353  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 09:46:58.038381  8058 solver.cpp:237]     Train net output #1: loss = 0.00553163 (* 1 = 0.00553163 loss)
I0618 09:46:58.038399  8058 sgd_solver.cpp:105] Iteration 55350, lr = 0.001
I0618 09:47:32.788602  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 09:47:55.804648  8058 solver.cpp:218] Iteration 55400 (0.865566 iter/s, 57.7657s/50 iters), loss = 0.00626144
I0618 09:47:55.804730  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 09:47:55.804761  8058 solver.cpp:237]     Train net output #1: loss = 0.00626148 (* 1 = 0.00626148 loss)
I0618 09:47:55.804781  8058 sgd_solver.cpp:105] Iteration 55400, lr = 0.001
I0618 09:48:53.561595  8058 solver.cpp:218] Iteration 55450 (0.865707 iter/s, 57.7563s/50 iters), loss = 0.00671033
I0618 09:48:53.561712  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 09:48:53.561739  8058 solver.cpp:237]     Train net output #1: loss = 0.00671036 (* 1 = 0.00671036 loss)
I0618 09:48:53.561758  8058 sgd_solver.cpp:105] Iteration 55450, lr = 0.001
I0618 09:49:51.325424  8058 solver.cpp:218] Iteration 55500 (0.865604 iter/s, 57.7631s/50 iters), loss = 0.00591096
I0618 09:49:51.325547  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 09:49:51.325577  8058 solver.cpp:237]     Train net output #1: loss = 0.00591099 (* 1 = 0.00591099 loss)
I0618 09:49:51.325593  8058 sgd_solver.cpp:105] Iteration 55500, lr = 0.001
I0618 09:49:51.389545  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 09:50:49.126479  8058 solver.cpp:218] Iteration 55550 (0.865047 iter/s, 57.8003s/50 iters), loss = 0.00751047
I0618 09:50:49.126677  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 09:50:49.126706  8058 solver.cpp:237]     Train net output #1: loss = 0.0075105 (* 1 = 0.0075105 loss)
I0618 09:50:49.126724  8058 sgd_solver.cpp:105] Iteration 55550, lr = 0.001
I0618 09:51:46.895004  8058 solver.cpp:218] Iteration 55600 (0.865535 iter/s, 57.7677s/50 iters), loss = 0.00821898
I0618 09:51:46.895156  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 09:51:46.895186  8058 solver.cpp:237]     Train net output #1: loss = 0.00821901 (* 1 = 0.00821901 loss)
I0618 09:51:46.895203  8058 sgd_solver.cpp:105] Iteration 55600, lr = 0.001
I0618 09:52:10.081364  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 09:52:44.704401  8058 solver.cpp:218] Iteration 55650 (0.864923 iter/s, 57.8086s/50 iters), loss = 0.00453723
I0618 09:52:44.704573  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 09:52:44.704622  8058 solver.cpp:237]     Train net output #1: loss = 0.00453726 (* 1 = 0.00453726 loss)
I0618 09:52:44.704641  8058 sgd_solver.cpp:105] Iteration 55650, lr = 0.001
I0618 09:53:42.484408  8058 solver.cpp:218] Iteration 55700 (0.865363 iter/s, 57.7792s/50 iters), loss = 0.00615954
I0618 09:53:42.484592  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 09:53:42.484632  8058 solver.cpp:237]     Train net output #1: loss = 0.00615957 (* 1 = 0.00615957 loss)
I0618 09:53:42.484653  8058 sgd_solver.cpp:105] Iteration 55700, lr = 0.001
I0618 09:54:28.777345  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 09:54:40.280817  8058 solver.cpp:218] Iteration 55750 (0.865118 iter/s, 57.7956s/50 iters), loss = 0.00590421
I0618 09:54:40.280923  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 09:54:40.280951  8058 solver.cpp:237]     Train net output #1: loss = 0.00590424 (* 1 = 0.00590424 loss)
I0618 09:54:40.280968  8058 sgd_solver.cpp:105] Iteration 55750, lr = 0.001
I0618 09:55:38.061764  8058 solver.cpp:218] Iteration 55800 (0.865348 iter/s, 57.7802s/50 iters), loss = 0.00473282
I0618 09:55:38.061882  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 09:55:38.061910  8058 solver.cpp:237]     Train net output #1: loss = 0.00473285 (* 1 = 0.00473285 loss)
I0618 09:55:38.061926  8058 sgd_solver.cpp:105] Iteration 55800, lr = 0.001
I0618 09:56:35.828990  8058 solver.cpp:218] Iteration 55850 (0.865554 iter/s, 57.7665s/50 iters), loss = 0.0062121
I0618 09:56:35.829133  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 09:56:35.829164  8058 solver.cpp:237]     Train net output #1: loss = 0.00621214 (* 1 = 0.00621214 loss)
I0618 09:56:35.829182  8058 sgd_solver.cpp:105] Iteration 55850, lr = 0.001
I0618 09:56:47.434454  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 09:57:33.619078  8058 solver.cpp:218] Iteration 55900 (0.865213 iter/s, 57.7893s/50 iters), loss = 0.00798705
I0618 09:57:33.619230  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 09:57:33.619267  8058 solver.cpp:237]     Train net output #1: loss = 0.00798708 (* 1 = 0.00798708 loss)
I0618 09:57:33.619285  8058 sgd_solver.cpp:105] Iteration 55900, lr = 0.001
I0618 09:58:31.393517  8058 solver.cpp:218] Iteration 55950 (0.865447 iter/s, 57.7736s/50 iters), loss = 0.0055831
I0618 09:58:31.393652  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 09:58:31.393682  8058 solver.cpp:237]     Train net output #1: loss = 0.00558313 (* 1 = 0.00558313 loss)
I0618 09:58:31.393700  8058 sgd_solver.cpp:105] Iteration 55950, lr = 0.001
I0618 09:59:05.003830  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 09:59:29.152776  8058 solver.cpp:218] Iteration 56000 (0.865673 iter/s, 57.7585s/50 iters), loss = 0.00670668
I0618 09:59:29.152853  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 09:59:29.152878  8058 solver.cpp:237]     Train net output #1: loss = 0.00670671 (* 1 = 0.00670671 loss)
I0618 09:59:29.152894  8058 sgd_solver.cpp:105] Iteration 56000, lr = 0.001
I0618 10:00:26.927500  8058 solver.cpp:218] Iteration 56050 (0.865442 iter/s, 57.774s/50 iters), loss = 0.00769983
I0618 10:00:26.927682  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 10:00:26.927731  8058 solver.cpp:237]     Train net output #1: loss = 0.00769986 (* 1 = 0.00769986 loss)
I0618 10:00:26.927757  8058 sgd_solver.cpp:105] Iteration 56050, lr = 0.001
I0618 10:01:23.611629  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 10:01:24.682708  8058 solver.cpp:218] Iteration 56100 (0.865735 iter/s, 57.7544s/50 iters), loss = 0.00602433
I0618 10:01:24.682793  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 10:01:24.682821  8058 solver.cpp:237]     Train net output #1: loss = 0.00602436 (* 1 = 0.00602436 loss)
I0618 10:01:24.682837  8058 sgd_solver.cpp:105] Iteration 56100, lr = 0.001
I0618 10:02:22.449240  8058 solver.cpp:218] Iteration 56150 (0.865564 iter/s, 57.7658s/50 iters), loss = 0.00720466
I0618 10:02:22.449393  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 10:02:22.449422  8058 solver.cpp:237]     Train net output #1: loss = 0.00720469 (* 1 = 0.00720469 loss)
I0618 10:02:22.449440  8058 sgd_solver.cpp:105] Iteration 56150, lr = 0.001
I0618 10:03:20.211369  8058 solver.cpp:218] Iteration 56200 (0.865631 iter/s, 57.7614s/50 iters), loss = 0.00790812
I0618 10:03:20.211480  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 10:03:20.211509  8058 solver.cpp:237]     Train net output #1: loss = 0.00790815 (* 1 = 0.00790815 loss)
I0618 10:03:20.211534  8058 sgd_solver.cpp:105] Iteration 56200, lr = 0.001
I0618 10:03:42.259497  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 10:04:17.963603  8058 solver.cpp:218] Iteration 56250 (0.865778 iter/s, 57.7515s/50 iters), loss = 0.00702229
I0618 10:04:17.963740  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 10:04:17.963769  8058 solver.cpp:237]     Train net output #1: loss = 0.00702233 (* 1 = 0.00702233 loss)
I0618 10:04:17.963791  8058 sgd_solver.cpp:105] Iteration 56250, lr = 0.001
I0618 10:05:15.734544  8058 solver.cpp:218] Iteration 56300 (0.865498 iter/s, 57.7702s/50 iters), loss = 0.00551005
I0618 10:05:15.734676  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 10:05:15.734705  8058 solver.cpp:237]     Train net output #1: loss = 0.00551008 (* 1 = 0.00551008 loss)
I0618 10:05:15.734722  8058 sgd_solver.cpp:105] Iteration 56300, lr = 0.001
I0618 10:06:00.867851  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 10:06:13.494559  8058 solver.cpp:218] Iteration 56350 (0.865662 iter/s, 57.7593s/50 iters), loss = 0.00469086
I0618 10:06:13.494634  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 10:06:13.494662  8058 solver.cpp:237]     Train net output #1: loss = 0.00469089 (* 1 = 0.00469089 loss)
I0618 10:06:13.494678  8058 sgd_solver.cpp:105] Iteration 56350, lr = 0.001
I0618 10:07:11.260043  8058 solver.cpp:218] Iteration 56400 (0.865579 iter/s, 57.7648s/50 iters), loss = 0.00813
I0618 10:07:11.260207  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 10:07:11.260236  8058 solver.cpp:237]     Train net output #1: loss = 0.00813003 (* 1 = 0.00813003 loss)
I0618 10:07:11.260252  8058 sgd_solver.cpp:105] Iteration 56400, lr = 0.001
I0618 10:08:09.042141  8058 solver.cpp:218] Iteration 56450 (0.865332 iter/s, 57.7813s/50 iters), loss = 0.00465609
I0618 10:08:09.042281  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 10:08:09.042310  8058 solver.cpp:237]     Train net output #1: loss = 0.00465612 (* 1 = 0.00465612 loss)
I0618 10:08:09.042328  8058 sgd_solver.cpp:105] Iteration 56450, lr = 0.001
I0618 10:08:19.529387  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 10:09:06.807561  8058 solver.cpp:218] Iteration 56500 (0.865581 iter/s, 57.7647s/50 iters), loss = 0.00493236
I0618 10:09:06.807976  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 10:09:06.808006  8058 solver.cpp:237]     Train net output #1: loss = 0.00493239 (* 1 = 0.00493239 loss)
I0618 10:09:06.808022  8058 sgd_solver.cpp:105] Iteration 56500, lr = 0.001
I0618 10:10:04.566035  8058 solver.cpp:218] Iteration 56550 (0.865689 iter/s, 57.7575s/50 iters), loss = 0.00650889
I0618 10:10:04.567234  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 10:10:04.567262  8058 solver.cpp:237]     Train net output #1: loss = 0.00650892 (* 1 = 0.00650892 loss)
I0618 10:10:04.567281  8058 sgd_solver.cpp:105] Iteration 56550, lr = 0.001
I0618 10:10:38.136903  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 10:11:02.325533  8058 solver.cpp:218] Iteration 56600 (0.865686 iter/s, 57.7577s/50 iters), loss = 0.00538767
I0618 10:11:02.325620  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 10:11:02.325647  8058 solver.cpp:237]     Train net output #1: loss = 0.00538771 (* 1 = 0.00538771 loss)
I0618 10:11:02.325664  8058 sgd_solver.cpp:105] Iteration 56600, lr = 0.001
I0618 10:12:00.071311  8058 solver.cpp:218] Iteration 56650 (0.865874 iter/s, 57.7451s/50 iters), loss = 0.00699427
I0618 10:12:00.071426  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 10:12:00.071455  8058 solver.cpp:237]     Train net output #1: loss = 0.0069943 (* 1 = 0.0069943 loss)
I0618 10:12:00.071471  8058 sgd_solver.cpp:105] Iteration 56650, lr = 0.001
I0618 10:12:56.736047  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 10:12:57.825477  8058 solver.cpp:218] Iteration 56700 (0.865749 iter/s, 57.7535s/50 iters), loss = 0.00644124
I0618 10:12:57.825561  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 10:12:57.825592  8058 solver.cpp:237]     Train net output #1: loss = 0.00644128 (* 1 = 0.00644128 loss)
I0618 10:12:57.825613  8058 sgd_solver.cpp:105] Iteration 56700, lr = 0.001
I0618 10:13:55.576973  8058 solver.cpp:218] Iteration 56750 (0.865788 iter/s, 57.7508s/50 iters), loss = 0.00812785
I0618 10:13:55.577093  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 10:13:55.577121  8058 solver.cpp:237]     Train net output #1: loss = 0.00812788 (* 1 = 0.00812788 loss)
I0618 10:13:55.577139  8058 sgd_solver.cpp:105] Iteration 56750, lr = 0.001
I0618 10:14:53.339336  8058 solver.cpp:218] Iteration 56800 (0.865626 iter/s, 57.7617s/50 iters), loss = 0.00599617
I0618 10:14:53.339453  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 10:14:53.339481  8058 solver.cpp:237]     Train net output #1: loss = 0.0059962 (* 1 = 0.0059962 loss)
I0618 10:14:53.339498  8058 sgd_solver.cpp:105] Iteration 56800, lr = 0.001
I0618 10:15:15.367291  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 10:15:51.107486  8058 solver.cpp:218] Iteration 56850 (0.865539 iter/s, 57.7675s/50 iters), loss = 0.00748125
I0618 10:15:51.107597  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 10:15:51.107625  8058 solver.cpp:237]     Train net output #1: loss = 0.00748128 (* 1 = 0.00748128 loss)
I0618 10:15:51.107643  8058 sgd_solver.cpp:105] Iteration 56850, lr = 0.001
I0618 10:16:48.866101  8058 solver.cpp:218] Iteration 56900 (0.865683 iter/s, 57.7579s/50 iters), loss = 0.00571871
I0618 10:16:48.866268  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 10:16:48.866304  8058 solver.cpp:237]     Train net output #1: loss = 0.00571874 (* 1 = 0.00571874 loss)
I0618 10:16:48.866324  8058 sgd_solver.cpp:105] Iteration 56900, lr = 0.001
I0618 10:17:32.846812  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 10:17:46.632678  8058 solver.cpp:218] Iteration 56950 (0.865563 iter/s, 57.7658s/50 iters), loss = 0.0067214
I0618 10:17:46.632763  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 10:17:46.632791  8058 solver.cpp:237]     Train net output #1: loss = 0.00672144 (* 1 = 0.00672144 loss)
I0618 10:17:46.632807  8058 sgd_solver.cpp:105] Iteration 56950, lr = 0.001
I0618 10:18:44.402554  8058 solver.cpp:218] Iteration 57000 (0.865513 iter/s, 57.7692s/50 iters), loss = 0.00559541
I0618 10:18:44.402707  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 10:18:44.402739  8058 solver.cpp:237]     Train net output #1: loss = 0.00559544 (* 1 = 0.00559544 loss)
I0618 10:18:44.402755  8058 sgd_solver.cpp:105] Iteration 57000, lr = 0.001
I0618 10:19:42.182490  8058 solver.cpp:218] Iteration 57050 (0.865363 iter/s, 57.7792s/50 iters), loss = 0.00493945
I0618 10:19:42.182662  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 10:19:42.182690  8058 solver.cpp:237]     Train net output #1: loss = 0.00493949 (* 1 = 0.00493949 loss)
I0618 10:19:42.182708  8058 sgd_solver.cpp:105] Iteration 57050, lr = 0.001
I0618 10:19:51.505287  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 10:20:39.971451  8058 solver.cpp:218] Iteration 57100 (0.865229 iter/s, 57.7882s/50 iters), loss = 0.0065194
I0618 10:20:39.971621  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 10:20:39.971650  8058 solver.cpp:237]     Train net output #1: loss = 0.00651943 (* 1 = 0.00651943 loss)
I0618 10:20:39.971683  8058 sgd_solver.cpp:105] Iteration 57100, lr = 0.001
I0618 10:21:37.765045  8058 solver.cpp:218] Iteration 57150 (0.865159 iter/s, 57.7928s/50 iters), loss = 0.00703677
I0618 10:21:37.765202  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 10:21:37.765230  8058 solver.cpp:237]     Train net output #1: loss = 0.00703681 (* 1 = 0.00703681 loss)
I0618 10:21:37.765247  8058 sgd_solver.cpp:105] Iteration 57150, lr = 0.001
I0618 10:22:10.202783  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 10:22:35.557684  8058 solver.cpp:218] Iteration 57200 (0.865173 iter/s, 57.7919s/50 iters), loss = 0.0045981
I0618 10:22:35.557799  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 10:22:35.557827  8058 solver.cpp:237]     Train net output #1: loss = 0.00459813 (* 1 = 0.00459813 loss)
I0618 10:22:35.557844  8058 sgd_solver.cpp:105] Iteration 57200, lr = 0.001
I0618 10:23:33.351423  8058 solver.cpp:218] Iteration 57250 (0.865156 iter/s, 57.793s/50 iters), loss = 0.00640026
I0618 10:23:33.351603  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 10:23:33.351632  8058 solver.cpp:237]     Train net output #1: loss = 0.00640029 (* 1 = 0.00640029 loss)
I0618 10:23:33.351649  8058 sgd_solver.cpp:105] Iteration 57250, lr = 0.001
I0618 10:24:28.895246  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 10:24:31.130897  8058 solver.cpp:218] Iteration 57300 (0.86537 iter/s, 57.7787s/50 iters), loss = 0.0063455
I0618 10:24:31.130973  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 10:24:31.131000  8058 solver.cpp:237]     Train net output #1: loss = 0.00634554 (* 1 = 0.00634554 loss)
I0618 10:24:31.131016  8058 sgd_solver.cpp:105] Iteration 57300, lr = 0.001
I0618 10:25:28.919221  8058 solver.cpp:218] Iteration 57350 (0.865237 iter/s, 57.7877s/50 iters), loss = 0.0070458
I0618 10:25:28.919379  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 10:25:28.919409  8058 solver.cpp:237]     Train net output #1: loss = 0.00704583 (* 1 = 0.00704583 loss)
I0618 10:25:28.919427  8058 sgd_solver.cpp:105] Iteration 57350, lr = 0.001
I0618 10:26:26.715065  8058 solver.cpp:218] Iteration 57400 (0.865125 iter/s, 57.7951s/50 iters), loss = 0.00648573
I0618 10:26:26.715221  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 10:26:26.715250  8058 solver.cpp:237]     Train net output #1: loss = 0.00648577 (* 1 = 0.00648577 loss)
I0618 10:26:26.715267  8058 sgd_solver.cpp:105] Iteration 57400, lr = 0.001
I0618 10:26:47.581568  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 10:27:24.500648  8058 solver.cpp:218] Iteration 57450 (0.865279 iter/s, 57.7849s/50 iters), loss = 0.00713428
I0618 10:27:24.500790  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 10:27:24.500820  8058 solver.cpp:237]     Train net output #1: loss = 0.00713431 (* 1 = 0.00713431 loss)
I0618 10:27:24.500843  8058 sgd_solver.cpp:105] Iteration 57450, lr = 0.001
I0618 10:28:22.296886  8058 solver.cpp:218] Iteration 57500 (0.865119 iter/s, 57.7955s/50 iters), loss = 0.00613635
I0618 10:28:22.297188  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 10:28:22.297217  8058 solver.cpp:237]     Train net output #1: loss = 0.00613638 (* 1 = 0.00613638 loss)
I0618 10:28:22.297233  8058 sgd_solver.cpp:105] Iteration 57500, lr = 0.001
I0618 10:29:06.290287  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 10:29:20.067785  8058 solver.cpp:218] Iteration 57550 (0.865501 iter/s, 57.77s/50 iters), loss = 0.00618339
I0618 10:29:20.067862  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 10:29:20.067889  8058 solver.cpp:237]     Train net output #1: loss = 0.00618342 (* 1 = 0.00618342 loss)
I0618 10:29:20.067906  8058 sgd_solver.cpp:105] Iteration 57550, lr = 0.001
I0618 10:30:17.842217  8058 solver.cpp:218] Iteration 57600 (0.865444 iter/s, 57.7738s/50 iters), loss = 0.00784635
I0618 10:30:17.842414  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 10:30:17.842455  8058 solver.cpp:237]     Train net output #1: loss = 0.00784639 (* 1 = 0.00784639 loss)
I0618 10:30:17.842473  8058 sgd_solver.cpp:105] Iteration 57600, lr = 0.001
I0618 10:31:15.609167  8058 solver.cpp:218] Iteration 57650 (0.865558 iter/s, 57.7662s/50 iters), loss = 0.00565044
I0618 10:31:15.609289  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 10:31:15.609318  8058 solver.cpp:237]     Train net output #1: loss = 0.00565047 (* 1 = 0.00565047 loss)
I0618 10:31:15.609335  8058 sgd_solver.cpp:105] Iteration 57650, lr = 0.001
I0618 10:31:24.910532  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 10:32:13.361877  8058 solver.cpp:218] Iteration 57700 (0.865771 iter/s, 57.752s/50 iters), loss = 0.00544056
I0618 10:32:13.362022  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 10:32:13.362057  8058 solver.cpp:237]     Train net output #1: loss = 0.0054406 (* 1 = 0.0054406 loss)
I0618 10:32:13.362076  8058 sgd_solver.cpp:105] Iteration 57700, lr = 0.001
I0618 10:33:11.126807  8058 solver.cpp:218] Iteration 57750 (0.865588 iter/s, 57.7642s/50 iters), loss = 0.00749781
I0618 10:33:11.126924  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 10:33:11.126952  8058 solver.cpp:237]     Train net output #1: loss = 0.00749784 (* 1 = 0.00749784 loss)
I0618 10:33:11.126969  8058 sgd_solver.cpp:105] Iteration 57750, lr = 0.001
I0618 10:33:43.546913  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 10:34:08.883035  8058 solver.cpp:218] Iteration 57800 (0.865718 iter/s, 57.7556s/50 iters), loss = 0.00778173
I0618 10:34:08.883111  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 10:34:08.883137  8058 solver.cpp:237]     Train net output #1: loss = 0.00778177 (* 1 = 0.00778177 loss)
I0618 10:34:08.883152  8058 sgd_solver.cpp:105] Iteration 57800, lr = 0.001
I0618 10:35:06.647351  8058 solver.cpp:218] Iteration 57850 (0.865596 iter/s, 57.7637s/50 iters), loss = 0.00754232
I0618 10:35:06.647536  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 10:35:06.647567  8058 solver.cpp:237]     Train net output #1: loss = 0.00754235 (* 1 = 0.00754235 loss)
I0618 10:35:06.647584  8058 sgd_solver.cpp:105] Iteration 57850, lr = 0.001
I0618 10:36:02.136584  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 10:36:04.400070  8058 solver.cpp:218] Iteration 57900 (0.865771 iter/s, 57.752s/50 iters), loss = 0.00794691
I0618 10:36:04.400136  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 10:36:04.400161  8058 solver.cpp:237]     Train net output #1: loss = 0.00794695 (* 1 = 0.00794695 loss)
I0618 10:36:04.400177  8058 sgd_solver.cpp:105] Iteration 57900, lr = 0.001
I0618 10:37:02.145545  8058 solver.cpp:218] Iteration 57950 (0.865878 iter/s, 57.7449s/50 iters), loss = 0.00554943
I0618 10:37:02.146082  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 10:37:02.146111  8058 solver.cpp:237]     Train net output #1: loss = 0.00554946 (* 1 = 0.00554946 loss)
I0618 10:37:02.146129  8058 sgd_solver.cpp:105] Iteration 57950, lr = 0.001
I0618 10:37:59.900991  8058 solver.cpp:218] Iteration 58000 (0.865736 iter/s, 57.7544s/50 iters), loss = 0.00495638
I0618 10:37:59.901129  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 10:37:59.901159  8058 solver.cpp:237]     Train net output #1: loss = 0.00495641 (* 1 = 0.00495641 loss)
I0618 10:37:59.901175  8058 sgd_solver.cpp:105] Iteration 58000, lr = 0.001
I0618 10:38:19.646332  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 10:38:57.645004  8058 solver.cpp:218] Iteration 58050 (0.865901 iter/s, 57.7433s/50 iters), loss = 0.00723371
I0618 10:38:57.645128  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 10:38:57.645156  8058 solver.cpp:237]     Train net output #1: loss = 0.00723374 (* 1 = 0.00723374 loss)
I0618 10:38:57.645174  8058 sgd_solver.cpp:105] Iteration 58050, lr = 0.001
I0618 10:39:55.415366  8058 solver.cpp:218] Iteration 58100 (0.865506 iter/s, 57.7697s/50 iters), loss = 0.00814078
I0618 10:39:55.415494  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 10:39:55.415531  8058 solver.cpp:237]     Train net output #1: loss = 0.00814081 (* 1 = 0.00814081 loss)
I0618 10:39:55.415552  8058 sgd_solver.cpp:105] Iteration 58100, lr = 0.001
I0618 10:40:38.252979  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 10:40:53.169806  8058 solver.cpp:218] Iteration 58150 (0.865744 iter/s, 57.7538s/50 iters), loss = 0.0070002
I0618 10:40:53.169886  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 10:40:53.169912  8058 solver.cpp:237]     Train net output #1: loss = 0.00700023 (* 1 = 0.00700023 loss)
I0618 10:40:53.169930  8058 sgd_solver.cpp:105] Iteration 58150, lr = 0.001
I0618 10:41:50.914458  8058 solver.cpp:218] Iteration 58200 (0.865891 iter/s, 57.744s/50 iters), loss = 0.00665796
I0618 10:41:50.915062  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 10:41:50.915091  8058 solver.cpp:237]     Train net output #1: loss = 0.00665799 (* 1 = 0.00665799 loss)
I0618 10:41:50.915107  8058 sgd_solver.cpp:105] Iteration 58200, lr = 0.001
I0618 10:42:48.696107  8058 solver.cpp:218] Iteration 58250 (0.865344 iter/s, 57.7805s/50 iters), loss = 0.0069479
I0618 10:42:48.696228  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 10:42:48.696256  8058 solver.cpp:237]     Train net output #1: loss = 0.00694793 (* 1 = 0.00694793 loss)
I0618 10:42:48.696274  8058 sgd_solver.cpp:105] Iteration 58250, lr = 0.001
I0618 10:42:56.876401  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 10:43:46.449000  8058 solver.cpp:218] Iteration 58300 (0.865768 iter/s, 57.7522s/50 iters), loss = 0.00573518
I0618 10:43:46.449116  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 10:43:46.449148  8058 solver.cpp:237]     Train net output #1: loss = 0.00573521 (* 1 = 0.00573521 loss)
I0618 10:43:46.449168  8058 sgd_solver.cpp:105] Iteration 58300, lr = 0.001
I0618 10:44:44.207427  8058 solver.cpp:218] Iteration 58350 (0.865685 iter/s, 57.7578s/50 iters), loss = 0.00589516
I0618 10:44:44.207563  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 10:44:44.207592  8058 solver.cpp:237]     Train net output #1: loss = 0.00589519 (* 1 = 0.00589519 loss)
I0618 10:44:44.207610  8058 sgd_solver.cpp:105] Iteration 58350, lr = 0.001
I0618 10:45:15.470551  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 10:45:41.964689  8058 solver.cpp:218] Iteration 58400 (0.865702 iter/s, 57.7566s/50 iters), loss = 0.00512836
I0618 10:45:41.964769  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 10:45:41.964795  8058 solver.cpp:237]     Train net output #1: loss = 0.0051284 (* 1 = 0.0051284 loss)
I0618 10:45:41.964812  8058 sgd_solver.cpp:105] Iteration 58400, lr = 0.001
I0618 10:46:39.725919  8058 solver.cpp:218] Iteration 58450 (0.865642 iter/s, 57.7606s/50 iters), loss = 0.00642179
I0618 10:46:39.726079  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 10:46:39.726109  8058 solver.cpp:237]     Train net output #1: loss = 0.00642182 (* 1 = 0.00642182 loss)
I0618 10:46:39.726126  8058 sgd_solver.cpp:105] Iteration 58450, lr = 0.001
I0618 10:47:34.091223  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 10:47:37.494921  8058 solver.cpp:218] Iteration 58500 (0.865527 iter/s, 57.7683s/50 iters), loss = 0.00507515
I0618 10:47:37.495003  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 10:47:37.495033  8058 solver.cpp:237]     Train net output #1: loss = 0.00507519 (* 1 = 0.00507519 loss)
I0618 10:47:37.495054  8058 sgd_solver.cpp:105] Iteration 58500, lr = 0.001
I0618 10:48:35.253757  8058 solver.cpp:218] Iteration 58550 (0.865678 iter/s, 57.7582s/50 iters), loss = 0.0056084
I0618 10:48:35.253880  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 10:48:35.253909  8058 solver.cpp:237]     Train net output #1: loss = 0.00560843 (* 1 = 0.00560843 loss)
I0618 10:48:35.253926  8058 sgd_solver.cpp:105] Iteration 58550, lr = 0.001
I0618 10:49:33.050540  8058 solver.cpp:218] Iteration 58600 (0.86511 iter/s, 57.7961s/50 iters), loss = 0.00691862
I0618 10:49:33.050696  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 10:49:33.050725  8058 solver.cpp:237]     Train net output #1: loss = 0.00691865 (* 1 = 0.00691865 loss)
I0618 10:49:33.050742  8058 sgd_solver.cpp:105] Iteration 58600, lr = 0.001
I0618 10:49:52.764192  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 10:50:30.841825  8058 solver.cpp:218] Iteration 58650 (0.865193 iter/s, 57.7906s/50 iters), loss = 0.00840037
I0618 10:50:30.842082  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 10:50:30.842113  8058 solver.cpp:237]     Train net output #1: loss = 0.0084004 (* 1 = 0.0084004 loss)
I0618 10:50:30.842130  8058 sgd_solver.cpp:105] Iteration 58650, lr = 0.001
I0618 10:51:28.634865  8058 solver.cpp:218] Iteration 58700 (0.865168 iter/s, 57.7922s/50 iters), loss = 0.00570094
I0618 10:51:28.635035  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 10:51:28.635064  8058 solver.cpp:237]     Train net output #1: loss = 0.00570097 (* 1 = 0.00570097 loss)
I0618 10:51:28.635082  8058 sgd_solver.cpp:105] Iteration 58700, lr = 0.001
I0618 10:52:11.451239  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 10:52:26.430888  8058 solver.cpp:218] Iteration 58750 (0.865122 iter/s, 57.7953s/50 iters), loss = 0.00651897
I0618 10:52:26.430994  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 10:52:26.431021  8058 solver.cpp:237]     Train net output #1: loss = 0.006519 (* 1 = 0.006519 loss)
I0618 10:52:26.431040  8058 sgd_solver.cpp:105] Iteration 58750, lr = 0.001
I0618 10:53:24.235951  8058 solver.cpp:218] Iteration 58800 (0.864986 iter/s, 57.8044s/50 iters), loss = 0.00596992
I0618 10:53:24.236098  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 10:53:24.236126  8058 solver.cpp:237]     Train net output #1: loss = 0.00596995 (* 1 = 0.00596995 loss)
I0618 10:53:24.236142  8058 sgd_solver.cpp:105] Iteration 58800, lr = 0.001
I0618 10:54:22.036911  8058 solver.cpp:218] Iteration 58850 (0.865048 iter/s, 57.8002s/50 iters), loss = 0.00613604
I0618 10:54:22.037073  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 10:54:22.037108  8058 solver.cpp:237]     Train net output #1: loss = 0.00613608 (* 1 = 0.00613608 loss)
I0618 10:54:22.037129  8058 sgd_solver.cpp:105] Iteration 58850, lr = 0.001
I0618 10:54:30.179196  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 10:55:19.839507  8058 solver.cpp:218] Iteration 58900 (0.865024 iter/s, 57.8019s/50 iters), loss = 0.00942627
I0618 10:55:19.839668  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 10:55:19.839697  8058 solver.cpp:237]     Train net output #1: loss = 0.00942631 (* 1 = 0.00942631 loss)
I0618 10:55:19.839715  8058 sgd_solver.cpp:105] Iteration 58900, lr = 0.001
I0618 10:56:17.643697  8058 solver.cpp:218] Iteration 58950 (0.865 iter/s, 57.8035s/50 iters), loss = 0.00548625
I0618 10:56:17.643931  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 10:56:17.643962  8058 solver.cpp:237]     Train net output #1: loss = 0.00548628 (* 1 = 0.00548628 loss)
I0618 10:56:17.643980  8058 sgd_solver.cpp:105] Iteration 58950, lr = 0.001
I0618 10:56:47.779448  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 10:57:15.438789  8058 solver.cpp:218] Iteration 59000 (0.865137 iter/s, 57.7943s/50 iters), loss = 0.0067877
I0618 10:57:15.438896  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 10:57:15.438923  8058 solver.cpp:237]     Train net output #1: loss = 0.00678773 (* 1 = 0.00678773 loss)
I0618 10:57:15.438941  8058 sgd_solver.cpp:105] Iteration 59000, lr = 0.001
I0618 10:58:13.237089  8058 solver.cpp:218] Iteration 59050 (0.865087 iter/s, 57.7976s/50 iters), loss = 0.00653525
I0618 10:58:13.237232  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 10:58:13.237260  8058 solver.cpp:237]     Train net output #1: loss = 0.00653529 (* 1 = 0.00653529 loss)
I0618 10:58:13.237290  8058 sgd_solver.cpp:105] Iteration 59050, lr = 0.001
I0618 10:59:06.468678  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 10:59:11.015681  8058 solver.cpp:218] Iteration 59100 (0.865383 iter/s, 57.7779s/50 iters), loss = 0.00630652
I0618 10:59:11.015761  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 10:59:11.015791  8058 solver.cpp:237]     Train net output #1: loss = 0.00630655 (* 1 = 0.00630655 loss)
I0618 10:59:11.015810  8058 sgd_solver.cpp:105] Iteration 59100, lr = 0.001
I0618 11:00:08.790000  8058 solver.cpp:218] Iteration 59150 (0.865446 iter/s, 57.7737s/50 iters), loss = 0.0058836
I0618 11:00:08.790169  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:00:08.790204  8058 solver.cpp:237]     Train net output #1: loss = 0.00588363 (* 1 = 0.00588363 loss)
I0618 11:00:08.790223  8058 sgd_solver.cpp:105] Iteration 59150, lr = 0.001
I0618 11:01:06.583672  8058 solver.cpp:218] Iteration 59200 (0.865157 iter/s, 57.793s/50 iters), loss = 0.00552791
I0618 11:01:06.583837  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:01:06.583868  8058 solver.cpp:237]     Train net output #1: loss = 0.00552795 (* 1 = 0.00552795 loss)
I0618 11:01:06.583884  8058 sgd_solver.cpp:105] Iteration 59200, lr = 0.001
I0618 11:01:25.166337  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 11:02:04.347219  8058 solver.cpp:218] Iteration 59250 (0.865608 iter/s, 57.7628s/50 iters), loss = 0.0060151
I0618 11:02:04.347368  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:02:04.347396  8058 solver.cpp:237]     Train net output #1: loss = 0.00601513 (* 1 = 0.00601513 loss)
I0618 11:02:04.347414  8058 sgd_solver.cpp:105] Iteration 59250, lr = 0.001
I0618 11:03:02.136781  8058 solver.cpp:218] Iteration 59300 (0.865218 iter/s, 57.7889s/50 iters), loss = 0.00618601
I0618 11:03:02.136922  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:03:02.136951  8058 solver.cpp:237]     Train net output #1: loss = 0.00618604 (* 1 = 0.00618604 loss)
I0618 11:03:02.136967  8058 sgd_solver.cpp:105] Iteration 59300, lr = 0.001
I0618 11:03:43.794802  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 11:03:59.897986  8058 solver.cpp:218] Iteration 59350 (0.865643 iter/s, 57.7605s/50 iters), loss = 0.00654108
I0618 11:03:59.898078  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:03:59.898110  8058 solver.cpp:237]     Train net output #1: loss = 0.00654111 (* 1 = 0.00654111 loss)
I0618 11:03:59.898130  8058 sgd_solver.cpp:105] Iteration 59350, lr = 0.001
I0618 11:04:57.700974  8058 solver.cpp:218] Iteration 59400 (0.865017 iter/s, 57.8024s/50 iters), loss = 0.00792691
I0618 11:04:57.701115  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:04:57.701144  8058 solver.cpp:237]     Train net output #1: loss = 0.00792694 (* 1 = 0.00792694 loss)
I0618 11:04:57.701160  8058 sgd_solver.cpp:105] Iteration 59400, lr = 0.001
I0618 11:05:55.462090  8058 solver.cpp:218] Iteration 59450 (0.865644 iter/s, 57.7604s/50 iters), loss = 0.00722719
I0618 11:05:55.462255  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:05:55.462283  8058 solver.cpp:237]     Train net output #1: loss = 0.00722722 (* 1 = 0.00722722 loss)
I0618 11:05:55.462301  8058 sgd_solver.cpp:105] Iteration 59450, lr = 0.001
I0618 11:06:02.467180  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 11:06:53.258772  8058 solver.cpp:218] Iteration 59500 (0.865112 iter/s, 57.796s/50 iters), loss = 0.00512548
I0618 11:06:53.258931  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:06:53.258960  8058 solver.cpp:237]     Train net output #1: loss = 0.00512552 (* 1 = 0.00512552 loss)
I0618 11:06:53.258976  8058 sgd_solver.cpp:105] Iteration 59500, lr = 0.001
I0618 11:07:51.049340  8058 solver.cpp:218] Iteration 59550 (0.865203 iter/s, 57.7899s/50 iters), loss = 0.00762117
I0618 11:07:51.049446  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:07:51.049485  8058 solver.cpp:237]     Train net output #1: loss = 0.0076212 (* 1 = 0.0076212 loss)
I0618 11:07:51.049504  8058 sgd_solver.cpp:105] Iteration 59550, lr = 0.001
I0618 11:08:21.139272  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 11:08:48.835652  8058 solver.cpp:218] Iteration 59600 (0.865266 iter/s, 57.7857s/50 iters), loss = 0.00758966
I0618 11:08:48.835729  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:08:48.835757  8058 solver.cpp:237]     Train net output #1: loss = 0.00758969 (* 1 = 0.00758969 loss)
I0618 11:08:48.835772  8058 sgd_solver.cpp:105] Iteration 59600, lr = 0.001
I0618 11:09:46.587224  8058 solver.cpp:218] Iteration 59650 (0.865786 iter/s, 57.751s/50 iters), loss = 0.00562704
I0618 11:09:46.587352  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:09:46.587379  8058 solver.cpp:237]     Train net output #1: loss = 0.00562707 (* 1 = 0.00562707 loss)
I0618 11:09:46.587396  8058 sgd_solver.cpp:105] Iteration 59650, lr = 0.001
I0618 11:10:39.797806  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 11:10:44.355044  8058 solver.cpp:218] Iteration 59700 (0.865543 iter/s, 57.7672s/50 iters), loss = 0.00933919
I0618 11:10:44.355129  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:10:44.355155  8058 solver.cpp:237]     Train net output #1: loss = 0.00933923 (* 1 = 0.00933923 loss)
I0618 11:10:44.355171  8058 sgd_solver.cpp:105] Iteration 59700, lr = 0.001
I0618 11:11:42.116289  8058 solver.cpp:218] Iteration 59750 (0.865642 iter/s, 57.7606s/50 iters), loss = 0.00679589
I0618 11:11:42.116425  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:11:42.116458  8058 solver.cpp:237]     Train net output #1: loss = 0.00679592 (* 1 = 0.00679592 loss)
I0618 11:11:42.116477  8058 sgd_solver.cpp:105] Iteration 59750, lr = 0.001
I0618 11:12:39.872026  8058 solver.cpp:218] Iteration 59800 (0.865725 iter/s, 57.7551s/50 iters), loss = 0.00601089
I0618 11:12:39.872138  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:12:39.872167  8058 solver.cpp:237]     Train net output #1: loss = 0.00601092 (* 1 = 0.00601092 loss)
I0618 11:12:39.872182  8058 sgd_solver.cpp:105] Iteration 59800, lr = 0.001
I0618 11:12:58.425423  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 11:13:37.622795  8058 solver.cpp:218] Iteration 59850 (0.865799 iter/s, 57.7501s/50 iters), loss = 0.00641054
I0618 11:13:37.622922  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:13:37.622951  8058 solver.cpp:237]     Train net output #1: loss = 0.00641058 (* 1 = 0.00641058 loss)
I0618 11:13:37.622968  8058 sgd_solver.cpp:105] Iteration 59850, lr = 0.001
I0618 11:14:35.382529  8058 solver.cpp:218] Iteration 59900 (0.865665 iter/s, 57.7591s/50 iters), loss = 0.00670006
I0618 11:14:35.382694  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:14:35.382722  8058 solver.cpp:237]     Train net output #1: loss = 0.0067001 (* 1 = 0.0067001 loss)
I0618 11:14:35.382740  8058 sgd_solver.cpp:105] Iteration 59900, lr = 0.001
I0618 11:15:15.887264  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 11:15:33.138025  8058 solver.cpp:218] Iteration 59950 (0.865729 iter/s, 57.7548s/50 iters), loss = 0.00619593
I0618 11:15:33.138106  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:15:33.138134  8058 solver.cpp:237]     Train net output #1: loss = 0.00619596 (* 1 = 0.00619596 loss)
I0618 11:15:33.138150  8058 sgd_solver.cpp:105] Iteration 59950, lr = 0.001
I0618 11:16:29.757150  8058 solver.cpp:447] Snapshotting to binary proto file mobilenet/mobile_cub_iter_60000.caffemodel
I0618 11:16:29.842792  8058 sgd_solver.cpp:273] Snapshotting solver state to binary proto file mobilenet/mobile_cub_iter_60000.solverstate
I0618 11:16:31.028028  8058 solver.cpp:218] Iteration 60000 (0.863716 iter/s, 57.8894s/50 iters), loss = 0.00627731
I0618 11:16:31.028105  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:16:31.028128  8058 solver.cpp:237]     Train net output #1: loss = 0.00627734 (* 1 = 0.00627734 loss)
I0618 11:16:31.028156  8058 sgd_solver.cpp:105] Iteration 60000, lr = 0.001
I0618 11:17:28.792594  8058 solver.cpp:218] Iteration 60050 (0.865591 iter/s, 57.764s/50 iters), loss = 0.00469517
I0618 11:17:28.792701  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:17:28.792731  8058 solver.cpp:237]     Train net output #1: loss = 0.0046952 (* 1 = 0.0046952 loss)
I0618 11:17:28.792747  8058 sgd_solver.cpp:105] Iteration 60050, lr = 0.001
I0618 11:17:34.670315  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 11:18:26.547777  8058 solver.cpp:218] Iteration 60100 (0.865733 iter/s, 57.7546s/50 iters), loss = 0.00735395
I0618 11:18:26.547895  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:18:26.547925  8058 solver.cpp:237]     Train net output #1: loss = 0.00735399 (* 1 = 0.00735399 loss)
I0618 11:18:26.547945  8058 sgd_solver.cpp:105] Iteration 60100, lr = 0.001
I0618 11:19:24.303822  8058 solver.cpp:218] Iteration 60150 (0.86572 iter/s, 57.7554s/50 iters), loss = 0.00577003
I0618 11:19:24.303941  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:19:24.303968  8058 solver.cpp:237]     Train net output #1: loss = 0.00577006 (* 1 = 0.00577006 loss)
I0618 11:19:24.303987  8058 sgd_solver.cpp:105] Iteration 60150, lr = 0.001
I0618 11:19:53.263109  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 11:20:22.073698  8058 solver.cpp:218] Iteration 60200 (0.865512 iter/s, 57.7693s/50 iters), loss = 0.00795506
I0618 11:20:22.073976  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:20:22.074004  8058 solver.cpp:237]     Train net output #1: loss = 0.0079551 (* 1 = 0.0079551 loss)
I0618 11:20:22.074021  8058 sgd_solver.cpp:105] Iteration 60200, lr = 0.001
I0618 11:21:19.838398  8058 solver.cpp:218] Iteration 60250 (0.865592 iter/s, 57.7639s/50 iters), loss = 0.00899019
I0618 11:21:19.838526  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:21:19.838557  8058 solver.cpp:237]     Train net output #1: loss = 0.00899022 (* 1 = 0.00899022 loss)
I0618 11:21:19.838574  8058 sgd_solver.cpp:105] Iteration 60250, lr = 0.001
I0618 11:22:11.912912  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 11:22:17.595273  8058 solver.cpp:218] Iteration 60300 (0.865707 iter/s, 57.7562s/50 iters), loss = 0.00634476
I0618 11:22:17.595355  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:22:17.595386  8058 solver.cpp:237]     Train net output #1: loss = 0.00634479 (* 1 = 0.00634479 loss)
I0618 11:22:17.595407  8058 sgd_solver.cpp:105] Iteration 60300, lr = 0.001
I0618 11:23:15.363397  8058 solver.cpp:218] Iteration 60350 (0.865538 iter/s, 57.7675s/50 iters), loss = 0.00800174
I0618 11:23:15.363574  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:23:15.363605  8058 solver.cpp:237]     Train net output #1: loss = 0.00800178 (* 1 = 0.00800178 loss)
I0618 11:23:15.363622  8058 sgd_solver.cpp:105] Iteration 60350, lr = 0.001
I0618 11:24:13.114138  8058 solver.cpp:218] Iteration 60400 (0.8658 iter/s, 57.7501s/50 iters), loss = 0.00570967
I0618 11:24:13.114266  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:24:13.114295  8058 solver.cpp:237]     Train net output #1: loss = 0.00570971 (* 1 = 0.00570971 loss)
I0618 11:24:13.114311  8058 sgd_solver.cpp:105] Iteration 60400, lr = 0.001
I0618 11:24:30.511971  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 11:25:10.871542  8058 solver.cpp:218] Iteration 60450 (0.865699 iter/s, 57.7568s/50 iters), loss = 0.00732811
I0618 11:25:10.871656  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:25:10.871685  8058 solver.cpp:237]     Train net output #1: loss = 0.00732814 (* 1 = 0.00732814 loss)
I0618 11:25:10.871703  8058 sgd_solver.cpp:105] Iteration 60450, lr = 0.001
I0618 11:26:08.629079  8058 solver.cpp:218] Iteration 60500 (0.865697 iter/s, 57.7569s/50 iters), loss = 0.00567706
I0618 11:26:08.629216  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:26:08.629251  8058 solver.cpp:237]     Train net output #1: loss = 0.0056771 (* 1 = 0.0056771 loss)
I0618 11:26:08.629271  8058 sgd_solver.cpp:105] Iteration 60500, lr = 0.001
I0618 11:26:49.129063  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 11:27:06.392407  8058 solver.cpp:218] Iteration 60550 (0.865611 iter/s, 57.7627s/50 iters), loss = 0.00750622
I0618 11:27:06.392488  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:27:06.392523  8058 solver.cpp:237]     Train net output #1: loss = 0.00750625 (* 1 = 0.00750625 loss)
I0618 11:27:06.392542  8058 sgd_solver.cpp:105] Iteration 60550, lr = 0.001
I0618 11:28:04.152989  8058 solver.cpp:218] Iteration 60600 (0.865651 iter/s, 57.76s/50 iters), loss = 0.00746058
I0618 11:28:04.153177  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:28:04.153221  8058 solver.cpp:237]     Train net output #1: loss = 0.00746061 (* 1 = 0.00746061 loss)
I0618 11:28:04.153241  8058 sgd_solver.cpp:105] Iteration 60600, lr = 0.001
I0618 11:29:01.922565  8058 solver.cpp:218] Iteration 60650 (0.865518 iter/s, 57.7689s/50 iters), loss = 0.00654195
I0618 11:29:01.922715  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:29:01.922745  8058 solver.cpp:237]     Train net output #1: loss = 0.00654199 (* 1 = 0.00654199 loss)
I0618 11:29:01.922762  8058 sgd_solver.cpp:105] Iteration 60650, lr = 0.001
I0618 11:29:07.784095  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 11:29:59.705967  8058 solver.cpp:218] Iteration 60700 (0.86531 iter/s, 57.7827s/50 iters), loss = 0.00876539
I0618 11:29:59.706084  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:29:59.706116  8058 solver.cpp:237]     Train net output #1: loss = 0.00876542 (* 1 = 0.00876542 loss)
I0618 11:29:59.706136  8058 sgd_solver.cpp:105] Iteration 60700, lr = 0.001
I0618 11:30:57.469120  8058 solver.cpp:218] Iteration 60750 (0.865613 iter/s, 57.7625s/50 iters), loss = 0.00602697
I0618 11:30:57.469247  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:30:57.469280  8058 solver.cpp:237]     Train net output #1: loss = 0.006027 (* 1 = 0.006027 loss)
I0618 11:30:57.469298  8058 sgd_solver.cpp:105] Iteration 60750, lr = 0.001
I0618 11:31:26.409127  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 11:31:55.228018  8058 solver.cpp:218] Iteration 60800 (0.865677 iter/s, 57.7583s/50 iters), loss = 0.00710703
I0618 11:31:55.228148  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:31:55.228176  8058 solver.cpp:237]     Train net output #1: loss = 0.00710706 (* 1 = 0.00710706 loss)
I0618 11:31:55.228194  8058 sgd_solver.cpp:105] Iteration 60800, lr = 0.001
I0618 11:32:53.007062  8058 solver.cpp:218] Iteration 60850 (0.865375 iter/s, 57.7784s/50 iters), loss = 0.00591122
I0618 11:32:53.007222  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:32:53.007253  8058 solver.cpp:237]     Train net output #1: loss = 0.00591125 (* 1 = 0.00591125 loss)
I0618 11:32:53.007272  8058 sgd_solver.cpp:105] Iteration 60850, lr = 0.001
I0618 11:33:45.059131  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 11:33:50.767949  8058 solver.cpp:218] Iteration 60900 (0.865647 iter/s, 57.7602s/50 iters), loss = 0.00633897
I0618 11:33:50.768025  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:33:50.768051  8058 solver.cpp:237]     Train net output #1: loss = 0.006339 (* 1 = 0.006339 loss)
I0618 11:33:50.768069  8058 sgd_solver.cpp:105] Iteration 60900, lr = 0.001
I0618 11:34:48.527447  8058 solver.cpp:218] Iteration 60950 (0.865667 iter/s, 57.7589s/50 iters), loss = 0.00617187
I0618 11:34:48.527570  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:34:48.527598  8058 solver.cpp:237]     Train net output #1: loss = 0.00617191 (* 1 = 0.00617191 loss)
I0618 11:34:48.527616  8058 sgd_solver.cpp:105] Iteration 60950, lr = 0.001
I0618 11:35:46.286736  8058 solver.cpp:218] Iteration 61000 (0.865671 iter/s, 57.7587s/50 iters), loss = 0.00721812
I0618 11:35:46.286859  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:35:46.286887  8058 solver.cpp:237]     Train net output #1: loss = 0.00721816 (* 1 = 0.00721816 loss)
I0618 11:35:46.286905  8058 sgd_solver.cpp:105] Iteration 61000, lr = 0.001
I0618 11:36:02.546631  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 11:36:44.061436  8058 solver.cpp:218] Iteration 61050 (0.86544 iter/s, 57.7741s/50 iters), loss = 0.00825851
I0618 11:36:44.061564  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:36:44.061594  8058 solver.cpp:237]     Train net output #1: loss = 0.00825854 (* 1 = 0.00825854 loss)
I0618 11:36:44.061611  8058 sgd_solver.cpp:105] Iteration 61050, lr = 0.001
I0618 11:37:41.811411  8058 solver.cpp:218] Iteration 61100 (0.865811 iter/s, 57.7494s/50 iters), loss = 0.00991734
I0618 11:37:41.811574  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:37:41.811621  8058 solver.cpp:237]     Train net output #1: loss = 0.00991737 (* 1 = 0.00991737 loss)
I0618 11:37:41.811640  8058 sgd_solver.cpp:105] Iteration 61100, lr = 0.001
I0618 11:38:21.175935  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 11:38:39.569730  8058 solver.cpp:218] Iteration 61150 (0.865686 iter/s, 57.7577s/50 iters), loss = 0.00739152
I0618 11:38:39.569806  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:38:39.569833  8058 solver.cpp:237]     Train net output #1: loss = 0.00739155 (* 1 = 0.00739155 loss)
I0618 11:38:39.569850  8058 sgd_solver.cpp:105] Iteration 61150, lr = 0.001
I0618 11:39:37.352551  8058 solver.cpp:218] Iteration 61200 (0.865318 iter/s, 57.7822s/50 iters), loss = 0.0073253
I0618 11:39:37.352702  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:39:37.352730  8058 solver.cpp:237]     Train net output #1: loss = 0.00732534 (* 1 = 0.00732534 loss)
I0618 11:39:37.352747  8058 sgd_solver.cpp:105] Iteration 61200, lr = 0.001
I0618 11:40:35.146973  8058 solver.cpp:218] Iteration 61250 (0.865145 iter/s, 57.7938s/50 iters), loss = 0.00664029
I0618 11:40:35.147140  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:40:35.147168  8058 solver.cpp:237]     Train net output #1: loss = 0.00664032 (* 1 = 0.00664032 loss)
I0618 11:40:35.147186  8058 sgd_solver.cpp:105] Iteration 61250, lr = 0.001
I0618 11:40:39.842855  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 11:41:32.926429  8058 solver.cpp:218] Iteration 61300 (0.86537 iter/s, 57.7788s/50 iters), loss = 0.00594499
I0618 11:41:32.926581  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:41:32.926610  8058 solver.cpp:237]     Train net output #1: loss = 0.00594502 (* 1 = 0.00594502 loss)
I0618 11:41:32.926628  8058 sgd_solver.cpp:105] Iteration 61300, lr = 0.001
I0618 11:42:30.713069  8058 solver.cpp:218] Iteration 61350 (0.865262 iter/s, 57.786s/50 iters), loss = 0.00772926
I0618 11:42:30.713251  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:42:30.713282  8058 solver.cpp:237]     Train net output #1: loss = 0.0077293 (* 1 = 0.0077293 loss)
I0618 11:42:30.713304  8058 sgd_solver.cpp:105] Iteration 61350, lr = 0.001
I0618 11:42:58.529161  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 11:43:28.507980  8058 solver.cpp:218] Iteration 61400 (0.865139 iter/s, 57.7942s/50 iters), loss = 0.00783218
I0618 11:43:28.508137  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:43:28.508165  8058 solver.cpp:237]     Train net output #1: loss = 0.00783222 (* 1 = 0.00783222 loss)
I0618 11:43:28.508183  8058 sgd_solver.cpp:105] Iteration 61400, lr = 0.001
I0618 11:44:26.303905  8058 solver.cpp:218] Iteration 61450 (0.865123 iter/s, 57.7953s/50 iters), loss = 0.00602516
I0618 11:44:26.304036  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:44:26.304065  8058 solver.cpp:237]     Train net output #1: loss = 0.0060252 (* 1 = 0.0060252 loss)
I0618 11:44:26.304083  8058 sgd_solver.cpp:105] Iteration 61450, lr = 0.001
I0618 11:45:17.220146  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 11:45:24.089710  8058 solver.cpp:218] Iteration 61500 (0.865274 iter/s, 57.7852s/50 iters), loss = 0.00564471
I0618 11:45:24.089817  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:45:24.089843  8058 solver.cpp:237]     Train net output #1: loss = 0.00564475 (* 1 = 0.00564475 loss)
I0618 11:45:24.089862  8058 sgd_solver.cpp:105] Iteration 61500, lr = 0.001
I0618 11:46:21.880071  8058 solver.cpp:218] Iteration 61550 (0.865206 iter/s, 57.7897s/50 iters), loss = 0.00650614
I0618 11:46:21.880229  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:46:21.880261  8058 solver.cpp:237]     Train net output #1: loss = 0.00650618 (* 1 = 0.00650618 loss)
I0618 11:46:21.880282  8058 sgd_solver.cpp:105] Iteration 61550, lr = 0.001
I0618 11:47:19.669886  8058 solver.cpp:218] Iteration 61600 (0.865214 iter/s, 57.7892s/50 iters), loss = 0.0079156
I0618 11:47:19.670004  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:47:19.670033  8058 solver.cpp:237]     Train net output #1: loss = 0.00791563 (* 1 = 0.00791563 loss)
I0618 11:47:19.670050  8058 sgd_solver.cpp:105] Iteration 61600, lr = 0.001
I0618 11:47:35.903193  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 11:48:17.464548  8058 solver.cpp:218] Iteration 61650 (0.865141 iter/s, 57.794s/50 iters), loss = 0.00612139
I0618 11:48:17.464645  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:48:17.464673  8058 solver.cpp:237]     Train net output #1: loss = 0.00612143 (* 1 = 0.00612143 loss)
I0618 11:48:17.464690  8058 sgd_solver.cpp:105] Iteration 61650, lr = 0.001
I0618 11:49:15.247459  8058 solver.cpp:218] Iteration 61700 (0.865317 iter/s, 57.7823s/50 iters), loss = 0.00618672
I0618 11:49:15.247580  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:49:15.247607  8058 solver.cpp:237]     Train net output #1: loss = 0.00618675 (* 1 = 0.00618675 loss)
I0618 11:49:15.247625  8058 sgd_solver.cpp:105] Iteration 61700, lr = 0.001
I0618 11:49:54.584823  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 11:50:13.011720  8058 solver.cpp:218] Iteration 61750 (0.865597 iter/s, 57.7636s/50 iters), loss = 0.00802759
I0618 11:50:13.011811  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:50:13.011837  8058 solver.cpp:237]     Train net output #1: loss = 0.00802762 (* 1 = 0.00802762 loss)
I0618 11:50:13.011855  8058 sgd_solver.cpp:105] Iteration 61750, lr = 0.001
I0618 11:51:10.773429  8058 solver.cpp:218] Iteration 61800 (0.865634 iter/s, 57.7611s/50 iters), loss = 0.00634951
I0618 11:51:10.773546  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:51:10.773576  8058 solver.cpp:237]     Train net output #1: loss = 0.00634954 (* 1 = 0.00634954 loss)
I0618 11:51:10.773593  8058 sgd_solver.cpp:105] Iteration 61800, lr = 0.001
I0618 11:52:08.540560  8058 solver.cpp:218] Iteration 61850 (0.865554 iter/s, 57.7665s/50 iters), loss = 0.00681211
I0618 11:52:08.540752  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:52:08.540783  8058 solver.cpp:237]     Train net output #1: loss = 0.00681214 (* 1 = 0.00681214 loss)
I0618 11:52:08.540802  8058 sgd_solver.cpp:105] Iteration 61850, lr = 0.001
I0618 11:52:13.220795  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 11:53:06.300552  8058 solver.cpp:218] Iteration 61900 (0.865662 iter/s, 57.7593s/50 iters), loss = 0.00753028
I0618 11:53:06.300696  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:53:06.300725  8058 solver.cpp:237]     Train net output #1: loss = 0.00753032 (* 1 = 0.00753032 loss)
I0618 11:53:06.300742  8058 sgd_solver.cpp:105] Iteration 61900, lr = 0.001
I0618 11:54:04.072794  8058 solver.cpp:218] Iteration 61950 (0.865477 iter/s, 57.7716s/50 iters), loss = 0.00628473
I0618 11:54:04.072923  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:54:04.072952  8058 solver.cpp:237]     Train net output #1: loss = 0.00628476 (* 1 = 0.00628476 loss)
I0618 11:54:04.072981  8058 sgd_solver.cpp:105] Iteration 61950, lr = 0.001
I0618 11:54:30.732820  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 11:55:01.837616  8058 solver.cpp:218] Iteration 62000 (0.865588 iter/s, 57.7642s/50 iters), loss = 0.00738557
I0618 11:55:01.837772  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:55:01.837801  8058 solver.cpp:237]     Train net output #1: loss = 0.00738561 (* 1 = 0.00738561 loss)
I0618 11:55:01.837818  8058 sgd_solver.cpp:105] Iteration 62000, lr = 0.001
I0618 11:55:59.608459  8058 solver.cpp:218] Iteration 62050 (0.865498 iter/s, 57.7702s/50 iters), loss = 0.00636938
I0618 11:55:59.608584  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:55:59.608613  8058 solver.cpp:237]     Train net output #1: loss = 0.00636942 (* 1 = 0.00636942 loss)
I0618 11:55:59.608631  8058 sgd_solver.cpp:105] Iteration 62050, lr = 0.001
I0618 11:56:49.370378  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 11:56:57.382840  8058 solver.cpp:218] Iteration 62100 (0.865444 iter/s, 57.7738s/50 iters), loss = 0.00718871
I0618 11:56:57.382935  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:56:57.382961  8058 solver.cpp:237]     Train net output #1: loss = 0.00718875 (* 1 = 0.00718875 loss)
I0618 11:56:57.382978  8058 sgd_solver.cpp:105] Iteration 62100, lr = 0.001
I0618 11:57:55.150259  8058 solver.cpp:218] Iteration 62150 (0.865548 iter/s, 57.7669s/50 iters), loss = 0.00648853
I0618 11:57:55.150391  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:57:55.150420  8058 solver.cpp:237]     Train net output #1: loss = 0.00648857 (* 1 = 0.00648857 loss)
I0618 11:57:55.150441  8058 sgd_solver.cpp:105] Iteration 62150, lr = 0.001
I0618 11:58:52.911391  8058 solver.cpp:218] Iteration 62200 (0.865643 iter/s, 57.7605s/50 iters), loss = 0.00703661
I0618 11:58:52.911504  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:58:52.911541  8058 solver.cpp:237]     Train net output #1: loss = 0.00703665 (* 1 = 0.00703665 loss)
I0618 11:58:52.911559  8058 sgd_solver.cpp:105] Iteration 62200, lr = 0.001
I0618 11:59:08.005682  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 11:59:50.675223  8058 solver.cpp:218] Iteration 62250 (0.865602 iter/s, 57.7632s/50 iters), loss = 0.00763037
I0618 11:59:50.675334  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 11:59:50.675364  8058 solver.cpp:237]     Train net output #1: loss = 0.00763041 (* 1 = 0.00763041 loss)
I0618 11:59:50.675381  8058 sgd_solver.cpp:105] Iteration 62250, lr = 0.001
I0618 12:00:48.441577  8058 solver.cpp:218] Iteration 62300 (0.865565 iter/s, 57.7658s/50 iters), loss = 0.00712738
I0618 12:00:48.441701  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 12:00:48.441741  8058 solver.cpp:237]     Train net output #1: loss = 0.00712741 (* 1 = 0.00712741 loss)
I0618 12:00:48.441761  8058 sgd_solver.cpp:105] Iteration 62300, lr = 0.001
I0618 12:01:26.657704  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 12:01:46.199314  8058 solver.cpp:218] Iteration 62350 (0.865694 iter/s, 57.7571s/50 iters), loss = 0.00762016
I0618 12:01:46.199388  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 12:01:46.199415  8058 solver.cpp:237]     Train net output #1: loss = 0.00762019 (* 1 = 0.00762019 loss)
I0618 12:01:46.199432  8058 sgd_solver.cpp:105] Iteration 62350, lr = 0.001
I0618 12:02:43.968247  8058 solver.cpp:218] Iteration 62400 (0.865525 iter/s, 57.7684s/50 iters), loss = 0.00494616
I0618 12:02:43.968382  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 12:02:43.968411  8058 solver.cpp:237]     Train net output #1: loss = 0.00494619 (* 1 = 0.00494619 loss)
I0618 12:02:43.968430  8058 sgd_solver.cpp:105] Iteration 62400, lr = 0.001
I0618 12:03:41.729133  8058 solver.cpp:218] Iteration 62450 (0.865647 iter/s, 57.7603s/50 iters), loss = 0.00853644
I0618 12:03:41.729266  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 12:03:41.729296  8058 solver.cpp:237]     Train net output #1: loss = 0.00853647 (* 1 = 0.00853647 loss)
I0618 12:03:41.729313  8058 sgd_solver.cpp:105] Iteration 62450, lr = 0.001
I0618 12:03:45.256980  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 12:04:39.500799  8058 solver.cpp:218] Iteration 62500 (0.865485 iter/s, 57.7711s/50 iters), loss = 0.00723397
I0618 12:04:39.500905  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 12:04:39.500933  8058 solver.cpp:237]     Train net output #1: loss = 0.007234 (* 1 = 0.007234 loss)
I0618 12:04:39.500952  8058 sgd_solver.cpp:105] Iteration 62500, lr = 0.001
I0618 12:05:37.262266  8058 solver.cpp:218] Iteration 62550 (0.865638 iter/s, 57.7609s/50 iters), loss = 0.00654373
I0618 12:05:37.262374  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 12:05:37.262403  8058 solver.cpp:237]     Train net output #1: loss = 0.00654376 (* 1 = 0.00654376 loss)
I0618 12:05:37.262420  8058 sgd_solver.cpp:105] Iteration 62550, lr = 0.001
I0618 12:06:03.905732  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 12:06:35.011019  8058 solver.cpp:218] Iteration 62600 (0.865828 iter/s, 57.7482s/50 iters), loss = 0.00668836
I0618 12:06:35.011135  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 12:06:35.011163  8058 solver.cpp:237]     Train net output #1: loss = 0.00668839 (* 1 = 0.00668839 loss)
I0618 12:06:35.011181  8058 sgd_solver.cpp:105] Iteration 62600, lr = 0.001
I0618 12:07:32.766628  8058 solver.cpp:218] Iteration 62650 (0.865726 iter/s, 57.755s/50 iters), loss = 0.00602394
I0618 12:07:32.766736  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 12:07:32.766764  8058 solver.cpp:237]     Train net output #1: loss = 0.00602397 (* 1 = 0.00602397 loss)
I0618 12:07:32.766782  8058 sgd_solver.cpp:105] Iteration 62650, lr = 0.001
I0618 12:08:22.500079  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 12:08:30.523591  8058 solver.cpp:218] Iteration 62700 (0.865705 iter/s, 57.7564s/50 iters), loss = 0.0068168
I0618 12:08:30.523668  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 12:08:30.523694  8058 solver.cpp:237]     Train net output #1: loss = 0.00681683 (* 1 = 0.00681683 loss)
I0618 12:08:30.523710  8058 sgd_solver.cpp:105] Iteration 62700, lr = 0.001
I0618 12:09:28.296190  8058 solver.cpp:218] Iteration 62750 (0.86547 iter/s, 57.772s/50 iters), loss = 0.00621443
I0618 12:09:28.296303  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 12:09:28.296334  8058 solver.cpp:237]     Train net output #1: loss = 0.00621447 (* 1 = 0.00621447 loss)
I0618 12:09:28.296350  8058 sgd_solver.cpp:105] Iteration 62750, lr = 0.001
I0618 12:10:26.067693  8058 solver.cpp:218] Iteration 62800 (0.865488 iter/s, 57.7709s/50 iters), loss = 0.00685641
I0618 12:10:26.067883  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 12:10:26.067914  8058 solver.cpp:237]     Train net output #1: loss = 0.00685645 (* 1 = 0.00685645 loss)
I0618 12:10:26.067931  8058 sgd_solver.cpp:105] Iteration 62800, lr = 0.001
I0618 12:10:41.154009  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 12:11:23.827659  8058 solver.cpp:218] Iteration 62850 (0.865662 iter/s, 57.7593s/50 iters), loss = 0.00902836
I0618 12:11:23.827846  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 12:11:23.827877  8058 solver.cpp:237]     Train net output #1: loss = 0.00902839 (* 1 = 0.00902839 loss)
I0618 12:11:23.827898  8058 sgd_solver.cpp:105] Iteration 62850, lr = 0.001
I0618 12:12:21.589349  8058 solver.cpp:218] Iteration 62900 (0.865636 iter/s, 57.761s/50 iters), loss = 0.00772742
I0618 12:12:21.589474  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 12:12:21.589504  8058 solver.cpp:237]     Train net output #1: loss = 0.00772745 (* 1 = 0.00772745 loss)
I0618 12:12:21.589529  8058 sgd_solver.cpp:105] Iteration 62900, lr = 0.001
I0618 12:12:58.649662  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 12:13:19.336886  8058 solver.cpp:218] Iteration 62950 (0.865847 iter/s, 57.7469s/50 iters), loss = 0.0100386
I0618 12:13:19.336961  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 12:13:19.336988  8058 solver.cpp:237]     Train net output #1: loss = 0.0100386 (* 1 = 0.0100386 loss)
I0618 12:13:19.337007  8058 sgd_solver.cpp:105] Iteration 62950, lr = 0.001
I0618 12:14:17.087545  8058 solver.cpp:218] Iteration 63000 (0.8658 iter/s, 57.7501s/50 iters), loss = 0.00734732
I0618 12:14:17.087671  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 12:14:17.087699  8058 solver.cpp:237]     Train net output #1: loss = 0.00734735 (* 1 = 0.00734735 loss)
I0618 12:14:17.087716  8058 sgd_solver.cpp:105] Iteration 63000, lr = 0.001
I0618 12:15:14.842798  8058 solver.cpp:218] Iteration 63050 (0.865731 iter/s, 57.7546s/50 iters), loss = 0.00710226
I0618 12:15:14.842933  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 12:15:14.842962  8058 solver.cpp:237]     Train net output #1: loss = 0.0071023 (* 1 = 0.0071023 loss)
I0618 12:15:14.842980  8058 sgd_solver.cpp:105] Iteration 63050, lr = 0.001
I0618 12:15:17.255950  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 12:16:12.608297  8058 solver.cpp:218] Iteration 63100 (0.865578 iter/s, 57.7648s/50 iters), loss = 0.00683817
I0618 12:16:12.608443  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 12:16:12.608476  8058 solver.cpp:237]     Train net output #1: loss = 0.0068382 (* 1 = 0.0068382 loss)
I0618 12:16:12.608497  8058 sgd_solver.cpp:105] Iteration 63100, lr = 0.001
I0618 12:17:10.376268  8058 solver.cpp:218] Iteration 63150 (0.865542 iter/s, 57.7673s/50 iters), loss = 0.00736139
I0618 12:17:10.376415  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 12:17:10.376452  8058 solver.cpp:237]     Train net output #1: loss = 0.00736142 (* 1 = 0.00736142 loss)
I0618 12:17:10.376477  8058 sgd_solver.cpp:105] Iteration 63150, lr = 0.001
I0618 12:17:35.898193  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 12:18:08.144328  8058 solver.cpp:218] Iteration 63200 (0.86554 iter/s, 57.7674s/50 iters), loss = 0.00669258
I0618 12:18:08.144474  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 12:18:08.144503  8058 solver.cpp:237]     Train net output #1: loss = 0.00669261 (* 1 = 0.00669261 loss)
I0618 12:18:08.144526  8058 sgd_solver.cpp:105] Iteration 63200, lr = 0.001
I0618 12:19:05.913087  8058 solver.cpp:218] Iteration 63250 (0.865529 iter/s, 57.7681s/50 iters), loss = 0.00718153
I0618 12:19:05.913228  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 12:19:05.913257  8058 solver.cpp:237]     Train net output #1: loss = 0.00718156 (* 1 = 0.00718156 loss)
I0618 12:19:05.913276  8058 sgd_solver.cpp:105] Iteration 63250, lr = 0.001
I0618 12:19:54.523937  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 12:20:03.666517  8058 solver.cpp:218] Iteration 63300 (0.865759 iter/s, 57.7528s/50 iters), loss = 0.0100819
I0618 12:20:03.666606  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 12:20:03.666640  8058 solver.cpp:237]     Train net output #1: loss = 0.0100819 (* 1 = 0.0100819 loss)
I0618 12:20:03.666664  8058 sgd_solver.cpp:105] Iteration 63300, lr = 0.001
I0618 12:21:01.423522  8058 solver.cpp:218] Iteration 63350 (0.865705 iter/s, 57.7564s/50 iters), loss = 0.00663459
I0618 12:21:01.423671  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 12:21:01.423701  8058 solver.cpp:237]     Train net output #1: loss = 0.00663463 (* 1 = 0.00663463 loss)
I0618 12:21:01.423718  8058 sgd_solver.cpp:105] Iteration 63350, lr = 0.001
I0618 12:21:59.204102  8058 solver.cpp:218] Iteration 63400 (0.865352 iter/s, 57.7799s/50 iters), loss = 0.00596697
I0618 12:21:59.204241  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 12:21:59.204270  8058 solver.cpp:237]     Train net output #1: loss = 0.00596701 (* 1 = 0.00596701 loss)
I0618 12:21:59.204288  8058 sgd_solver.cpp:105] Iteration 63400, lr = 0.001
I0618 12:22:13.139441  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 12:22:56.975046  8058 solver.cpp:218] Iteration 63450 (0.865496 iter/s, 57.7703s/50 iters), loss = 0.0065924
I0618 12:22:56.975174  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 12:22:56.975203  8058 solver.cpp:237]     Train net output #1: loss = 0.00659244 (* 1 = 0.00659244 loss)
I0618 12:22:56.975220  8058 sgd_solver.cpp:105] Iteration 63450, lr = 0.001
I0618 12:23:54.742602  8058 solver.cpp:218] Iteration 63500 (0.865547 iter/s, 57.7669s/50 iters), loss = 0.00499942
I0618 12:23:54.742719  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 12:23:54.742748  8058 solver.cpp:237]     Train net output #1: loss = 0.00499946 (* 1 = 0.00499946 loss)
I0618 12:23:54.742765  8058 sgd_solver.cpp:105] Iteration 63500, lr = 0.001
I0618 12:24:31.785989  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 12:24:52.514164  8058 solver.cpp:218] Iteration 63550 (0.865487 iter/s, 57.771s/50 iters), loss = 0.00570009
I0618 12:24:52.514246  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 12:24:52.514273  8058 solver.cpp:237]     Train net output #1: loss = 0.00570012 (* 1 = 0.00570012 loss)
I0618 12:24:52.514292  8058 sgd_solver.cpp:105] Iteration 63550, lr = 0.001
I0618 12:25:50.268542  8058 solver.cpp:218] Iteration 63600 (0.865744 iter/s, 57.7538s/50 iters), loss = 0.0092508
I0618 12:25:50.268649  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 12:25:50.268677  8058 solver.cpp:237]     Train net output #1: loss = 0.00925083 (* 1 = 0.00925083 loss)
I0618 12:25:50.268694  8058 sgd_solver.cpp:105] Iteration 63600, lr = 0.001
I0618 12:26:48.016494  8058 solver.cpp:218] Iteration 63650 (0.865841 iter/s, 57.7474s/50 iters), loss = 0.00968
I0618 12:26:48.016610  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 12:26:48.016639  8058 solver.cpp:237]     Train net output #1: loss = 0.00968004 (* 1 = 0.00968004 loss)
I0618 12:26:48.016656  8058 sgd_solver.cpp:105] Iteration 63650, lr = 0.001
I0618 12:26:50.379375  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 12:27:45.777088  8058 solver.cpp:218] Iteration 63700 (0.865651 iter/s, 57.76s/50 iters), loss = 0.00673462
I0618 12:27:45.777210  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 12:27:45.777238  8058 solver.cpp:237]     Train net output #1: loss = 0.00673465 (* 1 = 0.00673465 loss)
I0618 12:27:45.777256  8058 sgd_solver.cpp:105] Iteration 63700, lr = 0.001
I0618 12:28:43.541581  8058 solver.cpp:218] Iteration 63750 (0.865593 iter/s, 57.7639s/50 iters), loss = 0.00717955
I0618 12:28:43.541702  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 12:28:43.541729  8058 solver.cpp:237]     Train net output #1: loss = 0.00717958 (* 1 = 0.00717958 loss)
I0618 12:28:43.541748  8058 sgd_solver.cpp:105] Iteration 63750, lr = 0.001
I0618 12:29:08.999075  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 12:29:41.294385  8058 solver.cpp:218] Iteration 63800 (0.865768 iter/s, 57.7522s/50 iters), loss = 0.00587223
I0618 12:29:41.294545  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 12:29:41.294577  8058 solver.cpp:237]     Train net output #1: loss = 0.00587226 (* 1 = 0.00587226 loss)
I0618 12:29:41.294595  8058 sgd_solver.cpp:105] Iteration 63800, lr = 0.001
I0618 12:30:39.057931  8058 solver.cpp:218] Iteration 63850 (0.865608 iter/s, 57.7629s/50 iters), loss = 0.00842609
I0618 12:30:39.058022  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 12:30:39.058049  8058 solver.cpp:237]     Train net output #1: loss = 0.00842612 (* 1 = 0.00842612 loss)
I0618 12:30:39.058070  8058 sgd_solver.cpp:105] Iteration 63850, lr = 0.001
I0618 12:31:27.647394  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 12:31:36.816088  8058 solver.cpp:218] Iteration 63900 (0.865687 iter/s, 57.7576s/50 iters), loss = 0.00704212
I0618 12:31:36.816166  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 12:31:36.816206  8058 solver.cpp:237]     Train net output #1: loss = 0.00704216 (* 1 = 0.00704216 loss)
I0618 12:31:36.816224  8058 sgd_solver.cpp:105] Iteration 63900, lr = 0.001
I0618 12:32:34.581111  8058 solver.cpp:218] Iteration 63950 (0.865584 iter/s, 57.7645s/50 iters), loss = 0.00830905
I0618 12:32:34.581231  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 12:32:34.581259  8058 solver.cpp:237]     Train net output #1: loss = 0.00830908 (* 1 = 0.00830908 loss)
I0618 12:32:34.581277  8058 sgd_solver.cpp:105] Iteration 63950, lr = 0.001
I0618 12:33:32.344002  8058 solver.cpp:218] Iteration 64000 (0.865617 iter/s, 57.7623s/50 iters), loss = 0.00709696
I0618 12:33:32.344156  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 12:33:32.344184  8058 solver.cpp:237]     Train net output #1: loss = 0.00709699 (* 1 = 0.00709699 loss)
I0618 12:33:32.344202  8058 sgd_solver.cpp:105] Iteration 64000, lr = 0.001
I0618 12:33:45.135498  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 12:34:30.108026  8058 solver.cpp:218] Iteration 64050 (0.8656 iter/s, 57.7634s/50 iters), loss = 0.00698513
I0618 12:34:30.108150  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 12:34:30.108180  8058 solver.cpp:237]     Train net output #1: loss = 0.00698516 (* 1 = 0.00698516 loss)
I0618 12:34:30.108197  8058 sgd_solver.cpp:105] Iteration 64050, lr = 0.001
I0618 12:35:27.865813  8058 solver.cpp:218] Iteration 64100 (0.865693 iter/s, 57.7572s/50 iters), loss = 0.00611324
I0618 12:35:27.865933  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 12:35:27.865959  8058 solver.cpp:237]     Train net output #1: loss = 0.00611327 (* 1 = 0.00611327 loss)
I0618 12:35:27.865978  8058 sgd_solver.cpp:105] Iteration 64100, lr = 0.001
I0618 12:36:03.762320  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 12:36:25.637729  8058 solver.cpp:218] Iteration 64150 (0.865482 iter/s, 57.7713s/50 iters), loss = 0.00697392
I0618 12:36:25.637801  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 12:36:25.637827  8058 solver.cpp:237]     Train net output #1: loss = 0.00697395 (* 1 = 0.00697395 loss)
I0618 12:36:25.637845  8058 sgd_solver.cpp:105] Iteration 64150, lr = 0.001
I0618 12:37:23.396164  8058 solver.cpp:218] Iteration 64200 (0.865683 iter/s, 57.7579s/50 iters), loss = 0.0072031
I0618 12:37:23.396278  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 12:37:23.396306  8058 solver.cpp:237]     Train net output #1: loss = 0.00720313 (* 1 = 0.00720313 loss)
I0618 12:37:23.396324  8058 sgd_solver.cpp:105] Iteration 64200, lr = 0.001
I0618 12:38:21.153020  8058 solver.cpp:218] Iteration 64250 (0.865707 iter/s, 57.7562s/50 iters), loss = 0.00571837
I0618 12:38:21.153187  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 12:38:21.153218  8058 solver.cpp:237]     Train net output #1: loss = 0.00571841 (* 1 = 0.00571841 loss)
I0618 12:38:21.153235  8058 sgd_solver.cpp:105] Iteration 64250, lr = 0.001
I0618 12:38:22.380565  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 12:39:18.931924  8058 solver.cpp:218] Iteration 64300 (0.865378 iter/s, 57.7782s/50 iters), loss = 0.00629969
I0618 12:39:18.932067  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 12:39:18.932096  8058 solver.cpp:237]     Train net output #1: loss = 0.00629972 (* 1 = 0.00629972 loss)
I0618 12:39:18.932116  8058 sgd_solver.cpp:105] Iteration 64300, lr = 0.001
I0618 12:40:16.731451  8058 solver.cpp:218] Iteration 64350 (0.865069 iter/s, 57.7989s/50 iters), loss = 0.00818437
I0618 12:40:16.731617  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 12:40:16.731647  8058 solver.cpp:237]     Train net output #1: loss = 0.00818441 (* 1 = 0.00818441 loss)
I0618 12:40:16.731667  8058 sgd_solver.cpp:105] Iteration 64350, lr = 0.001
I0618 12:40:41.076851  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 12:41:14.538858  8058 solver.cpp:218] Iteration 64400 (0.864951 iter/s, 57.8067s/50 iters), loss = 0.00683737
I0618 12:41:14.539038  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 12:41:14.539067  8058 solver.cpp:237]     Train net output #1: loss = 0.0068374 (* 1 = 0.0068374 loss)
I0618 12:41:14.539084  8058 sgd_solver.cpp:105] Iteration 64400, lr = 0.001
I0618 12:42:12.346717  8058 solver.cpp:218] Iteration 64450 (0.864945 iter/s, 57.8072s/50 iters), loss = 0.00660708
I0618 12:42:12.346879  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 12:42:12.346907  8058 solver.cpp:237]     Train net output #1: loss = 0.00660711 (* 1 = 0.00660711 loss)
I0618 12:42:12.346925  8058 sgd_solver.cpp:105] Iteration 64450, lr = 0.001
I0618 12:42:59.804153  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 12:43:10.145974  8058 solver.cpp:218] Iteration 64500 (0.865073 iter/s, 57.7986s/50 iters), loss = 0.0066056
I0618 12:43:10.146087  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 12:43:10.146116  8058 solver.cpp:237]     Train net output #1: loss = 0.00660563 (* 1 = 0.00660563 loss)
I0618 12:43:10.146138  8058 sgd_solver.cpp:105] Iteration 64500, lr = 0.001
I0618 12:44:07.954738  8058 solver.cpp:218] Iteration 64550 (0.86493 iter/s, 57.8081s/50 iters), loss = 0.00679272
I0618 12:44:07.954895  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 12:44:07.954926  8058 solver.cpp:237]     Train net output #1: loss = 0.00679275 (* 1 = 0.00679275 loss)
I0618 12:44:07.954944  8058 sgd_solver.cpp:105] Iteration 64550, lr = 0.001
I0618 12:45:05.763857  8058 solver.cpp:218] Iteration 64600 (0.864926 iter/s, 57.8084s/50 iters), loss = 0.00711361
I0618 12:45:05.764016  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 12:45:05.764045  8058 solver.cpp:237]     Train net output #1: loss = 0.00711365 (* 1 = 0.00711365 loss)
I0618 12:45:05.764063  8058 sgd_solver.cpp:105] Iteration 64600, lr = 0.001
I0618 12:45:18.550961  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 12:46:03.571175  8058 solver.cpp:218] Iteration 64650 (0.864952 iter/s, 57.8066s/50 iters), loss = 0.00726407
I0618 12:46:03.571336  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 12:46:03.571367  8058 solver.cpp:237]     Train net output #1: loss = 0.0072641 (* 1 = 0.0072641 loss)
I0618 12:46:03.571384  8058 sgd_solver.cpp:105] Iteration 64650, lr = 0.001
I0618 12:47:01.386201  8058 solver.cpp:218] Iteration 64700 (0.864837 iter/s, 57.8143s/50 iters), loss = 0.00783904
I0618 12:47:01.386346  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 12:47:01.386379  8058 solver.cpp:237]     Train net output #1: loss = 0.00783907 (* 1 = 0.00783907 loss)
I0618 12:47:01.386400  8058 sgd_solver.cpp:105] Iteration 64700, lr = 0.001
I0618 12:47:37.299964  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 12:47:59.188154  8058 solver.cpp:218] Iteration 64750 (0.865032 iter/s, 57.8013s/50 iters), loss = 0.00674596
I0618 12:47:59.188261  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 12:47:59.188288  8058 solver.cpp:237]     Train net output #1: loss = 0.00674599 (* 1 = 0.00674599 loss)
I0618 12:47:59.188305  8058 sgd_solver.cpp:105] Iteration 64750, lr = 0.001
I0618 12:48:56.995203  8058 solver.cpp:218] Iteration 64800 (0.864955 iter/s, 57.8064s/50 iters), loss = 0.00814859
I0618 12:48:56.995332  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 12:48:56.995360  8058 solver.cpp:237]     Train net output #1: loss = 0.00814863 (* 1 = 0.00814863 loss)
I0618 12:48:56.995378  8058 sgd_solver.cpp:105] Iteration 64800, lr = 0.001
I0618 12:49:54.758054  8058 solver.cpp:218] Iteration 64850 (0.865618 iter/s, 57.7622s/50 iters), loss = 0.00830788
I0618 12:49:54.758167  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 12:49:54.758194  8058 solver.cpp:237]     Train net output #1: loss = 0.00830791 (* 1 = 0.00830791 loss)
I0618 12:49:54.758213  8058 sgd_solver.cpp:105] Iteration 64850, lr = 0.001
I0618 12:49:55.964174  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 12:50:52.522984  8058 solver.cpp:218] Iteration 64900 (0.865586 iter/s, 57.7643s/50 iters), loss = 0.00681616
I0618 12:50:52.523113  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 12:50:52.523145  8058 solver.cpp:237]     Train net output #1: loss = 0.0068162 (* 1 = 0.0068162 loss)
I0618 12:50:52.523165  8058 sgd_solver.cpp:105] Iteration 64900, lr = 0.001
I0618 12:51:50.271718  8058 solver.cpp:218] Iteration 64950 (0.865829 iter/s, 57.7481s/50 iters), loss = 0.00630512
I0618 12:51:50.271829  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 12:51:50.271858  8058 solver.cpp:237]     Train net output #1: loss = 0.00630516 (* 1 = 0.00630516 loss)
I0618 12:51:50.271877  8058 sgd_solver.cpp:105] Iteration 64950, lr = 0.001
I0618 12:52:13.462388  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 12:52:48.035302  8058 solver.cpp:218] Iteration 65000 (0.865606 iter/s, 57.763s/50 iters), loss = 0.00635542
I0618 12:52:48.035436  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 12:52:48.035465  8058 solver.cpp:237]     Train net output #1: loss = 0.00635546 (* 1 = 0.00635546 loss)
I0618 12:52:48.035482  8058 sgd_solver.cpp:105] Iteration 65000, lr = 0.001
I0618 12:53:45.801587  8058 solver.cpp:218] Iteration 65050 (0.865566 iter/s, 57.7657s/50 iters), loss = 0.00766526
I0618 12:53:45.801781  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 12:53:45.801810  8058 solver.cpp:237]     Train net output #1: loss = 0.00766529 (* 1 = 0.00766529 loss)
I0618 12:53:45.801828  8058 sgd_solver.cpp:105] Iteration 65050, lr = 0.001
I0618 12:54:32.106725  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 12:54:43.560081  8058 solver.cpp:218] Iteration 65100 (0.865685 iter/s, 57.7578s/50 iters), loss = 0.00655068
I0618 12:54:43.560173  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 12:54:43.560204  8058 solver.cpp:237]     Train net output #1: loss = 0.00655072 (* 1 = 0.00655072 loss)
I0618 12:54:43.560225  8058 sgd_solver.cpp:105] Iteration 65100, lr = 0.001
I0618 12:55:41.317576  8058 solver.cpp:218] Iteration 65150 (0.865697 iter/s, 57.7569s/50 iters), loss = 0.00950053
I0618 12:55:41.317713  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 12:55:41.317742  8058 solver.cpp:237]     Train net output #1: loss = 0.00950056 (* 1 = 0.00950056 loss)
I0618 12:55:41.317759  8058 sgd_solver.cpp:105] Iteration 65150, lr = 0.001
I0618 12:56:39.069039  8058 solver.cpp:218] Iteration 65200 (0.865789 iter/s, 57.7508s/50 iters), loss = 0.00740481
I0618 12:56:39.069123  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 12:56:39.069150  8058 solver.cpp:237]     Train net output #1: loss = 0.00740484 (* 1 = 0.00740484 loss)
I0618 12:56:39.069167  8058 sgd_solver.cpp:105] Iteration 65200, lr = 0.001
I0618 12:56:50.692080  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 12:57:36.822057  8058 solver.cpp:218] Iteration 65250 (0.865765 iter/s, 57.7524s/50 iters), loss = 0.00652613
I0618 12:57:36.822252  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 12:57:36.822283  8058 solver.cpp:237]     Train net output #1: loss = 0.00652617 (* 1 = 0.00652617 loss)
I0618 12:57:36.822301  8058 sgd_solver.cpp:105] Iteration 65250, lr = 0.001
I0618 12:58:34.581104  8058 solver.cpp:218] Iteration 65300 (0.865676 iter/s, 57.7583s/50 iters), loss = 0.00634078
I0618 12:58:34.581243  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 12:58:34.581271  8058 solver.cpp:237]     Train net output #1: loss = 0.00634082 (* 1 = 0.00634082 loss)
I0618 12:58:34.581290  8058 sgd_solver.cpp:105] Iteration 65300, lr = 0.001
I0618 12:59:09.310817  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 12:59:32.364828  8058 solver.cpp:218] Iteration 65350 (0.865305 iter/s, 57.7831s/50 iters), loss = 0.0078312
I0618 12:59:32.364910  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 12:59:32.364938  8058 solver.cpp:237]     Train net output #1: loss = 0.00783123 (* 1 = 0.00783123 loss)
I0618 12:59:32.364967  8058 sgd_solver.cpp:105] Iteration 65350, lr = 0.001
I0618 13:00:30.125608  8058 solver.cpp:218] Iteration 65400 (0.865648 iter/s, 57.7602s/50 iters), loss = 0.00606218
I0618 13:00:30.125725  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 13:00:30.125753  8058 solver.cpp:237]     Train net output #1: loss = 0.00606222 (* 1 = 0.00606222 loss)
I0618 13:00:30.125771  8058 sgd_solver.cpp:105] Iteration 65400, lr = 0.001
I0618 13:01:27.888607  8058 solver.cpp:218] Iteration 65450 (0.865615 iter/s, 57.7624s/50 iters), loss = 0.0083415
I0618 13:01:27.888731  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 13:01:27.888761  8058 solver.cpp:237]     Train net output #1: loss = 0.00834154 (* 1 = 0.00834154 loss)
I0618 13:01:27.888777  8058 sgd_solver.cpp:105] Iteration 65450, lr = 0.001
I0618 13:01:27.978329  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 13:02:25.646008  8058 solver.cpp:218] Iteration 65500 (0.8657 iter/s, 57.7567s/50 iters), loss = 0.00782916
I0618 13:02:25.646113  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 13:02:25.646142  8058 solver.cpp:237]     Train net output #1: loss = 0.00782919 (* 1 = 0.00782919 loss)
I0618 13:02:25.646159  8058 sgd_solver.cpp:105] Iteration 65500, lr = 0.001
I0618 13:03:23.409180  8058 solver.cpp:218] Iteration 65550 (0.865613 iter/s, 57.7625s/50 iters), loss = 0.00725973
I0618 13:03:23.409291  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 13:03:23.409320  8058 solver.cpp:237]     Train net output #1: loss = 0.00725976 (* 1 = 0.00725976 loss)
I0618 13:03:23.409338  8058 sgd_solver.cpp:105] Iteration 65550, lr = 0.001
I0618 13:03:46.586264  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 13:04:21.168326  8058 solver.cpp:218] Iteration 65600 (0.865674 iter/s, 57.7585s/50 iters), loss = 0.00732874
I0618 13:04:21.168445  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 13:04:21.168473  8058 solver.cpp:237]     Train net output #1: loss = 0.00732877 (* 1 = 0.00732877 loss)
I0618 13:04:21.168491  8058 sgd_solver.cpp:105] Iteration 65600, lr = 0.001
I0618 13:05:18.923844  8058 solver.cpp:218] Iteration 65650 (0.865728 iter/s, 57.7549s/50 iters), loss = 0.00632713
I0618 13:05:18.923966  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 13:05:18.923995  8058 solver.cpp:237]     Train net output #1: loss = 0.00632717 (* 1 = 0.00632717 loss)
I0618 13:05:18.924013  8058 sgd_solver.cpp:105] Iteration 65650, lr = 0.001
I0618 13:06:05.215529  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 13:06:16.686735  8058 solver.cpp:218] Iteration 65700 (0.865618 iter/s, 57.7622s/50 iters), loss = 0.00610589
I0618 13:06:16.686815  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 13:06:16.686841  8058 solver.cpp:237]     Train net output #1: loss = 0.00610592 (* 1 = 0.00610592 loss)
I0618 13:06:16.686859  8058 sgd_solver.cpp:105] Iteration 65700, lr = 0.001
I0618 13:07:14.447233  8058 solver.cpp:218] Iteration 65750 (0.865653 iter/s, 57.7599s/50 iters), loss = 0.00702459
I0618 13:07:14.447403  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 13:07:14.447433  8058 solver.cpp:237]     Train net output #1: loss = 0.00702462 (* 1 = 0.00702462 loss)
I0618 13:07:14.447451  8058 sgd_solver.cpp:105] Iteration 65750, lr = 0.001
I0618 13:08:12.204247  8058 solver.cpp:218] Iteration 65800 (0.865706 iter/s, 57.7563s/50 iters), loss = 0.00622988
I0618 13:08:12.204366  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 13:08:12.204396  8058 solver.cpp:237]     Train net output #1: loss = 0.00622992 (* 1 = 0.00622992 loss)
I0618 13:08:12.204412  8058 sgd_solver.cpp:105] Iteration 65800, lr = 0.001
I0618 13:08:23.810833  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 13:09:09.965577  8058 solver.cpp:218] Iteration 65850 (0.865641 iter/s, 57.7607s/50 iters), loss = 0.00640423
I0618 13:09:09.965687  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 13:09:09.965728  8058 solver.cpp:237]     Train net output #1: loss = 0.00640426 (* 1 = 0.00640426 loss)
I0618 13:09:09.965745  8058 sgd_solver.cpp:105] Iteration 65850, lr = 0.001
I0618 13:10:07.718116  8058 solver.cpp:218] Iteration 65900 (0.865773 iter/s, 57.7519s/50 iters), loss = 0.00749149
I0618 13:10:07.718251  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 13:10:07.718281  8058 solver.cpp:237]     Train net output #1: loss = 0.00749152 (* 1 = 0.00749152 loss)
I0618 13:10:07.718297  8058 sgd_solver.cpp:105] Iteration 65900, lr = 0.001
I0618 13:10:41.328465  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 13:11:05.483078  8058 solver.cpp:218] Iteration 65950 (0.865587 iter/s, 57.7643s/50 iters), loss = 0.00877549
I0618 13:11:05.483168  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 13:11:05.483196  8058 solver.cpp:237]     Train net output #1: loss = 0.00877553 (* 1 = 0.00877553 loss)
I0618 13:11:05.483213  8058 sgd_solver.cpp:105] Iteration 65950, lr = 0.001
I0618 13:12:03.256817  8058 solver.cpp:218] Iteration 66000 (0.865454 iter/s, 57.7731s/50 iters), loss = 0.00616255
I0618 13:12:03.256927  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 13:12:03.256954  8058 solver.cpp:237]     Train net output #1: loss = 0.00616259 (* 1 = 0.00616259 loss)
I0618 13:12:03.256971  8058 sgd_solver.cpp:105] Iteration 66000, lr = 0.001
I0618 13:12:59.966145  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 13:13:01.016537  8058 solver.cpp:218] Iteration 66050 (0.865665 iter/s, 57.7591s/50 iters), loss = 0.00687342
I0618 13:13:01.016611  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 13:13:01.016636  8058 solver.cpp:237]     Train net output #1: loss = 0.00687345 (* 1 = 0.00687345 loss)
I0618 13:13:01.016654  8058 sgd_solver.cpp:105] Iteration 66050, lr = 0.001
I0618 13:13:58.774060  8058 solver.cpp:218] Iteration 66100 (0.865697 iter/s, 57.7569s/50 iters), loss = 0.00673355
I0618 13:13:58.774169  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 13:13:58.774196  8058 solver.cpp:237]     Train net output #1: loss = 0.00673358 (* 1 = 0.00673358 loss)
I0618 13:13:58.774214  8058 sgd_solver.cpp:105] Iteration 66100, lr = 0.001
I0618 13:14:56.532838  8058 solver.cpp:218] Iteration 66150 (0.865679 iter/s, 57.7581s/50 iters), loss = 0.00996457
I0618 13:14:56.532964  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 13:14:56.532992  8058 solver.cpp:237]     Train net output #1: loss = 0.0099646 (* 1 = 0.0099646 loss)
I0618 13:14:56.533010  8058 sgd_solver.cpp:105] Iteration 66150, lr = 0.001
I0618 13:15:18.582437  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 13:15:54.287940  8058 solver.cpp:218] Iteration 66200 (0.865734 iter/s, 57.7544s/50 iters), loss = 0.00690488
I0618 13:15:54.288097  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 13:15:54.288126  8058 solver.cpp:237]     Train net output #1: loss = 0.00690491 (* 1 = 0.00690491 loss)
I0618 13:15:54.288143  8058 sgd_solver.cpp:105] Iteration 66200, lr = 0.001
I0618 13:16:52.049417  8058 solver.cpp:218] Iteration 66250 (0.865639 iter/s, 57.7608s/50 iters), loss = 0.0066656
I0618 13:16:52.049533  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 13:16:52.049563  8058 solver.cpp:237]     Train net output #1: loss = 0.00666563 (* 1 = 0.00666563 loss)
I0618 13:16:52.049582  8058 sgd_solver.cpp:105] Iteration 66250, lr = 0.001
I0618 13:17:37.172663  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 13:17:49.796902  8058 solver.cpp:218] Iteration 66300 (0.865848 iter/s, 57.7468s/50 iters), loss = 0.00624967
I0618 13:17:49.796984  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 13:17:49.797011  8058 solver.cpp:237]     Train net output #1: loss = 0.0062497 (* 1 = 0.0062497 loss)
I0618 13:17:49.797029  8058 sgd_solver.cpp:105] Iteration 66300, lr = 0.001
I0618 13:18:47.559857  8058 solver.cpp:218] Iteration 66350 (0.865616 iter/s, 57.7623s/50 iters), loss = 0.00656167
I0618 13:18:47.559979  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 13:18:47.560008  8058 solver.cpp:237]     Train net output #1: loss = 0.0065617 (* 1 = 0.0065617 loss)
I0618 13:18:47.560024  8058 sgd_solver.cpp:105] Iteration 66350, lr = 0.001
I0618 13:19:45.325793  8058 solver.cpp:218] Iteration 66400 (0.865571 iter/s, 57.7653s/50 iters), loss = 0.00613802
I0618 13:19:45.325911  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 13:19:45.325939  8058 solver.cpp:237]     Train net output #1: loss = 0.00613806 (* 1 = 0.00613806 loss)
I0618 13:19:45.325956  8058 sgd_solver.cpp:105] Iteration 66400, lr = 0.001
I0618 13:19:55.788527  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 13:20:43.100811  8058 solver.cpp:218] Iteration 66450 (0.865435 iter/s, 57.7744s/50 iters), loss = 0.00707875
I0618 13:20:43.100915  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 13:20:43.100944  8058 solver.cpp:237]     Train net output #1: loss = 0.00707878 (* 1 = 0.00707878 loss)
I0618 13:20:43.100960  8058 sgd_solver.cpp:105] Iteration 66450, lr = 0.001
I0618 13:21:40.864280  8058 solver.cpp:218] Iteration 66500 (0.865608 iter/s, 57.7629s/50 iters), loss = 0.00939109
I0618 13:21:40.864477  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 13:21:40.864506  8058 solver.cpp:237]     Train net output #1: loss = 0.00939113 (* 1 = 0.00939113 loss)
I0618 13:21:40.864531  8058 sgd_solver.cpp:105] Iteration 66500, lr = 0.001
I0618 13:22:14.440560  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 13:22:38.613023  8058 solver.cpp:218] Iteration 66550 (0.86583 iter/s, 57.7481s/50 iters), loss = 0.00849983
I0618 13:22:38.613099  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 13:22:38.613126  8058 solver.cpp:237]     Train net output #1: loss = 0.00849986 (* 1 = 0.00849986 loss)
I0618 13:22:38.613147  8058 sgd_solver.cpp:105] Iteration 66550, lr = 0.001
I0618 13:23:36.382175  8058 solver.cpp:218] Iteration 66600 (0.865522 iter/s, 57.7686s/50 iters), loss = 0.00628776
I0618 13:23:36.382288  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 13:23:36.382316  8058 solver.cpp:237]     Train net output #1: loss = 0.0062878 (* 1 = 0.0062878 loss)
I0618 13:23:36.382333  8058 sgd_solver.cpp:105] Iteration 66600, lr = 0.001
I0618 13:24:33.087429  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 13:24:34.161219  8058 solver.cpp:218] Iteration 66650 (0.865375 iter/s, 57.7784s/50 iters), loss = 0.00848713
I0618 13:24:34.161299  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 13:24:34.161325  8058 solver.cpp:237]     Train net output #1: loss = 0.00848717 (* 1 = 0.00848717 loss)
I0618 13:24:34.161342  8058 sgd_solver.cpp:105] Iteration 66650, lr = 0.001
I0618 13:25:31.916776  8058 solver.cpp:218] Iteration 66700 (0.865726 iter/s, 57.755s/50 iters), loss = 0.00859623
I0618 13:25:31.917119  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 13:25:31.917150  8058 solver.cpp:237]     Train net output #1: loss = 0.00859627 (* 1 = 0.00859627 loss)
I0618 13:25:31.917167  8058 sgd_solver.cpp:105] Iteration 66700, lr = 0.001
I0618 13:26:29.673720  8058 solver.cpp:218] Iteration 66750 (0.865709 iter/s, 57.7561s/50 iters), loss = 0.00674335
I0618 13:26:29.673846  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 13:26:29.673878  8058 solver.cpp:237]     Train net output #1: loss = 0.00674338 (* 1 = 0.00674338 loss)
I0618 13:26:29.673899  8058 sgd_solver.cpp:105] Iteration 66750, lr = 0.001
I0618 13:26:51.699589  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 13:27:27.433744  8058 solver.cpp:218] Iteration 66800 (0.86566 iter/s, 57.7594s/50 iters), loss = 0.00814896
I0618 13:27:27.433851  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 13:27:27.433879  8058 solver.cpp:237]     Train net output #1: loss = 0.00814899 (* 1 = 0.00814899 loss)
I0618 13:27:27.433897  8058 sgd_solver.cpp:105] Iteration 66800, lr = 0.001
I0618 13:28:25.193168  8058 solver.cpp:218] Iteration 66850 (0.865669 iter/s, 57.7588s/50 iters), loss = 0.00521974
I0618 13:28:25.193284  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 13:28:25.193311  8058 solver.cpp:237]     Train net output #1: loss = 0.00521977 (* 1 = 0.00521977 loss)
I0618 13:28:25.193330  8058 sgd_solver.cpp:105] Iteration 66850, lr = 0.001
I0618 13:29:10.287781  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 13:29:22.950935  8058 solver.cpp:218] Iteration 66900 (0.865694 iter/s, 57.7571s/50 iters), loss = 0.00721796
I0618 13:29:22.951021  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 13:29:22.951048  8058 solver.cpp:237]     Train net output #1: loss = 0.00721799 (* 1 = 0.00721799 loss)
I0618 13:29:22.951066  8058 sgd_solver.cpp:105] Iteration 66900, lr = 0.001
I0618 13:30:20.717859  8058 solver.cpp:218] Iteration 66950 (0.865556 iter/s, 57.7663s/50 iters), loss = 0.00677522
I0618 13:30:20.717973  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 13:30:20.718003  8058 solver.cpp:237]     Train net output #1: loss = 0.00677525 (* 1 = 0.00677525 loss)
I0618 13:30:20.718020  8058 sgd_solver.cpp:105] Iteration 66950, lr = 0.001
I0618 13:31:18.489609  8058 solver.cpp:218] Iteration 67000 (0.865485 iter/s, 57.7711s/50 iters), loss = 0.0070102
I0618 13:31:18.489749  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 13:31:18.489783  8058 solver.cpp:237]     Train net output #1: loss = 0.00701023 (* 1 = 0.00701023 loss)
I0618 13:31:18.489802  8058 sgd_solver.cpp:105] Iteration 67000, lr = 0.001
I0618 13:31:27.824079  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 13:32:16.247189  8058 solver.cpp:218] Iteration 67050 (0.865697 iter/s, 57.7569s/50 iters), loss = 0.00589874
I0618 13:32:16.247308  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 13:32:16.247335  8058 solver.cpp:237]     Train net output #1: loss = 0.00589878 (* 1 = 0.00589878 loss)
I0618 13:32:16.247354  8058 sgd_solver.cpp:105] Iteration 67050, lr = 0.001
I0618 13:33:14.008379  8058 solver.cpp:218] Iteration 67100 (0.865643 iter/s, 57.7606s/50 iters), loss = 0.00715196
I0618 13:33:14.008525  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 13:33:14.008560  8058 solver.cpp:237]     Train net output #1: loss = 0.00715199 (* 1 = 0.00715199 loss)
I0618 13:33:14.008581  8058 sgd_solver.cpp:105] Iteration 67100, lr = 0.001
I0618 13:33:46.432173  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 13:34:11.762344  8058 solver.cpp:218] Iteration 67150 (0.865751 iter/s, 57.7533s/50 iters), loss = 0.006318
I0618 13:34:11.762418  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 13:34:11.762444  8058 solver.cpp:237]     Train net output #1: loss = 0.00631804 (* 1 = 0.00631804 loss)
I0618 13:34:11.762462  8058 sgd_solver.cpp:105] Iteration 67150, lr = 0.001
I0618 13:35:09.524991  8058 solver.cpp:218] Iteration 67200 (0.86562 iter/s, 57.7621s/50 iters), loss = 0.00660803
I0618 13:35:09.525163  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 13:35:09.525193  8058 solver.cpp:237]     Train net output #1: loss = 0.00660806 (* 1 = 0.00660806 loss)
I0618 13:35:09.525212  8058 sgd_solver.cpp:105] Iteration 67200, lr = 0.001
I0618 13:36:05.072948  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 13:36:07.280525  8058 solver.cpp:218] Iteration 67250 (0.865728 iter/s, 57.7549s/50 iters), loss = 0.00699877
I0618 13:36:07.280596  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 13:36:07.280622  8058 solver.cpp:237]     Train net output #1: loss = 0.0069988 (* 1 = 0.0069988 loss)
I0618 13:36:07.280640  8058 sgd_solver.cpp:105] Iteration 67250, lr = 0.001
I0618 13:37:05.043434  8058 solver.cpp:218] Iteration 67300 (0.865616 iter/s, 57.7623s/50 iters), loss = 0.00848572
I0618 13:37:05.043553  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 13:37:05.043583  8058 solver.cpp:237]     Train net output #1: loss = 0.00848575 (* 1 = 0.00848575 loss)
I0618 13:37:05.043614  8058 sgd_solver.cpp:105] Iteration 67300, lr = 0.001
I0618 13:38:02.806749  8058 solver.cpp:218] Iteration 67350 (0.865611 iter/s, 57.7627s/50 iters), loss = 0.00803912
I0618 13:38:02.806869  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 13:38:02.806896  8058 solver.cpp:237]     Train net output #1: loss = 0.00803916 (* 1 = 0.00803916 loss)
I0618 13:38:02.806915  8058 sgd_solver.cpp:105] Iteration 67350, lr = 0.001
I0618 13:38:23.678966  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 13:39:00.569437  8058 solver.cpp:218] Iteration 67400 (0.86562 iter/s, 57.7621s/50 iters), loss = 0.00762718
I0618 13:39:00.569896  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 13:39:00.569931  8058 solver.cpp:237]     Train net output #1: loss = 0.00762721 (* 1 = 0.00762721 loss)
I0618 13:39:00.569950  8058 sgd_solver.cpp:105] Iteration 67400, lr = 0.001
I0618 13:39:58.331768  8058 solver.cpp:218] Iteration 67450 (0.86563 iter/s, 57.7614s/50 iters), loss = 0.00701363
I0618 13:39:58.331879  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 13:39:58.331908  8058 solver.cpp:237]     Train net output #1: loss = 0.00701366 (* 1 = 0.00701366 loss)
I0618 13:39:58.331925  8058 sgd_solver.cpp:105] Iteration 67450, lr = 0.001
I0618 13:40:42.294766  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 13:40:56.087225  8058 solver.cpp:218] Iteration 67500 (0.865728 iter/s, 57.7548s/50 iters), loss = 0.00668967
I0618 13:40:56.087301  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 13:40:56.087327  8058 solver.cpp:237]     Train net output #1: loss = 0.00668971 (* 1 = 0.00668971 loss)
I0618 13:40:56.087344  8058 sgd_solver.cpp:105] Iteration 67500, lr = 0.001
I0618 13:41:53.835254  8058 solver.cpp:218] Iteration 67550 (0.865839 iter/s, 57.7475s/50 iters), loss = 0.00856736
I0618 13:41:53.835425  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 13:41:53.835454  8058 solver.cpp:237]     Train net output #1: loss = 0.00856739 (* 1 = 0.00856739 loss)
I0618 13:41:53.835471  8058 sgd_solver.cpp:105] Iteration 67550, lr = 0.001
I0618 13:42:51.596248  8058 solver.cpp:218] Iteration 67600 (0.865646 iter/s, 57.7603s/50 iters), loss = 0.00656463
I0618 13:42:51.596364  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 13:42:51.596392  8058 solver.cpp:237]     Train net output #1: loss = 0.00656466 (* 1 = 0.00656466 loss)
I0618 13:42:51.596410  8058 sgd_solver.cpp:105] Iteration 67600, lr = 0.001
I0618 13:43:00.901374  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 13:43:49.356058  8058 solver.cpp:218] Iteration 67650 (0.865663 iter/s, 57.7592s/50 iters), loss = 0.00727028
I0618 13:43:49.356214  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 13:43:49.356245  8058 solver.cpp:237]     Train net output #1: loss = 0.00727031 (* 1 = 0.00727031 loss)
I0618 13:43:49.356262  8058 sgd_solver.cpp:105] Iteration 67650, lr = 0.001
I0618 13:44:47.110954  8058 solver.cpp:218] Iteration 67700 (0.865737 iter/s, 57.7542s/50 iters), loss = 0.00785016
I0618 13:44:47.111080  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 13:44:47.111109  8058 solver.cpp:237]     Train net output #1: loss = 0.0078502 (* 1 = 0.0078502 loss)
I0618 13:44:47.111125  8058 sgd_solver.cpp:105] Iteration 67700, lr = 0.001
I0618 13:45:19.512233  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 13:45:44.872397  8058 solver.cpp:218] Iteration 67750 (0.865639 iter/s, 57.7608s/50 iters), loss = 0.00890658
I0618 13:45:44.872474  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 13:45:44.872500  8058 solver.cpp:237]     Train net output #1: loss = 0.00890662 (* 1 = 0.00890662 loss)
I0618 13:45:44.872524  8058 sgd_solver.cpp:105] Iteration 67750, lr = 0.001
I0618 13:46:42.632473  8058 solver.cpp:218] Iteration 67800 (0.865659 iter/s, 57.7595s/50 iters), loss = 0.00839874
I0618 13:46:42.632601  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 13:46:42.632644  8058 solver.cpp:237]     Train net output #1: loss = 0.00839877 (* 1 = 0.00839877 loss)
I0618 13:46:42.632663  8058 sgd_solver.cpp:105] Iteration 67800, lr = 0.001
I0618 13:47:38.143792  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 13:47:40.398520  8058 solver.cpp:218] Iteration 67850 (0.86557 iter/s, 57.7654s/50 iters), loss = 0.00725932
I0618 13:47:40.398596  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 13:47:40.398622  8058 solver.cpp:237]     Train net output #1: loss = 0.00725935 (* 1 = 0.00725935 loss)
I0618 13:47:40.398638  8058 sgd_solver.cpp:105] Iteration 67850, lr = 0.001
I0618 13:48:38.165868  8058 solver.cpp:218] Iteration 67900 (0.86555 iter/s, 57.7668s/50 iters), loss = 0.0074932
I0618 13:48:38.165998  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 13:48:38.166028  8058 solver.cpp:237]     Train net output #1: loss = 0.00749324 (* 1 = 0.00749324 loss)
I0618 13:48:38.166044  8058 sgd_solver.cpp:105] Iteration 67900, lr = 0.001
I0618 13:49:35.927454  8058 solver.cpp:218] Iteration 67950 (0.865637 iter/s, 57.761s/50 iters), loss = 0.00549744
I0618 13:49:35.927592  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 13:49:35.927621  8058 solver.cpp:237]     Train net output #1: loss = 0.00549748 (* 1 = 0.00549748 loss)
I0618 13:49:35.927640  8058 sgd_solver.cpp:105] Iteration 67950, lr = 0.001
I0618 13:49:55.672276  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 13:50:33.682775  8058 solver.cpp:218] Iteration 68000 (0.865731 iter/s, 57.7547s/50 iters), loss = 0.00935854
I0618 13:50:33.682909  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 13:50:33.682937  8058 solver.cpp:237]     Train net output #1: loss = 0.00935858 (* 1 = 0.00935858 loss)
I0618 13:50:33.682955  8058 sgd_solver.cpp:105] Iteration 68000, lr = 0.001
I0618 13:51:31.449028  8058 solver.cpp:218] Iteration 68050 (0.865567 iter/s, 57.7656s/50 iters), loss = 0.00861115
I0618 13:51:31.449139  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 13:51:31.449168  8058 solver.cpp:237]     Train net output #1: loss = 0.00861119 (* 1 = 0.00861119 loss)
I0618 13:51:31.449187  8058 sgd_solver.cpp:105] Iteration 68050, lr = 0.001
I0618 13:52:14.275897  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 13:52:29.209810  8058 solver.cpp:218] Iteration 68100 (0.865649 iter/s, 57.7602s/50 iters), loss = 0.00798998
I0618 13:52:29.209890  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 13:52:29.209916  8058 solver.cpp:237]     Train net output #1: loss = 0.00799002 (* 1 = 0.00799002 loss)
I0618 13:52:29.209933  8058 sgd_solver.cpp:105] Iteration 68100, lr = 0.001
I0618 13:53:26.962019  8058 solver.cpp:218] Iteration 68150 (0.865777 iter/s, 57.7516s/50 iters), loss = 0.00960737
I0618 13:53:26.962206  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 13:53:26.962239  8058 solver.cpp:237]     Train net output #1: loss = 0.0096074 (* 1 = 0.0096074 loss)
I0618 13:53:26.962256  8058 sgd_solver.cpp:105] Iteration 68150, lr = 0.001
I0618 13:54:24.728938  8058 solver.cpp:218] Iteration 68200 (0.865557 iter/s, 57.7662s/50 iters), loss = 0.0065105
I0618 13:54:24.729069  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 13:54:24.729099  8058 solver.cpp:237]     Train net output #1: loss = 0.00651054 (* 1 = 0.00651054 loss)
I0618 13:54:24.729115  8058 sgd_solver.cpp:105] Iteration 68200, lr = 0.001
I0618 13:54:32.892029  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 13:55:22.498776  8058 solver.cpp:218] Iteration 68250 (0.865513 iter/s, 57.7692s/50 iters), loss = 0.00609626
I0618 13:55:22.498888  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 13:55:22.498916  8058 solver.cpp:237]     Train net output #1: loss = 0.0060963 (* 1 = 0.0060963 loss)
I0618 13:55:22.498934  8058 sgd_solver.cpp:105] Iteration 68250, lr = 0.001
I0618 13:56:20.252646  8058 solver.cpp:218] Iteration 68300 (0.865752 iter/s, 57.7533s/50 iters), loss = 0.00676449
I0618 13:56:20.252770  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 13:56:20.252799  8058 solver.cpp:237]     Train net output #1: loss = 0.00676453 (* 1 = 0.00676453 loss)
I0618 13:56:20.252816  8058 sgd_solver.cpp:105] Iteration 68300, lr = 0.001
I0618 13:56:51.511736  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 13:57:18.010421  8058 solver.cpp:218] Iteration 68350 (0.865694 iter/s, 57.7572s/50 iters), loss = 0.00873889
I0618 13:57:18.010498  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 13:57:18.010529  8058 solver.cpp:237]     Train net output #1: loss = 0.00873892 (* 1 = 0.00873892 loss)
I0618 13:57:18.010548  8058 sgd_solver.cpp:105] Iteration 68350, lr = 0.001
I0618 13:58:15.774232  8058 solver.cpp:218] Iteration 68400 (0.865602 iter/s, 57.7632s/50 iters), loss = 0.00856058
I0618 13:58:15.774346  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 13:58:15.774375  8058 solver.cpp:237]     Train net output #1: loss = 0.00856061 (* 1 = 0.00856061 loss)
I0618 13:58:15.774392  8058 sgd_solver.cpp:105] Iteration 68400, lr = 0.001
I0618 13:59:10.126725  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 13:59:13.529434  8058 solver.cpp:218] Iteration 68450 (0.865732 iter/s, 57.7546s/50 iters), loss = 0.00751862
I0618 13:59:13.529516  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 13:59:13.529546  8058 solver.cpp:237]     Train net output #1: loss = 0.00751865 (* 1 = 0.00751865 loss)
I0618 13:59:13.529566  8058 sgd_solver.cpp:105] Iteration 68450, lr = 0.001
I0618 14:00:11.298692  8058 solver.cpp:218] Iteration 68500 (0.865521 iter/s, 57.7687s/50 iters), loss = 0.00531717
I0618 14:00:11.298820  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:00:11.298848  8058 solver.cpp:237]     Train net output #1: loss = 0.0053172 (* 1 = 0.0053172 loss)
I0618 14:00:11.298866  8058 sgd_solver.cpp:105] Iteration 68500, lr = 0.001
I0618 14:01:09.067261  8058 solver.cpp:218] Iteration 68550 (0.865532 iter/s, 57.7679s/50 iters), loss = 0.00762104
I0618 14:01:09.067384  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:01:09.067414  8058 solver.cpp:237]     Train net output #1: loss = 0.00762107 (* 1 = 0.00762107 loss)
I0618 14:01:09.067431  8058 sgd_solver.cpp:105] Iteration 68550, lr = 0.001
I0618 14:01:28.771368  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 14:02:06.840890  8058 solver.cpp:218] Iteration 68600 (0.865456 iter/s, 57.773s/50 iters), loss = 0.00805152
I0618 14:02:06.841013  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:02:06.841042  8058 solver.cpp:237]     Train net output #1: loss = 0.00805155 (* 1 = 0.00805155 loss)
I0618 14:02:06.841060  8058 sgd_solver.cpp:105] Iteration 68600, lr = 0.001
I0618 14:03:04.601310  8058 solver.cpp:218] Iteration 68650 (0.865654 iter/s, 57.7598s/50 iters), loss = 0.00625353
I0618 14:03:04.601475  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:03:04.601510  8058 solver.cpp:237]     Train net output #1: loss = 0.00625356 (* 1 = 0.00625356 loss)
I0618 14:03:04.601537  8058 sgd_solver.cpp:105] Iteration 68650, lr = 0.001
I0618 14:03:47.400725  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 14:04:02.366173  8058 solver.cpp:218] Iteration 68700 (0.865588 iter/s, 57.7642s/50 iters), loss = 0.00609085
I0618 14:04:02.366252  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:04:02.366278  8058 solver.cpp:237]     Train net output #1: loss = 0.00609089 (* 1 = 0.00609089 loss)
I0618 14:04:02.366297  8058 sgd_solver.cpp:105] Iteration 68700, lr = 0.001
I0618 14:05:00.122865  8058 solver.cpp:218] Iteration 68750 (0.865709 iter/s, 57.7561s/50 iters), loss = 0.0071622
I0618 14:05:00.123309  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:05:00.123338  8058 solver.cpp:237]     Train net output #1: loss = 0.00716224 (* 1 = 0.00716224 loss)
I0618 14:05:00.123356  8058 sgd_solver.cpp:105] Iteration 68750, lr = 0.001
I0618 14:05:57.884150  8058 solver.cpp:218] Iteration 68800 (0.865646 iter/s, 57.7603s/50 iters), loss = 0.00692028
I0618 14:05:57.884269  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:05:57.884297  8058 solver.cpp:237]     Train net output #1: loss = 0.00692031 (* 1 = 0.00692031 loss)
I0618 14:05:57.884315  8058 sgd_solver.cpp:105] Iteration 68800, lr = 0.001
I0618 14:06:06.050117  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 14:06:55.647780  8058 solver.cpp:218] Iteration 68850 (0.865606 iter/s, 57.763s/50 iters), loss = 0.011427
I0618 14:06:55.647928  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:06:55.647961  8058 solver.cpp:237]     Train net output #1: loss = 0.0114271 (* 1 = 0.0114271 loss)
I0618 14:06:55.647981  8058 sgd_solver.cpp:105] Iteration 68850, lr = 0.001
I0618 14:07:53.407274  8058 solver.cpp:218] Iteration 68900 (0.865668 iter/s, 57.7589s/50 iters), loss = 0.0066906
I0618 14:07:53.407385  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:07:53.407413  8058 solver.cpp:237]     Train net output #1: loss = 0.00669063 (* 1 = 0.00669063 loss)
I0618 14:07:53.407430  8058 sgd_solver.cpp:105] Iteration 68900, lr = 0.001
I0618 14:08:23.553251  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 14:08:51.163039  8058 solver.cpp:218] Iteration 68950 (0.865724 iter/s, 57.7552s/50 iters), loss = 0.00865422
I0618 14:08:51.163120  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:08:51.163147  8058 solver.cpp:237]     Train net output #1: loss = 0.00865425 (* 1 = 0.00865425 loss)
I0618 14:08:51.163164  8058 sgd_solver.cpp:105] Iteration 68950, lr = 0.001
I0618 14:09:48.921530  8058 solver.cpp:218] Iteration 69000 (0.865682 iter/s, 57.7579s/50 iters), loss = 0.007459
I0618 14:09:48.921730  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:09:48.921759  8058 solver.cpp:237]     Train net output #1: loss = 0.00745903 (* 1 = 0.00745903 loss)
I0618 14:09:48.921777  8058 sgd_solver.cpp:105] Iteration 69000, lr = 0.001
I0618 14:10:42.165266  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 14:10:46.679980  8058 solver.cpp:218] Iteration 69050 (0.865685 iter/s, 57.7577s/50 iters), loss = 0.00732524
I0618 14:10:46.680058  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:10:46.680088  8058 solver.cpp:237]     Train net output #1: loss = 0.00732527 (* 1 = 0.00732527 loss)
I0618 14:10:46.680107  8058 sgd_solver.cpp:105] Iteration 69050, lr = 0.001
I0618 14:11:44.433573  8058 solver.cpp:218] Iteration 69100 (0.865755 iter/s, 57.753s/50 iters), loss = 0.00728132
I0618 14:11:44.433686  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:11:44.433715  8058 solver.cpp:237]     Train net output #1: loss = 0.00728135 (* 1 = 0.00728135 loss)
I0618 14:11:44.433732  8058 sgd_solver.cpp:105] Iteration 69100, lr = 0.001
I0618 14:12:42.188377  8058 solver.cpp:218] Iteration 69150 (0.865738 iter/s, 57.7542s/50 iters), loss = 0.00585236
I0618 14:12:42.188537  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:12:42.188570  8058 solver.cpp:237]     Train net output #1: loss = 0.00585239 (* 1 = 0.00585239 loss)
I0618 14:12:42.188587  8058 sgd_solver.cpp:105] Iteration 69150, lr = 0.001
I0618 14:13:00.740258  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 14:13:39.945436  8058 solver.cpp:218] Iteration 69200 (0.865705 iter/s, 57.7564s/50 iters), loss = 0.00785586
I0618 14:13:39.945570  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:13:39.945600  8058 solver.cpp:237]     Train net output #1: loss = 0.0078559 (* 1 = 0.0078559 loss)
I0618 14:13:39.945618  8058 sgd_solver.cpp:105] Iteration 69200, lr = 0.001
I0618 14:14:37.716938  8058 solver.cpp:218] Iteration 69250 (0.865488 iter/s, 57.7709s/50 iters), loss = 0.00925453
I0618 14:14:37.717061  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:14:37.717090  8058 solver.cpp:237]     Train net output #1: loss = 0.00925457 (* 1 = 0.00925457 loss)
I0618 14:14:37.717120  8058 sgd_solver.cpp:105] Iteration 69250, lr = 0.001
I0618 14:15:19.374985  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 14:15:35.473175  8058 solver.cpp:218] Iteration 69300 (0.865717 iter/s, 57.7556s/50 iters), loss = 0.0073388
I0618 14:15:35.473256  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:15:35.473282  8058 solver.cpp:237]     Train net output #1: loss = 0.00733883 (* 1 = 0.00733883 loss)
I0618 14:15:35.473300  8058 sgd_solver.cpp:105] Iteration 69300, lr = 0.001
I0618 14:16:33.223803  8058 solver.cpp:218] Iteration 69350 (0.8658 iter/s, 57.75s/50 iters), loss = 0.00720327
I0618 14:16:33.223919  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:16:33.223948  8058 solver.cpp:237]     Train net output #1: loss = 0.0072033 (* 1 = 0.0072033 loss)
I0618 14:16:33.223965  8058 sgd_solver.cpp:105] Iteration 69350, lr = 0.001
I0618 14:17:30.982345  8058 solver.cpp:218] Iteration 69400 (0.865682 iter/s, 57.7579s/50 iters), loss = 0.0104699
I0618 14:17:30.982475  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:17:30.982502  8058 solver.cpp:237]     Train net output #1: loss = 0.0104699 (* 1 = 0.0104699 loss)
I0618 14:17:30.982525  8058 sgd_solver.cpp:105] Iteration 69400, lr = 0.001
I0618 14:17:38.003141  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 14:18:28.745640  8058 solver.cpp:218] Iteration 69450 (0.865611 iter/s, 57.7627s/50 iters), loss = 0.00570678
I0618 14:18:28.745759  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:18:28.745787  8058 solver.cpp:237]     Train net output #1: loss = 0.00570682 (* 1 = 0.00570682 loss)
I0618 14:18:28.745805  8058 sgd_solver.cpp:105] Iteration 69450, lr = 0.001
I0618 14:19:26.529777  8058 solver.cpp:218] Iteration 69500 (0.865299 iter/s, 57.7835s/50 iters), loss = 0.00626772
I0618 14:19:26.529932  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:19:26.529960  8058 solver.cpp:237]     Train net output #1: loss = 0.00626776 (* 1 = 0.00626776 loss)
I0618 14:19:26.529978  8058 sgd_solver.cpp:105] Iteration 69500, lr = 0.001
I0618 14:19:56.654938  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 14:20:24.332676  8058 solver.cpp:218] Iteration 69550 (0.865018 iter/s, 57.8022s/50 iters), loss = 0.00812699
I0618 14:20:24.332785  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:20:24.332813  8058 solver.cpp:237]     Train net output #1: loss = 0.00812702 (* 1 = 0.00812702 loss)
I0618 14:20:24.332830  8058 sgd_solver.cpp:105] Iteration 69550, lr = 0.001
I0618 14:21:22.141085  8058 solver.cpp:218] Iteration 69600 (0.864935 iter/s, 57.8078s/50 iters), loss = 0.0064694
I0618 14:21:22.141242  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:21:22.141270  8058 solver.cpp:237]     Train net output #1: loss = 0.00646943 (* 1 = 0.00646943 loss)
I0618 14:21:22.141289  8058 sgd_solver.cpp:105] Iteration 69600, lr = 0.001
I0618 14:22:15.372439  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 14:22:19.934602  8058 solver.cpp:218] Iteration 69650 (0.865159 iter/s, 57.7929s/50 iters), loss = 0.00674497
I0618 14:22:19.934700  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:22:19.934727  8058 solver.cpp:237]     Train net output #1: loss = 0.006745 (* 1 = 0.006745 loss)
I0618 14:22:19.934744  8058 sgd_solver.cpp:105] Iteration 69650, lr = 0.001
I0618 14:23:17.734774  8058 solver.cpp:218] Iteration 69700 (0.865058 iter/s, 57.7996s/50 iters), loss = 0.00710323
I0618 14:23:17.734915  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:23:17.734943  8058 solver.cpp:237]     Train net output #1: loss = 0.00710326 (* 1 = 0.00710326 loss)
I0618 14:23:17.734961  8058 sgd_solver.cpp:105] Iteration 69700, lr = 0.001
I0618 14:24:15.537611  8058 solver.cpp:218] Iteration 69750 (0.865019 iter/s, 57.8022s/50 iters), loss = 0.00657794
I0618 14:24:15.537753  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:24:15.537798  8058 solver.cpp:237]     Train net output #1: loss = 0.00657798 (* 1 = 0.00657798 loss)
I0618 14:24:15.537817  8058 sgd_solver.cpp:105] Iteration 69750, lr = 0.001
I0618 14:24:34.079903  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 14:25:13.344569  8058 solver.cpp:218] Iteration 69800 (0.864958 iter/s, 57.8063s/50 iters), loss = 0.00767195
I0618 14:25:13.344718  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:25:13.344748  8058 solver.cpp:237]     Train net output #1: loss = 0.00767198 (* 1 = 0.00767198 loss)
I0618 14:25:13.344770  8058 sgd_solver.cpp:105] Iteration 69800, lr = 0.001
I0618 14:26:11.154884  8058 solver.cpp:218] Iteration 69850 (0.864907 iter/s, 57.8097s/50 iters), loss = 0.00888119
I0618 14:26:11.155021  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:26:11.155050  8058 solver.cpp:237]     Train net output #1: loss = 0.00888122 (* 1 = 0.00888122 loss)
I0618 14:26:11.155069  8058 sgd_solver.cpp:105] Iteration 69850, lr = 0.001
I0618 14:26:52.824671  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 14:27:08.955032  8058 solver.cpp:218] Iteration 69900 (0.86506 iter/s, 57.7995s/50 iters), loss = 0.00925346
I0618 14:27:08.955149  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:27:08.955183  8058 solver.cpp:237]     Train net output #1: loss = 0.0092535 (* 1 = 0.0092535 loss)
I0618 14:27:08.955204  8058 sgd_solver.cpp:105] Iteration 69900, lr = 0.001
I0618 14:28:06.763962  8058 solver.cpp:218] Iteration 69950 (0.864928 iter/s, 57.8083s/50 iters), loss = 0.00729482
I0618 14:28:06.764096  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:28:06.764125  8058 solver.cpp:237]     Train net output #1: loss = 0.00729485 (* 1 = 0.00729485 loss)
I0618 14:28:06.764143  8058 sgd_solver.cpp:105] Iteration 69950, lr = 0.001
I0618 14:29:03.412403  8058 solver.cpp:447] Snapshotting to binary proto file mobilenet/mobile_cub_iter_70000.caffemodel
I0618 14:29:03.495673  8058 sgd_solver.cpp:273] Snapshotting solver state to binary proto file mobilenet/mobile_cub_iter_70000.solverstate
I0618 14:29:04.678670  8058 solver.cpp:218] Iteration 70000 (0.863348 iter/s, 57.9141s/50 iters), loss = 0.00727863
I0618 14:29:04.678740  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:29:04.678763  8058 solver.cpp:237]     Train net output #1: loss = 0.00727867 (* 1 = 0.00727867 loss)
I0618 14:29:04.678778  8058 sgd_solver.cpp:105] Iteration 70000, lr = 0.001
I0618 14:29:10.561642  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 14:30:02.436275  8058 solver.cpp:218] Iteration 70050 (0.865695 iter/s, 57.757s/50 iters), loss = 0.00649872
I0618 14:30:02.436393  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:30:02.436420  8058 solver.cpp:237]     Train net output #1: loss = 0.00649875 (* 1 = 0.00649875 loss)
I0618 14:30:02.436436  8058 sgd_solver.cpp:105] Iteration 70050, lr = 0.001
I0618 14:31:00.198492  8058 solver.cpp:218] Iteration 70100 (0.865627 iter/s, 57.7616s/50 iters), loss = 0.00695118
I0618 14:31:00.198668  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:31:00.198698  8058 solver.cpp:237]     Train net output #1: loss = 0.00695122 (* 1 = 0.00695122 loss)
I0618 14:31:00.198716  8058 sgd_solver.cpp:105] Iteration 70100, lr = 0.001
I0618 14:31:29.179323  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 14:31:57.944978  8058 solver.cpp:218] Iteration 70150 (0.865864 iter/s, 57.7458s/50 iters), loss = 0.00751696
I0618 14:31:57.945097  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:31:57.945125  8058 solver.cpp:237]     Train net output #1: loss = 0.007517 (* 1 = 0.007517 loss)
I0618 14:31:57.945142  8058 sgd_solver.cpp:105] Iteration 70150, lr = 0.001
I0618 14:32:55.699234  8058 solver.cpp:218] Iteration 70200 (0.865746 iter/s, 57.7536s/50 iters), loss = 0.00833334
I0618 14:32:55.699436  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:32:55.699476  8058 solver.cpp:237]     Train net output #1: loss = 0.00833338 (* 1 = 0.00833338 loss)
I0618 14:32:55.699496  8058 sgd_solver.cpp:105] Iteration 70200, lr = 0.001
I0618 14:33:47.779992  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 14:33:53.458310  8058 solver.cpp:218] Iteration 70250 (0.865675 iter/s, 57.7584s/50 iters), loss = 0.00751736
I0618 14:33:53.458389  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:33:53.458415  8058 solver.cpp:237]     Train net output #1: loss = 0.0075174 (* 1 = 0.0075174 loss)
I0618 14:33:53.458431  8058 sgd_solver.cpp:105] Iteration 70250, lr = 0.001
I0618 14:34:51.215888  8058 solver.cpp:218] Iteration 70300 (0.865696 iter/s, 57.757s/50 iters), loss = 0.0103031
I0618 14:34:51.215998  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:34:51.216027  8058 solver.cpp:237]     Train net output #1: loss = 0.0103031 (* 1 = 0.0103031 loss)
I0618 14:34:51.216044  8058 sgd_solver.cpp:105] Iteration 70300, lr = 0.001
I0618 14:35:48.978137  8058 solver.cpp:218] Iteration 70350 (0.865626 iter/s, 57.7616s/50 iters), loss = 0.00758014
I0618 14:35:48.978258  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:35:48.978288  8058 solver.cpp:237]     Train net output #1: loss = 0.00758018 (* 1 = 0.00758018 loss)
I0618 14:35:48.978308  8058 sgd_solver.cpp:105] Iteration 70350, lr = 0.001
I0618 14:36:06.400331  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 14:36:46.733197  8058 solver.cpp:218] Iteration 70400 (0.865734 iter/s, 57.7544s/50 iters), loss = 0.00902654
I0618 14:36:46.733299  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:36:46.733326  8058 solver.cpp:237]     Train net output #1: loss = 0.00902658 (* 1 = 0.00902658 loss)
I0618 14:36:46.733343  8058 sgd_solver.cpp:105] Iteration 70400, lr = 0.001
I0618 14:37:44.485926  8058 solver.cpp:218] Iteration 70450 (0.865769 iter/s, 57.7521s/50 iters), loss = 0.00694172
I0618 14:37:44.486050  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:37:44.486078  8058 solver.cpp:237]     Train net output #1: loss = 0.00694176 (* 1 = 0.00694176 loss)
I0618 14:37:44.486094  8058 sgd_solver.cpp:105] Iteration 70450, lr = 0.001
I0618 14:38:24.985455  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 14:38:42.260538  8058 solver.cpp:218] Iteration 70500 (0.865441 iter/s, 57.774s/50 iters), loss = 0.00671181
I0618 14:38:42.260620  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:38:42.260648  8058 solver.cpp:237]     Train net output #1: loss = 0.00671184 (* 1 = 0.00671184 loss)
I0618 14:38:42.260664  8058 sgd_solver.cpp:105] Iteration 70500, lr = 0.001
I0618 14:39:40.024240  8058 solver.cpp:218] Iteration 70550 (0.865604 iter/s, 57.7631s/50 iters), loss = 0.00835049
I0618 14:39:40.024458  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:39:40.024507  8058 solver.cpp:237]     Train net output #1: loss = 0.00835052 (* 1 = 0.00835052 loss)
I0618 14:39:40.024538  8058 sgd_solver.cpp:105] Iteration 70550, lr = 0.001
I0618 14:40:37.787395  8058 solver.cpp:218] Iteration 70600 (0.865614 iter/s, 57.7625s/50 iters), loss = 0.00765819
I0618 14:40:37.787523  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:40:37.787554  8058 solver.cpp:237]     Train net output #1: loss = 0.00765823 (* 1 = 0.00765823 loss)
I0618 14:40:37.787572  8058 sgd_solver.cpp:105] Iteration 70600, lr = 0.001
I0618 14:40:43.625291  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 14:41:35.540827  8058 solver.cpp:218] Iteration 70650 (0.865759 iter/s, 57.7528s/50 iters), loss = 0.00847407
I0618 14:41:35.540946  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:41:35.540972  8058 solver.cpp:237]     Train net output #1: loss = 0.0084741 (* 1 = 0.0084741 loss)
I0618 14:41:35.540988  8058 sgd_solver.cpp:105] Iteration 70650, lr = 0.001
I0618 14:42:33.295171  8058 solver.cpp:218] Iteration 70700 (0.865745 iter/s, 57.7537s/50 iters), loss = 0.00663459
I0618 14:42:33.295306  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:42:33.295336  8058 solver.cpp:237]     Train net output #1: loss = 0.00663462 (* 1 = 0.00663462 loss)
I0618 14:42:33.295352  8058 sgd_solver.cpp:105] Iteration 70700, lr = 0.001
I0618 14:43:02.254878  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 14:43:31.051977  8058 solver.cpp:218] Iteration 70750 (0.865708 iter/s, 57.7562s/50 iters), loss = 0.00941703
I0618 14:43:31.052099  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:43:31.052132  8058 solver.cpp:237]     Train net output #1: loss = 0.00941706 (* 1 = 0.00941706 loss)
I0618 14:43:31.052153  8058 sgd_solver.cpp:105] Iteration 70750, lr = 0.001
I0618 14:44:28.817612  8058 solver.cpp:218] Iteration 70800 (0.865576 iter/s, 57.765s/50 iters), loss = 0.0061524
I0618 14:44:28.817740  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:44:28.817773  8058 solver.cpp:237]     Train net output #1: loss = 0.00615243 (* 1 = 0.00615243 loss)
I0618 14:44:28.817792  8058 sgd_solver.cpp:105] Iteration 70800, lr = 0.001
I0618 14:45:20.887934  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 14:45:26.590571  8058 solver.cpp:218] Iteration 70850 (0.865466 iter/s, 57.7724s/50 iters), loss = 0.00834889
I0618 14:45:26.590651  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:45:26.590677  8058 solver.cpp:237]     Train net output #1: loss = 0.00834892 (* 1 = 0.00834892 loss)
I0618 14:45:26.590692  8058 sgd_solver.cpp:105] Iteration 70850, lr = 0.001
I0618 14:46:24.351027  8058 solver.cpp:218] Iteration 70900 (0.865652 iter/s, 57.7599s/50 iters), loss = 0.00729383
I0618 14:46:24.351148  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:46:24.351176  8058 solver.cpp:237]     Train net output #1: loss = 0.00729387 (* 1 = 0.00729387 loss)
I0618 14:46:24.351193  8058 sgd_solver.cpp:105] Iteration 70900, lr = 0.001
I0618 14:47:22.111927  8058 solver.cpp:218] Iteration 70950 (0.865646 iter/s, 57.7603s/50 iters), loss = 0.00753019
I0618 14:47:22.112327  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:47:22.112361  8058 solver.cpp:237]     Train net output #1: loss = 0.00753022 (* 1 = 0.00753022 loss)
I0618 14:47:22.112381  8058 sgd_solver.cpp:105] Iteration 70950, lr = 0.001
I0618 14:47:38.387754  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 14:48:19.874269  8058 solver.cpp:218] Iteration 71000 (0.865629 iter/s, 57.7615s/50 iters), loss = 0.00959893
I0618 14:48:19.874406  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:48:19.874434  8058 solver.cpp:237]     Train net output #1: loss = 0.00959897 (* 1 = 0.00959897 loss)
I0618 14:48:19.874452  8058 sgd_solver.cpp:105] Iteration 71000, lr = 0.001
I0618 14:49:17.647416  8058 solver.cpp:218] Iteration 71050 (0.865463 iter/s, 57.7725s/50 iters), loss = 0.00896563
I0618 14:49:17.647584  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:49:17.647619  8058 solver.cpp:237]     Train net output #1: loss = 0.00896566 (* 1 = 0.00896566 loss)
I0618 14:49:17.647639  8058 sgd_solver.cpp:105] Iteration 71050, lr = 0.001
I0618 14:49:57.008468  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 14:50:15.410363  8058 solver.cpp:218] Iteration 71100 (0.865616 iter/s, 57.7623s/50 iters), loss = 0.00857045
I0618 14:50:15.410449  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:50:15.410475  8058 solver.cpp:237]     Train net output #1: loss = 0.00857048 (* 1 = 0.00857048 loss)
I0618 14:50:15.410492  8058 sgd_solver.cpp:105] Iteration 71100, lr = 0.001
I0618 14:51:13.174582  8058 solver.cpp:218] Iteration 71150 (0.865596 iter/s, 57.7637s/50 iters), loss = 0.00799698
I0618 14:51:13.174720  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:51:13.174748  8058 solver.cpp:237]     Train net output #1: loss = 0.00799701 (* 1 = 0.00799701 loss)
I0618 14:51:13.174768  8058 sgd_solver.cpp:105] Iteration 71150, lr = 0.001
I0618 14:52:10.933903  8058 solver.cpp:218] Iteration 71200 (0.86567 iter/s, 57.7587s/50 iters), loss = 0.00841859
I0618 14:52:10.934047  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:52:10.934075  8058 solver.cpp:237]     Train net output #1: loss = 0.00841863 (* 1 = 0.00841863 loss)
I0618 14:52:10.934093  8058 sgd_solver.cpp:105] Iteration 71200, lr = 0.001
I0618 14:52:15.656297  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 14:53:08.699688  8058 solver.cpp:218] Iteration 71250 (0.865573 iter/s, 57.7652s/50 iters), loss = 0.00707282
I0618 14:53:08.699816  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:53:08.699846  8058 solver.cpp:237]     Train net output #1: loss = 0.00707285 (* 1 = 0.00707285 loss)
I0618 14:53:08.699862  8058 sgd_solver.cpp:105] Iteration 71250, lr = 0.001
I0618 14:54:06.464025  8058 solver.cpp:218] Iteration 71300 (0.865595 iter/s, 57.7637s/50 iters), loss = 0.00818784
I0618 14:54:06.464144  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:54:06.464172  8058 solver.cpp:237]     Train net output #1: loss = 0.00818787 (* 1 = 0.00818787 loss)
I0618 14:54:06.464190  8058 sgd_solver.cpp:105] Iteration 71300, lr = 0.001
I0618 14:54:34.278621  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 14:55:04.218364  8058 solver.cpp:218] Iteration 71350 (0.865745 iter/s, 57.7538s/50 iters), loss = 0.0130043
I0618 14:55:04.218475  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:55:04.218503  8058 solver.cpp:237]     Train net output #1: loss = 0.0130044 (* 1 = 0.0130044 loss)
I0618 14:55:04.218525  8058 sgd_solver.cpp:105] Iteration 71350, lr = 0.001
I0618 14:56:01.972635  8058 solver.cpp:218] Iteration 71400 (0.865745 iter/s, 57.7537s/50 iters), loss = 0.00796355
I0618 14:56:01.972756  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:56:01.972784  8058 solver.cpp:237]     Train net output #1: loss = 0.00796358 (* 1 = 0.00796358 loss)
I0618 14:56:01.972802  8058 sgd_solver.cpp:105] Iteration 71400, lr = 0.001
I0618 14:56:52.899276  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 14:56:59.737151  8058 solver.cpp:218] Iteration 71450 (0.865592 iter/s, 57.7639s/50 iters), loss = 0.00752589
I0618 14:56:59.737231  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:56:59.737257  8058 solver.cpp:237]     Train net output #1: loss = 0.00752593 (* 1 = 0.00752593 loss)
I0618 14:56:59.737273  8058 sgd_solver.cpp:105] Iteration 71450, lr = 0.001
I0618 14:57:57.499881  8058 solver.cpp:218] Iteration 71500 (0.865618 iter/s, 57.7622s/50 iters), loss = 0.00781187
I0618 14:57:57.500005  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:57:57.500033  8058 solver.cpp:237]     Train net output #1: loss = 0.0078119 (* 1 = 0.0078119 loss)
I0618 14:57:57.500051  8058 sgd_solver.cpp:105] Iteration 71500, lr = 0.001
I0618 14:58:55.253962  8058 solver.cpp:218] Iteration 71550 (0.865749 iter/s, 57.7535s/50 iters), loss = 0.00803115
I0618 14:58:55.254132  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:58:55.254163  8058 solver.cpp:237]     Train net output #1: loss = 0.00803118 (* 1 = 0.00803118 loss)
I0618 14:58:55.254184  8058 sgd_solver.cpp:105] Iteration 71550, lr = 0.001
I0618 14:59:11.508688  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 14:59:53.008833  8058 solver.cpp:218] Iteration 71600 (0.865737 iter/s, 57.7542s/50 iters), loss = 0.00859092
I0618 14:59:53.008963  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 14:59:53.008992  8058 solver.cpp:237]     Train net output #1: loss = 0.00859095 (* 1 = 0.00859095 loss)
I0618 14:59:53.009011  8058 sgd_solver.cpp:105] Iteration 71600, lr = 0.001
I0618 15:00:50.761584  8058 solver.cpp:218] Iteration 71650 (0.865769 iter/s, 57.7522s/50 iters), loss = 0.00785014
I0618 15:00:50.761710  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 15:00:50.761739  8058 solver.cpp:237]     Train net output #1: loss = 0.00785017 (* 1 = 0.00785017 loss)
I0618 15:00:50.761765  8058 sgd_solver.cpp:105] Iteration 71650, lr = 0.001
I0618 15:01:30.114465  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 15:01:48.522109  8058 solver.cpp:218] Iteration 71700 (0.865652 iter/s, 57.76s/50 iters), loss = 0.0105882
I0618 15:01:48.522181  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 15:01:48.522207  8058 solver.cpp:237]     Train net output #1: loss = 0.0105882 (* 1 = 0.0105882 loss)
I0618 15:01:48.522224  8058 sgd_solver.cpp:105] Iteration 71700, lr = 0.001
I0618 15:02:46.304283  8058 solver.cpp:218] Iteration 71750 (0.865326 iter/s, 57.7817s/50 iters), loss = 0.00807444
I0618 15:02:46.304394  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 15:02:46.304424  8058 solver.cpp:237]     Train net output #1: loss = 0.00807448 (* 1 = 0.00807448 loss)
I0618 15:02:46.304438  8058 sgd_solver.cpp:105] Iteration 71750, lr = 0.001
I0618 15:03:44.072757  8058 solver.cpp:218] Iteration 71800 (0.865532 iter/s, 57.7679s/50 iters), loss = 0.00915477
I0618 15:03:44.072880  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 15:03:44.072908  8058 solver.cpp:237]     Train net output #1: loss = 0.00915481 (* 1 = 0.00915481 loss)
I0618 15:03:44.072926  8058 sgd_solver.cpp:105] Iteration 71800, lr = 0.001
I0618 15:03:48.749429  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 15:04:41.832435  8058 solver.cpp:218] Iteration 71850 (0.865664 iter/s, 57.7591s/50 iters), loss = 0.0096759
I0618 15:04:41.832588  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 15:04:41.832617  8058 solver.cpp:237]     Train net output #1: loss = 0.00967593 (* 1 = 0.00967593 loss)
I0618 15:04:41.832633  8058 sgd_solver.cpp:105] Iteration 71850, lr = 0.001
I0618 15:05:39.599378  8058 solver.cpp:218] Iteration 71900 (0.865556 iter/s, 57.7664s/50 iters), loss = 0.00767553
I0618 15:05:39.599491  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 15:05:39.599524  8058 solver.cpp:237]     Train net output #1: loss = 0.00767556 (* 1 = 0.00767556 loss)
I0618 15:05:39.599545  8058 sgd_solver.cpp:105] Iteration 71900, lr = 0.001
I0618 15:06:06.245604  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 15:06:37.356953  8058 solver.cpp:218] Iteration 71950 (0.865696 iter/s, 57.757s/50 iters), loss = 0.00867725
I0618 15:06:37.357071  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 15:06:37.357100  8058 solver.cpp:237]     Train net output #1: loss = 0.00867729 (* 1 = 0.00867729 loss)
I0618 15:06:37.357116  8058 sgd_solver.cpp:105] Iteration 71950, lr = 0.001
I0618 15:07:35.125850  8058 solver.cpp:218] Iteration 72000 (0.865526 iter/s, 57.7683s/50 iters), loss = 0.00744913
I0618 15:07:35.125991  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 15:07:35.126020  8058 solver.cpp:237]     Train net output #1: loss = 0.00744917 (* 1 = 0.00744917 loss)
I0618 15:07:35.126039  8058 sgd_solver.cpp:105] Iteration 72000, lr = 0.001
I0618 15:08:24.904495  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 15:08:32.888268  8058 solver.cpp:218] Iteration 72050 (0.865623 iter/s, 57.7618s/50 iters), loss = 0.00859381
I0618 15:08:32.888350  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 15:08:32.888375  8058 solver.cpp:237]     Train net output #1: loss = 0.00859384 (* 1 = 0.00859384 loss)
I0618 15:08:32.888391  8058 sgd_solver.cpp:105] Iteration 72050, lr = 0.001
I0618 15:09:30.654743  8058 solver.cpp:218] Iteration 72100 (0.865562 iter/s, 57.7659s/50 iters), loss = 0.00738041
I0618 15:09:30.654896  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 15:09:30.654923  8058 solver.cpp:237]     Train net output #1: loss = 0.00738045 (* 1 = 0.00738045 loss)
I0618 15:09:30.654942  8058 sgd_solver.cpp:105] Iteration 72100, lr = 0.001
I0618 15:10:28.442977  8058 solver.cpp:218] Iteration 72150 (0.865237 iter/s, 57.7876s/50 iters), loss = 0.00882211
I0618 15:10:28.443116  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 15:10:28.443159  8058 solver.cpp:237]     Train net output #1: loss = 0.00882214 (* 1 = 0.00882214 loss)
I0618 15:10:28.443176  8058 sgd_solver.cpp:105] Iteration 72150, lr = 0.001
I0618 15:10:43.546577  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 15:11:26.235121  8058 solver.cpp:218] Iteration 72200 (0.865179 iter/s, 57.7915s/50 iters), loss = 0.010692
I0618 15:11:26.235282  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 15:11:26.235317  8058 solver.cpp:237]     Train net output #1: loss = 0.0106921 (* 1 = 0.0106921 loss)
I0618 15:11:26.235339  8058 sgd_solver.cpp:105] Iteration 72200, lr = 0.001
I0618 15:12:24.037222  8058 solver.cpp:218] Iteration 72250 (0.86503 iter/s, 57.8015s/50 iters), loss = 0.0081697
I0618 15:12:24.037461  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 15:12:24.037489  8058 solver.cpp:237]     Train net output #1: loss = 0.00816974 (* 1 = 0.00816974 loss)
I0618 15:12:24.037506  8058 sgd_solver.cpp:105] Iteration 72250, lr = 0.001
I0618 15:13:02.247766  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 15:13:21.820838  8058 solver.cpp:218] Iteration 72300 (0.865308 iter/s, 57.7829s/50 iters), loss = 0.00816194
I0618 15:13:21.820935  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 15:13:21.820967  8058 solver.cpp:237]     Train net output #1: loss = 0.00816197 (* 1 = 0.00816197 loss)
I0618 15:13:21.820988  8058 sgd_solver.cpp:105] Iteration 72300, lr = 0.001
I0618 15:14:19.618644  8058 solver.cpp:218] Iteration 72350 (0.865093 iter/s, 57.7973s/50 iters), loss = 0.00536792
I0618 15:14:19.619920  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 15:14:19.619954  8058 solver.cpp:237]     Train net output #1: loss = 0.00536795 (* 1 = 0.00536795 loss)
I0618 15:14:19.619971  8058 sgd_solver.cpp:105] Iteration 72350, lr = 0.001
I0618 15:15:17.414690  8058 solver.cpp:218] Iteration 72400 (0.865137 iter/s, 57.7943s/50 iters), loss = 0.0106723
I0618 15:15:17.414845  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 15:15:17.414875  8058 solver.cpp:237]     Train net output #1: loss = 0.0106723 (* 1 = 0.0106723 loss)
I0618 15:15:17.414892  8058 sgd_solver.cpp:105] Iteration 72400, lr = 0.001
I0618 15:15:20.943712  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 15:16:15.210702  8058 solver.cpp:218] Iteration 72450 (0.865121 iter/s, 57.7954s/50 iters), loss = 0.0057534
I0618 15:16:15.210948  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 15:16:15.210978  8058 solver.cpp:237]     Train net output #1: loss = 0.00575344 (* 1 = 0.00575344 loss)
I0618 15:16:15.210994  8058 sgd_solver.cpp:105] Iteration 72450, lr = 0.001
I0618 15:17:13.004088  8058 solver.cpp:218] Iteration 72500 (0.865161 iter/s, 57.7927s/50 iters), loss = 0.00740225
I0618 15:17:13.004312  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 15:17:13.004341  8058 solver.cpp:237]     Train net output #1: loss = 0.00740228 (* 1 = 0.00740228 loss)
I0618 15:17:13.004359  8058 sgd_solver.cpp:105] Iteration 72500, lr = 0.001
I0618 15:17:39.646548  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 15:18:10.796499  8058 solver.cpp:218] Iteration 72550 (0.865176 iter/s, 57.7917s/50 iters), loss = 0.0077404
I0618 15:18:10.796629  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 15:18:10.796658  8058 solver.cpp:237]     Train net output #1: loss = 0.00774044 (* 1 = 0.00774044 loss)
I0618 15:18:10.796675  8058 sgd_solver.cpp:105] Iteration 72550, lr = 0.001
I0618 15:19:08.588712  8058 solver.cpp:218] Iteration 72600 (0.865178 iter/s, 57.7916s/50 iters), loss = 0.0070289
I0618 15:19:08.588829  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 15:19:08.588860  8058 solver.cpp:237]     Train net output #1: loss = 0.00702893 (* 1 = 0.00702893 loss)
I0618 15:19:08.588881  8058 sgd_solver.cpp:105] Iteration 72600, lr = 0.001
I0618 15:19:58.331363  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 15:20:06.362126  8058 solver.cpp:218] Iteration 72650 (0.865459 iter/s, 57.7728s/50 iters), loss = 0.00946242
I0618 15:20:06.362203  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 15:20:06.362231  8058 solver.cpp:237]     Train net output #1: loss = 0.00946246 (* 1 = 0.00946246 loss)
I0618 15:20:06.362246  8058 sgd_solver.cpp:105] Iteration 72650, lr = 0.001
I0618 15:21:04.116113  8058 solver.cpp:218] Iteration 72700 (0.865749 iter/s, 57.7534s/50 iters), loss = 0.00744202
I0618 15:21:04.116226  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 15:21:04.116255  8058 solver.cpp:237]     Train net output #1: loss = 0.00744205 (* 1 = 0.00744205 loss)
I0618 15:21:04.116272  8058 sgd_solver.cpp:105] Iteration 72700, lr = 0.001
I0618 15:22:01.871773  8058 solver.cpp:218] Iteration 72750 (0.865725 iter/s, 57.7551s/50 iters), loss = 0.0101069
I0618 15:22:01.871915  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 15:22:01.871944  8058 solver.cpp:237]     Train net output #1: loss = 0.0101069 (* 1 = 0.0101069 loss)
I0618 15:22:01.871960  8058 sgd_solver.cpp:105] Iteration 72750, lr = 0.001
I0618 15:22:16.934890  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 15:22:59.632203  8058 solver.cpp:218] Iteration 72800 (0.865654 iter/s, 57.7598s/50 iters), loss = 0.0122069
I0618 15:22:59.632313  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 15:22:59.632341  8058 solver.cpp:237]     Train net output #1: loss = 0.012207 (* 1 = 0.012207 loss)
I0618 15:22:59.632359  8058 sgd_solver.cpp:105] Iteration 72800, lr = 0.001
I0618 15:23:57.405779  8058 solver.cpp:218] Iteration 72850 (0.865457 iter/s, 57.773s/50 iters), loss = 0.0102759
I0618 15:23:57.405938  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 15:23:57.405967  8058 solver.cpp:237]     Train net output #1: loss = 0.010276 (* 1 = 0.010276 loss)
I0618 15:23:57.405983  8058 sgd_solver.cpp:105] Iteration 72850, lr = 0.001
I0618 15:24:35.578521  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 15:24:55.172791  8058 solver.cpp:218] Iteration 72900 (0.865555 iter/s, 57.7664s/50 iters), loss = 0.0131379
I0618 15:24:55.172870  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 15:24:55.172897  8058 solver.cpp:237]     Train net output #1: loss = 0.0131379 (* 1 = 0.0131379 loss)
I0618 15:24:55.172914  8058 sgd_solver.cpp:105] Iteration 72900, lr = 0.001
I0618 15:25:52.933761  8058 solver.cpp:218] Iteration 72950 (0.865645 iter/s, 57.7604s/50 iters), loss = 0.00912163
I0618 15:25:52.933874  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 15:25:52.933902  8058 solver.cpp:237]     Train net output #1: loss = 0.00912167 (* 1 = 0.00912167 loss)
I0618 15:25:52.933919  8058 sgd_solver.cpp:105] Iteration 72950, lr = 0.001
I0618 15:26:50.680555  8058 solver.cpp:218] Iteration 73000 (0.865858 iter/s, 57.7462s/50 iters), loss = 0.00928651
I0618 15:26:50.680734  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 15:26:50.680765  8058 solver.cpp:237]     Train net output #1: loss = 0.00928655 (* 1 = 0.00928655 loss)
I0618 15:26:50.680783  8058 sgd_solver.cpp:105] Iteration 73000, lr = 0.001
I0618 15:26:53.080497  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 15:27:48.441321  8058 solver.cpp:218] Iteration 73050 (0.865649 iter/s, 57.7601s/50 iters), loss = 0.0093593
I0618 15:27:48.441452  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 15:27:48.441480  8058 solver.cpp:237]     Train net output #1: loss = 0.00935933 (* 1 = 0.00935933 loss)
I0618 15:27:48.441496  8058 sgd_solver.cpp:105] Iteration 73050, lr = 0.001
I0618 15:28:46.208151  8058 solver.cpp:218] Iteration 73100 (0.865558 iter/s, 57.7662s/50 iters), loss = 0.00867689
I0618 15:28:46.208266  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 15:28:46.208295  8058 solver.cpp:237]     Train net output #1: loss = 0.00867693 (* 1 = 0.00867693 loss)
I0618 15:28:46.208312  8058 sgd_solver.cpp:105] Iteration 73100, lr = 0.001
I0618 15:29:11.701294  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 15:29:43.976280  8058 solver.cpp:218] Iteration 73150 (0.865538 iter/s, 57.7675s/50 iters), loss = 0.0088227
I0618 15:29:43.976418  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 15:29:43.976446  8058 solver.cpp:237]     Train net output #1: loss = 0.00882273 (* 1 = 0.00882273 loss)
I0618 15:29:43.976462  8058 sgd_solver.cpp:105] Iteration 73150, lr = 0.001
I0618 15:30:41.741827  8058 solver.cpp:218] Iteration 73200 (0.865577 iter/s, 57.7649s/50 iters), loss = 0.009312
I0618 15:30:41.741945  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 15:30:41.741973  8058 solver.cpp:237]     Train net output #1: loss = 0.00931203 (* 1 = 0.00931203 loss)
I0618 15:30:41.741991  8058 sgd_solver.cpp:105] Iteration 73200, lr = 0.001
I0618 15:31:30.348179  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 15:31:39.516074  8058 solver.cpp:218] Iteration 73250 (0.865447 iter/s, 57.7736s/50 iters), loss = 0.0118525
I0618 15:31:39.516165  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 15:31:39.516193  8058 solver.cpp:237]     Train net output #1: loss = 0.0118525 (* 1 = 0.0118525 loss)
I0618 15:31:39.516211  8058 sgd_solver.cpp:105] Iteration 73250, lr = 0.001
I0618 15:32:37.290477  8058 solver.cpp:218] Iteration 73300 (0.865444 iter/s, 57.7738s/50 iters), loss = 0.00790766
I0618 15:32:37.290601  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 15:32:37.290632  8058 solver.cpp:237]     Train net output #1: loss = 0.00790769 (* 1 = 0.00790769 loss)
I0618 15:32:37.290648  8058 sgd_solver.cpp:105] Iteration 73300, lr = 0.001
I0618 15:33:35.070740  8058 solver.cpp:218] Iteration 73350 (0.865357 iter/s, 57.7797s/50 iters), loss = 0.00887463
I0618 15:33:35.070866  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 15:33:35.070895  8058 solver.cpp:237]     Train net output #1: loss = 0.00887466 (* 1 = 0.00887466 loss)
I0618 15:33:35.070911  8058 sgd_solver.cpp:105] Iteration 73350, lr = 0.001
I0618 15:33:49.024060  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 15:34:32.834856  8058 solver.cpp:218] Iteration 73400 (0.865599 iter/s, 57.7635s/50 iters), loss = 0.00656601
I0618 15:34:32.835007  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 15:34:32.835037  8058 solver.cpp:237]     Train net output #1: loss = 0.00656604 (* 1 = 0.00656604 loss)
I0618 15:34:32.835055  8058 sgd_solver.cpp:105] Iteration 73400, lr = 0.001
I0618 15:35:30.600378  8058 solver.cpp:218] Iteration 73450 (0.865578 iter/s, 57.7649s/50 iters), loss = 0.0068742
I0618 15:35:30.600528  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 15:35:30.600565  8058 solver.cpp:237]     Train net output #1: loss = 0.00687423 (* 1 = 0.00687423 loss)
I0618 15:35:30.600585  8058 sgd_solver.cpp:105] Iteration 73450, lr = 0.001
I0618 15:36:07.642451  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 15:36:28.371572  8058 solver.cpp:218] Iteration 73500 (0.865493 iter/s, 57.7706s/50 iters), loss = 0.00770189
I0618 15:36:28.371657  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 15:36:28.371685  8058 solver.cpp:237]     Train net output #1: loss = 0.00770192 (* 1 = 0.00770192 loss)
I0618 15:36:28.371702  8058 sgd_solver.cpp:105] Iteration 73500, lr = 0.001
I0618 15:37:26.139214  8058 solver.cpp:218] Iteration 73550 (0.865545 iter/s, 57.7671s/50 iters), loss = 0.012077
I0618 15:37:26.139361  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 15:37:26.139396  8058 solver.cpp:237]     Train net output #1: loss = 0.0120771 (* 1 = 0.0120771 loss)
I0618 15:37:26.139417  8058 sgd_solver.cpp:105] Iteration 73550, lr = 0.001
I0618 15:38:23.907990  8058 solver.cpp:218] Iteration 73600 (0.865529 iter/s, 57.7682s/50 iters), loss = 0.00974093
I0618 15:38:23.908134  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 15:38:23.908164  8058 solver.cpp:237]     Train net output #1: loss = 0.00974096 (* 1 = 0.00974096 loss)
I0618 15:38:23.908195  8058 sgd_solver.cpp:105] Iteration 73600, lr = 0.001
I0618 15:38:26.299700  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 15:39:21.664433  8058 solver.cpp:218] Iteration 73650 (0.865714 iter/s, 57.7558s/50 iters), loss = 0.00836279
I0618 15:39:21.664556  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 15:39:21.664587  8058 solver.cpp:237]     Train net output #1: loss = 0.00836282 (* 1 = 0.00836282 loss)
I0618 15:39:21.664602  8058 sgd_solver.cpp:105] Iteration 73650, lr = 0.001
I0618 15:40:19.454421  8058 solver.cpp:218] Iteration 73700 (0.865211 iter/s, 57.7894s/50 iters), loss = 0.00819178
I0618 15:40:19.454571  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 15:40:19.454605  8058 solver.cpp:237]     Train net output #1: loss = 0.00819182 (* 1 = 0.00819182 loss)
I0618 15:40:19.454625  8058 sgd_solver.cpp:105] Iteration 73700, lr = 0.001
I0618 15:40:44.929790  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 15:41:17.234053  8058 solver.cpp:218] Iteration 73750 (0.865367 iter/s, 57.779s/50 iters), loss = 0.00754472
I0618 15:41:17.234194  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 15:41:17.234236  8058 solver.cpp:237]     Train net output #1: loss = 0.00754475 (* 1 = 0.00754475 loss)
I0618 15:41:17.234258  8058 sgd_solver.cpp:105] Iteration 73750, lr = 0.001
I0618 15:42:15.002632  8058 solver.cpp:218] Iteration 73800 (0.865532 iter/s, 57.768s/50 iters), loss = 0.0108506
I0618 15:42:15.002784  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 15:42:15.002813  8058 solver.cpp:237]     Train net output #1: loss = 0.0108506 (* 1 = 0.0108506 loss)
I0618 15:42:15.002831  8058 sgd_solver.cpp:105] Iteration 73800, lr = 0.001
I0618 15:43:03.580950  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 15:43:12.775748  8058 solver.cpp:218] Iteration 73850 (0.865464 iter/s, 57.7725s/50 iters), loss = 0.00897667
I0618 15:43:12.775835  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 15:43:12.775871  8058 solver.cpp:237]     Train net output #1: loss = 0.0089767 (* 1 = 0.0089767 loss)
I0618 15:43:12.775892  8058 sgd_solver.cpp:105] Iteration 73850, lr = 0.001
I0618 15:44:10.549394  8058 solver.cpp:218] Iteration 73900 (0.865455 iter/s, 57.7731s/50 iters), loss = 0.0123358
I0618 15:44:10.549509  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 15:44:10.549542  8058 solver.cpp:237]     Train net output #1: loss = 0.0123358 (* 1 = 0.0123358 loss)
I0618 15:44:10.549561  8058 sgd_solver.cpp:105] Iteration 73900, lr = 0.001
I0618 15:45:08.314620  8058 solver.cpp:218] Iteration 73950 (0.865582 iter/s, 57.7646s/50 iters), loss = 0.0090375
I0618 15:45:08.314748  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 15:45:08.314776  8058 solver.cpp:237]     Train net output #1: loss = 0.00903754 (* 1 = 0.00903754 loss)
I0618 15:45:08.314792  8058 sgd_solver.cpp:105] Iteration 73950, lr = 0.001
I0618 15:45:21.133548  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 15:46:06.085047  8058 solver.cpp:218] Iteration 74000 (0.865504 iter/s, 57.7698s/50 iters), loss = 0.00812995
I0618 15:46:06.085222  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 15:46:06.085252  8058 solver.cpp:237]     Train net output #1: loss = 0.00812998 (* 1 = 0.00812998 loss)
I0618 15:46:06.085269  8058 sgd_solver.cpp:105] Iteration 74000, lr = 0.001
I0618 15:47:03.862994  8058 solver.cpp:218] Iteration 74050 (0.865392 iter/s, 57.7773s/50 iters), loss = 0.00789728
I0618 15:47:03.863153  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 15:47:03.863183  8058 solver.cpp:237]     Train net output #1: loss = 0.00789731 (* 1 = 0.00789731 loss)
I0618 15:47:03.863200  8058 sgd_solver.cpp:105] Iteration 74050, lr = 0.001
I0618 15:47:39.781131  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 15:48:01.629413  8058 solver.cpp:218] Iteration 74100 (0.865565 iter/s, 57.7658s/50 iters), loss = 0.00709634
I0618 15:48:01.629511  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 15:48:01.629549  8058 solver.cpp:237]     Train net output #1: loss = 0.00709637 (* 1 = 0.00709637 loss)
I0618 15:48:01.629570  8058 sgd_solver.cpp:105] Iteration 74100, lr = 0.001
I0618 15:48:59.401537  8058 solver.cpp:218] Iteration 74150 (0.865478 iter/s, 57.7715s/50 iters), loss = 0.00833673
I0618 15:48:59.401657  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 15:48:59.401686  8058 solver.cpp:237]     Train net output #1: loss = 0.00833677 (* 1 = 0.00833677 loss)
I0618 15:48:59.401702  8058 sgd_solver.cpp:105] Iteration 74150, lr = 0.001
I0618 15:49:57.171694  8058 solver.cpp:218] Iteration 74200 (0.865508 iter/s, 57.7696s/50 iters), loss = 0.00734828
I0618 15:49:57.171813  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 15:49:57.171841  8058 solver.cpp:237]     Train net output #1: loss = 0.00734831 (* 1 = 0.00734831 loss)
I0618 15:49:57.171859  8058 sgd_solver.cpp:105] Iteration 74200, lr = 0.001
I0618 15:49:58.428903  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 15:50:54.933919  8058 solver.cpp:218] Iteration 74250 (0.865627 iter/s, 57.7616s/50 iters), loss = 0.00739876
I0618 15:50:54.934070  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 15:50:54.934103  8058 solver.cpp:237]     Train net output #1: loss = 0.0073988 (* 1 = 0.0073988 loss)
I0618 15:50:54.934123  8058 sgd_solver.cpp:105] Iteration 74250, lr = 0.001
I0618 15:51:52.689065  8058 solver.cpp:218] Iteration 74300 (0.865733 iter/s, 57.7545s/50 iters), loss = 0.00988158
I0618 15:51:52.689185  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 15:51:52.689214  8058 solver.cpp:237]     Train net output #1: loss = 0.00988161 (* 1 = 0.00988161 loss)
I0618 15:51:52.689231  8058 sgd_solver.cpp:105] Iteration 74300, lr = 0.001
I0618 15:52:17.036954  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 15:52:50.448360  8058 solver.cpp:218] Iteration 74350 (0.865671 iter/s, 57.7587s/50 iters), loss = 0.00841929
I0618 15:52:50.448483  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 15:52:50.448511  8058 solver.cpp:237]     Train net output #1: loss = 0.00841932 (* 1 = 0.00841932 loss)
I0618 15:52:50.448536  8058 sgd_solver.cpp:105] Iteration 74350, lr = 0.001
I0618 15:53:48.228227  8058 solver.cpp:218] Iteration 74400 (0.865363 iter/s, 57.7792s/50 iters), loss = 0.00769568
I0618 15:53:48.228344  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 15:53:48.228374  8058 solver.cpp:237]     Train net output #1: loss = 0.00769571 (* 1 = 0.00769571 loss)
I0618 15:53:48.228391  8058 sgd_solver.cpp:105] Iteration 74400, lr = 0.001
I0618 15:54:35.687286  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 15:54:45.990036  8058 solver.cpp:218] Iteration 74450 (0.865634 iter/s, 57.7611s/50 iters), loss = 0.0074423
I0618 15:54:45.990124  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 15:54:45.990155  8058 solver.cpp:237]     Train net output #1: loss = 0.00744234 (* 1 = 0.00744234 loss)
I0618 15:54:45.990175  8058 sgd_solver.cpp:105] Iteration 74450, lr = 0.001
I0618 15:55:43.751011  8058 solver.cpp:218] Iteration 74500 (0.865646 iter/s, 57.7603s/50 iters), loss = 0.0085665
I0618 15:55:43.751147  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 15:55:43.751175  8058 solver.cpp:237]     Train net output #1: loss = 0.00856654 (* 1 = 0.00856654 loss)
I0618 15:55:43.751194  8058 sgd_solver.cpp:105] Iteration 74500, lr = 0.001
I0618 15:56:41.522879  8058 solver.cpp:218] Iteration 74550 (0.865483 iter/s, 57.7712s/50 iters), loss = 0.00890922
I0618 15:56:41.523000  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 15:56:41.523030  8058 solver.cpp:237]     Train net output #1: loss = 0.00890925 (* 1 = 0.00890925 loss)
I0618 15:56:41.523046  8058 sgd_solver.cpp:105] Iteration 74550, lr = 0.001
I0618 15:56:54.280844  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 15:57:39.287163  8058 solver.cpp:218] Iteration 74600 (0.865597 iter/s, 57.7636s/50 iters), loss = 0.00718897
I0618 15:57:39.287278  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 15:57:39.287307  8058 solver.cpp:237]     Train net output #1: loss = 0.007189 (* 1 = 0.007189 loss)
I0618 15:57:39.287324  8058 sgd_solver.cpp:105] Iteration 74600, lr = 0.001
I0618 15:58:37.057487  8058 solver.cpp:218] Iteration 74650 (0.865507 iter/s, 57.7696s/50 iters), loss = 0.00708066
I0618 15:58:37.057627  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 15:58:37.057662  8058 solver.cpp:237]     Train net output #1: loss = 0.00708069 (* 1 = 0.00708069 loss)
I0618 15:58:37.057682  8058 sgd_solver.cpp:105] Iteration 74650, lr = 0.001
I0618 15:59:12.951110  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 15:59:34.833467  8058 solver.cpp:218] Iteration 74700 (0.865422 iter/s, 57.7753s/50 iters), loss = 0.00891122
I0618 15:59:34.833581  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 15:59:34.833614  8058 solver.cpp:237]     Train net output #1: loss = 0.00891125 (* 1 = 0.00891125 loss)
I0618 15:59:34.833636  8058 sgd_solver.cpp:105] Iteration 74700, lr = 0.001
I0618 16:00:32.615485  8058 solver.cpp:218] Iteration 74750 (0.865331 iter/s, 57.7814s/50 iters), loss = 0.00814465
I0618 16:00:32.615638  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 16:00:32.615666  8058 solver.cpp:237]     Train net output #1: loss = 0.00814468 (* 1 = 0.00814468 loss)
I0618 16:00:32.615684  8058 sgd_solver.cpp:105] Iteration 74750, lr = 0.001
I0618 16:01:30.385057  8058 solver.cpp:218] Iteration 74800 (0.865518 iter/s, 57.7689s/50 iters), loss = 0.00986001
I0618 16:01:30.385180  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 16:01:30.385208  8058 solver.cpp:237]     Train net output #1: loss = 0.00986005 (* 1 = 0.00986005 loss)
I0618 16:01:30.385226  8058 sgd_solver.cpp:105] Iteration 74800, lr = 0.001
I0618 16:01:31.618554  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 16:02:28.147431  8058 solver.cpp:218] Iteration 74850 (0.865625 iter/s, 57.7617s/50 iters), loss = 0.00730695
I0618 16:02:28.147586  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 16:02:28.147615  8058 solver.cpp:237]     Train net output #1: loss = 0.00730698 (* 1 = 0.00730698 loss)
I0618 16:02:28.147632  8058 sgd_solver.cpp:105] Iteration 74850, lr = 0.001
I0618 16:03:25.905993  8058 solver.cpp:218] Iteration 74900 (0.865683 iter/s, 57.7579s/50 iters), loss = 0.00860768
I0618 16:03:25.906131  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 16:03:25.906160  8058 solver.cpp:237]     Train net output #1: loss = 0.00860772 (* 1 = 0.00860772 loss)
I0618 16:03:25.906178  8058 sgd_solver.cpp:105] Iteration 74900, lr = 0.001
I0618 16:03:49.126675  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 16:04:23.679069  8058 solver.cpp:218] Iteration 74950 (0.865465 iter/s, 57.7724s/50 iters), loss = 0.00661353
I0618 16:04:23.679251  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 16:04:23.679281  8058 solver.cpp:237]     Train net output #1: loss = 0.00661356 (* 1 = 0.00661356 loss)
I0618 16:04:23.679297  8058 sgd_solver.cpp:105] Iteration 74950, lr = 0.001
I0618 16:05:21.466542  8058 solver.cpp:218] Iteration 75000 (0.86525 iter/s, 57.7867s/50 iters), loss = 0.00875648
I0618 16:05:21.466756  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 16:05:21.466785  8058 solver.cpp:237]     Train net output #1: loss = 0.00875651 (* 1 = 0.00875651 loss)
I0618 16:05:21.466804  8058 sgd_solver.cpp:105] Iteration 75000, lr = 0.001
I0618 16:06:07.813009  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 16:06:19.265846  8058 solver.cpp:218] Iteration 75050 (0.865074 iter/s, 57.7985s/50 iters), loss = 0.00788253
I0618 16:06:19.265925  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 16:06:19.265952  8058 solver.cpp:237]     Train net output #1: loss = 0.00788256 (* 1 = 0.00788256 loss)
I0618 16:06:19.265980  8058 sgd_solver.cpp:105] Iteration 75050, lr = 0.001
I0618 16:07:17.035493  8058 solver.cpp:218] Iteration 75100 (0.865516 iter/s, 57.769s/50 iters), loss = 0.0107483
I0618 16:07:17.035629  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 16:07:17.035657  8058 solver.cpp:237]     Train net output #1: loss = 0.0107483 (* 1 = 0.0107483 loss)
I0618 16:07:17.035676  8058 sgd_solver.cpp:105] Iteration 75100, lr = 0.001
I0618 16:08:14.798635  8058 solver.cpp:218] Iteration 75150 (0.865614 iter/s, 57.7625s/50 iters), loss = 0.00999085
I0618 16:08:14.798759  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 16:08:14.798789  8058 solver.cpp:237]     Train net output #1: loss = 0.00999088 (* 1 = 0.00999088 loss)
I0618 16:08:14.798805  8058 sgd_solver.cpp:105] Iteration 75150, lr = 0.001
I0618 16:08:26.459650  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 16:09:12.570065  8058 solver.cpp:218] Iteration 75200 (0.86549 iter/s, 57.7707s/50 iters), loss = 0.00848447
I0618 16:09:12.570258  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 16:09:12.570289  8058 solver.cpp:237]     Train net output #1: loss = 0.00848451 (* 1 = 0.00848451 loss)
I0618 16:09:12.570308  8058 sgd_solver.cpp:105] Iteration 75200, lr = 0.001
I0618 16:10:10.331351  8058 solver.cpp:218] Iteration 75250 (0.865643 iter/s, 57.7606s/50 iters), loss = 0.00756053
I0618 16:10:10.331480  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 16:10:10.331508  8058 solver.cpp:237]     Train net output #1: loss = 0.00756056 (* 1 = 0.00756056 loss)
I0618 16:10:10.331533  8058 sgd_solver.cpp:105] Iteration 75250, lr = 0.001
I0618 16:10:45.087474  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 16:11:08.091392  8058 solver.cpp:218] Iteration 75300 (0.86566 iter/s, 57.7594s/50 iters), loss = 0.00791891
I0618 16:11:08.091471  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 16:11:08.091498  8058 solver.cpp:237]     Train net output #1: loss = 0.00791894 (* 1 = 0.00791894 loss)
I0618 16:11:08.091521  8058 sgd_solver.cpp:105] Iteration 75300, lr = 0.001
I0618 16:12:05.858353  8058 solver.cpp:218] Iteration 75350 (0.865556 iter/s, 57.7663s/50 iters), loss = 0.00942561
I0618 16:12:05.858531  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 16:12:05.858562  8058 solver.cpp:237]     Train net output #1: loss = 0.00942564 (* 1 = 0.00942564 loss)
I0618 16:12:05.858580  8058 sgd_solver.cpp:105] Iteration 75350, lr = 0.001
I0618 16:13:03.632694  8058 solver.cpp:218] Iteration 75400 (0.865447 iter/s, 57.7736s/50 iters), loss = 0.0109636
I0618 16:13:03.632839  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 16:13:03.632869  8058 solver.cpp:237]     Train net output #1: loss = 0.0109636 (* 1 = 0.0109636 loss)
I0618 16:13:03.632886  8058 sgd_solver.cpp:105] Iteration 75400, lr = 0.001
I0618 16:13:03.726457  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 16:14:01.403028  8058 solver.cpp:218] Iteration 75450 (0.865506 iter/s, 57.7696s/50 iters), loss = 0.00768641
I0618 16:14:01.403229  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 16:14:01.403260  8058 solver.cpp:237]     Train net output #1: loss = 0.00768645 (* 1 = 0.00768645 loss)
I0618 16:14:01.403277  8058 sgd_solver.cpp:105] Iteration 75450, lr = 0.001
I0618 16:14:59.185761  8058 solver.cpp:218] Iteration 75500 (0.865321 iter/s, 57.782s/50 iters), loss = 0.0096753
I0618 16:14:59.185883  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 16:14:59.185914  8058 solver.cpp:237]     Train net output #1: loss = 0.00967533 (* 1 = 0.00967533 loss)
I0618 16:14:59.185931  8058 sgd_solver.cpp:105] Iteration 75500, lr = 0.001
I0618 16:15:22.382074  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 16:15:56.957936  8058 solver.cpp:218] Iteration 75550 (0.865479 iter/s, 57.7715s/50 iters), loss = 0.00879898
I0618 16:15:56.958068  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 16:15:56.958096  8058 solver.cpp:237]     Train net output #1: loss = 0.00879901 (* 1 = 0.00879901 loss)
I0618 16:15:56.958123  8058 sgd_solver.cpp:105] Iteration 75550, lr = 0.001
I0618 16:16:54.732677  8058 solver.cpp:218] Iteration 75600 (0.86544 iter/s, 57.7741s/50 iters), loss = 0.00846781
I0618 16:16:54.732810  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 16:16:54.732839  8058 solver.cpp:237]     Train net output #1: loss = 0.00846784 (* 1 = 0.00846784 loss)
I0618 16:16:54.732857  8058 sgd_solver.cpp:105] Iteration 75600, lr = 0.001
I0618 16:17:41.004256  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 16:17:52.514770  8058 solver.cpp:218] Iteration 75650 (0.86533 iter/s, 57.7814s/50 iters), loss = 0.00891398
I0618 16:17:52.514863  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 16:17:52.514889  8058 solver.cpp:237]     Train net output #1: loss = 0.00891401 (* 1 = 0.00891401 loss)
I0618 16:17:52.514905  8058 sgd_solver.cpp:105] Iteration 75650, lr = 0.001
I0618 16:18:50.306644  8058 solver.cpp:218] Iteration 75700 (0.865183 iter/s, 57.7912s/50 iters), loss = 0.00972524
I0618 16:18:50.306818  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 16:18:50.306848  8058 solver.cpp:237]     Train net output #1: loss = 0.00972528 (* 1 = 0.00972528 loss)
I0618 16:18:50.306869  8058 sgd_solver.cpp:105] Iteration 75700, lr = 0.001
I0618 16:19:48.079962  8058 solver.cpp:218] Iteration 75750 (0.865462 iter/s, 57.7726s/50 iters), loss = 0.00701679
I0618 16:19:48.080088  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 16:19:48.080118  8058 solver.cpp:237]     Train net output #1: loss = 0.00701682 (* 1 = 0.00701682 loss)
I0618 16:19:48.080135  8058 sgd_solver.cpp:105] Iteration 75750, lr = 0.001
I0618 16:19:59.690032  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 16:20:45.856647  8058 solver.cpp:218] Iteration 75800 (0.865411 iter/s, 57.776s/50 iters), loss = 0.00966452
I0618 16:20:45.856796  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 16:20:45.856824  8058 solver.cpp:237]     Train net output #1: loss = 0.00966455 (* 1 = 0.00966455 loss)
I0618 16:20:45.856843  8058 sgd_solver.cpp:105] Iteration 75800, lr = 0.001
I0618 16:21:43.631175  8058 solver.cpp:218] Iteration 75850 (0.865444 iter/s, 57.7738s/50 iters), loss = 0.00756763
I0618 16:21:43.631345  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 16:21:43.631374  8058 solver.cpp:237]     Train net output #1: loss = 0.00756767 (* 1 = 0.00756767 loss)
I0618 16:21:43.631391  8058 sgd_solver.cpp:105] Iteration 75850, lr = 0.001
I0618 16:22:18.368849  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 16:22:41.407184  8058 solver.cpp:218] Iteration 75900 (0.865422 iter/s, 57.7753s/50 iters), loss = 0.0103249
I0618 16:22:41.407277  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 16:22:41.407307  8058 solver.cpp:237]     Train net output #1: loss = 0.010325 (* 1 = 0.010325 loss)
I0618 16:22:41.407328  8058 sgd_solver.cpp:105] Iteration 75900, lr = 0.001
I0618 16:23:39.184959  8058 solver.cpp:218] Iteration 75950 (0.865394 iter/s, 57.7771s/50 iters), loss = 0.00811893
I0618 16:23:39.185137  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 16:23:39.185168  8058 solver.cpp:237]     Train net output #1: loss = 0.00811896 (* 1 = 0.00811896 loss)
I0618 16:23:39.185184  8058 sgd_solver.cpp:105] Iteration 75950, lr = 0.001
I0618 16:24:35.867460  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 16:24:36.956946  8058 solver.cpp:218] Iteration 76000 (0.865482 iter/s, 57.7713s/50 iters), loss = 0.00863314
I0618 16:24:36.957034  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 16:24:36.957062  8058 solver.cpp:237]     Train net output #1: loss = 0.00863318 (* 1 = 0.00863318 loss)
I0618 16:24:36.957079  8058 sgd_solver.cpp:105] Iteration 76000, lr = 0.001
I0618 16:25:34.735199  8058 solver.cpp:218] Iteration 76050 (0.865387 iter/s, 57.7776s/50 iters), loss = 0.0081569
I0618 16:25:34.735342  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 16:25:34.735384  8058 solver.cpp:237]     Train net output #1: loss = 0.00815694 (* 1 = 0.00815694 loss)
I0618 16:25:34.735401  8058 sgd_solver.cpp:105] Iteration 76050, lr = 0.001
I0618 16:26:32.508671  8058 solver.cpp:218] Iteration 76100 (0.865459 iter/s, 57.7728s/50 iters), loss = 0.00779259
I0618 16:26:32.508846  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 16:26:32.508879  8058 solver.cpp:237]     Train net output #1: loss = 0.00779263 (* 1 = 0.00779263 loss)
I0618 16:26:32.508900  8058 sgd_solver.cpp:105] Iteration 76100, lr = 0.001
I0618 16:26:54.542554  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 16:27:30.293700  8058 solver.cpp:218] Iteration 76150 (0.865286 iter/s, 57.7844s/50 iters), loss = 0.00894293
I0618 16:27:30.293830  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 16:27:30.293859  8058 solver.cpp:237]     Train net output #1: loss = 0.00894296 (* 1 = 0.00894296 loss)
I0618 16:27:30.293876  8058 sgd_solver.cpp:105] Iteration 76150, lr = 0.001
I0618 16:28:28.076331  8058 solver.cpp:218] Iteration 76200 (0.865321 iter/s, 57.782s/50 iters), loss = 0.00824635
I0618 16:28:28.076475  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 16:28:28.076506  8058 solver.cpp:237]     Train net output #1: loss = 0.00824639 (* 1 = 0.00824639 loss)
I0618 16:28:28.076532  8058 sgd_solver.cpp:105] Iteration 76200, lr = 0.001
I0618 16:29:13.220136  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 16:29:25.863435  8058 solver.cpp:218] Iteration 76250 (0.865255 iter/s, 57.7864s/50 iters), loss = 0.00746948
I0618 16:29:25.863549  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 16:29:25.863579  8058 solver.cpp:237]     Train net output #1: loss = 0.00746951 (* 1 = 0.00746951 loss)
I0618 16:29:25.863596  8058 sgd_solver.cpp:105] Iteration 76250, lr = 0.001
I0618 16:30:23.660461  8058 solver.cpp:218] Iteration 76300 (0.865106 iter/s, 57.7964s/50 iters), loss = 0.00841237
I0618 16:30:23.660620  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 16:30:23.660650  8058 solver.cpp:237]     Train net output #1: loss = 0.0084124 (* 1 = 0.0084124 loss)
I0618 16:30:23.660672  8058 sgd_solver.cpp:105] Iteration 76300, lr = 0.001
I0618 16:31:21.464926  8058 solver.cpp:218] Iteration 76350 (0.864995 iter/s, 57.8038s/50 iters), loss = 0.00749156
I0618 16:31:21.465154  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 16:31:21.465183  8058 solver.cpp:237]     Train net output #1: loss = 0.0074916 (* 1 = 0.0074916 loss)
I0618 16:31:21.465201  8058 sgd_solver.cpp:105] Iteration 76350, lr = 0.001
I0618 16:31:31.936357  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 16:32:19.255771  8058 solver.cpp:218] Iteration 76400 (0.8652 iter/s, 57.7901s/50 iters), loss = 0.00823344
I0618 16:32:19.255965  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 16:32:19.255995  8058 solver.cpp:237]     Train net output #1: loss = 0.00823347 (* 1 = 0.00823347 loss)
I0618 16:32:19.256014  8058 sgd_solver.cpp:105] Iteration 76400, lr = 0.001
I0618 16:33:17.028430  8058 solver.cpp:218] Iteration 76450 (0.865472 iter/s, 57.772s/50 iters), loss = 0.00754477
I0618 16:33:17.028633  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 16:33:17.028664  8058 solver.cpp:237]     Train net output #1: loss = 0.0075448 (* 1 = 0.0075448 loss)
I0618 16:33:17.028681  8058 sgd_solver.cpp:105] Iteration 76450, lr = 0.001
I0618 16:33:50.630971  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 16:34:14.809279  8058 solver.cpp:218] Iteration 76500 (0.865349 iter/s, 57.7801s/50 iters), loss = 0.00709069
I0618 16:34:14.809376  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 16:34:14.809403  8058 solver.cpp:237]     Train net output #1: loss = 0.00709072 (* 1 = 0.00709072 loss)
I0618 16:34:14.809422  8058 sgd_solver.cpp:105] Iteration 76500, lr = 0.001
I0618 16:35:12.594764  8058 solver.cpp:218] Iteration 76550 (0.865278 iter/s, 57.7849s/50 iters), loss = 0.00798067
I0618 16:35:12.594918  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 16:35:12.594947  8058 solver.cpp:237]     Train net output #1: loss = 0.00798071 (* 1 = 0.00798071 loss)
I0618 16:35:12.594964  8058 sgd_solver.cpp:105] Iteration 76550, lr = 0.001
I0618 16:36:09.313706  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 16:36:10.382535  8058 solver.cpp:218] Iteration 76600 (0.865245 iter/s, 57.7871s/50 iters), loss = 0.00945692
I0618 16:36:10.382634  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 16:36:10.382663  8058 solver.cpp:237]     Train net output #1: loss = 0.00945695 (* 1 = 0.00945695 loss)
I0618 16:36:10.382680  8058 sgd_solver.cpp:105] Iteration 76600, lr = 0.001
I0618 16:37:08.172250  8058 solver.cpp:218] Iteration 76650 (0.865216 iter/s, 57.7891s/50 iters), loss = 0.0101057
I0618 16:37:08.172399  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 16:37:08.172432  8058 solver.cpp:237]     Train net output #1: loss = 0.0101058 (* 1 = 0.0101058 loss)
I0618 16:37:08.172453  8058 sgd_solver.cpp:105] Iteration 76650, lr = 0.001
I0618 16:38:05.965404  8058 solver.cpp:218] Iteration 76700 (0.865164 iter/s, 57.7925s/50 iters), loss = 0.00857949
I0618 16:38:05.965544  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 16:38:05.965575  8058 solver.cpp:237]     Train net output #1: loss = 0.00857953 (* 1 = 0.00857953 loss)
I0618 16:38:05.965593  8058 sgd_solver.cpp:105] Iteration 76700, lr = 0.001
I0618 16:38:27.987635  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 16:39:03.754436  8058 solver.cpp:218] Iteration 76750 (0.865226 iter/s, 57.7884s/50 iters), loss = 0.0108119
I0618 16:39:03.754585  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 16:39:03.754614  8058 solver.cpp:237]     Train net output #1: loss = 0.0108119 (* 1 = 0.0108119 loss)
I0618 16:39:03.754631  8058 sgd_solver.cpp:105] Iteration 76750, lr = 0.001
I0618 16:40:01.527379  8058 solver.cpp:218] Iteration 76800 (0.865467 iter/s, 57.7723s/50 iters), loss = 0.00755015
I0618 16:40:01.527520  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 16:40:01.527551  8058 solver.cpp:237]     Train net output #1: loss = 0.00755019 (* 1 = 0.00755019 loss)
I0618 16:40:01.527570  8058 sgd_solver.cpp:105] Iteration 76800, lr = 0.001
I0618 16:40:46.648780  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 16:40:59.298676  8058 solver.cpp:218] Iteration 76850 (0.865491 iter/s, 57.7707s/50 iters), loss = 0.00705008
I0618 16:40:59.298753  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 16:40:59.298779  8058 solver.cpp:237]     Train net output #1: loss = 0.00705011 (* 1 = 0.00705011 loss)
I0618 16:40:59.298796  8058 sgd_solver.cpp:105] Iteration 76850, lr = 0.001
I0618 16:41:57.073503  8058 solver.cpp:218] Iteration 76900 (0.865438 iter/s, 57.7742s/50 iters), loss = 0.00829302
I0618 16:41:57.073710  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 16:41:57.073745  8058 solver.cpp:237]     Train net output #1: loss = 0.00829305 (* 1 = 0.00829305 loss)
I0618 16:41:57.073765  8058 sgd_solver.cpp:105] Iteration 76900, lr = 0.001
I0618 16:42:54.879528  8058 solver.cpp:218] Iteration 76950 (0.864972 iter/s, 57.8053s/50 iters), loss = 0.00849604
I0618 16:42:54.879691  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 16:42:54.879720  8058 solver.cpp:237]     Train net output #1: loss = 0.00849608 (* 1 = 0.00849608 loss)
I0618 16:42:54.879739  8058 sgd_solver.cpp:105] Iteration 76950, lr = 0.001
I0618 16:43:04.208194  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 16:43:52.674252  8058 solver.cpp:218] Iteration 77000 (0.865141 iter/s, 57.7941s/50 iters), loss = 0.0133307
I0618 16:43:52.674370  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 16:43:52.674397  8058 solver.cpp:237]     Train net output #1: loss = 0.0133308 (* 1 = 0.0133308 loss)
I0618 16:43:52.674415  8058 sgd_solver.cpp:105] Iteration 77000, lr = 0.001
I0618 16:44:50.447166  8058 solver.cpp:218] Iteration 77050 (0.865467 iter/s, 57.7722s/50 iters), loss = 0.00909229
I0618 16:44:50.458580  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 16:44:50.458613  8058 solver.cpp:237]     Train net output #1: loss = 0.00909232 (* 1 = 0.00909232 loss)
I0618 16:44:50.458634  8058 sgd_solver.cpp:105] Iteration 77050, lr = 0.001
I0618 16:45:22.918678  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 16:45:48.235996  8058 solver.cpp:218] Iteration 77100 (0.865398 iter/s, 57.7769s/50 iters), loss = 0.00882367
I0618 16:45:48.236074  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 16:45:48.236101  8058 solver.cpp:237]     Train net output #1: loss = 0.0088237 (* 1 = 0.0088237 loss)
I0618 16:45:48.236119  8058 sgd_solver.cpp:105] Iteration 77100, lr = 0.001
I0618 16:46:46.011858  8058 solver.cpp:218] Iteration 77150 (0.865423 iter/s, 57.7752s/50 iters), loss = 0.0097683
I0618 16:46:46.011981  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 16:46:46.012011  8058 solver.cpp:237]     Train net output #1: loss = 0.00976834 (* 1 = 0.00976834 loss)
I0618 16:46:46.012027  8058 sgd_solver.cpp:105] Iteration 77150, lr = 0.001
I0618 16:47:41.548666  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 16:47:43.781360  8058 solver.cpp:218] Iteration 77200 (0.865518 iter/s, 57.7688s/50 iters), loss = 0.0084172
I0618 16:47:43.781445  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 16:47:43.781471  8058 solver.cpp:237]     Train net output #1: loss = 0.00841724 (* 1 = 0.00841724 loss)
I0618 16:47:43.781489  8058 sgd_solver.cpp:105] Iteration 77200, lr = 0.001
I0618 16:48:41.558751  8058 solver.cpp:218] Iteration 77250 (0.8654 iter/s, 57.7768s/50 iters), loss = 0.0109347
I0618 16:48:41.558876  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 16:48:41.558904  8058 solver.cpp:237]     Train net output #1: loss = 0.0109347 (* 1 = 0.0109347 loss)
I0618 16:48:41.558921  8058 sgd_solver.cpp:105] Iteration 77250, lr = 0.001
I0618 16:49:39.328554  8058 solver.cpp:218] Iteration 77300 (0.865514 iter/s, 57.7691s/50 iters), loss = 0.00768723
I0618 16:49:39.328685  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 16:49:39.328713  8058 solver.cpp:237]     Train net output #1: loss = 0.00768726 (* 1 = 0.00768726 loss)
I0618 16:49:39.328732  8058 sgd_solver.cpp:105] Iteration 77300, lr = 0.001
I0618 16:50:00.189050  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 16:50:37.099189  8058 solver.cpp:218] Iteration 77350 (0.865502 iter/s, 57.77s/50 iters), loss = 0.00999255
I0618 16:50:37.099323  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 16:50:37.099352  8058 solver.cpp:237]     Train net output #1: loss = 0.00999259 (* 1 = 0.00999259 loss)
I0618 16:50:37.099369  8058 sgd_solver.cpp:105] Iteration 77350, lr = 0.001
I0618 16:51:34.877378  8058 solver.cpp:218] Iteration 77400 (0.865389 iter/s, 57.7775s/50 iters), loss = 0.00794024
I0618 16:51:34.877588  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 16:51:34.877619  8058 solver.cpp:237]     Train net output #1: loss = 0.00794027 (* 1 = 0.00794027 loss)
I0618 16:51:34.877638  8058 sgd_solver.cpp:105] Iteration 77400, lr = 0.001
I0618 16:52:18.882254  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 16:52:32.664608  8058 solver.cpp:218] Iteration 77450 (0.865254 iter/s, 57.7865s/50 iters), loss = 0.00822481
I0618 16:52:32.664691  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 16:52:32.664718  8058 solver.cpp:237]     Train net output #1: loss = 0.00822484 (* 1 = 0.00822484 loss)
I0618 16:52:32.664736  8058 sgd_solver.cpp:105] Iteration 77450, lr = 0.001
I0618 16:53:30.427608  8058 solver.cpp:218] Iteration 77500 (0.865615 iter/s, 57.7624s/50 iters), loss = 0.00934412
I0618 16:53:30.427734  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 16:53:30.427763  8058 solver.cpp:237]     Train net output #1: loss = 0.00934415 (* 1 = 0.00934415 loss)
I0618 16:53:30.427794  8058 sgd_solver.cpp:105] Iteration 77500, lr = 0.001
I0618 16:54:28.185344  8058 solver.cpp:218] Iteration 77550 (0.865695 iter/s, 57.7571s/50 iters), loss = 0.00965647
I0618 16:54:28.185474  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 16:54:28.185503  8058 solver.cpp:237]     Train net output #1: loss = 0.00965651 (* 1 = 0.00965651 loss)
I0618 16:54:28.185526  8058 sgd_solver.cpp:105] Iteration 77550, lr = 0.001
I0618 16:54:37.507412  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 16:55:25.942214  8058 solver.cpp:218] Iteration 77600 (0.865708 iter/s, 57.7562s/50 iters), loss = 0.0066366
I0618 16:55:25.942627  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 16:55:25.942669  8058 solver.cpp:237]     Train net output #1: loss = 0.00663663 (* 1 = 0.00663663 loss)
I0618 16:55:25.942694  8058 sgd_solver.cpp:105] Iteration 77600, lr = 0.001
I0618 16:56:23.703440  8058 solver.cpp:218] Iteration 77650 (0.865647 iter/s, 57.7603s/50 iters), loss = 0.00863934
I0618 16:56:23.703585  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 16:56:23.703614  8058 solver.cpp:237]     Train net output #1: loss = 0.00863937 (* 1 = 0.00863937 loss)
I0618 16:56:23.703630  8058 sgd_solver.cpp:105] Iteration 77650, lr = 0.001
I0618 16:56:56.128376  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 16:57:21.467686  8058 solver.cpp:218] Iteration 77700 (0.865597 iter/s, 57.7636s/50 iters), loss = 0.0080655
I0618 16:57:21.467797  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 16:57:21.467829  8058 solver.cpp:237]     Train net output #1: loss = 0.00806553 (* 1 = 0.00806553 loss)
I0618 16:57:21.467850  8058 sgd_solver.cpp:105] Iteration 77700, lr = 0.001
I0618 16:58:19.236464  8058 solver.cpp:218] Iteration 77750 (0.865529 iter/s, 57.7682s/50 iters), loss = 0.00874168
I0618 16:58:19.236578  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 16:58:19.236608  8058 solver.cpp:237]     Train net output #1: loss = 0.00874172 (* 1 = 0.00874172 loss)
I0618 16:58:19.236624  8058 sgd_solver.cpp:105] Iteration 77750, lr = 0.001
I0618 16:59:14.747684  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 16:59:17.012631  8058 solver.cpp:218] Iteration 77800 (0.865418 iter/s, 57.7755s/50 iters), loss = 0.0116476
I0618 16:59:17.012734  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 16:59:17.012761  8058 solver.cpp:237]     Train net output #1: loss = 0.0116477 (* 1 = 0.0116477 loss)
I0618 16:59:17.012779  8058 sgd_solver.cpp:105] Iteration 77800, lr = 0.001
I0618 17:00:14.808329  8058 solver.cpp:218] Iteration 77850 (0.865126 iter/s, 57.7951s/50 iters), loss = 0.00839777
I0618 17:00:14.808539  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:00:14.808571  8058 solver.cpp:237]     Train net output #1: loss = 0.0083978 (* 1 = 0.0083978 loss)
I0618 17:00:14.808588  8058 sgd_solver.cpp:105] Iteration 77850, lr = 0.001
I0618 17:01:12.607888  8058 solver.cpp:218] Iteration 77900 (0.865069 iter/s, 57.7988s/50 iters), loss = 0.00813586
I0618 17:01:12.608057  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:01:12.608086  8058 solver.cpp:237]     Train net output #1: loss = 0.00813589 (* 1 = 0.00813589 loss)
I0618 17:01:12.608103  8058 sgd_solver.cpp:105] Iteration 77900, lr = 0.001
I0618 17:01:32.336046  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 17:02:10.405432  8058 solver.cpp:218] Iteration 77950 (0.865099 iter/s, 57.7969s/50 iters), loss = 0.0106687
I0618 17:02:10.405582  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:02:10.405617  8058 solver.cpp:237]     Train net output #1: loss = 0.0106687 (* 1 = 0.0106687 loss)
I0618 17:02:10.405637  8058 sgd_solver.cpp:105] Iteration 77950, lr = 0.001
I0618 17:03:08.209928  8058 solver.cpp:218] Iteration 78000 (0.864994 iter/s, 57.8038s/50 iters), loss = 0.00820353
I0618 17:03:08.210078  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:03:08.210120  8058 solver.cpp:237]     Train net output #1: loss = 0.00820357 (* 1 = 0.00820357 loss)
I0618 17:03:08.210139  8058 sgd_solver.cpp:105] Iteration 78000, lr = 0.001
I0618 17:03:51.067922  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 17:04:06.011384  8058 solver.cpp:218] Iteration 78050 (0.86504 iter/s, 57.8008s/50 iters), loss = 0.0083067
I0618 17:04:06.011492  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:04:06.011525  8058 solver.cpp:237]     Train net output #1: loss = 0.00830674 (* 1 = 0.00830674 loss)
I0618 17:04:06.011543  8058 sgd_solver.cpp:105] Iteration 78050, lr = 0.001
I0618 17:05:03.806480  8058 solver.cpp:218] Iteration 78100 (0.865135 iter/s, 57.7945s/50 iters), loss = 0.0105786
I0618 17:05:03.807068  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:05:03.807097  8058 solver.cpp:237]     Train net output #1: loss = 0.0105786 (* 1 = 0.0105786 loss)
I0618 17:05:03.807114  8058 sgd_solver.cpp:105] Iteration 78100, lr = 0.001
I0618 17:06:01.604929  8058 solver.cpp:218] Iteration 78150 (0.865092 iter/s, 57.7974s/50 iters), loss = 0.00629616
I0618 17:06:01.605082  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:06:01.605110  8058 solver.cpp:237]     Train net output #1: loss = 0.00629619 (* 1 = 0.00629619 loss)
I0618 17:06:01.605128  8058 sgd_solver.cpp:105] Iteration 78150, lr = 0.001
I0618 17:06:09.771015  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 17:06:59.407178  8058 solver.cpp:218] Iteration 78200 (0.865028 iter/s, 57.8016s/50 iters), loss = 0.00808347
I0618 17:06:59.407335  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:06:59.407362  8058 solver.cpp:237]     Train net output #1: loss = 0.0080835 (* 1 = 0.0080835 loss)
I0618 17:06:59.407382  8058 sgd_solver.cpp:105] Iteration 78200, lr = 0.001
I0618 17:07:57.206907  8058 solver.cpp:218] Iteration 78250 (0.865066 iter/s, 57.7991s/50 iters), loss = 0.00826584
I0618 17:07:57.207062  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:07:57.207089  8058 solver.cpp:237]     Train net output #1: loss = 0.00826588 (* 1 = 0.00826588 loss)
I0618 17:07:57.207106  8058 sgd_solver.cpp:105] Iteration 78250, lr = 0.001
I0618 17:08:28.479210  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 17:08:55.004426  8058 solver.cpp:218] Iteration 78300 (0.865099 iter/s, 57.7969s/50 iters), loss = 0.00905959
I0618 17:08:55.004542  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:08:55.004572  8058 solver.cpp:237]     Train net output #1: loss = 0.00905962 (* 1 = 0.00905962 loss)
I0618 17:08:55.004590  8058 sgd_solver.cpp:105] Iteration 78300, lr = 0.001
I0618 17:09:52.793977  8058 solver.cpp:218] Iteration 78350 (0.865218 iter/s, 57.7889s/50 iters), loss = 0.00815412
I0618 17:09:52.794204  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:09:52.794235  8058 solver.cpp:237]     Train net output #1: loss = 0.00815415 (* 1 = 0.00815415 loss)
I0618 17:09:52.794252  8058 sgd_solver.cpp:105] Iteration 78350, lr = 0.001
I0618 17:10:47.204499  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 17:10:50.584460  8058 solver.cpp:218] Iteration 78400 (0.865205 iter/s, 57.7898s/50 iters), loss = 0.00843016
I0618 17:10:50.584554  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:10:50.584583  8058 solver.cpp:237]     Train net output #1: loss = 0.00843019 (* 1 = 0.00843019 loss)
I0618 17:10:50.584599  8058 sgd_solver.cpp:105] Iteration 78400, lr = 0.001
I0618 17:11:48.366156  8058 solver.cpp:218] Iteration 78450 (0.865335 iter/s, 57.7811s/50 iters), loss = 0.00758523
I0618 17:11:48.366286  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:11:48.366313  8058 solver.cpp:237]     Train net output #1: loss = 0.00758526 (* 1 = 0.00758526 loss)
I0618 17:11:48.366330  8058 sgd_solver.cpp:105] Iteration 78450, lr = 0.001
I0618 17:12:46.160959  8058 solver.cpp:218] Iteration 78500 (0.86514 iter/s, 57.7941s/50 iters), loss = 0.00976513
I0618 17:12:46.161136  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:12:46.161170  8058 solver.cpp:237]     Train net output #1: loss = 0.00976517 (* 1 = 0.00976517 loss)
I0618 17:12:46.161190  8058 sgd_solver.cpp:105] Iteration 78500, lr = 0.001
I0618 17:13:05.879601  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 17:13:43.960696  8058 solver.cpp:218] Iteration 78550 (0.865066 iter/s, 57.799s/50 iters), loss = 0.0107025
I0618 17:13:43.960846  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:13:43.960875  8058 solver.cpp:237]     Train net output #1: loss = 0.0107025 (* 1 = 0.0107025 loss)
I0618 17:13:43.960892  8058 sgd_solver.cpp:105] Iteration 78550, lr = 0.001
I0618 17:14:41.748216  8058 solver.cpp:218] Iteration 78600 (0.865249 iter/s, 57.7869s/50 iters), loss = 0.00825285
I0618 17:14:41.748360  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:14:41.748389  8058 solver.cpp:237]     Train net output #1: loss = 0.00825288 (* 1 = 0.00825288 loss)
I0618 17:14:41.748407  8058 sgd_solver.cpp:105] Iteration 78600, lr = 0.001
I0618 17:15:24.599692  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 17:15:39.542441  8058 solver.cpp:218] Iteration 78650 (0.865148 iter/s, 57.7936s/50 iters), loss = 0.0078358
I0618 17:15:39.542562  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:15:39.542592  8058 solver.cpp:237]     Train net output #1: loss = 0.00783583 (* 1 = 0.00783583 loss)
I0618 17:15:39.542608  8058 sgd_solver.cpp:105] Iteration 78650, lr = 0.001
I0618 17:16:37.340149  8058 solver.cpp:218] Iteration 78700 (0.865096 iter/s, 57.7971s/50 iters), loss = 0.00889356
I0618 17:16:37.340315  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:16:37.340343  8058 solver.cpp:237]     Train net output #1: loss = 0.0088936 (* 1 = 0.0088936 loss)
I0618 17:16:37.340361  8058 sgd_solver.cpp:105] Iteration 78700, lr = 0.001
I0618 17:17:35.135938  8058 solver.cpp:218] Iteration 78750 (0.865125 iter/s, 57.7951s/50 iters), loss = 0.00962345
I0618 17:17:35.136091  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:17:35.136121  8058 solver.cpp:237]     Train net output #1: loss = 0.00962348 (* 1 = 0.00962348 loss)
I0618 17:17:35.136137  8058 sgd_solver.cpp:105] Iteration 78750, lr = 0.001
I0618 17:17:43.279400  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 17:18:32.923892  8058 solver.cpp:218] Iteration 78800 (0.865242 iter/s, 57.7873s/50 iters), loss = 0.0123584
I0618 17:18:32.924062  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:18:32.924089  8058 solver.cpp:237]     Train net output #1: loss = 0.0123584 (* 1 = 0.0123584 loss)
I0618 17:18:32.924106  8058 sgd_solver.cpp:105] Iteration 78800, lr = 0.001
I0618 17:19:30.701371  8058 solver.cpp:218] Iteration 78850 (0.865399 iter/s, 57.7768s/50 iters), loss = 0.008669
I0618 17:19:30.701550  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:19:30.701586  8058 solver.cpp:237]     Train net output #1: loss = 0.00866903 (* 1 = 0.00866903 loss)
I0618 17:19:30.701608  8058 sgd_solver.cpp:105] Iteration 78850, lr = 0.001
I0618 17:20:01.945545  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 17:20:28.487079  8058 solver.cpp:218] Iteration 78900 (0.865276 iter/s, 57.785s/50 iters), loss = 0.0108976
I0618 17:20:28.487170  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:20:28.487197  8058 solver.cpp:237]     Train net output #1: loss = 0.0108976 (* 1 = 0.0108976 loss)
I0618 17:20:28.487215  8058 sgd_solver.cpp:105] Iteration 78900, lr = 0.001
I0618 17:21:26.262527  8058 solver.cpp:218] Iteration 78950 (0.865428 iter/s, 57.7749s/50 iters), loss = 0.0081271
I0618 17:21:26.262650  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:21:26.262679  8058 solver.cpp:237]     Train net output #1: loss = 0.00812714 (* 1 = 0.00812714 loss)
I0618 17:21:26.262696  8058 sgd_solver.cpp:105] Iteration 78950, lr = 0.001
I0618 17:22:19.520864  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 17:22:24.037690  8058 solver.cpp:218] Iteration 79000 (0.865433 iter/s, 57.7745s/50 iters), loss = 0.00869069
I0618 17:22:24.037786  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:22:24.037817  8058 solver.cpp:237]     Train net output #1: loss = 0.00869072 (* 1 = 0.00869072 loss)
I0618 17:22:24.037838  8058 sgd_solver.cpp:105] Iteration 79000, lr = 0.001
I0618 17:23:21.811333  8058 solver.cpp:218] Iteration 79050 (0.865455 iter/s, 57.7731s/50 iters), loss = 0.00758166
I0618 17:23:21.811449  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:23:21.811476  8058 solver.cpp:237]     Train net output #1: loss = 0.00758169 (* 1 = 0.00758169 loss)
I0618 17:23:21.811492  8058 sgd_solver.cpp:105] Iteration 79050, lr = 0.001
I0618 17:24:19.588593  8058 solver.cpp:218] Iteration 79100 (0.865402 iter/s, 57.7766s/50 iters), loss = 0.00723716
I0618 17:24:19.588732  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:24:19.588760  8058 solver.cpp:237]     Train net output #1: loss = 0.0072372 (* 1 = 0.0072372 loss)
I0618 17:24:19.588778  8058 sgd_solver.cpp:105] Iteration 79100, lr = 0.001
I0618 17:24:38.179337  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 17:25:17.363677  8058 solver.cpp:218] Iteration 79150 (0.865435 iter/s, 57.7744s/50 iters), loss = 0.00705784
I0618 17:25:17.363816  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:25:17.363845  8058 solver.cpp:237]     Train net output #1: loss = 0.00705787 (* 1 = 0.00705787 loss)
I0618 17:25:17.363862  8058 sgd_solver.cpp:105] Iteration 79150, lr = 0.001
I0618 17:26:15.132791  8058 solver.cpp:218] Iteration 79200 (0.865524 iter/s, 57.7685s/50 iters), loss = 0.010906
I0618 17:26:15.132917  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:26:15.132944  8058 solver.cpp:237]     Train net output #1: loss = 0.0109061 (* 1 = 0.0109061 loss)
I0618 17:26:15.132962  8058 sgd_solver.cpp:105] Iteration 79200, lr = 0.001
I0618 17:26:56.805408  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 17:27:12.905678  8058 solver.cpp:218] Iteration 79250 (0.865467 iter/s, 57.7723s/50 iters), loss = 0.00924036
I0618 17:27:12.905760  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:27:12.905786  8058 solver.cpp:237]     Train net output #1: loss = 0.00924039 (* 1 = 0.00924039 loss)
I0618 17:27:12.905802  8058 sgd_solver.cpp:105] Iteration 79250, lr = 0.001
I0618 17:28:10.675746  8058 solver.cpp:218] Iteration 79300 (0.865509 iter/s, 57.7695s/50 iters), loss = 0.00995944
I0618 17:28:10.675863  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:28:10.675891  8058 solver.cpp:237]     Train net output #1: loss = 0.00995948 (* 1 = 0.00995948 loss)
I0618 17:28:10.675909  8058 sgd_solver.cpp:105] Iteration 79300, lr = 0.001
I0618 17:29:08.443792  8058 solver.cpp:218] Iteration 79350 (0.86554 iter/s, 57.7674s/50 iters), loss = 0.0130325
I0618 17:29:08.443980  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:29:08.444010  8058 solver.cpp:237]     Train net output #1: loss = 0.0130326 (* 1 = 0.0130326 loss)
I0618 17:29:08.444026  8058 sgd_solver.cpp:105] Iteration 79350, lr = 0.001
I0618 17:29:15.459592  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 17:30:06.197717  8058 solver.cpp:218] Iteration 79400 (0.865752 iter/s, 57.7532s/50 iters), loss = 0.00820318
I0618 17:30:06.197831  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:30:06.197860  8058 solver.cpp:237]     Train net output #1: loss = 0.00820321 (* 1 = 0.00820321 loss)
I0618 17:30:06.197877  8058 sgd_solver.cpp:105] Iteration 79400, lr = 0.001
I0618 17:31:03.951864  8058 solver.cpp:218] Iteration 79450 (0.865748 iter/s, 57.7535s/50 iters), loss = 0.00787961
I0618 17:31:03.951982  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:31:03.952011  8058 solver.cpp:237]     Train net output #1: loss = 0.00787965 (* 1 = 0.00787965 loss)
I0618 17:31:03.952040  8058 sgd_solver.cpp:105] Iteration 79450, lr = 0.001
I0618 17:31:34.053426  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 17:32:01.713932  8058 solver.cpp:218] Iteration 79500 (0.865629 iter/s, 57.7615s/50 iters), loss = 0.0088016
I0618 17:32:01.714004  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:32:01.714030  8058 solver.cpp:237]     Train net output #1: loss = 0.00880164 (* 1 = 0.00880164 loss)
I0618 17:32:01.714047  8058 sgd_solver.cpp:105] Iteration 79500, lr = 0.001
I0618 17:32:59.492614  8058 solver.cpp:218] Iteration 79550 (0.86538 iter/s, 57.7781s/50 iters), loss = 0.0078103
I0618 17:32:59.492794  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:32:59.492823  8058 solver.cpp:237]     Train net output #1: loss = 0.00781033 (* 1 = 0.00781033 loss)
I0618 17:32:59.492839  8058 sgd_solver.cpp:105] Iteration 79550, lr = 0.001
I0618 17:33:52.723574  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 17:33:57.260447  8058 solver.cpp:218] Iteration 79600 (0.865544 iter/s, 57.7672s/50 iters), loss = 0.00836062
I0618 17:33:57.260534  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:33:57.260561  8058 solver.cpp:237]     Train net output #1: loss = 0.00836065 (* 1 = 0.00836065 loss)
I0618 17:33:57.260579  8058 sgd_solver.cpp:105] Iteration 79600, lr = 0.001
I0618 17:34:55.013708  8058 solver.cpp:218] Iteration 79650 (0.865761 iter/s, 57.7527s/50 iters), loss = 0.00865894
I0618 17:34:55.013823  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:34:55.013849  8058 solver.cpp:237]     Train net output #1: loss = 0.00865897 (* 1 = 0.00865897 loss)
I0618 17:34:55.013865  8058 sgd_solver.cpp:105] Iteration 79650, lr = 0.001
I0618 17:35:52.773957  8058 solver.cpp:218] Iteration 79700 (0.865656 iter/s, 57.7596s/50 iters), loss = 0.00748843
I0618 17:35:52.774065  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:35:52.774094  8058 solver.cpp:237]     Train net output #1: loss = 0.00748847 (* 1 = 0.00748847 loss)
I0618 17:35:52.774112  8058 sgd_solver.cpp:105] Iteration 79700, lr = 0.001
I0618 17:36:11.315673  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 17:36:50.525846  8058 solver.cpp:218] Iteration 79750 (0.865781 iter/s, 57.7513s/50 iters), loss = 0.0102225
I0618 17:36:50.525962  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:36:50.525990  8058 solver.cpp:237]     Train net output #1: loss = 0.0102226 (* 1 = 0.0102226 loss)
I0618 17:36:50.526007  8058 sgd_solver.cpp:105] Iteration 79750, lr = 0.001
I0618 17:37:48.287006  8058 solver.cpp:218] Iteration 79800 (0.865643 iter/s, 57.7606s/50 iters), loss = 0.00846653
I0618 17:37:48.287123  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:37:48.287151  8058 solver.cpp:237]     Train net output #1: loss = 0.00846657 (* 1 = 0.00846657 loss)
I0618 17:37:48.287168  8058 sgd_solver.cpp:105] Iteration 79800, lr = 0.001
I0618 17:38:29.951109  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 17:38:46.047827  8058 solver.cpp:218] Iteration 79850 (0.865648 iter/s, 57.7602s/50 iters), loss = 0.0099216
I0618 17:38:46.047914  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:38:46.047941  8058 solver.cpp:237]     Train net output #1: loss = 0.00992163 (* 1 = 0.00992163 loss)
I0618 17:38:46.047958  8058 sgd_solver.cpp:105] Iteration 79850, lr = 0.001
I0618 17:39:43.822454  8058 solver.cpp:218] Iteration 79900 (0.86544 iter/s, 57.7741s/50 iters), loss = 0.00914956
I0618 17:39:43.822602  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:39:43.822633  8058 solver.cpp:237]     Train net output #1: loss = 0.00914959 (* 1 = 0.00914959 loss)
I0618 17:39:43.822654  8058 sgd_solver.cpp:105] Iteration 79900, lr = 0.001
I0618 17:40:41.581239  8058 solver.cpp:218] Iteration 79950 (0.865679 iter/s, 57.7582s/50 iters), loss = 0.00745857
I0618 17:40:41.581368  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:40:41.581409  8058 solver.cpp:237]     Train net output #1: loss = 0.00745861 (* 1 = 0.00745861 loss)
I0618 17:40:41.581426  8058 sgd_solver.cpp:105] Iteration 79950, lr = 0.001
I0618 17:40:47.466554  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 17:41:38.205113  8058 solver.cpp:447] Snapshotting to binary proto file mobilenet/mobile_cub_iter_80000.caffemodel
I0618 17:41:38.287153  8058 sgd_solver.cpp:273] Snapshotting solver state to binary proto file mobilenet/mobile_cub_iter_80000.solverstate
I0618 17:41:39.469360  8058 solver.cpp:218] Iteration 80000 (0.863744 iter/s, 57.8875s/50 iters), loss = 0.00952433
I0618 17:41:39.469429  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:41:39.469452  8058 solver.cpp:237]     Train net output #1: loss = 0.00952436 (* 1 = 0.00952436 loss)
I0618 17:41:39.469467  8058 sgd_solver.cpp:105] Iteration 80000, lr = 0.001
I0618 17:42:37.241827  8058 solver.cpp:218] Iteration 80050 (0.865472 iter/s, 57.7719s/50 iters), loss = 0.00781293
I0618 17:42:37.241941  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:42:37.241971  8058 solver.cpp:237]     Train net output #1: loss = 0.00781296 (* 1 = 0.00781296 loss)
I0618 17:42:37.241987  8058 sgd_solver.cpp:105] Iteration 80050, lr = 0.001
I0618 17:43:06.232632  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 17:43:35.010372  8058 solver.cpp:218] Iteration 80100 (0.865532 iter/s, 57.7679s/50 iters), loss = 0.00849038
I0618 17:43:35.010529  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:43:35.010565  8058 solver.cpp:237]     Train net output #1: loss = 0.00849042 (* 1 = 0.00849042 loss)
I0618 17:43:35.010586  8058 sgd_solver.cpp:105] Iteration 80100, lr = 0.001
I0618 17:44:32.776212  8058 solver.cpp:218] Iteration 80150 (0.865573 iter/s, 57.7652s/50 iters), loss = 0.00790055
I0618 17:44:32.776340  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:44:32.776368  8058 solver.cpp:237]     Train net output #1: loss = 0.00790058 (* 1 = 0.00790058 loss)
I0618 17:44:32.776386  8058 sgd_solver.cpp:105] Iteration 80150, lr = 0.001
I0618 17:45:24.861690  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 17:45:30.568212  8058 solver.cpp:218] Iteration 80200 (0.865181 iter/s, 57.7914s/50 iters), loss = 0.00890067
I0618 17:45:30.568298  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:45:30.568325  8058 solver.cpp:237]     Train net output #1: loss = 0.00890071 (* 1 = 0.00890071 loss)
I0618 17:45:30.568342  8058 sgd_solver.cpp:105] Iteration 80200, lr = 0.001
I0618 17:46:28.341678  8058 solver.cpp:218] Iteration 80250 (0.865458 iter/s, 57.7729s/50 iters), loss = 0.00883191
I0618 17:46:28.341801  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:46:28.341830  8058 solver.cpp:237]     Train net output #1: loss = 0.00883194 (* 1 = 0.00883194 loss)
I0618 17:46:28.341846  8058 sgd_solver.cpp:105] Iteration 80250, lr = 0.001
I0618 17:47:26.116230  8058 solver.cpp:218] Iteration 80300 (0.865442 iter/s, 57.7739s/50 iters), loss = 0.00893344
I0618 17:47:26.116421  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:47:26.116456  8058 solver.cpp:237]     Train net output #1: loss = 0.00893347 (* 1 = 0.00893347 loss)
I0618 17:47:26.116477  8058 sgd_solver.cpp:105] Iteration 80300, lr = 0.001
I0618 17:47:43.535029  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 17:48:23.878329  8058 solver.cpp:218] Iteration 80350 (0.86563 iter/s, 57.7614s/50 iters), loss = 0.0104697
I0618 17:48:23.878474  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:48:23.878502  8058 solver.cpp:237]     Train net output #1: loss = 0.0104697 (* 1 = 0.0104697 loss)
I0618 17:48:23.878526  8058 sgd_solver.cpp:105] Iteration 80350, lr = 0.001
I0618 17:49:21.661255  8058 solver.cpp:218] Iteration 80400 (0.865317 iter/s, 57.7823s/50 iters), loss = 0.00854521
I0618 17:49:21.661413  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:49:21.661456  8058 solver.cpp:237]     Train net output #1: loss = 0.00854525 (* 1 = 0.00854525 loss)
I0618 17:49:21.661475  8058 sgd_solver.cpp:105] Iteration 80400, lr = 0.001
I0618 17:50:02.194845  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 17:50:19.470732  8058 solver.cpp:218] Iteration 80450 (0.86492 iter/s, 57.8088s/50 iters), loss = 0.00886345
I0618 17:50:19.470840  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:50:19.470867  8058 solver.cpp:237]     Train net output #1: loss = 0.00886349 (* 1 = 0.00886349 loss)
I0618 17:50:19.470885  8058 sgd_solver.cpp:105] Iteration 80450, lr = 0.001
I0618 17:51:17.282588  8058 solver.cpp:218] Iteration 80500 (0.864884 iter/s, 57.8112s/50 iters), loss = 0.0077594
I0618 17:51:17.282778  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:51:17.282814  8058 solver.cpp:237]     Train net output #1: loss = 0.00775943 (* 1 = 0.00775943 loss)
I0618 17:51:17.282836  8058 sgd_solver.cpp:105] Iteration 80500, lr = 0.001
I0618 17:52:15.084558  8058 solver.cpp:218] Iteration 80550 (0.865033 iter/s, 57.8013s/50 iters), loss = 0.00926212
I0618 17:52:15.084703  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:52:15.084733  8058 solver.cpp:237]     Train net output #1: loss = 0.00926215 (* 1 = 0.00926215 loss)
I0618 17:52:15.084750  8058 sgd_solver.cpp:105] Iteration 80550, lr = 0.001
I0618 17:52:20.922302  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 17:53:12.906327  8058 solver.cpp:218] Iteration 80600 (0.864735 iter/s, 57.8212s/50 iters), loss = 0.0087289
I0618 17:53:12.906554  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:53:12.906586  8058 solver.cpp:237]     Train net output #1: loss = 0.00872894 (* 1 = 0.00872894 loss)
I0618 17:53:12.906610  8058 sgd_solver.cpp:105] Iteration 80600, lr = 0.001
I0618 17:54:10.723428  8058 solver.cpp:218] Iteration 80650 (0.864806 iter/s, 57.8165s/50 iters), loss = 0.00737021
I0618 17:54:10.723592  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:54:10.723623  8058 solver.cpp:237]     Train net output #1: loss = 0.00737025 (* 1 = 0.00737025 loss)
I0618 17:54:10.723640  8058 sgd_solver.cpp:105] Iteration 80650, lr = 0.001
I0618 17:54:39.680557  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 17:55:08.536757  8058 solver.cpp:218] Iteration 80700 (0.864861 iter/s, 57.8127s/50 iters), loss = 0.00956175
I0618 17:55:08.536911  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:55:08.536939  8058 solver.cpp:237]     Train net output #1: loss = 0.00956178 (* 1 = 0.00956178 loss)
I0618 17:55:08.536957  8058 sgd_solver.cpp:105] Iteration 80700, lr = 0.001
I0618 17:56:06.368612  8058 solver.cpp:218] Iteration 80750 (0.864584 iter/s, 57.8313s/50 iters), loss = 0.00834625
I0618 17:56:06.368827  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:56:06.368857  8058 solver.cpp:237]     Train net output #1: loss = 0.00834629 (* 1 = 0.00834629 loss)
I0618 17:56:06.368875  8058 sgd_solver.cpp:105] Iteration 80750, lr = 0.001
I0618 17:56:58.459050  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 17:57:04.187624  8058 solver.cpp:218] Iteration 80800 (0.864777 iter/s, 57.8184s/50 iters), loss = 0.00910913
I0618 17:57:04.187719  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:57:04.187747  8058 solver.cpp:237]     Train net output #1: loss = 0.00910917 (* 1 = 0.00910917 loss)
I0618 17:57:04.187764  8058 sgd_solver.cpp:105] Iteration 80800, lr = 0.001
I0618 17:58:02.004647  8058 solver.cpp:218] Iteration 80850 (0.864805 iter/s, 57.8165s/50 iters), loss = 0.00902265
I0618 17:58:02.004824  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:58:02.004858  8058 solver.cpp:237]     Train net output #1: loss = 0.00902268 (* 1 = 0.00902268 loss)
I0618 17:58:02.004881  8058 sgd_solver.cpp:105] Iteration 80850, lr = 0.001
I0618 17:58:59.831332  8058 solver.cpp:218] Iteration 80900 (0.864662 iter/s, 57.8261s/50 iters), loss = 0.0101465
I0618 17:58:59.831526  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:58:59.831557  8058 solver.cpp:237]     Train net output #1: loss = 0.0101465 (* 1 = 0.0101465 loss)
I0618 17:58:59.831575  8058 sgd_solver.cpp:105] Iteration 80900, lr = 0.001
I0618 17:59:16.090586  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 17:59:57.585338  8058 solver.cpp:218] Iteration 80950 (0.86575 iter/s, 57.7534s/50 iters), loss = 0.00939419
I0618 17:59:57.585459  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 17:59:57.585487  8058 solver.cpp:237]     Train net output #1: loss = 0.00939422 (* 1 = 0.00939422 loss)
I0618 17:59:57.585505  8058 sgd_solver.cpp:105] Iteration 80950, lr = 0.001
I0618 18:00:55.345736  8058 solver.cpp:218] Iteration 81000 (0.865653 iter/s, 57.7599s/50 iters), loss = 0.00988103
I0618 18:00:55.345851  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 18:00:55.345880  8058 solver.cpp:237]     Train net output #1: loss = 0.00988106 (* 1 = 0.00988106 loss)
I0618 18:00:55.345897  8058 sgd_solver.cpp:105] Iteration 81000, lr = 0.001
I0618 18:01:34.724258  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 18:01:53.109091  8058 solver.cpp:218] Iteration 81050 (0.865609 iter/s, 57.7628s/50 iters), loss = 0.0105018
I0618 18:01:53.109184  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 18:01:53.109215  8058 solver.cpp:237]     Train net output #1: loss = 0.0105018 (* 1 = 0.0105018 loss)
I0618 18:01:53.109237  8058 sgd_solver.cpp:105] Iteration 81050, lr = 0.001
I0618 18:02:50.862499  8058 solver.cpp:218] Iteration 81100 (0.865757 iter/s, 57.7529s/50 iters), loss = 0.00846145
I0618 18:02:50.862668  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 18:02:50.862696  8058 solver.cpp:237]     Train net output #1: loss = 0.00846148 (* 1 = 0.00846148 loss)
I0618 18:02:50.862715  8058 sgd_solver.cpp:105] Iteration 81100, lr = 0.001
I0618 18:03:48.619660  8058 solver.cpp:218] Iteration 81150 (0.865702 iter/s, 57.7566s/50 iters), loss = 0.0117463
I0618 18:03:48.619771  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 18:03:48.619799  8058 solver.cpp:237]     Train net output #1: loss = 0.0117464 (* 1 = 0.0117464 loss)
I0618 18:03:48.619817  8058 sgd_solver.cpp:105] Iteration 81150, lr = 0.001
I0618 18:03:53.339123  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 18:04:46.372519  8058 solver.cpp:218] Iteration 81200 (0.865766 iter/s, 57.7523s/50 iters), loss = 0.00843899
I0618 18:04:46.372627  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 18:04:46.372654  8058 solver.cpp:237]     Train net output #1: loss = 0.00843902 (* 1 = 0.00843902 loss)
I0618 18:04:46.372671  8058 sgd_solver.cpp:105] Iteration 81200, lr = 0.001
I0618 18:05:44.133445  8058 solver.cpp:218] Iteration 81250 (0.865645 iter/s, 57.7604s/50 iters), loss = 0.00954589
I0618 18:05:44.133627  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 18:05:44.133657  8058 solver.cpp:237]     Train net output #1: loss = 0.00954592 (* 1 = 0.00954592 loss)
I0618 18:05:44.133675  8058 sgd_solver.cpp:105] Iteration 81250, lr = 0.001
I0618 18:06:11.930706  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 18:06:41.882485  8058 solver.cpp:218] Iteration 81300 (0.865824 iter/s, 57.7484s/50 iters), loss = 0.0103598
I0618 18:06:41.882606  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 18:06:41.882634  8058 solver.cpp:237]     Train net output #1: loss = 0.0103598 (* 1 = 0.0103598 loss)
I0618 18:06:41.882652  8058 sgd_solver.cpp:105] Iteration 81300, lr = 0.001
I0618 18:07:39.646874  8058 solver.cpp:218] Iteration 81350 (0.865593 iter/s, 57.7639s/50 iters), loss = 0.0098321
I0618 18:07:39.646993  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 18:07:39.647022  8058 solver.cpp:237]     Train net output #1: loss = 0.00983214 (* 1 = 0.00983214 loss)
I0618 18:07:39.647038  8058 sgd_solver.cpp:105] Iteration 81350, lr = 0.001
I0618 18:08:30.535161  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 18:08:37.399957  8058 solver.cpp:218] Iteration 81400 (0.865763 iter/s, 57.7526s/50 iters), loss = 0.00949825
I0618 18:08:37.400037  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 18:08:37.400063  8058 solver.cpp:237]     Train net output #1: loss = 0.00949828 (* 1 = 0.00949828 loss)
I0618 18:08:37.400080  8058 sgd_solver.cpp:105] Iteration 81400, lr = 0.001
I0618 18:09:35.162942  8058 solver.cpp:218] Iteration 81450 (0.865614 iter/s, 57.7625s/50 iters), loss = 0.00970929
I0618 18:09:35.163058  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 18:09:35.163086  8058 solver.cpp:237]     Train net output #1: loss = 0.00970933 (* 1 = 0.00970933 loss)
I0618 18:09:35.163105  8058 sgd_solver.cpp:105] Iteration 81450, lr = 0.001
I0618 18:10:32.938349  8058 solver.cpp:218] Iteration 81500 (0.865428 iter/s, 57.7749s/50 iters), loss = 0.00898169
I0618 18:10:32.938489  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 18:10:32.938524  8058 solver.cpp:237]     Train net output #1: loss = 0.00898172 (* 1 = 0.00898172 loss)
I0618 18:10:32.938544  8058 sgd_solver.cpp:105] Iteration 81500, lr = 0.001
I0618 18:10:49.197386  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 18:11:30.690488  8058 solver.cpp:218] Iteration 81550 (0.865777 iter/s, 57.7516s/50 iters), loss = 0.0107316
I0618 18:11:30.690618  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 18:11:30.690650  8058 solver.cpp:237]     Train net output #1: loss = 0.0107316 (* 1 = 0.0107316 loss)
I0618 18:11:30.690670  8058 sgd_solver.cpp:105] Iteration 81550, lr = 0.001
I0618 18:12:28.446864  8058 solver.cpp:218] Iteration 81600 (0.865714 iter/s, 57.7558s/50 iters), loss = 0.00997589
I0618 18:12:28.446976  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 18:12:28.447005  8058 solver.cpp:237]     Train net output #1: loss = 0.00997593 (* 1 = 0.00997593 loss)
I0618 18:12:28.447022  8058 sgd_solver.cpp:105] Iteration 81600, lr = 0.001
I0618 18:13:07.806661  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 18:13:26.212508  8058 solver.cpp:218] Iteration 81650 (0.865574 iter/s, 57.7651s/50 iters), loss = 0.0100711
I0618 18:13:26.212586  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 18:13:26.212613  8058 solver.cpp:237]     Train net output #1: loss = 0.0100711 (* 1 = 0.0100711 loss)
I0618 18:13:26.212630  8058 sgd_solver.cpp:105] Iteration 81650, lr = 0.001
I0618 18:14:23.973274  8058 solver.cpp:218] Iteration 81700 (0.865647 iter/s, 57.7603s/50 iters), loss = 0.00819177
I0618 18:14:23.973402  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 18:14:23.973429  8058 solver.cpp:237]     Train net output #1: loss = 0.00819181 (* 1 = 0.00819181 loss)
I0618 18:14:23.973448  8058 sgd_solver.cpp:105] Iteration 81700, lr = 0.001
I0618 18:15:21.736212  8058 solver.cpp:218] Iteration 81750 (0.865615 iter/s, 57.7624s/50 iters), loss = 0.00896413
I0618 18:15:21.737119  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 18:15:21.737149  8058 solver.cpp:237]     Train net output #1: loss = 0.00896416 (* 1 = 0.00896416 loss)
I0618 18:15:21.737167  8058 sgd_solver.cpp:105] Iteration 81750, lr = 0.001
I0618 18:15:26.437830  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 18:16:19.505735  8058 solver.cpp:218] Iteration 81800 (0.865528 iter/s, 57.7682s/50 iters), loss = 0.0135848
I0618 18:16:19.505853  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 18:16:19.505882  8058 solver.cpp:237]     Train net output #1: loss = 0.0135849 (* 1 = 0.0135849 loss)
I0618 18:16:19.505899  8058 sgd_solver.cpp:105] Iteration 81800, lr = 0.001
I0618 18:17:17.264019  8058 solver.cpp:218] Iteration 81850 (0.865685 iter/s, 57.7577s/50 iters), loss = 0.00837374
I0618 18:17:17.264127  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 18:17:17.264156  8058 solver.cpp:237]     Train net output #1: loss = 0.00837378 (* 1 = 0.00837378 loss)
I0618 18:17:17.264189  8058 sgd_solver.cpp:105] Iteration 81850, lr = 0.001
I0618 18:17:45.042260  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 18:18:15.029928  8058 solver.cpp:218] Iteration 81900 (0.865571 iter/s, 57.7654s/50 iters), loss = 0.00948631
I0618 18:18:15.030040  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 18:18:15.030067  8058 solver.cpp:237]     Train net output #1: loss = 0.00948634 (* 1 = 0.00948634 loss)
I0618 18:18:15.030086  8058 sgd_solver.cpp:105] Iteration 81900, lr = 0.001
I0618 18:19:12.793387  8058 solver.cpp:218] Iteration 81950 (0.865608 iter/s, 57.7629s/50 iters), loss = 0.00849015
I0618 18:19:12.793556  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 18:19:12.793586  8058 solver.cpp:237]     Train net output #1: loss = 0.00849018 (* 1 = 0.00849018 loss)
I0618 18:19:12.793603  8058 sgd_solver.cpp:105] Iteration 81950, lr = 0.001
I0618 18:20:02.585619  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 18:20:10.584062  8058 solver.cpp:218] Iteration 82000 (0.865201 iter/s, 57.7901s/50 iters), loss = 0.00892009
I0618 18:20:10.584173  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 18:20:10.584202  8058 solver.cpp:237]     Train net output #1: loss = 0.00892012 (* 1 = 0.00892012 loss)
I0618 18:20:10.584219  8058 sgd_solver.cpp:105] Iteration 82000, lr = 0.001
I0618 18:21:08.383725  8058 solver.cpp:218] Iteration 82050 (0.865065 iter/s, 57.7991s/50 iters), loss = 0.0110085
I0618 18:21:08.383877  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 18:21:08.383905  8058 solver.cpp:237]     Train net output #1: loss = 0.0110086 (* 1 = 0.0110086 loss)
I0618 18:21:08.383924  8058 sgd_solver.cpp:105] Iteration 82050, lr = 0.001
I0618 18:22:06.191287  8058 solver.cpp:218] Iteration 82100 (0.864948 iter/s, 57.807s/50 iters), loss = 0.00982317
I0618 18:22:06.191426  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 18:22:06.191459  8058 solver.cpp:237]     Train net output #1: loss = 0.0098232 (* 1 = 0.0098232 loss)
I0618 18:22:06.191481  8058 sgd_solver.cpp:105] Iteration 82100, lr = 0.001
I0618 18:22:21.303483  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 18:23:03.997472  8058 solver.cpp:218] Iteration 82150 (0.864968 iter/s, 57.8056s/50 iters), loss = 0.0109486
I0618 18:23:03.997642  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 18:23:03.997671  8058 solver.cpp:237]     Train net output #1: loss = 0.0109486 (* 1 = 0.0109486 loss)
I0618 18:23:03.997689  8058 sgd_solver.cpp:105] Iteration 82150, lr = 0.001
I0618 18:24:01.809381  8058 solver.cpp:218] Iteration 82200 (0.864883 iter/s, 57.8113s/50 iters), loss = 0.0101034
I0618 18:24:01.809589  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 18:24:01.809625  8058 solver.cpp:237]     Train net output #1: loss = 0.0101034 (* 1 = 0.0101034 loss)
I0618 18:24:01.809646  8058 sgd_solver.cpp:105] Iteration 82200, lr = 0.001
I0618 18:24:40.042313  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 18:24:59.618171  8058 solver.cpp:218] Iteration 82250 (0.86493 iter/s, 57.8081s/50 iters), loss = 0.0115153
I0618 18:24:59.618274  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 18:24:59.618301  8058 solver.cpp:237]     Train net output #1: loss = 0.0115153 (* 1 = 0.0115153 loss)
I0618 18:24:59.618319  8058 sgd_solver.cpp:105] Iteration 82250, lr = 0.001
I0618 18:25:57.431090  8058 solver.cpp:218] Iteration 82300 (0.864867 iter/s, 57.8124s/50 iters), loss = 0.00915967
I0618 18:25:57.431260  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 18:25:57.431289  8058 solver.cpp:237]     Train net output #1: loss = 0.00915971 (* 1 = 0.00915971 loss)
I0618 18:25:57.431308  8058 sgd_solver.cpp:105] Iteration 82300, lr = 0.001
I0618 18:26:55.237844  8058 solver.cpp:218] Iteration 82350 (0.86496 iter/s, 57.8061s/50 iters), loss = 0.0122123
I0618 18:26:55.238006  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 18:26:55.238040  8058 solver.cpp:237]     Train net output #1: loss = 0.0122123 (* 1 = 0.0122123 loss)
I0618 18:26:55.238077  8058 sgd_solver.cpp:105] Iteration 82350, lr = 0.001
I0618 18:26:58.779772  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 18:27:53.032078  8058 solver.cpp:218] Iteration 82400 (0.865147 iter/s, 57.7936s/50 iters), loss = 0.00748542
I0618 18:27:53.032233  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 18:27:53.032263  8058 solver.cpp:237]     Train net output #1: loss = 0.00748546 (* 1 = 0.00748546 loss)
I0618 18:27:53.032280  8058 sgd_solver.cpp:105] Iteration 82400, lr = 0.001
I0618 18:28:50.832214  8058 solver.cpp:218] Iteration 82450 (0.865059 iter/s, 57.7995s/50 iters), loss = 0.00893508
I0618 18:28:50.832382  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 18:28:50.832412  8058 solver.cpp:237]     Train net output #1: loss = 0.00893511 (* 1 = 0.00893511 loss)
I0618 18:28:50.832429  8058 sgd_solver.cpp:105] Iteration 82450, lr = 0.001
I0618 18:29:17.483675  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 18:29:48.636410  8058 solver.cpp:218] Iteration 82500 (0.864999 iter/s, 57.8036s/50 iters), loss = 0.0106172
I0618 18:29:48.636567  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 18:29:48.636598  8058 solver.cpp:237]     Train net output #1: loss = 0.0106173 (* 1 = 0.0106173 loss)
I0618 18:29:48.636617  8058 sgd_solver.cpp:105] Iteration 82500, lr = 0.001
I0618 18:30:46.442504  8058 solver.cpp:218] Iteration 82550 (0.86497 iter/s, 57.8055s/50 iters), loss = 0.00806973
I0618 18:30:46.442657  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 18:30:46.442687  8058 solver.cpp:237]     Train net output #1: loss = 0.00806977 (* 1 = 0.00806977 loss)
I0618 18:30:46.442705  8058 sgd_solver.cpp:105] Iteration 82550, lr = 0.001
I0618 18:31:36.215488  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 18:31:44.246956  8058 solver.cpp:218] Iteration 82600 (0.864995 iter/s, 57.8038s/50 iters), loss = 0.00971461
I0618 18:31:44.247076  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 18:31:44.247109  8058 solver.cpp:237]     Train net output #1: loss = 0.00971465 (* 1 = 0.00971465 loss)
I0618 18:31:44.247130  8058 sgd_solver.cpp:105] Iteration 82600, lr = 0.001
I0618 18:32:42.053634  8058 solver.cpp:218] Iteration 82650 (0.864961 iter/s, 57.8061s/50 iters), loss = 0.00960826
I0618 18:32:42.053784  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 18:32:42.053813  8058 solver.cpp:237]     Train net output #1: loss = 0.00960829 (* 1 = 0.00960829 loss)
I0618 18:32:42.053831  8058 sgd_solver.cpp:105] Iteration 82650, lr = 0.001
I0618 18:33:39.858285  8058 solver.cpp:218] Iteration 82700 (0.864992 iter/s, 57.804s/50 iters), loss = 0.0105482
I0618 18:33:39.858521  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 18:33:39.858554  8058 solver.cpp:237]     Train net output #1: loss = 0.0105482 (* 1 = 0.0105482 loss)
I0618 18:33:39.858573  8058 sgd_solver.cpp:105] Iteration 82700, lr = 0.001
I0618 18:33:54.938694  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 18:34:37.670181  8058 solver.cpp:218] Iteration 82750 (0.864884 iter/s, 57.8112s/50 iters), loss = 0.0125594
I0618 18:34:37.670349  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 18:34:37.670378  8058 solver.cpp:237]     Train net output #1: loss = 0.0125594 (* 1 = 0.0125594 loss)
I0618 18:34:37.670397  8058 sgd_solver.cpp:105] Iteration 82750, lr = 0.001
I0618 18:35:35.482741  8058 solver.cpp:218] Iteration 82800 (0.864873 iter/s, 57.8119s/50 iters), loss = 0.00981453
I0618 18:35:35.482899  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 18:35:35.482928  8058 solver.cpp:237]     Train net output #1: loss = 0.00981456 (* 1 = 0.00981456 loss)
I0618 18:35:35.482945  8058 sgd_solver.cpp:105] Iteration 82800, lr = 0.001
I0618 18:36:13.680603  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 18:36:33.278461  8058 solver.cpp:218] Iteration 82850 (0.865125 iter/s, 57.7951s/50 iters), loss = 0.01146
I0618 18:36:33.278595  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 18:36:33.278622  8058 solver.cpp:237]     Train net output #1: loss = 0.01146 (* 1 = 0.01146 loss)
I0618 18:36:33.278640  8058 sgd_solver.cpp:105] Iteration 82850, lr = 0.001
I0618 18:37:31.071694  8058 solver.cpp:218] Iteration 82900 (0.865162 iter/s, 57.7926s/50 iters), loss = 0.0102426
I0618 18:37:31.071837  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 18:37:31.071866  8058 solver.cpp:237]     Train net output #1: loss = 0.0102426 (* 1 = 0.0102426 loss)
I0618 18:37:31.071884  8058 sgd_solver.cpp:105] Iteration 82900, lr = 0.001
I0618 18:38:28.873009  8058 solver.cpp:218] Iteration 82950 (0.865041 iter/s, 57.8007s/50 iters), loss = 0.0110189
I0618 18:38:28.873164  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 18:38:28.873193  8058 solver.cpp:237]     Train net output #1: loss = 0.0110189 (* 1 = 0.0110189 loss)
I0618 18:38:28.873209  8058 sgd_solver.cpp:105] Iteration 82950, lr = 0.001
I0618 18:38:31.263316  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 18:39:26.661532  8058 solver.cpp:218] Iteration 83000 (0.865233 iter/s, 57.7879s/50 iters), loss = 0.0107002
I0618 18:39:26.661650  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 18:39:26.661679  8058 solver.cpp:237]     Train net output #1: loss = 0.0107002 (* 1 = 0.0107002 loss)
I0618 18:39:26.661697  8058 sgd_solver.cpp:105] Iteration 83000, lr = 0.001
I0618 18:40:24.421712  8058 solver.cpp:218] Iteration 83050 (0.865657 iter/s, 57.7596s/50 iters), loss = 0.0109996
I0618 18:40:24.421835  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 18:40:24.421864  8058 solver.cpp:237]     Train net output #1: loss = 0.0109996 (* 1 = 0.0109996 loss)
I0618 18:40:24.421881  8058 sgd_solver.cpp:105] Iteration 83050, lr = 0.001
I0618 18:40:49.934134  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 18:41:22.183622  8058 solver.cpp:218] Iteration 83100 (0.865631 iter/s, 57.7613s/50 iters), loss = 0.00950932
I0618 18:41:22.183734  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 18:41:22.183763  8058 solver.cpp:237]     Train net output #1: loss = 0.00950935 (* 1 = 0.00950935 loss)
I0618 18:41:22.183780  8058 sgd_solver.cpp:105] Iteration 83100, lr = 0.001
I0618 18:42:19.947157  8058 solver.cpp:218] Iteration 83150 (0.865607 iter/s, 57.763s/50 iters), loss = 0.0105726
I0618 18:42:19.947288  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 18:42:19.947317  8058 solver.cpp:237]     Train net output #1: loss = 0.0105727 (* 1 = 0.0105727 loss)
I0618 18:42:19.947335  8058 sgd_solver.cpp:105] Iteration 83150, lr = 0.001
I0618 18:43:08.567939  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 18:43:17.712168  8058 solver.cpp:218] Iteration 83200 (0.865585 iter/s, 57.7644s/50 iters), loss = 0.0114838
I0618 18:43:17.712244  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 18:43:17.712271  8058 solver.cpp:237]     Train net output #1: loss = 0.0114839 (* 1 = 0.0114839 loss)
I0618 18:43:17.712290  8058 sgd_solver.cpp:105] Iteration 83200, lr = 0.001
I0618 18:44:15.485066  8058 solver.cpp:218] Iteration 83250 (0.865468 iter/s, 57.7722s/50 iters), loss = 0.00981275
I0618 18:44:15.485195  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 18:44:15.485224  8058 solver.cpp:237]     Train net output #1: loss = 0.00981279 (* 1 = 0.00981279 loss)
I0618 18:44:15.485242  8058 sgd_solver.cpp:105] Iteration 83250, lr = 0.001
I0618 18:45:13.239428  8058 solver.cpp:218] Iteration 83300 (0.865747 iter/s, 57.7536s/50 iters), loss = 0.00842884
I0618 18:45:13.239552  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 18:45:13.239581  8058 solver.cpp:237]     Train net output #1: loss = 0.00842887 (* 1 = 0.00842887 loss)
I0618 18:45:13.239599  8058 sgd_solver.cpp:105] Iteration 83300, lr = 0.001
I0618 18:45:27.191092  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 18:46:10.999790  8058 solver.cpp:218] Iteration 83350 (0.865657 iter/s, 57.7596s/50 iters), loss = 0.0093768
I0618 18:46:10.999919  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 18:46:10.999949  8058 solver.cpp:237]     Train net output #1: loss = 0.00937684 (* 1 = 0.00937684 loss)
I0618 18:46:10.999971  8058 sgd_solver.cpp:105] Iteration 83350, lr = 0.001
I0618 18:47:08.764995  8058 solver.cpp:218] Iteration 83400 (0.865584 iter/s, 57.7644s/50 iters), loss = 0.00812233
I0618 18:47:08.765117  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 18:47:08.765146  8058 solver.cpp:237]     Train net output #1: loss = 0.00812236 (* 1 = 0.00812236 loss)
I0618 18:47:08.765164  8058 sgd_solver.cpp:105] Iteration 83400, lr = 0.001
I0618 18:47:45.798156  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 18:48:06.538960  8058 solver.cpp:218] Iteration 83450 (0.865453 iter/s, 57.7732s/50 iters), loss = 0.00753119
I0618 18:48:06.539036  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 18:48:06.539062  8058 solver.cpp:237]     Train net output #1: loss = 0.00753122 (* 1 = 0.00753122 loss)
I0618 18:48:06.539079  8058 sgd_solver.cpp:105] Iteration 83450, lr = 0.001
I0618 18:49:04.298444  8058 solver.cpp:218] Iteration 83500 (0.865669 iter/s, 57.7588s/50 iters), loss = 0.0119871
I0618 18:49:04.298565  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 18:49:04.298593  8058 solver.cpp:237]     Train net output #1: loss = 0.0119872 (* 1 = 0.0119872 loss)
I0618 18:49:04.298611  8058 sgd_solver.cpp:105] Iteration 83500, lr = 0.001
I0618 18:50:02.057958  8058 solver.cpp:218] Iteration 83550 (0.86567 iter/s, 57.7588s/50 iters), loss = 0.00924532
I0618 18:50:02.058085  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 18:50:02.058117  8058 solver.cpp:237]     Train net output #1: loss = 0.00924535 (* 1 = 0.00924535 loss)
I0618 18:50:02.058137  8058 sgd_solver.cpp:105] Iteration 83550, lr = 0.001
I0618 18:50:04.431105  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 18:50:59.810048  8058 solver.cpp:218] Iteration 83600 (0.865781 iter/s, 57.7513s/50 iters), loss = 0.00900666
I0618 18:50:59.810181  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 18:50:59.810210  8058 solver.cpp:237]     Train net output #1: loss = 0.00900669 (* 1 = 0.00900669 loss)
I0618 18:50:59.810228  8058 sgd_solver.cpp:105] Iteration 83600, lr = 0.001
I0618 18:51:57.570930  8058 solver.cpp:218] Iteration 83650 (0.865649 iter/s, 57.7601s/50 iters), loss = 0.00949092
I0618 18:51:57.571041  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 18:51:57.571069  8058 solver.cpp:237]     Train net output #1: loss = 0.00949095 (* 1 = 0.00949095 loss)
I0618 18:51:57.571085  8058 sgd_solver.cpp:105] Iteration 83650, lr = 0.001
I0618 18:52:23.063828  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 18:52:55.330620  8058 solver.cpp:218] Iteration 83700 (0.865667 iter/s, 57.759s/50 iters), loss = 0.0100556
I0618 18:52:55.330781  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 18:52:55.330812  8058 solver.cpp:237]     Train net output #1: loss = 0.0100557 (* 1 = 0.0100557 loss)
I0618 18:52:55.330831  8058 sgd_solver.cpp:105] Iteration 83700, lr = 0.001
I0618 18:53:53.098299  8058 solver.cpp:218] Iteration 83750 (0.865548 iter/s, 57.7669s/50 iters), loss = 0.0100148
I0618 18:53:53.098425  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 18:53:53.098459  8058 solver.cpp:237]     Train net output #1: loss = 0.0100148 (* 1 = 0.0100148 loss)
I0618 18:53:53.098477  8058 sgd_solver.cpp:105] Iteration 83750, lr = 0.001
I0618 18:54:41.677565  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 18:54:50.869182  8058 solver.cpp:218] Iteration 83800 (0.865499 iter/s, 57.7701s/50 iters), loss = 0.0101629
I0618 18:54:50.869261  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 18:54:50.869287  8058 solver.cpp:237]     Train net output #1: loss = 0.010163 (* 1 = 0.010163 loss)
I0618 18:54:50.869316  8058 sgd_solver.cpp:105] Iteration 83800, lr = 0.001
I0618 18:55:48.643637  8058 solver.cpp:218] Iteration 83850 (0.865445 iter/s, 57.7738s/50 iters), loss = 0.00971492
I0618 18:55:48.643748  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 18:55:48.643774  8058 solver.cpp:237]     Train net output #1: loss = 0.00971496 (* 1 = 0.00971496 loss)
I0618 18:55:48.643791  8058 sgd_solver.cpp:105] Iteration 83850, lr = 0.001
I0618 18:56:46.405719  8058 solver.cpp:218] Iteration 83900 (0.865631 iter/s, 57.7614s/50 iters), loss = 0.00936231
I0618 18:56:46.405831  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 18:56:46.405859  8058 solver.cpp:237]     Train net output #1: loss = 0.00936234 (* 1 = 0.00936234 loss)
I0618 18:56:46.405876  8058 sgd_solver.cpp:105] Iteration 83900, lr = 0.001
I0618 18:56:59.207595  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 18:57:44.168118  8058 solver.cpp:218] Iteration 83950 (0.865627 iter/s, 57.7616s/50 iters), loss = 0.00970534
I0618 18:57:44.168246  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 18:57:44.168280  8058 solver.cpp:237]     Train net output #1: loss = 0.00970537 (* 1 = 0.00970537 loss)
I0618 18:57:44.168299  8058 sgd_solver.cpp:105] Iteration 83950, lr = 0.001
I0618 18:58:41.931998  8058 solver.cpp:218] Iteration 84000 (0.865604 iter/s, 57.7631s/50 iters), loss = 0.00975613
I0618 18:58:41.932155  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 18:58:41.932185  8058 solver.cpp:237]     Train net output #1: loss = 0.00975616 (* 1 = 0.00975616 loss)
I0618 18:58:41.932204  8058 sgd_solver.cpp:105] Iteration 84000, lr = 0.001
I0618 18:59:17.848048  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 18:59:39.727145  8058 solver.cpp:218] Iteration 84050 (0.865137 iter/s, 57.7943s/50 iters), loss = 0.00802717
I0618 18:59:39.727234  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 18:59:39.727268  8058 solver.cpp:237]     Train net output #1: loss = 0.0080272 (* 1 = 0.0080272 loss)
I0618 18:59:39.727293  8058 sgd_solver.cpp:105] Iteration 84050, lr = 0.001
I0618 19:00:37.517997  8058 solver.cpp:218] Iteration 84100 (0.865199 iter/s, 57.7901s/50 iters), loss = 0.009614
I0618 19:00:37.518139  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 19:00:37.518175  8058 solver.cpp:237]     Train net output #1: loss = 0.00961403 (* 1 = 0.00961403 loss)
I0618 19:00:37.518196  8058 sgd_solver.cpp:105] Iteration 84100, lr = 0.001
I0618 19:01:35.296587  8058 solver.cpp:218] Iteration 84150 (0.865383 iter/s, 57.7779s/50 iters), loss = 0.00754534
I0618 19:01:35.296736  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 19:01:35.296766  8058 solver.cpp:237]     Train net output #1: loss = 0.00754538 (* 1 = 0.00754538 loss)
I0618 19:01:35.296783  8058 sgd_solver.cpp:105] Iteration 84150, lr = 0.001
I0618 19:01:36.555214  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 19:02:33.072255  8058 solver.cpp:218] Iteration 84200 (0.865427 iter/s, 57.7749s/50 iters), loss = 0.00837018
I0618 19:02:33.072445  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 19:02:33.072475  8058 solver.cpp:237]     Train net output #1: loss = 0.00837022 (* 1 = 0.00837022 loss)
I0618 19:02:33.072494  8058 sgd_solver.cpp:105] Iteration 84200, lr = 0.001
I0618 19:03:30.854120  8058 solver.cpp:218] Iteration 84250 (0.865335 iter/s, 57.7811s/50 iters), loss = 0.0100937
I0618 19:03:30.854373  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 19:03:30.854403  8058 solver.cpp:237]     Train net output #1: loss = 0.0100937 (* 1 = 0.0100937 loss)
I0618 19:03:30.854421  8058 sgd_solver.cpp:105] Iteration 84250, lr = 0.001
I0618 19:03:55.194622  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 19:04:28.630067  8058 solver.cpp:218] Iteration 84300 (0.865425 iter/s, 57.7751s/50 iters), loss = 0.00929935
I0618 19:04:28.630224  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 19:04:28.630272  8058 solver.cpp:237]     Train net output #1: loss = 0.00929938 (* 1 = 0.00929938 loss)
I0618 19:04:28.630295  8058 sgd_solver.cpp:105] Iteration 84300, lr = 0.001
I0618 19:05:26.403949  8058 solver.cpp:218] Iteration 84350 (0.865454 iter/s, 57.7731s/50 iters), loss = 0.00901776
I0618 19:05:26.404065  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 19:05:26.404093  8058 solver.cpp:237]     Train net output #1: loss = 0.00901779 (* 1 = 0.00901779 loss)
I0618 19:05:26.404111  8058 sgd_solver.cpp:105] Iteration 84350, lr = 0.001
I0618 19:06:13.859027  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 19:06:24.184152  8058 solver.cpp:218] Iteration 84400 (0.865359 iter/s, 57.7795s/50 iters), loss = 0.00787145
I0618 19:06:24.184229  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 19:06:24.184257  8058 solver.cpp:237]     Train net output #1: loss = 0.00787149 (* 1 = 0.00787149 loss)
I0618 19:06:24.184275  8058 sgd_solver.cpp:105] Iteration 84400, lr = 0.001
I0618 19:07:21.950912  8058 solver.cpp:218] Iteration 84450 (0.86556 iter/s, 57.7661s/50 iters), loss = 0.00892894
I0618 19:07:21.951064  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 19:07:21.951093  8058 solver.cpp:237]     Train net output #1: loss = 0.00892897 (* 1 = 0.00892897 loss)
I0618 19:07:21.951112  8058 sgd_solver.cpp:105] Iteration 84450, lr = 0.001
I0618 19:08:19.734078  8058 solver.cpp:218] Iteration 84500 (0.865315 iter/s, 57.7824s/50 iters), loss = 0.00847671
I0618 19:08:19.734210  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 19:08:19.734241  8058 solver.cpp:237]     Train net output #1: loss = 0.00847675 (* 1 = 0.00847675 loss)
I0618 19:08:19.734258  8058 sgd_solver.cpp:105] Iteration 84500, lr = 0.001
I0618 19:08:32.507782  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 19:09:17.515307  8058 solver.cpp:218] Iteration 84550 (0.865344 iter/s, 57.7805s/50 iters), loss = 0.00840119
I0618 19:09:17.515429  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 19:09:17.515457  8058 solver.cpp:237]     Train net output #1: loss = 0.00840123 (* 1 = 0.00840123 loss)
I0618 19:09:17.515475  8058 sgd_solver.cpp:105] Iteration 84550, lr = 0.001
I0618 19:10:15.286479  8058 solver.cpp:218] Iteration 84600 (0.865494 iter/s, 57.7705s/50 iters), loss = 0.00904326
I0618 19:10:15.286595  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 19:10:15.286625  8058 solver.cpp:237]     Train net output #1: loss = 0.00904329 (* 1 = 0.00904329 loss)
I0618 19:10:15.286643  8058 sgd_solver.cpp:105] Iteration 84600, lr = 0.001
I0618 19:10:51.159369  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 19:11:13.052057  8058 solver.cpp:218] Iteration 84650 (0.865578 iter/s, 57.7649s/50 iters), loss = 0.0119152
I0618 19:11:13.052147  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 19:11:13.052175  8058 solver.cpp:237]     Train net output #1: loss = 0.0119152 (* 1 = 0.0119152 loss)
I0618 19:11:13.052194  8058 sgd_solver.cpp:105] Iteration 84650, lr = 0.001
I0618 19:12:10.841338  8058 solver.cpp:218] Iteration 84700 (0.865223 iter/s, 57.7886s/50 iters), loss = 0.00957191
I0618 19:12:10.841609  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 19:12:10.841640  8058 solver.cpp:237]     Train net output #1: loss = 0.00957194 (* 1 = 0.00957194 loss)
I0618 19:12:10.841657  8058 sgd_solver.cpp:105] Iteration 84700, lr = 0.001
I0618 19:13:08.610306  8058 solver.cpp:218] Iteration 84750 (0.86553 iter/s, 57.7681s/50 iters), loss = 0.00991712
I0618 19:13:08.610440  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 19:13:08.610474  8058 solver.cpp:237]     Train net output #1: loss = 0.00991715 (* 1 = 0.00991715 loss)
I0618 19:13:08.610499  8058 sgd_solver.cpp:105] Iteration 84750, lr = 0.001
I0618 19:13:09.817550  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 19:14:06.375864  8058 solver.cpp:218] Iteration 84800 (0.865578 iter/s, 57.7648s/50 iters), loss = 0.00953742
I0618 19:14:06.376039  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 19:14:06.376071  8058 solver.cpp:237]     Train net output #1: loss = 0.00953745 (* 1 = 0.00953745 loss)
I0618 19:14:06.376088  8058 sgd_solver.cpp:105] Iteration 84800, lr = 0.001
I0618 19:15:04.150671  8058 solver.cpp:218] Iteration 84850 (0.86544 iter/s, 57.7741s/50 iters), loss = 0.00944953
I0618 19:15:04.151177  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 19:15:04.151207  8058 solver.cpp:237]     Train net output #1: loss = 0.00944956 (* 1 = 0.00944956 loss)
I0618 19:15:04.151224  8058 sgd_solver.cpp:105] Iteration 84850, lr = 0.001
I0618 19:15:28.495108  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 19:16:01.928649  8058 solver.cpp:218] Iteration 84900 (0.865398 iter/s, 57.7769s/50 iters), loss = 0.00939777
I0618 19:16:01.928771  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 19:16:01.928799  8058 solver.cpp:237]     Train net output #1: loss = 0.0093978 (* 1 = 0.0093978 loss)
I0618 19:16:01.928817  8058 sgd_solver.cpp:105] Iteration 84900, lr = 0.001
I0618 19:16:59.697823  8058 solver.cpp:218] Iteration 84950 (0.865524 iter/s, 57.7685s/50 iters), loss = 0.0101722
I0618 19:16:59.698101  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 19:16:59.698133  8058 solver.cpp:237]     Train net output #1: loss = 0.0101722 (* 1 = 0.0101722 loss)
I0618 19:16:59.698153  8058 sgd_solver.cpp:105] Iteration 84950, lr = 0.001
I0618 19:17:45.995625  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 19:17:57.466724  8058 solver.cpp:218] Iteration 85000 (0.86553 iter/s, 57.7681s/50 iters), loss = 0.00912391
I0618 19:17:57.466800  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 19:17:57.466827  8058 solver.cpp:237]     Train net output #1: loss = 0.00912395 (* 1 = 0.00912395 loss)
I0618 19:17:57.466845  8058 sgd_solver.cpp:105] Iteration 85000, lr = 0.001
I0618 19:18:55.234035  8058 solver.cpp:218] Iteration 85050 (0.865551 iter/s, 57.7667s/50 iters), loss = 0.0123807
I0618 19:18:55.234145  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 19:18:55.234172  8058 solver.cpp:237]     Train net output #1: loss = 0.0123807 (* 1 = 0.0123807 loss)
I0618 19:18:55.234189  8058 sgd_solver.cpp:105] Iteration 85050, lr = 0.001
I0618 19:19:53.047494  8058 solver.cpp:218] Iteration 85100 (0.864861 iter/s, 57.8128s/50 iters), loss = 0.0105452
I0618 19:19:53.047659  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 19:19:53.047688  8058 solver.cpp:237]     Train net output #1: loss = 0.0105452 (* 1 = 0.0105452 loss)
I0618 19:19:53.047706  8058 sgd_solver.cpp:105] Iteration 85100, lr = 0.001
I0618 19:20:04.680555  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 19:20:50.853068  8058 solver.cpp:218] Iteration 85150 (0.86498 iter/s, 57.8048s/50 iters), loss = 0.0101027
I0618 19:20:50.853310  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 19:20:50.853345  8058 solver.cpp:237]     Train net output #1: loss = 0.0101027 (* 1 = 0.0101027 loss)
I0618 19:20:50.853366  8058 sgd_solver.cpp:105] Iteration 85150, lr = 0.001
I0618 19:21:48.655792  8058 solver.cpp:218] Iteration 85200 (0.865023 iter/s, 57.8019s/50 iters), loss = 0.00957512
I0618 19:21:48.655938  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 19:21:48.655967  8058 solver.cpp:237]     Train net output #1: loss = 0.00957515 (* 1 = 0.00957515 loss)
I0618 19:21:48.655985  8058 sgd_solver.cpp:105] Iteration 85200, lr = 0.001
I0618 19:22:23.411710  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 19:22:46.472481  8058 solver.cpp:218] Iteration 85250 (0.864813 iter/s, 57.816s/50 iters), loss = 0.00977125
I0618 19:22:46.472596  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 19:22:46.472623  8058 solver.cpp:237]     Train net output #1: loss = 0.00977128 (* 1 = 0.00977128 loss)
I0618 19:22:46.472640  8058 sgd_solver.cpp:105] Iteration 85250, lr = 0.001
I0618 19:23:44.282261  8058 solver.cpp:218] Iteration 85300 (0.864916 iter/s, 57.8091s/50 iters), loss = 0.00976824
I0618 19:23:44.282423  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 19:23:44.282451  8058 solver.cpp:237]     Train net output #1: loss = 0.00976827 (* 1 = 0.00976827 loss)
I0618 19:23:44.282469  8058 sgd_solver.cpp:105] Iteration 85300, lr = 0.001
I0618 19:24:42.091145  8058 solver.cpp:218] Iteration 85350 (0.86493 iter/s, 57.8081s/50 iters), loss = 0.00997632
I0618 19:24:42.091281  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 19:24:42.091315  8058 solver.cpp:237]     Train net output #1: loss = 0.00997635 (* 1 = 0.00997635 loss)
I0618 19:24:42.091336  8058 sgd_solver.cpp:105] Iteration 85350, lr = 0.001
I0618 19:24:42.160274  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 19:25:39.911970  8058 solver.cpp:218] Iteration 85400 (0.864751 iter/s, 57.8201s/50 iters), loss = 0.00953149
I0618 19:25:39.912111  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 19:25:39.912140  8058 solver.cpp:237]     Train net output #1: loss = 0.00953152 (* 1 = 0.00953152 loss)
I0618 19:25:39.912158  8058 sgd_solver.cpp:105] Iteration 85400, lr = 0.001
I0618 19:26:37.721441  8058 solver.cpp:218] Iteration 85450 (0.864921 iter/s, 57.8088s/50 iters), loss = 0.0123772
I0618 19:26:37.721604  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 19:26:37.721632  8058 solver.cpp:237]     Train net output #1: loss = 0.0123772 (* 1 = 0.0123772 loss)
I0618 19:26:37.721649  8058 sgd_solver.cpp:105] Iteration 85450, lr = 0.001
I0618 19:27:00.909453  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 19:27:35.527930  8058 solver.cpp:218] Iteration 85500 (0.864966 iter/s, 57.8058s/50 iters), loss = 0.0102761
I0618 19:27:35.528093  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 19:27:35.528122  8058 solver.cpp:237]     Train net output #1: loss = 0.0102762 (* 1 = 0.0102762 loss)
I0618 19:27:35.528141  8058 sgd_solver.cpp:105] Iteration 85500, lr = 0.001
I0618 19:28:33.332484  8058 solver.cpp:218] Iteration 85550 (0.864996 iter/s, 57.8038s/50 iters), loss = 0.00877424
I0618 19:28:33.332664  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 19:28:33.332698  8058 solver.cpp:237]     Train net output #1: loss = 0.00877428 (* 1 = 0.00877428 loss)
I0618 19:28:33.332718  8058 sgd_solver.cpp:105] Iteration 85550, lr = 0.001
I0618 19:29:19.634869  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 19:29:31.122562  8058 solver.cpp:218] Iteration 85600 (0.865212 iter/s, 57.7893s/50 iters), loss = 0.0129503
I0618 19:29:31.122651  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 19:29:31.122683  8058 solver.cpp:237]     Train net output #1: loss = 0.0129504 (* 1 = 0.0129504 loss)
I0618 19:29:31.122704  8058 sgd_solver.cpp:105] Iteration 85600, lr = 0.001
I0618 19:30:28.893488  8058 solver.cpp:218] Iteration 85650 (0.865497 iter/s, 57.7703s/50 iters), loss = 0.0116489
I0618 19:30:28.893666  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 19:30:28.893697  8058 solver.cpp:237]     Train net output #1: loss = 0.0116489 (* 1 = 0.0116489 loss)
I0618 19:30:28.893714  8058 sgd_solver.cpp:105] Iteration 85650, lr = 0.001
I0618 19:31:26.660742  8058 solver.cpp:218] Iteration 85700 (0.865553 iter/s, 57.7665s/50 iters), loss = 0.00872092
I0618 19:31:26.660858  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 19:31:26.660887  8058 solver.cpp:237]     Train net output #1: loss = 0.00872096 (* 1 = 0.00872096 loss)
I0618 19:31:26.660904  8058 sgd_solver.cpp:105] Iteration 85700, lr = 0.001
I0618 19:31:38.274001  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 19:32:24.430441  8058 solver.cpp:218] Iteration 85750 (0.865516 iter/s, 57.769s/50 iters), loss = 0.0103771
I0618 19:32:24.430567  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 19:32:24.430595  8058 solver.cpp:237]     Train net output #1: loss = 0.0103772 (* 1 = 0.0103772 loss)
I0618 19:32:24.430624  8058 sgd_solver.cpp:105] Iteration 85750, lr = 0.001
I0618 19:33:22.212915  8058 solver.cpp:218] Iteration 85800 (0.865325 iter/s, 57.7818s/50 iters), loss = 0.00876885
I0618 19:33:22.213047  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 19:33:22.213080  8058 solver.cpp:237]     Train net output #1: loss = 0.00876889 (* 1 = 0.00876889 loss)
I0618 19:33:22.213100  8058 sgd_solver.cpp:105] Iteration 85800, lr = 0.001
I0618 19:33:56.943039  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 19:34:19.974618  8058 solver.cpp:218] Iteration 85850 (0.865636 iter/s, 57.761s/50 iters), loss = 0.00876539
I0618 19:34:19.974696  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 19:34:19.974722  8058 solver.cpp:237]     Train net output #1: loss = 0.00876542 (* 1 = 0.00876542 loss)
I0618 19:34:19.974740  8058 sgd_solver.cpp:105] Iteration 85850, lr = 0.001
I0618 19:35:17.729511  8058 solver.cpp:218] Iteration 85900 (0.865737 iter/s, 57.7542s/50 iters), loss = 0.00938009
I0618 19:35:17.729629  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 19:35:17.729657  8058 solver.cpp:237]     Train net output #1: loss = 0.00938012 (* 1 = 0.00938012 loss)
I0618 19:35:17.729674  8058 sgd_solver.cpp:105] Iteration 85900, lr = 0.001
I0618 19:36:14.441954  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 19:36:15.491451  8058 solver.cpp:218] Iteration 85950 (0.865632 iter/s, 57.7613s/50 iters), loss = 0.0104546
I0618 19:36:15.491533  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 19:36:15.491561  8058 solver.cpp:237]     Train net output #1: loss = 0.0104547 (* 1 = 0.0104547 loss)
I0618 19:36:15.491585  8058 sgd_solver.cpp:105] Iteration 85950, lr = 0.001
I0618 19:37:13.268142  8058 solver.cpp:218] Iteration 86000 (0.865411 iter/s, 57.7761s/50 iters), loss = 0.00898907
I0618 19:37:13.268259  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 19:37:13.268287  8058 solver.cpp:237]     Train net output #1: loss = 0.0089891 (* 1 = 0.0089891 loss)
I0618 19:37:13.268304  8058 sgd_solver.cpp:105] Iteration 86000, lr = 0.001
I0618 19:38:11.043066  8058 solver.cpp:218] Iteration 86050 (0.865437 iter/s, 57.7743s/50 iters), loss = 0.00989715
I0618 19:38:11.043184  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 19:38:11.043212  8058 solver.cpp:237]     Train net output #1: loss = 0.00989719 (* 1 = 0.00989719 loss)
I0618 19:38:11.043231  8058 sgd_solver.cpp:105] Iteration 86050, lr = 0.001
I0618 19:38:33.071017  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 19:39:08.799640  8058 solver.cpp:218] Iteration 86100 (0.865712 iter/s, 57.7559s/50 iters), loss = 0.00943547
I0618 19:39:08.799790  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 19:39:08.799819  8058 solver.cpp:237]     Train net output #1: loss = 0.0094355 (* 1 = 0.0094355 loss)
I0618 19:39:08.799836  8058 sgd_solver.cpp:105] Iteration 86100, lr = 0.001
I0618 19:40:06.589184  8058 solver.cpp:218] Iteration 86150 (0.865219 iter/s, 57.7888s/50 iters), loss = 0.00772555
I0618 19:40:06.589375  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 19:40:06.589407  8058 solver.cpp:237]     Train net output #1: loss = 0.00772559 (* 1 = 0.00772559 loss)
I0618 19:40:06.589427  8058 sgd_solver.cpp:105] Iteration 86150, lr = 0.001
I0618 19:40:51.747001  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 19:41:04.385438  8058 solver.cpp:218] Iteration 86200 (0.865119 iter/s, 57.7955s/50 iters), loss = 0.00886391
I0618 19:41:04.385534  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 19:41:04.385562  8058 solver.cpp:237]     Train net output #1: loss = 0.00886394 (* 1 = 0.00886394 loss)
I0618 19:41:04.385579  8058 sgd_solver.cpp:105] Iteration 86200, lr = 0.001
I0618 19:42:02.175318  8058 solver.cpp:218] Iteration 86250 (0.865214 iter/s, 57.7892s/50 iters), loss = 0.0104707
I0618 19:42:02.175473  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 19:42:02.175530  8058 solver.cpp:237]     Train net output #1: loss = 0.0104707 (* 1 = 0.0104707 loss)
I0618 19:42:02.175554  8058 sgd_solver.cpp:105] Iteration 86250, lr = 0.001
I0618 19:42:59.973357  8058 solver.cpp:218] Iteration 86300 (0.865092 iter/s, 57.7973s/50 iters), loss = 0.00874679
I0618 19:42:59.973528  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 19:42:59.973558  8058 solver.cpp:237]     Train net output #1: loss = 0.00874682 (* 1 = 0.00874682 loss)
I0618 19:42:59.973577  8058 sgd_solver.cpp:105] Iteration 86300, lr = 0.001
I0618 19:43:10.444061  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 19:43:57.768172  8058 solver.cpp:218] Iteration 86350 (0.865141 iter/s, 57.7941s/50 iters), loss = 0.00895198
I0618 19:43:57.768345  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 19:43:57.768374  8058 solver.cpp:237]     Train net output #1: loss = 0.00895202 (* 1 = 0.00895202 loss)
I0618 19:43:57.768393  8058 sgd_solver.cpp:105] Iteration 86350, lr = 0.001
I0618 19:44:55.555434  8058 solver.cpp:218] Iteration 86400 (0.865254 iter/s, 57.7865s/50 iters), loss = 0.00856075
I0618 19:44:55.555570  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 19:44:55.555600  8058 solver.cpp:237]     Train net output #1: loss = 0.00856079 (* 1 = 0.00856079 loss)
I0618 19:44:55.555619  8058 sgd_solver.cpp:105] Iteration 86400, lr = 0.001
I0618 19:45:29.143074  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 19:45:53.345082  8058 solver.cpp:218] Iteration 86450 (0.865218 iter/s, 57.7889s/50 iters), loss = 0.0112171
I0618 19:45:53.345201  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 19:45:53.345233  8058 solver.cpp:237]     Train net output #1: loss = 0.0112171 (* 1 = 0.0112171 loss)
I0618 19:45:53.345254  8058 sgd_solver.cpp:105] Iteration 86450, lr = 0.001
I0618 19:46:51.142496  8058 solver.cpp:218] Iteration 86500 (0.865101 iter/s, 57.7967s/50 iters), loss = 0.0094283
I0618 19:46:51.142642  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 19:46:51.142670  8058 solver.cpp:237]     Train net output #1: loss = 0.00942834 (* 1 = 0.00942834 loss)
I0618 19:46:51.142688  8058 sgd_solver.cpp:105] Iteration 86500, lr = 0.001
I0618 19:47:47.836175  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 19:47:48.935866  8058 solver.cpp:218] Iteration 86550 (0.865162 iter/s, 57.7927s/50 iters), loss = 0.00988501
I0618 19:47:48.935957  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 19:47:48.935983  8058 solver.cpp:237]     Train net output #1: loss = 0.00988504 (* 1 = 0.00988504 loss)
I0618 19:47:48.936002  8058 sgd_solver.cpp:105] Iteration 86550, lr = 0.001
I0618 19:48:46.730682  8058 solver.cpp:218] Iteration 86600 (0.865139 iter/s, 57.7942s/50 iters), loss = 0.0114486
I0618 19:48:46.730872  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 19:48:46.730903  8058 solver.cpp:237]     Train net output #1: loss = 0.0114487 (* 1 = 0.0114487 loss)
I0618 19:48:46.730921  8058 sgd_solver.cpp:105] Iteration 86600, lr = 0.001
I0618 19:49:44.517565  8058 solver.cpp:218] Iteration 86650 (0.865259 iter/s, 57.7861s/50 iters), loss = 0.00920497
I0618 19:49:44.517684  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 19:49:44.517714  8058 solver.cpp:237]     Train net output #1: loss = 0.009205 (* 1 = 0.009205 loss)
I0618 19:49:44.517731  8058 sgd_solver.cpp:105] Iteration 86650, lr = 0.001
I0618 19:50:06.537411  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 19:50:42.308900  8058 solver.cpp:218] Iteration 86700 (0.865192 iter/s, 57.7906s/50 iters), loss = 0.0130444
I0618 19:50:42.309053  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 19:50:42.309082  8058 solver.cpp:237]     Train net output #1: loss = 0.0130444 (* 1 = 0.0130444 loss)
I0618 19:50:42.309100  8058 sgd_solver.cpp:105] Iteration 86700, lr = 0.001
I0618 19:51:40.096961  8058 solver.cpp:218] Iteration 86750 (0.865242 iter/s, 57.7873s/50 iters), loss = 0.00776876
I0618 19:51:40.097124  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 19:51:40.097153  8058 solver.cpp:237]     Train net output #1: loss = 0.00776879 (* 1 = 0.00776879 loss)
I0618 19:51:40.097170  8058 sgd_solver.cpp:105] Iteration 86750, lr = 0.001
I0618 19:52:25.194583  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 19:52:37.888861  8058 solver.cpp:218] Iteration 86800 (0.865184 iter/s, 57.7912s/50 iters), loss = 0.0072695
I0618 19:52:37.888973  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 19:52:37.889000  8058 solver.cpp:237]     Train net output #1: loss = 0.00726953 (* 1 = 0.00726953 loss)
I0618 19:52:37.889019  8058 sgd_solver.cpp:105] Iteration 86800, lr = 0.001
I0618 19:53:35.671141  8058 solver.cpp:218] Iteration 86850 (0.865328 iter/s, 57.7816s/50 iters), loss = 0.00787981
I0618 19:53:35.671270  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 19:53:35.671299  8058 solver.cpp:237]     Train net output #1: loss = 0.00787984 (* 1 = 0.00787984 loss)
I0618 19:53:35.671316  8058 sgd_solver.cpp:105] Iteration 86850, lr = 0.001
I0618 19:54:33.458199  8058 solver.cpp:218] Iteration 86900 (0.865256 iter/s, 57.7864s/50 iters), loss = 0.00942626
I0618 19:54:33.458338  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 19:54:33.458366  8058 solver.cpp:237]     Train net output #1: loss = 0.0094263 (* 1 = 0.0094263 loss)
I0618 19:54:33.458384  8058 sgd_solver.cpp:105] Iteration 86900, lr = 0.001
I0618 19:54:42.794335  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 19:55:31.243317  8058 solver.cpp:218] Iteration 86950 (0.865285 iter/s, 57.7844s/50 iters), loss = 0.00944415
I0618 19:55:31.243443  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 19:55:31.243471  8058 solver.cpp:237]     Train net output #1: loss = 0.00944418 (* 1 = 0.00944418 loss)
I0618 19:55:31.243489  8058 sgd_solver.cpp:105] Iteration 86950, lr = 0.001
I0618 19:56:29.036077  8058 solver.cpp:218] Iteration 87000 (0.865171 iter/s, 57.7921s/50 iters), loss = 0.00988208
I0618 19:56:29.036195  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 19:56:29.036222  8058 solver.cpp:237]     Train net output #1: loss = 0.00988212 (* 1 = 0.00988212 loss)
I0618 19:56:29.036240  8058 sgd_solver.cpp:105] Iteration 87000, lr = 0.001
I0618 19:57:01.470711  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 19:57:26.813417  8058 solver.cpp:218] Iteration 87050 (0.865401 iter/s, 57.7767s/50 iters), loss = 0.0103471
I0618 19:57:26.813498  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 19:57:26.813530  8058 solver.cpp:237]     Train net output #1: loss = 0.0103471 (* 1 = 0.0103471 loss)
I0618 19:57:26.813550  8058 sgd_solver.cpp:105] Iteration 87050, lr = 0.001
I0618 19:58:24.607635  8058 solver.cpp:218] Iteration 87100 (0.865148 iter/s, 57.7935s/50 iters), loss = 0.00951939
I0618 19:58:24.607878  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 19:58:24.607908  8058 solver.cpp:237]     Train net output #1: loss = 0.00951943 (* 1 = 0.00951943 loss)
I0618 19:58:24.607926  8058 sgd_solver.cpp:105] Iteration 87100, lr = 0.001
I0618 19:59:20.162554  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 19:59:22.405427  8058 solver.cpp:218] Iteration 87150 (0.865097 iter/s, 57.797s/50 iters), loss = 0.00815824
I0618 19:59:22.405542  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 19:59:22.405570  8058 solver.cpp:237]     Train net output #1: loss = 0.00815828 (* 1 = 0.00815828 loss)
I0618 19:59:22.405588  8058 sgd_solver.cpp:105] Iteration 87150, lr = 0.001
I0618 20:00:20.219342  8058 solver.cpp:218] Iteration 87200 (0.864854 iter/s, 57.8132s/50 iters), loss = 0.0131989
I0618 20:00:20.219463  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 20:00:20.219492  8058 solver.cpp:237]     Train net output #1: loss = 0.0131989 (* 1 = 0.0131989 loss)
I0618 20:00:20.219509  8058 sgd_solver.cpp:105] Iteration 87200, lr = 0.001
I0618 20:01:18.033869  8058 solver.cpp:218] Iteration 87250 (0.864845 iter/s, 57.8138s/50 iters), loss = 0.0102081
I0618 20:01:18.034040  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 20:01:18.034068  8058 solver.cpp:237]     Train net output #1: loss = 0.0102081 (* 1 = 0.0102081 loss)
I0618 20:01:18.034085  8058 sgd_solver.cpp:105] Iteration 87250, lr = 0.001
I0618 20:01:38.914921  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 20:02:15.844228  8058 solver.cpp:218] Iteration 87300 (0.864909 iter/s, 57.8096s/50 iters), loss = 0.0113699
I0618 20:02:15.844424  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 20:02:15.844461  8058 solver.cpp:237]     Train net output #1: loss = 0.0113699 (* 1 = 0.0113699 loss)
I0618 20:02:15.844483  8058 sgd_solver.cpp:105] Iteration 87300, lr = 0.001
I0618 20:03:13.650722  8058 solver.cpp:218] Iteration 87350 (0.864966 iter/s, 57.8057s/50 iters), loss = 0.00976868
I0618 20:03:13.650880  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 20:03:13.650908  8058 solver.cpp:237]     Train net output #1: loss = 0.00976871 (* 1 = 0.00976871 loss)
I0618 20:03:13.650926  8058 sgd_solver.cpp:105] Iteration 87350, lr = 0.001
I0618 20:03:57.647068  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 20:04:11.450132  8058 solver.cpp:218] Iteration 87400 (0.865072 iter/s, 57.7987s/50 iters), loss = 0.00879954
I0618 20:04:11.450248  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 20:04:11.450275  8058 solver.cpp:237]     Train net output #1: loss = 0.00879957 (* 1 = 0.00879957 loss)
I0618 20:04:11.450292  8058 sgd_solver.cpp:105] Iteration 87400, lr = 0.001
I0618 20:05:09.255558  8058 solver.cpp:218] Iteration 87450 (0.864981 iter/s, 57.8047s/50 iters), loss = 0.00941102
I0618 20:05:09.255713  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 20:05:09.255741  8058 solver.cpp:237]     Train net output #1: loss = 0.00941105 (* 1 = 0.00941105 loss)
I0618 20:05:09.255759  8058 sgd_solver.cpp:105] Iteration 87450, lr = 0.001
I0618 20:06:07.063272  8058 solver.cpp:218] Iteration 87500 (0.864948 iter/s, 57.8069s/50 iters), loss = 0.0107042
I0618 20:06:07.063444  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 20:06:07.063478  8058 solver.cpp:237]     Train net output #1: loss = 0.0107042 (* 1 = 0.0107042 loss)
I0618 20:06:07.063499  8058 sgd_solver.cpp:105] Iteration 87500, lr = 0.001
I0618 20:06:16.375221  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 20:07:04.862401  8058 solver.cpp:218] Iteration 87550 (0.865076 iter/s, 57.7984s/50 iters), loss = 0.00824355
I0618 20:07:04.862561  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 20:07:04.862591  8058 solver.cpp:237]     Train net output #1: loss = 0.00824358 (* 1 = 0.00824358 loss)
I0618 20:07:04.862609  8058 sgd_solver.cpp:105] Iteration 87550, lr = 0.001
I0618 20:08:02.676676  8058 solver.cpp:218] Iteration 87600 (0.864849 iter/s, 57.8135s/50 iters), loss = 0.0107696
I0618 20:08:02.676880  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 20:08:02.676910  8058 solver.cpp:237]     Train net output #1: loss = 0.0107697 (* 1 = 0.0107697 loss)
I0618 20:08:02.676929  8058 sgd_solver.cpp:105] Iteration 87600, lr = 0.001
I0618 20:08:35.099138  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 20:09:00.472134  8058 solver.cpp:218] Iteration 87650 (0.865132 iter/s, 57.7947s/50 iters), loss = 0.00948376
I0618 20:09:00.472244  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 20:09:00.472270  8058 solver.cpp:237]     Train net output #1: loss = 0.00948379 (* 1 = 0.00948379 loss)
I0618 20:09:00.472288  8058 sgd_solver.cpp:105] Iteration 87650, lr = 0.001
I0618 20:09:58.246104  8058 solver.cpp:218] Iteration 87700 (0.865452 iter/s, 57.7733s/50 iters), loss = 0.0094358
I0618 20:09:58.246229  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 20:09:58.246258  8058 solver.cpp:237]     Train net output #1: loss = 0.00943583 (* 1 = 0.00943583 loss)
I0618 20:09:58.246289  8058 sgd_solver.cpp:105] Iteration 87700, lr = 0.001
I0618 20:10:53.763713  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 20:10:56.020812  8058 solver.cpp:218] Iteration 87750 (0.865441 iter/s, 57.774s/50 iters), loss = 0.013067
I0618 20:10:56.020900  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 20:10:56.020925  8058 solver.cpp:237]     Train net output #1: loss = 0.0130671 (* 1 = 0.0130671 loss)
I0618 20:10:56.020943  8058 sgd_solver.cpp:105] Iteration 87750, lr = 0.001
I0618 20:11:53.799186  8058 solver.cpp:218] Iteration 87800 (0.865386 iter/s, 57.7777s/50 iters), loss = 0.00958484
I0618 20:11:53.799322  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 20:11:53.799351  8058 solver.cpp:237]     Train net output #1: loss = 0.00958488 (* 1 = 0.00958488 loss)
I0618 20:11:53.799370  8058 sgd_solver.cpp:105] Iteration 87800, lr = 0.001
I0618 20:12:51.570772  8058 solver.cpp:218] Iteration 87850 (0.865488 iter/s, 57.7709s/50 iters), loss = 0.00872173
I0618 20:12:51.570904  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 20:12:51.570932  8058 solver.cpp:237]     Train net output #1: loss = 0.00872177 (* 1 = 0.00872177 loss)
I0618 20:12:51.570950  8058 sgd_solver.cpp:105] Iteration 87850, lr = 0.001
I0618 20:13:12.434587  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 20:13:49.346401  8058 solver.cpp:218] Iteration 87900 (0.865427 iter/s, 57.7749s/50 iters), loss = 0.0105824
I0618 20:13:49.346525  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 20:13:49.346555  8058 solver.cpp:237]     Train net output #1: loss = 0.0105824 (* 1 = 0.0105824 loss)
I0618 20:13:49.346572  8058 sgd_solver.cpp:105] Iteration 87900, lr = 0.001
I0618 20:14:47.140353  8058 solver.cpp:218] Iteration 87950 (0.865153 iter/s, 57.7933s/50 iters), loss = 0.0100681
I0618 20:14:47.140477  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 20:14:47.140506  8058 solver.cpp:237]     Train net output #1: loss = 0.0100681 (* 1 = 0.0100681 loss)
I0618 20:14:47.140529  8058 sgd_solver.cpp:105] Iteration 87950, lr = 0.001
I0618 20:15:29.972991  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 20:15:44.914275  8058 solver.cpp:218] Iteration 88000 (0.865453 iter/s, 57.7732s/50 iters), loss = 0.009214
I0618 20:15:44.914378  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 20:15:44.914405  8058 solver.cpp:237]     Train net output #1: loss = 0.00921404 (* 1 = 0.00921404 loss)
I0618 20:15:44.914423  8058 sgd_solver.cpp:105] Iteration 88000, lr = 0.001
I0618 20:16:42.687635  8058 solver.cpp:218] Iteration 88050 (0.865461 iter/s, 57.7727s/50 iters), loss = 0.0087927
I0618 20:16:42.687773  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 20:16:42.687803  8058 solver.cpp:237]     Train net output #1: loss = 0.00879274 (* 1 = 0.00879274 loss)
I0618 20:16:42.687824  8058 sgd_solver.cpp:105] Iteration 88050, lr = 0.001
I0618 20:17:40.467578  8058 solver.cpp:218] Iteration 88100 (0.865363 iter/s, 57.7792s/50 iters), loss = 0.00991544
I0618 20:17:40.467728  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 20:17:40.467758  8058 solver.cpp:237]     Train net output #1: loss = 0.00991548 (* 1 = 0.00991548 loss)
I0618 20:17:40.467777  8058 sgd_solver.cpp:105] Iteration 88100, lr = 0.001
I0618 20:17:48.634992  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 20:18:38.240732  8058 solver.cpp:218] Iteration 88150 (0.865465 iter/s, 57.7724s/50 iters), loss = 0.00896767
I0618 20:18:38.240869  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 20:18:38.240898  8058 solver.cpp:237]     Train net output #1: loss = 0.00896771 (* 1 = 0.00896771 loss)
I0618 20:18:38.240916  8058 sgd_solver.cpp:105] Iteration 88150, lr = 0.001
I0618 20:19:36.008272  8058 solver.cpp:218] Iteration 88200 (0.865549 iter/s, 57.7668s/50 iters), loss = 0.0119293
I0618 20:19:36.008393  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 20:19:36.008421  8058 solver.cpp:237]     Train net output #1: loss = 0.0119293 (* 1 = 0.0119293 loss)
I0618 20:19:36.008452  8058 sgd_solver.cpp:105] Iteration 88200, lr = 0.001
I0618 20:20:07.301937  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 20:20:33.764614  8058 solver.cpp:218] Iteration 88250 (0.865716 iter/s, 57.7556s/50 iters), loss = 0.0104155
I0618 20:20:33.764708  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 20:20:33.764739  8058 solver.cpp:237]     Train net output #1: loss = 0.0104155 (* 1 = 0.0104155 loss)
I0618 20:20:33.764758  8058 sgd_solver.cpp:105] Iteration 88250, lr = 0.001
I0618 20:21:31.528275  8058 solver.cpp:218] Iteration 88300 (0.865606 iter/s, 57.763s/50 iters), loss = 0.0111114
I0618 20:21:31.528391  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 20:21:31.528419  8058 solver.cpp:237]     Train net output #1: loss = 0.0111114 (* 1 = 0.0111114 loss)
I0618 20:21:31.528436  8058 sgd_solver.cpp:105] Iteration 88300, lr = 0.001
I0618 20:22:25.896543  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 20:22:29.284052  8058 solver.cpp:218] Iteration 88350 (0.865724 iter/s, 57.7551s/50 iters), loss = 0.0112429
I0618 20:22:29.284126  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 20:22:29.284152  8058 solver.cpp:237]     Train net output #1: loss = 0.0112429 (* 1 = 0.0112429 loss)
I0618 20:22:29.284168  8058 sgd_solver.cpp:105] Iteration 88350, lr = 0.001
I0618 20:23:27.045295  8058 solver.cpp:218] Iteration 88400 (0.865642 iter/s, 57.7606s/50 iters), loss = 0.00866726
I0618 20:23:27.045418  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 20:23:27.045445  8058 solver.cpp:237]     Train net output #1: loss = 0.00866729 (* 1 = 0.00866729 loss)
I0618 20:23:27.045462  8058 sgd_solver.cpp:105] Iteration 88400, lr = 0.001
I0618 20:24:24.798681  8058 solver.cpp:218] Iteration 88450 (0.865761 iter/s, 57.7527s/50 iters), loss = 0.0104764
I0618 20:24:24.798797  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 20:24:24.798830  8058 solver.cpp:237]     Train net output #1: loss = 0.0104764 (* 1 = 0.0104764 loss)
I0618 20:24:24.798851  8058 sgd_solver.cpp:105] Iteration 88450, lr = 0.001
I0618 20:24:44.496700  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 20:25:22.551314  8058 solver.cpp:218] Iteration 88500 (0.865772 iter/s, 57.752s/50 iters), loss = 0.00921697
I0618 20:25:22.551436  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 20:25:22.551465  8058 solver.cpp:237]     Train net output #1: loss = 0.00921701 (* 1 = 0.00921701 loss)
I0618 20:25:22.551481  8058 sgd_solver.cpp:105] Iteration 88500, lr = 0.001
I0618 20:26:20.311563  8058 solver.cpp:218] Iteration 88550 (0.865655 iter/s, 57.7597s/50 iters), loss = 0.00906585
I0618 20:26:20.311731  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 20:26:20.311761  8058 solver.cpp:237]     Train net output #1: loss = 0.00906588 (* 1 = 0.00906588 loss)
I0618 20:26:20.311779  8058 sgd_solver.cpp:105] Iteration 88550, lr = 0.001
I0618 20:27:03.157372  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 20:27:18.093268  8058 solver.cpp:218] Iteration 88600 (0.865333 iter/s, 57.7812s/50 iters), loss = 0.0122175
I0618 20:27:18.093340  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 20:27:18.093365  8058 solver.cpp:237]     Train net output #1: loss = 0.0122176 (* 1 = 0.0122176 loss)
I0618 20:27:18.093382  8058 sgd_solver.cpp:105] Iteration 88600, lr = 0.001
I0618 20:28:15.861006  8058 solver.cpp:218] Iteration 88650 (0.865542 iter/s, 57.7673s/50 iters), loss = 0.0103224
I0618 20:28:15.861141  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 20:28:15.861176  8058 solver.cpp:237]     Train net output #1: loss = 0.0103224 (* 1 = 0.0103224 loss)
I0618 20:28:15.861194  8058 sgd_solver.cpp:105] Iteration 88650, lr = 0.001
I0618 20:29:13.631834  8058 solver.cpp:218] Iteration 88700 (0.865496 iter/s, 57.7704s/50 iters), loss = 0.0107521
I0618 20:29:13.631971  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 20:29:13.632014  8058 solver.cpp:237]     Train net output #1: loss = 0.0107521 (* 1 = 0.0107521 loss)
I0618 20:29:13.632031  8058 sgd_solver.cpp:105] Iteration 88700, lr = 0.001
I0618 20:29:21.775557  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 20:30:11.399744  8058 solver.cpp:218] Iteration 88750 (0.86554 iter/s, 57.7674s/50 iters), loss = 0.0110163
I0618 20:30:11.399869  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 20:30:11.399899  8058 solver.cpp:237]     Train net output #1: loss = 0.0110164 (* 1 = 0.0110164 loss)
I0618 20:30:11.399915  8058 sgd_solver.cpp:105] Iteration 88750, lr = 0.001
I0618 20:31:09.171591  8058 solver.cpp:218] Iteration 88800 (0.865481 iter/s, 57.7714s/50 iters), loss = 0.00862799
I0618 20:31:09.171712  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 20:31:09.171741  8058 solver.cpp:237]     Train net output #1: loss = 0.00862802 (* 1 = 0.00862802 loss)
I0618 20:31:09.171758  8058 sgd_solver.cpp:105] Iteration 88800, lr = 0.001
I0618 20:31:40.439924  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 20:32:06.934644  8058 solver.cpp:218] Iteration 88850 (0.865612 iter/s, 57.7626s/50 iters), loss = 0.010127
I0618 20:32:06.934720  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 20:32:06.934747  8058 solver.cpp:237]     Train net output #1: loss = 0.010127 (* 1 = 0.010127 loss)
I0618 20:32:06.934764  8058 sgd_solver.cpp:105] Iteration 88850, lr = 0.001
I0618 20:33:04.686743  8058 solver.cpp:218] Iteration 88900 (0.865776 iter/s, 57.7517s/50 iters), loss = 0.00954345
I0618 20:33:04.686864  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 20:33:04.686893  8058 solver.cpp:237]     Train net output #1: loss = 0.00954348 (* 1 = 0.00954348 loss)
I0618 20:33:04.686910  8058 sgd_solver.cpp:105] Iteration 88900, lr = 0.001
I0618 20:33:57.915072  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 20:34:02.453850  8058 solver.cpp:218] Iteration 88950 (0.865552 iter/s, 57.7666s/50 iters), loss = 0.0104626
I0618 20:34:02.453930  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 20:34:02.453956  8058 solver.cpp:237]     Train net output #1: loss = 0.0104626 (* 1 = 0.0104626 loss)
I0618 20:34:02.453974  8058 sgd_solver.cpp:105] Iteration 88950, lr = 0.001
I0618 20:35:00.224059  8058 solver.cpp:218] Iteration 89000 (0.865505 iter/s, 57.7698s/50 iters), loss = 0.00829827
I0618 20:35:00.224202  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 20:35:00.224232  8058 solver.cpp:237]     Train net output #1: loss = 0.00829831 (* 1 = 0.00829831 loss)
I0618 20:35:00.224251  8058 sgd_solver.cpp:105] Iteration 89000, lr = 0.001
I0618 20:35:57.996110  8058 solver.cpp:218] Iteration 89050 (0.865478 iter/s, 57.7715s/50 iters), loss = 0.00943351
I0618 20:35:57.996296  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 20:35:57.996330  8058 solver.cpp:237]     Train net output #1: loss = 0.00943354 (* 1 = 0.00943354 loss)
I0618 20:35:57.996350  8058 sgd_solver.cpp:105] Iteration 89050, lr = 0.001
I0618 20:36:16.565292  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 20:36:55.755240  8058 solver.cpp:218] Iteration 89100 (0.865672 iter/s, 57.7586s/50 iters), loss = 0.0101891
I0618 20:36:55.755360  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 20:36:55.755388  8058 solver.cpp:237]     Train net output #1: loss = 0.0101892 (* 1 = 0.0101892 loss)
I0618 20:36:55.755406  8058 sgd_solver.cpp:105] Iteration 89100, lr = 0.001
I0618 20:37:53.520788  8058 solver.cpp:218] Iteration 89150 (0.865575 iter/s, 57.7651s/50 iters), loss = 0.0103306
I0618 20:37:53.520915  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 20:37:53.520942  8058 solver.cpp:237]     Train net output #1: loss = 0.0103306 (* 1 = 0.0103306 loss)
I0618 20:37:53.520959  8058 sgd_solver.cpp:105] Iteration 89150, lr = 0.001
I0618 20:38:35.192481  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 20:38:51.291373  8058 solver.cpp:218] Iteration 89200 (0.8655 iter/s, 57.7701s/50 iters), loss = 0.011781
I0618 20:38:51.291462  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 20:38:51.291489  8058 solver.cpp:237]     Train net output #1: loss = 0.011781 (* 1 = 0.011781 loss)
I0618 20:38:51.291507  8058 sgd_solver.cpp:105] Iteration 89200, lr = 0.001
I0618 20:39:49.096050  8058 solver.cpp:218] Iteration 89250 (0.864989 iter/s, 57.8042s/50 iters), loss = 0.0117902
I0618 20:39:49.096220  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 20:39:49.096253  8058 solver.cpp:237]     Train net output #1: loss = 0.0117902 (* 1 = 0.0117902 loss)
I0618 20:39:49.096276  8058 sgd_solver.cpp:105] Iteration 89250, lr = 0.001
I0618 20:40:46.904577  8058 solver.cpp:218] Iteration 89300 (0.864932 iter/s, 57.808s/50 iters), loss = 0.0111402
I0618 20:40:46.904770  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 20:40:46.904799  8058 solver.cpp:237]     Train net output #1: loss = 0.0111402 (* 1 = 0.0111402 loss)
I0618 20:40:46.904816  8058 sgd_solver.cpp:105] Iteration 89300, lr = 0.001
I0618 20:40:53.912595  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 20:41:44.721201  8058 solver.cpp:218] Iteration 89350 (0.864812 iter/s, 57.816s/50 iters), loss = 0.00941708
I0618 20:41:44.721355  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 20:41:44.721384  8058 solver.cpp:237]     Train net output #1: loss = 0.00941711 (* 1 = 0.00941711 loss)
I0618 20:41:44.721401  8058 sgd_solver.cpp:105] Iteration 89350, lr = 0.001
I0618 20:42:42.540169  8058 solver.cpp:218] Iteration 89400 (0.864777 iter/s, 57.8184s/50 iters), loss = 0.00827738
I0618 20:42:42.540330  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 20:42:42.540360  8058 solver.cpp:237]     Train net output #1: loss = 0.00827741 (* 1 = 0.00827741 loss)
I0618 20:42:42.540379  8058 sgd_solver.cpp:105] Iteration 89400, lr = 0.001
I0618 20:43:12.666230  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 20:43:40.351608  8058 solver.cpp:218] Iteration 89450 (0.864892 iter/s, 57.8107s/50 iters), loss = 0.00992442
I0618 20:43:40.351704  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 20:43:40.351732  8058 solver.cpp:237]     Train net output #1: loss = 0.00992446 (* 1 = 0.00992446 loss)
I0618 20:43:40.351752  8058 sgd_solver.cpp:105] Iteration 89450, lr = 0.001
I0618 20:44:38.166016  8058 solver.cpp:218] Iteration 89500 (0.864847 iter/s, 57.8137s/50 iters), loss = 0.00878656
I0618 20:44:38.166177  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 20:44:38.166206  8058 solver.cpp:237]     Train net output #1: loss = 0.00878659 (* 1 = 0.00878659 loss)
I0618 20:44:38.166224  8058 sgd_solver.cpp:105] Iteration 89500, lr = 0.001
I0618 20:45:31.412758  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 20:45:35.978004  8058 solver.cpp:218] Iteration 89550 (0.864884 iter/s, 57.8112s/50 iters), loss = 0.00902253
I0618 20:45:35.978118  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 20:45:35.978150  8058 solver.cpp:237]     Train net output #1: loss = 0.00902256 (* 1 = 0.00902256 loss)
I0618 20:45:35.978170  8058 sgd_solver.cpp:105] Iteration 89550, lr = 0.001
I0618 20:46:33.804498  8058 solver.cpp:218] Iteration 89600 (0.864667 iter/s, 57.8257s/50 iters), loss = 0.010447
I0618 20:46:33.804689  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 20:46:33.804724  8058 solver.cpp:237]     Train net output #1: loss = 0.010447 (* 1 = 0.010447 loss)
I0618 20:46:33.804746  8058 sgd_solver.cpp:105] Iteration 89600, lr = 0.001
I0618 20:47:31.611138  8058 solver.cpp:218] Iteration 89650 (0.864964 iter/s, 57.8058s/50 iters), loss = 0.010081
I0618 20:47:31.611289  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 20:47:31.611317  8058 solver.cpp:237]     Train net output #1: loss = 0.010081 (* 1 = 0.010081 loss)
I0618 20:47:31.611335  8058 sgd_solver.cpp:105] Iteration 89650, lr = 0.001
I0618 20:47:50.166864  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 20:48:29.415999  8058 solver.cpp:218] Iteration 89700 (0.864991 iter/s, 57.8041s/50 iters), loss = 0.00981179
I0618 20:48:29.416173  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 20:48:29.416203  8058 solver.cpp:237]     Train net output #1: loss = 0.00981183 (* 1 = 0.00981183 loss)
I0618 20:48:29.416221  8058 sgd_solver.cpp:105] Iteration 89700, lr = 0.001
I0618 20:49:27.221374  8058 solver.cpp:218] Iteration 89750 (0.864983 iter/s, 57.8046s/50 iters), loss = 0.011865
I0618 20:49:27.221520  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 20:49:27.221550  8058 solver.cpp:237]     Train net output #1: loss = 0.011865 (* 1 = 0.011865 loss)
I0618 20:49:27.221567  8058 sgd_solver.cpp:105] Iteration 89750, lr = 0.001
I0618 20:50:08.896947  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 20:50:25.031632  8058 solver.cpp:218] Iteration 89800 (0.86491 iter/s, 57.8095s/50 iters), loss = 0.0108056
I0618 20:50:25.031744  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 20:50:25.031776  8058 solver.cpp:237]     Train net output #1: loss = 0.0108056 (* 1 = 0.0108056 loss)
I0618 20:50:25.031797  8058 sgd_solver.cpp:105] Iteration 89800, lr = 0.001
I0618 20:51:22.840811  8058 solver.cpp:218] Iteration 89850 (0.864925 iter/s, 57.8085s/50 iters), loss = 0.010957
I0618 20:51:22.841174  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 20:51:22.841203  8058 solver.cpp:237]     Train net output #1: loss = 0.010957 (* 1 = 0.010957 loss)
I0618 20:51:22.841222  8058 sgd_solver.cpp:105] Iteration 89850, lr = 0.001
I0618 20:52:20.642256  8058 solver.cpp:218] Iteration 89900 (0.865045 iter/s, 57.8005s/50 iters), loss = 0.00719127
I0618 20:52:20.642413  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 20:52:20.642443  8058 solver.cpp:237]     Train net output #1: loss = 0.0071913 (* 1 = 0.0071913 loss)
I0618 20:52:20.642460  8058 sgd_solver.cpp:105] Iteration 89900, lr = 0.001
I0618 20:52:26.495548  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 20:53:18.443910  8058 solver.cpp:218] Iteration 89950 (0.865039 iter/s, 57.8009s/50 iters), loss = 0.0114798
I0618 20:53:18.444166  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 20:53:18.444195  8058 solver.cpp:237]     Train net output #1: loss = 0.0114798 (* 1 = 0.0114798 loss)
I0618 20:53:18.444213  8058 sgd_solver.cpp:105] Iteration 89950, lr = 0.001
I0618 20:54:15.096298  8058 solver.cpp:447] Snapshotting to binary proto file mobilenet/mobile_cub_iter_90000.caffemodel
I0618 20:54:15.180649  8058 sgd_solver.cpp:273] Snapshotting solver state to binary proto file mobilenet/mobile_cub_iter_90000.solverstate
I0618 20:54:16.364668  8058 solver.cpp:218] Iteration 90000 (0.863261 iter/s, 57.9199s/50 iters), loss = 0.0109726
I0618 20:54:16.364766  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 20:54:16.364790  8058 solver.cpp:237]     Train net output #1: loss = 0.0109727 (* 1 = 0.0109727 loss)
I0618 20:54:16.364807  8058 sgd_solver.cpp:105] Iteration 90000, lr = 0.001
I0618 20:54:45.341747  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 20:55:14.166839  8058 solver.cpp:218] Iteration 90050 (0.86503 iter/s, 57.8015s/50 iters), loss = 0.0102683
I0618 20:55:14.166934  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 20:55:14.166961  8058 solver.cpp:237]     Train net output #1: loss = 0.0102684 (* 1 = 0.0102684 loss)
I0618 20:55:14.166980  8058 sgd_solver.cpp:105] Iteration 90050, lr = 0.001
I0618 20:56:11.967916  8058 solver.cpp:218] Iteration 90100 (0.865046 iter/s, 57.8004s/50 iters), loss = 0.012331
I0618 20:56:11.968089  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 20:56:11.968119  8058 solver.cpp:237]     Train net output #1: loss = 0.012331 (* 1 = 0.012331 loss)
I0618 20:56:11.968137  8058 sgd_solver.cpp:105] Iteration 90100, lr = 0.001
I0618 20:57:04.060633  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 20:57:09.765554  8058 solver.cpp:218] Iteration 90150 (0.865099 iter/s, 57.7969s/50 iters), loss = 0.00832303
I0618 20:57:09.765662  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 20:57:09.765689  8058 solver.cpp:237]     Train net output #1: loss = 0.00832306 (* 1 = 0.00832306 loss)
I0618 20:57:09.765707  8058 sgd_solver.cpp:105] Iteration 90150, lr = 0.001
I0618 20:58:07.567289  8058 solver.cpp:218] Iteration 90200 (0.865036 iter/s, 57.801s/50 iters), loss = 0.0107603
I0618 20:58:07.567435  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 20:58:07.567463  8058 solver.cpp:237]     Train net output #1: loss = 0.0107603 (* 1 = 0.0107603 loss)
I0618 20:58:07.567481  8058 sgd_solver.cpp:105] Iteration 90200, lr = 0.001
I0618 20:59:05.368887  8058 solver.cpp:218] Iteration 90250 (0.865039 iter/s, 57.8008s/50 iters), loss = 0.010173
I0618 20:59:05.369036  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 20:59:05.369065  8058 solver.cpp:237]     Train net output #1: loss = 0.010173 (* 1 = 0.010173 loss)
I0618 20:59:05.369082  8058 sgd_solver.cpp:105] Iteration 90250, lr = 0.001
I0618 20:59:22.776093  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 21:00:03.130424  8058 solver.cpp:218] Iteration 90300 (0.865638 iter/s, 57.7609s/50 iters), loss = 0.0104755
I0618 21:00:03.130553  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:00:03.130584  8058 solver.cpp:237]     Train net output #1: loss = 0.0104755 (* 1 = 0.0104755 loss)
I0618 21:00:03.130605  8058 sgd_solver.cpp:105] Iteration 90300, lr = 0.001
I0618 21:01:00.896064  8058 solver.cpp:218] Iteration 90350 (0.865573 iter/s, 57.7652s/50 iters), loss = 0.0104069
I0618 21:01:00.896195  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:01:00.896224  8058 solver.cpp:237]     Train net output #1: loss = 0.0104069 (* 1 = 0.0104069 loss)
I0618 21:01:00.896241  8058 sgd_solver.cpp:105] Iteration 90350, lr = 0.001
I0618 21:01:41.404204  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 21:01:58.660326  8058 solver.cpp:218] Iteration 90400 (0.865594 iter/s, 57.7638s/50 iters), loss = 0.00790614
I0618 21:01:58.660401  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:01:58.660429  8058 solver.cpp:237]     Train net output #1: loss = 0.00790617 (* 1 = 0.00790617 loss)
I0618 21:01:58.660446  8058 sgd_solver.cpp:105] Iteration 90400, lr = 0.001
I0618 21:02:56.422554  8058 solver.cpp:218] Iteration 90450 (0.865624 iter/s, 57.7618s/50 iters), loss = 0.010554
I0618 21:02:56.422669  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:02:56.422698  8058 solver.cpp:237]     Train net output #1: loss = 0.010554 (* 1 = 0.010554 loss)
I0618 21:02:56.422714  8058 sgd_solver.cpp:105] Iteration 90450, lr = 0.001
I0618 21:03:54.191313  8058 solver.cpp:218] Iteration 90500 (0.865527 iter/s, 57.7683s/50 iters), loss = 0.0126441
I0618 21:03:54.191480  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:03:54.191520  8058 solver.cpp:237]     Train net output #1: loss = 0.0126441 (* 1 = 0.0126441 loss)
I0618 21:03:54.191545  8058 sgd_solver.cpp:105] Iteration 90500, lr = 0.001
I0618 21:04:00.028086  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 21:04:51.959611  8058 solver.cpp:218] Iteration 90550 (0.865534 iter/s, 57.7678s/50 iters), loss = 0.0111578
I0618 21:04:51.959745  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:04:51.959774  8058 solver.cpp:237]     Train net output #1: loss = 0.0111579 (* 1 = 0.0111579 loss)
I0618 21:04:51.959791  8058 sgd_solver.cpp:105] Iteration 90550, lr = 0.001
I0618 21:05:49.708528  8058 solver.cpp:218] Iteration 90600 (0.865824 iter/s, 57.7484s/50 iters), loss = 0.00782594
I0618 21:05:49.708647  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:05:49.708676  8058 solver.cpp:237]     Train net output #1: loss = 0.00782597 (* 1 = 0.00782597 loss)
I0618 21:05:49.708693  8058 sgd_solver.cpp:105] Iteration 90600, lr = 0.001
I0618 21:06:18.663386  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 21:06:47.509217  8058 solver.cpp:218] Iteration 90650 (0.865049 iter/s, 57.8002s/50 iters), loss = 0.0102905
I0618 21:06:47.509383  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:06:47.509413  8058 solver.cpp:237]     Train net output #1: loss = 0.0102905 (* 1 = 0.0102905 loss)
I0618 21:06:47.509430  8058 sgd_solver.cpp:105] Iteration 90650, lr = 0.001
I0618 21:07:45.289427  8058 solver.cpp:218] Iteration 90700 (0.865356 iter/s, 57.7797s/50 iters), loss = 0.00816763
I0618 21:07:45.289556  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:07:45.289589  8058 solver.cpp:237]     Train net output #1: loss = 0.00816767 (* 1 = 0.00816767 loss)
I0618 21:07:45.289609  8058 sgd_solver.cpp:105] Iteration 90700, lr = 0.001
I0618 21:08:37.347057  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 21:08:43.051996  8058 solver.cpp:218] Iteration 90750 (0.865619 iter/s, 57.7621s/50 iters), loss = 0.00946075
I0618 21:08:43.052073  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:08:43.052099  8058 solver.cpp:237]     Train net output #1: loss = 0.00946078 (* 1 = 0.00946078 loss)
I0618 21:08:43.052117  8058 sgd_solver.cpp:105] Iteration 90750, lr = 0.001
I0618 21:09:40.807799  8058 solver.cpp:218] Iteration 90800 (0.86572 iter/s, 57.7554s/50 iters), loss = 0.0106809
I0618 21:09:40.807899  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:09:40.807929  8058 solver.cpp:237]     Train net output #1: loss = 0.0106809 (* 1 = 0.0106809 loss)
I0618 21:09:40.807945  8058 sgd_solver.cpp:105] Iteration 90800, lr = 0.001
I0618 21:10:38.569248  8058 solver.cpp:218] Iteration 90850 (0.865636 iter/s, 57.761s/50 iters), loss = 0.0104882
I0618 21:10:38.569362  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:10:38.569391  8058 solver.cpp:237]     Train net output #1: loss = 0.0104882 (* 1 = 0.0104882 loss)
I0618 21:10:38.569407  8058 sgd_solver.cpp:105] Iteration 90850, lr = 0.001
I0618 21:10:55.950453  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 21:11:36.332888  8058 solver.cpp:218] Iteration 90900 (0.865604 iter/s, 57.7632s/50 iters), loss = 0.0107485
I0618 21:11:36.332995  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:11:36.333025  8058 solver.cpp:237]     Train net output #1: loss = 0.0107486 (* 1 = 0.0107486 loss)
I0618 21:11:36.333042  8058 sgd_solver.cpp:105] Iteration 90900, lr = 0.001
I0618 21:12:34.096113  8058 solver.cpp:218] Iteration 90950 (0.86561 iter/s, 57.7628s/50 iters), loss = 0.0130315
I0618 21:12:34.096252  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:12:34.096282  8058 solver.cpp:237]     Train net output #1: loss = 0.0130315 (* 1 = 0.0130315 loss)
I0618 21:12:34.096299  8058 sgd_solver.cpp:105] Iteration 90950, lr = 0.001
I0618 21:13:13.488407  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 21:13:31.867622  8058 solver.cpp:218] Iteration 91000 (0.865486 iter/s, 57.771s/50 iters), loss = 0.0107488
I0618 21:13:31.867697  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:13:31.867724  8058 solver.cpp:237]     Train net output #1: loss = 0.0107488 (* 1 = 0.0107488 loss)
I0618 21:13:31.867743  8058 sgd_solver.cpp:105] Iteration 91000, lr = 0.001
I0618 21:14:29.633599  8058 solver.cpp:218] Iteration 91050 (0.865568 iter/s, 57.7655s/50 iters), loss = 0.00967606
I0618 21:14:29.633726  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:14:29.633754  8058 solver.cpp:237]     Train net output #1: loss = 0.00967609 (* 1 = 0.00967609 loss)
I0618 21:14:29.633772  8058 sgd_solver.cpp:105] Iteration 91050, lr = 0.001
I0618 21:15:27.404112  8058 solver.cpp:218] Iteration 91100 (0.865501 iter/s, 57.77s/50 iters), loss = 0.0122003
I0618 21:15:27.404212  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:15:27.404242  8058 solver.cpp:237]     Train net output #1: loss = 0.0122004 (* 1 = 0.0122004 loss)
I0618 21:15:27.404273  8058 sgd_solver.cpp:105] Iteration 91100, lr = 0.001
I0618 21:15:32.109110  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 21:16:25.182831  8058 solver.cpp:218] Iteration 91150 (0.865378 iter/s, 57.7782s/50 iters), loss = 0.0114701
I0618 21:16:25.182945  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:16:25.182974  8058 solver.cpp:237]     Train net output #1: loss = 0.0114701 (* 1 = 0.0114701 loss)
I0618 21:16:25.182991  8058 sgd_solver.cpp:105] Iteration 91150, lr = 0.001
I0618 21:17:22.946605  8058 solver.cpp:218] Iteration 91200 (0.865602 iter/s, 57.7633s/50 iters), loss = 0.0110256
I0618 21:17:22.946722  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:17:22.946750  8058 solver.cpp:237]     Train net output #1: loss = 0.0110256 (* 1 = 0.0110256 loss)
I0618 21:17:22.946768  8058 sgd_solver.cpp:105] Iteration 91200, lr = 0.001
I0618 21:17:50.751302  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 21:18:20.707312  8058 solver.cpp:218] Iteration 91250 (0.865648 iter/s, 57.7602s/50 iters), loss = 0.0124579
I0618 21:18:20.707424  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:18:20.707453  8058 solver.cpp:237]     Train net output #1: loss = 0.012458 (* 1 = 0.012458 loss)
I0618 21:18:20.707470  8058 sgd_solver.cpp:105] Iteration 91250, lr = 0.001
I0618 21:19:18.475953  8058 solver.cpp:218] Iteration 91300 (0.865529 iter/s, 57.7682s/50 iters), loss = 0.0107243
I0618 21:19:18.476078  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:19:18.476106  8058 solver.cpp:237]     Train net output #1: loss = 0.0107244 (* 1 = 0.0107244 loss)
I0618 21:19:18.476125  8058 sgd_solver.cpp:105] Iteration 91300, lr = 0.001
I0618 21:20:09.418678  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 21:20:16.258416  8058 solver.cpp:218] Iteration 91350 (0.865322 iter/s, 57.782s/50 iters), loss = 0.0105532
I0618 21:20:16.258502  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:20:16.258533  8058 solver.cpp:237]     Train net output #1: loss = 0.0105532 (* 1 = 0.0105532 loss)
I0618 21:20:16.258553  8058 sgd_solver.cpp:105] Iteration 91350, lr = 0.001
I0618 21:21:14.044445  8058 solver.cpp:218] Iteration 91400 (0.865268 iter/s, 57.7856s/50 iters), loss = 0.0111061
I0618 21:21:14.044570  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:21:14.044600  8058 solver.cpp:237]     Train net output #1: loss = 0.0111061 (* 1 = 0.0111061 loss)
I0618 21:21:14.044617  8058 sgd_solver.cpp:105] Iteration 91400, lr = 0.001
I0618 21:22:11.822674  8058 solver.cpp:218] Iteration 91450 (0.865386 iter/s, 57.7777s/50 iters), loss = 0.0101783
I0618 21:22:11.822803  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:22:11.822834  8058 solver.cpp:237]     Train net output #1: loss = 0.0101784 (* 1 = 0.0101784 loss)
I0618 21:22:11.822854  8058 sgd_solver.cpp:105] Iteration 91450, lr = 0.001
I0618 21:22:28.080739  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 21:23:09.594931  8058 solver.cpp:218] Iteration 91500 (0.865475 iter/s, 57.7717s/50 iters), loss = 0.0108373
I0618 21:23:09.595118  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:23:09.595149  8058 solver.cpp:237]     Train net output #1: loss = 0.0108374 (* 1 = 0.0108374 loss)
I0618 21:23:09.595167  8058 sgd_solver.cpp:105] Iteration 91500, lr = 0.001
I0618 21:24:07.369209  8058 solver.cpp:218] Iteration 91550 (0.865446 iter/s, 57.7737s/50 iters), loss = 0.00977417
I0618 21:24:07.369343  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:24:07.369372  8058 solver.cpp:237]     Train net output #1: loss = 0.0097742 (* 1 = 0.0097742 loss)
I0618 21:24:07.369390  8058 sgd_solver.cpp:105] Iteration 91550, lr = 0.001
I0618 21:24:46.715322  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 21:25:05.151365  8058 solver.cpp:218] Iteration 91600 (0.865327 iter/s, 57.7816s/50 iters), loss = 0.0100373
I0618 21:25:05.151444  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:25:05.151482  8058 solver.cpp:237]     Train net output #1: loss = 0.0100373 (* 1 = 0.0100373 loss)
I0618 21:25:05.151500  8058 sgd_solver.cpp:105] Iteration 91600, lr = 0.001
I0618 21:26:02.924644  8058 solver.cpp:218] Iteration 91650 (0.865459 iter/s, 57.7728s/50 iters), loss = 0.0096132
I0618 21:26:02.924794  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:26:02.924827  8058 solver.cpp:237]     Train net output #1: loss = 0.00961323 (* 1 = 0.00961323 loss)
I0618 21:26:02.924847  8058 sgd_solver.cpp:105] Iteration 91650, lr = 0.001
I0618 21:27:00.694686  8058 solver.cpp:218] Iteration 91700 (0.865509 iter/s, 57.7695s/50 iters), loss = 0.0100783
I0618 21:27:00.694814  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:27:00.694844  8058 solver.cpp:237]     Train net output #1: loss = 0.0100784 (* 1 = 0.0100784 loss)
I0618 21:27:00.694860  8058 sgd_solver.cpp:105] Iteration 91700, lr = 0.001
I0618 21:27:05.371094  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 21:27:58.458039  8058 solver.cpp:218] Iteration 91750 (0.865609 iter/s, 57.7628s/50 iters), loss = 0.0112744
I0618 21:27:58.458164  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:27:58.458194  8058 solver.cpp:237]     Train net output #1: loss = 0.0112744 (* 1 = 0.0112744 loss)
I0618 21:27:58.458210  8058 sgd_solver.cpp:105] Iteration 91750, lr = 0.001
I0618 21:28:56.241569  8058 solver.cpp:218] Iteration 91800 (0.865306 iter/s, 57.783s/50 iters), loss = 0.0096647
I0618 21:28:56.241683  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:28:56.241711  8058 solver.cpp:237]     Train net output #1: loss = 0.00966473 (* 1 = 0.00966473 loss)
I0618 21:28:56.241729  8058 sgd_solver.cpp:105] Iteration 91800, lr = 0.001
I0618 21:29:24.026654  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 21:29:54.002846  8058 solver.cpp:218] Iteration 91850 (0.86564 iter/s, 57.7607s/50 iters), loss = 0.00929427
I0618 21:29:54.002998  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:29:54.003032  8058 solver.cpp:237]     Train net output #1: loss = 0.00929431 (* 1 = 0.00929431 loss)
I0618 21:29:54.003052  8058 sgd_solver.cpp:105] Iteration 91850, lr = 0.001
I0618 21:30:51.763797  8058 solver.cpp:218] Iteration 91900 (0.865645 iter/s, 57.7604s/50 iters), loss = 0.00924616
I0618 21:30:51.763907  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:30:51.763936  8058 solver.cpp:237]     Train net output #1: loss = 0.00924619 (* 1 = 0.00924619 loss)
I0618 21:30:51.763953  8058 sgd_solver.cpp:105] Iteration 91900, lr = 0.001
I0618 21:31:41.523784  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 21:31:49.527426  8058 solver.cpp:218] Iteration 91950 (0.865604 iter/s, 57.7631s/50 iters), loss = 0.00955036
I0618 21:31:49.527496  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:31:49.527528  8058 solver.cpp:237]     Train net output #1: loss = 0.00955039 (* 1 = 0.00955039 loss)
I0618 21:31:49.527547  8058 sgd_solver.cpp:105] Iteration 91950, lr = 0.001
I0618 21:32:47.282889  8058 solver.cpp:218] Iteration 92000 (0.865726 iter/s, 57.755s/50 iters), loss = 0.00919977
I0618 21:32:47.283051  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:32:47.283082  8058 solver.cpp:237]     Train net output #1: loss = 0.0091998 (* 1 = 0.0091998 loss)
I0618 21:32:47.283100  8058 sgd_solver.cpp:105] Iteration 92000, lr = 0.001
I0618 21:33:45.040359  8058 solver.cpp:218] Iteration 92050 (0.865698 iter/s, 57.7569s/50 iters), loss = 0.0103137
I0618 21:33:45.040488  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:33:45.040522  8058 solver.cpp:237]     Train net output #1: loss = 0.0103138 (* 1 = 0.0103138 loss)
I0618 21:33:45.040542  8058 sgd_solver.cpp:105] Iteration 92050, lr = 0.001
I0618 21:34:00.138254  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 21:34:42.798486  8058 solver.cpp:218] Iteration 92100 (0.865687 iter/s, 57.7576s/50 iters), loss = 0.0100847
I0618 21:34:42.798672  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:34:42.798702  8058 solver.cpp:237]     Train net output #1: loss = 0.0100847 (* 1 = 0.0100847 loss)
I0618 21:34:42.798720  8058 sgd_solver.cpp:105] Iteration 92100, lr = 0.001
I0618 21:35:40.558421  8058 solver.cpp:218] Iteration 92150 (0.865661 iter/s, 57.7593s/50 iters), loss = 0.0097695
I0618 21:35:40.558534  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:35:40.558563  8058 solver.cpp:237]     Train net output #1: loss = 0.00976954 (* 1 = 0.00976954 loss)
I0618 21:35:40.558580  8058 sgd_solver.cpp:105] Iteration 92150, lr = 0.001
I0618 21:36:18.782863  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 21:36:38.320051  8058 solver.cpp:218] Iteration 92200 (0.865634 iter/s, 57.7611s/50 iters), loss = 0.0110831
I0618 21:36:38.320124  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:36:38.320152  8058 solver.cpp:237]     Train net output #1: loss = 0.0110831 (* 1 = 0.0110831 loss)
I0618 21:36:38.320169  8058 sgd_solver.cpp:105] Iteration 92200, lr = 0.001
I0618 21:37:36.076728  8058 solver.cpp:218] Iteration 92250 (0.865708 iter/s, 57.7562s/50 iters), loss = 0.00788689
I0618 21:37:36.076850  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:37:36.076884  8058 solver.cpp:237]     Train net output #1: loss = 0.00788692 (* 1 = 0.00788692 loss)
I0618 21:37:36.076903  8058 sgd_solver.cpp:105] Iteration 92250, lr = 0.001
I0618 21:38:33.835177  8058 solver.cpp:218] Iteration 92300 (0.865682 iter/s, 57.7579s/50 iters), loss = 0.012165
I0618 21:38:33.835322  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:38:33.835353  8058 solver.cpp:237]     Train net output #1: loss = 0.0121651 (* 1 = 0.0121651 loss)
I0618 21:38:33.835373  8058 sgd_solver.cpp:105] Iteration 92300, lr = 0.001
I0618 21:38:37.395028  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 21:39:31.590332  8058 solver.cpp:218] Iteration 92350 (0.865732 iter/s, 57.7546s/50 iters), loss = 0.00898931
I0618 21:39:31.590531  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:39:31.590562  8058 solver.cpp:237]     Train net output #1: loss = 0.00898935 (* 1 = 0.00898935 loss)
I0618 21:39:31.590580  8058 sgd_solver.cpp:105] Iteration 92350, lr = 0.001
I0618 21:40:29.351318  8058 solver.cpp:218] Iteration 92400 (0.865645 iter/s, 57.7604s/50 iters), loss = 0.0106875
I0618 21:40:29.351423  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:40:29.351452  8058 solver.cpp:237]     Train net output #1: loss = 0.0106876 (* 1 = 0.0106876 loss)
I0618 21:40:29.351469  8058 sgd_solver.cpp:105] Iteration 92400, lr = 0.001
I0618 21:40:55.989425  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 21:41:27.130501  8058 solver.cpp:218] Iteration 92450 (0.865372 iter/s, 57.7786s/50 iters), loss = 0.00968744
I0618 21:41:27.130677  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:41:27.130713  8058 solver.cpp:237]     Train net output #1: loss = 0.00968747 (* 1 = 0.00968747 loss)
I0618 21:41:27.130734  8058 sgd_solver.cpp:105] Iteration 92450, lr = 0.001
I0618 21:42:24.891883  8058 solver.cpp:218] Iteration 92500 (0.865639 iter/s, 57.7608s/50 iters), loss = 0.0096732
I0618 21:42:24.892045  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:42:24.892076  8058 solver.cpp:237]     Train net output #1: loss = 0.00967323 (* 1 = 0.00967323 loss)
I0618 21:42:24.892093  8058 sgd_solver.cpp:105] Iteration 92500, lr = 0.001
I0618 21:43:14.649588  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 21:43:22.648977  8058 solver.cpp:218] Iteration 92550 (0.865703 iter/s, 57.7565s/50 iters), loss = 0.00970629
I0618 21:43:22.649051  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:43:22.649077  8058 solver.cpp:237]     Train net output #1: loss = 0.00970633 (* 1 = 0.00970633 loss)
I0618 21:43:22.649094  8058 sgd_solver.cpp:105] Iteration 92550, lr = 0.001
I0618 21:44:20.409560  8058 solver.cpp:218] Iteration 92600 (0.86565 iter/s, 57.7601s/50 iters), loss = 0.00916907
I0618 21:44:20.409662  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:44:20.409690  8058 solver.cpp:237]     Train net output #1: loss = 0.0091691 (* 1 = 0.0091691 loss)
I0618 21:44:20.409708  8058 sgd_solver.cpp:105] Iteration 92600, lr = 0.001
I0618 21:45:18.165457  8058 solver.cpp:218] Iteration 92650 (0.865721 iter/s, 57.7554s/50 iters), loss = 0.0106349
I0618 21:45:18.165571  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:45:18.165602  8058 solver.cpp:237]     Train net output #1: loss = 0.010635 (* 1 = 0.010635 loss)
I0618 21:45:18.165623  8058 sgd_solver.cpp:105] Iteration 92650, lr = 0.001
I0618 21:45:33.248896  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 21:46:15.937921  8058 solver.cpp:218] Iteration 92700 (0.865472 iter/s, 57.7719s/50 iters), loss = 0.0119013
I0618 21:46:15.938048  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:46:15.938077  8058 solver.cpp:237]     Train net output #1: loss = 0.0119013 (* 1 = 0.0119013 loss)
I0618 21:46:15.938096  8058 sgd_solver.cpp:105] Iteration 92700, lr = 0.001
I0618 21:47:13.708153  8058 solver.cpp:218] Iteration 92750 (0.865506 iter/s, 57.7697s/50 iters), loss = 0.00980135
I0618 21:47:13.708269  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:47:13.708297  8058 solver.cpp:237]     Train net output #1: loss = 0.00980138 (* 1 = 0.00980138 loss)
I0618 21:47:13.708315  8058 sgd_solver.cpp:105] Iteration 92750, lr = 0.001
I0618 21:47:51.877584  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 21:48:11.463979  8058 solver.cpp:218] Iteration 92800 (0.865722 iter/s, 57.7553s/50 iters), loss = 0.011476
I0618 21:48:11.464058  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:48:11.464085  8058 solver.cpp:237]     Train net output #1: loss = 0.0114761 (* 1 = 0.0114761 loss)
I0618 21:48:11.464103  8058 sgd_solver.cpp:105] Iteration 92800, lr = 0.001
I0618 21:49:09.219740  8058 solver.cpp:218] Iteration 92850 (0.865722 iter/s, 57.7552s/50 iters), loss = 0.010056
I0618 21:49:09.219862  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:49:09.219895  8058 solver.cpp:237]     Train net output #1: loss = 0.010056 (* 1 = 0.010056 loss)
I0618 21:49:09.219916  8058 sgd_solver.cpp:105] Iteration 92850, lr = 0.001
I0618 21:50:06.980530  8058 solver.cpp:218] Iteration 92900 (0.865647 iter/s, 57.7602s/50 iters), loss = 0.00950018
I0618 21:50:06.980646  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:50:06.980676  8058 solver.cpp:237]     Train net output #1: loss = 0.00950021 (* 1 = 0.00950021 loss)
I0618 21:50:06.980693  8058 sgd_solver.cpp:105] Iteration 92900, lr = 0.001
I0618 21:50:09.371289  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 21:51:04.743826  8058 solver.cpp:218] Iteration 92950 (0.86561 iter/s, 57.7627s/50 iters), loss = 0.0126478
I0618 21:51:04.743989  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:51:04.744019  8058 solver.cpp:237]     Train net output #1: loss = 0.0126479 (* 1 = 0.0126479 loss)
I0618 21:51:04.744037  8058 sgd_solver.cpp:105] Iteration 92950, lr = 0.001
I0618 21:52:02.513875  8058 solver.cpp:218] Iteration 93000 (0.865509 iter/s, 57.7695s/50 iters), loss = 0.0113365
I0618 21:52:02.513985  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:52:02.514014  8058 solver.cpp:237]     Train net output #1: loss = 0.0113365 (* 1 = 0.0113365 loss)
I0618 21:52:02.514032  8058 sgd_solver.cpp:105] Iteration 93000, lr = 0.001
I0618 21:52:28.023176  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 21:53:00.279542  8058 solver.cpp:218] Iteration 93050 (0.865575 iter/s, 57.7651s/50 iters), loss = 0.0108627
I0618 21:53:00.279688  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:53:00.279722  8058 solver.cpp:237]     Train net output #1: loss = 0.0108628 (* 1 = 0.0108628 loss)
I0618 21:53:00.279757  8058 sgd_solver.cpp:105] Iteration 93050, lr = 0.001
I0618 21:53:58.060564  8058 solver.cpp:218] Iteration 93100 (0.865345 iter/s, 57.7804s/50 iters), loss = 0.0106983
I0618 21:53:58.060664  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:53:58.060693  8058 solver.cpp:237]     Train net output #1: loss = 0.0106983 (* 1 = 0.0106983 loss)
I0618 21:53:58.060710  8058 sgd_solver.cpp:105] Iteration 93100, lr = 0.001
I0618 21:54:46.686836  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 21:54:55.829296  8058 solver.cpp:218] Iteration 93150 (0.865528 iter/s, 57.7682s/50 iters), loss = 0.0112117
I0618 21:54:55.829373  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:54:55.829399  8058 solver.cpp:237]     Train net output #1: loss = 0.0112118 (* 1 = 0.0112118 loss)
I0618 21:54:55.829417  8058 sgd_solver.cpp:105] Iteration 93150, lr = 0.001
I0618 21:55:53.595115  8058 solver.cpp:218] Iteration 93200 (0.865571 iter/s, 57.7653s/50 iters), loss = 0.0113154
I0618 21:55:53.596407  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:55:53.596437  8058 solver.cpp:237]     Train net output #1: loss = 0.0113154 (* 1 = 0.0113154 loss)
I0618 21:55:53.596454  8058 sgd_solver.cpp:105] Iteration 93200, lr = 0.001
I0618 21:56:51.356077  8058 solver.cpp:218] Iteration 93250 (0.865663 iter/s, 57.7592s/50 iters), loss = 0.0103759
I0618 21:56:51.356199  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:56:51.356231  8058 solver.cpp:237]     Train net output #1: loss = 0.0103759 (* 1 = 0.0103759 loss)
I0618 21:56:51.356251  8058 sgd_solver.cpp:105] Iteration 93250, lr = 0.001
I0618 21:57:05.294878  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 21:57:49.134759  8058 solver.cpp:218] Iteration 93300 (0.865379 iter/s, 57.7781s/50 iters), loss = 0.00896852
I0618 21:57:49.134865  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:57:49.134894  8058 solver.cpp:237]     Train net output #1: loss = 0.00896855 (* 1 = 0.00896855 loss)
I0618 21:57:49.134912  8058 sgd_solver.cpp:105] Iteration 93300, lr = 0.001
I0618 21:58:46.891217  8058 solver.cpp:218] Iteration 93350 (0.865712 iter/s, 57.7559s/50 iters), loss = 0.00841003
I0618 21:58:46.899592  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:58:46.899623  8058 solver.cpp:237]     Train net output #1: loss = 0.00841006 (* 1 = 0.00841006 loss)
I0618 21:58:46.899641  8058 sgd_solver.cpp:105] Iteration 93350, lr = 0.001
I0618 21:59:23.933123  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 21:59:44.658995  8058 solver.cpp:218] Iteration 93400 (0.865667 iter/s, 57.7589s/50 iters), loss = 0.00799366
I0618 21:59:44.659087  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 21:59:44.659116  8058 solver.cpp:237]     Train net output #1: loss = 0.00799369 (* 1 = 0.00799369 loss)
I0618 21:59:44.659133  8058 sgd_solver.cpp:105] Iteration 93400, lr = 0.001
I0618 22:00:42.429818  8058 solver.cpp:218] Iteration 93450 (0.865497 iter/s, 57.7703s/50 iters), loss = 0.010271
I0618 22:00:42.429996  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 22:00:42.430025  8058 solver.cpp:237]     Train net output #1: loss = 0.010271 (* 1 = 0.010271 loss)
I0618 22:00:42.430043  8058 sgd_solver.cpp:105] Iteration 93450, lr = 0.001
I0618 22:01:40.192644  8058 solver.cpp:218] Iteration 93500 (0.865618 iter/s, 57.7622s/50 iters), loss = 0.0116359
I0618 22:01:40.192770  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 22:01:40.192798  8058 solver.cpp:237]     Train net output #1: loss = 0.0116359 (* 1 = 0.0116359 loss)
I0618 22:01:40.192816  8058 sgd_solver.cpp:105] Iteration 93500, lr = 0.001
I0618 22:01:42.589748  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 22:02:37.964226  8058 solver.cpp:218] Iteration 93550 (0.865486 iter/s, 57.771s/50 iters), loss = 0.0114378
I0618 22:02:37.964354  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 22:02:37.964395  8058 solver.cpp:237]     Train net output #1: loss = 0.0114378 (* 1 = 0.0114378 loss)
I0618 22:02:37.964413  8058 sgd_solver.cpp:105] Iteration 93550, lr = 0.001
I0618 22:03:35.721842  8058 solver.cpp:218] Iteration 93600 (0.865695 iter/s, 57.7571s/50 iters), loss = 0.0095437
I0618 22:03:35.721963  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 22:03:35.721993  8058 solver.cpp:237]     Train net output #1: loss = 0.00954373 (* 1 = 0.00954373 loss)
I0618 22:03:35.722010  8058 sgd_solver.cpp:105] Iteration 93600, lr = 0.001
I0618 22:04:01.209455  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 22:04:33.465018  8058 solver.cpp:218] Iteration 93650 (0.865912 iter/s, 57.7426s/50 iters), loss = 0.00977445
I0618 22:04:33.465136  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 22:04:33.465163  8058 solver.cpp:237]     Train net output #1: loss = 0.00977449 (* 1 = 0.00977449 loss)
I0618 22:04:33.465181  8058 sgd_solver.cpp:105] Iteration 93650, lr = 0.001
I0618 22:05:31.224370  8058 solver.cpp:218] Iteration 93700 (0.865669 iter/s, 57.7588s/50 iters), loss = 0.00983643
I0618 22:05:31.224501  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 22:05:31.224540  8058 solver.cpp:237]     Train net output #1: loss = 0.00983647 (* 1 = 0.00983647 loss)
I0618 22:05:31.224560  8058 sgd_solver.cpp:105] Iteration 93700, lr = 0.001
I0618 22:06:19.841913  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 22:06:29.004577  8058 solver.cpp:218] Iteration 93750 (0.865357 iter/s, 57.7796s/50 iters), loss = 0.0100539
I0618 22:06:29.004650  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 22:06:29.004678  8058 solver.cpp:237]     Train net output #1: loss = 0.0100539 (* 1 = 0.0100539 loss)
I0618 22:06:29.004694  8058 sgd_solver.cpp:105] Iteration 93750, lr = 0.001
I0618 22:07:26.764057  8058 solver.cpp:218] Iteration 93800 (0.865667 iter/s, 57.759s/50 iters), loss = 0.0112909
I0618 22:07:26.765254  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 22:07:26.765283  8058 solver.cpp:237]     Train net output #1: loss = 0.011291 (* 1 = 0.011291 loss)
I0618 22:07:26.765300  8058 sgd_solver.cpp:105] Iteration 93800, lr = 0.001
I0618 22:08:24.520550  8058 solver.cpp:218] Iteration 93850 (0.865729 iter/s, 57.7548s/50 iters), loss = 0.0109442
I0618 22:08:24.520676  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 22:08:24.520704  8058 solver.cpp:237]     Train net output #1: loss = 0.0109442 (* 1 = 0.0109442 loss)
I0618 22:08:24.520721  8058 sgd_solver.cpp:105] Iteration 93850, lr = 0.001
I0618 22:08:38.452498  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 22:09:22.290333  8058 solver.cpp:218] Iteration 93900 (0.865517 iter/s, 57.7689s/50 iters), loss = 0.0101167
I0618 22:09:22.290550  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 22:09:22.290583  8058 solver.cpp:237]     Train net output #1: loss = 0.0101168 (* 1 = 0.0101168 loss)
I0618 22:09:22.290601  8058 sgd_solver.cpp:105] Iteration 93900, lr = 0.001
I0618 22:10:20.107902  8058 solver.cpp:218] Iteration 93950 (0.864803 iter/s, 57.8166s/50 iters), loss = 0.0102004
I0618 22:10:20.108038  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 22:10:20.108067  8058 solver.cpp:237]     Train net output #1: loss = 0.0102005 (* 1 = 0.0102005 loss)
I0618 22:10:20.108085  8058 sgd_solver.cpp:105] Iteration 93950, lr = 0.001
I0618 22:10:56.037436  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 22:11:17.933696  8058 solver.cpp:218] Iteration 94000 (0.864679 iter/s, 57.8249s/50 iters), loss = 0.008871
I0618 22:11:17.933809  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 22:11:17.933835  8058 solver.cpp:237]     Train net output #1: loss = 0.00887104 (* 1 = 0.00887104 loss)
I0618 22:11:17.933853  8058 sgd_solver.cpp:105] Iteration 94000, lr = 0.001
I0618 22:12:15.750865  8058 solver.cpp:218] Iteration 94050 (0.864808 iter/s, 57.8163s/50 iters), loss = 0.0100205
I0618 22:12:15.751049  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 22:12:15.751077  8058 solver.cpp:237]     Train net output #1: loss = 0.0100206 (* 1 = 0.0100206 loss)
I0618 22:12:15.751094  8058 sgd_solver.cpp:105] Iteration 94050, lr = 0.001
I0618 22:13:13.577404  8058 solver.cpp:218] Iteration 94100 (0.864668 iter/s, 57.8256s/50 iters), loss = 0.00907549
I0618 22:13:13.577553  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 22:13:13.577584  8058 solver.cpp:237]     Train net output #1: loss = 0.00907553 (* 1 = 0.00907553 loss)
I0618 22:13:13.577601  8058 sgd_solver.cpp:105] Iteration 94100, lr = 0.001
I0618 22:13:14.810348  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 22:14:11.392380  8058 solver.cpp:218] Iteration 94150 (0.864841 iter/s, 57.8141s/50 iters), loss = 0.0106041
I0618 22:14:11.392544  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 22:14:11.392575  8058 solver.cpp:237]     Train net output #1: loss = 0.0106041 (* 1 = 0.0106041 loss)
I0618 22:14:11.392592  8058 sgd_solver.cpp:105] Iteration 94150, lr = 0.001
I0618 22:15:09.214386  8058 solver.cpp:218] Iteration 94200 (0.864736 iter/s, 57.8211s/50 iters), loss = 0.0107969
I0618 22:15:09.214537  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 22:15:09.214568  8058 solver.cpp:237]     Train net output #1: loss = 0.0107969 (* 1 = 0.0107969 loss)
I0618 22:15:09.214586  8058 sgd_solver.cpp:105] Iteration 94200, lr = 0.001
I0618 22:15:33.570497  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 22:16:07.032557  8058 solver.cpp:218] Iteration 94250 (0.864793 iter/s, 57.8173s/50 iters), loss = 0.00821608
I0618 22:16:07.032726  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 22:16:07.032753  8058 solver.cpp:237]     Train net output #1: loss = 0.00821612 (* 1 = 0.00821612 loss)
I0618 22:16:07.032773  8058 sgd_solver.cpp:105] Iteration 94250, lr = 0.001
I0618 22:17:04.848836  8058 solver.cpp:218] Iteration 94300 (0.864822 iter/s, 57.8154s/50 iters), loss = 0.00977096
I0618 22:17:04.849009  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 22:17:04.849038  8058 solver.cpp:237]     Train net output #1: loss = 0.009771 (* 1 = 0.009771 loss)
I0618 22:17:04.849059  8058 sgd_solver.cpp:105] Iteration 94300, lr = 0.001
I0618 22:17:52.366577  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 22:18:02.680876  8058 solver.cpp:218] Iteration 94350 (0.864586 iter/s, 57.8311s/50 iters), loss = 0.00970709
I0618 22:18:02.681001  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 22:18:02.681030  8058 solver.cpp:237]     Train net output #1: loss = 0.00970712 (* 1 = 0.00970712 loss)
I0618 22:18:02.681047  8058 sgd_solver.cpp:105] Iteration 94350, lr = 0.001
I0618 22:19:00.509361  8058 solver.cpp:218] Iteration 94400 (0.864639 iter/s, 57.8276s/50 iters), loss = 0.00893304
I0618 22:19:00.509594  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 22:19:00.509626  8058 solver.cpp:237]     Train net output #1: loss = 0.00893308 (* 1 = 0.00893308 loss)
I0618 22:19:00.509644  8058 sgd_solver.cpp:105] Iteration 94400, lr = 0.001
I0618 22:19:58.313091  8058 solver.cpp:218] Iteration 94450 (0.86501 iter/s, 57.8028s/50 iters), loss = 0.00958269
I0618 22:19:58.313258  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 22:19:58.313288  8058 solver.cpp:237]     Train net output #1: loss = 0.00958273 (* 1 = 0.00958273 loss)
I0618 22:19:58.313307  8058 sgd_solver.cpp:105] Iteration 94450, lr = 0.001
I0618 22:20:11.093695  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 22:20:56.099084  8058 solver.cpp:218] Iteration 94500 (0.865275 iter/s, 57.7851s/50 iters), loss = 0.00967247
I0618 22:20:56.099227  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 22:20:56.099265  8058 solver.cpp:237]     Train net output #1: loss = 0.0096725 (* 1 = 0.0096725 loss)
I0618 22:20:56.099292  8058 sgd_solver.cpp:105] Iteration 94500, lr = 0.001
I0618 22:21:53.872357  8058 solver.cpp:218] Iteration 94550 (0.865465 iter/s, 57.7724s/50 iters), loss = 0.00934057
I0618 22:21:53.872526  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 22:21:53.872560  8058 solver.cpp:237]     Train net output #1: loss = 0.0093406 (* 1 = 0.0093406 loss)
I0618 22:21:53.872576  8058 sgd_solver.cpp:105] Iteration 94550, lr = 0.001
I0618 22:22:29.779096  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 22:22:51.654696  8058 solver.cpp:218] Iteration 94600 (0.865329 iter/s, 57.7815s/50 iters), loss = 0.0114388
I0618 22:22:51.654781  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 22:22:51.654808  8058 solver.cpp:237]     Train net output #1: loss = 0.0114389 (* 1 = 0.0114389 loss)
I0618 22:22:51.654826  8058 sgd_solver.cpp:105] Iteration 94600, lr = 0.001
I0618 22:23:49.438071  8058 solver.cpp:218] Iteration 94650 (0.865313 iter/s, 57.7826s/50 iters), loss = 0.00916436
I0618 22:23:49.438192  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 22:23:49.438221  8058 solver.cpp:237]     Train net output #1: loss = 0.00916439 (* 1 = 0.00916439 loss)
I0618 22:23:49.438240  8058 sgd_solver.cpp:105] Iteration 94650, lr = 0.001
I0618 22:24:47.215102  8058 solver.cpp:218] Iteration 94700 (0.865408 iter/s, 57.7762s/50 iters), loss = 0.0123896
I0618 22:24:47.215240  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 22:24:47.215270  8058 solver.cpp:237]     Train net output #1: loss = 0.0123897 (* 1 = 0.0123897 loss)
I0618 22:24:47.215288  8058 sgd_solver.cpp:105] Iteration 94700, lr = 0.001
I0618 22:24:48.424368  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 22:25:44.994230  8058 solver.cpp:218] Iteration 94750 (0.865377 iter/s, 57.7783s/50 iters), loss = 0.0100699
I0618 22:25:44.994376  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 22:25:44.994407  8058 solver.cpp:237]     Train net output #1: loss = 0.01007 (* 1 = 0.01007 loss)
I0618 22:25:44.994426  8058 sgd_solver.cpp:105] Iteration 94750, lr = 0.001
I0618 22:26:42.775180  8058 solver.cpp:218] Iteration 94800 (0.86535 iter/s, 57.7801s/50 iters), loss = 0.0121416
I0618 22:26:42.775321  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 22:26:42.775351  8058 solver.cpp:237]     Train net output #1: loss = 0.0121416 (* 1 = 0.0121416 loss)
I0618 22:26:42.775368  8058 sgd_solver.cpp:105] Iteration 94800, lr = 0.001
I0618 22:27:07.084338  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 22:27:40.556527  8058 solver.cpp:218] Iteration 94850 (0.865344 iter/s, 57.7805s/50 iters), loss = 0.00858419
I0618 22:27:40.556646  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 22:27:40.556676  8058 solver.cpp:237]     Train net output #1: loss = 0.00858423 (* 1 = 0.00858423 loss)
I0618 22:27:40.556694  8058 sgd_solver.cpp:105] Iteration 94850, lr = 0.001
I0618 22:28:38.338631  8058 solver.cpp:218] Iteration 94900 (0.865332 iter/s, 57.7813s/50 iters), loss = 0.0101894
I0618 22:28:38.338806  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 22:28:38.338840  8058 solver.cpp:237]     Train net output #1: loss = 0.0101895 (* 1 = 0.0101895 loss)
I0618 22:28:38.338861  8058 sgd_solver.cpp:105] Iteration 94900, lr = 0.001
I0618 22:29:34.265897  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 22:29:51.675452  8058 solver.cpp:218] Iteration 94950 (0.681796 iter/s, 73.3358s/50 iters), loss = 0.0108224
I0618 22:29:51.675557  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 22:29:51.675587  8058 solver.cpp:237]     Train net output #1: loss = 0.0108225 (* 1 = 0.0108225 loss)
I0618 22:29:51.675606  8058 sgd_solver.cpp:105] Iteration 94950, lr = 0.001
I0618 22:31:19.461004  8058 solver.cpp:218] Iteration 95000 (0.569594 iter/s, 87.7818s/50 iters), loss = 0.0128244
I0618 22:31:19.461185  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 22:31:19.461215  8058 solver.cpp:237]     Train net output #1: loss = 0.0128245 (* 1 = 0.0128245 loss)
I0618 22:31:19.461235  8058 sgd_solver.cpp:105] Iteration 95000, lr = 0.001
I0618 22:32:47.273427  8058 solver.cpp:218] Iteration 95050 (0.56941 iter/s, 87.8102s/50 iters), loss = 0.0129556
I0618 22:32:47.273607  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 22:32:47.273638  8058 solver.cpp:237]     Train net output #1: loss = 0.0129556 (* 1 = 0.0129556 loss)
I0618 22:32:47.273655  8058 sgd_solver.cpp:105] Iteration 95050, lr = 0.001
I0618 22:33:04.876698  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 22:34:14.926297  8058 solver.cpp:218] Iteration 95100 (0.57044 iter/s, 87.6516s/50 iters), loss = 0.0112607
I0618 22:34:14.926447  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 22:34:14.926477  8058 solver.cpp:237]     Train net output #1: loss = 0.0112607 (* 1 = 0.0112607 loss)
I0618 22:34:14.926496  8058 sgd_solver.cpp:105] Iteration 95100, lr = 0.001
I0618 22:35:42.650776  8058 solver.cpp:218] Iteration 95150 (0.569975 iter/s, 87.7232s/50 iters), loss = 0.00983135
I0618 22:35:42.650955  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 22:35:42.650985  8058 solver.cpp:237]     Train net output #1: loss = 0.00983139 (* 1 = 0.00983139 loss)
I0618 22:35:42.651005  8058 sgd_solver.cpp:105] Iteration 95150, lr = 0.001
I0618 22:36:35.439855  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 22:37:10.425595  8058 solver.cpp:218] Iteration 95200 (0.569653 iter/s, 87.7727s/50 iters), loss = 0.00947607
I0618 22:37:10.425779  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 22:37:10.425809  8058 solver.cpp:237]     Train net output #1: loss = 0.0094761 (* 1 = 0.0094761 loss)
I0618 22:37:10.425827  8058 sgd_solver.cpp:105] Iteration 95200, lr = 0.001
I0618 22:38:36.884845  8058 solver.cpp:218] Iteration 95250 (0.578322 iter/s, 86.4571s/50 iters), loss = 0.0104729
I0618 22:38:36.885005  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 22:38:36.885035  8058 solver.cpp:237]     Train net output #1: loss = 0.010473 (* 1 = 0.010473 loss)
I0618 22:38:36.885054  8058 sgd_solver.cpp:105] Iteration 95250, lr = 0.001
I0618 22:39:43.895313  8058 solver.cpp:218] Iteration 95300 (0.746163 iter/s, 67.0095s/50 iters), loss = 0.0119773
I0618 22:39:43.895566  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 22:39:43.895597  8058 solver.cpp:237]     Train net output #1: loss = 0.0119773 (* 1 = 0.0119773 loss)
I0618 22:39:43.895615  8058 sgd_solver.cpp:105] Iteration 95300, lr = 0.001
I0618 22:39:44.016916  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 22:41:11.785729  8058 solver.cpp:218] Iteration 95350 (0.568904 iter/s, 87.8882s/50 iters), loss = 0.00932343
I0618 22:41:11.785903  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 22:41:11.785931  8058 solver.cpp:237]     Train net output #1: loss = 0.00932346 (* 1 = 0.00932346 loss)
I0618 22:41:11.785949  8058 sgd_solver.cpp:105] Iteration 95350, lr = 0.001
I0618 22:42:39.479640  8058 solver.cpp:218] Iteration 95400 (0.570173 iter/s, 87.6926s/50 iters), loss = 0.0109665
I0618 22:42:39.479826  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 22:42:39.479857  8058 solver.cpp:237]     Train net output #1: loss = 0.0109665 (* 1 = 0.0109665 loss)
I0618 22:42:39.479876  8058 sgd_solver.cpp:105] Iteration 95400, lr = 0.001
I0618 22:43:14.788027  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 22:44:07.361117  8058 solver.cpp:218] Iteration 95450 (0.568963 iter/s, 87.8792s/50 iters), loss = 0.0111076
I0618 22:44:07.361300  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 22:44:07.361330  8058 solver.cpp:237]     Train net output #1: loss = 0.0111077 (* 1 = 0.0111077 loss)
I0618 22:44:07.361348  8058 sgd_solver.cpp:105] Iteration 95450, lr = 0.001
I0618 22:45:34.961848  8058 solver.cpp:218] Iteration 95500 (0.570781 iter/s, 87.5993s/50 iters), loss = 0.00972067
I0618 22:45:34.961985  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 22:45:34.962023  8058 solver.cpp:237]     Train net output #1: loss = 0.0097207 (* 1 = 0.0097207 loss)
I0618 22:45:34.962056  8058 sgd_solver.cpp:105] Iteration 95500, lr = 0.001
I0618 22:46:45.188896  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 22:47:02.631222  8058 solver.cpp:218] Iteration 95550 (0.570352 iter/s, 87.6652s/50 iters), loss = 0.0118804
I0618 22:47:02.631331  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 22:47:02.631366  8058 solver.cpp:237]     Train net output #1: loss = 0.0118805 (* 1 = 0.0118805 loss)
I0618 22:47:02.631386  8058 sgd_solver.cpp:105] Iteration 95550, lr = 0.001
I0618 22:48:30.268384  8058 solver.cpp:218] Iteration 95600 (0.570549 iter/s, 87.6349s/50 iters), loss = 0.00987824
I0618 22:48:30.268509  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 22:48:30.268548  8058 solver.cpp:237]     Train net output #1: loss = 0.00987827 (* 1 = 0.00987827 loss)
I0618 22:48:30.268566  8058 sgd_solver.cpp:105] Iteration 95600, lr = 0.001
I0618 22:49:42.367396  8058 solver.cpp:218] Iteration 95650 (0.69351 iter/s, 72.097s/50 iters), loss = 0.0108676
I0618 22:49:42.367552  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 22:49:42.367583  8058 solver.cpp:237]     Train net output #1: loss = 0.0108676 (* 1 = 0.0108676 loss)
I0618 22:49:42.367600  8058 sgd_solver.cpp:105] Iteration 95650, lr = 0.001
I0618 22:49:57.726245  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 22:51:03.410027  8058 solver.cpp:218] Iteration 95700 (0.616969 iter/s, 81.0414s/50 iters), loss = 0.0117003
I0618 22:51:03.410205  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 22:51:03.410239  8058 solver.cpp:237]     Train net output #1: loss = 0.0117003 (* 1 = 0.0117003 loss)
I0618 22:51:03.410260  8058 sgd_solver.cpp:105] Iteration 95700, lr = 0.001
I0618 22:52:31.007470  8058 solver.cpp:218] Iteration 95750 (0.570808 iter/s, 87.5952s/50 iters), loss = 0.0126433
I0618 22:52:31.007602  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 22:52:31.007634  8058 solver.cpp:237]     Train net output #1: loss = 0.0126433 (* 1 = 0.0126433 loss)
I0618 22:52:31.007655  8058 sgd_solver.cpp:105] Iteration 95750, lr = 0.001
I0618 22:53:23.623744  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 22:53:58.574487  8058 solver.cpp:218] Iteration 95800 (0.571006 iter/s, 87.5647s/50 iters), loss = 0.0126463
I0618 22:53:58.574623  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 22:53:58.574651  8058 solver.cpp:237]     Train net output #1: loss = 0.0126463 (* 1 = 0.0126463 loss)
I0618 22:53:58.574669  8058 sgd_solver.cpp:105] Iteration 95800, lr = 0.001
I0618 22:55:26.124608  8058 solver.cpp:218] Iteration 95850 (0.57111 iter/s, 87.5487s/50 iters), loss = 0.0102444
I0618 22:55:26.124761  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 22:55:26.124791  8058 solver.cpp:237]     Train net output #1: loss = 0.0102444 (* 1 = 0.0102444 loss)
I0618 22:55:26.124809  8058 sgd_solver.cpp:105] Iteration 95850, lr = 0.001
I0618 22:56:52.199266  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 22:56:53.858922  8058 solver.cpp:218] Iteration 95900 (0.569914 iter/s, 87.7326s/50 iters), loss = 0.00970418
I0618 22:56:53.859005  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 22:56:53.859031  8058 solver.cpp:237]     Train net output #1: loss = 0.00970421 (* 1 = 0.00970421 loss)
I0618 22:56:53.859048  8058 sgd_solver.cpp:105] Iteration 95900, lr = 0.001
I0618 22:58:21.584905  8058 solver.cpp:218] Iteration 95950 (0.569971 iter/s, 87.7238s/50 iters), loss = 0.0111598
I0618 22:58:21.585075  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 22:58:21.585104  8058 solver.cpp:237]     Train net output #1: loss = 0.0111598 (* 1 = 0.0111598 loss)
I0618 22:58:21.585122  8058 sgd_solver.cpp:105] Iteration 95950, lr = 0.001
I0618 22:59:44.504573  8058 solver.cpp:218] Iteration 96000 (0.603002 iter/s, 82.9185s/50 iters), loss = 0.0108799
I0618 22:59:44.504690  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 22:59:44.504735  8058 solver.cpp:237]     Train net output #1: loss = 0.01088 (* 1 = 0.01088 loss)
I0618 22:59:44.504756  8058 sgd_solver.cpp:105] Iteration 96000, lr = 0.001
I0618 23:00:07.517032  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 23:00:54.833875  8058 solver.cpp:218] Iteration 96050 (0.710949 iter/s, 70.3285s/50 iters), loss = 0.009474
I0618 23:00:54.834025  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 23:00:54.834059  8058 solver.cpp:237]     Train net output #1: loss = 0.00947403 (* 1 = 0.00947403 loss)
I0618 23:00:54.834080  8058 sgd_solver.cpp:105] Iteration 96050, lr = 0.001
I0618 23:02:22.456333  8058 solver.cpp:218] Iteration 96100 (0.570636 iter/s, 87.6215s/50 iters), loss = 0.00926032
I0618 23:02:22.456482  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 23:02:22.456517  8058 solver.cpp:237]     Train net output #1: loss = 0.00926035 (* 1 = 0.00926035 loss)
I0618 23:02:22.456538  8058 sgd_solver.cpp:105] Iteration 96100, lr = 0.001
I0618 23:03:30.879124  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 23:03:50.038120  8058 solver.cpp:218] Iteration 96150 (0.570928 iter/s, 87.5768s/50 iters), loss = 0.00939977
I0618 23:03:50.038197  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 23:03:50.038228  8058 solver.cpp:237]     Train net output #1: loss = 0.0093998 (* 1 = 0.0093998 loss)
I0618 23:03:50.038249  8058 sgd_solver.cpp:105] Iteration 96150, lr = 0.001
I0618 23:05:17.618711  8058 solver.cpp:218] Iteration 96200 (0.570917 iter/s, 87.5785s/50 iters), loss = 0.0109288
I0618 23:05:17.618824  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 23:05:17.618852  8058 solver.cpp:237]     Train net output #1: loss = 0.0109288 (* 1 = 0.0109288 loss)
I0618 23:05:17.618870  8058 sgd_solver.cpp:105] Iteration 96200, lr = 0.001
I0618 23:06:45.197130  8058 solver.cpp:218] Iteration 96250 (0.570924 iter/s, 87.5773s/50 iters), loss = 0.0122297
I0618 23:06:45.197248  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 23:06:45.197276  8058 solver.cpp:237]     Train net output #1: loss = 0.0122298 (* 1 = 0.0122298 loss)
I0618 23:06:45.197293  8058 sgd_solver.cpp:105] Iteration 96250, lr = 0.001
I0618 23:07:01.315635  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 23:08:12.823819  8058 solver.cpp:218] Iteration 96300 (0.570624 iter/s, 87.6234s/50 iters), loss = 0.00915732
I0618 23:08:12.824012  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 23:08:12.824043  8058 solver.cpp:237]     Train net output #1: loss = 0.00915735 (* 1 = 0.00915735 loss)
I0618 23:08:12.824060  8058 sgd_solver.cpp:105] Iteration 96300, lr = 0.001
I0618 23:09:40.685534  8058 solver.cpp:218] Iteration 96350 (0.569089 iter/s, 87.8597s/50 iters), loss = 0.00961124
I0618 23:09:40.685683  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 23:09:40.685719  8058 solver.cpp:237]     Train net output #1: loss = 0.00961128 (* 1 = 0.00961128 loss)
I0618 23:09:40.685739  8058 sgd_solver.cpp:105] Iteration 96350, lr = 0.001
I0618 23:10:23.114048  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 23:10:52.390957  8058 solver.cpp:218] Iteration 96400 (0.697315 iter/s, 71.7036s/50 iters), loss = 0.0119067
I0618 23:10:52.391033  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 23:10:52.391058  8058 solver.cpp:237]     Train net output #1: loss = 0.0119068 (* 1 = 0.0119068 loss)
I0618 23:10:52.391075  8058 sgd_solver.cpp:105] Iteration 96400, lr = 0.001
I0618 23:12:13.972085  8058 solver.cpp:218] Iteration 96450 (0.61291 iter/s, 81.5781s/50 iters), loss = 0.0102826
I0618 23:12:13.972229  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 23:12:13.972257  8058 solver.cpp:237]     Train net output #1: loss = 0.0102827 (* 1 = 0.0102827 loss)
I0618 23:12:13.972275  8058 sgd_solver.cpp:105] Iteration 96450, lr = 0.001
I0618 23:13:39.891191  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 23:13:41.534261  8058 solver.cpp:218] Iteration 96500 (0.571045 iter/s, 87.5588s/50 iters), loss = 0.0103638
I0618 23:13:41.534355  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 23:13:41.534384  8058 solver.cpp:237]     Train net output #1: loss = 0.0103639 (* 1 = 0.0103639 loss)
I0618 23:13:41.534400  8058 sgd_solver.cpp:105] Iteration 96500, lr = 0.001
I0618 23:15:09.236166  8058 solver.cpp:218] Iteration 96550 (0.570138 iter/s, 87.6981s/50 iters), loss = 0.0101105
I0618 23:15:09.236322  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 23:15:09.236351  8058 solver.cpp:237]     Train net output #1: loss = 0.0101105 (* 1 = 0.0101105 loss)
I0618 23:15:09.236368  8058 sgd_solver.cpp:105] Iteration 96550, lr = 0.001
I0618 23:16:36.918800  8058 solver.cpp:218] Iteration 96600 (0.570251 iter/s, 87.6807s/50 iters), loss = 0.0105649
I0618 23:16:36.918949  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 23:16:36.918979  8058 solver.cpp:237]     Train net output #1: loss = 0.0105649 (* 1 = 0.0105649 loss)
I0618 23:16:36.918998  8058 sgd_solver.cpp:105] Iteration 96600, lr = 0.001
I0618 23:17:10.256719  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 23:18:04.497781  8058 solver.cpp:218] Iteration 96650 (0.570929 iter/s, 87.5766s/50 iters), loss = 0.0129815
I0618 23:18:04.497920  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 23:18:04.497947  8058 solver.cpp:237]     Train net output #1: loss = 0.0129815 (* 1 = 0.0129815 loss)
I0618 23:18:04.497966  8058 sgd_solver.cpp:105] Iteration 96650, lr = 0.001
I0618 23:19:32.008644  8058 solver.cpp:218] Iteration 96700 (0.571371 iter/s, 87.5089s/50 iters), loss = 0.0113829
I0618 23:19:32.008787  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 23:19:32.008817  8058 solver.cpp:237]     Train net output #1: loss = 0.011383 (* 1 = 0.011383 loss)
I0618 23:19:32.008836  8058 sgd_solver.cpp:105] Iteration 96700, lr = 0.001
I0618 23:20:39.349172  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 23:20:52.033263  8058 solver.cpp:218] Iteration 96750 (0.624816 iter/s, 80.0236s/50 iters), loss = 0.00716229
I0618 23:20:52.033388  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 23:20:52.033418  8058 solver.cpp:237]     Train net output #1: loss = 0.00716232 (* 1 = 0.00716232 loss)
I0618 23:20:52.033437  8058 sgd_solver.cpp:105] Iteration 96750, lr = 0.001
I0618 23:22:04.967922  8058 solver.cpp:218] Iteration 96800 (0.685553 iter/s, 72.9338s/50 iters), loss = 0.00957421
I0618 23:22:04.968130  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 23:22:04.968160  8058 solver.cpp:237]     Train net output #1: loss = 0.00957425 (* 1 = 0.00957425 loss)
I0618 23:22:04.968178  8058 sgd_solver.cpp:105] Iteration 96800, lr = 0.001
I0618 23:23:32.539788  8058 solver.cpp:218] Iteration 96850 (0.570967 iter/s, 87.5707s/50 iters), loss = 0.0104909
I0618 23:23:32.540009  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 23:23:32.540043  8058 solver.cpp:237]     Train net output #1: loss = 0.0104909 (* 1 = 0.0104909 loss)
I0618 23:23:32.540065  8058 sgd_solver.cpp:105] Iteration 96850, lr = 0.001
I0618 23:23:48.435902  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 23:25:00.199892  8058 solver.cpp:218] Iteration 96900 (0.570394 iter/s, 87.6587s/50 iters), loss = 0.00886717
I0618 23:25:00.200121  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 23:25:00.200156  8058 solver.cpp:237]     Train net output #1: loss = 0.00886721 (* 1 = 0.00886721 loss)
I0618 23:25:00.200177  8058 sgd_solver.cpp:105] Iteration 96900, lr = 0.001
I0618 23:26:27.953470  8058 solver.cpp:218] Iteration 96950 (0.56979 iter/s, 87.7516s/50 iters), loss = 0.0122991
I0618 23:26:27.953660  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 23:26:27.953696  8058 solver.cpp:237]     Train net output #1: loss = 0.0122991 (* 1 = 0.0122991 loss)
I0618 23:26:27.953716  8058 sgd_solver.cpp:105] Iteration 96950, lr = 0.001
I0618 23:27:17.137624  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 23:27:55.606053  8058 solver.cpp:218] Iteration 97000 (0.570447 iter/s, 87.6506s/50 iters), loss = 0.00994642
I0618 23:27:55.606206  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 23:27:55.606236  8058 solver.cpp:237]     Train net output #1: loss = 0.00994645 (* 1 = 0.00994645 loss)
I0618 23:27:55.606256  8058 sgd_solver.cpp:105] Iteration 97000, lr = 0.001
I0618 23:29:23.224900  8058 solver.cpp:218] Iteration 97050 (0.570667 iter/s, 87.6168s/50 iters), loss = 0.0108261
I0618 23:29:23.225020  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 23:29:23.225047  8058 solver.cpp:237]     Train net output #1: loss = 0.0108261 (* 1 = 0.0108261 loss)
I0618 23:29:23.225065  8058 sgd_solver.cpp:105] Iteration 97050, lr = 0.001
I0618 23:30:47.366489  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 23:30:50.826266  8058 solver.cpp:218] Iteration 97100 (0.570781 iter/s, 87.5993s/50 iters), loss = 0.00980873
I0618 23:30:50.826340  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 23:30:50.826367  8058 solver.cpp:237]     Train net output #1: loss = 0.00980876 (* 1 = 0.00980876 loss)
I0618 23:30:50.826385  8058 sgd_solver.cpp:105] Iteration 97100, lr = 0.001
I0618 23:32:01.705888  8058 solver.cpp:218] Iteration 97150 (0.705432 iter/s, 70.8786s/50 iters), loss = 0.0117573
I0618 23:32:01.706073  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 23:32:01.706107  8058 solver.cpp:237]     Train net output #1: loss = 0.0117573 (* 1 = 0.0117573 loss)
I0618 23:32:01.706125  8058 sgd_solver.cpp:105] Iteration 97150, lr = 0.001
I0618 23:33:24.204946  8058 solver.cpp:218] Iteration 97200 (0.606075 iter/s, 82.498s/50 iters), loss = 0.00917817
I0618 23:33:24.205199  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 23:33:24.205230  8058 solver.cpp:237]     Train net output #1: loss = 0.0091782 (* 1 = 0.0091782 loss)
I0618 23:33:24.205250  8058 sgd_solver.cpp:105] Iteration 97200, lr = 0.001
I0618 23:33:54.327219  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 23:34:31.232368  8058 solver.cpp:218] Iteration 97250 (0.745974 iter/s, 67.0265s/50 iters), loss = 0.0114306
I0618 23:34:31.232528  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 23:34:31.232558  8058 solver.cpp:237]     Train net output #1: loss = 0.0114306 (* 1 = 0.0114306 loss)
I0618 23:34:31.232576  8058 sgd_solver.cpp:105] Iteration 97250, lr = 0.001
I0618 23:35:29.006202  8058 solver.cpp:218] Iteration 97300 (0.865451 iter/s, 57.7733s/50 iters), loss = 0.0110698
I0618 23:35:29.006355  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 23:35:29.006387  8058 solver.cpp:237]     Train net output #1: loss = 0.0110699 (* 1 = 0.0110699 loss)
I0618 23:35:29.006408  8058 sgd_solver.cpp:105] Iteration 97300, lr = 0.001
I0618 23:36:12.995719  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 23:36:26.783061  8058 solver.cpp:218] Iteration 97350 (0.865405 iter/s, 57.7764s/50 iters), loss = 0.0126218
I0618 23:36:26.783146  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 23:36:26.783174  8058 solver.cpp:237]     Train net output #1: loss = 0.0126218 (* 1 = 0.0126218 loss)
I0618 23:36:26.783191  8058 sgd_solver.cpp:105] Iteration 97350, lr = 0.001
I0618 23:37:24.547315  8058 solver.cpp:218] Iteration 97400 (0.865593 iter/s, 57.7639s/50 iters), loss = 0.0105727
I0618 23:37:24.547435  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 23:37:24.547464  8058 solver.cpp:237]     Train net output #1: loss = 0.0105727 (* 1 = 0.0105727 loss)
I0618 23:37:24.547482  8058 sgd_solver.cpp:105] Iteration 97400, lr = 0.001
I0618 23:38:31.182157  8058 solver.cpp:218] Iteration 97450 (0.750364 iter/s, 66.6344s/50 iters), loss = 0.011293
I0618 23:38:31.182307  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 23:38:31.182335  8058 solver.cpp:237]     Train net output #1: loss = 0.011293 (* 1 = 0.011293 loss)
I0618 23:38:31.182353  8058 sgd_solver.cpp:105] Iteration 97450, lr = 0.001
I0618 23:38:45.250845  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 23:39:58.857264  8058 solver.cpp:218] Iteration 97500 (0.570298 iter/s, 87.6734s/50 iters), loss = 0.0114496
I0618 23:39:58.857501  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 23:39:58.857547  8058 solver.cpp:237]     Train net output #1: loss = 0.0114496 (* 1 = 0.0114496 loss)
I0618 23:39:58.857570  8058 sgd_solver.cpp:105] Iteration 97500, lr = 0.001
I0618 23:41:26.461319  8058 solver.cpp:218] Iteration 97550 (0.57076 iter/s, 87.6025s/50 iters), loss = 0.0111631
I0618 23:41:26.461473  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 23:41:26.461508  8058 solver.cpp:237]     Train net output #1: loss = 0.0111631 (* 1 = 0.0111631 loss)
I0618 23:41:26.461535  8058 sgd_solver.cpp:105] Iteration 97550, lr = 0.001
I0618 23:42:15.696157  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 23:42:54.057260  8058 solver.cpp:218] Iteration 97600 (0.570808 iter/s, 87.5952s/50 iters), loss = 0.00983685
I0618 23:42:54.057386  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 23:42:54.057420  8058 solver.cpp:237]     Train net output #1: loss = 0.00983689 (* 1 = 0.00983689 loss)
I0618 23:42:54.057440  8058 sgd_solver.cpp:105] Iteration 97600, lr = 0.001
I0618 23:44:21.766065  8058 solver.cpp:218] Iteration 97650 (0.57009 iter/s, 87.7055s/50 iters), loss = 0.0121006
I0618 23:44:21.766228  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 23:44:21.766263  8058 solver.cpp:237]     Train net output #1: loss = 0.0121007 (* 1 = 0.0121007 loss)
I0618 23:44:21.766284  8058 sgd_solver.cpp:105] Iteration 97650, lr = 0.001
I0618 23:45:46.056740  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 23:45:49.527163  8058 solver.cpp:218] Iteration 97700 (0.569739 iter/s, 87.7595s/50 iters), loss = 0.0135613
I0618 23:45:49.527245  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 23:45:49.527273  8058 solver.cpp:237]     Train net output #1: loss = 0.0135613 (* 1 = 0.0135613 loss)
I0618 23:45:49.527290  8058 sgd_solver.cpp:105] Iteration 97700, lr = 0.001
I0618 23:47:17.161197  8058 solver.cpp:218] Iteration 97750 (0.570565 iter/s, 87.6324s/50 iters), loss = 0.00886567
I0618 23:47:17.161391  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 23:47:17.161419  8058 solver.cpp:237]     Train net output #1: loss = 0.0088657 (* 1 = 0.0088657 loss)
I0618 23:47:17.161437  8058 sgd_solver.cpp:105] Iteration 97750, lr = 0.001
I0618 23:48:27.398380  8058 solver.cpp:218] Iteration 97800 (0.71189 iter/s, 70.2356s/50 iters), loss = 0.0120076
I0618 23:48:27.398532  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 23:48:27.398563  8058 solver.cpp:237]     Train net output #1: loss = 0.0120077 (* 1 = 0.0120077 loss)
I0618 23:48:27.398581  8058 sgd_solver.cpp:105] Iteration 97800, lr = 0.001
I0618 23:48:54.551468  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 23:49:50.552534  8058 solver.cpp:218] Iteration 97850 (0.601298 iter/s, 83.1535s/50 iters), loss = 0.01118
I0618 23:49:50.552798  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 23:49:50.552832  8058 solver.cpp:237]     Train net output #1: loss = 0.0111801 (* 1 = 0.0111801 loss)
I0618 23:49:50.552853  8058 sgd_solver.cpp:105] Iteration 97850, lr = 0.001
I0618 23:51:18.263279  8058 solver.cpp:218] Iteration 97900 (0.570062 iter/s, 87.7097s/50 iters), loss = 0.0119457
I0618 23:51:18.263442  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 23:51:18.263471  8058 solver.cpp:237]     Train net output #1: loss = 0.0119457 (* 1 = 0.0119457 loss)
I0618 23:51:18.263489  8058 sgd_solver.cpp:105] Iteration 97900, lr = 0.001
I0618 23:52:23.201885  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 23:52:45.847837  8058 solver.cpp:218] Iteration 97950 (0.57089 iter/s, 87.5825s/50 iters), loss = 0.0101013
I0618 23:52:45.847929  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 23:52:45.847970  8058 solver.cpp:237]     Train net output #1: loss = 0.0101013 (* 1 = 0.0101013 loss)
I0618 23:52:45.847988  8058 sgd_solver.cpp:105] Iteration 97950, lr = 0.001
I0618 23:54:13.378912  8058 solver.cpp:218] Iteration 98000 (0.571239 iter/s, 87.5291s/50 iters), loss = 0.00970184
I0618 23:54:13.379112  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 23:54:13.379140  8058 solver.cpp:237]     Train net output #1: loss = 0.00970188 (* 1 = 0.00970188 loss)
I0618 23:54:13.379158  8058 sgd_solver.cpp:105] Iteration 98000, lr = 0.001
I0618 23:55:40.995959  8058 solver.cpp:218] Iteration 98050 (0.570679 iter/s, 87.615s/50 iters), loss = 0.00942869
I0618 23:55:40.996085  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 23:55:40.996114  8058 solver.cpp:237]     Train net output #1: loss = 0.00942872 (* 1 = 0.00942872 loss)
I0618 23:55:40.996131  8058 sgd_solver.cpp:105] Iteration 98050, lr = 0.001
I0618 23:55:53.381896  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 23:57:08.607771  8058 solver.cpp:218] Iteration 98100 (0.570712 iter/s, 87.6098s/50 iters), loss = 0.0110464
I0618 23:57:08.607944  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 23:57:08.607975  8058 solver.cpp:237]     Train net output #1: loss = 0.0110464 (* 1 = 0.0110464 loss)
I0618 23:57:08.607991  8058 sgd_solver.cpp:105] Iteration 98100, lr = 0.001
I0618 23:58:25.634220  8058 solver.cpp:218] Iteration 98150 (0.649137 iter/s, 77.0253s/50 iters), loss = 0.0129224
I0618 23:58:25.634358  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 23:58:25.634387  8058 solver.cpp:237]     Train net output #1: loss = 0.0129224 (* 1 = 0.0129224 loss)
I0618 23:58:25.634403  8058 sgd_solver.cpp:105] Iteration 98150, lr = 0.001
I0618 23:59:03.528694  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0618 23:59:41.790648  8058 solver.cpp:218] Iteration 98200 (0.656551 iter/s, 76.1555s/50 iters), loss = 0.0116097
I0618 23:59:41.799597  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0618 23:59:41.799631  8058 solver.cpp:237]     Train net output #1: loss = 0.0116097 (* 1 = 0.0116097 loss)
I0618 23:59:41.799652  8058 sgd_solver.cpp:105] Iteration 98200, lr = 0.001
I0619 00:01:09.491875  8058 solver.cpp:218] Iteration 98250 (0.570186 iter/s, 87.6908s/50 iters), loss = 0.0102698
I0619 00:01:09.492017  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 00:01:09.492044  8058 solver.cpp:237]     Train net output #1: loss = 0.0102699 (* 1 = 0.0102699 loss)
I0619 00:01:09.492063  8058 sgd_solver.cpp:105] Iteration 98250, lr = 0.001
I0619 00:02:32.028059  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 00:02:37.133615  8058 solver.cpp:218] Iteration 98300 (0.570512 iter/s, 87.6405s/50 iters), loss = 0.0121761
I0619 00:02:37.133684  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 00:02:37.133710  8058 solver.cpp:237]     Train net output #1: loss = 0.0121761 (* 1 = 0.0121761 loss)
I0619 00:02:37.133728  8058 sgd_solver.cpp:105] Iteration 98300, lr = 0.001
I0619 00:04:04.757830  8058 solver.cpp:218] Iteration 98350 (0.570626 iter/s, 87.623s/50 iters), loss = 0.0103664
I0619 00:04:04.758077  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 00:04:04.758110  8058 solver.cpp:237]     Train net output #1: loss = 0.0103664 (* 1 = 0.0103664 loss)
I0619 00:04:04.758128  8058 sgd_solver.cpp:105] Iteration 98350, lr = 0.001
I0619 00:05:32.409958  8058 solver.cpp:218] Iteration 98400 (0.57045 iter/s, 87.65s/50 iters), loss = 0.00912939
I0619 00:05:32.410114  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 00:05:32.410145  8058 solver.cpp:237]     Train net output #1: loss = 0.00912942 (* 1 = 0.00912942 loss)
I0619 00:05:32.410162  8058 sgd_solver.cpp:105] Iteration 98400, lr = 0.001
I0619 00:06:02.337460  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 00:06:45.856590  8058 solver.cpp:218] Iteration 98450 (0.680784 iter/s, 73.4447s/50 iters), loss = 0.012502
I0619 00:06:45.856750  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 00:06:45.856784  8058 solver.cpp:237]     Train net output #1: loss = 0.012502 (* 1 = 0.012502 loss)
I0619 00:06:45.856806  8058 sgd_solver.cpp:105] Iteration 98450, lr = 0.001
I0619 00:07:43.630501  8058 solver.cpp:218] Iteration 98500 (0.865454 iter/s, 57.7731s/50 iters), loss = 0.00992311
I0619 00:07:43.630645  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 00:07:43.630674  8058 solver.cpp:237]     Train net output #1: loss = 0.00992314 (* 1 = 0.00992314 loss)
I0619 00:07:43.630692  8058 sgd_solver.cpp:105] Iteration 98500, lr = 0.001
I0619 00:08:26.439888  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 00:08:41.399660  8058 solver.cpp:218] Iteration 98550 (0.865525 iter/s, 57.7684s/50 iters), loss = 0.0103401
I0619 00:08:41.399756  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 00:08:41.399783  8058 solver.cpp:237]     Train net output #1: loss = 0.0103402 (* 1 = 0.0103402 loss)
I0619 00:08:41.399801  8058 sgd_solver.cpp:105] Iteration 98550, lr = 0.001
I0619 00:09:50.262660  8058 solver.cpp:218] Iteration 98600 (0.726088 iter/s, 68.8622s/50 iters), loss = 0.0101308
I0619 00:09:50.262853  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 00:09:50.262888  8058 solver.cpp:237]     Train net output #1: loss = 0.0101308 (* 1 = 0.0101308 loss)
I0619 00:09:50.262909  8058 sgd_solver.cpp:105] Iteration 98600, lr = 0.001
I0619 00:11:18.134385  8058 solver.cpp:218] Iteration 98650 (0.569019 iter/s, 87.8706s/50 iters), loss = 0.0104828
I0619 00:11:18.134542  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 00:11:18.134573  8058 solver.cpp:237]     Train net output #1: loss = 0.0104829 (* 1 = 0.0104829 loss)
I0619 00:11:18.134598  8058 sgd_solver.cpp:105] Iteration 98650, lr = 0.001
I0619 00:11:30.531069  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 00:12:45.864018  8058 solver.cpp:218] Iteration 98700 (0.569948 iter/s, 87.7272s/50 iters), loss = 0.0113803
I0619 00:12:45.864169  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 00:12:45.864199  8058 solver.cpp:237]     Train net output #1: loss = 0.0113803 (* 1 = 0.0113803 loss)
I0619 00:12:45.864217  8058 sgd_solver.cpp:105] Iteration 98700, lr = 0.001
I0619 00:14:13.649940  8058 solver.cpp:218] Iteration 98750 (0.569575 iter/s, 87.7848s/50 iters), loss = 0.0110543
I0619 00:14:13.650127  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 00:14:13.650157  8058 solver.cpp:237]     Train net output #1: loss = 0.0110543 (* 1 = 0.0110543 loss)
I0619 00:14:13.650176  8058 sgd_solver.cpp:105] Iteration 98750, lr = 0.001
I0619 00:15:01.173460  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 00:15:41.451601  8058 solver.cpp:218] Iteration 98800 (0.569479 iter/s, 87.7996s/50 iters), loss = 0.0102707
I0619 00:15:41.451783  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 00:15:41.451813  8058 solver.cpp:237]     Train net output #1: loss = 0.0102707 (* 1 = 0.0102707 loss)
I0619 00:15:41.451833  8058 sgd_solver.cpp:105] Iteration 98800, lr = 0.001
I0619 00:17:09.266096  8058 solver.cpp:218] Iteration 98850 (0.56939 iter/s, 87.8133s/50 iters), loss = 0.0112627
I0619 00:17:09.266284  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 00:17:09.266316  8058 solver.cpp:237]     Train net output #1: loss = 0.0112627 (* 1 = 0.0112627 loss)
I0619 00:17:09.266337  8058 sgd_solver.cpp:105] Iteration 98850, lr = 0.001
I0619 00:18:30.119627  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 00:18:37.039582  8058 solver.cpp:218] Iteration 98900 (0.569661 iter/s, 87.7715s/50 iters), loss = 0.00990533
I0619 00:18:37.039685  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 00:18:37.039719  8058 solver.cpp:237]     Train net output #1: loss = 0.00990537 (* 1 = 0.00990537 loss)
I0619 00:18:37.039741  8058 sgd_solver.cpp:105] Iteration 98900, lr = 0.001
I0619 00:19:44.675820  8058 solver.cpp:218] Iteration 98950 (0.739258 iter/s, 67.6354s/50 iters), loss = 0.0103109
I0619 00:19:44.675982  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 00:19:44.676012  8058 solver.cpp:237]     Train net output #1: loss = 0.0103109 (* 1 = 0.0103109 loss)
I0619 00:19:44.676029  8058 sgd_solver.cpp:105] Iteration 98950, lr = 0.001
I0619 00:21:12.447005  8058 solver.cpp:218] Iteration 99000 (0.56967 iter/s, 87.7701s/50 iters), loss = 0.00916539
I0619 00:21:12.447161  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 00:21:12.447203  8058 solver.cpp:237]     Train net output #1: loss = 0.00916542 (* 1 = 0.00916542 loss)
I0619 00:21:12.447227  8058 sgd_solver.cpp:105] Iteration 99000, lr = 0.001
I0619 00:21:40.683737  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 00:22:40.173146  8058 solver.cpp:218] Iteration 99050 (0.569969 iter/s, 87.7241s/50 iters), loss = 0.0103229
I0619 00:22:40.173337  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 00:22:40.173374  8058 solver.cpp:237]     Train net output #1: loss = 0.010323 (* 1 = 0.010323 loss)
I0619 00:22:40.173396  8058 sgd_solver.cpp:105] Iteration 99050, lr = 0.001
I0619 00:24:07.957775  8058 solver.cpp:218] Iteration 99100 (0.569589 iter/s, 87.7826s/50 iters), loss = 0.0105079
I0619 00:24:07.964284  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 00:24:07.964318  8058 solver.cpp:237]     Train net output #1: loss = 0.0105079 (* 1 = 0.0105079 loss)
I0619 00:24:07.964335  8058 sgd_solver.cpp:105] Iteration 99100, lr = 0.001
I0619 00:25:11.279863  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 00:25:35.719804  8058 solver.cpp:218] Iteration 99150 (0.569771 iter/s, 87.7545s/50 iters), loss = 0.0125839
I0619 00:25:35.719908  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 00:25:35.719941  8058 solver.cpp:237]     Train net output #1: loss = 0.012584 (* 1 = 0.012584 loss)
I0619 00:25:35.719969  8058 sgd_solver.cpp:105] Iteration 99150, lr = 0.001
I0619 00:27:03.325942  8058 solver.cpp:218] Iteration 99200 (0.570749 iter/s, 87.6042s/50 iters), loss = 0.0119913
I0619 00:27:03.327249  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 00:27:03.327280  8058 solver.cpp:237]     Train net output #1: loss = 0.0119914 (* 1 = 0.0119914 loss)
I0619 00:27:03.327298  8058 sgd_solver.cpp:105] Iteration 99200, lr = 0.001
I0619 00:28:30.972895  8058 solver.cpp:218] Iteration 99250 (0.570485 iter/s, 87.6447s/50 iters), loss = 0.0116353
I0619 00:28:30.973042  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 00:28:30.973070  8058 solver.cpp:237]     Train net output #1: loss = 0.0116353 (* 1 = 0.0116353 loss)
I0619 00:28:30.973088  8058 sgd_solver.cpp:105] Iteration 99250, lr = 0.001
I0619 00:28:41.654666  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 00:29:44.933568  8058 solver.cpp:218] Iteration 99300 (0.676046 iter/s, 73.9594s/50 iters), loss = 0.00926572
I0619 00:29:44.933768  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 00:29:44.933799  8058 solver.cpp:237]     Train net output #1: loss = 0.00926575 (* 1 = 0.00926575 loss)
I0619 00:29:44.933817  8058 sgd_solver.cpp:105] Iteration 99300, lr = 0.001
I0619 00:31:06.003262  8058 solver.cpp:218] Iteration 99350 (0.616778 iter/s, 81.0664s/50 iters), loss = 0.00886082
I0619 00:31:06.003399  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 00:31:06.003427  8058 solver.cpp:237]     Train net output #1: loss = 0.00886085 (* 1 = 0.00886085 loss)
I0619 00:31:06.003445  8058 sgd_solver.cpp:105] Iteration 99350, lr = 0.001
I0619 00:31:51.624325  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 00:32:33.682098  8058 solver.cpp:218] Iteration 99400 (0.570276 iter/s, 87.6769s/50 iters), loss = 0.0108091
I0619 00:32:33.682210  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 00:32:33.682240  8058 solver.cpp:237]     Train net output #1: loss = 0.0108091 (* 1 = 0.0108091 loss)
I0619 00:32:33.682256  8058 sgd_solver.cpp:105] Iteration 99400, lr = 0.001
I0619 00:34:01.298494  8058 solver.cpp:218] Iteration 99450 (0.570677 iter/s, 87.6152s/50 iters), loss = 0.0100863
I0619 00:34:01.298682  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 00:34:01.298715  8058 solver.cpp:237]     Train net output #1: loss = 0.0100863 (* 1 = 0.0100863 loss)
I0619 00:34:01.298735  8058 sgd_solver.cpp:105] Iteration 99450, lr = 0.001
I0619 00:35:22.058579  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 00:35:28.880954  8058 solver.cpp:218] Iteration 99500 (0.570904 iter/s, 87.5804s/50 iters), loss = 0.0101493
I0619 00:35:28.881037  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 00:35:28.881063  8058 solver.cpp:237]     Train net output #1: loss = 0.0101493 (* 1 = 0.0101493 loss)
I0619 00:35:28.881080  8058 sgd_solver.cpp:105] Iteration 99500, lr = 0.001
I0619 00:36:56.575597  8058 solver.cpp:218] Iteration 99550 (0.570174 iter/s, 87.6926s/50 iters), loss = 0.0107541
I0619 00:36:56.575729  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 00:36:56.575757  8058 solver.cpp:237]     Train net output #1: loss = 0.0107541 (* 1 = 0.0107541 loss)
I0619 00:36:56.575775  8058 sgd_solver.cpp:105] Iteration 99550, lr = 0.001
I0619 00:38:24.337136  8058 solver.cpp:218] Iteration 99600 (0.569742 iter/s, 87.759s/50 iters), loss = 0.0104481
I0619 00:38:24.337290  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 00:38:24.337321  8058 solver.cpp:237]     Train net output #1: loss = 0.0104481 (* 1 = 0.0104481 loss)
I0619 00:38:24.337342  8058 sgd_solver.cpp:105] Iteration 99600, lr = 0.001
I0619 00:38:52.419613  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 00:39:47.254797  8058 solver.cpp:218] Iteration 99650 (0.603015 iter/s, 82.9166s/50 iters), loss = 0.0116373
I0619 00:39:47.254943  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 00:39:47.254972  8058 solver.cpp:237]     Train net output #1: loss = 0.0116373 (* 1 = 0.0116373 loss)
I0619 00:39:47.254989  8058 sgd_solver.cpp:105] Iteration 99650, lr = 0.001
I0619 00:40:59.524241  8058 solver.cpp:218] Iteration 99700 (0.691864 iter/s, 72.2686s/50 iters), loss = 0.0107063
I0619 00:40:59.524395  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 00:40:59.524425  8058 solver.cpp:237]     Train net output #1: loss = 0.0107063 (* 1 = 0.0107063 loss)
I0619 00:40:59.524447  8058 sgd_solver.cpp:105] Iteration 99700, lr = 0.001
I0619 00:42:02.821116  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 00:42:27.265430  8058 solver.cpp:218] Iteration 99750 (0.569871 iter/s, 87.7391s/50 iters), loss = 0.0120568
I0619 00:42:27.265522  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 00:42:27.265552  8058 solver.cpp:237]     Train net output #1: loss = 0.0120569 (* 1 = 0.0120569 loss)
I0619 00:42:27.265568  8058 sgd_solver.cpp:105] Iteration 99750, lr = 0.001
I0619 00:43:54.933089  8058 solver.cpp:218] Iteration 99800 (0.570349 iter/s, 87.6656s/50 iters), loss = 0.00986505
I0619 00:43:54.933292  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 00:43:54.933324  8058 solver.cpp:237]     Train net output #1: loss = 0.00986508 (* 1 = 0.00986508 loss)
I0619 00:43:54.933342  8058 sgd_solver.cpp:105] Iteration 99800, lr = 0.001
I0619 00:45:22.555392  8058 solver.cpp:218] Iteration 99850 (0.570644 iter/s, 87.6203s/50 iters), loss = 0.00897944
I0619 00:45:22.555588  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 00:45:22.555618  8058 solver.cpp:237]     Train net output #1: loss = 0.00897947 (* 1 = 0.00897947 loss)
I0619 00:45:22.555635  8058 sgd_solver.cpp:105] Iteration 99850, lr = 0.001
I0619 00:45:33.168716  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 00:46:50.230664  8058 solver.cpp:218] Iteration 99900 (0.5703 iter/s, 87.6732s/50 iters), loss = 0.0115484
I0619 00:46:50.230839  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 00:46:50.230871  8058 solver.cpp:237]     Train net output #1: loss = 0.0115485 (* 1 = 0.0115485 loss)
I0619 00:46:50.230902  8058 sgd_solver.cpp:105] Iteration 99900, lr = 0.001
I0619 00:48:17.783095  8058 solver.cpp:218] Iteration 99950 (0.571094 iter/s, 87.5512s/50 iters), loss = 0.0116868
I0619 00:48:17.783218  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 00:48:17.783246  8058 solver.cpp:237]     Train net output #1: loss = 0.0116869 (* 1 = 0.0116869 loss)
I0619 00:48:17.783263  8058 sgd_solver.cpp:105] Iteration 99950, lr = 0.001
I0619 00:49:01.764703  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 00:49:43.839217  8058 solver.cpp:447] Snapshotting to binary proto file mobilenet/mobile_cub_iter_100000.caffemodel
I0619 00:49:43.922924  8058 sgd_solver.cpp:273] Snapshotting solver state to binary proto file mobilenet/mobile_cub_iter_100000.solverstate
I0619 00:49:45.706738  8058 solver.cpp:218] Iteration 100000 (0.568683 iter/s, 87.9224s/50 iters), loss = 0.0109241
I0619 00:49:45.706827  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 00:49:45.706859  8058 solver.cpp:237]     Train net output #1: loss = 0.0109242 (* 1 = 0.0109242 loss)
I0619 00:49:45.706881  8058 sgd_solver.cpp:105] Iteration 100000, lr = 0.0001
I0619 00:50:56.420969  8058 solver.cpp:218] Iteration 100050 (0.70709 iter/s, 70.7124s/50 iters), loss = 0.0104344
I0619 00:50:56.421113  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 00:50:56.421141  8058 solver.cpp:237]     Train net output #1: loss = 0.0104344 (* 1 = 0.0104344 loss)
I0619 00:50:56.421159  8058 sgd_solver.cpp:105] Iteration 100050, lr = 0.0001
I0619 00:52:11.910274  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 00:52:20.569537  8058 solver.cpp:218] Iteration 100100 (0.594194 iter/s, 84.1476s/50 iters), loss = 0.00952809
I0619 00:52:20.569644  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 00:52:20.569672  8058 solver.cpp:237]     Train net output #1: loss = 0.00952812 (* 1 = 0.00952812 loss)
I0619 00:52:20.569689  8058 sgd_solver.cpp:105] Iteration 100100, lr = 0.0001
I0619 00:53:48.201761  8058 solver.cpp:218] Iteration 100150 (0.570584 iter/s, 87.6295s/50 iters), loss = 0.0139357
I0619 00:53:48.201946  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 00:53:48.201978  8058 solver.cpp:237]     Train net output #1: loss = 0.0139357 (* 1 = 0.0139357 loss)
I0619 00:53:48.201998  8058 sgd_solver.cpp:105] Iteration 100150, lr = 0.0001
I0619 00:55:15.869547  8058 solver.cpp:218] Iteration 100200 (0.570348 iter/s, 87.6657s/50 iters), loss = 0.0125548
I0619 00:55:15.869719  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 00:55:15.869751  8058 solver.cpp:237]     Train net output #1: loss = 0.0125548 (* 1 = 0.0125548 loss)
I0619 00:55:15.869768  8058 sgd_solver.cpp:105] Iteration 100200, lr = 0.0001
I0619 00:55:42.261553  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 00:56:43.534447  8058 solver.cpp:218] Iteration 100250 (0.570367 iter/s, 87.6629s/50 iters), loss = 0.0114004
I0619 00:56:43.534633  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 00:56:43.534663  8058 solver.cpp:237]     Train net output #1: loss = 0.0114004 (* 1 = 0.0114004 loss)
I0619 00:56:43.534682  8058 sgd_solver.cpp:105] Iteration 100250, lr = 0.0001
I0619 00:58:11.080425  8058 solver.cpp:218] Iteration 100300 (0.571142 iter/s, 87.5439s/50 iters), loss = 0.0102808
I0619 00:58:11.080565  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 00:58:11.080598  8058 solver.cpp:237]     Train net output #1: loss = 0.0102808 (* 1 = 0.0102808 loss)
I0619 00:58:11.080621  8058 sgd_solver.cpp:105] Iteration 100300, lr = 0.0001
I0619 00:59:12.440754  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 00:59:38.631877  8058 solver.cpp:218] Iteration 100350 (0.571103 iter/s, 87.5499s/50 iters), loss = 0.00878373
I0619 00:59:38.631964  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 00:59:38.631992  8058 solver.cpp:237]     Train net output #1: loss = 0.00878376 (* 1 = 0.00878376 loss)
I0619 00:59:38.632024  8058 sgd_solver.cpp:105] Iteration 100350, lr = 0.0001
I0619 01:00:54.656711  8058 solver.cpp:218] Iteration 100400 (0.657697 iter/s, 76.0229s/50 iters), loss = 0.0106697
I0619 01:00:54.656837  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 01:00:54.656870  8058 solver.cpp:237]     Train net output #1: loss = 0.0106698 (* 1 = 0.0106698 loss)
I0619 01:00:54.656891  8058 sgd_solver.cpp:105] Iteration 100400, lr = 0.0001
I0619 01:02:13.552189  8058 solver.cpp:218] Iteration 100450 (0.633757 iter/s, 78.8945s/50 iters), loss = 0.0108313
I0619 01:02:13.552317  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 01:02:13.552347  8058 solver.cpp:237]     Train net output #1: loss = 0.0108314 (* 1 = 0.0108314 loss)
I0619 01:02:13.552364  8058 sgd_solver.cpp:105] Iteration 100450, lr = 0.0001
I0619 01:02:22.397035  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 01:03:41.217581  8058 solver.cpp:218] Iteration 100500 (0.570357 iter/s, 87.6643s/50 iters), loss = 0.0106087
I0619 01:03:41.217924  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 01:03:41.217954  8058 solver.cpp:237]     Train net output #1: loss = 0.0106088 (* 1 = 0.0106088 loss)
I0619 01:03:41.217970  8058 sgd_solver.cpp:105] Iteration 100500, lr = 0.0001
I0619 01:05:08.882570  8058 solver.cpp:218] Iteration 100550 (0.570362 iter/s, 87.6636s/50 iters), loss = 0.00851804
I0619 01:05:08.882747  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 01:05:08.882781  8058 solver.cpp:237]     Train net output #1: loss = 0.00851807 (* 1 = 0.00851807 loss)
I0619 01:05:08.882802  8058 sgd_solver.cpp:105] Iteration 100550, lr = 0.0001
I0619 01:05:52.792829  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 01:06:36.529122  8058 solver.cpp:218] Iteration 100600 (0.570487 iter/s, 87.6445s/50 iters), loss = 0.0108878
I0619 01:06:36.529278  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 01:06:36.529314  8058 solver.cpp:237]     Train net output #1: loss = 0.0108878 (* 1 = 0.0108878 loss)
I0619 01:06:36.529333  8058 sgd_solver.cpp:105] Iteration 100600, lr = 0.0001
I0619 01:08:04.217382  8058 solver.cpp:218] Iteration 100650 (0.570215 iter/s, 87.6862s/50 iters), loss = 0.0102278
I0619 01:08:04.217545  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 01:08:04.217579  8058 solver.cpp:237]     Train net output #1: loss = 0.0102279 (* 1 = 0.0102279 loss)
I0619 01:08:04.217602  8058 sgd_solver.cpp:105] Iteration 100650, lr = 0.0001
I0619 01:09:23.101512  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 01:09:31.783114  8058 solver.cpp:218] Iteration 100700 (0.571007 iter/s, 87.5645s/50 iters), loss = 0.0117549
I0619 01:09:31.783203  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 01:09:31.783229  8058 solver.cpp:237]     Train net output #1: loss = 0.0117549 (* 1 = 0.0117549 loss)
I0619 01:09:31.783246  8058 sgd_solver.cpp:105] Iteration 100700, lr = 0.0001
I0619 01:10:59.360270  8058 solver.cpp:218] Iteration 100750 (0.570932 iter/s, 87.5761s/50 iters), loss = 0.0102615
I0619 01:10:59.360487  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 01:10:59.360523  8058 solver.cpp:237]     Train net output #1: loss = 0.0102615 (* 1 = 0.0102615 loss)
I0619 01:10:59.360543  8058 sgd_solver.cpp:105] Iteration 100750, lr = 0.0001
I0619 01:12:06.733745  8058 solver.cpp:218] Iteration 100800 (0.742143 iter/s, 67.3725s/50 iters), loss = 0.0118604
I0619 01:12:06.733871  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 01:12:06.733901  8058 solver.cpp:237]     Train net output #1: loss = 0.0118604 (* 1 = 0.0118604 loss)
I0619 01:12:06.733916  8058 sgd_solver.cpp:105] Iteration 100800, lr = 0.0001
I0619 01:12:33.114802  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 01:13:34.444840  8058 solver.cpp:218] Iteration 100850 (0.570063 iter/s, 87.7096s/50 iters), loss = 0.0112315
I0619 01:13:34.445025  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 01:13:34.445067  8058 solver.cpp:237]     Train net output #1: loss = 0.0112315 (* 1 = 0.0112315 loss)
I0619 01:13:34.445086  8058 sgd_solver.cpp:105] Iteration 100850, lr = 0.0001
I0619 01:15:02.057118  8058 solver.cpp:218] Iteration 100900 (0.57071 iter/s, 87.6102s/50 iters), loss = 0.010812
I0619 01:15:02.057235  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 01:15:02.057265  8058 solver.cpp:237]     Train net output #1: loss = 0.010812 (* 1 = 0.010812 loss)
I0619 01:15:02.057281  8058 sgd_solver.cpp:105] Iteration 100900, lr = 0.0001
I0619 01:16:01.762421  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 01:16:29.766446  8058 solver.cpp:218] Iteration 100950 (0.570072 iter/s, 87.7082s/50 iters), loss = 0.0113923
I0619 01:16:29.766546  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 01:16:29.766579  8058 solver.cpp:237]     Train net output #1: loss = 0.0113923 (* 1 = 0.0113923 loss)
I0619 01:16:29.766600  8058 sgd_solver.cpp:105] Iteration 100950, lr = 0.0001
I0619 01:17:57.367538  8058 solver.cpp:218] Iteration 101000 (0.57078 iter/s, 87.5994s/50 iters), loss = 0.00907114
I0619 01:17:57.367657  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 01:17:57.367686  8058 solver.cpp:237]     Train net output #1: loss = 0.00907117 (* 1 = 0.00907117 loss)
I0619 01:17:57.367702  8058 sgd_solver.cpp:105] Iteration 101000, lr = 0.0001
I0619 01:19:25.047827  8058 solver.cpp:218] Iteration 101050 (0.570264 iter/s, 87.6786s/50 iters), loss = 0.0118654
I0619 01:19:25.047953  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 01:19:25.047981  8058 solver.cpp:237]     Train net output #1: loss = 0.0118654 (* 1 = 0.0118654 loss)
I0619 01:19:25.047998  8058 sgd_solver.cpp:105] Iteration 101050, lr = 0.0001
I0619 01:19:32.165871  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 01:20:52.767858  8058 solver.cpp:218] Iteration 101100 (0.570006 iter/s, 87.7183s/50 iters), loss = 0.0112263
I0619 01:20:52.772745  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 01:20:52.772776  8058 solver.cpp:237]     Train net output #1: loss = 0.0112263 (* 1 = 0.0112263 loss)
I0619 01:20:52.772792  8058 sgd_solver.cpp:105] Iteration 101100, lr = 0.0001
I0619 01:22:06.554952  8058 solver.cpp:218] Iteration 101150 (0.677677 iter/s, 73.7814s/50 iters), loss = 0.00931163
I0619 01:22:06.555094  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 01:22:06.555122  8058 solver.cpp:237]     Train net output #1: loss = 0.00931166 (* 1 = 0.00931166 loss)
I0619 01:22:06.555140  8058 sgd_solver.cpp:105] Iteration 101150, lr = 0.0001
I0619 01:22:42.343598  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 01:23:27.778851  8058 solver.cpp:218] Iteration 101200 (0.61559 iter/s, 81.2229s/50 iters), loss = 0.0121892
I0619 01:23:27.779036  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 01:23:27.779067  8058 solver.cpp:237]     Train net output #1: loss = 0.0121893 (* 1 = 0.0121893 loss)
I0619 01:23:27.779086  8058 sgd_solver.cpp:105] Iteration 101200, lr = 0.0001
I0619 01:24:55.590261  8058 solver.cpp:218] Iteration 101250 (0.569407 iter/s, 87.8106s/50 iters), loss = 0.0120179
I0619 01:24:55.590443  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 01:24:55.590472  8058 solver.cpp:237]     Train net output #1: loss = 0.0120179 (* 1 = 0.0120179 loss)
I0619 01:24:55.590489  8058 sgd_solver.cpp:105] Iteration 101250, lr = 0.0001
I0619 01:26:12.683416  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 01:26:23.139612  8058 solver.cpp:218] Iteration 101300 (0.571118 iter/s, 87.5476s/50 iters), loss = 0.00976398
I0619 01:26:23.139691  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 01:26:23.139719  8058 solver.cpp:237]     Train net output #1: loss = 0.00976401 (* 1 = 0.00976401 loss)
I0619 01:26:23.139734  8058 sgd_solver.cpp:105] Iteration 101300, lr = 0.0001
I0619 01:27:50.719265  8058 solver.cpp:218] Iteration 101350 (0.570921 iter/s, 87.5778s/50 iters), loss = 0.0118608
I0619 01:27:50.719475  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 01:27:50.719506  8058 solver.cpp:237]     Train net output #1: loss = 0.0118608 (* 1 = 0.0118608 loss)
I0619 01:27:50.719530  8058 sgd_solver.cpp:105] Iteration 101350, lr = 0.0001
I0619 01:29:18.355856  8058 solver.cpp:218] Iteration 101400 (0.570545 iter/s, 87.6356s/50 iters), loss = 0.0108446
I0619 01:29:18.355993  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 01:29:18.356021  8058 solver.cpp:237]     Train net output #1: loss = 0.0108446 (* 1 = 0.0108446 loss)
I0619 01:29:18.356037  8058 sgd_solver.cpp:105] Iteration 101400, lr = 0.0001
I0619 01:29:42.998381  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 01:30:45.926823  8058 solver.cpp:218] Iteration 101450 (0.570971 iter/s, 87.5702s/50 iters), loss = 0.0108847
I0619 01:30:45.926939  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 01:30:45.926969  8058 solver.cpp:237]     Train net output #1: loss = 0.0108847 (* 1 = 0.0108847 loss)
I0619 01:30:45.926986  8058 sgd_solver.cpp:105] Iteration 101450, lr = 0.0001
I0619 01:32:07.868257  8058 solver.cpp:218] Iteration 101500 (0.610198 iter/s, 81.9406s/50 iters), loss = 0.00979338
I0619 01:32:07.868443  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 01:32:07.868472  8058 solver.cpp:237]     Train net output #1: loss = 0.00979341 (* 1 = 0.00979341 loss)
I0619 01:32:07.868489  8058 sgd_solver.cpp:105] Iteration 101500, lr = 0.0001
I0619 01:32:53.866021  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 01:33:20.729070  8058 solver.cpp:218] Iteration 101550 (0.686246 iter/s, 72.8601s/50 iters), loss = 0.0115419
I0619 01:33:20.729168  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 01:33:20.729195  8058 solver.cpp:237]     Train net output #1: loss = 0.0115419 (* 1 = 0.0115419 loss)
I0619 01:33:20.729212  8058 sgd_solver.cpp:105] Iteration 101550, lr = 0.0001
I0619 01:34:48.317553  8058 solver.cpp:218] Iteration 101600 (0.570856 iter/s, 87.5877s/50 iters), loss = 0.0107066
I0619 01:34:48.317684  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 01:34:48.317719  8058 solver.cpp:237]     Train net output #1: loss = 0.0107066 (* 1 = 0.0107066 loss)
I0619 01:34:48.317739  8058 sgd_solver.cpp:105] Iteration 101600, lr = 0.0001
I0619 01:36:16.050122  8058 solver.cpp:218] Iteration 101650 (0.569919 iter/s, 87.7317s/50 iters), loss = 0.0120667
I0619 01:36:16.050263  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 01:36:16.050292  8058 solver.cpp:237]     Train net output #1: loss = 0.0120668 (* 1 = 0.0120668 loss)
I0619 01:36:16.050314  8058 sgd_solver.cpp:105] Iteration 101650, lr = 0.0001
I0619 01:36:23.159240  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 01:37:43.751081  8058 solver.cpp:218] Iteration 101700 (0.570131 iter/s, 87.6992s/50 iters), loss = 0.00981956
I0619 01:37:43.753654  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 01:37:43.753705  8058 solver.cpp:237]     Train net output #1: loss = 0.00981959 (* 1 = 0.00981959 loss)
I0619 01:37:43.753726  8058 sgd_solver.cpp:105] Iteration 101700, lr = 0.0001
I0619 01:39:11.316815  8058 solver.cpp:218] Iteration 101750 (0.571021 iter/s, 87.5625s/50 iters), loss = 0.00949636
I0619 01:39:11.316961  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 01:39:11.316990  8058 solver.cpp:237]     Train net output #1: loss = 0.0094964 (* 1 = 0.0094964 loss)
I0619 01:39:11.317008  8058 sgd_solver.cpp:105] Iteration 101750, lr = 0.0001
I0619 01:39:53.454988  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 01:40:38.907544  8058 solver.cpp:218] Iteration 101800 (0.570858 iter/s, 87.5875s/50 iters), loss = 0.011626
I0619 01:40:38.907737  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 01:40:38.907771  8058 solver.cpp:237]     Train net output #1: loss = 0.011626 (* 1 = 0.011626 loss)
I0619 01:40:38.907793  8058 sgd_solver.cpp:105] Iteration 101800, lr = 0.0001
I0619 01:42:06.503303  8058 solver.cpp:218] Iteration 101850 (0.570809 iter/s, 87.5949s/50 iters), loss = 0.00993333
I0619 01:42:06.503439  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 01:42:06.503468  8058 solver.cpp:237]     Train net output #1: loss = 0.00993336 (* 1 = 0.00993336 loss)
I0619 01:42:06.503485  8058 sgd_solver.cpp:105] Iteration 101850, lr = 0.0001
I0619 01:43:07.822749  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 01:43:17.116078  8058 solver.cpp:218] Iteration 101900 (0.708104 iter/s, 70.6111s/50 iters), loss = 0.0111144
I0619 01:43:17.116171  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 01:43:17.116199  8058 solver.cpp:237]     Train net output #1: loss = 0.0111145 (* 1 = 0.0111145 loss)
I0619 01:43:17.116214  8058 sgd_solver.cpp:105] Iteration 101900, lr = 0.0001
I0619 01:44:41.544589  8058 solver.cpp:218] Iteration 101950 (0.592222 iter/s, 84.4278s/50 iters), loss = 0.0123815
I0619 01:44:41.544713  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 01:44:41.544741  8058 solver.cpp:237]     Train net output #1: loss = 0.0123816 (* 1 = 0.0123816 loss)
I0619 01:44:41.544759  8058 sgd_solver.cpp:105] Iteration 101950, lr = 0.0001
I0619 01:46:09.265506  8058 solver.cpp:218] Iteration 102000 (0.570001 iter/s, 87.7191s/50 iters), loss = 0.0121948
I0619 01:46:09.265628  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 01:46:09.265661  8058 solver.cpp:237]     Train net output #1: loss = 0.0121949 (* 1 = 0.0121949 loss)
I0619 01:46:09.265681  8058 sgd_solver.cpp:105] Iteration 102000, lr = 0.0001
I0619 01:46:32.101776  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 01:47:36.832372  8058 solver.cpp:218] Iteration 102050 (0.571001 iter/s, 87.5655s/50 iters), loss = 0.0111384
I0619 01:47:36.832571  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 01:47:36.832602  8058 solver.cpp:237]     Train net output #1: loss = 0.0111384 (* 1 = 0.0111384 loss)
I0619 01:47:36.832620  8058 sgd_solver.cpp:105] Iteration 102050, lr = 0.0001
I0619 01:49:04.529913  8058 solver.cpp:218] Iteration 102100 (0.570153 iter/s, 87.6957s/50 iters), loss = 0.0103053
I0619 01:49:04.530048  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 01:49:04.530077  8058 solver.cpp:237]     Train net output #1: loss = 0.0103053 (* 1 = 0.0103053 loss)
I0619 01:49:04.530093  8058 sgd_solver.cpp:105] Iteration 102100, lr = 0.0001
I0619 01:50:02.516777  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 01:50:32.221895  8058 solver.cpp:218] Iteration 102150 (0.570183 iter/s, 87.6912s/50 iters), loss = 0.0127573
I0619 01:50:32.221976  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 01:50:32.222002  8058 solver.cpp:237]     Train net output #1: loss = 0.0127573 (* 1 = 0.0127573 loss)
I0619 01:50:32.222019  8058 sgd_solver.cpp:105] Iteration 102150, lr = 0.0001
I0619 01:51:59.790599  8058 solver.cpp:218] Iteration 102200 (0.570992 iter/s, 87.567s/50 iters), loss = 0.00834008
I0619 01:51:59.790848  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 01:51:59.790884  8058 solver.cpp:237]     Train net output #1: loss = 0.00834012 (* 1 = 0.00834012 loss)
I0619 01:51:59.790905  8058 sgd_solver.cpp:105] Iteration 102200, lr = 0.0001
I0619 01:53:15.628738  8058 solver.cpp:218] Iteration 102250 (0.659313 iter/s, 75.8365s/50 iters), loss = 0.0123845
I0619 01:53:15.628880  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 01:53:15.628917  8058 solver.cpp:237]     Train net output #1: loss = 0.0123845 (* 1 = 0.0123845 loss)
I0619 01:53:15.628940  8058 sgd_solver.cpp:105] Iteration 102250, lr = 0.0001
I0619 01:53:19.435230  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 01:54:34.830824  8058 solver.cpp:218] Iteration 102300 (0.631301 iter/s, 79.2015s/50 iters), loss = 0.00864426
I0619 01:54:34.831007  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 01:54:34.831043  8058 solver.cpp:237]     Train net output #1: loss = 0.00864429 (* 1 = 0.00864429 loss)
I0619 01:54:34.831079  8058 sgd_solver.cpp:105] Iteration 102300, lr = 0.0001
I0619 01:56:02.416549  8058 solver.cpp:218] Iteration 102350 (0.570875 iter/s, 87.5849s/50 iters), loss = 0.0123687
I0619 01:56:02.418501  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 01:56:02.418543  8058 solver.cpp:237]     Train net output #1: loss = 0.0123688 (* 1 = 0.0123688 loss)
I0619 01:56:02.418566  8058 sgd_solver.cpp:105] Iteration 102350, lr = 0.0001
I0619 01:56:42.849920  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 01:57:30.080015  8058 solver.cpp:218] Iteration 102400 (0.570382 iter/s, 87.6606s/50 iters), loss = 0.0114499
I0619 01:57:30.080147  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 01:57:30.080176  8058 solver.cpp:237]     Train net output #1: loss = 0.0114499 (* 1 = 0.0114499 loss)
I0619 01:57:30.080195  8058 sgd_solver.cpp:105] Iteration 102400, lr = 0.0001
I0619 01:58:57.830880  8058 solver.cpp:218] Iteration 102450 (0.569807 iter/s, 87.749s/50 iters), loss = 0.00973148
I0619 01:58:57.831029  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 01:58:57.831058  8058 solver.cpp:237]     Train net output #1: loss = 0.00973151 (* 1 = 0.00973151 loss)
I0619 01:58:57.831076  8058 sgd_solver.cpp:105] Iteration 102450, lr = 0.0001
I0619 02:00:13.319319  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 02:00:25.511813  8058 solver.cpp:218] Iteration 102500 (0.57026 iter/s, 87.6793s/50 iters), loss = 0.0116731
I0619 02:00:25.511905  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 02:00:25.511931  8058 solver.cpp:237]     Train net output #1: loss = 0.0116731 (* 1 = 0.0116731 loss)
I0619 02:00:25.511948  8058 sgd_solver.cpp:105] Iteration 102500, lr = 0.0001
I0619 02:01:53.124670  8058 solver.cpp:218] Iteration 102550 (0.570706 iter/s, 87.6108s/50 iters), loss = 0.00851328
I0619 02:01:53.124792  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 02:01:53.124825  8058 solver.cpp:237]     Train net output #1: loss = 0.00851331 (* 1 = 0.00851331 loss)
I0619 02:01:53.124846  8058 sgd_solver.cpp:105] Iteration 102550, lr = 0.0001
I0619 02:03:20.539414  8058 solver.cpp:218] Iteration 102600 (0.571997 iter/s, 87.4131s/50 iters), loss = 0.0124891
I0619 02:03:20.539541  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 02:03:20.539577  8058 solver.cpp:237]     Train net output #1: loss = 0.0124892 (* 1 = 0.0124892 loss)
I0619 02:03:20.539597  8058 sgd_solver.cpp:105] Iteration 102600, lr = 0.0001
I0619 02:03:35.616575  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 02:04:28.115270  8058 solver.cpp:218] Iteration 102650 (0.739915 iter/s, 67.5753s/50 iters), loss = 0.012601
I0619 02:04:28.115476  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 02:04:28.115506  8058 solver.cpp:237]     Train net output #1: loss = 0.0126011 (* 1 = 0.0126011 loss)
I0619 02:04:28.115531  8058 sgd_solver.cpp:105] Iteration 102650, lr = 0.0001
I0619 02:05:55.853631  8058 solver.cpp:218] Iteration 102700 (0.569887 iter/s, 87.7367s/50 iters), loss = 0.00864628
I0619 02:05:55.856052  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 02:05:55.856082  8058 solver.cpp:237]     Train net output #1: loss = 0.00864631 (* 1 = 0.00864631 loss)
I0619 02:05:55.856099  8058 sgd_solver.cpp:105] Iteration 102700, lr = 0.0001
I0619 02:06:53.658727  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 02:07:23.413182  8058 solver.cpp:218] Iteration 102750 (0.57106 iter/s, 87.5565s/50 iters), loss = 0.0118501
I0619 02:07:23.413271  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 02:07:23.413298  8058 solver.cpp:237]     Train net output #1: loss = 0.0118501 (* 1 = 0.0118501 loss)
I0619 02:07:23.413316  8058 sgd_solver.cpp:105] Iteration 102750, lr = 0.0001
I0619 02:08:51.113216  8058 solver.cpp:218] Iteration 102800 (0.57013 iter/s, 87.6993s/50 iters), loss = 0.00940735
I0619 02:08:51.113353  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 02:08:51.113394  8058 solver.cpp:237]     Train net output #1: loss = 0.00940738 (* 1 = 0.00940738 loss)
I0619 02:08:51.113411  8058 sgd_solver.cpp:105] Iteration 102800, lr = 0.0001
I0619 02:10:18.747015  8058 solver.cpp:218] Iteration 102850 (0.570562 iter/s, 87.6329s/50 iters), loss = 0.00989864
I0619 02:10:18.747133  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 02:10:18.747165  8058 solver.cpp:237]     Train net output #1: loss = 0.00989868 (* 1 = 0.00989868 loss)
I0619 02:10:18.747186  8058 sgd_solver.cpp:105] Iteration 102850, lr = 0.0001
I0619 02:10:24.133327  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 02:11:46.428424  8058 solver.cpp:218] Iteration 102900 (0.570258 iter/s, 87.6797s/50 iters), loss = 0.0110194
I0619 02:11:46.428602  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 02:11:46.428630  8058 solver.cpp:237]     Train net output #1: loss = 0.0110195 (* 1 = 0.0110195 loss)
I0619 02:11:46.428647  8058 sgd_solver.cpp:105] Iteration 102900, lr = 0.0001
I0619 02:13:14.150444  8058 solver.cpp:218] Iteration 102950 (0.569993 iter/s, 87.7203s/50 iters), loss = 0.0119711
I0619 02:13:14.150590  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 02:13:14.150619  8058 solver.cpp:237]     Train net output #1: loss = 0.0119712 (* 1 = 0.0119712 loss)
I0619 02:13:14.150635  8058 sgd_solver.cpp:105] Iteration 102950, lr = 0.0001
I0619 02:13:50.924417  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 02:14:27.763613  8058 solver.cpp:218] Iteration 103000 (0.679242 iter/s, 73.6114s/50 iters), loss = 0.012107
I0619 02:14:27.763733  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 02:14:27.763761  8058 solver.cpp:237]     Train net output #1: loss = 0.012107 (* 1 = 0.012107 loss)
I0619 02:14:27.763777  8058 sgd_solver.cpp:105] Iteration 103000, lr = 0.0001
I0619 02:15:49.324730  8058 solver.cpp:218] Iteration 103050 (0.613044 iter/s, 81.5602s/50 iters), loss = 0.0103446
I0619 02:15:49.324885  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 02:15:49.324913  8058 solver.cpp:237]     Train net output #1: loss = 0.0103447 (* 1 = 0.0103447 loss)
I0619 02:15:49.324931  8058 sgd_solver.cpp:105] Iteration 103050, lr = 0.0001
I0619 02:17:03.072942  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 02:17:17.000006  8058 solver.cpp:218] Iteration 103100 (0.570291 iter/s, 87.6745s/50 iters), loss = 0.011449
I0619 02:17:17.000109  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 02:17:17.000136  8058 solver.cpp:237]     Train net output #1: loss = 0.011449 (* 1 = 0.011449 loss)
I0619 02:17:17.000152  8058 sgd_solver.cpp:105] Iteration 103100, lr = 0.0001
I0619 02:18:44.701081  8058 solver.cpp:218] Iteration 103150 (0.570123 iter/s, 87.7004s/50 iters), loss = 0.0112913
I0619 02:18:44.701246  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 02:18:44.701275  8058 solver.cpp:237]     Train net output #1: loss = 0.0112913 (* 1 = 0.0112913 loss)
I0619 02:18:44.701293  8058 sgd_solver.cpp:105] Iteration 103150, lr = 0.0001
I0619 02:20:12.427156  8058 solver.cpp:218] Iteration 103200 (0.569967 iter/s, 87.7243s/50 iters), loss = 0.0109819
I0619 02:20:12.427304  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 02:20:12.427335  8058 solver.cpp:237]     Train net output #1: loss = 0.0109819 (* 1 = 0.0109819 loss)
I0619 02:20:12.427351  8058 sgd_solver.cpp:105] Iteration 103200, lr = 0.0001
I0619 02:20:33.588407  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 02:21:40.185686  8058 solver.cpp:218] Iteration 103250 (0.569757 iter/s, 87.7568s/50 iters), loss = 0.00971076
I0619 02:21:40.185889  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 02:21:40.185919  8058 solver.cpp:237]     Train net output #1: loss = 0.00971079 (* 1 = 0.00971079 loss)
I0619 02:21:40.185937  8058 sgd_solver.cpp:105] Iteration 103250, lr = 0.0001
I0619 02:23:07.928678  8058 solver.cpp:218] Iteration 103300 (0.569852 iter/s, 87.7422s/50 iters), loss = 0.00860044
I0619 02:23:07.928838  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 02:23:07.928867  8058 solver.cpp:237]     Train net output #1: loss = 0.00860047 (* 1 = 0.00860047 loss)
I0619 02:23:07.928884  8058 sgd_solver.cpp:105] Iteration 103300, lr = 0.0001
I0619 02:24:04.227830  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 02:24:28.173347  8058 solver.cpp:218] Iteration 103350 (0.623108 iter/s, 80.243s/50 iters), loss = 0.00904949
I0619 02:24:28.173454  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 02:24:28.173481  8058 solver.cpp:237]     Train net output #1: loss = 0.00904952 (* 1 = 0.00904952 loss)
I0619 02:24:28.173498  8058 sgd_solver.cpp:105] Iteration 103350, lr = 0.0001
I0619 02:25:43.071725  8058 solver.cpp:218] Iteration 103400 (0.667577 iter/s, 74.8978s/50 iters), loss = 0.0105213
I0619 02:25:43.071866  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 02:25:43.071894  8058 solver.cpp:237]     Train net output #1: loss = 0.0105213 (* 1 = 0.0105213 loss)
I0619 02:25:43.071912  8058 sgd_solver.cpp:105] Iteration 103400, lr = 0.0001
I0619 02:27:10.635411  8058 solver.cpp:218] Iteration 103450 (0.571029 iter/s, 87.5612s/50 iters), loss = 0.0106868
I0619 02:27:10.635617  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 02:27:10.635648  8058 solver.cpp:237]     Train net output #1: loss = 0.0106868 (* 1 = 0.0106868 loss)
I0619 02:27:10.635666  8058 sgd_solver.cpp:105] Iteration 103450, lr = 0.0001
I0619 02:27:14.284790  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 02:28:38.381351  8058 solver.cpp:218] Iteration 103500 (0.569832 iter/s, 87.7451s/50 iters), loss = 0.012521
I0619 02:28:38.381527  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 02:28:38.381558  8058 solver.cpp:237]     Train net output #1: loss = 0.0125211 (* 1 = 0.0125211 loss)
I0619 02:28:38.381575  8058 sgd_solver.cpp:105] Iteration 103500, lr = 0.0001
I0619 02:30:06.130470  8058 solver.cpp:218] Iteration 103550 (0.569817 iter/s, 87.7474s/50 iters), loss = 0.0102781
I0619 02:30:06.130623  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 02:30:06.130652  8058 solver.cpp:237]     Train net output #1: loss = 0.0102782 (* 1 = 0.0102782 loss)
I0619 02:30:06.130671  8058 sgd_solver.cpp:105] Iteration 103550, lr = 0.0001
I0619 02:30:44.718865  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 02:31:33.763980  8058 solver.cpp:218] Iteration 103600 (0.570563 iter/s, 87.6327s/50 iters), loss = 0.0110088
I0619 02:31:33.767182  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 02:31:33.767225  8058 solver.cpp:237]     Train net output #1: loss = 0.0110088 (* 1 = 0.0110088 loss)
I0619 02:31:33.767242  8058 sgd_solver.cpp:105] Iteration 103600, lr = 0.0001
I0619 02:33:01.518378  8058 solver.cpp:218] Iteration 103650 (0.569823 iter/s, 87.7466s/50 iters), loss = 0.0122576
I0619 02:33:01.518606  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 02:33:01.518635  8058 solver.cpp:237]     Train net output #1: loss = 0.0122577 (* 1 = 0.0122577 loss)
I0619 02:33:01.518653  8058 sgd_solver.cpp:105] Iteration 103650, lr = 0.0001
I0619 02:34:15.202558  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 02:34:29.214033  8058 solver.cpp:218] Iteration 103700 (0.570165 iter/s, 87.6939s/50 iters), loss = 0.010255
I0619 02:34:29.214128  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 02:34:29.214155  8058 solver.cpp:237]     Train net output #1: loss = 0.0102551 (* 1 = 0.0102551 loss)
I0619 02:34:29.214171  8058 sgd_solver.cpp:105] Iteration 103700, lr = 0.0001
I0619 02:35:37.484134  8058 solver.cpp:218] Iteration 103750 (0.732402 iter/s, 68.2686s/50 iters), loss = 0.0112461
I0619 02:35:37.484303  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 02:35:37.484333  8058 solver.cpp:237]     Train net output #1: loss = 0.0112461 (* 1 = 0.0112461 loss)
I0619 02:35:37.484364  8058 sgd_solver.cpp:105] Iteration 103750, lr = 0.0001
I0619 02:37:04.172642  8058 solver.cpp:218] Iteration 103800 (0.576783 iter/s, 86.6878s/50 iters), loss = 0.00930105
I0619 02:37:04.175604  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 02:37:04.175648  8058 solver.cpp:237]     Train net output #1: loss = 0.00930108 (* 1 = 0.00930108 loss)
I0619 02:37:04.175665  8058 sgd_solver.cpp:105] Iteration 103800, lr = 0.0001
I0619 02:37:25.459493  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 02:38:32.052184  8058 solver.cpp:218] Iteration 103850 (0.569001 iter/s, 87.8733s/50 iters), loss = 0.0111888
I0619 02:38:32.052392  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 02:38:32.052422  8058 solver.cpp:237]     Train net output #1: loss = 0.0111888 (* 1 = 0.0111888 loss)
I0619 02:38:32.052438  8058 sgd_solver.cpp:105] Iteration 103850, lr = 0.0001
I0619 02:39:59.702425  8058 solver.cpp:218] Iteration 103900 (0.57046 iter/s, 87.6485s/50 iters), loss = 0.0124914
I0619 02:39:59.704468  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 02:39:59.704500  8058 solver.cpp:237]     Train net output #1: loss = 0.0124914 (* 1 = 0.0124914 loss)
I0619 02:39:59.704525  8058 sgd_solver.cpp:105] Iteration 103900, lr = 0.0001
I0619 02:40:54.327394  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 02:41:27.368304  8058 solver.cpp:218] Iteration 103950 (0.570365 iter/s, 87.6632s/50 iters), loss = 0.00940294
I0619 02:41:27.368438  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 02:41:27.368471  8058 solver.cpp:237]     Train net output #1: loss = 0.00940297 (* 1 = 0.00940297 loss)
I0619 02:41:27.368491  8058 sgd_solver.cpp:105] Iteration 103950, lr = 0.0001
I0619 02:42:55.064200  8058 solver.cpp:218] Iteration 104000 (0.570156 iter/s, 87.6953s/50 iters), loss = 0.0109049
I0619 02:42:55.064337  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 02:42:55.064366  8058 solver.cpp:237]     Train net output #1: loss = 0.010905 (* 1 = 0.010905 loss)
I0619 02:42:55.064383  8058 sgd_solver.cpp:105] Iteration 104000, lr = 0.0001
I0619 02:44:22.769079  8058 solver.cpp:218] Iteration 104050 (0.570104 iter/s, 87.7033s/50 iters), loss = 0.00921535
I0619 02:44:22.769196  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 02:44:22.769224  8058 solver.cpp:237]     Train net output #1: loss = 0.00921538 (* 1 = 0.00921538 loss)
I0619 02:44:22.769243  8058 sgd_solver.cpp:105] Iteration 104050, lr = 0.0001
I0619 02:44:24.629314  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 02:45:36.881757  8058 solver.cpp:218] Iteration 104100 (0.674663 iter/s, 74.1111s/50 iters), loss = 0.0106553
I0619 02:45:36.881908  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 02:45:36.881937  8058 solver.cpp:237]     Train net output #1: loss = 0.0106554 (* 1 = 0.0106554 loss)
I0619 02:45:36.881953  8058 sgd_solver.cpp:105] Iteration 104100, lr = 0.0001
I0619 02:46:57.728884  8058 solver.cpp:218] Iteration 104150 (0.618473 iter/s, 80.8442s/50 iters), loss = 0.0114343
I0619 02:46:57.729068  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 02:46:57.729102  8058 solver.cpp:237]     Train net output #1: loss = 0.0114344 (* 1 = 0.0114344 loss)
I0619 02:46:57.729123  8058 sgd_solver.cpp:105] Iteration 104150, lr = 0.0001
I0619 02:47:34.663797  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 02:48:25.376410  8058 solver.cpp:218] Iteration 104200 (0.570489 iter/s, 87.6441s/50 iters), loss = 0.0106834
I0619 02:48:25.376549  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 02:48:25.376579  8058 solver.cpp:237]     Train net output #1: loss = 0.0106835 (* 1 = 0.0106835 loss)
I0619 02:48:25.376595  8058 sgd_solver.cpp:105] Iteration 104200, lr = 0.0001
I0619 02:49:53.081921  8058 solver.cpp:218] Iteration 104250 (0.5701 iter/s, 87.7039s/50 iters), loss = 0.011705
I0619 02:49:53.082060  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 02:49:53.082103  8058 solver.cpp:237]     Train net output #1: loss = 0.011705 (* 1 = 0.011705 loss)
I0619 02:49:53.082123  8058 sgd_solver.cpp:105] Iteration 104250, lr = 0.0001
I0619 02:51:05.118291  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 02:51:20.801570  8058 solver.cpp:218] Iteration 104300 (0.570008 iter/s, 87.718s/50 iters), loss = 0.0104613
I0619 02:51:20.801661  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 02:51:20.801688  8058 solver.cpp:237]     Train net output #1: loss = 0.0104613 (* 1 = 0.0104613 loss)
I0619 02:51:20.801704  8058 sgd_solver.cpp:105] Iteration 104300, lr = 0.0001
I0619 02:52:48.418126  8058 solver.cpp:218] Iteration 104350 (0.570673 iter/s, 87.6158s/50 iters), loss = 0.0109288
I0619 02:52:48.418280  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 02:52:48.418309  8058 solver.cpp:237]     Train net output #1: loss = 0.0109288 (* 1 = 0.0109288 loss)
I0619 02:52:48.418326  8058 sgd_solver.cpp:105] Iteration 104350, lr = 0.0001
I0619 02:54:16.187047  8058 solver.cpp:218] Iteration 104400 (0.569682 iter/s, 87.7682s/50 iters), loss = 0.00882461
I0619 02:54:16.187163  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 02:54:16.187192  8058 solver.cpp:237]     Train net output #1: loss = 0.00882464 (* 1 = 0.00882464 loss)
I0619 02:54:16.187209  8058 sgd_solver.cpp:105] Iteration 104400, lr = 0.0001
I0619 02:54:35.619760  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 02:55:40.827927  8058 solver.cpp:218] Iteration 104450 (0.590742 iter/s, 84.6393s/50 iters), loss = 0.0117412
I0619 02:55:40.828079  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 02:55:40.828112  8058 solver.cpp:237]     Train net output #1: loss = 0.0117412 (* 1 = 0.0117412 loss)
I0619 02:55:40.828133  8058 sgd_solver.cpp:105] Iteration 104450, lr = 0.0001
I0619 02:56:51.118917  8058 solver.cpp:218] Iteration 104500 (0.711334 iter/s, 70.2904s/50 iters), loss = 0.0100723
I0619 02:56:51.119060  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 02:56:51.119088  8058 solver.cpp:237]     Train net output #1: loss = 0.0100724 (* 1 = 0.0100724 loss)
I0619 02:56:51.119104  8058 sgd_solver.cpp:105] Iteration 104500, lr = 0.0001
I0619 02:57:45.563740  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 02:58:18.814455  8058 solver.cpp:218] Iteration 104550 (0.57016 iter/s, 87.6947s/50 iters), loss = 0.0116818
I0619 02:58:18.814613  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 02:58:18.814642  8058 solver.cpp:237]     Train net output #1: loss = 0.0116818 (* 1 = 0.0116818 loss)
I0619 02:58:18.814661  8058 sgd_solver.cpp:105] Iteration 104550, lr = 0.0001
I0619 02:59:46.561476  8058 solver.cpp:218] Iteration 104600 (0.569831 iter/s, 87.7453s/50 iters), loss = 0.0100641
I0619 02:59:46.561662  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 02:59:46.561694  8058 solver.cpp:237]     Train net output #1: loss = 0.0100641 (* 1 = 0.0100641 loss)
I0619 02:59:46.561712  8058 sgd_solver.cpp:105] Iteration 104600, lr = 0.0001
I0619 03:01:14.214844  8058 solver.cpp:218] Iteration 104650 (0.570438 iter/s, 87.6519s/50 iters), loss = 0.0111788
I0619 03:01:14.214982  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 03:01:14.215010  8058 solver.cpp:237]     Train net output #1: loss = 0.0111788 (* 1 = 0.0111788 loss)
I0619 03:01:14.215028  8058 sgd_solver.cpp:105] Iteration 104650, lr = 0.0001
I0619 03:01:16.025454  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 03:02:41.837165  8058 solver.cpp:218] Iteration 104700 (0.570636 iter/s, 87.6216s/50 iters), loss = 0.0104288
I0619 03:02:41.837316  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 03:02:41.837344  8058 solver.cpp:237]     Train net output #1: loss = 0.0104288 (* 1 = 0.0104288 loss)
I0619 03:02:41.837362  8058 sgd_solver.cpp:105] Iteration 104700, lr = 0.0001
I0619 03:04:09.442596  8058 solver.cpp:218] Iteration 104750 (0.570746 iter/s, 87.6047s/50 iters), loss = 0.0177089
I0619 03:04:09.442733  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 03:04:09.442760  8058 solver.cpp:237]     Train net output #1: loss = 0.017709 (* 1 = 0.017709 loss)
I0619 03:04:09.442777  8058 sgd_solver.cpp:105] Iteration 104750, lr = 0.0001
I0619 03:04:46.410841  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 03:05:37.077975  8058 solver.cpp:218] Iteration 104800 (0.570557 iter/s, 87.6336s/50 iters), loss = 0.00891385
I0619 03:05:37.078088  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 03:05:37.078116  8058 solver.cpp:237]     Train net output #1: loss = 0.00891388 (* 1 = 0.00891388 loss)
I0619 03:05:37.078135  8058 sgd_solver.cpp:105] Iteration 104800, lr = 0.0001
I0619 03:06:49.998548  8058 solver.cpp:218] Iteration 104850 (0.685693 iter/s, 72.9189s/50 iters), loss = 0.0103252
I0619 03:06:49.998697  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 03:06:49.998730  8058 solver.cpp:237]     Train net output #1: loss = 0.0103252 (* 1 = 0.0103252 loss)
I0619 03:06:49.998751  8058 sgd_solver.cpp:105] Iteration 104850, lr = 0.0001
I0619 03:07:54.735210  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 03:08:12.155638  8058 solver.cpp:218] Iteration 104900 (0.608595 iter/s, 82.1564s/50 iters), loss = 0.0110616
I0619 03:08:12.155726  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 03:08:12.155760  8058 solver.cpp:237]     Train net output #1: loss = 0.0110616 (* 1 = 0.0110616 loss)
I0619 03:08:12.155779  8058 sgd_solver.cpp:105] Iteration 104900, lr = 0.0001
I0619 03:09:39.723804  8058 solver.cpp:218] Iteration 104950 (0.570989 iter/s, 87.5673s/50 iters), loss = 0.0108137
I0619 03:09:39.723947  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 03:09:39.723975  8058 solver.cpp:237]     Train net output #1: loss = 0.0108137 (* 1 = 0.0108137 loss)
I0619 03:09:39.723994  8058 sgd_solver.cpp:105] Iteration 104950, lr = 0.0001
I0619 03:11:07.381844  8058 solver.cpp:218] Iteration 105000 (0.570423 iter/s, 87.6542s/50 iters), loss = 0.0114417
I0619 03:11:07.382009  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 03:11:07.382045  8058 solver.cpp:237]     Train net output #1: loss = 0.0114418 (* 1 = 0.0114418 loss)
I0619 03:11:07.382063  8058 sgd_solver.cpp:105] Iteration 105000, lr = 0.0001
I0619 03:11:25.090729  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 03:12:35.172994  8058 solver.cpp:218] Iteration 105050 (0.569545 iter/s, 87.7894s/50 iters), loss = 0.0106549
I0619 03:12:35.173136  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 03:12:35.173164  8058 solver.cpp:237]     Train net output #1: loss = 0.0106549 (* 1 = 0.0106549 loss)
I0619 03:12:35.173182  8058 sgd_solver.cpp:105] Iteration 105050, lr = 0.0001
I0619 03:14:02.831667  8058 solver.cpp:218] Iteration 105100 (0.570406 iter/s, 87.6569s/50 iters), loss = 0.010229
I0619 03:14:02.831905  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 03:14:02.831941  8058 solver.cpp:237]     Train net output #1: loss = 0.0102291 (* 1 = 0.0102291 loss)
I0619 03:14:02.831962  8058 sgd_solver.cpp:105] Iteration 105100, lr = 0.0001
I0619 03:14:55.687366  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 03:15:30.473220  8058 solver.cpp:218] Iteration 105150 (0.570511 iter/s, 87.6407s/50 iters), loss = 0.0099988
I0619 03:15:30.473354  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 03:15:30.473387  8058 solver.cpp:237]     Train net output #1: loss = 0.00999883 (* 1 = 0.00999883 loss)
I0619 03:15:30.473407  8058 sgd_solver.cpp:105] Iteration 105150, lr = 0.0001
I0619 03:16:48.361347  8058 solver.cpp:218] Iteration 105200 (0.641954 iter/s, 77.8872s/50 iters), loss = 0.0099891
I0619 03:16:48.361503  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 03:16:48.361539  8058 solver.cpp:237]     Train net output #1: loss = 0.00998914 (* 1 = 0.00998914 loss)
I0619 03:16:48.361557  8058 sgd_solver.cpp:105] Iteration 105200, lr = 0.0001
I0619 03:18:05.629421  8058 solver.cpp:218] Iteration 105250 (0.647105 iter/s, 77.2673s/50 iters), loss = 0.00978232
I0619 03:18:05.629554  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 03:18:05.629585  8058 solver.cpp:237]     Train net output #1: loss = 0.00978236 (* 1 = 0.00978236 loss)
I0619 03:18:05.629602  8058 sgd_solver.cpp:105] Iteration 105250, lr = 0.0001
I0619 03:18:05.763587  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 03:19:33.388880  8058 solver.cpp:218] Iteration 105300 (0.569751 iter/s, 87.7576s/50 iters), loss = 0.00995804
I0619 03:19:33.389055  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 03:19:33.389083  8058 solver.cpp:237]     Train net output #1: loss = 0.00995808 (* 1 = 0.00995808 loss)
I0619 03:19:33.389101  8058 sgd_solver.cpp:105] Iteration 105300, lr = 0.0001
I0619 03:21:01.026520  8058 solver.cpp:218] Iteration 105350 (0.570544 iter/s, 87.6357s/50 iters), loss = 0.00965563
I0619 03:21:01.026710  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 03:21:01.026738  8058 solver.cpp:237]     Train net output #1: loss = 0.00965566 (* 1 = 0.00965566 loss)
I0619 03:21:01.026757  8058 sgd_solver.cpp:105] Iteration 105350, lr = 0.0001
I0619 03:21:36.205466  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 03:22:28.864084  8058 solver.cpp:218] Iteration 105400 (0.56924 iter/s, 87.8365s/50 iters), loss = 0.012064
I0619 03:22:28.864233  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 03:22:28.864267  8058 solver.cpp:237]     Train net output #1: loss = 0.0120641 (* 1 = 0.0120641 loss)
I0619 03:22:28.864285  8058 sgd_solver.cpp:105] Iteration 105400, lr = 0.0001
I0619 03:23:56.600414  8058 solver.cpp:218] Iteration 105450 (0.569901 iter/s, 87.7345s/50 iters), loss = 0.00877371
I0619 03:23:56.600543  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 03:23:56.600574  8058 solver.cpp:237]     Train net output #1: loss = 0.00877374 (* 1 = 0.00877374 loss)
I0619 03:23:56.600591  8058 sgd_solver.cpp:105] Iteration 105450, lr = 0.0001
I0619 03:25:06.786293  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 03:25:24.221638  8058 solver.cpp:218] Iteration 105500 (0.570648 iter/s, 87.6198s/50 iters), loss = 0.0113055
I0619 03:25:24.221734  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 03:25:24.221760  8058 solver.cpp:237]     Train net output #1: loss = 0.0113056 (* 1 = 0.0113056 loss)
I0619 03:25:24.221776  8058 sgd_solver.cpp:105] Iteration 105500, lr = 0.0001
I0619 03:26:51.807085  8058 solver.cpp:218] Iteration 105550 (0.570877 iter/s, 87.5845s/50 iters), loss = 0.00985196
I0619 03:26:51.807200  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 03:26:51.807229  8058 solver.cpp:237]     Train net output #1: loss = 0.00985199 (* 1 = 0.00985199 loss)
I0619 03:26:51.807246  8058 sgd_solver.cpp:105] Iteration 105550, lr = 0.0001
I0619 03:27:59.146287  8058 solver.cpp:218] Iteration 105600 (0.742518 iter/s, 67.3385s/50 iters), loss = 0.010262
I0619 03:27:59.146482  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 03:27:59.146512  8058 solver.cpp:237]     Train net output #1: loss = 0.010262 (* 1 = 0.010262 loss)
I0619 03:27:59.146538  8058 sgd_solver.cpp:105] Iteration 105600, lr = 0.0001
I0619 03:28:16.820016  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 03:29:26.751046  8058 solver.cpp:218] Iteration 105650 (0.570752 iter/s, 87.6038s/50 iters), loss = 0.0116408
I0619 03:29:26.751163  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 03:29:26.751193  8058 solver.cpp:237]     Train net output #1: loss = 0.0116408 (* 1 = 0.0116408 loss)
I0619 03:29:26.751210  8058 sgd_solver.cpp:105] Iteration 105650, lr = 0.0001
I0619 03:30:54.363672  8058 solver.cpp:218] Iteration 105700 (0.570706 iter/s, 87.6107s/50 iters), loss = 0.0112227
I0619 03:30:54.363812  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 03:30:54.363842  8058 solver.cpp:237]     Train net output #1: loss = 0.0112227 (* 1 = 0.0112227 loss)
I0619 03:30:54.363869  8058 sgd_solver.cpp:105] Iteration 105700, lr = 0.0001
I0619 03:31:47.168401  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 03:32:22.000049  8058 solver.cpp:218] Iteration 105750 (0.570552 iter/s, 87.6345s/50 iters), loss = 0.0133093
I0619 03:32:22.001596  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 03:32:22.001626  8058 solver.cpp:237]     Train net output #1: loss = 0.0133093 (* 1 = 0.0133093 loss)
I0619 03:32:22.001642  8058 sgd_solver.cpp:105] Iteration 105750, lr = 0.0001
I0619 03:33:49.763906  8058 solver.cpp:218] Iteration 105800 (0.56973 iter/s, 87.7609s/50 iters), loss = 0.00941866
I0619 03:33:49.764041  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 03:33:49.764070  8058 solver.cpp:237]     Train net output #1: loss = 0.00941869 (* 1 = 0.00941869 loss)
I0619 03:33:49.764086  8058 sgd_solver.cpp:105] Iteration 105800, lr = 0.0001
I0619 03:35:17.451616  8058 solver.cpp:218] Iteration 105850 (0.570211 iter/s, 87.6868s/50 iters), loss = 0.0108462
I0619 03:35:17.451742  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 03:35:17.451771  8058 solver.cpp:237]     Train net output #1: loss = 0.0108462 (* 1 = 0.0108462 loss)
I0619 03:35:17.451788  8058 sgd_solver.cpp:105] Iteration 105850, lr = 0.0001
I0619 03:35:17.551476  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 03:36:45.284557  8058 solver.cpp:218] Iteration 105900 (0.569275 iter/s, 87.831s/50 iters), loss = 0.0102476
I0619 03:36:45.284693  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 03:36:45.284721  8058 solver.cpp:237]     Train net output #1: loss = 0.0102476 (* 1 = 0.0102476 loss)
I0619 03:36:45.284737  8058 sgd_solver.cpp:105] Iteration 105900, lr = 0.0001
I0619 03:37:59.117746  8058 solver.cpp:218] Iteration 105950 (0.677219 iter/s, 73.8314s/50 iters), loss = 0.0101568
I0619 03:37:59.117835  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 03:37:59.117863  8058 solver.cpp:237]     Train net output #1: loss = 0.0101568 (* 1 = 0.0101568 loss)
I0619 03:37:59.117879  8058 sgd_solver.cpp:105] Iteration 105950, lr = 0.0001
I0619 03:38:25.994463  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 03:39:20.182374  8058 solver.cpp:218] Iteration 106000 (0.616798 iter/s, 81.0638s/50 iters), loss = 0.00915105
I0619 03:39:20.182509  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 03:39:20.182546  8058 solver.cpp:237]     Train net output #1: loss = 0.00915109 (* 1 = 0.00915109 loss)
I0619 03:39:20.182564  8058 sgd_solver.cpp:105] Iteration 106000, lr = 0.0001
I0619 03:40:48.045801  8058 solver.cpp:218] Iteration 106050 (0.569077 iter/s, 87.8615s/50 iters), loss = 0.00966751
I0619 03:40:48.045960  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 03:40:48.045994  8058 solver.cpp:237]     Train net output #1: loss = 0.00966754 (* 1 = 0.00966754 loss)
I0619 03:40:48.046015  8058 sgd_solver.cpp:105] Iteration 106050, lr = 0.0001
I0619 03:41:56.475385  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 03:42:15.666772  8058 solver.cpp:218] Iteration 106100 (0.570653 iter/s, 87.619s/50 iters), loss = 0.0113634
I0619 03:42:15.666858  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 03:42:15.666885  8058 solver.cpp:237]     Train net output #1: loss = 0.0113634 (* 1 = 0.0113634 loss)
I0619 03:42:15.666901  8058 sgd_solver.cpp:105] Iteration 106100, lr = 0.0001
I0619 03:43:43.242434  8058 solver.cpp:218] Iteration 106150 (0.570955 iter/s, 87.5726s/50 iters), loss = 0.0104148
I0619 03:43:43.242583  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 03:43:43.242611  8058 solver.cpp:237]     Train net output #1: loss = 0.0104149 (* 1 = 0.0104149 loss)
I0619 03:43:43.242630  8058 sgd_solver.cpp:105] Iteration 106150, lr = 0.0001
I0619 03:45:10.975466  8058 solver.cpp:218] Iteration 106200 (0.569917 iter/s, 87.7321s/50 iters), loss = 0.0122109
I0619 03:45:10.975610  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 03:45:10.975652  8058 solver.cpp:237]     Train net output #1: loss = 0.0122109 (* 1 = 0.0122109 loss)
I0619 03:45:10.975669  8058 sgd_solver.cpp:105] Iteration 106200, lr = 0.0001
I0619 03:45:26.815948  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 03:46:38.650049  8058 solver.cpp:218] Iteration 106250 (0.570303 iter/s, 87.6727s/50 iters), loss = 0.00917815
I0619 03:46:38.650231  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 03:46:38.650260  8058 solver.cpp:237]     Train net output #1: loss = 0.00917818 (* 1 = 0.00917818 loss)
I0619 03:46:38.650279  8058 sgd_solver.cpp:105] Iteration 106250, lr = 0.0001
I0619 03:48:01.120337  8058 solver.cpp:218] Iteration 106300 (0.606292 iter/s, 82.4685s/50 iters), loss = 0.0120858
I0619 03:48:01.120504  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 03:48:01.120540  8058 solver.cpp:237]     Train net output #1: loss = 0.0120859 (* 1 = 0.0120859 loss)
I0619 03:48:01.120558  8058 sgd_solver.cpp:105] Iteration 106300, lr = 0.0001
I0619 03:48:41.389055  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 03:49:13.753181  8058 solver.cpp:218] Iteration 106350 (0.688401 iter/s, 72.6321s/50 iters), loss = 0.012354
I0619 03:49:13.753365  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 03:49:13.753394  8058 solver.cpp:237]     Train net output #1: loss = 0.012354 (* 1 = 0.012354 loss)
I0619 03:49:13.753412  8058 sgd_solver.cpp:105] Iteration 106350, lr = 0.0001
I0619 03:50:41.569026  8058 solver.cpp:218] Iteration 106400 (0.569385 iter/s, 87.814s/50 iters), loss = 0.0117018
I0619 03:50:41.569203  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 03:50:41.569231  8058 solver.cpp:237]     Train net output #1: loss = 0.0117018 (* 1 = 0.0117018 loss)
I0619 03:50:41.569247  8058 sgd_solver.cpp:105] Iteration 106400, lr = 0.0001
I0619 03:52:07.527045  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 03:52:09.145274  8058 solver.cpp:218] Iteration 106450 (0.570937 iter/s, 87.5754s/50 iters), loss = 0.00942676
I0619 03:52:09.145367  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 03:52:09.145393  8058 solver.cpp:237]     Train net output #1: loss = 0.00942679 (* 1 = 0.00942679 loss)
I0619 03:52:09.145411  8058 sgd_solver.cpp:105] Iteration 106450, lr = 0.0001
I0619 03:53:36.796351  8058 solver.cpp:218] Iteration 106500 (0.570453 iter/s, 87.6496s/50 iters), loss = 0.0100746
I0619 03:53:36.796475  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 03:53:36.796504  8058 solver.cpp:237]     Train net output #1: loss = 0.0100747 (* 1 = 0.0100747 loss)
I0619 03:53:36.796525  8058 sgd_solver.cpp:105] Iteration 106500, lr = 0.0001
I0619 03:55:04.532500  8058 solver.cpp:218] Iteration 106550 (0.569903 iter/s, 87.7343s/50 iters), loss = 0.0112341
I0619 03:55:04.532696  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 03:55:04.532727  8058 solver.cpp:237]     Train net output #1: loss = 0.0112341 (* 1 = 0.0112341 loss)
I0619 03:55:04.532743  8058 sgd_solver.cpp:105] Iteration 106550, lr = 0.0001
I0619 03:55:37.935408  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 03:56:32.232435  8058 solver.cpp:218] Iteration 106600 (0.570138 iter/s, 87.6981s/50 iters), loss = 0.0109846
I0619 03:56:32.232594  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 03:56:32.232628  8058 solver.cpp:237]     Train net output #1: loss = 0.0109846 (* 1 = 0.0109846 loss)
I0619 03:56:32.232647  8058 sgd_solver.cpp:105] Iteration 106600, lr = 0.0001
I0619 03:57:59.918411  8058 solver.cpp:218] Iteration 106650 (0.570223 iter/s, 87.685s/50 iters), loss = 0.0104376
I0619 03:57:59.918546  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 03:57:59.918576  8058 solver.cpp:237]     Train net output #1: loss = 0.0104376 (* 1 = 0.0104376 loss)
I0619 03:57:59.918593  8058 sgd_solver.cpp:105] Iteration 106650, lr = 0.0001
I0619 03:58:54.553227  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 03:59:10.477124  8058 solver.cpp:218] Iteration 106700 (0.708637 iter/s, 70.558s/50 iters), loss = 0.00835796
I0619 03:59:10.477236  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 03:59:10.477269  8058 solver.cpp:237]     Train net output #1: loss = 0.00835799 (* 1 = 0.00835799 loss)
I0619 03:59:10.477291  8058 sgd_solver.cpp:105] Iteration 106700, lr = 0.0001
I0619 04:00:34.932432  8058 solver.cpp:218] Iteration 106750 (0.592034 iter/s, 84.4545s/50 iters), loss = 0.00861218
I0619 04:00:34.932595  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 04:00:34.932626  8058 solver.cpp:237]     Train net output #1: loss = 0.00861221 (* 1 = 0.00861221 loss)
I0619 04:00:34.932646  8058 sgd_solver.cpp:105] Iteration 106750, lr = 0.0001
I0619 04:02:02.579067  8058 solver.cpp:218] Iteration 106800 (0.570484 iter/s, 87.6448s/50 iters), loss = 0.00894637
I0619 04:02:02.579226  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 04:02:02.579257  8058 solver.cpp:237]     Train net output #1: loss = 0.0089464 (* 1 = 0.0089464 loss)
I0619 04:02:02.579272  8058 sgd_solver.cpp:105] Iteration 106800, lr = 0.0001
I0619 04:02:18.468639  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 04:03:30.155648  8058 solver.cpp:218] Iteration 106850 (0.570935 iter/s, 87.5757s/50 iters), loss = 0.00896317
I0619 04:03:30.155809  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 04:03:30.155839  8058 solver.cpp:237]     Train net output #1: loss = 0.0089632 (* 1 = 0.0089632 loss)
I0619 04:03:30.155858  8058 sgd_solver.cpp:105] Iteration 106850, lr = 0.0001
I0619 04:04:57.736636  8058 solver.cpp:218] Iteration 106900 (0.570906 iter/s, 87.5801s/50 iters), loss = 0.0107567
I0619 04:04:57.736795  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 04:04:57.736824  8058 solver.cpp:237]     Train net output #1: loss = 0.0107568 (* 1 = 0.0107568 loss)
I0619 04:04:57.736840  8058 sgd_solver.cpp:105] Iteration 106900, lr = 0.0001
I0619 04:05:46.983939  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 04:06:25.311257  8058 solver.cpp:218] Iteration 106950 (0.570948 iter/s, 87.5737s/50 iters), loss = 0.00964589
I0619 04:06:25.313483  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 04:06:25.313521  8058 solver.cpp:237]     Train net output #1: loss = 0.00964593 (* 1 = 0.00964593 loss)
I0619 04:06:25.313542  8058 sgd_solver.cpp:105] Iteration 106950, lr = 0.0001
I0619 04:07:52.861778  8058 solver.cpp:218] Iteration 107000 (0.571133 iter/s, 87.5453s/50 iters), loss = 0.0103832
I0619 04:07:52.861984  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 04:07:52.862012  8058 solver.cpp:237]     Train net output #1: loss = 0.0103832 (* 1 = 0.0103832 loss)
I0619 04:07:52.862030  8058 sgd_solver.cpp:105] Iteration 107000, lr = 0.0001
I0619 04:09:06.642477  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 04:09:08.763880  8058 solver.cpp:218] Iteration 107050 (0.658775 iter/s, 75.8984s/50 iters), loss = 0.0132608
I0619 04:09:08.763983  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 04:09:08.764010  8058 solver.cpp:237]     Train net output #1: loss = 0.0132609 (* 1 = 0.0132609 loss)
I0619 04:09:08.764030  8058 sgd_solver.cpp:105] Iteration 107050, lr = 0.0001
I0619 04:10:27.773780  8058 solver.cpp:218] Iteration 107100 (0.632838 iter/s, 79.0092s/50 iters), loss = 0.0121049
I0619 04:10:27.773932  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 04:10:27.773962  8058 solver.cpp:237]     Train net output #1: loss = 0.012105 (* 1 = 0.012105 loss)
I0619 04:10:27.773980  8058 sgd_solver.cpp:105] Iteration 107100, lr = 0.0001
I0619 04:11:55.533061  8058 solver.cpp:218] Iteration 107150 (0.569752 iter/s, 87.7574s/50 iters), loss = 0.00936385
I0619 04:11:55.533228  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 04:11:55.533258  8058 solver.cpp:237]     Train net output #1: loss = 0.00936389 (* 1 = 0.00936389 loss)
I0619 04:11:55.533275  8058 sgd_solver.cpp:105] Iteration 107150, lr = 0.0001
I0619 04:12:27.167821  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 04:13:23.143699  8058 solver.cpp:218] Iteration 107200 (0.570713 iter/s, 87.6097s/50 iters), loss = 0.0110086
I0619 04:13:23.143868  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 04:13:23.143898  8058 solver.cpp:237]     Train net output #1: loss = 0.0110087 (* 1 = 0.0110087 loss)
I0619 04:13:23.143913  8058 sgd_solver.cpp:105] Iteration 107200, lr = 0.0001
I0619 04:14:50.955665  8058 solver.cpp:218] Iteration 107250 (0.569404 iter/s, 87.8111s/50 iters), loss = 0.0106695
I0619 04:14:50.955797  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 04:14:50.955826  8058 solver.cpp:237]     Train net output #1: loss = 0.0106695 (* 1 = 0.0106695 loss)
I0619 04:14:50.955843  8058 sgd_solver.cpp:105] Iteration 107250, lr = 0.0001
I0619 04:15:57.651095  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 04:16:18.637148  8058 solver.cpp:218] Iteration 107300 (0.570258 iter/s, 87.6796s/50 iters), loss = 0.0114867
I0619 04:16:18.637231  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 04:16:18.637257  8058 solver.cpp:237]     Train net output #1: loss = 0.0114867 (* 1 = 0.0114867 loss)
I0619 04:16:18.637274  8058 sgd_solver.cpp:105] Iteration 107300, lr = 0.0001
I0619 04:17:46.252620  8058 solver.cpp:218] Iteration 107350 (0.570681 iter/s, 87.6147s/50 iters), loss = 0.0109049
I0619 04:17:46.252777  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 04:17:46.252806  8058 solver.cpp:237]     Train net output #1: loss = 0.0109049 (* 1 = 0.0109049 loss)
I0619 04:17:46.252825  8058 sgd_solver.cpp:105] Iteration 107350, lr = 0.0001
I0619 04:19:13.553535  8058 solver.cpp:218] Iteration 107400 (0.572738 iter/s, 87.3s/50 iters), loss = 0.0114547
I0619 04:19:13.553689  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 04:19:13.553719  8058 solver.cpp:237]     Train net output #1: loss = 0.0114547 (* 1 = 0.0114547 loss)
I0619 04:19:13.553735  8058 sgd_solver.cpp:105] Iteration 107400, lr = 0.0001
I0619 04:19:22.862970  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 04:20:21.184532  8058 solver.cpp:218] Iteration 107450 (0.739314 iter/s, 67.6303s/50 iters), loss = 0.00972495
I0619 04:20:21.184659  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 04:20:21.184691  8058 solver.cpp:237]     Train net output #1: loss = 0.00972498 (* 1 = 0.00972498 loss)
I0619 04:20:21.184711  8058 sgd_solver.cpp:105] Iteration 107450, lr = 0.0001
I0619 04:21:48.800251  8058 solver.cpp:218] Iteration 107500 (0.570685 iter/s, 87.6139s/50 iters), loss = 0.0121275
I0619 04:21:48.800392  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 04:21:48.800420  8058 solver.cpp:237]     Train net output #1: loss = 0.0121275 (* 1 = 0.0121275 loss)
I0619 04:21:48.800437  8058 sgd_solver.cpp:105] Iteration 107500, lr = 0.0001
I0619 04:22:37.905562  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 04:23:16.452368  8058 solver.cpp:218] Iteration 107550 (0.570449 iter/s, 87.6503s/50 iters), loss = 0.0100429
I0619 04:23:16.452531  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 04:23:16.452566  8058 solver.cpp:237]     Train net output #1: loss = 0.0100429 (* 1 = 0.0100429 loss)
I0619 04:23:16.452589  8058 sgd_solver.cpp:105] Iteration 107550, lr = 0.0001
I0619 04:24:44.145508  8058 solver.cpp:218] Iteration 107600 (0.570183 iter/s, 87.6912s/50 iters), loss = 0.0105031
I0619 04:24:44.145643  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 04:24:44.145676  8058 solver.cpp:237]     Train net output #1: loss = 0.0105031 (* 1 = 0.0105031 loss)
I0619 04:24:44.145696  8058 sgd_solver.cpp:105] Iteration 107600, lr = 0.0001
I0619 04:26:08.432241  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 04:26:11.846776  8058 solver.cpp:218] Iteration 107650 (0.570144 iter/s, 87.6971s/50 iters), loss = 0.0127716
I0619 04:26:11.846856  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 04:26:11.846897  8058 solver.cpp:237]     Train net output #1: loss = 0.0127716 (* 1 = 0.0127716 loss)
I0619 04:26:11.846916  8058 sgd_solver.cpp:105] Iteration 107650, lr = 0.0001
I0619 04:27:39.598489  8058 solver.cpp:218] Iteration 107700 (0.569803 iter/s, 87.7497s/50 iters), loss = 0.00842984
I0619 04:27:39.598671  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 04:27:39.598701  8058 solver.cpp:237]     Train net output #1: loss = 0.00842987 (* 1 = 0.00842987 loss)
I0619 04:27:39.598717  8058 sgd_solver.cpp:105] Iteration 107700, lr = 0.0001
I0619 04:29:07.190387  8058 solver.cpp:218] Iteration 107750 (0.570837 iter/s, 87.5908s/50 iters), loss = 0.0126482
I0619 04:29:07.190502  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 04:29:07.190538  8058 solver.cpp:237]     Train net output #1: loss = 0.0126483 (* 1 = 0.0126483 loss)
I0619 04:29:07.190557  8058 sgd_solver.cpp:105] Iteration 107750, lr = 0.0001
I0619 04:29:38.817967  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 04:30:20.682178  8058 solver.cpp:218] Iteration 107800 (0.680359 iter/s, 73.4906s/50 iters), loss = 0.013239
I0619 04:30:20.682363  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 04:30:20.682392  8058 solver.cpp:237]     Train net output #1: loss = 0.013239 (* 1 = 0.013239 loss)
I0619 04:30:20.682410  8058 sgd_solver.cpp:105] Iteration 107800, lr = 0.0001
I0619 04:31:41.791522  8058 solver.cpp:218] Iteration 107850 (0.61646 iter/s, 81.1083s/50 iters), loss = 0.0110923
I0619 04:31:41.798593  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 04:31:41.798625  8058 solver.cpp:237]     Train net output #1: loss = 0.0110923 (* 1 = 0.0110923 loss)
I0619 04:31:41.798643  8058 sgd_solver.cpp:105] Iteration 107850, lr = 0.0001
I0619 04:32:46.686939  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 04:33:09.341645  8058 solver.cpp:218] Iteration 107900 (0.571156 iter/s, 87.5417s/50 iters), loss = 0.0104927
I0619 04:33:09.341737  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 04:33:09.341763  8058 solver.cpp:237]     Train net output #1: loss = 0.0104928 (* 1 = 0.0104928 loss)
I0619 04:33:09.341779  8058 sgd_solver.cpp:105] Iteration 107900, lr = 0.0001
I0619 04:34:36.918469  8058 solver.cpp:218] Iteration 107950 (0.570938 iter/s, 87.5752s/50 iters), loss = 0.00996613
I0619 04:34:36.918628  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 04:34:36.918661  8058 solver.cpp:237]     Train net output #1: loss = 0.00996616 (* 1 = 0.00996616 loss)
I0619 04:34:36.918684  8058 sgd_solver.cpp:105] Iteration 107950, lr = 0.0001
I0619 04:36:04.617458  8058 solver.cpp:218] Iteration 108000 (0.570145 iter/s, 87.697s/50 iters), loss = 0.0101687
I0619 04:36:04.617632  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 04:36:04.617664  8058 solver.cpp:237]     Train net output #1: loss = 0.0101687 (* 1 = 0.0101687 loss)
I0619 04:36:04.617681  8058 sgd_solver.cpp:105] Iteration 108000, lr = 0.0001
I0619 04:36:16.935995  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 04:37:32.264989  8058 solver.cpp:218] Iteration 108050 (0.57048 iter/s, 87.6455s/50 iters), loss = 0.00838599
I0619 04:37:32.265161  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 04:37:32.265195  8058 solver.cpp:237]     Train net output #1: loss = 0.00838602 (* 1 = 0.00838602 loss)
I0619 04:37:32.265216  8058 sgd_solver.cpp:105] Iteration 108050, lr = 0.0001
I0619 04:38:59.820190  8058 solver.cpp:218] Iteration 108100 (0.571076 iter/s, 87.5541s/50 iters), loss = 0.0111922
I0619 04:38:59.820338  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 04:38:59.820365  8058 solver.cpp:237]     Train net output #1: loss = 0.0111923 (* 1 = 0.0111923 loss)
I0619 04:38:59.820381  8058 sgd_solver.cpp:105] Iteration 108100, lr = 0.0001
I0619 04:39:47.167512  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 04:40:21.241997  8058 solver.cpp:218] Iteration 108150 (0.614094 iter/s, 81.4208s/50 iters), loss = 0.0121447
I0619 04:40:21.242164  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 04:40:21.242192  8058 solver.cpp:237]     Train net output #1: loss = 0.0121447 (* 1 = 0.0121447 loss)
I0619 04:40:21.242210  8058 sgd_solver.cpp:105] Iteration 108150, lr = 0.0001
I0619 04:41:34.152462  8058 solver.cpp:218] Iteration 108200 (0.685781 iter/s, 72.9096s/50 iters), loss = 0.0103533
I0619 04:41:34.152606  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 04:41:34.152639  8058 solver.cpp:237]     Train net output #1: loss = 0.0103534 (* 1 = 0.0103534 loss)
I0619 04:41:34.152659  8058 sgd_solver.cpp:105] Iteration 108200, lr = 0.0001
I0619 04:42:56.636982  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 04:43:01.710320  8058 solver.cpp:218] Iteration 108250 (0.571058 iter/s, 87.5568s/50 iters), loss = 0.0122713
I0619 04:43:01.710404  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 04:43:01.710431  8058 solver.cpp:237]     Train net output #1: loss = 0.0122714 (* 1 = 0.0122714 loss)
I0619 04:43:01.710453  8058 sgd_solver.cpp:105] Iteration 108250, lr = 0.0001
I0619 04:44:29.302927  8058 solver.cpp:218] Iteration 108300 (0.570831 iter/s, 87.5916s/50 iters), loss = 0.010457
I0619 04:44:29.303087  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 04:44:29.303115  8058 solver.cpp:237]     Train net output #1: loss = 0.010457 (* 1 = 0.010457 loss)
I0619 04:44:29.303133  8058 sgd_solver.cpp:105] Iteration 108300, lr = 0.0001
I0619 04:45:56.935237  8058 solver.cpp:218] Iteration 108350 (0.570574 iter/s, 87.6311s/50 iters), loss = 0.0101071
I0619 04:45:56.935416  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 04:45:56.935446  8058 solver.cpp:237]     Train net output #1: loss = 0.0101071 (* 1 = 0.0101071 loss)
I0619 04:45:56.935463  8058 sgd_solver.cpp:105] Iteration 108350, lr = 0.0001
I0619 04:46:27.061939  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 04:47:24.549306  8058 solver.cpp:218] Iteration 108400 (0.570698 iter/s, 87.612s/50 iters), loss = 0.0125996
I0619 04:47:24.549448  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 04:47:24.549476  8058 solver.cpp:237]     Train net output #1: loss = 0.0125996 (* 1 = 0.0125996 loss)
I0619 04:47:24.549492  8058 sgd_solver.cpp:105] Iteration 108400, lr = 0.0001
I0619 04:48:52.129076  8058 solver.cpp:218] Iteration 108450 (0.570921 iter/s, 87.5777s/50 iters), loss = 0.0114531
I0619 04:48:52.129205  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 04:48:52.129235  8058 solver.cpp:237]     Train net output #1: loss = 0.0114531 (* 1 = 0.0114531 loss)
I0619 04:48:52.129251  8058 sgd_solver.cpp:105] Iteration 108450, lr = 0.0001
I0619 04:49:57.119382  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 04:50:19.755524  8058 solver.cpp:218] Iteration 108500 (0.570617 iter/s, 87.6244s/50 iters), loss = 0.0109234
I0619 04:50:19.755622  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 04:50:19.755650  8058 solver.cpp:237]     Train net output #1: loss = 0.0109235 (* 1 = 0.0109235 loss)
I0619 04:50:19.755666  8058 sgd_solver.cpp:105] Iteration 108500, lr = 0.0001
I0619 04:51:30.765372  8058 solver.cpp:218] Iteration 108550 (0.704146 iter/s, 71.008s/50 iters), loss = 0.0108297
I0619 04:51:30.765547  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 04:51:30.765578  8058 solver.cpp:237]     Train net output #1: loss = 0.0108297 (* 1 = 0.0108297 loss)
I0619 04:51:30.765596  8058 sgd_solver.cpp:105] Iteration 108550, lr = 0.0001
I0619 04:52:54.420796  8058 solver.cpp:218] Iteration 108600 (0.597697 iter/s, 83.6544s/50 iters), loss = 0.0101489
I0619 04:52:54.421542  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 04:52:54.421577  8058 solver.cpp:237]     Train net output #1: loss = 0.010149 (* 1 = 0.010149 loss)
I0619 04:52:54.421597  8058 sgd_solver.cpp:105] Iteration 108600, lr = 0.0001
I0619 04:53:06.820389  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 04:54:22.004892  8058 solver.cpp:218] Iteration 108650 (0.570904 iter/s, 87.5803s/50 iters), loss = 0.0115416
I0619 04:54:22.005053  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 04:54:22.005082  8058 solver.cpp:237]     Train net output #1: loss = 0.0115417 (* 1 = 0.0115417 loss)
I0619 04:54:22.005100  8058 sgd_solver.cpp:105] Iteration 108650, lr = 0.0001
I0619 04:55:49.594092  8058 solver.cpp:218] Iteration 108700 (0.570878 iter/s, 87.5844s/50 iters), loss = 0.00891555
I0619 04:55:49.594259  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 04:55:49.594288  8058 solver.cpp:237]     Train net output #1: loss = 0.00891559 (* 1 = 0.00891559 loss)
I0619 04:55:49.594305  8058 sgd_solver.cpp:105] Iteration 108700, lr = 0.0001
I0619 04:56:37.022645  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 04:57:17.186986  8058 solver.cpp:218] Iteration 108750 (0.570829 iter/s, 87.5918s/50 iters), loss = 0.0109864
I0619 04:57:17.189061  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 04:57:17.189115  8058 solver.cpp:237]     Train net output #1: loss = 0.0109864 (* 1 = 0.0109864 loss)
I0619 04:57:17.189137  8058 sgd_solver.cpp:105] Iteration 108750, lr = 0.0001
I0619 04:58:44.761400  8058 solver.cpp:218] Iteration 108800 (0.570981 iter/s, 87.5686s/50 iters), loss = 0.011366
I0619 04:58:44.761543  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 04:58:44.761576  8058 solver.cpp:237]     Train net output #1: loss = 0.011366 (* 1 = 0.011366 loss)
I0619 04:58:44.761598  8058 sgd_solver.cpp:105] Iteration 108800, lr = 0.0001
I0619 05:00:07.216606  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 05:00:12.347578  8058 solver.cpp:218] Iteration 108850 (0.570898 iter/s, 87.5814s/50 iters), loss = 0.00850059
I0619 05:00:12.347661  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 05:00:12.347688  8058 solver.cpp:237]     Train net output #1: loss = 0.00850062 (* 1 = 0.00850062 loss)
I0619 05:00:12.347705  8058 sgd_solver.cpp:105] Iteration 108850, lr = 0.0001
I0619 05:01:29.259927  8058 solver.cpp:218] Iteration 108900 (0.650099 iter/s, 76.9113s/50 iters), loss = 0.00991823
I0619 05:01:29.260061  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 05:01:29.260090  8058 solver.cpp:237]     Train net output #1: loss = 0.00991826 (* 1 = 0.00991826 loss)
I0619 05:01:29.260107  8058 sgd_solver.cpp:105] Iteration 108900, lr = 0.0001
I0619 05:02:47.125315  8058 solver.cpp:218] Iteration 108950 (0.642141 iter/s, 77.8645s/50 iters), loss = 0.00959148
I0619 05:02:47.125437  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 05:02:47.125466  8058 solver.cpp:237]     Train net output #1: loss = 0.00959151 (* 1 = 0.00959151 loss)
I0619 05:02:47.125488  8058 sgd_solver.cpp:105] Iteration 108950, lr = 0.0001
I0619 05:03:15.329808  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 05:04:14.780246  8058 solver.cpp:218] Iteration 109000 (0.570432 iter/s, 87.6529s/50 iters), loss = 0.0119249
I0619 05:04:14.780521  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 05:04:14.780560  8058 solver.cpp:237]     Train net output #1: loss = 0.0119249 (* 1 = 0.0119249 loss)
I0619 05:04:14.780580  8058 sgd_solver.cpp:105] Iteration 109000, lr = 0.0001
I0619 05:05:42.495903  8058 solver.cpp:218] Iteration 109050 (0.570037 iter/s, 87.7137s/50 iters), loss = 0.00988061
I0619 05:05:42.496045  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 05:05:42.496078  8058 solver.cpp:237]     Train net output #1: loss = 0.00988065 (* 1 = 0.00988065 loss)
I0619 05:05:42.496099  8058 sgd_solver.cpp:105] Iteration 109050, lr = 0.0001
I0619 05:06:45.581424  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 05:07:10.037560  8058 solver.cpp:218] Iteration 109100 (0.571171 iter/s, 87.5395s/50 iters), loss = 0.0119894
I0619 05:07:10.037647  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 05:07:10.037678  8058 solver.cpp:237]     Train net output #1: loss = 0.0119894 (* 1 = 0.0119894 loss)
I0619 05:07:10.037709  8058 sgd_solver.cpp:105] Iteration 109100, lr = 0.0001
I0619 05:08:37.602161  8058 solver.cpp:218] Iteration 109150 (0.571019 iter/s, 87.5628s/50 iters), loss = 0.0099448
I0619 05:08:37.602293  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 05:08:37.602325  8058 solver.cpp:237]     Train net output #1: loss = 0.00994483 (* 1 = 0.00994483 loss)
I0619 05:08:37.602344  8058 sgd_solver.cpp:105] Iteration 109150, lr = 0.0001
I0619 05:10:05.120313  8058 solver.cpp:218] Iteration 109200 (0.57132 iter/s, 87.5166s/50 iters), loss = 0.0125209
I0619 05:10:05.120436  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 05:10:05.120465  8058 solver.cpp:237]     Train net output #1: loss = 0.0125209 (* 1 = 0.0125209 loss)
I0619 05:10:05.120481  8058 sgd_solver.cpp:105] Iteration 109200, lr = 0.0001
I0619 05:10:15.709309  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 05:11:32.752377  8058 solver.cpp:218] Iteration 109250 (0.570582 iter/s, 87.6298s/50 iters), loss = 0.011265
I0619 05:11:32.752506  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 05:11:32.752542  8058 solver.cpp:237]     Train net output #1: loss = 0.011265 (* 1 = 0.011265 loss)
I0619 05:11:32.752559  8058 sgd_solver.cpp:105] Iteration 109250, lr = 0.0001
I0619 05:12:39.877012  8058 solver.cpp:218] Iteration 109300 (0.744894 iter/s, 67.1237s/50 iters), loss = 0.00926419
I0619 05:12:39.878386  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 05:12:39.878419  8058 solver.cpp:237]     Train net output #1: loss = 0.00926422 (* 1 = 0.00926422 loss)
I0619 05:12:39.878438  8058 sgd_solver.cpp:105] Iteration 109300, lr = 0.0001
I0619 05:13:25.497092  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 05:14:07.502612  8058 solver.cpp:218] Iteration 109350 (0.57063 iter/s, 87.6225s/50 iters), loss = 0.00855181
I0619 05:14:07.502746  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 05:14:07.502775  8058 solver.cpp:237]     Train net output #1: loss = 0.00855184 (* 1 = 0.00855184 loss)
I0619 05:14:07.502794  8058 sgd_solver.cpp:105] Iteration 109350, lr = 0.0001
I0619 05:15:35.034258  8058 solver.cpp:218] Iteration 109400 (0.571235 iter/s, 87.5297s/50 iters), loss = 0.0103372
I0619 05:15:35.034421  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 05:15:35.034451  8058 solver.cpp:237]     Train net output #1: loss = 0.0103372 (* 1 = 0.0103372 loss)
I0619 05:15:35.034471  8058 sgd_solver.cpp:105] Iteration 109400, lr = 0.0001
I0619 05:16:55.650178  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 05:17:02.617058  8058 solver.cpp:218] Iteration 109450 (0.570901 iter/s, 87.5808s/50 iters), loss = 0.00932231
I0619 05:17:02.617146  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 05:17:02.617177  8058 solver.cpp:237]     Train net output #1: loss = 0.00932234 (* 1 = 0.00932234 loss)
I0619 05:17:02.617197  8058 sgd_solver.cpp:105] Iteration 109450, lr = 0.0001
I0619 05:18:30.213392  8058 solver.cpp:218] Iteration 109500 (0.570812 iter/s, 87.5945s/50 iters), loss = 0.00930132
I0619 05:18:30.213627  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 05:18:30.213656  8058 solver.cpp:237]     Train net output #1: loss = 0.00930135 (* 1 = 0.00930135 loss)
I0619 05:18:30.213673  8058 sgd_solver.cpp:105] Iteration 109500, lr = 0.0001
I0619 05:19:57.754801  8058 solver.cpp:218] Iteration 109550 (0.571168 iter/s, 87.5399s/50 iters), loss = 0.00771609
I0619 05:19:57.754921  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 05:19:57.754951  8058 solver.cpp:237]     Train net output #1: loss = 0.00771613 (* 1 = 0.00771613 loss)
I0619 05:19:57.754969  8058 sgd_solver.cpp:105] Iteration 109550, lr = 0.0001
I0619 05:20:26.039408  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 05:21:25.332702  8058 solver.cpp:218] Iteration 109600 (0.570934 iter/s, 87.5759s/50 iters), loss = 0.010328
I0619 05:21:25.332844  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 05:21:25.332872  8058 solver.cpp:237]     Train net output #1: loss = 0.0103281 (* 1 = 0.0103281 loss)
I0619 05:21:25.332888  8058 sgd_solver.cpp:105] Iteration 109600, lr = 0.0001
I0619 05:22:39.240089  8058 solver.cpp:218] Iteration 109650 (0.67653 iter/s, 73.9065s/50 iters), loss = 0.0106294
I0619 05:22:39.240257  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 05:22:39.240289  8058 solver.cpp:237]     Train net output #1: loss = 0.0106294 (* 1 = 0.0106294 loss)
I0619 05:22:39.240311  8058 sgd_solver.cpp:105] Iteration 109650, lr = 0.0001
I0619 05:23:35.788323  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 05:24:00.245647  8058 solver.cpp:218] Iteration 109700 (0.617264 iter/s, 81.0026s/50 iters), loss = 0.0100143
I0619 05:24:00.245739  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 05:24:00.245766  8058 solver.cpp:237]     Train net output #1: loss = 0.0100144 (* 1 = 0.0100144 loss)
I0619 05:24:00.245784  8058 sgd_solver.cpp:105] Iteration 109700, lr = 0.0001
I0619 05:25:27.866883  8058 solver.cpp:218] Iteration 109750 (0.57065 iter/s, 87.6193s/50 iters), loss = 0.0106651
I0619 05:25:27.867013  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 05:25:27.867046  8058 solver.cpp:237]     Train net output #1: loss = 0.0106652 (* 1 = 0.0106652 loss)
I0619 05:25:27.867067  8058 sgd_solver.cpp:105] Iteration 109750, lr = 0.0001
I0619 05:26:55.447706  8058 solver.cpp:218] Iteration 109800 (0.570913 iter/s, 87.579s/50 iters), loss = 0.00874205
I0619 05:26:55.447854  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 05:26:55.447883  8058 solver.cpp:237]     Train net output #1: loss = 0.00874208 (* 1 = 0.00874208 loss)
I0619 05:26:55.447901  8058 sgd_solver.cpp:105] Iteration 109800, lr = 0.0001
I0619 05:27:05.984997  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 05:28:23.037488  8058 solver.cpp:218] Iteration 109850 (0.570855 iter/s, 87.5879s/50 iters), loss = 0.011198
I0619 05:28:23.037606  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 05:28:23.037634  8058 solver.cpp:237]     Train net output #1: loss = 0.011198 (* 1 = 0.011198 loss)
I0619 05:28:23.037652  8058 sgd_solver.cpp:105] Iteration 109850, lr = 0.0001
I0619 05:29:50.635025  8058 solver.cpp:218] Iteration 109900 (0.570805 iter/s, 87.5956s/50 iters), loss = 0.00979581
I0619 05:29:50.635175  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 05:29:50.635205  8058 solver.cpp:237]     Train net output #1: loss = 0.00979584 (* 1 = 0.00979584 loss)
I0619 05:29:50.635221  8058 sgd_solver.cpp:105] Iteration 109900, lr = 0.0001
I0619 05:30:34.602486  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 05:31:18.226701  8058 solver.cpp:218] Iteration 109950 (0.570843 iter/s, 87.5898s/50 iters), loss = 0.010556
I0619 05:31:18.226835  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 05:31:18.226863  8058 solver.cpp:237]     Train net output #1: loss = 0.010556 (* 1 = 0.010556 loss)
I0619 05:31:18.226881  8058 sgd_solver.cpp:105] Iteration 109950, lr = 0.0001
I0619 05:32:41.079776  8058 solver.cpp:447] Snapshotting to binary proto file mobilenet/mobile_cub_iter_110000.caffemodel
I0619 05:32:41.163707  8058 sgd_solver.cpp:273] Snapshotting solver state to binary proto file mobilenet/mobile_cub_iter_110000.solverstate
I0619 05:32:42.347288  8058 solver.cpp:218] Iteration 110000 (0.594391 iter/s, 84.1197s/50 iters), loss = 0.0104777
I0619 05:32:42.347373  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 05:32:42.347396  8058 solver.cpp:237]     Train net output #1: loss = 0.0104778 (* 1 = 0.0104778 loss)
I0619 05:32:42.347411  8058 sgd_solver.cpp:105] Iteration 110000, lr = 0.0001
I0619 05:33:44.188936  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 05:33:52.840960  8058 solver.cpp:218] Iteration 110050 (0.709291 iter/s, 70.493s/50 iters), loss = 0.00971909
I0619 05:33:52.841080  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 05:33:52.841109  8058 solver.cpp:237]     Train net output #1: loss = 0.00971912 (* 1 = 0.00971912 loss)
I0619 05:33:52.841126  8058 sgd_solver.cpp:105] Iteration 110050, lr = 0.0001
I0619 05:35:20.396064  8058 solver.cpp:218] Iteration 110100 (0.571075 iter/s, 87.5542s/50 iters), loss = 0.0112456
I0619 05:35:20.396260  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 05:35:20.396289  8058 solver.cpp:237]     Train net output #1: loss = 0.0112456 (* 1 = 0.0112456 loss)
I0619 05:35:20.396307  8058 sgd_solver.cpp:105] Iteration 110100, lr = 0.0001
I0619 05:36:47.947589  8058 solver.cpp:218] Iteration 110150 (0.571099 iter/s, 87.5505s/50 iters), loss = 0.0130963
I0619 05:36:47.947831  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 05:36:47.947865  8058 solver.cpp:237]     Train net output #1: loss = 0.0130964 (* 1 = 0.0130964 loss)
I0619 05:36:47.947885  8058 sgd_solver.cpp:105] Iteration 110150, lr = 0.0001
I0619 05:37:14.324481  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 05:38:15.527638  8058 solver.cpp:218] Iteration 110200 (0.570913 iter/s, 87.579s/50 iters), loss = 0.0126322
I0619 05:38:15.527797  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 05:38:15.527827  8058 solver.cpp:237]     Train net output #1: loss = 0.0126322 (* 1 = 0.0126322 loss)
I0619 05:38:15.527843  8058 sgd_solver.cpp:105] Iteration 110200, lr = 0.0001
I0619 05:39:43.087144  8058 solver.cpp:218] Iteration 110250 (0.571055 iter/s, 87.5572s/50 iters), loss = 0.00957452
I0619 05:39:43.087265  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 05:39:43.087299  8058 solver.cpp:237]     Train net output #1: loss = 0.00957455 (* 1 = 0.00957455 loss)
I0619 05:39:43.087321  8058 sgd_solver.cpp:105] Iteration 110250, lr = 0.0001
I0619 05:40:44.457876  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 05:41:10.632472  8058 solver.cpp:218] Iteration 110300 (0.57114 iter/s, 87.5443s/50 iters), loss = 0.00877931
I0619 05:41:10.632555  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 05:41:10.632583  8058 solver.cpp:237]     Train net output #1: loss = 0.00877934 (* 1 = 0.00877934 loss)
I0619 05:41:10.632601  8058 sgd_solver.cpp:105] Iteration 110300, lr = 0.0001
I0619 05:42:38.185194  8058 solver.cpp:218] Iteration 110350 (0.571091 iter/s, 87.5517s/50 iters), loss = 0.0101
I0619 05:42:38.185338  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 05:42:38.185372  8058 solver.cpp:237]     Train net output #1: loss = 0.0101001 (* 1 = 0.0101001 loss)
I0619 05:42:38.185394  8058 sgd_solver.cpp:105] Iteration 110350, lr = 0.0001
I0619 05:43:51.374559  8058 solver.cpp:218] Iteration 110400 (0.683167 iter/s, 73.1886s/50 iters), loss = 0.0111351
I0619 05:43:51.374778  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 05:43:51.374809  8058 solver.cpp:237]     Train net output #1: loss = 0.0111351 (* 1 = 0.0111351 loss)
I0619 05:43:51.374825  8058 sgd_solver.cpp:105] Iteration 110400, lr = 0.0001
I0619 05:43:57.585542  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 05:45:12.890110  8058 solver.cpp:218] Iteration 110450 (0.613387 iter/s, 81.5146s/50 iters), loss = 0.00963678
I0619 05:45:12.890271  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 05:45:12.890305  8058 solver.cpp:237]     Train net output #1: loss = 0.00963681 (* 1 = 0.00963681 loss)
I0619 05:45:12.890326  8058 sgd_solver.cpp:105] Iteration 110450, lr = 0.0001
I0619 05:46:40.446653  8058 solver.cpp:218] Iteration 110500 (0.571066 iter/s, 87.5556s/50 iters), loss = 0.00934253
I0619 05:46:40.447378  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 05:46:40.447407  8058 solver.cpp:237]     Train net output #1: loss = 0.00934257 (* 1 = 0.00934257 loss)
I0619 05:46:40.447424  8058 sgd_solver.cpp:105] Iteration 110500, lr = 0.0001
I0619 05:47:24.391396  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 05:48:08.034490  8058 solver.cpp:218] Iteration 110550 (0.570888 iter/s, 87.5828s/50 iters), loss = 0.0116924
I0619 05:48:08.034628  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 05:48:08.034658  8058 solver.cpp:237]     Train net output #1: loss = 0.0116925 (* 1 = 0.0116925 loss)
I0619 05:48:08.034675  8058 sgd_solver.cpp:105] Iteration 110550, lr = 0.0001
I0619 05:49:35.620200  8058 solver.cpp:218] Iteration 110600 (0.570882 iter/s, 87.5838s/50 iters), loss = 0.010214
I0619 05:49:35.620335  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 05:49:35.620364  8058 solver.cpp:237]     Train net output #1: loss = 0.0102141 (* 1 = 0.0102141 loss)
I0619 05:49:35.620383  8058 sgd_solver.cpp:105] Iteration 110600, lr = 0.0001
I0619 05:50:54.527423  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 05:51:03.216383  8058 solver.cpp:218] Iteration 110650 (0.570813 iter/s, 87.5943s/50 iters), loss = 0.0102233
I0619 05:51:03.216459  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 05:51:03.216485  8058 solver.cpp:237]     Train net output #1: loss = 0.0102234 (* 1 = 0.0102234 loss)
I0619 05:51:03.216502  8058 sgd_solver.cpp:105] Iteration 110650, lr = 0.0001
I0619 05:52:30.841605  8058 solver.cpp:218] Iteration 110700 (0.570624 iter/s, 87.6234s/50 iters), loss = 0.0104126
I0619 05:52:30.841882  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 05:52:30.841915  8058 solver.cpp:237]     Train net output #1: loss = 0.0104126 (* 1 = 0.0104126 loss)
I0619 05:52:30.841938  8058 sgd_solver.cpp:105] Iteration 110700, lr = 0.0001
I0619 05:53:49.982650  8058 solver.cpp:218] Iteration 110750 (0.631797 iter/s, 79.1393s/50 iters), loss = 0.0104109
I0619 05:53:49.982774  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 05:53:49.982802  8058 solver.cpp:237]     Train net output #1: loss = 0.010411 (* 1 = 0.010411 loss)
I0619 05:53:49.982820  8058 sgd_solver.cpp:105] Iteration 110750, lr = 0.0001
I0619 05:54:10.929154  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 05:55:05.738456  8058 solver.cpp:218] Iteration 110800 (0.660022 iter/s, 75.7551s/50 iters), loss = 0.0117512
I0619 05:55:05.739279  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 05:55:05.739308  8058 solver.cpp:237]     Train net output #1: loss = 0.0117512 (* 1 = 0.0117512 loss)
I0619 05:55:05.739326  8058 sgd_solver.cpp:105] Iteration 110800, lr = 0.0001
I0619 05:56:33.459882  8058 solver.cpp:218] Iteration 110850 (0.569996 iter/s, 87.7199s/50 iters), loss = 0.0127161
I0619 05:56:33.459992  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 05:56:33.460021  8058 solver.cpp:237]     Train net output #1: loss = 0.0127161 (* 1 = 0.0127161 loss)
I0619 05:56:33.460039  8058 sgd_solver.cpp:105] Iteration 110850, lr = 0.0001
I0619 05:57:33.143806  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 05:58:01.029546  8058 solver.cpp:218] Iteration 110900 (0.57098 iter/s, 87.5687s/50 iters), loss = 0.0116561
I0619 05:58:01.029630  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 05:58:01.029657  8058 solver.cpp:237]     Train net output #1: loss = 0.0116562 (* 1 = 0.0116562 loss)
I0619 05:58:01.029675  8058 sgd_solver.cpp:105] Iteration 110900, lr = 0.0001
I0619 05:59:28.610473  8058 solver.cpp:218] Iteration 110950 (0.570906 iter/s, 87.5801s/50 iters), loss = 0.00956792
I0619 05:59:28.610589  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 05:59:28.610618  8058 solver.cpp:237]     Train net output #1: loss = 0.00956795 (* 1 = 0.00956795 loss)
I0619 05:59:28.610636  8058 sgd_solver.cpp:105] Iteration 110950, lr = 0.0001
I0619 06:00:56.249415  8058 solver.cpp:218] Iteration 111000 (0.570529 iter/s, 87.6379s/50 iters), loss = 0.0109926
I0619 06:00:56.249572  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 06:00:56.249604  8058 solver.cpp:237]     Train net output #1: loss = 0.0109926 (* 1 = 0.0109926 loss)
I0619 06:00:56.249624  8058 sgd_solver.cpp:105] Iteration 111000, lr = 0.0001
I0619 06:01:03.413091  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 06:02:23.846299  8058 solver.cpp:218] Iteration 111050 (0.570802 iter/s, 87.596s/50 iters), loss = 0.00910776
I0619 06:02:23.846441  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 06:02:23.846472  8058 solver.cpp:237]     Train net output #1: loss = 0.0091078 (* 1 = 0.0091078 loss)
I0619 06:02:23.846489  8058 sgd_solver.cpp:105] Iteration 111050, lr = 0.0001
I0619 06:03:51.430646  8058 solver.cpp:218] Iteration 111100 (0.570885 iter/s, 87.5833s/50 iters), loss = 0.00929307
I0619 06:03:51.430770  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 06:03:51.430799  8058 solver.cpp:237]     Train net output #1: loss = 0.0092931 (* 1 = 0.0092931 loss)
I0619 06:03:51.430817  8058 sgd_solver.cpp:105] Iteration 111100, lr = 0.0001
I0619 06:04:22.977502  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 06:04:59.546802  8058 solver.cpp:218] Iteration 111150 (0.734048 iter/s, 68.1154s/50 iters), loss = 0.0118565
I0619 06:04:59.546933  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 06:04:59.546962  8058 solver.cpp:237]     Train net output #1: loss = 0.0118565 (* 1 = 0.0118565 loss)
I0619 06:04:59.546982  8058 sgd_solver.cpp:105] Iteration 111150, lr = 0.0001
I0619 06:06:26.286674  8058 solver.cpp:218] Iteration 111200 (0.576442 iter/s, 86.7391s/50 iters), loss = 0.0140168
I0619 06:06:26.286830  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 06:06:26.286859  8058 solver.cpp:237]     Train net output #1: loss = 0.0140168 (* 1 = 0.0140168 loss)
I0619 06:06:26.286876  8058 sgd_solver.cpp:105] Iteration 111200, lr = 0.0001
I0619 06:07:43.471997  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 06:07:53.880736  8058 solver.cpp:218] Iteration 111250 (0.570827 iter/s, 87.5922s/50 iters), loss = 0.0110556
I0619 06:07:53.880827  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 06:07:53.880854  8058 solver.cpp:237]     Train net output #1: loss = 0.0110556 (* 1 = 0.0110556 loss)
I0619 06:07:53.880872  8058 sgd_solver.cpp:105] Iteration 111250, lr = 0.0001
I0619 06:09:21.434247  8058 solver.cpp:218] Iteration 111300 (0.571086 iter/s, 87.5525s/50 iters), loss = 0.0124258
I0619 06:09:21.434366  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 06:09:21.434396  8058 solver.cpp:237]     Train net output #1: loss = 0.0124258 (* 1 = 0.0124258 loss)
I0619 06:09:21.434412  8058 sgd_solver.cpp:105] Iteration 111300, lr = 0.0001
I0619 06:10:49.014084  8058 solver.cpp:218] Iteration 111350 (0.57092 iter/s, 87.5779s/50 iters), loss = 0.0121036
I0619 06:10:49.014223  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 06:10:49.014257  8058 solver.cpp:237]     Train net output #1: loss = 0.0121037 (* 1 = 0.0121037 loss)
I0619 06:10:49.014277  8058 sgd_solver.cpp:105] Iteration 111350, lr = 0.0001
I0619 06:11:13.736956  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 06:12:16.692314  8058 solver.cpp:218] Iteration 111400 (0.570279 iter/s, 87.6764s/50 iters), loss = 0.00910505
I0619 06:12:16.692494  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 06:12:16.692530  8058 solver.cpp:237]     Train net output #1: loss = 0.00910509 (* 1 = 0.00910509 loss)
I0619 06:12:16.692550  8058 sgd_solver.cpp:105] Iteration 111400, lr = 0.0001
I0619 06:13:44.285284  8058 solver.cpp:218] Iteration 111450 (0.570834 iter/s, 87.5911s/50 iters), loss = 0.00964025
I0619 06:13:44.285403  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 06:13:44.285430  8058 solver.cpp:237]     Train net output #1: loss = 0.00964028 (* 1 = 0.00964028 loss)
I0619 06:13:44.285449  8058 sgd_solver.cpp:105] Iteration 111450, lr = 0.0001
I0619 06:14:39.547510  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 06:14:58.449286  8058 solver.cpp:218] Iteration 111500 (0.674197 iter/s, 74.1623s/50 iters), loss = 0.00892989
I0619 06:14:58.449363  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 06:14:58.449403  8058 solver.cpp:237]     Train net output #1: loss = 0.00892992 (* 1 = 0.00892992 loss)
I0619 06:14:58.449421  8058 sgd_solver.cpp:105] Iteration 111500, lr = 0.0001
I0619 06:16:19.158876  8058 solver.cpp:218] Iteration 111550 (0.619512 iter/s, 80.7087s/50 iters), loss = 0.011497
I0619 06:16:19.158991  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 06:16:19.159020  8058 solver.cpp:237]     Train net output #1: loss = 0.0114971 (* 1 = 0.0114971 loss)
I0619 06:16:19.159039  8058 sgd_solver.cpp:105] Iteration 111550, lr = 0.0001
I0619 06:17:46.805862  8058 solver.cpp:218] Iteration 111600 (0.570482 iter/s, 87.6451s/50 iters), loss = 0.0102628
I0619 06:17:46.805985  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 06:17:46.806017  8058 solver.cpp:237]     Train net output #1: loss = 0.0102629 (* 1 = 0.0102629 loss)
I0619 06:17:46.806038  8058 sgd_solver.cpp:105] Iteration 111600, lr = 0.0001
I0619 06:17:53.948681  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 06:19:14.386432  8058 solver.cpp:218] Iteration 111650 (0.570908 iter/s, 87.5797s/50 iters), loss = 0.00993291
I0619 06:19:14.386543  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 06:19:14.386574  8058 solver.cpp:237]     Train net output #1: loss = 0.00993294 (* 1 = 0.00993294 loss)
I0619 06:19:14.386590  8058 sgd_solver.cpp:105] Iteration 111650, lr = 0.0001
I0619 06:20:41.968508  8058 solver.cpp:218] Iteration 111700 (0.570899 iter/s, 87.5812s/50 iters), loss = 0.00984296
I0619 06:20:41.968644  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 06:20:41.968677  8058 solver.cpp:237]     Train net output #1: loss = 0.00984299 (* 1 = 0.00984299 loss)
I0619 06:20:41.968698  8058 sgd_solver.cpp:105] Iteration 111700, lr = 0.0001
I0619 06:21:24.145546  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 06:22:09.588253  8058 solver.cpp:218] Iteration 111750 (0.570654 iter/s, 87.6188s/50 iters), loss = 0.0116037
I0619 06:22:09.588361  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 06:22:09.588390  8058 solver.cpp:237]     Train net output #1: loss = 0.0116037 (* 1 = 0.0116037 loss)
I0619 06:22:09.588408  8058 sgd_solver.cpp:105] Iteration 111750, lr = 0.0001
I0619 06:23:37.162577  8058 solver.cpp:218] Iteration 111800 (0.570949 iter/s, 87.5734s/50 iters), loss = 0.0101589
I0619 06:23:37.162698  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 06:23:37.162725  8058 solver.cpp:237]     Train net output #1: loss = 0.0101589 (* 1 = 0.0101589 loss)
I0619 06:23:37.162744  8058 sgd_solver.cpp:105] Iteration 111800, lr = 0.0001
I0619 06:24:54.319149  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 06:25:03.001194  8058 solver.cpp:218] Iteration 111850 (0.582494 iter/s, 85.8377s/50 iters), loss = 0.0127731
I0619 06:25:03.001272  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 06:25:03.001299  8058 solver.cpp:237]     Train net output #1: loss = 0.0127732 (* 1 = 0.0127732 loss)
I0619 06:25:03.001317  8058 sgd_solver.cpp:105] Iteration 111850, lr = 0.0001
I0619 06:26:11.987156  8058 solver.cpp:218] Iteration 111900 (0.724792 iter/s, 68.9853s/50 iters), loss = 0.0114761
I0619 06:26:11.987383  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 06:26:11.987413  8058 solver.cpp:237]     Train net output #1: loss = 0.0114762 (* 1 = 0.0114762 loss)
I0619 06:26:11.987431  8058 sgd_solver.cpp:105] Iteration 111900, lr = 0.0001
I0619 06:27:39.576261  8058 solver.cpp:218] Iteration 111950 (0.570859 iter/s, 87.5872s/50 iters), loss = 0.0129954
I0619 06:27:39.576390  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 06:27:39.576418  8058 solver.cpp:237]     Train net output #1: loss = 0.0129955 (* 1 = 0.0129955 loss)
I0619 06:27:39.576436  8058 sgd_solver.cpp:105] Iteration 111950, lr = 0.0001
I0619 06:28:02.478437  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 06:29:07.155791  8058 solver.cpp:218] Iteration 112000 (0.570922 iter/s, 87.5776s/50 iters), loss = 0.0119231
I0619 06:29:07.156345  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 06:29:07.156375  8058 solver.cpp:237]     Train net output #1: loss = 0.0119231 (* 1 = 0.0119231 loss)
I0619 06:29:07.156394  8058 sgd_solver.cpp:105] Iteration 112000, lr = 0.0001
I0619 06:30:34.751912  8058 solver.cpp:218] Iteration 112050 (0.570814 iter/s, 87.5943s/50 iters), loss = 0.0113718
I0619 06:30:34.752028  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 06:30:34.752058  8058 solver.cpp:237]     Train net output #1: loss = 0.0113718 (* 1 = 0.0113718 loss)
I0619 06:30:34.752076  8058 sgd_solver.cpp:105] Iteration 112050, lr = 0.0001
I0619 06:31:32.696884  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 06:32:02.309348  8058 solver.cpp:218] Iteration 112100 (0.571066 iter/s, 87.5556s/50 iters), loss = 0.0147103
I0619 06:32:02.309428  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 06:32:02.309454  8058 solver.cpp:237]     Train net output #1: loss = 0.0147103 (* 1 = 0.0147103 loss)
I0619 06:32:02.309471  8058 sgd_solver.cpp:105] Iteration 112100, lr = 0.0001
I0619 06:33:29.881706  8058 solver.cpp:218] Iteration 112150 (0.570969 iter/s, 87.5705s/50 iters), loss = 0.00880008
I0619 06:33:29.881829  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 06:33:29.881860  8058 solver.cpp:237]     Train net output #1: loss = 0.00880012 (* 1 = 0.00880012 loss)
I0619 06:33:29.881876  8058 sgd_solver.cpp:105] Iteration 112150, lr = 0.0001
I0619 06:34:57.447808  8058 solver.cpp:218] Iteration 112200 (0.571003 iter/s, 87.5652s/50 iters), loss = 0.0130699
I0619 06:34:57.447965  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 06:34:57.447994  8058 solver.cpp:237]     Train net output #1: loss = 0.0130699 (* 1 = 0.0130699 loss)
I0619 06:34:57.448012  8058 sgd_solver.cpp:105] Iteration 112200, lr = 0.0001
I0619 06:35:02.838111  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 06:36:10.885623  8058 solver.cpp:218] Iteration 112250 (0.680865 iter/s, 73.4361s/50 iters), loss = 0.00915849
I0619 06:36:10.885749  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 06:36:10.885778  8058 solver.cpp:237]     Train net output #1: loss = 0.00915852 (* 1 = 0.00915852 loss)
I0619 06:36:10.885797  8058 sgd_solver.cpp:105] Iteration 112250, lr = 0.0001
I0619 06:37:32.183404  8058 solver.cpp:218] Iteration 112300 (0.615031 iter/s, 81.2967s/50 iters), loss = 0.0113329
I0619 06:37:32.183529  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 06:37:32.183560  8058 solver.cpp:237]     Train net output #1: loss = 0.0113329 (* 1 = 0.0113329 loss)
I0619 06:37:32.183578  8058 sgd_solver.cpp:105] Iteration 112300, lr = 0.0001
I0619 06:38:12.611300  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 06:38:59.728140  8058 solver.cpp:218] Iteration 112350 (0.571149 iter/s, 87.5429s/50 iters), loss = 0.0105273
I0619 06:38:59.728274  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 06:38:59.728307  8058 solver.cpp:237]     Train net output #1: loss = 0.0105274 (* 1 = 0.0105274 loss)
I0619 06:38:59.728327  8058 sgd_solver.cpp:105] Iteration 112350, lr = 0.0001
I0619 06:40:27.369099  8058 solver.cpp:218] Iteration 112400 (0.570522 iter/s, 87.6391s/50 iters), loss = 0.00883434
I0619 06:40:27.369185  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 06:40:27.369213  8058 solver.cpp:237]     Train net output #1: loss = 0.00883437 (* 1 = 0.00883437 loss)
I0619 06:40:27.369231  8058 sgd_solver.cpp:105] Iteration 112400, lr = 0.0001
I0619 06:41:42.780546  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 06:41:55.006914  8058 solver.cpp:218] Iteration 112450 (0.570543 iter/s, 87.6358s/50 iters), loss = 0.00955112
I0619 06:41:55.007004  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 06:41:55.007031  8058 solver.cpp:237]     Train net output #1: loss = 0.00955115 (* 1 = 0.00955115 loss)
I0619 06:41:55.007050  8058 sgd_solver.cpp:105] Iteration 112450, lr = 0.0001
I0619 06:43:22.655294  8058 solver.cpp:218] Iteration 112500 (0.570474 iter/s, 87.6464s/50 iters), loss = 0.0109522
I0619 06:43:22.655473  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 06:43:22.655508  8058 solver.cpp:237]     Train net output #1: loss = 0.0109522 (* 1 = 0.0109522 loss)
I0619 06:43:22.655539  8058 sgd_solver.cpp:105] Iteration 112500, lr = 0.0001
I0619 06:44:50.213747  8058 solver.cpp:218] Iteration 112550 (0.57106 iter/s, 87.5565s/50 iters), loss = 0.0132267
I0619 06:44:50.213868  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 06:44:50.213898  8058 solver.cpp:237]     Train net output #1: loss = 0.0132267 (* 1 = 0.0132267 loss)
I0619 06:44:50.213917  8058 sgd_solver.cpp:105] Iteration 112550, lr = 0.0001
I0619 06:45:13.003720  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 06:46:10.703532  8058 solver.cpp:218] Iteration 112600 (0.621211 iter/s, 80.4879s/50 iters), loss = 0.015144
I0619 06:46:10.703649  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 06:46:10.703677  8058 solver.cpp:237]     Train net output #1: loss = 0.0151441 (* 1 = 0.0151441 loss)
I0619 06:46:10.703694  8058 sgd_solver.cpp:105] Iteration 112600, lr = 0.0001
I0619 06:47:24.813053  8058 solver.cpp:218] Iteration 112650 (0.674685 iter/s, 74.1087s/50 iters), loss = 0.0084099
I0619 06:47:24.813175  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 06:47:24.813206  8058 solver.cpp:237]     Train net output #1: loss = 0.00840993 (* 1 = 0.00840993 loss)
I0619 06:47:24.813225  8058 sgd_solver.cpp:105] Iteration 112650, lr = 0.0001
I0619 06:48:22.657198  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 06:48:52.387416  8058 solver.cpp:218] Iteration 112700 (0.570956 iter/s, 87.5724s/50 iters), loss = 0.0132683
I0619 06:48:52.387502  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 06:48:52.387544  8058 solver.cpp:237]     Train net output #1: loss = 0.0132683 (* 1 = 0.0132683 loss)
I0619 06:48:52.387567  8058 sgd_solver.cpp:105] Iteration 112700, lr = 0.0001
I0619 06:50:19.996268  8058 solver.cpp:218] Iteration 112750 (0.570731 iter/s, 87.6069s/50 iters), loss = 0.00975632
I0619 06:50:19.996389  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 06:50:19.996418  8058 solver.cpp:237]     Train net output #1: loss = 0.00975635 (* 1 = 0.00975635 loss)
I0619 06:50:19.996438  8058 sgd_solver.cpp:105] Iteration 112750, lr = 0.0001
I0619 06:51:47.630084  8058 solver.cpp:218] Iteration 112800 (0.570569 iter/s, 87.6318s/50 iters), loss = 0.0100089
I0619 06:51:47.630192  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 06:51:47.630220  8058 solver.cpp:237]     Train net output #1: loss = 0.0100089 (* 1 = 0.0100089 loss)
I0619 06:51:47.630237  8058 sgd_solver.cpp:105] Iteration 112800, lr = 0.0001
I0619 06:51:52.938009  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 06:53:15.269623  8058 solver.cpp:218] Iteration 112850 (0.570532 iter/s, 87.6376s/50 iters), loss = 0.0104537
I0619 06:53:15.269805  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 06:53:15.269835  8058 solver.cpp:237]     Train net output #1: loss = 0.0104537 (* 1 = 0.0104537 loss)
I0619 06:53:15.269853  8058 sgd_solver.cpp:105] Iteration 112850, lr = 0.0001
I0619 06:54:42.926054  8058 solver.cpp:218] Iteration 112900 (0.570419 iter/s, 87.6549s/50 iters), loss = 0.0119561
I0619 06:54:42.926252  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 06:54:42.926281  8058 solver.cpp:237]     Train net output #1: loss = 0.0119561 (* 1 = 0.0119561 loss)
I0619 06:54:42.926300  8058 sgd_solver.cpp:105] Iteration 112900, lr = 0.0001
I0619 06:55:21.560763  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 06:56:10.507410  8058 solver.cpp:218] Iteration 112950 (0.570905 iter/s, 87.5803s/50 iters), loss = 0.00923182
I0619 06:56:10.507536  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 06:56:10.507570  8058 solver.cpp:237]     Train net output #1: loss = 0.00923186 (* 1 = 0.00923186 loss)
I0619 06:56:10.507602  8058 sgd_solver.cpp:105] Iteration 112950, lr = 0.0001
I0619 06:57:20.170601  8058 solver.cpp:218] Iteration 113000 (0.717748 iter/s, 69.6623s/50 iters), loss = 0.0113829
I0619 06:57:20.170749  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 06:57:20.170778  8058 solver.cpp:237]     Train net output #1: loss = 0.0113829 (* 1 = 0.0113829 loss)
I0619 06:57:20.170796  8058 sgd_solver.cpp:105] Iteration 113000, lr = 0.0001
I0619 06:58:31.201556  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 06:58:45.170289  8058 solver.cpp:218] Iteration 113050 (0.588244 iter/s, 84.9987s/50 iters), loss = 0.00980791
I0619 06:58:45.170361  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 06:58:45.170388  8058 solver.cpp:237]     Train net output #1: loss = 0.00980794 (* 1 = 0.00980794 loss)
I0619 06:58:45.170405  8058 sgd_solver.cpp:105] Iteration 113050, lr = 0.0001
I0619 07:00:12.742681  8058 solver.cpp:218] Iteration 113100 (0.570963 iter/s, 87.5714s/50 iters), loss = 0.0117377
I0619 07:00:12.742806  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 07:00:12.742835  8058 solver.cpp:237]     Train net output #1: loss = 0.0117377 (* 1 = 0.0117377 loss)
I0619 07:00:12.742852  8058 sgd_solver.cpp:105] Iteration 113100, lr = 0.0001
I0619 07:01:40.363719  8058 solver.cpp:218] Iteration 113150 (0.570653 iter/s, 87.619s/50 iters), loss = 0.0107549
I0619 07:01:40.363837  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 07:01:40.363870  8058 solver.cpp:237]     Train net output #1: loss = 0.0107549 (* 1 = 0.0107549 loss)
I0619 07:01:40.363891  8058 sgd_solver.cpp:105] Iteration 113150, lr = 0.0001
I0619 07:02:01.441548  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 07:03:07.937562  8058 solver.cpp:218] Iteration 113200 (0.570954 iter/s, 87.5727s/50 iters), loss = 0.0102091
I0619 07:03:07.937695  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 07:03:07.937723  8058 solver.cpp:237]     Train net output #1: loss = 0.0102092 (* 1 = 0.0102092 loss)
I0619 07:03:07.937741  8058 sgd_solver.cpp:105] Iteration 113200, lr = 0.0001
I0619 07:04:35.510509  8058 solver.cpp:218] Iteration 113250 (0.57096 iter/s, 87.5719s/50 iters), loss = 0.0119553
I0619 07:04:35.510653  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 07:04:35.510682  8058 solver.cpp:237]     Train net output #1: loss = 0.0119553 (* 1 = 0.0119553 loss)
I0619 07:04:35.510699  8058 sgd_solver.cpp:105] Iteration 113250, lr = 0.0001
I0619 07:05:31.638780  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 07:06:03.063534  8058 solver.cpp:218] Iteration 113300 (0.571089 iter/s, 87.552s/50 iters), loss = 0.00933512
I0619 07:06:03.063700  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 07:06:03.063731  8058 solver.cpp:237]     Train net output #1: loss = 0.00933515 (* 1 = 0.00933515 loss)
I0619 07:06:03.063750  8058 sgd_solver.cpp:105] Iteration 113300, lr = 0.0001
I0619 07:07:18.555220  8058 solver.cpp:218] Iteration 113350 (0.662333 iter/s, 75.4908s/50 iters), loss = 0.0107886
I0619 07:07:18.555536  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 07:07:18.555567  8058 solver.cpp:237]     Train net output #1: loss = 0.0107887 (* 1 = 0.0107887 loss)
I0619 07:07:18.555585  8058 sgd_solver.cpp:105] Iteration 113350, lr = 0.0001
I0619 07:08:37.856319  8058 solver.cpp:218] Iteration 113400 (0.630517 iter/s, 79.3s/50 iters), loss = 0.0115358
I0619 07:08:37.856458  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 07:08:37.856488  8058 solver.cpp:237]     Train net output #1: loss = 0.0115359 (* 1 = 0.0115359 loss)
I0619 07:08:37.856511  8058 sgd_solver.cpp:105] Iteration 113400, lr = 0.0001
I0619 07:08:41.546022  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 07:10:05.426098  8058 solver.cpp:218] Iteration 113450 (0.57098 iter/s, 87.5687s/50 iters), loss = 0.0116404
I0619 07:10:05.426223  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 07:10:05.426267  8058 solver.cpp:237]     Train net output #1: loss = 0.0116404 (* 1 = 0.0116404 loss)
I0619 07:10:05.426286  8058 sgd_solver.cpp:105] Iteration 113450, lr = 0.0001
I0619 07:11:32.981001  8058 solver.cpp:218] Iteration 113500 (0.571091 iter/s, 87.5518s/50 iters), loss = 0.00932126
I0619 07:11:32.981147  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 07:11:32.981180  8058 solver.cpp:237]     Train net output #1: loss = 0.00932129 (* 1 = 0.00932129 loss)
I0619 07:11:32.981201  8058 sgd_solver.cpp:105] Iteration 113500, lr = 0.0001
I0619 07:12:11.630494  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 07:13:00.536402  8058 solver.cpp:218] Iteration 113550 (0.571074 iter/s, 87.5543s/50 iters), loss = 0.0116167
I0619 07:13:00.536523  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 07:13:00.536554  8058 solver.cpp:237]     Train net output #1: loss = 0.0116167 (* 1 = 0.0116167 loss)
I0619 07:13:00.536572  8058 sgd_solver.cpp:105] Iteration 113550, lr = 0.0001
I0619 07:14:28.116345  8058 solver.cpp:218] Iteration 113600 (0.570913 iter/s, 87.579s/50 iters), loss = 0.0118728
I0619 07:14:28.116495  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 07:14:28.116529  8058 solver.cpp:237]     Train net output #1: loss = 0.0118728 (* 1 = 0.0118728 loss)
I0619 07:14:28.116549  8058 sgd_solver.cpp:105] Iteration 113600, lr = 0.0001
I0619 07:15:41.832998  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 07:15:55.687965  8058 solver.cpp:218] Iteration 113650 (0.570968 iter/s, 87.5706s/50 iters), loss = 0.0108774
I0619 07:15:55.688052  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 07:15:55.688083  8058 solver.cpp:237]     Train net output #1: loss = 0.0108774 (* 1 = 0.0108774 loss)
I0619 07:15:55.688103  8058 sgd_solver.cpp:105] Iteration 113650, lr = 0.0001
I0619 07:17:23.209483  8058 solver.cpp:218] Iteration 113700 (0.571295 iter/s, 87.5205s/50 iters), loss = 0.0120461
I0619 07:17:23.209622  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 07:17:23.209651  8058 solver.cpp:237]     Train net output #1: loss = 0.0120461 (* 1 = 0.0120461 loss)
I0619 07:17:23.209669  8058 sgd_solver.cpp:105] Iteration 113700, lr = 0.0001
I0619 07:18:30.450116  8058 solver.cpp:218] Iteration 113750 (0.74363 iter/s, 67.2377s/50 iters), loss = 0.0122532
I0619 07:18:30.450251  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 07:18:30.450281  8058 solver.cpp:237]     Train net output #1: loss = 0.0122533 (* 1 = 0.0122533 loss)
I0619 07:18:30.450299  8058 sgd_solver.cpp:105] Iteration 113750, lr = 0.0001
I0619 07:18:51.551524  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 07:19:58.049959  8058 solver.cpp:218] Iteration 113800 (0.570785 iter/s, 87.5987s/50 iters), loss = 0.00967912
I0619 07:19:58.050207  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 07:19:58.050238  8058 solver.cpp:237]     Train net output #1: loss = 0.00967915 (* 1 = 0.00967915 loss)
I0619 07:19:58.050256  8058 sgd_solver.cpp:105] Iteration 113800, lr = 0.0001
I0619 07:21:25.638295  8058 solver.cpp:218] Iteration 113850 (0.57086 iter/s, 87.5872s/50 iters), loss = 0.0101599
I0619 07:21:25.638432  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 07:21:25.638461  8058 solver.cpp:237]     Train net output #1: loss = 0.0101599 (* 1 = 0.0101599 loss)
I0619 07:21:25.638480  8058 sgd_solver.cpp:105] Iteration 113850, lr = 0.0001
I0619 07:22:20.055269  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 07:22:53.210027  8058 solver.cpp:218] Iteration 113900 (0.570968 iter/s, 87.5706s/50 iters), loss = 0.00930269
I0619 07:22:53.210144  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 07:22:53.210172  8058 solver.cpp:237]     Train net output #1: loss = 0.00930272 (* 1 = 0.00930272 loss)
I0619 07:22:53.210189  8058 sgd_solver.cpp:105] Iteration 113900, lr = 0.0001
I0619 07:24:20.877542  8058 solver.cpp:218] Iteration 113950 (0.570361 iter/s, 87.6637s/50 iters), loss = 0.0114058
I0619 07:24:20.877697  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 07:24:20.877727  8058 solver.cpp:237]     Train net output #1: loss = 0.0114059 (* 1 = 0.0114059 loss)
I0619 07:24:20.877745  8058 sgd_solver.cpp:105] Iteration 113950, lr = 0.0001
I0619 07:25:48.462893  8058 solver.cpp:218] Iteration 114000 (0.570885 iter/s, 87.5834s/50 iters), loss = 0.00951196
I0619 07:25:48.463011  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 07:25:48.463038  8058 solver.cpp:237]     Train net output #1: loss = 0.009512 (* 1 = 0.009512 loss)
I0619 07:25:48.463057  8058 sgd_solver.cpp:105] Iteration 114000, lr = 0.0001
I0619 07:25:50.398262  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 07:27:16.050447  8058 solver.cpp:218] Iteration 114050 (0.57087 iter/s, 87.5856s/50 iters), loss = 0.0105292
I0619 07:27:16.050572  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 07:27:16.050601  8058 solver.cpp:237]     Train net output #1: loss = 0.0105292 (* 1 = 0.0105292 loss)
I0619 07:27:16.050618  8058 sgd_solver.cpp:105] Iteration 114050, lr = 0.0001
I0619 07:28:29.818125  8058 solver.cpp:218] Iteration 114100 (0.677821 iter/s, 73.7658s/50 iters), loss = 0.00995027
I0619 07:28:29.818266  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 07:28:29.818298  8058 solver.cpp:237]     Train net output #1: loss = 0.00995031 (* 1 = 0.00995031 loss)
I0619 07:28:29.818320  8058 sgd_solver.cpp:105] Iteration 114100, lr = 0.0001
I0619 07:29:00.366724  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 07:29:51.118595  8058 solver.cpp:218] Iteration 114150 (0.615017 iter/s, 81.2986s/50 iters), loss = 0.00931784
I0619 07:29:51.118703  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 07:29:51.118733  8058 solver.cpp:237]     Train net output #1: loss = 0.00931787 (* 1 = 0.00931787 loss)
I0619 07:29:51.118752  8058 sgd_solver.cpp:105] Iteration 114150, lr = 0.0001
I0619 07:31:18.735271  8058 solver.cpp:218] Iteration 114200 (0.57068 iter/s, 87.6147s/50 iters), loss = 0.0108761
I0619 07:31:18.735386  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 07:31:18.735415  8058 solver.cpp:237]     Train net output #1: loss = 0.0108761 (* 1 = 0.0108761 loss)
I0619 07:31:18.735432  8058 sgd_solver.cpp:105] Iteration 114200, lr = 0.0001
I0619 07:32:30.742830  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 07:32:46.398325  8058 solver.cpp:218] Iteration 114250 (0.570379 iter/s, 87.661s/50 iters), loss = 0.0108267
I0619 07:32:46.398416  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 07:32:46.398442  8058 solver.cpp:237]     Train net output #1: loss = 0.0108267 (* 1 = 0.0108267 loss)
I0619 07:32:46.398463  8058 sgd_solver.cpp:105] Iteration 114250, lr = 0.0001
I0619 07:34:14.120421  8058 solver.cpp:218] Iteration 114300 (0.569995 iter/s, 87.7201s/50 iters), loss = 0.0116916
I0619 07:34:14.120582  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 07:34:14.120612  8058 solver.cpp:237]     Train net output #1: loss = 0.0116916 (* 1 = 0.0116916 loss)
I0619 07:34:14.120630  8058 sgd_solver.cpp:105] Iteration 114300, lr = 0.0001
I0619 07:35:41.734617  8058 solver.cpp:218] Iteration 114350 (0.570692 iter/s, 87.6129s/50 iters), loss = 0.0116075
I0619 07:35:41.734741  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 07:35:41.734773  8058 solver.cpp:237]     Train net output #1: loss = 0.0116076 (* 1 = 0.0116076 loss)
I0619 07:35:41.734793  8058 sgd_solver.cpp:105] Iteration 114350, lr = 0.0001
I0619 07:36:01.072535  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 07:37:09.340756  8058 solver.cpp:218] Iteration 114400 (0.570743 iter/s, 87.605s/50 iters), loss = 0.0101952
I0619 07:37:09.340889  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 07:37:09.340924  8058 solver.cpp:237]     Train net output #1: loss = 0.0101953 (* 1 = 0.0101953 loss)
I0619 07:37:09.340956  8058 sgd_solver.cpp:105] Iteration 114400, lr = 0.0001
I0619 07:38:31.801481  8058 solver.cpp:218] Iteration 114450 (0.606357 iter/s, 82.4596s/50 iters), loss = 0.00948652
I0619 07:38:31.801617  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 07:38:31.801648  8058 solver.cpp:237]     Train net output #1: loss = 0.00948655 (* 1 = 0.00948655 loss)
I0619 07:38:31.801669  8058 sgd_solver.cpp:105] Iteration 114450, lr = 0.0001
I0619 07:39:14.397727  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 07:39:44.246994  8058 solver.cpp:218] Iteration 114500 (0.690182 iter/s, 72.4446s/50 iters), loss = 0.0115769
I0619 07:39:44.247076  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 07:39:44.247107  8058 solver.cpp:237]     Train net output #1: loss = 0.0115769 (* 1 = 0.0115769 loss)
I0619 07:39:44.247126  8058 sgd_solver.cpp:105] Iteration 114500, lr = 0.0001
I0619 07:41:11.831995  8058 solver.cpp:218] Iteration 114550 (0.570897 iter/s, 87.5815s/50 iters), loss = 0.00995017
I0619 07:41:11.832165  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 07:41:11.832198  8058 solver.cpp:237]     Train net output #1: loss = 0.00995021 (* 1 = 0.00995021 loss)
I0619 07:41:11.832219  8058 sgd_solver.cpp:105] Iteration 114550, lr = 0.0001
I0619 07:42:39.438336  8058 solver.cpp:218] Iteration 114600 (0.570742 iter/s, 87.6052s/50 iters), loss = 0.0127189
I0619 07:42:39.438498  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 07:42:39.438537  8058 solver.cpp:237]     Train net output #1: loss = 0.012719 (* 1 = 0.012719 loss)
I0619 07:42:39.438560  8058 sgd_solver.cpp:105] Iteration 114600, lr = 0.0001
I0619 07:42:41.360659  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 07:44:07.132726  8058 solver.cpp:218] Iteration 114650 (0.570175 iter/s, 87.6923s/50 iters), loss = 0.0111878
I0619 07:44:07.133124  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 07:44:07.133153  8058 solver.cpp:237]     Train net output #1: loss = 0.0111878 (* 1 = 0.0111878 loss)
I0619 07:44:07.133172  8058 sgd_solver.cpp:105] Iteration 114650, lr = 0.0001
I0619 07:45:34.885749  8058 solver.cpp:218] Iteration 114700 (0.569794 iter/s, 87.751s/50 iters), loss = 0.0118738
I0619 07:45:34.885917  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 07:45:34.885954  8058 solver.cpp:237]     Train net output #1: loss = 0.0118739 (* 1 = 0.0118739 loss)
I0619 07:45:34.885980  8058 sgd_solver.cpp:105] Iteration 114700, lr = 0.0001
I0619 07:46:11.715457  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 07:47:02.414263  8058 solver.cpp:218] Iteration 114750 (0.571253 iter/s, 87.527s/50 iters), loss = 0.0122512
I0619 07:47:02.414371  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 07:47:02.414403  8058 solver.cpp:237]     Train net output #1: loss = 0.0122513 (* 1 = 0.0122513 loss)
I0619 07:47:02.414424  8058 sgd_solver.cpp:105] Iteration 114750, lr = 0.0001
I0619 07:48:30.042349  8058 solver.cpp:218] Iteration 114800 (0.570606 iter/s, 87.6261s/50 iters), loss = 0.0112394
I0619 07:48:30.042551  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 07:48:30.042582  8058 solver.cpp:237]     Train net output #1: loss = 0.0112394 (* 1 = 0.0112394 loss)
I0619 07:48:30.042600  8058 sgd_solver.cpp:105] Iteration 114800, lr = 0.0001
I0619 07:49:27.987006  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 07:49:41.173635  8058 solver.cpp:218] Iteration 114850 (0.702935 iter/s, 71.1303s/50 iters), loss = 0.0106758
I0619 07:49:41.173723  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 07:49:41.173750  8058 solver.cpp:237]     Train net output #1: loss = 0.0106758 (* 1 = 0.0106758 loss)
I0619 07:49:41.173768  8058 sgd_solver.cpp:105] Iteration 114850, lr = 0.0001
I0619 07:51:04.879935  8058 solver.cpp:218] Iteration 114900 (0.597333 iter/s, 83.7054s/50 iters), loss = 0.0114767
I0619 07:51:04.880067  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 07:51:04.880096  8058 solver.cpp:237]     Train net output #1: loss = 0.0114767 (* 1 = 0.0114767 loss)
I0619 07:51:04.880125  8058 sgd_solver.cpp:105] Iteration 114900, lr = 0.0001
I0619 07:52:32.552470  8058 solver.cpp:218] Iteration 114950 (0.570317 iter/s, 87.6705s/50 iters), loss = 0.0107511
I0619 07:52:32.552597  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 07:52:32.552625  8058 solver.cpp:237]     Train net output #1: loss = 0.0107511 (* 1 = 0.0107511 loss)
I0619 07:52:32.552644  8058 sgd_solver.cpp:105] Iteration 114950, lr = 0.0001
I0619 07:52:50.213966  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 07:54:00.248504  8058 solver.cpp:218] Iteration 115000 (0.570164 iter/s, 87.694s/50 iters), loss = 0.0100107
I0619 07:54:00.248636  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 07:54:00.248664  8058 solver.cpp:237]     Train net output #1: loss = 0.0100107 (* 1 = 0.0100107 loss)
I0619 07:54:00.248682  8058 sgd_solver.cpp:105] Iteration 115000, lr = 0.0001
I0619 07:55:27.824663  8058 solver.cpp:218] Iteration 115050 (0.570945 iter/s, 87.5741s/50 iters), loss = 0.0110498
I0619 07:55:27.824836  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 07:55:27.824869  8058 solver.cpp:237]     Train net output #1: loss = 0.0110498 (* 1 = 0.0110498 loss)
I0619 07:55:27.824889  8058 sgd_solver.cpp:105] Iteration 115050, lr = 0.0001
I0619 07:56:20.550276  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 07:56:55.462060  8058 solver.cpp:218] Iteration 115100 (0.57054 iter/s, 87.6362s/50 iters), loss = 0.00997709
I0619 07:56:55.462216  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 07:56:55.462245  8058 solver.cpp:237]     Train net output #1: loss = 0.00997712 (* 1 = 0.00997712 loss)
I0619 07:56:55.462265  8058 sgd_solver.cpp:105] Iteration 115100, lr = 0.0001
I0619 07:58:23.025285  8058 solver.cpp:218] Iteration 115150 (0.571023 iter/s, 87.5621s/50 iters), loss = 0.0108458
I0619 07:58:23.025471  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 07:58:23.025508  8058 solver.cpp:237]     Train net output #1: loss = 0.0108458 (* 1 = 0.0108458 loss)
I0619 07:58:23.025545  8058 sgd_solver.cpp:105] Iteration 115150, lr = 0.0001
I0619 07:59:39.417799  8058 solver.cpp:218] Iteration 115200 (0.654542 iter/s, 76.3893s/50 iters), loss = 0.0100818
I0619 07:59:39.417965  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 07:59:39.418000  8058 solver.cpp:237]     Train net output #1: loss = 0.0100819 (* 1 = 0.0100819 loss)
I0619 07:59:39.418022  8058 sgd_solver.cpp:105] Iteration 115200, lr = 0.0001
I0619 07:59:39.486352  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 08:00:57.977666  8058 solver.cpp:218] Iteration 115250 (0.636465 iter/s, 78.5589s/50 iters), loss = 0.0110725
I0619 08:00:57.977857  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 08:00:57.977888  8058 solver.cpp:237]     Train net output #1: loss = 0.0110725 (* 1 = 0.0110725 loss)
I0619 08:00:57.977906  8058 sgd_solver.cpp:105] Iteration 115250, lr = 0.0001
I0619 08:02:25.588112  8058 solver.cpp:218] Iteration 115300 (0.570721 iter/s, 87.6084s/50 iters), loss = 0.0107748
I0619 08:02:25.588253  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 08:02:25.588296  8058 solver.cpp:237]     Train net output #1: loss = 0.0107748 (* 1 = 0.0107748 loss)
I0619 08:02:25.588320  8058 sgd_solver.cpp:105] Iteration 115300, lr = 0.0001
I0619 08:03:00.774924  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 08:03:53.160871  8058 solver.cpp:218] Iteration 115350 (0.570965 iter/s, 87.5711s/50 iters), loss = 0.00974859
I0619 08:03:53.160989  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 08:03:53.161018  8058 solver.cpp:237]     Train net output #1: loss = 0.00974862 (* 1 = 0.00974862 loss)
I0619 08:03:53.161036  8058 sgd_solver.cpp:105] Iteration 115350, lr = 0.0001
I0619 08:05:20.807232  8058 solver.cpp:218] Iteration 115400 (0.570487 iter/s, 87.6443s/50 iters), loss = 0.009299
I0619 08:05:20.807365  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 08:05:20.807394  8058 solver.cpp:237]     Train net output #1: loss = 0.00929903 (* 1 = 0.00929903 loss)
I0619 08:05:20.807410  8058 sgd_solver.cpp:105] Iteration 115400, lr = 0.0001
I0619 08:06:31.013878  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 08:06:48.426501  8058 solver.cpp:218] Iteration 115450 (0.570664 iter/s, 87.6172s/50 iters), loss = 0.0114478
I0619 08:06:48.426587  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 08:06:48.426614  8058 solver.cpp:237]     Train net output #1: loss = 0.0114478 (* 1 = 0.0114478 loss)
I0619 08:06:48.426632  8058 sgd_solver.cpp:105] Iteration 115450, lr = 0.0001
I0619 08:08:16.215389  8058 solver.cpp:218] Iteration 115500 (0.569556 iter/s, 87.7877s/50 iters), loss = 0.0105198
I0619 08:08:16.215543  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 08:08:16.215574  8058 solver.cpp:237]     Train net output #1: loss = 0.0105198 (* 1 = 0.0105198 loss)
I0619 08:08:16.215590  8058 sgd_solver.cpp:105] Iteration 115500, lr = 0.0001
I0619 08:09:43.842798  8058 solver.cpp:218] Iteration 115550 (0.570611 iter/s, 87.6253s/50 iters), loss = 0.0101339
I0619 08:09:43.842954  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 08:09:43.842984  8058 solver.cpp:237]     Train net output #1: loss = 0.0101339 (* 1 = 0.0101339 loss)
I0619 08:09:43.843003  8058 sgd_solver.cpp:105] Iteration 115550, lr = 0.0001
I0619 08:09:56.363009  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 08:10:50.879051  8058 solver.cpp:218] Iteration 115600 (0.745886 iter/s, 67.0344s/50 iters), loss = 0.0111802
I0619 08:10:50.879175  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 08:10:50.879204  8058 solver.cpp:237]     Train net output #1: loss = 0.0111802 (* 1 = 0.0111802 loss)
I0619 08:10:50.879221  8058 sgd_solver.cpp:105] Iteration 115600, lr = 0.0001
I0619 08:12:18.443410  8058 solver.cpp:218] Iteration 115650 (0.571022 iter/s, 87.5623s/50 iters), loss = 0.00937242
I0619 08:12:18.443538  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 08:12:18.443568  8058 solver.cpp:237]     Train net output #1: loss = 0.00937245 (* 1 = 0.00937245 loss)
I0619 08:12:18.443586  8058 sgd_solver.cpp:105] Iteration 115650, lr = 0.0001
I0619 08:13:11.071640  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 08:13:45.971534  8058 solver.cpp:218] Iteration 115700 (0.571258 iter/s, 87.5261s/50 iters), loss = 0.0107388
I0619 08:13:45.971655  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 08:13:45.971683  8058 solver.cpp:237]     Train net output #1: loss = 0.0107388 (* 1 = 0.0107388 loss)
I0619 08:13:45.971700  8058 sgd_solver.cpp:105] Iteration 115700, lr = 0.0001
I0619 08:15:13.569226  8058 solver.cpp:218] Iteration 115750 (0.570799 iter/s, 87.5966s/50 iters), loss = 0.0107017
I0619 08:15:13.569370  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 08:15:13.569401  8058 solver.cpp:237]     Train net output #1: loss = 0.0107017 (* 1 = 0.0107017 loss)
I0619 08:15:13.569420  8058 sgd_solver.cpp:105] Iteration 115750, lr = 0.0001
I0619 08:16:41.181095  8058 solver.cpp:218] Iteration 115800 (0.570713 iter/s, 87.6098s/50 iters), loss = 0.0110995
I0619 08:16:41.181213  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 08:16:41.181242  8058 solver.cpp:237]     Train net output #1: loss = 0.0110995 (* 1 = 0.0110995 loss)
I0619 08:16:41.181259  8058 sgd_solver.cpp:105] Iteration 115800, lr = 0.0001
I0619 08:16:41.274749  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 08:18:08.815150  8058 solver.cpp:218] Iteration 115850 (0.570568 iter/s, 87.632s/50 iters), loss = 0.0115227
I0619 08:18:08.815282  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 08:18:08.815311  8058 solver.cpp:237]     Train net output #1: loss = 0.0115228 (* 1 = 0.0115228 loss)
I0619 08:18:08.815330  8058 sgd_solver.cpp:105] Iteration 115850, lr = 0.0001
I0619 08:19:36.360769  8058 solver.cpp:218] Iteration 115900 (0.571144 iter/s, 87.5436s/50 iters), loss = 0.0106663
I0619 08:19:36.360895  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 08:19:36.360924  8058 solver.cpp:237]     Train net output #1: loss = 0.0106663 (* 1 = 0.0106663 loss)
I0619 08:19:36.360941  8058 sgd_solver.cpp:105] Iteration 115900, lr = 0.0001
I0619 08:20:09.812391  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 08:20:50.202015  8058 solver.cpp:218] Iteration 115950 (0.677147 iter/s, 73.8392s/50 iters), loss = 0.0104513
I0619 08:20:50.202188  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 08:20:50.202217  8058 solver.cpp:237]     Train net output #1: loss = 0.0104514 (* 1 = 0.0104514 loss)
I0619 08:20:50.202235  8058 sgd_solver.cpp:105] Iteration 115950, lr = 0.0001
I0619 08:22:11.287981  8058 solver.cpp:218] Iteration 116000 (0.616637 iter/s, 81.0849s/50 iters), loss = 0.0101099
I0619 08:22:11.288111  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 08:22:11.288141  8058 solver.cpp:237]     Train net output #1: loss = 0.0101099 (* 1 = 0.0101099 loss)
I0619 08:22:11.288157  8058 sgd_solver.cpp:105] Iteration 116000, lr = 0.0001
I0619 08:23:19.744374  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 08:23:38.974391  8058 solver.cpp:218] Iteration 116050 (0.570227 iter/s, 87.6844s/50 iters), loss = 0.00977584
I0619 08:23:38.974472  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 08:23:38.974500  8058 solver.cpp:237]     Train net output #1: loss = 0.00977588 (* 1 = 0.00977588 loss)
I0619 08:23:38.974529  8058 sgd_solver.cpp:105] Iteration 116050, lr = 0.0001
I0619 08:25:06.707145  8058 solver.cpp:218] Iteration 116100 (0.569925 iter/s, 87.7308s/50 iters), loss = 0.011956
I0619 08:25:06.707623  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 08:25:06.707653  8058 solver.cpp:237]     Train net output #1: loss = 0.011956 (* 1 = 0.011956 loss)
I0619 08:25:06.707669  8058 sgd_solver.cpp:105] Iteration 116100, lr = 0.0001
I0619 08:26:34.254662  8058 solver.cpp:218] Iteration 116150 (0.571131 iter/s, 87.5456s/50 iters), loss = 0.0124774
I0619 08:26:34.254789  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 08:26:34.254818  8058 solver.cpp:237]     Train net output #1: loss = 0.0124775 (* 1 = 0.0124775 loss)
I0619 08:26:34.254839  8058 sgd_solver.cpp:105] Iteration 116150, lr = 0.0001
I0619 08:26:50.101405  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 08:28:01.884901  8058 solver.cpp:218] Iteration 116200 (0.570592 iter/s, 87.6283s/50 iters), loss = 0.0107489
I0619 08:28:01.885031  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 08:28:01.885061  8058 solver.cpp:237]     Train net output #1: loss = 0.0107489 (* 1 = 0.0107489 loss)
I0619 08:28:01.885078  8058 sgd_solver.cpp:105] Iteration 116200, lr = 0.0001
I0619 08:29:29.574220  8058 solver.cpp:218] Iteration 116250 (0.570201 iter/s, 87.6884s/50 iters), loss = 0.0106923
I0619 08:29:29.574400  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 08:29:29.574435  8058 solver.cpp:237]     Train net output #1: loss = 0.0106923 (* 1 = 0.0106923 loss)
I0619 08:29:29.574456  8058 sgd_solver.cpp:105] Iteration 116250, lr = 0.0001
I0619 08:30:20.475066  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 08:30:52.340700  8058 solver.cpp:218] Iteration 116300 (0.604123 iter/s, 82.7646s/50 iters), loss = 0.0137854
I0619 08:30:52.340838  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 08:30:52.340867  8058 solver.cpp:237]     Train net output #1: loss = 0.0137854 (* 1 = 0.0137854 loss)
I0619 08:30:52.340883  8058 sgd_solver.cpp:105] Iteration 116300, lr = 0.0001
I0619 08:32:04.465703  8058 solver.cpp:218] Iteration 116350 (0.693248 iter/s, 72.1242s/50 iters), loss = 0.0113212
I0619 08:32:04.465836  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 08:32:04.465865  8058 solver.cpp:237]     Train net output #1: loss = 0.0113213 (* 1 = 0.0113213 loss)
I0619 08:32:04.465895  8058 sgd_solver.cpp:105] Iteration 116350, lr = 0.0001
I0619 08:33:30.354323  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 08:33:32.035933  8058 solver.cpp:218] Iteration 116400 (0.570983 iter/s, 87.5683s/50 iters), loss = 0.0115977
I0619 08:33:32.036005  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 08:33:32.036031  8058 solver.cpp:237]     Train net output #1: loss = 0.0115978 (* 1 = 0.0115978 loss)
I0619 08:33:32.036048  8058 sgd_solver.cpp:105] Iteration 116400, lr = 0.0001
I0619 08:34:59.606645  8058 solver.cpp:218] Iteration 116450 (0.57098 iter/s, 87.5688s/50 iters), loss = 0.0108148
I0619 08:34:59.606750  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 08:34:59.606778  8058 solver.cpp:237]     Train net output #1: loss = 0.0108149 (* 1 = 0.0108149 loss)
I0619 08:34:59.606796  8058 sgd_solver.cpp:105] Iteration 116450, lr = 0.0001
I0619 08:36:27.147229  8058 solver.cpp:218] Iteration 116500 (0.571176 iter/s, 87.5387s/50 iters), loss = 0.012489
I0619 08:36:27.147339  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 08:36:27.147372  8058 solver.cpp:237]     Train net output #1: loss = 0.012489 (* 1 = 0.012489 loss)
I0619 08:36:27.147392  8058 sgd_solver.cpp:105] Iteration 116500, lr = 0.0001
I0619 08:37:00.474915  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 08:37:54.744153  8058 solver.cpp:218] Iteration 116550 (0.570809 iter/s, 87.595s/50 iters), loss = 0.010702
I0619 08:37:54.744318  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 08:37:54.744348  8058 solver.cpp:237]     Train net output #1: loss = 0.010702 (* 1 = 0.010702 loss)
I0619 08:37:54.744365  8058 sgd_solver.cpp:105] Iteration 116550, lr = 0.0001
I0619 08:39:22.290706  8058 solver.cpp:218] Iteration 116600 (0.571137 iter/s, 87.5446s/50 iters), loss = 0.0106027
I0619 08:39:22.290843  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 08:39:22.290876  8058 solver.cpp:237]     Train net output #1: loss = 0.0106028 (* 1 = 0.0106028 loss)
I0619 08:39:22.290896  8058 sgd_solver.cpp:105] Iteration 116600, lr = 0.0001
I0619 08:40:30.683840  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 08:40:49.846796  8058 solver.cpp:218] Iteration 116650 (0.571075 iter/s, 87.5542s/50 iters), loss = 0.00803767
I0619 08:40:49.846881  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 08:40:49.846909  8058 solver.cpp:237]     Train net output #1: loss = 0.0080377 (* 1 = 0.0080377 loss)
I0619 08:40:49.846926  8058 sgd_solver.cpp:105] Iteration 116650, lr = 0.0001
I0619 08:42:01.684005  8058 solver.cpp:218] Iteration 116700 (0.696036 iter/s, 71.8354s/50 iters), loss = 0.00920285
I0619 08:42:01.684119  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 08:42:01.684147  8058 solver.cpp:237]     Train net output #1: loss = 0.00920288 (* 1 = 0.00920288 loss)
I0619 08:42:01.684165  8058 sgd_solver.cpp:105] Iteration 116700, lr = 0.0001
I0619 08:43:24.788466  8058 solver.cpp:218] Iteration 116750 (0.601658 iter/s, 83.1036s/50 iters), loss = 0.00999352
I0619 08:43:24.788630  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 08:43:24.788661  8058 solver.cpp:237]     Train net output #1: loss = 0.00999355 (* 1 = 0.00999355 loss)
I0619 08:43:24.788679  8058 sgd_solver.cpp:105] Iteration 116750, lr = 0.0001
I0619 08:43:40.685464  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 08:44:52.384457  8058 solver.cpp:218] Iteration 116800 (0.570814 iter/s, 87.5943s/50 iters), loss = 0.00908996
I0619 08:44:52.384603  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 08:44:52.384636  8058 solver.cpp:237]     Train net output #1: loss = 0.00908999 (* 1 = 0.00908999 loss)
I0619 08:44:52.384657  8058 sgd_solver.cpp:105] Iteration 116800, lr = 0.0001
I0619 08:46:19.935616  8058 solver.cpp:218] Iteration 116850 (0.571112 iter/s, 87.5485s/50 iters), loss = 0.0111799
I0619 08:46:19.935755  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 08:46:19.935797  8058 solver.cpp:237]     Train net output #1: loss = 0.01118 (* 1 = 0.01118 loss)
I0619 08:46:19.935816  8058 sgd_solver.cpp:105] Iteration 116850, lr = 0.0001
I0619 08:47:09.170446  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 08:47:47.497284  8058 solver.cpp:218] Iteration 116900 (0.571049 iter/s, 87.5582s/50 iters), loss = 0.0114467
I0619 08:47:47.497396  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 08:47:47.497424  8058 solver.cpp:237]     Train net output #1: loss = 0.0114467 (* 1 = 0.0114467 loss)
I0619 08:47:47.497442  8058 sgd_solver.cpp:105] Iteration 116900, lr = 0.0001
I0619 08:49:15.126629  8058 solver.cpp:218] Iteration 116950 (0.570592 iter/s, 87.6283s/50 iters), loss = 0.0124638
I0619 08:49:15.126727  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 08:49:15.126756  8058 solver.cpp:237]     Train net output #1: loss = 0.0124638 (* 1 = 0.0124638 loss)
I0619 08:49:15.126773  8058 sgd_solver.cpp:105] Iteration 116950, lr = 0.0001
I0619 08:50:39.298540  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 08:50:42.682994  8058 solver.cpp:218] Iteration 117000 (0.571067 iter/s, 87.5553s/50 iters), loss = 0.0130074
I0619 08:50:42.683074  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 08:50:42.683100  8058 solver.cpp:237]     Train net output #1: loss = 0.0130074 (* 1 = 0.0130074 loss)
I0619 08:50:42.683118  8058 sgd_solver.cpp:105] Iteration 117000, lr = 0.0001
I0619 08:51:59.949074  8058 solver.cpp:218] Iteration 117050 (0.64713 iter/s, 77.2642s/50 iters), loss = 0.0114499
I0619 08:51:59.949201  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 08:51:59.949231  8058 solver.cpp:237]     Train net output #1: loss = 0.0114499 (* 1 = 0.0114499 loss)
I0619 08:51:59.949249  8058 sgd_solver.cpp:105] Iteration 117050, lr = 0.0001
I0619 08:53:17.736047  8058 solver.cpp:218] Iteration 117100 (0.642788 iter/s, 77.7862s/50 iters), loss = 0.0094778
I0619 08:53:17.736178  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 08:53:17.736207  8058 solver.cpp:237]     Train net output #1: loss = 0.00947783 (* 1 = 0.00947783 loss)
I0619 08:53:17.736225  8058 sgd_solver.cpp:105] Iteration 117100, lr = 0.0001
I0619 08:53:49.422585  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 08:54:45.342959  8058 solver.cpp:218] Iteration 117150 (0.570737 iter/s, 87.606s/50 iters), loss = 0.0115414
I0619 08:54:45.343077  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 08:54:45.343111  8058 solver.cpp:237]     Train net output #1: loss = 0.0115414 (* 1 = 0.0115414 loss)
I0619 08:54:45.343130  8058 sgd_solver.cpp:105] Iteration 117150, lr = 0.0001
I0619 08:56:12.982966  8058 solver.cpp:218] Iteration 117200 (0.570523 iter/s, 87.639s/50 iters), loss = 0.0107438
I0619 08:56:12.983170  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 08:56:12.983206  8058 solver.cpp:237]     Train net output #1: loss = 0.0107439 (* 1 = 0.0107439 loss)
I0619 08:56:12.983227  8058 sgd_solver.cpp:105] Iteration 117200, lr = 0.0001
I0619 08:57:19.754848  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 08:57:40.582090  8058 solver.cpp:218] Iteration 117250 (0.570788 iter/s, 87.5981s/50 iters), loss = 0.0104072
I0619 08:57:40.582180  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 08:57:40.582212  8058 solver.cpp:237]     Train net output #1: loss = 0.0104072 (* 1 = 0.0104072 loss)
I0619 08:57:40.582233  8058 sgd_solver.cpp:105] Iteration 117250, lr = 0.0001
I0619 08:59:08.232175  8058 solver.cpp:218] Iteration 117300 (0.570457 iter/s, 87.6491s/50 iters), loss = 0.0100033
I0619 08:59:08.232657  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 08:59:08.232692  8058 solver.cpp:237]     Train net output #1: loss = 0.0100033 (* 1 = 0.0100033 loss)
I0619 08:59:08.232713  8058 sgd_solver.cpp:105] Iteration 117300, lr = 0.0001
I0619 09:00:35.821013  8058 solver.cpp:218] Iteration 117350 (0.570861 iter/s, 87.587s/50 iters), loss = 0.0112293
I0619 09:00:35.821161  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 09:00:35.821190  8058 solver.cpp:237]     Train net output #1: loss = 0.0112293 (* 1 = 0.0112293 loss)
I0619 09:00:35.821208  8058 sgd_solver.cpp:105] Iteration 117350, lr = 0.0001
I0619 09:00:49.956324  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 09:02:03.397603  8058 solver.cpp:218] Iteration 117400 (0.570941 iter/s, 87.5747s/50 iters), loss = 0.010515
I0619 09:02:03.397790  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 09:02:03.397822  8058 solver.cpp:237]     Train net output #1: loss = 0.010515 (* 1 = 0.010515 loss)
I0619 09:02:03.397843  8058 sgd_solver.cpp:105] Iteration 117400, lr = 0.0001
I0619 09:03:10.776309  8058 solver.cpp:218] Iteration 117450 (0.742093 iter/s, 67.377s/50 iters), loss = 0.0120303
I0619 09:03:10.776509  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 09:03:10.776545  8058 solver.cpp:237]     Train net output #1: loss = 0.0120304 (* 1 = 0.0120304 loss)
I0619 09:03:10.776563  8058 sgd_solver.cpp:105] Iteration 117450, lr = 0.0001
I0619 09:03:59.916807  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 09:04:38.476198  8058 solver.cpp:218] Iteration 117500 (0.570138 iter/s, 87.6981s/50 iters), loss = 0.0105508
I0619 09:04:38.476333  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 09:04:38.476361  8058 solver.cpp:237]     Train net output #1: loss = 0.0105508 (* 1 = 0.0105508 loss)
I0619 09:04:38.476379  8058 sgd_solver.cpp:105] Iteration 117500, lr = 0.0001
I0619 09:06:06.089993  8058 solver.cpp:218] Iteration 117550 (0.570692 iter/s, 87.6129s/50 iters), loss = 0.0124132
I0619 09:06:06.090198  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 09:06:06.090232  8058 solver.cpp:237]     Train net output #1: loss = 0.0124132 (* 1 = 0.0124132 loss)
I0619 09:06:06.090252  8058 sgd_solver.cpp:105] Iteration 117550, lr = 0.0001
I0619 09:07:30.290143  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 09:07:33.644608  8058 solver.cpp:218] Iteration 117600 (0.571078 iter/s, 87.5537s/50 iters), loss = 0.0106558
I0619 09:07:33.644690  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 09:07:33.644716  8058 solver.cpp:237]     Train net output #1: loss = 0.0106558 (* 1 = 0.0106558 loss)
I0619 09:07:33.644732  8058 sgd_solver.cpp:105] Iteration 117600, lr = 0.0001
I0619 09:09:01.213079  8058 solver.cpp:218] Iteration 117650 (0.570995 iter/s, 87.5665s/50 iters), loss = 0.00849674
I0619 09:09:01.213188  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 09:09:01.213217  8058 solver.cpp:237]     Train net output #1: loss = 0.00849677 (* 1 = 0.00849677 loss)
I0619 09:09:01.213235  8058 sgd_solver.cpp:105] Iteration 117650, lr = 0.0001
I0619 09:10:28.785282  8058 solver.cpp:218] Iteration 117700 (0.570964 iter/s, 87.5712s/50 iters), loss = 0.0114859
I0619 09:10:28.785441  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 09:10:28.785472  8058 solver.cpp:237]     Train net output #1: loss = 0.0114859 (* 1 = 0.0114859 loss)
I0619 09:10:28.785492  8058 sgd_solver.cpp:105] Iteration 117700, lr = 0.0001
I0619 09:11:00.479337  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 09:11:56.399727  8058 solver.cpp:218] Iteration 117750 (0.570713 iter/s, 87.6098s/50 iters), loss = 0.0122756
I0619 09:11:56.399849  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 09:11:56.399878  8058 solver.cpp:237]     Train net output #1: loss = 0.0122756 (* 1 = 0.0122756 loss)
I0619 09:11:56.399896  8058 sgd_solver.cpp:105] Iteration 117750, lr = 0.0001
I0619 09:13:10.301723  8058 solver.cpp:218] Iteration 117800 (0.676581 iter/s, 73.901s/50 iters), loss = 0.0112421
I0619 09:13:10.301853  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 09:13:10.301885  8058 solver.cpp:237]     Train net output #1: loss = 0.0112421 (* 1 = 0.0112421 loss)
I0619 09:13:10.301905  8058 sgd_solver.cpp:105] Iteration 117800, lr = 0.0001
I0619 09:14:10.259095  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 09:14:31.235198  8058 solver.cpp:218] Iteration 117850 (0.617798 iter/s, 80.9326s/50 iters), loss = 0.00985874
I0619 09:14:31.235283  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 09:14:31.235311  8058 solver.cpp:237]     Train net output #1: loss = 0.00985877 (* 1 = 0.00985877 loss)
I0619 09:14:31.235328  8058 sgd_solver.cpp:105] Iteration 117850, lr = 0.0001
I0619 09:15:58.790987  8058 solver.cpp:218] Iteration 117900 (0.571076 iter/s, 87.554s/50 iters), loss = 0.0101882
I0619 09:15:58.791111  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 09:15:58.791141  8058 solver.cpp:237]     Train net output #1: loss = 0.0101883 (* 1 = 0.0101883 loss)
I0619 09:15:58.791158  8058 sgd_solver.cpp:105] Iteration 117900, lr = 0.0001
I0619 09:17:26.350347  8058 solver.cpp:218] Iteration 117950 (0.571053 iter/s, 87.5575s/50 iters), loss = 0.00844445
I0619 09:17:26.350450  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 09:17:26.350477  8058 solver.cpp:237]     Train net output #1: loss = 0.00844449 (* 1 = 0.00844449 loss)
I0619 09:17:26.350495  8058 sgd_solver.cpp:105] Iteration 117950, lr = 0.0001
I0619 09:17:38.703318  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 09:18:53.892542  8058 solver.cpp:218] Iteration 118000 (0.571165 iter/s, 87.5403s/50 iters), loss = 0.0104468
I0619 09:18:53.892680  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 09:18:53.892712  8058 solver.cpp:237]     Train net output #1: loss = 0.0104468 (* 1 = 0.0104468 loss)
I0619 09:18:53.892734  8058 sgd_solver.cpp:105] Iteration 118000, lr = 0.0001
I0619 09:20:21.541330  8058 solver.cpp:218] Iteration 118050 (0.570471 iter/s, 87.6469s/50 iters), loss = 0.0110533
I0619 09:20:21.541447  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 09:20:21.541476  8058 solver.cpp:237]     Train net output #1: loss = 0.0110533 (* 1 = 0.0110533 loss)
I0619 09:20:21.541493  8058 sgd_solver.cpp:105] Iteration 118050, lr = 0.0001
I0619 09:21:08.875746  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 09:21:49.089861  8058 solver.cpp:218] Iteration 118100 (0.571121 iter/s, 87.5471s/50 iters), loss = 0.0115636
I0619 09:21:49.089987  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 09:21:49.090015  8058 solver.cpp:237]     Train net output #1: loss = 0.0115637 (* 1 = 0.0115637 loss)
I0619 09:21:49.090032  8058 sgd_solver.cpp:105] Iteration 118100, lr = 0.0001
I0619 09:23:12.560251  8058 solver.cpp:218] Iteration 118150 (0.599028 iter/s, 83.4686s/50 iters), loss = 0.0140693
I0619 09:23:12.560370  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 09:23:12.560400  8058 solver.cpp:237]     Train net output #1: loss = 0.0140693 (* 1 = 0.0140693 loss)
I0619 09:23:12.560416  8058 sgd_solver.cpp:105] Iteration 118150, lr = 0.0001
I0619 09:24:18.711441  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 09:24:23.919486  8058 solver.cpp:218] Iteration 118200 (0.700687 iter/s, 71.3585s/50 iters), loss = 0.0111943
I0619 09:24:23.919579  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 09:24:23.919606  8058 solver.cpp:237]     Train net output #1: loss = 0.0111943 (* 1 = 0.0111943 loss)
I0619 09:24:23.919623  8058 sgd_solver.cpp:105] Iteration 118200, lr = 0.0001
I0619 09:25:51.580447  8058 solver.cpp:218] Iteration 118250 (0.570385 iter/s, 87.6601s/50 iters), loss = 0.00989439
I0619 09:25:51.580579  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 09:25:51.580612  8058 solver.cpp:237]     Train net output #1: loss = 0.00989442 (* 1 = 0.00989442 loss)
I0619 09:25:51.580632  8058 sgd_solver.cpp:105] Iteration 118250, lr = 0.0001
I0619 09:27:19.183539  8058 solver.cpp:218] Iteration 118300 (0.570769 iter/s, 87.6012s/50 iters), loss = 0.0102193
I0619 09:27:19.183650  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 09:27:19.183677  8058 solver.cpp:237]     Train net output #1: loss = 0.0102194 (* 1 = 0.0102194 loss)
I0619 09:27:19.183706  8058 sgd_solver.cpp:105] Iteration 118300, lr = 0.0001
I0619 09:27:49.175814  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 09:28:46.827374  8058 solver.cpp:218] Iteration 118350 (0.570503 iter/s, 87.6419s/50 iters), loss = 0.0116744
I0619 09:28:46.827502  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 09:28:46.827539  8058 solver.cpp:237]     Train net output #1: loss = 0.0116745 (* 1 = 0.0116745 loss)
I0619 09:28:46.827558  8058 sgd_solver.cpp:105] Iteration 118350, lr = 0.0001
I0619 09:30:14.490466  8058 solver.cpp:218] Iteration 118400 (0.570372 iter/s, 87.6621s/50 iters), loss = 0.0108635
I0619 09:30:14.490653  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 09:30:14.490681  8058 solver.cpp:237]     Train net output #1: loss = 0.0108635 (* 1 = 0.0108635 loss)
I0619 09:30:14.490698  8058 sgd_solver.cpp:105] Iteration 118400, lr = 0.0001
I0619 09:31:19.396482  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 09:31:42.191987  8058 solver.cpp:218] Iteration 118450 (0.570122 iter/s, 87.7005s/50 iters), loss = 0.0103434
I0619 09:31:42.192059  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 09:31:42.192086  8058 solver.cpp:237]     Train net output #1: loss = 0.0103434 (* 1 = 0.0103434 loss)
I0619 09:31:42.192104  8058 sgd_solver.cpp:105] Iteration 118450, lr = 0.0001
I0619 09:33:09.826611  8058 solver.cpp:218] Iteration 118500 (0.570556 iter/s, 87.6338s/50 iters), loss = 0.0105512
I0619 09:33:09.826737  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 09:33:09.826766  8058 solver.cpp:237]     Train net output #1: loss = 0.0105513 (* 1 = 0.0105513 loss)
I0619 09:33:09.826787  8058 sgd_solver.cpp:105] Iteration 118500, lr = 0.0001
I0619 09:34:22.069587  8058 solver.cpp:218] Iteration 118550 (0.692117 iter/s, 72.2421s/50 iters), loss = 0.0091908
I0619 09:34:22.069705  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 09:34:22.069735  8058 solver.cpp:237]     Train net output #1: loss = 0.00919084 (* 1 = 0.00919084 loss)
I0619 09:34:22.069751  8058 sgd_solver.cpp:105] Iteration 118550, lr = 0.0001
I0619 09:34:30.234778  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 09:35:44.732301  8058 solver.cpp:218] Iteration 118600 (0.604873 iter/s, 82.6619s/50 iters), loss = 0.0107961
I0619 09:35:44.732424  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 09:35:44.732451  8058 solver.cpp:237]     Train net output #1: loss = 0.0107961 (* 1 = 0.0107961 loss)
I0619 09:35:44.732468  8058 sgd_solver.cpp:105] Iteration 118600, lr = 0.0001
I0619 09:37:12.329274  8058 solver.cpp:218] Iteration 118650 (0.570802 iter/s, 87.5961s/50 iters), loss = 0.0102928
I0619 09:37:12.329392  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 09:37:12.329421  8058 solver.cpp:237]     Train net output #1: loss = 0.0102928 (* 1 = 0.0102928 loss)
I0619 09:37:12.329438  8058 sgd_solver.cpp:105] Iteration 118650, lr = 0.0001
I0619 09:37:59.853938  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 09:38:40.060722  8058 solver.cpp:218] Iteration 118700 (0.569927 iter/s, 87.7305s/50 iters), loss = 0.0129689
I0619 09:38:40.060837  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 09:38:40.060864  8058 solver.cpp:237]     Train net output #1: loss = 0.012969 (* 1 = 0.012969 loss)
I0619 09:38:40.060881  8058 sgd_solver.cpp:105] Iteration 118700, lr = 0.0001
I0619 09:40:07.727064  8058 solver.cpp:218] Iteration 118750 (0.570356 iter/s, 87.6645s/50 iters), loss = 0.0118739
I0619 09:40:07.727205  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 09:40:07.727233  8058 solver.cpp:237]     Train net output #1: loss = 0.0118739 (* 1 = 0.0118739 loss)
I0619 09:40:07.727252  8058 sgd_solver.cpp:105] Iteration 118750, lr = 0.0001
I0619 09:41:30.123539  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 09:41:35.327613  8058 solver.cpp:218] Iteration 118800 (0.570785 iter/s, 87.5987s/50 iters), loss = 0.00971652
I0619 09:41:35.327710  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 09:41:35.327736  8058 solver.cpp:237]     Train net output #1: loss = 0.00971656 (* 1 = 0.00971656 loss)
I0619 09:41:35.327754  8058 sgd_solver.cpp:105] Iteration 118800, lr = 0.0001
I0619 09:43:02.904934  8058 solver.cpp:218] Iteration 118850 (0.570936 iter/s, 87.5755s/50 iters), loss = 0.0124308
I0619 09:43:02.905061  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 09:43:02.905089  8058 solver.cpp:237]     Train net output #1: loss = 0.0124308 (* 1 = 0.0124308 loss)
I0619 09:43:02.905110  8058 sgd_solver.cpp:105] Iteration 118850, lr = 0.0001
I0619 09:44:20.560272  8058 solver.cpp:218] Iteration 118900 (0.643885 iter/s, 77.6536s/50 iters), loss = 0.0102622
I0619 09:44:20.560389  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 09:44:20.560418  8058 solver.cpp:237]     Train net output #1: loss = 0.0102623 (* 1 = 0.0102623 loss)
I0619 09:44:20.560436  8058 sgd_solver.cpp:105] Iteration 118900, lr = 0.0001
I0619 09:44:44.437647  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 09:45:37.696254  8058 solver.cpp:218] Iteration 118950 (0.648212 iter/s, 77.1352s/50 iters), loss = 0.0120573
I0619 09:45:37.696373  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 09:45:37.696403  8058 solver.cpp:237]     Train net output #1: loss = 0.0120573 (* 1 = 0.0120573 loss)
I0619 09:45:37.696419  8058 sgd_solver.cpp:105] Iteration 118950, lr = 0.0001
I0619 09:47:05.241248  8058 solver.cpp:218] Iteration 119000 (0.571147 iter/s, 87.5431s/50 iters), loss = 0.00989672
I0619 09:47:05.241441  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 09:47:05.241470  8058 solver.cpp:237]     Train net output #1: loss = 0.00989675 (* 1 = 0.00989675 loss)
I0619 09:47:05.241488  8058 sgd_solver.cpp:105] Iteration 119000, lr = 0.0001
I0619 09:48:08.438004  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 09:48:32.773164  8058 solver.cpp:218] Iteration 119050 (0.571232 iter/s, 87.53s/50 iters), loss = 0.0102662
I0619 09:48:32.773252  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 09:48:32.773279  8058 solver.cpp:237]     Train net output #1: loss = 0.0102662 (* 1 = 0.0102662 loss)
I0619 09:48:32.773298  8058 sgd_solver.cpp:105] Iteration 119050, lr = 0.0001
I0619 09:49:45.879887  8058 solver.cpp:218] Iteration 119100 (0.683948 iter/s, 73.105s/50 iters), loss = 0.0145726
I0619 09:49:45.880020  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 09:49:45.880048  8058 solver.cpp:237]     Train net output #1: loss = 0.0145726 (* 1 = 0.0145726 loss)
I0619 09:49:45.880065  8058 sgd_solver.cpp:105] Iteration 119100, lr = 0.0001
I0619 09:50:43.645673  8058 solver.cpp:218] Iteration 119150 (0.865574 iter/s, 57.7651s/50 iters), loss = 0.0103471
I0619 09:50:43.645840  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 09:50:43.645870  8058 solver.cpp:237]     Train net output #1: loss = 0.0103472 (* 1 = 0.0103472 loss)
I0619 09:50:43.645887  8058 sgd_solver.cpp:105] Iteration 119150, lr = 0.0001
I0619 09:50:50.653286  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 09:51:41.410521  8058 solver.cpp:218] Iteration 119200 (0.865588 iter/s, 57.7642s/50 iters), loss = 0.0116435
I0619 09:51:41.410657  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 09:51:41.410686  8058 solver.cpp:237]     Train net output #1: loss = 0.0116435 (* 1 = 0.0116435 loss)
I0619 09:51:41.410704  8058 sgd_solver.cpp:105] Iteration 119200, lr = 0.0001
I0619 09:52:39.157676  8058 solver.cpp:218] Iteration 119250 (0.865853 iter/s, 57.7465s/50 iters), loss = 0.00859281
I0619 09:52:39.157802  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 09:52:39.157831  8058 solver.cpp:237]     Train net output #1: loss = 0.00859284 (* 1 = 0.00859284 loss)
I0619 09:52:39.157850  8058 sgd_solver.cpp:105] Iteration 119250, lr = 0.0001
I0619 09:53:09.282851  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 09:53:36.918640  8058 solver.cpp:218] Iteration 119300 (0.865646 iter/s, 57.7603s/50 iters), loss = 0.00851821
I0619 09:53:36.918716  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 09:53:36.918743  8058 solver.cpp:237]     Train net output #1: loss = 0.00851825 (* 1 = 0.00851825 loss)
I0619 09:53:36.918761  8058 sgd_solver.cpp:105] Iteration 119300, lr = 0.0001
I0619 09:54:34.684875  8058 solver.cpp:218] Iteration 119350 (0.865566 iter/s, 57.7657s/50 iters), loss = 0.00958479
I0619 09:54:34.684988  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 09:54:34.685016  8058 solver.cpp:237]     Train net output #1: loss = 0.00958482 (* 1 = 0.00958482 loss)
I0619 09:54:34.685034  8058 sgd_solver.cpp:105] Iteration 119350, lr = 0.0001
I0619 09:55:31.633528  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 09:55:38.585921  8058 solver.cpp:218] Iteration 119400 (0.782468 iter/s, 63.9004s/50 iters), loss = 0.0112467
I0619 09:55:38.586001  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 09:55:38.586028  8058 solver.cpp:237]     Train net output #1: loss = 0.0112468 (* 1 = 0.0112468 loss)
I0619 09:55:38.586046  8058 sgd_solver.cpp:105] Iteration 119400, lr = 0.0001
I0619 09:57:06.140542  8058 solver.cpp:218] Iteration 119450 (0.571078 iter/s, 87.5537s/50 iters), loss = 0.00970711
I0619 09:57:06.140666  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 09:57:06.140698  8058 solver.cpp:237]     Train net output #1: loss = 0.00970714 (* 1 = 0.00970714 loss)
I0619 09:57:06.140718  8058 sgd_solver.cpp:105] Iteration 119450, lr = 0.0001
I0619 09:58:33.686343  8058 solver.cpp:218] Iteration 119500 (0.571136 iter/s, 87.5449s/50 iters), loss = 0.00827397
I0619 09:58:33.686511  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 09:58:33.686549  8058 solver.cpp:237]     Train net output #1: loss = 0.008274 (* 1 = 0.008274 loss)
I0619 09:58:33.686566  8058 sgd_solver.cpp:105] Iteration 119500, lr = 0.0001
I0619 09:59:01.757261  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 10:00:01.229555  8058 solver.cpp:218] Iteration 119550 (0.571154 iter/s, 87.5421s/50 iters), loss = 0.0123485
I0619 10:00:01.229671  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 10:00:01.229698  8058 solver.cpp:237]     Train net output #1: loss = 0.0123486 (* 1 = 0.0123486 loss)
I0619 10:00:01.229717  8058 sgd_solver.cpp:105] Iteration 119550, lr = 0.0001
I0619 10:01:28.778553  8058 solver.cpp:218] Iteration 119600 (0.571115 iter/s, 87.548s/50 iters), loss = 0.0103822
I0619 10:01:28.778705  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 10:01:28.778733  8058 solver.cpp:237]     Train net output #1: loss = 0.0103822 (* 1 = 0.0103822 loss)
I0619 10:01:28.778750  8058 sgd_solver.cpp:105] Iteration 119600, lr = 0.0001
I0619 10:02:31.957553  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 10:02:56.387423  8058 solver.cpp:218] Iteration 119650 (0.570725 iter/s, 87.6078s/50 iters), loss = 0.0108495
I0619 10:02:56.387503  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 10:02:56.387538  8058 solver.cpp:237]     Train net output #1: loss = 0.0108495 (* 1 = 0.0108495 loss)
I0619 10:02:56.387557  8058 sgd_solver.cpp:105] Iteration 119650, lr = 0.0001
I0619 10:04:23.943709  8058 solver.cpp:218] Iteration 119700 (0.571081 iter/s, 87.5532s/50 iters), loss = 0.0112836
I0619 10:04:23.943836  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 10:04:23.943868  8058 solver.cpp:237]     Train net output #1: loss = 0.0112836 (* 1 = 0.0112836 loss)
I0619 10:04:23.943888  8058 sgd_solver.cpp:105] Iteration 119700, lr = 0.0001
I0619 10:05:37.516664  8058 solver.cpp:218] Iteration 119750 (0.679605 iter/s, 73.5722s/50 iters), loss = 0.00945447
I0619 10:05:37.516798  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 10:05:37.516827  8058 solver.cpp:237]     Train net output #1: loss = 0.0094545 (* 1 = 0.0094545 loss)
I0619 10:05:37.516845  8058 sgd_solver.cpp:105] Iteration 119750, lr = 0.0001
I0619 10:05:44.524775  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 10:07:00.840796  8058 solver.cpp:218] Iteration 119800 (0.600072 iter/s, 83.3233s/50 iters), loss = 0.0114904
I0619 10:07:00.840939  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 10:07:00.840967  8058 solver.cpp:237]     Train net output #1: loss = 0.0114905 (* 1 = 0.0114905 loss)
I0619 10:07:00.840984  8058 sgd_solver.cpp:105] Iteration 119800, lr = 0.0001
I0619 10:08:28.480442  8058 solver.cpp:218] Iteration 119850 (0.57053 iter/s, 87.6378s/50 iters), loss = 0.0109175
I0619 10:08:28.480578  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 10:08:28.480612  8058 solver.cpp:237]     Train net output #1: loss = 0.0109175 (* 1 = 0.0109175 loss)
I0619 10:08:28.480631  8058 sgd_solver.cpp:105] Iteration 119850, lr = 0.0001
I0619 10:09:12.421640  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 10:09:56.107058  8058 solver.cpp:218] Iteration 119900 (0.570615 iter/s, 87.6247s/50 iters), loss = 0.0109614
I0619 10:09:56.107209  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 10:09:56.107239  8058 solver.cpp:237]     Train net output #1: loss = 0.0109614 (* 1 = 0.0109614 loss)
I0619 10:09:56.107255  8058 sgd_solver.cpp:105] Iteration 119900, lr = 0.0001
I0619 10:11:23.645531  8058 solver.cpp:218] Iteration 119950 (0.571184 iter/s, 87.5375s/50 iters), loss = 0.0103125
I0619 10:11:23.645659  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 10:11:23.645691  8058 solver.cpp:237]     Train net output #1: loss = 0.0103125 (* 1 = 0.0103125 loss)
I0619 10:11:23.645711  8058 sgd_solver.cpp:105] Iteration 119950, lr = 0.0001
I0619 10:12:42.520349  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 10:12:49.477885  8058 solver.cpp:447] Snapshotting to binary proto file mobilenet/mobile_cub_iter_120000.caffemodel
I0619 10:12:49.564229  8058 sgd_solver.cpp:273] Snapshotting solver state to binary proto file mobilenet/mobile_cub_iter_120000.solverstate
I0619 10:12:51.296928  8058 solver.cpp:218] Iteration 120000 (0.570448 iter/s, 87.6504s/50 iters), loss = 0.00918879
I0619 10:12:51.297001  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 10:12:51.297025  8058 solver.cpp:237]     Train net output #1: loss = 0.00918882 (* 1 = 0.00918882 loss)
I0619 10:12:51.297041  8058 sgd_solver.cpp:105] Iteration 120000, lr = 0.0001
I0619 10:14:19.002893  8058 solver.cpp:218] Iteration 120050 (0.570099 iter/s, 87.704s/50 iters), loss = 0.0105589
I0619 10:14:19.003026  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 10:14:19.003053  8058 solver.cpp:237]     Train net output #1: loss = 0.0105589 (* 1 = 0.0105589 loss)
I0619 10:14:19.003070  8058 sgd_solver.cpp:105] Iteration 120050, lr = 0.0001
I0619 10:15:35.666559  8058 solver.cpp:218] Iteration 120100 (0.652215 iter/s, 76.6619s/50 iters), loss = 0.013094
I0619 10:15:35.666760  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 10:15:35.666790  8058 solver.cpp:237]     Train net output #1: loss = 0.013094 (* 1 = 0.013094 loss)
I0619 10:15:35.666807  8058 sgd_solver.cpp:105] Iteration 120100, lr = 0.0001
I0619 10:15:59.695411  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 10:16:55.975355  8058 solver.cpp:218] Iteration 120150 (0.622604 iter/s, 80.3079s/50 iters), loss = 0.0116079
I0619 10:16:55.975498  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 10:16:55.975533  8058 solver.cpp:237]     Train net output #1: loss = 0.0116079 (* 1 = 0.0116079 loss)
I0619 10:16:55.975551  8058 sgd_solver.cpp:105] Iteration 120150, lr = 0.0001
I0619 10:18:23.561015  8058 solver.cpp:218] Iteration 120200 (0.570877 iter/s, 87.5845s/50 iters), loss = 0.0096053
I0619 10:18:23.561137  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 10:18:23.561168  8058 solver.cpp:237]     Train net output #1: loss = 0.00960533 (* 1 = 0.00960533 loss)
I0619 10:18:23.561189  8058 sgd_solver.cpp:105] Iteration 120200, lr = 0.0001
I0619 10:19:25.032457  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 10:19:51.174192  8058 solver.cpp:218] Iteration 120250 (0.570697 iter/s, 87.6122s/50 iters), loss = 0.0084222
I0619 10:19:51.174269  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 10:19:51.174296  8058 solver.cpp:237]     Train net output #1: loss = 0.00842223 (* 1 = 0.00842223 loss)
I0619 10:19:51.174312  8058 sgd_solver.cpp:105] Iteration 120250, lr = 0.0001
I0619 10:21:18.727123  8058 solver.cpp:218] Iteration 120300 (0.571096 iter/s, 87.551s/50 iters), loss = 0.0105861
I0619 10:21:18.727277  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 10:21:18.727306  8058 solver.cpp:237]     Train net output #1: loss = 0.0105861 (* 1 = 0.0105861 loss)
I0619 10:21:18.727324  8058 sgd_solver.cpp:105] Iteration 120300, lr = 0.0001
I0619 10:22:46.245587  8058 solver.cpp:218] Iteration 120350 (0.571315 iter/s, 87.5174s/50 iters), loss = 0.0110522
I0619 10:22:46.245745  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 10:22:46.245774  8058 solver.cpp:237]     Train net output #1: loss = 0.0110522 (* 1 = 0.0110522 loss)
I0619 10:22:46.245790  8058 sgd_solver.cpp:105] Iteration 120350, lr = 0.0001
I0619 10:22:55.119874  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 10:24:13.891935  8058 solver.cpp:218] Iteration 120400 (0.570481 iter/s, 87.6453s/50 iters), loss = 0.010126
I0619 10:24:13.892083  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 10:24:13.892112  8058 solver.cpp:237]     Train net output #1: loss = 0.010126 (* 1 = 0.010126 loss)
I0619 10:24:13.892129  8058 sgd_solver.cpp:105] Iteration 120400, lr = 0.0001
I0619 10:25:40.541072  8058 solver.cpp:218] Iteration 120450 (0.577052 iter/s, 86.6473s/50 iters), loss = 0.00776128
I0619 10:25:40.541893  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 10:25:40.541926  8058 solver.cpp:237]     Train net output #1: loss = 0.00776131 (* 1 = 0.00776131 loss)
I0619 10:25:40.541947  8058 sgd_solver.cpp:105] Iteration 120450, lr = 0.0001
I0619 10:26:13.378271  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 10:26:50.777580  8058 solver.cpp:218] Iteration 120500 (0.711895 iter/s, 70.2351s/50 iters), loss = 0.0112448
I0619 10:26:50.777703  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 10:26:50.777730  8058 solver.cpp:237]     Train net output #1: loss = 0.0112448 (* 1 = 0.0112448 loss)
I0619 10:26:50.777748  8058 sgd_solver.cpp:105] Iteration 120500, lr = 0.0001
I0619 10:28:18.341351  8058 solver.cpp:218] Iteration 120550 (0.571025 iter/s, 87.5619s/50 iters), loss = 0.00885324
I0619 10:28:18.341533  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 10:28:18.341564  8058 solver.cpp:237]     Train net output #1: loss = 0.00885327 (* 1 = 0.00885327 loss)
I0619 10:28:18.341580  8058 sgd_solver.cpp:105] Iteration 120550, lr = 0.0001
I0619 10:29:37.280678  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 10:29:45.864078  8058 solver.cpp:218] Iteration 120600 (0.571287 iter/s, 87.5216s/50 iters), loss = 0.00891084
I0619 10:29:45.864174  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 10:29:45.864200  8058 solver.cpp:237]     Train net output #1: loss = 0.00891087 (* 1 = 0.00891087 loss)
I0619 10:29:45.864217  8058 sgd_solver.cpp:105] Iteration 120600, lr = 0.0001
I0619 10:31:13.455693  8058 solver.cpp:218] Iteration 120650 (0.570843 iter/s, 87.5898s/50 iters), loss = 0.00976232
I0619 10:31:13.455829  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 10:31:13.455858  8058 solver.cpp:237]     Train net output #1: loss = 0.00976235 (* 1 = 0.00976235 loss)
I0619 10:31:13.455875  8058 sgd_solver.cpp:105] Iteration 120650, lr = 0.0001
I0619 10:32:41.020206  8058 solver.cpp:218] Iteration 120700 (0.571014 iter/s, 87.5636s/50 iters), loss = 0.0104207
I0619 10:32:41.020323  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 10:32:41.020349  8058 solver.cpp:237]     Train net output #1: loss = 0.0104208 (* 1 = 0.0104208 loss)
I0619 10:32:41.020380  8058 sgd_solver.cpp:105] Iteration 120700, lr = 0.0001
I0619 10:33:07.402382  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 10:34:08.608454  8058 solver.cpp:218] Iteration 120750 (0.570865 iter/s, 87.5863s/50 iters), loss = 0.0130066
I0619 10:34:08.608603  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 10:34:08.608633  8058 solver.cpp:237]     Train net output #1: loss = 0.0130066 (* 1 = 0.0130066 loss)
I0619 10:34:08.608654  8058 sgd_solver.cpp:105] Iteration 120750, lr = 0.0001
I0619 10:35:36.208904  8058 solver.cpp:218] Iteration 120800 (0.57078 iter/s, 87.5995s/50 iters), loss = 0.0116936
I0619 10:35:36.209015  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 10:35:36.209043  8058 solver.cpp:237]     Train net output #1: loss = 0.0116936 (* 1 = 0.0116936 loss)
I0619 10:35:36.209060  8058 sgd_solver.cpp:105] Iteration 120800, lr = 0.0001
I0619 10:36:26.198046  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 10:36:49.730783  8058 solver.cpp:218] Iteration 120850 (0.680077 iter/s, 73.5211s/50 iters), loss = 0.0116067
I0619 10:36:49.730859  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 10:36:49.730885  8058 solver.cpp:237]     Train net output #1: loss = 0.0116067 (* 1 = 0.0116067 loss)
I0619 10:36:49.730901  8058 sgd_solver.cpp:105] Iteration 120850, lr = 0.0001
I0619 10:38:13.062826  8058 solver.cpp:218] Iteration 120900 (0.600015 iter/s, 83.3313s/50 iters), loss = 0.0105701
I0619 10:38:13.062942  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 10:38:13.062969  8058 solver.cpp:237]     Train net output #1: loss = 0.0105701 (* 1 = 0.0105701 loss)
I0619 10:38:13.062988  8058 sgd_solver.cpp:105] Iteration 120900, lr = 0.0001
I0619 10:39:40.736703  8058 solver.cpp:218] Iteration 120950 (0.570307 iter/s, 87.672s/50 iters), loss = 0.0134361
I0619 10:39:40.736819  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 10:39:40.736848  8058 solver.cpp:237]     Train net output #1: loss = 0.0134361 (* 1 = 0.0134361 loss)
I0619 10:39:40.736868  8058 sgd_solver.cpp:105] Iteration 120950, lr = 0.0001
I0619 10:39:47.861811  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 10:41:08.371640  8058 solver.cpp:218] Iteration 121000 (0.570561 iter/s, 87.633s/50 iters), loss = 0.00936141
I0619 10:41:08.371744  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 10:41:08.371772  8058 solver.cpp:237]     Train net output #1: loss = 0.00936144 (* 1 = 0.00936144 loss)
I0619 10:41:08.371788  8058 sgd_solver.cpp:105] Iteration 121000, lr = 0.0001
I0619 10:42:36.026345  8058 solver.cpp:218] Iteration 121050 (0.570444 iter/s, 87.651s/50 iters), loss = 0.00859775
I0619 10:42:36.026536  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 10:42:36.026568  8058 solver.cpp:237]     Train net output #1: loss = 0.00859778 (* 1 = 0.00859778 loss)
I0619 10:42:36.026585  8058 sgd_solver.cpp:105] Iteration 121050, lr = 0.0001
I0619 10:43:18.184834  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 10:44:03.582713  8058 solver.cpp:218] Iteration 121100 (0.571067 iter/s, 87.5554s/50 iters), loss = 0.0105343
I0619 10:44:03.582841  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 10:44:03.582871  8058 solver.cpp:237]     Train net output #1: loss = 0.0105343 (* 1 = 0.0105343 loss)
I0619 10:44:03.582893  8058 sgd_solver.cpp:105] Iteration 121100, lr = 0.0001
I0619 10:45:31.125681  8058 solver.cpp:218] Iteration 121150 (0.571155 iter/s, 87.5419s/50 iters), loss = 0.0142619
I0619 10:45:31.125790  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 10:45:31.125818  8058 solver.cpp:237]     Train net output #1: loss = 0.0142619 (* 1 = 0.0142619 loss)
I0619 10:45:31.125834  8058 sgd_solver.cpp:105] Iteration 121150, lr = 0.0001
I0619 10:46:41.054292  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 10:46:47.922647  8058 solver.cpp:218] Iteration 121200 (0.651083 iter/s, 76.7951s/50 iters), loss = 0.0119557
I0619 10:46:47.922747  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 10:46:47.922775  8058 solver.cpp:237]     Train net output #1: loss = 0.0119558 (* 1 = 0.0119558 loss)
I0619 10:46:47.922792  8058 sgd_solver.cpp:105] Iteration 121200, lr = 0.0001
I0619 10:48:08.019487  8058 solver.cpp:218] Iteration 121250 (0.62425 iter/s, 80.0961s/50 iters), loss = 0.0110759
I0619 10:48:08.019626  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 10:48:08.019656  8058 solver.cpp:237]     Train net output #1: loss = 0.011076 (* 1 = 0.011076 loss)
I0619 10:48:08.019672  8058 sgd_solver.cpp:105] Iteration 121250, lr = 0.0001
I0619 10:49:35.565717  8058 solver.cpp:218] Iteration 121300 (0.571139 iter/s, 87.5444s/50 iters), loss = 0.0124566
I0619 10:49:35.565840  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 10:49:35.565870  8058 solver.cpp:237]     Train net output #1: loss = 0.0124566 (* 1 = 0.0124566 loss)
I0619 10:49:35.565886  8058 sgd_solver.cpp:105] Iteration 121300, lr = 0.0001
I0619 10:50:00.172091  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 10:51:03.170177  8058 solver.cpp:218] Iteration 121350 (0.570759 iter/s, 87.6026s/50 iters), loss = 0.0102302
I0619 10:51:03.170285  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 10:51:03.170317  8058 solver.cpp:237]     Train net output #1: loss = 0.0102303 (* 1 = 0.0102303 loss)
I0619 10:51:03.170338  8058 sgd_solver.cpp:105] Iteration 121350, lr = 0.0001
I0619 10:52:30.713110  8058 solver.cpp:218] Iteration 121400 (0.571161 iter/s, 87.541s/50 iters), loss = 0.0115454
I0619 10:52:30.713241  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 10:52:30.713270  8058 solver.cpp:237]     Train net output #1: loss = 0.0115454 (* 1 = 0.0115454 loss)
I0619 10:52:30.713289  8058 sgd_solver.cpp:105] Iteration 121400, lr = 0.0001
I0619 10:53:30.304347  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 10:53:58.318431  8058 solver.cpp:218] Iteration 121450 (0.570754 iter/s, 87.6034s/50 iters), loss = 0.00876319
I0619 10:53:58.318521  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 10:53:58.318550  8058 solver.cpp:237]     Train net output #1: loss = 0.00876322 (* 1 = 0.00876322 loss)
I0619 10:53:58.318567  8058 sgd_solver.cpp:105] Iteration 121450, lr = 0.0001
I0619 10:55:25.962213  8058 solver.cpp:218] Iteration 121500 (0.570504 iter/s, 87.6418s/50 iters), loss = 0.0104837
I0619 10:55:25.962343  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 10:55:25.962373  8058 solver.cpp:237]     Train net output #1: loss = 0.0104838 (* 1 = 0.0104838 loss)
I0619 10:55:25.962390  8058 sgd_solver.cpp:105] Iteration 121500, lr = 0.0001
I0619 10:56:52.956595  8058 solver.cpp:218] Iteration 121550 (0.574762 iter/s, 86.9925s/50 iters), loss = 0.0121785
I0619 10:56:52.956766  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 10:56:52.956795  8058 solver.cpp:237]     Train net output #1: loss = 0.0121785 (* 1 = 0.0121785 loss)
I0619 10:56:52.956811  8058 sgd_solver.cpp:105] Iteration 121550, lr = 0.0001
I0619 10:56:57.660193  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 10:58:02.838644  8058 solver.cpp:218] Iteration 121600 (0.715501 iter/s, 69.8811s/50 iters), loss = 0.0102994
I0619 10:58:02.838780  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 10:58:02.838816  8058 solver.cpp:237]     Train net output #1: loss = 0.0102994 (* 1 = 0.0102994 loss)
I0619 10:58:02.838837  8058 sgd_solver.cpp:105] Iteration 121600, lr = 0.0001
I0619 10:59:30.475718  8058 solver.cpp:218] Iteration 121650 (0.570548 iter/s, 87.635s/50 iters), loss = 0.0116105
I0619 10:59:30.475847  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 10:59:30.475875  8058 solver.cpp:237]     Train net output #1: loss = 0.0116105 (* 1 = 0.0116105 loss)
I0619 10:59:30.475891  8058 sgd_solver.cpp:105] Iteration 121650, lr = 0.0001
I0619 11:00:12.632017  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 11:00:58.104496  8058 solver.cpp:218] Iteration 121700 (0.570605 iter/s, 87.6263s/50 iters), loss = 0.0103704
I0619 11:00:58.104648  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 11:00:58.104677  8058 solver.cpp:237]     Train net output #1: loss = 0.0103704 (* 1 = 0.0103704 loss)
I0619 11:00:58.104694  8058 sgd_solver.cpp:105] Iteration 121700, lr = 0.0001
I0619 11:02:25.694298  8058 solver.cpp:218] Iteration 121750 (0.570856 iter/s, 87.5877s/50 iters), loss = 0.0109261
I0619 11:02:25.694416  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 11:02:25.694443  8058 solver.cpp:237]     Train net output #1: loss = 0.0109262 (* 1 = 0.0109262 loss)
I0619 11:02:25.694460  8058 sgd_solver.cpp:105] Iteration 121750, lr = 0.0001
I0619 11:03:42.819977  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 11:03:53.263684  8058 solver.cpp:218] Iteration 121800 (0.570989 iter/s, 87.5673s/50 iters), loss = 0.0125548
I0619 11:03:53.263782  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 11:03:53.263808  8058 solver.cpp:237]     Train net output #1: loss = 0.0125548 (* 1 = 0.0125548 loss)
I0619 11:03:53.263825  8058 sgd_solver.cpp:105] Iteration 121800, lr = 0.0001
I0619 11:05:20.854931  8058 solver.cpp:218] Iteration 121850 (0.570841 iter/s, 87.5901s/50 iters), loss = 0.0114434
I0619 11:05:20.855168  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 11:05:20.855199  8058 solver.cpp:237]     Train net output #1: loss = 0.0114435 (* 1 = 0.0114435 loss)
I0619 11:05:20.855218  8058 sgd_solver.cpp:105] Iteration 121850, lr = 0.0001
I0619 11:06:48.446346  8058 solver.cpp:218] Iteration 121900 (0.570845 iter/s, 87.5894s/50 iters), loss = 0.0122025
I0619 11:06:48.446466  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 11:06:48.446494  8058 solver.cpp:237]     Train net output #1: loss = 0.0122026 (* 1 = 0.0122026 loss)
I0619 11:06:48.446517  8058 sgd_solver.cpp:105] Iteration 121900, lr = 0.0001
I0619 11:07:11.266024  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 11:08:02.766396  8058 solver.cpp:218] Iteration 121950 (0.672787 iter/s, 74.3177s/50 iters), loss = 0.0119464
I0619 11:08:02.766654  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 11:08:02.766687  8058 solver.cpp:237]     Train net output #1: loss = 0.0119464 (* 1 = 0.0119464 loss)
I0619 11:08:02.766708  8058 sgd_solver.cpp:105] Iteration 121950, lr = 0.0001
I0619 11:09:25.292937  8058 solver.cpp:218] Iteration 122000 (0.605874 iter/s, 82.5254s/50 iters), loss = 0.0117865
I0619 11:09:25.293053  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 11:09:25.293082  8058 solver.cpp:237]     Train net output #1: loss = 0.0117865 (* 1 = 0.0117865 loss)
I0619 11:09:25.293099  8058 sgd_solver.cpp:105] Iteration 122000, lr = 0.0001
I0619 11:10:23.157464  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 11:10:52.837231  8058 solver.cpp:218] Iteration 122050 (0.571153 iter/s, 87.5423s/50 iters), loss = 0.0125245
I0619 11:10:52.837321  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 11:10:52.837348  8058 solver.cpp:237]     Train net output #1: loss = 0.0125245 (* 1 = 0.0125245 loss)
I0619 11:10:52.837365  8058 sgd_solver.cpp:105] Iteration 122050, lr = 0.0001
I0619 11:12:20.398859  8058 solver.cpp:218] Iteration 122100 (0.571041 iter/s, 87.5594s/50 iters), loss = 0.00958888
I0619 11:12:20.398989  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 11:12:20.399018  8058 solver.cpp:237]     Train net output #1: loss = 0.00958891 (* 1 = 0.00958891 loss)
I0619 11:12:20.399035  8058 sgd_solver.cpp:105] Iteration 122100, lr = 0.0001
I0619 11:13:47.954381  8058 solver.cpp:218] Iteration 122150 (0.57108 iter/s, 87.5534s/50 iters), loss = 0.0142758
I0619 11:13:47.954555  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 11:13:47.954586  8058 solver.cpp:237]     Train net output #1: loss = 0.0142759 (* 1 = 0.0142759 loss)
I0619 11:13:47.954613  8058 sgd_solver.cpp:105] Iteration 122150, lr = 0.0001
I0619 11:13:53.278934  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 11:15:15.517074  8058 solver.cpp:218] Iteration 122200 (0.571034 iter/s, 87.5605s/50 iters), loss = 0.00928273
I0619 11:15:15.517199  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 11:15:15.517227  8058 solver.cpp:237]     Train net output #1: loss = 0.00928276 (* 1 = 0.00928276 loss)
I0619 11:15:15.517244  8058 sgd_solver.cpp:105] Iteration 122200, lr = 0.0001
I0619 11:16:43.065621  8058 solver.cpp:218] Iteration 122250 (0.571125 iter/s, 87.5465s/50 iters), loss = 0.0119204
I0619 11:16:43.065800  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 11:16:43.065831  8058 solver.cpp:237]     Train net output #1: loss = 0.0119204 (* 1 = 0.0119204 loss)
I0619 11:16:43.065852  8058 sgd_solver.cpp:105] Iteration 122250, lr = 0.0001
I0619 11:17:23.422952  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 11:18:01.119540  8058 solver.cpp:218] Iteration 122300 (0.640599 iter/s, 78.0519s/50 iters), loss = 0.00995793
I0619 11:18:01.119882  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 11:18:01.119911  8058 solver.cpp:237]     Train net output #1: loss = 0.00995796 (* 1 = 0.00995796 loss)
I0619 11:18:01.119928  8058 sgd_solver.cpp:105] Iteration 122300, lr = 0.0001
I0619 11:19:19.304893  8058 solver.cpp:218] Iteration 122350 (0.639515 iter/s, 78.1842s/50 iters), loss = 0.00868663
I0619 11:19:19.305016  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 11:19:19.305044  8058 solver.cpp:237]     Train net output #1: loss = 0.00868666 (* 1 = 0.00868666 loss)
I0619 11:19:19.305060  8058 sgd_solver.cpp:105] Iteration 122350, lr = 0.0001
I0619 11:20:34.625857  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 11:20:46.884997  8058 solver.cpp:218] Iteration 122400 (0.570914 iter/s, 87.5788s/50 iters), loss = 0.00938792
I0619 11:20:46.885123  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 11:20:46.885156  8058 solver.cpp:237]     Train net output #1: loss = 0.00938795 (* 1 = 0.00938795 loss)
I0619 11:20:46.885179  8058 sgd_solver.cpp:105] Iteration 122400, lr = 0.0001
I0619 11:22:14.552268  8058 solver.cpp:218] Iteration 122450 (0.570352 iter/s, 87.6652s/50 iters), loss = 0.00869111
I0619 11:22:14.552444  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 11:22:14.552474  8058 solver.cpp:237]     Train net output #1: loss = 0.00869114 (* 1 = 0.00869114 loss)
I0619 11:22:14.552492  8058 sgd_solver.cpp:105] Iteration 122450, lr = 0.0001
I0619 11:23:42.207562  8058 solver.cpp:218] Iteration 122500 (0.57045 iter/s, 87.6501s/50 iters), loss = 0.0099322
I0619 11:23:42.207824  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 11:23:42.207855  8058 solver.cpp:237]     Train net output #1: loss = 0.00993223 (* 1 = 0.00993223 loss)
I0619 11:23:42.207873  8058 sgd_solver.cpp:105] Iteration 122500, lr = 0.0001
I0619 11:24:05.079946  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 11:25:09.876862  8058 solver.cpp:218] Iteration 122550 (0.570333 iter/s, 87.6681s/50 iters), loss = 0.0132732
I0619 11:25:09.877094  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 11:25:09.877125  8058 solver.cpp:237]     Train net output #1: loss = 0.0132732 (* 1 = 0.0132732 loss)
I0619 11:25:09.877141  8058 sgd_solver.cpp:105] Iteration 122550, lr = 0.0001
I0619 11:26:37.482432  8058 solver.cpp:218] Iteration 122600 (0.570753 iter/s, 87.6036s/50 iters), loss = 0.0101869
I0619 11:26:37.482630  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 11:26:37.482658  8058 solver.cpp:237]     Train net output #1: loss = 0.0101869 (* 1 = 0.0101869 loss)
I0619 11:26:37.482676  8058 sgd_solver.cpp:105] Iteration 122600, lr = 0.0001
I0619 11:27:35.315517  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 11:28:05.165907  8058 solver.cpp:218] Iteration 122650 (0.570246 iter/s, 87.6814s/50 iters), loss = 0.0135451
I0619 11:28:05.166028  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 11:28:05.166055  8058 solver.cpp:237]     Train net output #1: loss = 0.0135452 (* 1 = 0.0135452 loss)
I0619 11:28:05.166071  8058 sgd_solver.cpp:105] Iteration 122650, lr = 0.0001
I0619 11:29:14.028451  8058 solver.cpp:218] Iteration 122700 (0.726104 iter/s, 68.8607s/50 iters), loss = 0.0101365
I0619 11:29:14.028581  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 11:29:14.028609  8058 solver.cpp:237]     Train net output #1: loss = 0.0101365 (* 1 = 0.0101365 loss)
I0619 11:29:14.028627  8058 sgd_solver.cpp:105] Iteration 122700, lr = 0.0001
I0619 11:30:41.634809  8058 solver.cpp:218] Iteration 122750 (0.570742 iter/s, 87.6053s/50 iters), loss = 0.00953475
I0619 11:30:41.634996  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 11:30:41.635026  8058 solver.cpp:237]     Train net output #1: loss = 0.00953478 (* 1 = 0.00953478 loss)
I0619 11:30:41.635046  8058 sgd_solver.cpp:105] Iteration 122750, lr = 0.0001
I0619 11:30:46.974386  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 11:32:09.243355  8058 solver.cpp:218] Iteration 122800 (0.570728 iter/s, 87.6074s/50 iters), loss = 0.010808
I0619 11:32:09.243551  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 11:32:09.243587  8058 solver.cpp:237]     Train net output #1: loss = 0.010808 (* 1 = 0.010808 loss)
I0619 11:32:09.243609  8058 sgd_solver.cpp:105] Iteration 122800, lr = 0.0001
I0619 11:33:36.841429  8058 solver.cpp:218] Iteration 122850 (0.570797 iter/s, 87.5968s/50 iters), loss = 0.0114066
I0619 11:33:36.841574  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 11:33:36.841603  8058 solver.cpp:237]     Train net output #1: loss = 0.0114066 (* 1 = 0.0114066 loss)
I0619 11:33:36.841619  8058 sgd_solver.cpp:105] Iteration 122850, lr = 0.0001
I0619 11:34:15.460021  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 11:35:04.431653  8058 solver.cpp:218] Iteration 122900 (0.570847 iter/s, 87.5891s/50 iters), loss = 0.00965815
I0619 11:35:04.431771  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 11:35:04.431798  8058 solver.cpp:237]     Train net output #1: loss = 0.00965818 (* 1 = 0.00965818 loss)
I0619 11:35:04.431815  8058 sgd_solver.cpp:105] Iteration 122900, lr = 0.0001
I0619 11:36:32.029438  8058 solver.cpp:218] Iteration 122950 (0.570798 iter/s, 87.5966s/50 iters), loss = 0.0106096
I0619 11:36:32.029567  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 11:36:32.029595  8058 solver.cpp:237]     Train net output #1: loss = 0.0106096 (* 1 = 0.0106096 loss)
I0619 11:36:32.029613  8058 sgd_solver.cpp:105] Iteration 122950, lr = 0.0001
I0619 11:37:45.683940  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 11:37:59.607499  8058 solver.cpp:218] Iteration 123000 (0.570927 iter/s, 87.5769s/50 iters), loss = 0.011057
I0619 11:37:59.607586  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 11:37:59.607612  8058 solver.cpp:237]     Train net output #1: loss = 0.011057 (* 1 = 0.011057 loss)
I0619 11:37:59.607630  8058 sgd_solver.cpp:105] Iteration 123000, lr = 0.0001
I0619 11:39:14.796080  8058 solver.cpp:218] Iteration 123050 (0.665002 iter/s, 75.1877s/50 iters), loss = 0.0120799
I0619 11:39:14.796211  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 11:39:14.796241  8058 solver.cpp:237]     Train net output #1: loss = 0.0120799 (* 1 = 0.0120799 loss)
I0619 11:39:14.796257  8058 sgd_solver.cpp:105] Iteration 123050, lr = 0.0001
I0619 11:40:36.372822  8058 solver.cpp:218] Iteration 123100 (0.612927 iter/s, 81.5757s/50 iters), loss = 0.0117315
I0619 11:40:36.372998  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 11:40:36.373034  8058 solver.cpp:237]     Train net output #1: loss = 0.0117316 (* 1 = 0.0117316 loss)
I0619 11:40:36.373054  8058 sgd_solver.cpp:105] Iteration 123100, lr = 0.0001
I0619 11:40:57.570227  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 11:42:03.967329  8058 solver.cpp:218] Iteration 123150 (0.570819 iter/s, 87.5934s/50 iters), loss = 0.01094
I0619 11:42:03.967459  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 11:42:03.967489  8058 solver.cpp:237]     Train net output #1: loss = 0.01094 (* 1 = 0.01094 loss)
I0619 11:42:03.967505  8058 sgd_solver.cpp:105] Iteration 123150, lr = 0.0001
I0619 11:43:31.588032  8058 solver.cpp:218] Iteration 123200 (0.570673 iter/s, 87.6159s/50 iters), loss = 0.0102786
I0619 11:43:31.588223  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 11:43:31.588253  8058 solver.cpp:237]     Train net output #1: loss = 0.0102786 (* 1 = 0.0102786 loss)
I0619 11:43:31.588269  8058 sgd_solver.cpp:105] Iteration 123200, lr = 0.0001
I0619 11:44:27.817145  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 11:44:59.167577  8058 solver.cpp:218] Iteration 123250 (0.570935 iter/s, 87.5757s/50 iters), loss = 0.0110567
I0619 11:44:59.167732  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 11:44:59.167760  8058 solver.cpp:237]     Train net output #1: loss = 0.0110568 (* 1 = 0.0110568 loss)
I0619 11:44:59.167776  8058 sgd_solver.cpp:105] Iteration 123250, lr = 0.0001
I0619 11:46:26.783527  8058 solver.cpp:218] Iteration 123300 (0.570679 iter/s, 87.6149s/50 iters), loss = 0.0105002
I0619 11:46:26.783666  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 11:46:26.783700  8058 solver.cpp:237]     Train net output #1: loss = 0.0105003 (* 1 = 0.0105003 loss)
I0619 11:46:26.783720  8058 sgd_solver.cpp:105] Iteration 123300, lr = 0.0001
I0619 11:47:54.464413  8058 solver.cpp:218] Iteration 123350 (0.570257 iter/s, 87.6798s/50 iters), loss = 0.0125877
I0619 11:47:54.464553  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 11:47:54.464583  8058 solver.cpp:237]     Train net output #1: loss = 0.0125877 (* 1 = 0.0125877 loss)
I0619 11:47:54.464599  8058 sgd_solver.cpp:105] Iteration 123350, lr = 0.0001
I0619 11:47:58.048048  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 11:49:14.108029  8058 solver.cpp:218] Iteration 123400 (0.627811 iter/s, 79.6418s/50 iters), loss = 0.0131454
I0619 11:49:14.108250  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 11:49:14.108279  8058 solver.cpp:237]     Train net output #1: loss = 0.0131454 (* 1 = 0.0131454 loss)
I0619 11:49:14.108297  8058 sgd_solver.cpp:105] Iteration 123400, lr = 0.0001
I0619 11:50:30.886106  8058 solver.cpp:218] Iteration 123450 (0.651235 iter/s, 76.7772s/50 iters), loss = 0.0105917
I0619 11:50:30.886245  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 11:50:30.886277  8058 solver.cpp:237]     Train net output #1: loss = 0.0105917 (* 1 = 0.0105917 loss)
I0619 11:50:30.886294  8058 sgd_solver.cpp:105] Iteration 123450, lr = 0.0001
I0619 11:51:09.496203  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 11:51:58.452466  8058 solver.cpp:218] Iteration 123500 (0.571002 iter/s, 87.5654s/50 iters), loss = 0.0118435
I0619 11:51:58.452613  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 11:51:58.452642  8058 solver.cpp:237]     Train net output #1: loss = 0.0118435 (* 1 = 0.0118435 loss)
I0619 11:51:58.452659  8058 sgd_solver.cpp:105] Iteration 123500, lr = 0.0001
I0619 11:53:26.011209  8058 solver.cpp:218] Iteration 123550 (0.571051 iter/s, 87.5578s/50 iters), loss = 0.0111559
I0619 11:53:26.011337  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 11:53:26.011365  8058 solver.cpp:237]     Train net output #1: loss = 0.0111559 (* 1 = 0.0111559 loss)
I0619 11:53:26.011381  8058 sgd_solver.cpp:105] Iteration 123550, lr = 0.0001
I0619 11:54:39.616243  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 11:54:53.564074  8058 solver.cpp:218] Iteration 123600 (0.571089 iter/s, 87.552s/50 iters), loss = 0.0119679
I0619 11:54:53.564147  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 11:54:53.564173  8058 solver.cpp:237]     Train net output #1: loss = 0.0119679 (* 1 = 0.0119679 loss)
I0619 11:54:53.564204  8058 sgd_solver.cpp:105] Iteration 123600, lr = 0.0001
I0619 11:56:21.133167  8058 solver.cpp:218] Iteration 123650 (0.570983 iter/s, 87.5683s/50 iters), loss = 0.0119015
I0619 11:56:21.133313  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 11:56:21.133342  8058 solver.cpp:237]     Train net output #1: loss = 0.0119016 (* 1 = 0.0119016 loss)
I0619 11:56:21.133358  8058 sgd_solver.cpp:105] Iteration 123650, lr = 0.0001
I0619 11:57:48.682871  8058 solver.cpp:218] Iteration 123700 (0.571111 iter/s, 87.5487s/50 iters), loss = 0.0106505
I0619 11:57:48.683043  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 11:57:48.683071  8058 solver.cpp:237]     Train net output #1: loss = 0.0106505 (* 1 = 0.0106505 loss)
I0619 11:57:48.683089  8058 sgd_solver.cpp:105] Iteration 123700, lr = 0.0001
I0619 11:58:09.804694  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 11:59:16.249127  8058 solver.cpp:218] Iteration 123750 (0.571003 iter/s, 87.5652s/50 iters), loss = 0.0095842
I0619 11:59:16.249248  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 11:59:16.249280  8058 solver.cpp:237]     Train net output #1: loss = 0.00958424 (* 1 = 0.00958424 loss)
I0619 11:59:16.249302  8058 sgd_solver.cpp:105] Iteration 123750, lr = 0.0001
I0619 12:00:25.390787  8058 solver.cpp:218] Iteration 123800 (0.723162 iter/s, 69.1408s/50 iters), loss = 0.0108143
I0619 12:00:25.390902  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 12:00:25.390933  8058 solver.cpp:237]     Train net output #1: loss = 0.0108143 (* 1 = 0.0108143 loss)
I0619 12:00:25.390954  8058 sgd_solver.cpp:105] Iteration 123800, lr = 0.0001
I0619 12:01:21.612298  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 12:01:53.012279  8058 solver.cpp:218] Iteration 123850 (0.570646 iter/s, 87.6199s/50 iters), loss = 0.00848384
I0619 12:01:53.012405  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 12:01:53.012434  8058 solver.cpp:237]     Train net output #1: loss = 0.00848387 (* 1 = 0.00848387 loss)
I0619 12:01:53.012450  8058 sgd_solver.cpp:105] Iteration 123850, lr = 0.0001
I0619 12:03:20.597923  8058 solver.cpp:218] Iteration 123900 (0.570877 iter/s, 87.5845s/50 iters), loss = 0.0123146
I0619 12:03:20.598105  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 12:03:20.598171  8058 solver.cpp:237]     Train net output #1: loss = 0.0123146 (* 1 = 0.0123146 loss)
I0619 12:03:20.598197  8058 sgd_solver.cpp:105] Iteration 123900, lr = 0.0001
I0619 12:04:48.191371  8058 solver.cpp:218] Iteration 123950 (0.570825 iter/s, 87.5925s/50 iters), loss = 0.0108134
I0619 12:04:48.191534  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 12:04:48.191565  8058 solver.cpp:237]     Train net output #1: loss = 0.0108134 (* 1 = 0.0108134 loss)
I0619 12:04:48.191581  8058 sgd_solver.cpp:105] Iteration 123950, lr = 0.0001
I0619 12:04:50.051947  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 12:06:15.763573  8058 solver.cpp:218] Iteration 124000 (0.570964 iter/s, 87.5712s/50 iters), loss = 0.011249
I0619 12:06:15.763727  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 12:06:15.763758  8058 solver.cpp:237]     Train net output #1: loss = 0.0112491 (* 1 = 0.0112491 loss)
I0619 12:06:15.763775  8058 sgd_solver.cpp:105] Iteration 124000, lr = 0.0001
I0619 12:07:43.524060  8058 solver.cpp:218] Iteration 124050 (0.569739 iter/s, 87.7595s/50 iters), loss = 0.0123856
I0619 12:07:43.524238  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 12:07:43.524274  8058 solver.cpp:237]     Train net output #1: loss = 0.0123856 (* 1 = 0.0123856 loss)
I0619 12:07:43.524296  8058 sgd_solver.cpp:105] Iteration 124050, lr = 0.0001
I0619 12:08:20.448101  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 12:09:11.069978  8058 solver.cpp:218] Iteration 124100 (0.571141 iter/s, 87.5441s/50 iters), loss = 0.00941884
I0619 12:09:11.070099  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 12:09:11.070139  8058 solver.cpp:237]     Train net output #1: loss = 0.00941887 (* 1 = 0.00941887 loss)
I0619 12:09:11.070158  8058 sgd_solver.cpp:105] Iteration 124100, lr = 0.0001
I0619 12:10:26.516242  8058 solver.cpp:218] Iteration 124150 (0.662739 iter/s, 75.4445s/50 iters), loss = 0.00875917
I0619 12:10:26.516372  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 12:10:26.516404  8058 solver.cpp:237]     Train net output #1: loss = 0.0087592 (* 1 = 0.0087592 loss)
I0619 12:10:26.516424  8058 sgd_solver.cpp:105] Iteration 124150, lr = 0.0001
I0619 12:11:32.236042  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 12:11:47.948667  8058 solver.cpp:218] Iteration 124200 (0.614013 iter/s, 81.4316s/50 iters), loss = 0.0100775
I0619 12:11:47.948760  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 12:11:47.948787  8058 solver.cpp:237]     Train net output #1: loss = 0.0100775 (* 1 = 0.0100775 loss)
I0619 12:11:47.948804  8058 sgd_solver.cpp:105] Iteration 124200, lr = 0.0001
I0619 12:13:15.535660  8058 solver.cpp:218] Iteration 124250 (0.570875 iter/s, 87.5849s/50 iters), loss = 0.0104227
I0619 12:13:15.535804  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 12:13:15.535831  8058 solver.cpp:237]     Train net output #1: loss = 0.0104227 (* 1 = 0.0104227 loss)
I0619 12:13:15.535848  8058 sgd_solver.cpp:105] Iteration 124250, lr = 0.0001
I0619 12:14:43.066025  8058 solver.cpp:218] Iteration 124300 (0.571238 iter/s, 87.5293s/50 iters), loss = 0.0105691
I0619 12:14:43.066145  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 12:14:43.066180  8058 solver.cpp:237]     Train net output #1: loss = 0.0105691 (* 1 = 0.0105691 loss)
I0619 12:14:43.066200  8058 sgd_solver.cpp:105] Iteration 124300, lr = 0.0001
I0619 12:15:02.394728  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 12:16:10.604605  8058 solver.cpp:218] Iteration 124350 (0.571183 iter/s, 87.5377s/50 iters), loss = 0.0113905
I0619 12:16:10.604733  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 12:16:10.604761  8058 solver.cpp:237]     Train net output #1: loss = 0.0113906 (* 1 = 0.0113906 loss)
I0619 12:16:10.604776  8058 sgd_solver.cpp:105] Iteration 124350, lr = 0.0001
I0619 12:17:38.176949  8058 solver.cpp:218] Iteration 124400 (0.570962 iter/s, 87.5714s/50 iters), loss = 0.0108107
I0619 12:17:38.177059  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 12:17:38.177088  8058 solver.cpp:237]     Train net output #1: loss = 0.0108107 (* 1 = 0.0108107 loss)
I0619 12:17:38.177104  8058 sgd_solver.cpp:105] Iteration 124400, lr = 0.0001
I0619 12:18:32.559808  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 12:19:05.747094  8058 solver.cpp:218] Iteration 124450 (0.570985 iter/s, 87.568s/50 iters), loss = 0.0164623
I0619 12:19:05.747269  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 12:19:05.747299  8058 solver.cpp:237]     Train net output #1: loss = 0.0164624 (* 1 = 0.0164624 loss)
I0619 12:19:05.747314  8058 sgd_solver.cpp:105] Iteration 124450, lr = 0.0001
I0619 12:20:26.630100  8058 solver.cpp:218] Iteration 124500 (0.618184 iter/s, 80.8821s/50 iters), loss = 0.0124701
I0619 12:20:26.630244  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 12:20:26.630271  8058 solver.cpp:237]     Train net output #1: loss = 0.0124702 (* 1 = 0.0124702 loss)
I0619 12:20:26.630290  8058 sgd_solver.cpp:105] Iteration 124500, lr = 0.0001
I0619 12:21:42.509874  8058 solver.cpp:218] Iteration 124550 (0.658944 iter/s, 75.879s/50 iters), loss = 0.0114198
I0619 12:21:42.509996  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 12:21:42.510025  8058 solver.cpp:237]     Train net output #1: loss = 0.0114199 (* 1 = 0.0114199 loss)
I0619 12:21:42.510040  8058 sgd_solver.cpp:105] Iteration 124550, lr = 0.0001
I0619 12:21:44.368707  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 12:23:10.188745  8058 solver.cpp:218] Iteration 124600 (0.570266 iter/s, 87.6784s/50 iters), loss = 0.00974722
I0619 12:23:10.188875  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 12:23:10.188904  8058 solver.cpp:237]     Train net output #1: loss = 0.00974725 (* 1 = 0.00974725 loss)
I0619 12:23:10.188920  8058 sgd_solver.cpp:105] Iteration 124600, lr = 0.0001
I0619 12:24:37.856062  8058 solver.cpp:218] Iteration 124650 (0.570347 iter/s, 87.6659s/50 iters), loss = 0.00998715
I0619 12:24:37.856212  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 12:24:37.856246  8058 solver.cpp:237]     Train net output #1: loss = 0.00998718 (* 1 = 0.00998718 loss)
I0619 12:24:37.856266  8058 sgd_solver.cpp:105] Iteration 124650, lr = 0.0001
I0619 12:25:14.817597  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 12:26:05.453774  8058 solver.cpp:218] Iteration 124700 (0.5708 iter/s, 87.5964s/50 iters), loss = 0.0106266
I0619 12:26:05.453884  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 12:26:05.453913  8058 solver.cpp:237]     Train net output #1: loss = 0.0106267 (* 1 = 0.0106267 loss)
I0619 12:26:05.453930  8058 sgd_solver.cpp:105] Iteration 124700, lr = 0.0001
I0619 12:27:33.125632  8058 solver.cpp:218] Iteration 124750 (0.570317 iter/s, 87.6705s/50 iters), loss = 0.00983887
I0619 12:27:33.125767  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 12:27:33.125797  8058 solver.cpp:237]     Train net output #1: loss = 0.00983891 (* 1 = 0.00983891 loss)
I0619 12:27:33.125813  8058 sgd_solver.cpp:105] Iteration 124750, lr = 0.0001
I0619 12:28:44.967650  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 12:29:00.703733  8058 solver.cpp:218] Iteration 124800 (0.570928 iter/s, 87.5767s/50 iters), loss = 0.0107823
I0619 12:29:00.703814  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 12:29:00.703840  8058 solver.cpp:237]     Train net output #1: loss = 0.0107823 (* 1 = 0.0107823 loss)
I0619 12:29:00.703860  8058 sgd_solver.cpp:105] Iteration 124800, lr = 0.0001
I0619 12:30:28.321038  8058 solver.cpp:218] Iteration 124850 (0.570672 iter/s, 87.616s/50 iters), loss = 0.0123739
I0619 12:30:28.321153  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 12:30:28.321182  8058 solver.cpp:237]     Train net output #1: loss = 0.012374 (* 1 = 0.012374 loss)
I0619 12:30:28.321197  8058 sgd_solver.cpp:105] Iteration 124850, lr = 0.0001
I0619 12:31:37.570647  8058 solver.cpp:218] Iteration 124900 (0.722031 iter/s, 69.2491s/50 iters), loss = 0.0108947
I0619 12:31:37.570766  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 12:31:37.570794  8058 solver.cpp:237]     Train net output #1: loss = 0.0108948 (* 1 = 0.0108948 loss)
I0619 12:31:37.570811  8058 sgd_solver.cpp:105] Iteration 124900, lr = 0.0001
I0619 12:31:55.224222  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 12:33:05.156194  8058 solver.cpp:218] Iteration 124950 (0.570874 iter/s, 87.585s/50 iters), loss = 0.0122041
I0619 12:33:05.156415  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 12:33:05.156450  8058 solver.cpp:237]     Train net output #1: loss = 0.0122041 (* 1 = 0.0122041 loss)
I0619 12:33:05.156471  8058 sgd_solver.cpp:105] Iteration 124950, lr = 0.0001
I0619 12:34:32.727244  8058 solver.cpp:218] Iteration 125000 (0.570968 iter/s, 87.5705s/50 iters), loss = 0.0103235
I0619 12:34:32.727340  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 12:34:32.727367  8058 solver.cpp:237]     Train net output #1: loss = 0.0103235 (* 1 = 0.0103235 loss)
I0619 12:34:32.727383  8058 sgd_solver.cpp:105] Iteration 125000, lr = 0.0001
I0619 12:35:25.383885  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 12:36:00.306172  8058 solver.cpp:218] Iteration 125050 (0.570936 iter/s, 87.5755s/50 iters), loss = 0.0106957
I0619 12:36:00.306318  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 12:36:00.306346  8058 solver.cpp:237]     Train net output #1: loss = 0.0106957 (* 1 = 0.0106957 loss)
I0619 12:36:00.306363  8058 sgd_solver.cpp:105] Iteration 125050, lr = 0.0001
I0619 12:37:27.892614  8058 solver.cpp:218] Iteration 125100 (0.570876 iter/s, 87.5846s/50 iters), loss = 0.00947481
I0619 12:37:27.892786  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 12:37:27.892822  8058 solver.cpp:237]     Train net output #1: loss = 0.00947484 (* 1 = 0.00947484 loss)
I0619 12:37:27.892843  8058 sgd_solver.cpp:105] Iteration 125100, lr = 0.0001
I0619 12:38:55.476025  8058 solver.cpp:218] Iteration 125150 (0.570888 iter/s, 87.5828s/50 iters), loss = 0.0101854
I0619 12:38:55.476140  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 12:38:55.476168  8058 solver.cpp:237]     Train net output #1: loss = 0.0101854 (* 1 = 0.0101854 loss)
I0619 12:38:55.476184  8058 sgd_solver.cpp:105] Iteration 125150, lr = 0.0001
I0619 12:38:55.581276  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 12:40:23.038067  8058 solver.cpp:218] Iteration 125200 (0.571027 iter/s, 87.5615s/50 iters), loss = 0.0104876
I0619 12:40:23.038185  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 12:40:23.038214  8058 solver.cpp:237]     Train net output #1: loss = 0.0104876 (* 1 = 0.0104876 loss)
I0619 12:40:23.038231  8058 sgd_solver.cpp:105] Iteration 125200, lr = 0.0001
I0619 12:41:38.579183  8058 solver.cpp:218] Iteration 125250 (0.661896 iter/s, 75.5405s/50 iters), loss = 0.0104272
I0619 12:41:38.579305  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 12:41:38.579334  8058 solver.cpp:237]     Train net output #1: loss = 0.0104272 (* 1 = 0.0104272 loss)
I0619 12:41:38.579350  8058 sgd_solver.cpp:105] Iteration 125250, lr = 0.0001
I0619 12:42:07.398798  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 12:42:59.815342  8058 solver.cpp:218] Iteration 125300 (0.615495 iter/s, 81.2354s/50 iters), loss = 0.00992246
I0619 12:42:59.815464  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 12:42:59.815492  8058 solver.cpp:237]     Train net output #1: loss = 0.00992249 (* 1 = 0.00992249 loss)
I0619 12:42:59.815510  8058 sgd_solver.cpp:105] Iteration 125300, lr = 0.0001
I0619 12:44:27.431694  8058 solver.cpp:218] Iteration 125350 (0.57068 iter/s, 87.6148s/50 iters), loss = 0.00873744
I0619 12:44:27.431850  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 12:44:27.431885  8058 solver.cpp:237]     Train net output #1: loss = 0.00873747 (* 1 = 0.00873747 loss)
I0619 12:44:27.431907  8058 sgd_solver.cpp:105] Iteration 125350, lr = 0.0001
I0619 12:45:37.679643  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 12:45:55.084578  8058 solver.cpp:218] Iteration 125400 (0.570441 iter/s, 87.6514s/50 iters), loss = 0.0128249
I0619 12:45:55.084657  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 12:45:55.084684  8058 solver.cpp:237]     Train net output #1: loss = 0.0128249 (* 1 = 0.0128249 loss)
I0619 12:45:55.084702  8058 sgd_solver.cpp:105] Iteration 125400, lr = 0.0001
I0619 12:47:22.882938  8058 solver.cpp:218] Iteration 125450 (0.56949 iter/s, 87.7978s/50 iters), loss = 0.0121919
I0619 12:47:22.883239  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 12:47:22.883270  8058 solver.cpp:237]     Train net output #1: loss = 0.012192 (* 1 = 0.012192 loss)
I0619 12:47:22.883288  8058 sgd_solver.cpp:105] Iteration 125450, lr = 0.0001
I0619 12:48:50.449005  8058 solver.cpp:218] Iteration 125500 (0.571007 iter/s, 87.5646s/50 iters), loss = 0.011116
I0619 12:48:50.449129  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 12:48:50.449158  8058 solver.cpp:237]     Train net output #1: loss = 0.011116 (* 1 = 0.011116 loss)
I0619 12:48:50.449175  8058 sgd_solver.cpp:105] Iteration 125500, lr = 0.0001
I0619 12:49:08.079109  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 12:50:18.196985  8058 solver.cpp:218] Iteration 125550 (0.569823 iter/s, 87.7465s/50 iters), loss = 0.0107605
I0619 12:50:18.197571  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 12:50:18.197624  8058 solver.cpp:237]     Train net output #1: loss = 0.0107605 (* 1 = 0.0107605 loss)
I0619 12:50:18.197660  8058 sgd_solver.cpp:105] Iteration 125550, lr = 0.0001
I0619 12:51:39.666493  8058 solver.cpp:218] Iteration 125600 (0.613738 iter/s, 81.468s/50 iters), loss = 0.0104139
I0619 12:51:39.666622  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 12:51:39.666651  8058 solver.cpp:237]     Train net output #1: loss = 0.010414 (* 1 = 0.010414 loss)
I0619 12:51:39.666668  8058 sgd_solver.cpp:105] Iteration 125600, lr = 0.0001
I0619 12:52:21.033342  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 12:52:54.993784  8058 solver.cpp:218] Iteration 125650 (0.663774 iter/s, 75.3269s/50 iters), loss = 0.0101495
I0619 12:52:54.993907  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 12:52:54.993937  8058 solver.cpp:237]     Train net output #1: loss = 0.0101496 (* 1 = 0.0101496 loss)
I0619 12:52:54.993953  8058 sgd_solver.cpp:105] Iteration 125650, lr = 0.0001
I0619 12:54:22.566593  8058 solver.cpp:218] Iteration 125700 (0.570958 iter/s, 87.5722s/50 iters), loss = 0.00974603
I0619 12:54:22.566725  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 12:54:22.566753  8058 solver.cpp:237]     Train net output #1: loss = 0.00974607 (* 1 = 0.00974607 loss)
I0619 12:54:22.566769  8058 sgd_solver.cpp:105] Iteration 125700, lr = 0.0001
I0619 12:55:50.118898  8058 solver.cpp:218] Iteration 125750 (0.571091 iter/s, 87.5518s/50 iters), loss = 0.011128
I0619 12:55:50.119002  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 12:55:50.119030  8058 solver.cpp:237]     Train net output #1: loss = 0.0111281 (* 1 = 0.0111281 loss)
I0619 12:55:50.119046  8058 sgd_solver.cpp:105] Iteration 125750, lr = 0.0001
I0619 12:55:50.217872  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 12:57:17.677795  8058 solver.cpp:218] Iteration 125800 (0.571051 iter/s, 87.5579s/50 iters), loss = 0.011105
I0619 12:57:17.677927  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 12:57:17.677956  8058 solver.cpp:237]     Train net output #1: loss = 0.011105 (* 1 = 0.011105 loss)
I0619 12:57:17.677974  8058 sgd_solver.cpp:105] Iteration 125800, lr = 0.0001
I0619 12:58:45.241468  8058 solver.cpp:218] Iteration 125850 (0.57102 iter/s, 87.5626s/50 iters), loss = 0.0117343
I0619 12:58:45.241593  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 12:58:45.241622  8058 solver.cpp:237]     Train net output #1: loss = 0.0117343 (* 1 = 0.0117343 loss)
I0619 12:58:45.241638  8058 sgd_solver.cpp:105] Iteration 125850, lr = 0.0001
I0619 12:59:18.692873  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 13:00:12.796185  8058 solver.cpp:218] Iteration 125900 (0.571079 iter/s, 87.5536s/50 iters), loss = 0.0101048
I0619 13:00:12.796397  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 13:00:12.796427  8058 solver.cpp:237]     Train net output #1: loss = 0.0101048 (* 1 = 0.0101048 loss)
I0619 13:00:12.796444  8058 sgd_solver.cpp:105] Iteration 125900, lr = 0.0001
I0619 13:01:40.338261  8058 solver.cpp:218] Iteration 125950 (0.571161 iter/s, 87.541s/50 iters), loss = 0.0100248
I0619 13:01:40.338526  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 13:01:40.338558  8058 solver.cpp:237]     Train net output #1: loss = 0.0100249 (* 1 = 0.0100249 loss)
I0619 13:01:40.338574  8058 sgd_solver.cpp:105] Iteration 125950, lr = 0.0001
I0619 13:02:36.320822  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 13:02:49.312285  8058 solver.cpp:218] Iteration 126000 (0.724922 iter/s, 68.9729s/50 iters), loss = 0.0121983
I0619 13:02:49.312360  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 13:02:49.312386  8058 solver.cpp:237]     Train net output #1: loss = 0.0121983 (* 1 = 0.0121983 loss)
I0619 13:02:49.312403  8058 sgd_solver.cpp:105] Iteration 126000, lr = 0.0001
I0619 13:04:16.917054  8058 solver.cpp:218] Iteration 126050 (0.570752 iter/s, 87.6038s/50 iters), loss = 0.00920752
I0619 13:04:16.917186  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 13:04:16.917230  8058 solver.cpp:237]     Train net output #1: loss = 0.00920755 (* 1 = 0.00920755 loss)
I0619 13:04:16.917250  8058 sgd_solver.cpp:105] Iteration 126050, lr = 0.0001
I0619 13:05:44.508675  8058 solver.cpp:218] Iteration 126100 (0.57084 iter/s, 87.5901s/50 iters), loss = 0.0123073
I0619 13:05:44.508810  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 13:05:44.508839  8058 solver.cpp:237]     Train net output #1: loss = 0.0123073 (* 1 = 0.0123073 loss)
I0619 13:05:44.508857  8058 sgd_solver.cpp:105] Iteration 126100, lr = 0.0001
I0619 13:06:00.385017  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 13:07:12.131069  8058 solver.cpp:218] Iteration 126150 (0.570644 iter/s, 87.6204s/50 iters), loss = 0.00981029
I0619 13:07:12.131183  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 13:07:12.131212  8058 solver.cpp:237]     Train net output #1: loss = 0.00981032 (* 1 = 0.00981032 loss)
I0619 13:07:12.131228  8058 sgd_solver.cpp:105] Iteration 126150, lr = 0.0001
I0619 13:08:39.733788  8058 solver.cpp:218] Iteration 126200 (0.570772 iter/s, 87.6007s/50 iters), loss = 0.0116186
I0619 13:08:39.733921  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 13:08:39.733952  8058 solver.cpp:237]     Train net output #1: loss = 0.0116187 (* 1 = 0.0116187 loss)
I0619 13:08:39.733973  8058 sgd_solver.cpp:105] Iteration 126200, lr = 0.0001
I0619 13:09:30.634529  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 13:10:07.314245  8058 solver.cpp:218] Iteration 126250 (0.570917 iter/s, 87.5784s/50 iters), loss = 0.0132852
I0619 13:10:07.314401  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 13:10:07.314430  8058 solver.cpp:237]     Train net output #1: loss = 0.0132853 (* 1 = 0.0132853 loss)
I0619 13:10:07.314447  8058 sgd_solver.cpp:105] Iteration 126250, lr = 0.0001
I0619 13:11:34.937325  8058 solver.cpp:218] Iteration 126300 (0.570639 iter/s, 87.621s/50 iters), loss = 0.0122259
I0619 13:11:34.937464  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 13:11:34.937492  8058 solver.cpp:237]     Train net output #1: loss = 0.0122259 (* 1 = 0.0122259 loss)
I0619 13:11:34.937511  8058 sgd_solver.cpp:105] Iteration 126300, lr = 0.0001
I0619 13:12:49.172910  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 13:12:50.723971  8058 solver.cpp:218] Iteration 126350 (0.659763 iter/s, 75.7848s/50 iters), loss = 0.0122084
I0619 13:12:50.724043  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 13:12:50.724071  8058 solver.cpp:237]     Train net output #1: loss = 0.0122085 (* 1 = 0.0122085 loss)
I0619 13:12:50.724086  8058 sgd_solver.cpp:105] Iteration 126350, lr = 0.0001
I0619 13:14:11.791699  8058 solver.cpp:218] Iteration 126400 (0.616776 iter/s, 81.0667s/50 iters), loss = 0.0109733
I0619 13:14:11.791860  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 13:14:11.791890  8058 solver.cpp:237]     Train net output #1: loss = 0.0109733 (* 1 = 0.0109733 loss)
I0619 13:14:11.791908  8058 sgd_solver.cpp:105] Iteration 126400, lr = 0.0001
I0619 13:15:39.351331  8058 solver.cpp:218] Iteration 126450 (0.571047 iter/s, 87.5585s/50 iters), loss = 0.0111641
I0619 13:15:39.351526  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 13:15:39.351562  8058 solver.cpp:237]     Train net output #1: loss = 0.0111641 (* 1 = 0.0111641 loss)
I0619 13:15:39.351582  8058 sgd_solver.cpp:105] Iteration 126450, lr = 0.0001
I0619 13:16:12.712891  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 13:17:06.872093  8058 solver.cpp:218] Iteration 126500 (0.5713 iter/s, 87.5196s/50 iters), loss = 0.00992703
I0619 13:17:06.872241  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 13:17:06.872270  8058 solver.cpp:237]     Train net output #1: loss = 0.00992706 (* 1 = 0.00992706 loss)
I0619 13:17:06.872287  8058 sgd_solver.cpp:105] Iteration 126500, lr = 0.0001
I0619 13:18:34.569661  8058 solver.cpp:218] Iteration 126550 (0.570154 iter/s, 87.6956s/50 iters), loss = 0.00909841
I0619 13:18:34.569810  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 13:18:34.569839  8058 solver.cpp:237]     Train net output #1: loss = 0.00909844 (* 1 = 0.00909844 loss)
I0619 13:18:34.569856  8058 sgd_solver.cpp:105] Iteration 126550, lr = 0.0001
I0619 13:19:42.897296  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 13:20:02.080881  8058 solver.cpp:218] Iteration 126600 (0.571368 iter/s, 87.5093s/50 iters), loss = 0.00975916
I0619 13:20:02.080967  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 13:20:02.080998  8058 solver.cpp:237]     Train net output #1: loss = 0.00975919 (* 1 = 0.00975919 loss)
I0619 13:20:02.081019  8058 sgd_solver.cpp:105] Iteration 126600, lr = 0.0001
I0619 13:21:29.716739  8058 solver.cpp:218] Iteration 126650 (0.570555 iter/s, 87.6339s/50 iters), loss = 0.0101987
I0619 13:21:29.716861  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 13:21:29.716889  8058 solver.cpp:237]     Train net output #1: loss = 0.0101987 (* 1 = 0.0101987 loss)
I0619 13:21:29.716905  8058 sgd_solver.cpp:105] Iteration 126650, lr = 0.0001
I0619 13:22:52.724942  8058 solver.cpp:218] Iteration 126700 (0.602364 iter/s, 83.0063s/50 iters), loss = 0.0118587
I0619 13:22:52.725157  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 13:22:52.725186  8058 solver.cpp:237]     Train net output #1: loss = 0.0118588 (* 1 = 0.0118588 loss)
I0619 13:22:52.725203  8058 sgd_solver.cpp:105] Iteration 126700, lr = 0.0001
I0619 13:23:03.175920  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 13:24:06.347533  8058 solver.cpp:218] Iteration 126750 (0.679148 iter/s, 73.6217s/50 iters), loss = 0.00941357
I0619 13:24:06.347678  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 13:24:06.347708  8058 solver.cpp:237]     Train net output #1: loss = 0.00941361 (* 1 = 0.00941361 loss)
I0619 13:24:06.347723  8058 sgd_solver.cpp:105] Iteration 126750, lr = 0.0001
I0619 13:25:33.976291  8058 solver.cpp:218] Iteration 126800 (0.570602 iter/s, 87.6268s/50 iters), loss = 0.0116235
I0619 13:25:33.976439  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 13:25:33.976469  8058 solver.cpp:237]     Train net output #1: loss = 0.0116235 (* 1 = 0.0116235 loss)
I0619 13:25:33.976485  8058 sgd_solver.cpp:105] Iteration 126800, lr = 0.0001
I0619 13:26:24.811925  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 13:27:01.520603  8058 solver.cpp:218] Iteration 126850 (0.571152 iter/s, 87.5423s/50 iters), loss = 0.0106687
I0619 13:27:01.520745  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 13:27:01.520776  8058 solver.cpp:237]     Train net output #1: loss = 0.0106688 (* 1 = 0.0106688 loss)
I0619 13:27:01.520795  8058 sgd_solver.cpp:105] Iteration 126850, lr = 0.0001
I0619 13:28:29.066577  8058 solver.cpp:218] Iteration 126900 (0.571142 iter/s, 87.5439s/50 iters), loss = 0.0103764
I0619 13:28:29.066795  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 13:28:29.066824  8058 solver.cpp:237]     Train net output #1: loss = 0.0103765 (* 1 = 0.0103765 loss)
I0619 13:28:29.066843  8058 sgd_solver.cpp:105] Iteration 126900, lr = 0.0001
I0619 13:29:53.191097  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 13:29:56.638664  8058 solver.cpp:218] Iteration 126950 (0.570966 iter/s, 87.5709s/50 iters), loss = 0.0112035
I0619 13:29:56.638741  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 13:29:56.638767  8058 solver.cpp:237]     Train net output #1: loss = 0.0112035 (* 1 = 0.0112035 loss)
I0619 13:29:56.638783  8058 sgd_solver.cpp:105] Iteration 126950, lr = 0.0001
I0619 13:31:24.241521  8058 solver.cpp:218] Iteration 127000 (0.570771 iter/s, 87.6009s/50 iters), loss = 0.011932
I0619 13:31:24.241717  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 13:31:24.241747  8058 solver.cpp:237]     Train net output #1: loss = 0.0119321 (* 1 = 0.0119321 loss)
I0619 13:31:24.241765  8058 sgd_solver.cpp:105] Iteration 127000, lr = 0.0001
I0619 13:32:51.782229  8058 solver.cpp:218] Iteration 127050 (0.571183 iter/s, 87.5376s/50 iters), loss = 0.00980176
I0619 13:32:51.782414  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 13:32:51.782444  8058 solver.cpp:237]     Train net output #1: loss = 0.0098018 (* 1 = 0.0098018 loss)
I0619 13:32:51.782460  8058 sgd_solver.cpp:105] Iteration 127050, lr = 0.0001
I0619 13:33:18.369221  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 13:34:01.970021  8058 solver.cpp:218] Iteration 127100 (0.712413 iter/s, 70.184s/50 iters), loss = 0.0147147
I0619 13:34:01.970214  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 13:34:01.970243  8058 solver.cpp:237]     Train net output #1: loss = 0.0147147 (* 1 = 0.0147147 loss)
I0619 13:34:01.970262  8058 sgd_solver.cpp:105] Iteration 127100, lr = 0.0001
I0619 13:35:28.629323  8058 solver.cpp:218] Iteration 127150 (0.576979 iter/s, 86.6583s/50 iters), loss = 0.0106247
I0619 13:35:28.629451  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 13:35:28.629480  8058 solver.cpp:237]     Train net output #1: loss = 0.0106247 (* 1 = 0.0106247 loss)
I0619 13:35:28.629497  8058 sgd_solver.cpp:105] Iteration 127150, lr = 0.0001
I0619 13:36:35.440613  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 13:36:56.309659  8058 solver.cpp:218] Iteration 127200 (0.57026 iter/s, 87.6794s/50 iters), loss = 0.00874852
I0619 13:36:56.309741  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 13:36:56.309767  8058 solver.cpp:237]     Train net output #1: loss = 0.00874856 (* 1 = 0.00874856 loss)
I0619 13:36:56.309785  8058 sgd_solver.cpp:105] Iteration 127200, lr = 0.0001
I0619 13:38:23.917315  8058 solver.cpp:218] Iteration 127250 (0.570737 iter/s, 87.606s/50 iters), loss = 0.00952473
I0619 13:38:23.917456  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 13:38:23.917490  8058 solver.cpp:237]     Train net output #1: loss = 0.00952476 (* 1 = 0.00952476 loss)
I0619 13:38:23.917510  8058 sgd_solver.cpp:105] Iteration 127250, lr = 0.0001
I0619 13:39:51.500977  8058 solver.cpp:218] Iteration 127300 (0.570892 iter/s, 87.5823s/50 iters), loss = 0.0103268
I0619 13:39:51.501102  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 13:39:51.501130  8058 solver.cpp:237]     Train net output #1: loss = 0.0103268 (* 1 = 0.0103268 loss)
I0619 13:39:51.501147  8058 sgd_solver.cpp:105] Iteration 127300, lr = 0.0001
I0619 13:40:05.721801  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 13:41:19.275105  8058 solver.cpp:218] Iteration 127350 (0.569651 iter/s, 87.7731s/50 iters), loss = 0.00934201
I0619 13:41:19.275226  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 13:41:19.275254  8058 solver.cpp:237]     Train net output #1: loss = 0.00934205 (* 1 = 0.00934205 loss)
I0619 13:41:19.275270  8058 sgd_solver.cpp:105] Iteration 127350, lr = 0.0001
I0619 13:42:46.921840  8058 solver.cpp:218] Iteration 127400 (0.570485 iter/s, 87.6448s/50 iters), loss = 0.0117624
I0619 13:42:46.922053  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 13:42:46.922083  8058 solver.cpp:237]     Train net output #1: loss = 0.0117624 (* 1 = 0.0117624 loss)
I0619 13:42:46.922101  8058 sgd_solver.cpp:105] Iteration 127400, lr = 0.0001
I0619 13:43:35.320317  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 13:44:02.736428  8058 solver.cpp:218] Iteration 127450 (0.659519 iter/s, 75.8128s/50 iters), loss = 0.0129982
I0619 13:44:02.736507  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 13:44:02.736541  8058 solver.cpp:237]     Train net output #1: loss = 0.0129982 (* 1 = 0.0129982 loss)
I0619 13:44:02.736558  8058 sgd_solver.cpp:105] Iteration 127450, lr = 0.0001
I0619 13:45:23.668977  8058 solver.cpp:218] Iteration 127500 (0.617836 iter/s, 80.9277s/50 iters), loss = 0.00944974
I0619 13:45:23.669100  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 13:45:23.669128  8058 solver.cpp:237]     Train net output #1: loss = 0.00944977 (* 1 = 0.00944977 loss)
I0619 13:45:23.669158  8058 sgd_solver.cpp:105] Iteration 127500, lr = 0.0001
I0619 13:46:47.835386  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 13:46:51.305971  8058 solver.cpp:218] Iteration 127550 (0.570548 iter/s, 87.6351s/50 iters), loss = 0.011883
I0619 13:46:51.306048  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 13:46:51.306076  8058 solver.cpp:237]     Train net output #1: loss = 0.011883 (* 1 = 0.011883 loss)
I0619 13:46:51.306092  8058 sgd_solver.cpp:105] Iteration 127550, lr = 0.0001
I0619 13:48:18.996451  8058 solver.cpp:218] Iteration 127600 (0.5702 iter/s, 87.6885s/50 iters), loss = 0.0106478
I0619 13:48:18.996582  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 13:48:18.996610  8058 solver.cpp:237]     Train net output #1: loss = 0.0106478 (* 1 = 0.0106478 loss)
I0619 13:48:18.996628  8058 sgd_solver.cpp:105] Iteration 127600, lr = 0.0001
I0619 13:49:46.568837  8058 solver.cpp:218] Iteration 127650 (0.570963 iter/s, 87.5713s/50 iters), loss = 0.0114537
I0619 13:49:46.568974  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 13:49:46.569001  8058 solver.cpp:237]     Train net output #1: loss = 0.0114537 (* 1 = 0.0114537 loss)
I0619 13:49:46.569017  8058 sgd_solver.cpp:105] Iteration 127650, lr = 0.0001
I0619 13:50:18.206359  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 13:51:14.131909  8058 solver.cpp:218] Iteration 127700 (0.571025 iter/s, 87.5619s/50 iters), loss = 0.0105389
I0619 13:51:14.132025  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 13:51:14.132056  8058 solver.cpp:237]     Train net output #1: loss = 0.010539 (* 1 = 0.010539 loss)
I0619 13:51:14.132077  8058 sgd_solver.cpp:105] Iteration 127700, lr = 0.0001
I0619 13:52:41.740057  8058 solver.cpp:218] Iteration 127750 (0.57073 iter/s, 87.6071s/50 iters), loss = 0.0120678
I0619 13:52:41.740180  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 13:52:41.740207  8058 solver.cpp:237]     Train net output #1: loss = 0.0120679 (* 1 = 0.0120679 loss)
I0619 13:52:41.740224  8058 sgd_solver.cpp:105] Iteration 127750, lr = 0.0001
I0619 13:53:48.384033  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 13:54:05.655529  8058 solver.cpp:218] Iteration 127800 (0.595845 iter/s, 83.9145s/50 iters), loss = 0.00867499
I0619 13:54:05.655604  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 13:54:05.655632  8058 solver.cpp:237]     Train net output #1: loss = 0.00867502 (* 1 = 0.00867502 loss)
I0619 13:54:05.655649  8058 sgd_solver.cpp:105] Iteration 127800, lr = 0.0001
I0619 13:55:18.395648  8058 solver.cpp:218] Iteration 127850 (0.687386 iter/s, 72.7393s/50 iters), loss = 0.0116617
I0619 13:55:18.395809  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 13:55:18.395838  8058 solver.cpp:237]     Train net output #1: loss = 0.0116617 (* 1 = 0.0116617 loss)
I0619 13:55:18.395855  8058 sgd_solver.cpp:105] Iteration 127850, lr = 0.0001
I0619 13:56:45.982919  8058 solver.cpp:218] Iteration 127900 (0.570872 iter/s, 87.5853s/50 iters), loss = 0.00959561
I0619 13:56:45.983050  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 13:56:45.983079  8058 solver.cpp:237]     Train net output #1: loss = 0.00959565 (* 1 = 0.00959565 loss)
I0619 13:56:45.983096  8058 sgd_solver.cpp:105] Iteration 127900, lr = 0.0001
I0619 13:56:58.345597  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 13:58:13.630475  8058 solver.cpp:218] Iteration 127950 (0.570473 iter/s, 87.6465s/50 iters), loss = 0.00926853
I0619 13:58:13.630606  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 13:58:13.630640  8058 solver.cpp:237]     Train net output #1: loss = 0.00926856 (* 1 = 0.00926856 loss)
I0619 13:58:13.630661  8058 sgd_solver.cpp:105] Iteration 127950, lr = 0.0001
I0619 13:59:41.182190  8058 solver.cpp:218] Iteration 128000 (0.571104 iter/s, 87.5497s/50 iters), loss = 0.0106905
I0619 13:59:41.182309  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 13:59:41.182337  8058 solver.cpp:237]     Train net output #1: loss = 0.0106905 (* 1 = 0.0106905 loss)
I0619 13:59:41.182354  8058 sgd_solver.cpp:105] Iteration 128000, lr = 0.0001
I0619 14:00:28.679811  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 14:01:08.745062  8058 solver.cpp:218] Iteration 128050 (0.571031 iter/s, 87.5609s/50 iters), loss = 0.00964785
I0619 14:01:08.745172  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 14:01:08.745201  8058 solver.cpp:237]     Train net output #1: loss = 0.00964788 (* 1 = 0.00964788 loss)
I0619 14:01:08.745218  8058 sgd_solver.cpp:105] Iteration 128050, lr = 0.0001
I0619 14:02:36.318150  8058 solver.cpp:218] Iteration 128100 (0.570965 iter/s, 87.5711s/50 iters), loss = 0.0105238
I0619 14:02:36.318274  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 14:02:36.318305  8058 solver.cpp:237]     Train net output #1: loss = 0.0105238 (* 1 = 0.0105238 loss)
I0619 14:02:36.318325  8058 sgd_solver.cpp:105] Iteration 128100, lr = 0.0001
I0619 14:03:58.824972  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 14:04:03.886052  8058 solver.cpp:218] Iteration 128150 (0.570999 iter/s, 87.5659s/50 iters), loss = 0.0123265
I0619 14:04:03.886145  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 14:04:03.886173  8058 solver.cpp:237]     Train net output #1: loss = 0.0123266 (* 1 = 0.0123266 loss)
I0619 14:04:03.886189  8058 sgd_solver.cpp:105] Iteration 128150, lr = 0.0001
I0619 14:05:14.878346  8058 solver.cpp:218] Iteration 128200 (0.70432 iter/s, 70.9904s/50 iters), loss = 0.0103745
I0619 14:05:14.878541  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 14:05:14.878572  8058 solver.cpp:237]     Train net output #1: loss = 0.0103745 (* 1 = 0.0103745 loss)
I0619 14:05:14.878590  8058 sgd_solver.cpp:105] Iteration 128200, lr = 0.0001
I0619 14:06:40.713815  8058 solver.cpp:218] Iteration 128250 (0.582517 iter/s, 85.8345s/50 iters), loss = 0.0103636
I0619 14:06:40.713928  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 14:06:40.713956  8058 solver.cpp:237]     Train net output #1: loss = 0.0103637 (* 1 = 0.0103637 loss)
I0619 14:06:40.713973  8058 sgd_solver.cpp:105] Iteration 128250, lr = 0.0001
I0619 14:07:10.585535  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 14:08:08.292598  8058 solver.cpp:218] Iteration 128300 (0.570927 iter/s, 87.5768s/50 iters), loss = 0.0117952
I0619 14:08:08.292769  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 14:08:08.292798  8058 solver.cpp:237]     Train net output #1: loss = 0.0117952 (* 1 = 0.0117952 loss)
I0619 14:08:08.292815  8058 sgd_solver.cpp:105] Iteration 128300, lr = 0.0001
I0619 14:09:35.843207  8058 solver.cpp:218] Iteration 128350 (0.571111 iter/s, 87.5486s/50 iters), loss = 0.00979387
I0619 14:09:35.843425  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 14:09:35.843461  8058 solver.cpp:237]     Train net output #1: loss = 0.0097939 (* 1 = 0.0097939 loss)
I0619 14:09:35.843482  8058 sgd_solver.cpp:105] Iteration 128350, lr = 0.0001
I0619 14:10:40.734854  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 14:11:03.435808  8058 solver.cpp:218] Iteration 128400 (0.570837 iter/s, 87.5907s/50 iters), loss = 0.00994978
I0619 14:11:03.435899  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 14:11:03.435925  8058 solver.cpp:237]     Train net output #1: loss = 0.00994981 (* 1 = 0.00994981 loss)
I0619 14:11:03.435943  8058 sgd_solver.cpp:105] Iteration 128400, lr = 0.0001
I0619 14:12:30.975838  8058 solver.cpp:218] Iteration 128450 (0.57118 iter/s, 87.5381s/50 iters), loss = 0.00954672
I0619 14:12:30.975982  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 14:12:30.976011  8058 solver.cpp:237]     Train net output #1: loss = 0.00954675 (* 1 = 0.00954675 loss)
I0619 14:12:30.976027  8058 sgd_solver.cpp:105] Iteration 128450, lr = 0.0001
I0619 14:13:58.718251  8058 solver.cpp:218] Iteration 128500 (0.569862 iter/s, 87.7405s/50 iters), loss = 0.00905324
I0619 14:13:58.718367  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 14:13:58.718396  8058 solver.cpp:237]     Train net output #1: loss = 0.00905327 (* 1 = 0.00905327 loss)
I0619 14:13:58.718415  8058 sgd_solver.cpp:105] Iteration 128500, lr = 0.0001
I0619 14:14:11.052460  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 14:15:14.642408  8058 solver.cpp:218] Iteration 128550 (0.65856 iter/s, 75.9233s/50 iters), loss = 0.0139569
I0619 14:15:14.642560  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 14:15:14.642590  8058 solver.cpp:237]     Train net output #1: loss = 0.013957 (* 1 = 0.013957 loss)
I0619 14:15:14.642606  8058 sgd_solver.cpp:105] Iteration 128550, lr = 0.0001
I0619 14:16:35.433615  8058 solver.cpp:218] Iteration 128600 (0.618888 iter/s, 80.79s/50 iters), loss = 0.00926244
I0619 14:16:35.433713  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 14:16:35.433742  8058 solver.cpp:237]     Train net output #1: loss = 0.00926248 (* 1 = 0.00926248 loss)
I0619 14:16:35.433758  8058 sgd_solver.cpp:105] Iteration 128600, lr = 0.0001
I0619 14:17:22.795186  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 14:18:02.966481  8058 solver.cpp:218] Iteration 128650 (0.57122 iter/s, 87.5319s/50 iters), loss = 0.0104076
I0619 14:18:02.966598  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 14:18:02.966627  8058 solver.cpp:237]     Train net output #1: loss = 0.0104077 (* 1 = 0.0104077 loss)
I0619 14:18:02.966644  8058 sgd_solver.cpp:105] Iteration 128650, lr = 0.0001
I0619 14:19:30.502884  8058 solver.cpp:218] Iteration 128700 (0.571197 iter/s, 87.5354s/50 iters), loss = 0.0129334
I0619 14:19:30.503016  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 14:19:30.503046  8058 solver.cpp:237]     Train net output #1: loss = 0.0129334 (* 1 = 0.0129334 loss)
I0619 14:19:30.503062  8058 sgd_solver.cpp:105] Iteration 128700, lr = 0.0001
I0619 14:20:53.022685  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 14:20:58.208097  8058 solver.cpp:218] Iteration 128750 (0.570099 iter/s, 87.7041s/50 iters), loss = 0.0101743
I0619 14:20:58.208195  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 14:20:58.208227  8058 solver.cpp:237]     Train net output #1: loss = 0.0101743 (* 1 = 0.0101743 loss)
I0619 14:20:58.208248  8058 sgd_solver.cpp:105] Iteration 128750, lr = 0.0001
I0619 14:22:25.969071  8058 solver.cpp:218] Iteration 128800 (0.569735 iter/s, 87.76s/50 iters), loss = 0.0108108
I0619 14:22:25.969211  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 14:22:25.969240  8058 solver.cpp:237]     Train net output #1: loss = 0.0108108 (* 1 = 0.0108108 loss)
I0619 14:22:25.969257  8058 sgd_solver.cpp:105] Iteration 128800, lr = 0.0001
I0619 14:23:53.775252  8058 solver.cpp:218] Iteration 128850 (0.569449 iter/s, 87.8042s/50 iters), loss = 0.011701
I0619 14:23:53.775423  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 14:23:53.775454  8058 solver.cpp:237]     Train net output #1: loss = 0.0117011 (* 1 = 0.0117011 loss)
I0619 14:23:53.775475  8058 sgd_solver.cpp:105] Iteration 128850, lr = 0.0001
I0619 14:24:21.873667  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 14:25:18.201304  8058 solver.cpp:218] Iteration 128900 (0.592241 iter/s, 84.4251s/50 iters), loss = 0.0130836
I0619 14:25:18.201434  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 14:25:18.201464  8058 solver.cpp:237]     Train net output #1: loss = 0.0130836 (* 1 = 0.0130836 loss)
I0619 14:25:18.201481  8058 sgd_solver.cpp:105] Iteration 128900, lr = 0.0001
I0619 14:26:30.509989  8058 solver.cpp:218] Iteration 128950 (0.691487 iter/s, 72.3079s/50 iters), loss = 0.00918496
I0619 14:26:30.510121  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 14:26:30.510154  8058 solver.cpp:237]     Train net output #1: loss = 0.00918499 (* 1 = 0.00918499 loss)
I0619 14:26:30.510185  8058 sgd_solver.cpp:105] Iteration 128950, lr = 0.0001
I0619 14:27:33.734534  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 14:27:58.134966  8058 solver.cpp:218] Iteration 129000 (0.57062 iter/s, 87.624s/50 iters), loss = 0.0104455
I0619 14:27:58.135042  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 14:27:58.135069  8058 solver.cpp:237]     Train net output #1: loss = 0.0104456 (* 1 = 0.0104456 loss)
I0619 14:27:58.135087  8058 sgd_solver.cpp:105] Iteration 129000, lr = 0.0001
I0619 14:29:25.732693  8058 solver.cpp:218] Iteration 129050 (0.570797 iter/s, 87.5967s/50 iters), loss = 0.0119291
I0619 14:29:25.732831  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 14:29:25.732858  8058 solver.cpp:237]     Train net output #1: loss = 0.0119291 (* 1 = 0.0119291 loss)
I0619 14:29:25.732874  8058 sgd_solver.cpp:105] Iteration 129050, lr = 0.0001
I0619 14:30:53.371584  8058 solver.cpp:218] Iteration 129100 (0.570529 iter/s, 87.638s/50 iters), loss = 0.0130271
I0619 14:30:53.371716  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 14:30:53.371744  8058 solver.cpp:237]     Train net output #1: loss = 0.0130271 (* 1 = 0.0130271 loss)
I0619 14:30:53.371762  8058 sgd_solver.cpp:105] Iteration 129100, lr = 0.0001
I0619 14:31:04.064452  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 14:32:21.000087  8058 solver.cpp:218] Iteration 129150 (0.570603 iter/s, 87.6265s/50 iters), loss = 0.0118306
I0619 14:32:21.001154  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 14:32:21.001184  8058 solver.cpp:237]     Train net output #1: loss = 0.0118306 (* 1 = 0.0118306 loss)
I0619 14:32:21.001201  8058 sgd_solver.cpp:105] Iteration 129150, lr = 0.0001
I0619 14:33:49.181795  8058 solver.cpp:218] Iteration 129200 (0.567024 iter/s, 88.1798s/50 iters), loss = 0.00959242
I0619 14:33:49.181923  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 14:33:49.181952  8058 solver.cpp:237]     Train net output #1: loss = 0.00959245 (* 1 = 0.00959245 loss)
I0619 14:33:49.181973  8058 sgd_solver.cpp:105] Iteration 129200, lr = 0.0001
I0619 14:34:34.768640  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 14:35:16.852969  8058 solver.cpp:218] Iteration 129250 (0.570325 iter/s, 87.6693s/50 iters), loss = 0.00964978
I0619 14:35:16.853093  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 14:35:16.853121  8058 solver.cpp:237]     Train net output #1: loss = 0.00964981 (* 1 = 0.00964981 loss)
I0619 14:35:16.853137  8058 sgd_solver.cpp:105] Iteration 129250, lr = 0.0001
I0619 14:36:28.068794  8058 solver.cpp:218] Iteration 129300 (0.7021 iter/s, 71.215s/50 iters), loss = 0.00979409
I0619 14:36:28.068958  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 14:36:28.068987  8058 solver.cpp:237]     Train net output #1: loss = 0.00979412 (* 1 = 0.00979412 loss)
I0619 14:36:28.069005  8058 sgd_solver.cpp:105] Iteration 129300, lr = 0.0001
I0619 14:37:46.856220  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 14:37:53.728963  8058 solver.cpp:218] Iteration 129350 (0.583708 iter/s, 85.6593s/50 iters), loss = 0.0110683
I0619 14:37:53.729048  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 14:37:53.729075  8058 solver.cpp:237]     Train net output #1: loss = 0.0110683 (* 1 = 0.0110683 loss)
I0619 14:37:53.729091  8058 sgd_solver.cpp:105] Iteration 129350, lr = 0.0001
I0619 14:39:21.394345  8058 solver.cpp:218] Iteration 129400 (0.570356 iter/s, 87.6645s/50 iters), loss = 0.0110033
I0619 14:39:21.394537  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 14:39:21.394568  8058 solver.cpp:237]     Train net output #1: loss = 0.0110034 (* 1 = 0.0110034 loss)
I0619 14:39:21.394585  8058 sgd_solver.cpp:105] Iteration 129400, lr = 0.0001
I0619 14:40:48.943153  8058 solver.cpp:218] Iteration 129450 (0.571123 iter/s, 87.5469s/50 iters), loss = 0.00846232
I0619 14:40:48.943301  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 14:40:48.943343  8058 solver.cpp:237]     Train net output #1: loss = 0.00846236 (* 1 = 0.00846236 loss)
I0619 14:40:48.943361  8058 sgd_solver.cpp:105] Iteration 129450, lr = 0.0001
I0619 14:41:17.097920  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 14:42:16.493146  8058 solver.cpp:218] Iteration 129500 (0.571115 iter/s, 87.5481s/50 iters), loss = 0.0112495
I0619 14:42:16.493258  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 14:42:16.493288  8058 solver.cpp:237]     Train net output #1: loss = 0.0112496 (* 1 = 0.0112496 loss)
I0619 14:42:16.493304  8058 sgd_solver.cpp:105] Iteration 129500, lr = 0.0001
I0619 14:43:44.710193  8058 solver.cpp:218] Iteration 129550 (0.566796 iter/s, 88.2151s/50 iters), loss = 0.0122903
I0619 14:43:44.710315  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 14:43:44.710345  8058 solver.cpp:237]     Train net output #1: loss = 0.0122904 (* 1 = 0.0122904 loss)
I0619 14:43:44.710362  8058 sgd_solver.cpp:105] Iteration 129550, lr = 0.0001
I0619 14:44:48.364156  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 14:45:12.810153  8058 solver.cpp:218] Iteration 129600 (0.567552 iter/s, 88.0976s/50 iters), loss = 0.0103358
I0619 14:45:12.810230  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 14:45:12.810257  8058 solver.cpp:237]     Train net output #1: loss = 0.0103359 (* 1 = 0.0103359 loss)
I0619 14:45:12.810276  8058 sgd_solver.cpp:105] Iteration 129600, lr = 0.0001
I0619 14:46:29.504890  8058 solver.cpp:218] Iteration 129650 (0.651942 iter/s, 76.694s/50 iters), loss = 0.0104773
I0619 14:46:29.505019  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 14:46:29.505048  8058 solver.cpp:237]     Train net output #1: loss = 0.0104773 (* 1 = 0.0104773 loss)
I0619 14:46:29.505064  8058 sgd_solver.cpp:105] Iteration 129650, lr = 0.0001
I0619 14:47:50.275030  8058 solver.cpp:218] Iteration 129700 (0.619047 iter/s, 80.7693s/50 iters), loss = 0.0105502
I0619 14:47:50.275171  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 14:47:50.275199  8058 solver.cpp:237]     Train net output #1: loss = 0.0105503 (* 1 = 0.0105503 loss)
I0619 14:47:50.275218  8058 sgd_solver.cpp:105] Iteration 129700, lr = 0.0001
I0619 14:48:00.935237  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 14:49:18.405480  8058 solver.cpp:218] Iteration 129750 (0.567351 iter/s, 88.1288s/50 iters), loss = 0.0099512
I0619 14:49:18.405644  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 14:49:18.405678  8058 solver.cpp:237]     Train net output #1: loss = 0.00995123 (* 1 = 0.00995123 loss)
I0619 14:49:18.405696  8058 sgd_solver.cpp:105] Iteration 129750, lr = 0.0001
I0619 14:50:46.073158  8058 solver.cpp:218] Iteration 129800 (0.570348 iter/s, 87.6658s/50 iters), loss = 0.0110021
I0619 14:50:46.073318  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 14:50:46.073348  8058 solver.cpp:237]     Train net output #1: loss = 0.0110021 (* 1 = 0.0110021 loss)
I0619 14:50:46.073364  8058 sgd_solver.cpp:105] Iteration 129800, lr = 0.0001
I0619 14:51:31.677353  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 14:52:13.685685  8058 solver.cpp:218] Iteration 129850 (0.570707 iter/s, 87.6106s/50 iters), loss = 0.00957365
I0619 14:52:13.685802  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 14:52:13.685830  8058 solver.cpp:237]     Train net output #1: loss = 0.00957368 (* 1 = 0.00957368 loss)
I0619 14:52:13.685847  8058 sgd_solver.cpp:105] Iteration 129850, lr = 0.0001
I0619 14:53:41.296407  8058 solver.cpp:218] Iteration 129900 (0.570719 iter/s, 87.6088s/50 iters), loss = 0.0117045
I0619 14:53:41.296543  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 14:53:41.296573  8058 solver.cpp:237]     Train net output #1: loss = 0.0117045 (* 1 = 0.0117045 loss)
I0619 14:53:41.296591  8058 sgd_solver.cpp:105] Iteration 129900, lr = 0.0001
I0619 14:55:00.181113  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 14:55:08.819365  8058 solver.cpp:218] Iteration 129950 (0.571285 iter/s, 87.522s/50 iters), loss = 0.00907686
I0619 14:55:08.819444  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 14:55:08.819470  8058 solver.cpp:237]     Train net output #1: loss = 0.00907689 (* 1 = 0.00907689 loss)
I0619 14:55:08.819485  8058 sgd_solver.cpp:105] Iteration 129950, lr = 0.0001
I0619 14:56:32.163839  8058 solver.cpp:447] Snapshotting to binary proto file mobilenet/mobile_cub_iter_130000.caffemodel
I0619 14:56:32.245683  8058 sgd_solver.cpp:273] Snapshotting solver state to binary proto file mobilenet/mobile_cub_iter_130000.solverstate
I0619 14:56:33.428725  8058 solver.cpp:218] Iteration 130000 (0.590964 iter/s, 84.6075s/50 iters), loss = 0.0114412
I0619 14:56:33.428793  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 14:56:33.428817  8058 solver.cpp:237]     Train net output #1: loss = 0.0114412 (* 1 = 0.0114412 loss)
I0619 14:56:33.428833  8058 sgd_solver.cpp:105] Iteration 130000, lr = 0.0001
I0619 14:57:45.798796  8058 solver.cpp:218] Iteration 130050 (0.6909 iter/s, 72.3694s/50 iters), loss = 0.0105578
I0619 14:57:45.799007  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 14:57:45.799036  8058 solver.cpp:237]     Train net output #1: loss = 0.0105578 (* 1 = 0.0105578 loss)
I0619 14:57:45.799054  8058 sgd_solver.cpp:105] Iteration 130050, lr = 0.0001
I0619 14:58:12.224289  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 14:59:13.410692  8058 solver.cpp:218] Iteration 130100 (0.570707 iter/s, 87.6106s/50 iters), loss = 0.0129437
I0619 14:59:13.411034  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 14:59:13.411064  8058 solver.cpp:237]     Train net output #1: loss = 0.0129437 (* 1 = 0.0129437 loss)
I0619 14:59:13.411082  8058 sgd_solver.cpp:105] Iteration 130100, lr = 0.0001
I0619 15:00:41.044850  8058 solver.cpp:218] Iteration 130150 (0.570575 iter/s, 87.6309s/50 iters), loss = 0.0105372
I0619 15:00:41.044968  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 15:00:41.044996  8058 solver.cpp:237]     Train net output #1: loss = 0.0105372 (* 1 = 0.0105372 loss)
I0619 15:00:41.045013  8058 sgd_solver.cpp:105] Iteration 130150, lr = 0.0001
I0619 15:01:42.447057  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 15:02:08.625591  8058 solver.cpp:218] Iteration 130200 (0.570908 iter/s, 87.5798s/50 iters), loss = 0.00995338
I0619 15:02:08.625679  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 15:02:08.625705  8058 solver.cpp:237]     Train net output #1: loss = 0.00995342 (* 1 = 0.00995342 loss)
I0619 15:02:08.625723  8058 sgd_solver.cpp:105] Iteration 130200, lr = 0.0001
I0619 15:03:36.220813  8058 solver.cpp:218] Iteration 130250 (0.570813 iter/s, 87.5943s/50 iters), loss = 0.010195
I0619 15:03:36.220985  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 15:03:36.221015  8058 solver.cpp:237]     Train net output #1: loss = 0.010195 (* 1 = 0.010195 loss)
I0619 15:03:36.221036  8058 sgd_solver.cpp:105] Iteration 130250, lr = 0.0001
I0619 15:05:03.860126  8058 solver.cpp:218] Iteration 130300 (0.570526 iter/s, 87.6384s/50 iters), loss = 0.010512
I0619 15:05:03.860252  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 15:05:03.860280  8058 solver.cpp:237]     Train net output #1: loss = 0.0105121 (* 1 = 0.0105121 loss)
I0619 15:05:03.860298  8058 sgd_solver.cpp:105] Iteration 130300, lr = 0.0001
I0619 15:05:12.712909  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 15:06:31.397099  8058 solver.cpp:218] Iteration 130350 (0.5712 iter/s, 87.535s/50 iters), loss = 0.0111469
I0619 15:06:31.397193  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 15:06:31.397222  8058 solver.cpp:237]     Train net output #1: loss = 0.0111469 (* 1 = 0.0111469 loss)
I0619 15:06:31.397240  8058 sgd_solver.cpp:105] Iteration 130350, lr = 0.0001
I0619 15:07:43.088788  8058 solver.cpp:218] Iteration 130400 (0.697448 iter/s, 71.6899s/50 iters), loss = 0.00957801
I0619 15:07:43.088919  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 15:07:43.088948  8058 solver.cpp:237]     Train net output #1: loss = 0.00957805 (* 1 = 0.00957805 loss)
I0619 15:07:43.088966  8058 sgd_solver.cpp:105] Iteration 130400, lr = 0.0001
I0619 15:08:24.651196  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 15:09:08.343261  8058 solver.cpp:218] Iteration 130450 (0.586485 iter/s, 85.2536s/50 iters), loss = 0.0111466
I0619 15:09:08.343394  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 15:09:08.343422  8058 solver.cpp:237]     Train net output #1: loss = 0.0111467 (* 1 = 0.0111467 loss)
I0619 15:09:08.343439  8058 sgd_solver.cpp:105] Iteration 130450, lr = 0.0001
I0619 15:10:35.921140  8058 solver.cpp:218] Iteration 130500 (0.570933 iter/s, 87.576s/50 iters), loss = 0.00956007
I0619 15:10:35.921288  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 15:10:35.921316  8058 solver.cpp:237]     Train net output #1: loss = 0.00956011 (* 1 = 0.00956011 loss)
I0619 15:10:35.921334  8058 sgd_solver.cpp:105] Iteration 130500, lr = 0.0001
I0619 15:11:54.860031  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 15:12:03.523499  8058 solver.cpp:218] Iteration 130550 (0.570773 iter/s, 87.6004s/50 iters), loss = 0.0097819
I0619 15:12:03.523586  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 15:12:03.523615  8058 solver.cpp:237]     Train net output #1: loss = 0.00978193 (* 1 = 0.00978193 loss)
I0619 15:12:03.523635  8058 sgd_solver.cpp:105] Iteration 130550, lr = 0.0001
I0619 15:13:31.099040  8058 solver.cpp:218] Iteration 130600 (0.570942 iter/s, 87.5746s/50 iters), loss = 0.00900004
I0619 15:13:31.099176  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 15:13:31.099205  8058 solver.cpp:237]     Train net output #1: loss = 0.00900008 (* 1 = 0.00900008 loss)
I0619 15:13:31.099221  8058 sgd_solver.cpp:105] Iteration 130600, lr = 0.0001
I0619 15:14:58.913471  8058 solver.cpp:218] Iteration 130650 (0.569395 iter/s, 87.8126s/50 iters), loss = 0.0109555
I0619 15:14:58.913609  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 15:14:58.913638  8058 solver.cpp:237]     Train net output #1: loss = 0.0109556 (* 1 = 0.0109556 loss)
I0619 15:14:58.913655  8058 sgd_solver.cpp:105] Iteration 130650, lr = 0.0001
I0619 15:15:25.325299  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 15:16:26.676018  8058 solver.cpp:218] Iteration 130700 (0.569731 iter/s, 87.7607s/50 iters), loss = 0.0129508
I0619 15:16:26.676141  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 15:16:26.676170  8058 solver.cpp:237]     Train net output #1: loss = 0.0129509 (* 1 = 0.0129509 loss)
I0619 15:16:26.676190  8058 sgd_solver.cpp:105] Iteration 130700, lr = 0.0001
I0619 15:17:42.664561  8058 solver.cpp:218] Iteration 130750 (0.658009 iter/s, 75.9868s/50 iters), loss = 0.0119869
I0619 15:17:42.664737  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 15:17:42.664769  8058 solver.cpp:237]     Train net output #1: loss = 0.0119869 (* 1 = 0.0119869 loss)
I0619 15:17:42.664791  8058 sgd_solver.cpp:105] Iteration 130750, lr = 0.0001
I0619 15:18:37.292769  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 15:19:03.529136  8058 solver.cpp:218] Iteration 130800 (0.618324 iter/s, 80.8637s/50 iters), loss = 0.0118349
I0619 15:19:03.529220  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 15:19:03.529247  8058 solver.cpp:237]     Train net output #1: loss = 0.0118349 (* 1 = 0.0118349 loss)
I0619 15:19:03.529265  8058 sgd_solver.cpp:105] Iteration 130800, lr = 0.0001
I0619 15:20:31.086452  8058 solver.cpp:218] Iteration 130850 (0.57106 iter/s, 87.5565s/50 iters), loss = 0.0115199
I0619 15:20:31.086565  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 15:20:31.086592  8058 solver.cpp:237]     Train net output #1: loss = 0.01152 (* 1 = 0.01152 loss)
I0619 15:20:31.086611  8058 sgd_solver.cpp:105] Iteration 130850, lr = 0.0001
I0619 15:21:58.652827  8058 solver.cpp:218] Iteration 130900 (0.571001 iter/s, 87.5655s/50 iters), loss = 0.0144081
I0619 15:21:58.652937  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 15:21:58.652966  8058 solver.cpp:237]     Train net output #1: loss = 0.0144081 (* 1 = 0.0144081 loss)
I0619 15:21:58.652983  8058 sgd_solver.cpp:105] Iteration 130900, lr = 0.0001
I0619 15:22:05.807660  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 15:23:26.211882  8058 solver.cpp:218] Iteration 130950 (0.571049 iter/s, 87.5581s/50 iters), loss = 0.0093017
I0619 15:23:26.211987  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 15:23:26.212015  8058 solver.cpp:237]     Train net output #1: loss = 0.00930173 (* 1 = 0.00930173 loss)
I0619 15:23:26.212033  8058 sgd_solver.cpp:105] Iteration 130950, lr = 0.0001
I0619 15:24:53.813748  8058 solver.cpp:218] Iteration 131000 (0.570769 iter/s, 87.601s/50 iters), loss = 0.00862523
I0619 15:24:53.813886  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 15:24:53.813915  8058 solver.cpp:237]     Train net output #1: loss = 0.00862526 (* 1 = 0.00862526 loss)
I0619 15:24:53.813932  8058 sgd_solver.cpp:105] Iteration 131000, lr = 0.0001
I0619 15:25:35.957340  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 15:26:21.356011  8058 solver.cpp:218] Iteration 131050 (0.571184 iter/s, 87.5374s/50 iters), loss = 0.0109346
I0619 15:26:21.356143  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 15:26:21.356171  8058 solver.cpp:237]     Train net output #1: loss = 0.0109346 (* 1 = 0.0109346 loss)
I0619 15:26:21.356189  8058 sgd_solver.cpp:105] Iteration 131050, lr = 0.0001
I0619 15:27:46.730826  8058 solver.cpp:218] Iteration 131100 (0.585659 iter/s, 85.374s/50 iters), loss = 0.0122331
I0619 15:27:46.730948  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 15:27:46.730976  8058 solver.cpp:237]     Train net output #1: loss = 0.0122332 (* 1 = 0.0122332 loss)
I0619 15:27:46.730994  8058 sgd_solver.cpp:105] Iteration 131100, lr = 0.0001
I0619 15:28:47.458577  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 15:28:57.906795  8058 solver.cpp:218] Iteration 131150 (0.702491 iter/s, 71.1753s/50 iters), loss = 0.0129751
I0619 15:28:57.906873  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 15:28:57.906899  8058 solver.cpp:237]     Train net output #1: loss = 0.0129752 (* 1 = 0.0129752 loss)
I0619 15:28:57.906916  8058 sgd_solver.cpp:105] Iteration 131150, lr = 0.0001
I0619 15:30:25.524180  8058 solver.cpp:218] Iteration 131200 (0.570674 iter/s, 87.6157s/50 iters), loss = 0.0115869
I0619 15:30:25.524297  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 15:30:25.524327  8058 solver.cpp:237]     Train net output #1: loss = 0.011587 (* 1 = 0.011587 loss)
I0619 15:30:25.524344  8058 sgd_solver.cpp:105] Iteration 131200, lr = 0.0001
I0619 15:31:53.120035  8058 solver.cpp:218] Iteration 131250 (0.570809 iter/s, 87.595s/50 iters), loss = 0.011135
I0619 15:31:53.120200  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 15:31:53.120230  8058 solver.cpp:237]     Train net output #1: loss = 0.011135 (* 1 = 0.011135 loss)
I0619 15:31:53.120247  8058 sgd_solver.cpp:105] Iteration 131250, lr = 0.0001
I0619 15:32:17.803285  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 15:33:20.679352  8058 solver.cpp:218] Iteration 131300 (0.571048 iter/s, 87.5583s/50 iters), loss = 0.0100623
I0619 15:33:20.679476  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 15:33:20.679504  8058 solver.cpp:237]     Train net output #1: loss = 0.0100624 (* 1 = 0.0100624 loss)
I0619 15:33:20.679527  8058 sgd_solver.cpp:105] Iteration 131300, lr = 0.0001
I0619 15:34:48.230254  8058 solver.cpp:218] Iteration 131350 (0.571102 iter/s, 87.55s/50 iters), loss = 0.0127632
I0619 15:34:48.230371  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 15:34:48.230399  8058 solver.cpp:237]     Train net output #1: loss = 0.0127632 (* 1 = 0.0127632 loss)
I0619 15:34:48.230429  8058 sgd_solver.cpp:105] Iteration 131350, lr = 0.0001
I0619 15:35:47.918845  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 15:36:15.781796  8058 solver.cpp:218] Iteration 131400 (0.571098 iter/s, 87.5507s/50 iters), loss = 0.00964714
I0619 15:36:15.781883  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 15:36:15.781911  8058 solver.cpp:237]     Train net output #1: loss = 0.00964717 (* 1 = 0.00964717 loss)
I0619 15:36:15.781929  8058 sgd_solver.cpp:105] Iteration 131400, lr = 0.0001
I0619 15:37:43.394944  8058 solver.cpp:218] Iteration 131450 (0.570696 iter/s, 87.6123s/50 iters), loss = 0.0126381
I0619 15:37:43.395089  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 15:37:43.395117  8058 solver.cpp:237]     Train net output #1: loss = 0.0126381 (* 1 = 0.0126381 loss)
I0619 15:37:43.395134  8058 sgd_solver.cpp:105] Iteration 131450, lr = 0.0001
I0619 15:38:56.043977  8058 solver.cpp:218] Iteration 131500 (0.688248 iter/s, 72.6483s/50 iters), loss = 0.0120283
I0619 15:38:56.044126  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 15:38:56.044154  8058 solver.cpp:237]     Train net output #1: loss = 0.0120283 (* 1 = 0.0120283 loss)
I0619 15:38:56.044173  8058 sgd_solver.cpp:105] Iteration 131500, lr = 0.0001
I0619 15:39:00.730679  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 15:40:20.578999  8058 solver.cpp:218] Iteration 131550 (0.591477 iter/s, 84.5342s/50 iters), loss = 0.0110407
I0619 15:40:20.579152  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 15:40:20.579186  8058 solver.cpp:237]     Train net output #1: loss = 0.0110407 (* 1 = 0.0110407 loss)
I0619 15:40:20.579207  8058 sgd_solver.cpp:105] Iteration 131550, lr = 0.0001
I0619 15:41:48.281759  8058 solver.cpp:218] Iteration 131600 (0.57012 iter/s, 87.7008s/50 iters), loss = 0.00910473
I0619 15:41:48.283597  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 15:41:48.283638  8058 solver.cpp:237]     Train net output #1: loss = 0.00910476 (* 1 = 0.00910476 loss)
I0619 15:41:48.283668  8058 sgd_solver.cpp:105] Iteration 131600, lr = 0.0001
I0619 15:42:30.918187  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 15:43:16.420560  8058 solver.cpp:218] Iteration 131650 (0.567322 iter/s, 88.1334s/50 iters), loss = 0.010892
I0619 15:43:16.420775  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 15:43:16.420810  8058 solver.cpp:237]     Train net output #1: loss = 0.0108921 (* 1 = 0.0108921 loss)
I0619 15:43:16.420831  8058 sgd_solver.cpp:105] Iteration 131650, lr = 0.0001
I0619 15:44:44.141528  8058 solver.cpp:218] Iteration 131700 (0.570001 iter/s, 87.7192s/50 iters), loss = 0.0113142
I0619 15:44:44.141654  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 15:44:44.141683  8058 solver.cpp:237]     Train net output #1: loss = 0.0113143 (* 1 = 0.0113143 loss)
I0619 15:44:44.141705  8058 sgd_solver.cpp:105] Iteration 131700, lr = 0.0001
I0619 15:46:01.333014  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 15:46:11.739679  8058 solver.cpp:218] Iteration 131750 (0.570796 iter/s, 87.597s/50 iters), loss = 0.00940399
I0619 15:46:11.739768  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 15:46:11.739799  8058 solver.cpp:237]     Train net output #1: loss = 0.00940402 (* 1 = 0.00940402 loss)
I0619 15:46:11.739823  8058 sgd_solver.cpp:105] Iteration 131750, lr = 0.0001
I0619 15:47:39.823534  8058 solver.cpp:218] Iteration 131800 (0.567653 iter/s, 88.082s/50 iters), loss = 0.0126617
I0619 15:47:39.823715  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 15:47:39.823745  8058 solver.cpp:237]     Train net output #1: loss = 0.0126618 (* 1 = 0.0126618 loss)
I0619 15:47:39.823763  8058 sgd_solver.cpp:105] Iteration 131800, lr = 0.0001
I0619 15:48:59.729025  8058 solver.cpp:218] Iteration 131850 (0.625768 iter/s, 79.9019s/50 iters), loss = 0.0105915
I0619 15:48:59.729241  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 15:48:59.729284  8058 solver.cpp:237]     Train net output #1: loss = 0.0105915 (* 1 = 0.0105915 loss)
I0619 15:48:59.729302  8058 sgd_solver.cpp:105] Iteration 131850, lr = 0.0001
I0619 15:49:20.273401  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 15:50:21.915307  8058 solver.cpp:218] Iteration 131900 (0.608381 iter/s, 82.1853s/50 iters), loss = 0.0111743
I0619 15:50:21.915477  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 15:50:21.915510  8058 solver.cpp:237]     Train net output #1: loss = 0.0111744 (* 1 = 0.0111744 loss)
I0619 15:50:21.915539  8058 sgd_solver.cpp:105] Iteration 131900, lr = 0.0001
I0619 15:51:49.505018  8058 solver.cpp:218] Iteration 131950 (0.57085 iter/s, 87.5886s/50 iters), loss = 0.0133112
I0619 15:51:49.505165  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 15:51:49.505200  8058 solver.cpp:237]     Train net output #1: loss = 0.0133113 (* 1 = 0.0133113 loss)
I0619 15:51:49.505221  8058 sgd_solver.cpp:105] Iteration 131950, lr = 0.0001
I0619 15:52:47.365409  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 15:53:17.149240  8058 solver.cpp:218] Iteration 132000 (0.570501 iter/s, 87.6423s/50 iters), loss = 0.0138257
I0619 15:53:17.149315  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 15:53:17.149341  8058 solver.cpp:237]     Train net output #1: loss = 0.0138257 (* 1 = 0.0138257 loss)
I0619 15:53:17.149358  8058 sgd_solver.cpp:105] Iteration 132000, lr = 0.0001
I0619 15:54:44.706954  8058 solver.cpp:218] Iteration 132050 (0.571057 iter/s, 87.5569s/50 iters), loss = 0.00959626
I0619 15:54:44.707074  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 15:54:44.707103  8058 solver.cpp:237]     Train net output #1: loss = 0.00959629 (* 1 = 0.00959629 loss)
I0619 15:54:44.707120  8058 sgd_solver.cpp:105] Iteration 132050, lr = 0.0001
I0619 15:56:12.293602  8058 solver.cpp:218] Iteration 132100 (0.57087 iter/s, 87.5856s/50 iters), loss = 0.0128792
I0619 15:56:12.293722  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 15:56:12.293751  8058 solver.cpp:237]     Train net output #1: loss = 0.0128793 (* 1 = 0.0128793 loss)
I0619 15:56:12.293768  8058 sgd_solver.cpp:105] Iteration 132100, lr = 0.0001
I0619 15:56:17.655421  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 15:57:39.955284  8058 solver.cpp:218] Iteration 132150 (0.570381 iter/s, 87.6607s/50 iters), loss = 0.00887907
I0619 15:57:39.955427  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 15:57:39.955456  8058 solver.cpp:237]     Train net output #1: loss = 0.00887911 (* 1 = 0.00887911 loss)
I0619 15:57:39.955474  8058 sgd_solver.cpp:105] Iteration 132150, lr = 0.0001
I0619 15:59:03.751374  8058 solver.cpp:218] Iteration 132200 (0.596695 iter/s, 83.795s/50 iters), loss = 0.0107942
I0619 15:59:03.751534  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 15:59:03.751566  8058 solver.cpp:237]     Train net output #1: loss = 0.0107942 (* 1 = 0.0107942 loss)
I0619 15:59:03.751585  8058 sgd_solver.cpp:105] Iteration 132200, lr = 0.0001
I0619 15:59:35.692796  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 16:00:16.718782  8058 solver.cpp:218] Iteration 132250 (0.685245 iter/s, 72.9666s/50 iters), loss = 0.0118035
I0619 16:00:16.718945  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 16:00:16.718973  8058 solver.cpp:237]     Train net output #1: loss = 0.0118035 (* 1 = 0.0118035 loss)
I0619 16:00:16.718991  8058 sgd_solver.cpp:105] Iteration 132250, lr = 0.0001
I0619 16:01:44.318063  8058 solver.cpp:218] Iteration 132300 (0.570793 iter/s, 87.5974s/50 iters), loss = 0.00934953
I0619 16:01:44.320513  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 16:01:44.320549  8058 solver.cpp:237]     Train net output #1: loss = 0.00934956 (* 1 = 0.00934956 loss)
I0619 16:01:44.320567  8058 sgd_solver.cpp:105] Iteration 132300, lr = 0.0001
I0619 16:02:59.740787  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 16:03:11.868928  8058 solver.cpp:218] Iteration 132350 (0.571118 iter/s, 87.5475s/50 iters), loss = 0.0105969
I0619 16:03:11.869025  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 16:03:11.869058  8058 solver.cpp:237]     Train net output #1: loss = 0.010597 (* 1 = 0.010597 loss)
I0619 16:03:11.869079  8058 sgd_solver.cpp:105] Iteration 132350, lr = 0.0001
I0619 16:04:39.446033  8058 solver.cpp:218] Iteration 132400 (0.570938 iter/s, 87.5752s/50 iters), loss = 0.00797581
I0619 16:04:39.446149  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 16:04:39.446177  8058 solver.cpp:237]     Train net output #1: loss = 0.00797585 (* 1 = 0.00797585 loss)
I0619 16:04:39.446195  8058 sgd_solver.cpp:105] Iteration 132400, lr = 0.0001
I0619 16:06:06.957473  8058 solver.cpp:218] Iteration 132450 (0.57136 iter/s, 87.5105s/50 iters), loss = 0.0122729
I0619 16:06:06.957614  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 16:06:06.957641  8058 solver.cpp:237]     Train net output #1: loss = 0.012273 (* 1 = 0.012273 loss)
I0619 16:06:06.957659  8058 sgd_solver.cpp:105] Iteration 132450, lr = 0.0001
I0619 16:06:29.861842  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 16:07:34.565094  8058 solver.cpp:218] Iteration 132500 (0.570739 iter/s, 87.6057s/50 iters), loss = 0.0173211
I0619 16:07:34.565263  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 16:07:34.565292  8058 solver.cpp:237]     Train net output #1: loss = 0.0173211 (* 1 = 0.0173211 loss)
I0619 16:07:34.565310  8058 sgd_solver.cpp:105] Iteration 132500, lr = 0.0001
I0619 16:09:02.122568  8058 solver.cpp:218] Iteration 132550 (0.57106 iter/s, 87.5565s/50 iters), loss = 0.0099948
I0619 16:09:02.122689  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 16:09:02.122719  8058 solver.cpp:237]     Train net output #1: loss = 0.00999483 (* 1 = 0.00999483 loss)
I0619 16:09:02.122735  8058 sgd_solver.cpp:105] Iteration 132550, lr = 0.0001
I0619 16:09:48.295559  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 16:10:13.112162  8058 solver.cpp:218] Iteration 132600 (0.704346 iter/s, 70.9878s/50 iters), loss = 0.0113516
I0619 16:10:13.112241  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 16:10:13.112268  8058 solver.cpp:237]     Train net output #1: loss = 0.0113516 (* 1 = 0.0113516 loss)
I0619 16:10:13.112285  8058 sgd_solver.cpp:105] Iteration 132600, lr = 0.0001
I0619 16:11:38.808281  8058 solver.cpp:218] Iteration 132650 (0.583462 iter/s, 85.6953s/50 iters), loss = 0.0092157
I0619 16:11:38.808424  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 16:11:38.808457  8058 solver.cpp:237]     Train net output #1: loss = 0.00921573 (* 1 = 0.00921573 loss)
I0619 16:11:38.808478  8058 sgd_solver.cpp:105] Iteration 132650, lr = 0.0001
I0619 16:13:06.463670  8058 solver.cpp:218] Iteration 132700 (0.570428 iter/s, 87.6535s/50 iters), loss = 0.0104991
I0619 16:13:06.463855  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 16:13:06.463886  8058 solver.cpp:237]     Train net output #1: loss = 0.0104991 (* 1 = 0.0104991 loss)
I0619 16:13:06.463903  8058 sgd_solver.cpp:105] Iteration 132700, lr = 0.0001
I0619 16:13:11.782816  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 16:14:34.179276  8058 solver.cpp:218] Iteration 132750 (0.570036 iter/s, 87.7137s/50 iters), loss = 0.00911248
I0619 16:14:34.179425  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 16:14:34.179455  8058 solver.cpp:237]     Train net output #1: loss = 0.00911251 (* 1 = 0.00911251 loss)
I0619 16:14:34.179472  8058 sgd_solver.cpp:105] Iteration 132750, lr = 0.0001
I0619 16:16:01.791052  8058 solver.cpp:218] Iteration 132800 (0.570712 iter/s, 87.6099s/50 iters), loss = 0.0124931
I0619 16:16:01.791172  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 16:16:01.791200  8058 solver.cpp:237]     Train net output #1: loss = 0.0124931 (* 1 = 0.0124931 loss)
I0619 16:16:01.791218  8058 sgd_solver.cpp:105] Iteration 132800, lr = 0.0001
I0619 16:16:42.186256  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 16:17:29.440999  8058 solver.cpp:218] Iteration 132850 (0.570457 iter/s, 87.649s/50 iters), loss = 0.0094056
I0619 16:17:29.441191  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 16:17:29.441220  8058 solver.cpp:237]     Train net output #1: loss = 0.00940563 (* 1 = 0.00940563 loss)
I0619 16:17:29.441238  8058 sgd_solver.cpp:105] Iteration 132850, lr = 0.0001
I0619 16:18:57.090138  8058 solver.cpp:218] Iteration 132900 (0.570463 iter/s, 87.6482s/50 iters), loss = 0.0107108
I0619 16:18:57.090268  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 16:18:57.090301  8058 solver.cpp:237]     Train net output #1: loss = 0.0107108 (* 1 = 0.0107108 loss)
I0619 16:18:57.090322  8058 sgd_solver.cpp:105] Iteration 132900, lr = 0.0001
I0619 16:20:02.404259  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 16:20:13.022995  8058 solver.cpp:218] Iteration 132950 (0.658497 iter/s, 75.9304s/50 iters), loss = 0.00952695
I0619 16:20:13.023072  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 16:20:13.023098  8058 solver.cpp:237]     Train net output #1: loss = 0.00952698 (* 1 = 0.00952698 loss)
I0619 16:20:13.023116  8058 sgd_solver.cpp:105] Iteration 132950, lr = 0.0001
I0619 16:21:33.976783  8058 solver.cpp:218] Iteration 133000 (0.617644 iter/s, 80.9528s/50 iters), loss = 0.0116578
I0619 16:21:33.976933  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 16:21:33.976963  8058 solver.cpp:237]     Train net output #1: loss = 0.0116578 (* 1 = 0.0116578 loss)
I0619 16:21:33.976979  8058 sgd_solver.cpp:105] Iteration 133000, lr = 0.0001
I0619 16:23:01.513473  8058 solver.cpp:218] Iteration 133050 (0.571196 iter/s, 87.5356s/50 iters), loss = 0.011294
I0619 16:23:01.513620  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 16:23:01.513649  8058 solver.cpp:237]     Train net output #1: loss = 0.011294 (* 1 = 0.011294 loss)
I0619 16:23:01.513667  8058 sgd_solver.cpp:105] Iteration 133050, lr = 0.0001
I0619 16:23:22.615952  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 16:24:29.073968  8058 solver.cpp:218] Iteration 133100 (0.571041 iter/s, 87.5594s/50 iters), loss = 0.0104238
I0619 16:24:29.074080  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 16:24:29.074110  8058 solver.cpp:237]     Train net output #1: loss = 0.0104238 (* 1 = 0.0104238 loss)
I0619 16:24:29.074126  8058 sgd_solver.cpp:105] Iteration 133100, lr = 0.0001
I0619 16:25:56.704284  8058 solver.cpp:218] Iteration 133150 (0.570603 iter/s, 87.6265s/50 iters), loss = 0.0114705
I0619 16:25:56.704423  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 16:25:56.704457  8058 solver.cpp:237]     Train net output #1: loss = 0.0114705 (* 1 = 0.0114705 loss)
I0619 16:25:56.704478  8058 sgd_solver.cpp:105] Iteration 133150, lr = 0.0001
I0619 16:26:52.937610  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 16:27:24.237674  8058 solver.cpp:218] Iteration 133200 (0.571224 iter/s, 87.5314s/50 iters), loss = 0.00897604
I0619 16:27:24.237841  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 16:27:24.237870  8058 solver.cpp:237]     Train net output #1: loss = 0.00897607 (* 1 = 0.00897607 loss)
I0619 16:27:24.237887  8058 sgd_solver.cpp:105] Iteration 133200, lr = 0.0001
I0619 16:28:51.769584  8058 solver.cpp:218] Iteration 133250 (0.571234 iter/s, 87.5299s/50 iters), loss = 0.0101382
I0619 16:28:51.769788  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 16:28:51.769816  8058 solver.cpp:237]     Train net output #1: loss = 0.0101382 (* 1 = 0.0101382 loss)
I0619 16:28:51.769834  8058 sgd_solver.cpp:105] Iteration 133250, lr = 0.0001
I0619 16:30:16.505164  8058 solver.cpp:218] Iteration 133300 (0.590085 iter/s, 84.7336s/50 iters), loss = 0.0110352
I0619 16:30:16.505375  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 16:30:16.505409  8058 solver.cpp:237]     Train net output #1: loss = 0.0110352 (* 1 = 0.0110352 loss)
I0619 16:30:16.505446  8058 sgd_solver.cpp:105] Iteration 133300, lr = 0.0001
I0619 16:30:18.886476  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 16:31:27.992091  8058 solver.cpp:218] Iteration 133350 (0.699437 iter/s, 71.486s/50 iters), loss = 0.0128182
I0619 16:31:27.992249  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 16:31:27.992277  8058 solver.cpp:237]     Train net output #1: loss = 0.0128182 (* 1 = 0.0128182 loss)
I0619 16:31:27.992295  8058 sgd_solver.cpp:105] Iteration 133350, lr = 0.0001
I0619 16:32:55.699010  8058 solver.cpp:218] Iteration 133400 (0.570094 iter/s, 87.7049s/50 iters), loss = 0.00887657
I0619 16:32:55.699256  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 16:32:55.699290  8058 solver.cpp:237]     Train net output #1: loss = 0.0088766 (* 1 = 0.0088766 loss)
I0619 16:32:55.699309  8058 sgd_solver.cpp:105] Iteration 133400, lr = 0.0001
I0619 16:33:34.305356  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 16:34:23.349601  8058 solver.cpp:218] Iteration 133450 (0.57046 iter/s, 87.6486s/50 iters), loss = 0.0127722
I0619 16:34:23.349839  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 16:34:23.349874  8058 solver.cpp:237]     Train net output #1: loss = 0.0127722 (* 1 = 0.0127722 loss)
I0619 16:34:23.349894  8058 sgd_solver.cpp:105] Iteration 133450, lr = 0.0001
I0619 16:35:50.959138  8058 solver.cpp:218] Iteration 133500 (0.570721 iter/s, 87.6084s/50 iters), loss = 0.010889
I0619 16:35:50.959278  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 16:35:50.959311  8058 solver.cpp:237]     Train net output #1: loss = 0.0108891 (* 1 = 0.0108891 loss)
I0619 16:35:50.959332  8058 sgd_solver.cpp:105] Iteration 133500, lr = 0.0001
I0619 16:37:04.606711  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 16:37:18.576532  8058 solver.cpp:218] Iteration 133550 (0.570676 iter/s, 87.6154s/50 iters), loss = 0.0142465
I0619 16:37:18.576617  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 16:37:18.576642  8058 solver.cpp:237]     Train net output #1: loss = 0.0142465 (* 1 = 0.0142465 loss)
I0619 16:37:18.576660  8058 sgd_solver.cpp:105] Iteration 133550, lr = 0.0001
I0619 16:38:46.180932  8058 solver.cpp:218] Iteration 133600 (0.57076 iter/s, 87.6024s/50 iters), loss = 0.0139716
I0619 16:38:46.181123  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 16:38:46.181151  8058 solver.cpp:237]     Train net output #1: loss = 0.0139717 (* 1 = 0.0139717 loss)
I0619 16:38:46.181169  8058 sgd_solver.cpp:105] Iteration 133600, lr = 0.0001
I0619 16:40:13.863373  8058 solver.cpp:218] Iteration 133650 (0.570253 iter/s, 87.6804s/50 iters), loss = 0.0119353
I0619 16:40:13.863555  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 16:40:13.863586  8058 solver.cpp:237]     Train net output #1: loss = 0.0119353 (* 1 = 0.0119353 loss)
I0619 16:40:13.863605  8058 sgd_solver.cpp:105] Iteration 133650, lr = 0.0001
I0619 16:40:34.905401  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 16:41:26.072048  8058 solver.cpp:218] Iteration 133700 (0.692456 iter/s, 72.2068s/50 iters), loss = 0.00859114
I0619 16:41:26.072202  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 16:41:26.072232  8058 solver.cpp:237]     Train net output #1: loss = 0.00859117 (* 1 = 0.00859117 loss)
I0619 16:41:26.072249  8058 sgd_solver.cpp:105] Iteration 133700, lr = 0.0001
I0619 16:42:50.247236  8058 solver.cpp:218] Iteration 133750 (0.594006 iter/s, 84.1742s/50 iters), loss = 0.0116785
I0619 16:42:50.247373  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 16:42:50.247402  8058 solver.cpp:237]     Train net output #1: loss = 0.0116786 (* 1 = 0.0116786 loss)
I0619 16:42:50.247421  8058 sgd_solver.cpp:105] Iteration 133750, lr = 0.0001
I0619 16:43:46.415549  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 16:44:17.786587  8058 solver.cpp:218] Iteration 133800 (0.571178 iter/s, 87.5384s/50 iters), loss = 0.00908207
I0619 16:44:17.786737  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 16:44:17.786765  8058 solver.cpp:237]     Train net output #1: loss = 0.0090821 (* 1 = 0.0090821 loss)
I0619 16:44:17.786782  8058 sgd_solver.cpp:105] Iteration 133800, lr = 0.0001
I0619 16:45:45.364603  8058 solver.cpp:218] Iteration 133850 (0.570927 iter/s, 87.5769s/50 iters), loss = 0.011138
I0619 16:45:45.364749  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 16:45:45.364783  8058 solver.cpp:237]     Train net output #1: loss = 0.0111381 (* 1 = 0.0111381 loss)
I0619 16:45:45.364804  8058 sgd_solver.cpp:105] Iteration 133850, lr = 0.0001
I0619 16:47:12.943771  8058 solver.cpp:218] Iteration 133900 (0.570919 iter/s, 87.5782s/50 iters), loss = 0.0105856
I0619 16:47:12.943914  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 16:47:12.943943  8058 solver.cpp:237]     Train net output #1: loss = 0.0105857 (* 1 = 0.0105857 loss)
I0619 16:47:12.943960  8058 sgd_solver.cpp:105] Iteration 133900, lr = 0.0001
I0619 16:47:14.824353  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 16:48:40.509932  8058 solver.cpp:218] Iteration 133950 (0.571003 iter/s, 87.5652s/50 iters), loss = 0.0124424
I0619 16:48:40.510068  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 16:48:40.510097  8058 solver.cpp:237]     Train net output #1: loss = 0.0124425 (* 1 = 0.0124425 loss)
I0619 16:48:40.510114  8058 sgd_solver.cpp:105] Iteration 133950, lr = 0.0001
I0619 16:50:08.161730  8058 solver.cpp:218] Iteration 134000 (0.57047 iter/s, 87.647s/50 iters), loss = 0.0110871
I0619 16:50:08.161867  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 16:50:08.161896  8058 solver.cpp:237]     Train net output #1: loss = 0.0110871 (* 1 = 0.0110871 loss)
I0619 16:50:08.161914  8058 sgd_solver.cpp:105] Iteration 134000, lr = 0.0001
I0619 16:50:45.186900  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 16:51:24.547264  8058 solver.cpp:218] Iteration 134050 (0.654583 iter/s, 76.3845s/50 iters), loss = 0.0105169
I0619 16:51:24.547415  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 16:51:24.547456  8058 solver.cpp:237]     Train net output #1: loss = 0.0105169 (* 1 = 0.0105169 loss)
I0619 16:51:24.547479  8058 sgd_solver.cpp:105] Iteration 134050, lr = 0.0001
I0619 16:52:44.844652  8058 solver.cpp:218] Iteration 134100 (0.622692 iter/s, 80.2965s/50 iters), loss = 0.0105014
I0619 16:52:44.844831  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 16:52:44.844868  8058 solver.cpp:237]     Train net output #1: loss = 0.0105014 (* 1 = 0.0105014 loss)
I0619 16:52:44.844888  8058 sgd_solver.cpp:105] Iteration 134100, lr = 0.0001
I0619 16:53:56.984928  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 16:54:12.611130  8058 solver.cpp:218] Iteration 134150 (0.569724 iter/s, 87.7617s/50 iters), loss = 0.0121712
I0619 16:54:12.611232  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 16:54:12.611259  8058 solver.cpp:237]     Train net output #1: loss = 0.0121713 (* 1 = 0.0121713 loss)
I0619 16:54:12.611276  8058 sgd_solver.cpp:105] Iteration 134150, lr = 0.0001
I0619 16:55:43.838565  8058 solver.cpp:218] Iteration 134200 (0.548093 iter/s, 91.2254s/50 iters), loss = 0.0104014
I0619 16:55:43.838763  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 16:55:43.838800  8058 solver.cpp:237]     Train net output #1: loss = 0.0104015 (* 1 = 0.0104015 loss)
I0619 16:55:43.838819  8058 sgd_solver.cpp:105] Iteration 134200, lr = 0.0001
I0619 16:57:12.893746  8058 solver.cpp:218] Iteration 134250 (0.561462 iter/s, 89.0532s/50 iters), loss = 0.0100124
I0619 16:57:12.893904  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 16:57:12.893934  8058 solver.cpp:237]     Train net output #1: loss = 0.0100124 (* 1 = 0.0100124 loss)
I0619 16:57:12.893952  8058 sgd_solver.cpp:105] Iteration 134250, lr = 0.0001
I0619 16:57:32.270761  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 16:58:40.540601  8058 solver.cpp:218] Iteration 134300 (0.570485 iter/s, 87.6448s/50 iters), loss = 0.0106989
I0619 16:58:40.540690  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 16:58:40.540717  8058 solver.cpp:237]     Train net output #1: loss = 0.010699 (* 1 = 0.010699 loss)
I0619 16:58:40.540735  8058 sgd_solver.cpp:105] Iteration 134300, lr = 0.0001
I0619 17:00:08.322438  8058 solver.cpp:218] Iteration 134350 (0.569607 iter/s, 87.7799s/50 iters), loss = 0.0109279
I0619 17:00:08.322614  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 17:00:08.322643  8058 solver.cpp:237]     Train net output #1: loss = 0.0109279 (* 1 = 0.0109279 loss)
I0619 17:00:08.322660  8058 sgd_solver.cpp:105] Iteration 134350, lr = 0.0001
I0619 17:01:02.698070  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 17:01:33.301133  8058 solver.cpp:218] Iteration 134400 (0.588396 iter/s, 84.9768s/50 iters), loss = 0.0144298
I0619 17:01:33.301309  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 17:01:33.301338  8058 solver.cpp:237]     Train net output #1: loss = 0.0144298 (* 1 = 0.0144298 loss)
I0619 17:01:33.301357  8058 sgd_solver.cpp:105] Iteration 134400, lr = 0.0001
I0619 17:02:44.922582  8058 solver.cpp:218] Iteration 134450 (0.698123 iter/s, 71.6206s/50 iters), loss = 0.0117779
I0619 17:02:44.922915  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 17:02:44.922950  8058 solver.cpp:237]     Train net output #1: loss = 0.011778 (* 1 = 0.011778 loss)
I0619 17:02:44.922971  8058 sgd_solver.cpp:105] Iteration 134450, lr = 0.0001
I0619 17:04:12.541215  8058 solver.cpp:218] Iteration 134500 (0.570668 iter/s, 87.6167s/50 iters), loss = 0.014216
I0619 17:04:12.541436  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 17:04:12.541465  8058 solver.cpp:237]     Train net output #1: loss = 0.0142161 (* 1 = 0.0142161 loss)
I0619 17:04:12.541483  8058 sgd_solver.cpp:105] Iteration 134500, lr = 0.0001
I0619 17:04:14.419736  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 17:05:40.127856  8058 solver.cpp:218] Iteration 134550 (0.570871 iter/s, 87.5855s/50 iters), loss = 0.0116992
I0619 17:05:40.127998  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 17:05:40.128026  8058 solver.cpp:237]     Train net output #1: loss = 0.0116992 (* 1 = 0.0116992 loss)
I0619 17:05:40.128044  8058 sgd_solver.cpp:105] Iteration 134550, lr = 0.0001
I0619 17:07:07.709877  8058 solver.cpp:218] Iteration 134600 (0.570906 iter/s, 87.5801s/50 iters), loss = 0.0124325
I0619 17:07:07.710002  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 17:07:07.710031  8058 solver.cpp:237]     Train net output #1: loss = 0.0124325 (* 1 = 0.0124325 loss)
I0619 17:07:07.710049  8058 sgd_solver.cpp:105] Iteration 134600, lr = 0.0001
I0619 17:07:44.654216  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 17:08:35.326061  8058 solver.cpp:218] Iteration 134650 (0.570683 iter/s, 87.6143s/50 iters), loss = 0.0112526
I0619 17:08:35.326215  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 17:08:35.326243  8058 solver.cpp:237]     Train net output #1: loss = 0.0112526 (* 1 = 0.0112526 loss)
I0619 17:08:35.326261  8058 sgd_solver.cpp:105] Iteration 134650, lr = 0.0001
I0619 17:10:02.900887  8058 solver.cpp:218] Iteration 134700 (0.570953 iter/s, 87.5729s/50 iters), loss = 0.0101949
I0619 17:10:02.901046  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 17:10:02.901075  8058 solver.cpp:237]     Train net output #1: loss = 0.010195 (* 1 = 0.010195 loss)
I0619 17:10:02.901093  8058 sgd_solver.cpp:105] Iteration 134700, lr = 0.0001
I0619 17:11:14.820904  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 17:11:30.465179  8058 solver.cpp:218] Iteration 134750 (0.571022 iter/s, 87.5623s/50 iters), loss = 0.0112205
I0619 17:11:30.465266  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 17:11:30.465292  8058 solver.cpp:237]     Train net output #1: loss = 0.0112206 (* 1 = 0.0112206 loss)
I0619 17:11:30.465323  8058 sgd_solver.cpp:105] Iteration 134750, lr = 0.0001
I0619 17:12:43.001061  8058 solver.cpp:218] Iteration 134800 (0.689331 iter/s, 72.5341s/50 iters), loss = 0.0111998
I0619 17:12:43.001173  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 17:12:43.001201  8058 solver.cpp:237]     Train net output #1: loss = 0.0111998 (* 1 = 0.0111998 loss)
I0619 17:12:43.001219  8058 sgd_solver.cpp:105] Iteration 134800, lr = 0.0001
I0619 17:14:07.205952  8058 solver.cpp:218] Iteration 134850 (0.593796 iter/s, 84.204s/50 iters), loss = 0.0106
I0619 17:14:07.206092  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 17:14:07.206121  8058 solver.cpp:237]     Train net output #1: loss = 0.0106001 (* 1 = 0.0106001 loss)
I0619 17:14:07.206140  8058 sgd_solver.cpp:105] Iteration 134850, lr = 0.0001
I0619 17:14:24.819207  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 17:15:34.801133  8058 solver.cpp:218] Iteration 134900 (0.570815 iter/s, 87.5941s/50 iters), loss = 0.0118249
I0619 17:15:34.801288  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 17:15:34.801317  8058 solver.cpp:237]     Train net output #1: loss = 0.0118249 (* 1 = 0.0118249 loss)
I0619 17:15:34.801339  8058 sgd_solver.cpp:105] Iteration 134900, lr = 0.0001
I0619 17:17:02.458942  8058 solver.cpp:218] Iteration 134950 (0.570407 iter/s, 87.6568s/50 iters), loss = 0.0123604
I0619 17:17:02.459072  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 17:17:02.459101  8058 solver.cpp:237]     Train net output #1: loss = 0.0123604 (* 1 = 0.0123604 loss)
I0619 17:17:02.459118  8058 sgd_solver.cpp:105] Iteration 134950, lr = 0.0001
I0619 17:17:55.177986  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 17:18:30.048378  8058 solver.cpp:218] Iteration 135000 (0.570858 iter/s, 87.5874s/50 iters), loss = 0.0103916
I0619 17:18:30.048621  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 17:18:30.048650  8058 solver.cpp:237]     Train net output #1: loss = 0.0103917 (* 1 = 0.0103917 loss)
I0619 17:18:30.048668  8058 sgd_solver.cpp:105] Iteration 135000, lr = 0.0001
I0619 17:19:57.751940  8058 solver.cpp:218] Iteration 135050 (0.570115 iter/s, 87.7016s/50 iters), loss = 0.00819768
I0619 17:19:57.752058  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 17:19:57.752086  8058 solver.cpp:237]     Train net output #1: loss = 0.00819771 (* 1 = 0.00819771 loss)
I0619 17:19:57.752104  8058 sgd_solver.cpp:105] Iteration 135050, lr = 0.0001
I0619 17:21:25.467000  8058 solver.cpp:218] Iteration 135100 (0.57004 iter/s, 87.7131s/50 iters), loss = 0.0110729
I0619 17:21:25.467130  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 17:21:25.467164  8058 solver.cpp:237]     Train net output #1: loss = 0.0110729 (* 1 = 0.0110729 loss)
I0619 17:21:25.467185  8058 sgd_solver.cpp:105] Iteration 135100, lr = 0.0001
I0619 17:21:25.582525  8084 data_layer.cpp:73] Restarting data prefetching from start.
I0619 17:22:41.622563  8058 solver.cpp:218] Iteration 135150 (0.656567 iter/s, 76.1537s/50 iters), loss = 0.0100979
I0619 17:22:41.622711  8058 solver.cpp:237]     Train net output #0: accuracy = 1
I0619 17:22:41.622741  8058 solver.cpp:237]     Train net output #1: loss = 0.010098 (* 1 = 0.010098 loss)
I0619 17:22:41.622759  8058 sgd_solver.cpp:105] Iteration 135150, lr = 0.0001
train_cub.sh: line 2:  8058 Killed                  ../../build/tools/caffe.bin train -solver=mobilenet/solver_cub.prototxt -gpu=0
I0620 22:47:15.452258 32183 caffe.cpp:218] Using GPUs 1
I0620 22:47:15.600020 32183 caffe.cpp:223] GPU 1: Tesla K40m
I0620 22:47:16.049767 32183 solver.cpp:44] Initializing solver from parameters: 
test_iter: 124
test_interval: 500
base_lr: 0.01
display: 50
max_iter: 200000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 50000
snapshot: 10000
snapshot_prefix: "mobilenet/mobile_pruning"
solver_mode: GPU
device_id: 1
net: "/home/xingzhaolong/caffe_project/Auto_prune/models/oxford/mobilenet/mobilenet_deploy.prototxt_pruning"
train_state {
  level: 0
  stage: ""
}
iter_size: 5
I0620 22:47:16.050186 32183 solver.cpp:87] Creating training net from net file: /home/xingzhaolong/caffe_project/Auto_prune/models/oxford/mobilenet/mobilenet_deploy.prototxt_pruning
I0620 22:47:16.052801 32183 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/xingzhaolong/caffe_project/Auto_prune/models/oxford/mobilenet/mobilenet_deploy.prototxt_pruning
I0620 22:47:16.052830 32183 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0620 22:47:16.053129 32183 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0620 22:47:16.053225 32183 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0620 22:47:16.054188 32183 net.cpp:51] Initializing net from parameters: 
name: "MOBILENET"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_file: "/home/xingzhaolong/caffe_project/caffe/models/caffe-oxford102/imagenet_mean.binaryproto"
  }
  image_data_param {
    source: "/home/xingzhaolong/caffe_project/caffe/models/caffe-oxford102/test.txt"
    batch_size: 10
    new_height: 256
    new_width: 256
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv1/bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1/scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2_1/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv1"
  top: "conv2_1/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 32
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv2_1/dw"
  top: "conv2_1/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_1/dw/scale"
  type: "Scale"
  bottom: "conv2_1/dw"
  top: "conv2_1/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_1/dw"
  type: "ReLU"
  bottom: "conv2_1/dw"
  top: "conv2_1/dw"
}
layer {
  name: "conv2_1/sep"
  type: "CConvolution"
  bottom: "conv2_1/dw"
  top: "conv2_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv2_1/sep"
  top: "conv2_1/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_1/sep/scale"
  type: "Scale"
  bottom: "conv2_1/sep"
  top: "conv2_1/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_1/sep"
  type: "ReLU"
  bottom: "conv2_1/sep"
  top: "conv2_1/sep"
}
layer {
  name: "conv2_2/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv2_1/sep"
  top: "conv2_2/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 64
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv2_2/dw"
  top: "conv2_2/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_2/dw/scale"
  type: "Scale"
  bottom: "conv2_2/dw"
  top: "conv2_2/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_2/dw"
  type: "ReLU"
  bottom: "conv2_2/dw"
  top: "conv2_2/dw"
}
layer {
  name: "conv2_2/sep"
  type: "CConvolution"
  bottom: "conv2_2/dw"
  top: "conv2_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv2_2/sep"
  top: "conv2_2/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_2/sep/scale"
  type: "Scale"
  bottom: "conv2_2/sep"
  top: "conv2_2/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_2/sep"
  type: "ReLU"
  bottom: "conv2_2/sep"
  top: "conv2_2/sep"
}
layer {
  name: "conv3_1/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv2_2/sep"
  top: "conv3_1/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv3_1/dw"
  top: "conv3_1/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_1/dw/scale"
  type: "Scale"
  bottom: "conv3_1/dw"
  top: "conv3_1/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_1/dw"
  type: "ReLU"
  bottom: "conv3_1/dw"
  top: "conv3_1/dw"
}
layer {
  name: "conv3_1/sep"
  type: "CConvolution"
  bottom: "conv3_1/dw"
  top: "conv3_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv3_1/sep"
  top: "conv3_1/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_1/sep/scale"
  type: "Scale"
  bottom: "conv3_1/sep"
  top: "conv3_1/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_1/sep"
  type: "ReLU"
  bottom: "conv3_1/sep"
  top: "conv3_1/sep"
}
layer {
  name: "conv3_2/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv3_1/sep"
  top: "conv3_2/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv3_2/dw"
  top: "conv3_2/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_2/dw/scale"
  type: "Scale"
  bottom: "conv3_2/dw"
  top: "conv3_2/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_2/dw"
  type: "ReLU"
  bottom: "conv3_2/dw"
  top: "conv3_2/dw"
}
layer {
  name: "conv3_2/sep"
  type: "CConvolution"
  bottom: "conv3_2/dw"
  top: "conv3_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv3_2/sep"
  top: "conv3_2/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_2/sep/scale"
  type: "Scale"
  bottom: "conv3_2/sep"
  top: "conv3_2/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_2/sep"
  type: "ReLU"
  bottom: "conv3_2/sep"
  top: "conv3_2/sep"
}
layer {
  name: "conv4_1/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv3_2/sep"
  top: "conv4_1/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv4_1/dw"
  top: "conv4_1/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv4_1/dw/scale"
  type: "Scale"
  bottom: "conv4_1/dw"
  top: "conv4_1/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu4_1/dw"
  type: "ReLU"
  bottom: "conv4_1/dw"
  top: "conv4_1/dw"
}
layer {
  name: "conv4_1/sep"
  type: "CConvolution"
  bottom: "conv4_1/dw"
  top: "conv4_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv4_1/sep"
  top: "conv4_1/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv4_1/sep/scale"
  type: "Scale"
  bottom: "conv4_1/sep"
  top: "conv4_1/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu4_1/sep"
  type: "ReLU"
  bottom: "conv4_1/sep"
  top: "conv4_1/sep"
}
layer {
  name: "conv4_2/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv4_1/sep"
  top: "conv4_2/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv4_2/dw"
  top: "conv4_2/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv4_2/dw/scale"
  type: "Scale"
  bottom: "conv4_2/dw"
  top: "conv4_2/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu4_2/dw"
  type: "ReLU"
  bottom: "conv4_2/dw"
  top: "conv4_2/dw"
}
layer {
  name: "conv4_2/sep"
  type: "CConvolution"
  bottom: "conv4_2/dw"
  top: "conv4_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv4_2/sep"
  top: "conv4_2/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv4_2/sep/scale"
  type: "Scale"
  bottom: "conv4_2/sep"
  top: "conv4_2/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu4_2/sep"
  type: "ReLU"
  bottom: "conv4_2/sep"
  top: "conv4_2/sep"
}
layer {
  name: "conv5_1/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv4_2/sep"
  top: "conv5_1/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_1/dw"
  top: "conv5_1/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_1/dw/scale"
  type: "Scale"
  bottom: "conv5_1/dw"
  top: "conv5_1/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_1/dw"
  type: "ReLU"
  bottom: "conv5_1/dw"
  top: "conv5_1/dw"
}
layer {
  name: "conv5_1/sep"
  type: "CConvolution"
  bottom: "conv5_1/dw"
  top: "conv5_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_1/sep"
  top: "conv5_1/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_1/sep/scale"
  type: "Scale"
  bottom: "conv5_1/sep"
  top: "conv5_1/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_1/sep"
  type: "ReLU"
  bottom: "conv5_1/sep"
  top: "conv5_1/sep"
}
layer {
  name: "conv5_2/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_1/sep"
  top: "conv5_2/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_2/dw"
  top: "conv5_2/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_2/dw/scale"
  type: "Scale"
  bottom: "conv5_2/dw"
  top: "conv5_2/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_2/dw"
  type: "ReLU"
  bottom: "conv5_2/dw"
  top: "conv5_2/dw"
}
layer {
  name: "conv5_2/sep"
  type: "CConvolution"
  bottom: "conv5_2/dw"
  top: "conv5_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_2/sep"
  top: "conv5_2/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_2/sep/scale"
  type: "Scale"
  bottom: "conv5_2/sep"
  top: "conv5_2/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_2/sep"
  type: "ReLU"
  bottom: "conv5_2/sep"
  top: "conv5_2/sep"
}
layer {
  name: "conv5_3/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_2/sep"
  top: "conv5_3/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_3/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_3/dw"
  top: "conv5_3/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_3/dw/scale"
  type: "Scale"
  bottom: "conv5_3/dw"
  top: "conv5_3/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_3/dw"
  type: "ReLU"
  bottom: "conv5_3/dw"
  top: "conv5_3/dw"
}
layer {
  name: "conv5_3/sep"
  type: "CConvolution"
  bottom: "conv5_3/dw"
  top: "conv5_3/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_3/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_3/sep"
  top: "conv5_3/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_3/sep/scale"
  type: "Scale"
  bottom: "conv5_3/sep"
  top: "conv5_3/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_3/sep"
  type: "ReLU"
  bottom: "conv5_3/sep"
  top: "conv5_3/sep"
}
layer {
  name: "conv5_4/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_3/sep"
  top: "conv5_4/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_4/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_4/dw"
  top: "conv5_4/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_4/dw/scale"
  type: "Scale"
  bottom: "conv5_4/dw"
  top: "conv5_4/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_4/dw"
  type: "ReLU"
  bottom: "conv5_4/dw"
  top: "conv5_4/dw"
}
layer {
  name: "conv5_4/sep"
  type: "CConvolution"
  bottom: "conv5_4/dw"
  top: "conv5_4/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_4/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_4/sep"
  top: "conv5_4/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_4/sep/scale"
  type: "Scale"
  bottom: "conv5_4/sep"
  top: "conv5_4/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_4/sep"
  type: "ReLU"
  bottom: "conv5_4/sep"
  top: "conv5_4/sep"
}
layer {
  name: "conv5_5/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_4/sep"
  top: "conv5_5/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_5/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_5/dw"
  top: "conv5_5/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_5/dw/scale"
  type: "Scale"
  bottom: "conv5_5/dw"
  top: "conv5_5/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_5/dw"
  type: "ReLU"
  bottom: "conv5_5/dw"
  top: "conv5_5/dw"
}
layer {
  name: "conv5_5/sep"
  type: "CConvolution"
  bottom: "conv5_5/dw"
  top: "conv5_5/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_5/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_5/sep"
  top: "conv5_5/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_5/sep/scale"
  type: "Scale"
  bottom: "conv5_5/sep"
  top: "conv5_5/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_5/sep"
  type: "ReLU"
  bottom: "conv5_5/sep"
  top: "conv5_5/sep"
}
layer {
  name: "conv5_6/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_5/sep"
  top: "conv5_6/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_6/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_6/dw"
  top: "conv5_6/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_6/dw/scale"
  type: "Scale"
  bottom: "conv5_6/dw"
  top: "conv5_6/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_6/dw"
  type: "ReLU"
  bottom: "conv5_6/dw"
  top: "conv5_6/dw"
}
layer {
  name: "conv5_6/sep"
  type: "CConvolution"
  bottom: "conv5_6/dw"
  top: "conv5_6/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_6/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_6/sep"
  top: "conv5_6/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_6/sep/scale"
  type: "Scale"
  bottom: "conv5_6/sep"
  top: "conv5_6/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_6/sep"
  type: "ReLU"
  bottom: "conv5_6/sep"
  top: "conv5_6/sep"
}
layer {
  name: "conv6/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_6/sep"
  top: "conv6/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 1024
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv6/dw/bn"
  type: "BatchNorm"
  bottom: "conv6/dw"
  top: "conv6/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv6/dw/scale"
  type: "Scale"
  bottom: "conv6/dw"
  top: "conv6/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu6/dw"
  type: "ReLU"
  bottom: "conv6/dw"
  top: "conv6/dw"
}
layer {
  name: "conv6/sep"
  type: "CConvolution"
  bottom: "conv6/dw"
  top: "conv6/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv6/sep/bn"
  type: "BatchNorm"
  bottom: "conv6/sep"
  top: "conv6/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv6/sep/scale"
  type: "Scale"
  bottom: "conv6/sep"
  top: "conv6/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu6/sep"
  type: "ReLU"
  bottom: "conv6/sep"
  top: "conv6/sep"
}
layer {
  name: "pool6"
  type: "Pooling"
  bottom: "conv6/sep"
  top: "pool6"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc7_oxford"
  type: "CConvolution"
  bottom: "pool6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 102
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc7"
  bottom: "label"
  top: "loss"
}
I0620 22:47:16.054710 32183 layer_factory.hpp:77] Creating layer data
I0620 22:47:16.054819 32183 net.cpp:84] Creating Layer data
I0620 22:47:16.054843 32183 net.cpp:380] data -> data
I0620 22:47:16.054888 32183 net.cpp:380] data -> label
I0620 22:47:16.054924 32183 data_transformer.cpp:25] Loading mean file from: /home/xingzhaolong/caffe_project/caffe/models/caffe-oxford102/imagenet_mean.binaryproto
I0620 22:47:16.060190 32183 image_data_layer.cpp:38] Opening file /home/xingzhaolong/caffe_project/caffe/models/caffe-oxford102/test.txt
I0620 22:47:16.062559 32183 image_data_layer.cpp:63] A total of 6149 images.
I0620 22:47:16.071542 32183 image_data_layer.cpp:90] output data size: 10,3,224,224
I0620 22:47:16.095280 32183 net.cpp:122] Setting up data
I0620 22:47:16.095360 32183 net.cpp:129] Top shape: 10 3 224 224 (1505280)
I0620 22:47:16.095374 32183 net.cpp:129] Top shape: 10 (10)
I0620 22:47:16.095383 32183 net.cpp:137] Memory required for data: 6021160
I0620 22:47:16.095398 32183 layer_factory.hpp:77] Creating layer conv1
I0620 22:47:16.095453 32183 net.cpp:84] Creating Layer conv1
I0620 22:47:16.095468 32183 net.cpp:406] conv1 <- data
I0620 22:47:16.095504 32183 net.cpp:380] conv1 -> conv1
I0620 22:47:16.325291 32183 net.cpp:122] Setting up conv1
I0620 22:47:16.325363 32183 net.cpp:129] Top shape: 10 32 112 112 (4014080)
I0620 22:47:16.325373 32183 net.cpp:137] Memory required for data: 22077480
I0620 22:47:16.325402 32183 layer_factory.hpp:77] Creating layer conv1/bn
I0620 22:47:16.325428 32183 net.cpp:84] Creating Layer conv1/bn
I0620 22:47:16.325439 32183 net.cpp:406] conv1/bn <- conv1
I0620 22:47:16.325453 32183 net.cpp:367] conv1/bn -> conv1 (in-place)
I0620 22:47:16.326555 32183 net.cpp:122] Setting up conv1/bn
I0620 22:47:16.326580 32183 net.cpp:129] Top shape: 10 32 112 112 (4014080)
I0620 22:47:16.326589 32183 net.cpp:137] Memory required for data: 38133800
I0620 22:47:16.326611 32183 layer_factory.hpp:77] Creating layer conv1/scale
I0620 22:47:16.326632 32183 net.cpp:84] Creating Layer conv1/scale
I0620 22:47:16.326642 32183 net.cpp:406] conv1/scale <- conv1
I0620 22:47:16.326653 32183 net.cpp:367] conv1/scale -> conv1 (in-place)
I0620 22:47:16.326720 32183 layer_factory.hpp:77] Creating layer conv1/scale
I0620 22:47:16.326877 32183 net.cpp:122] Setting up conv1/scale
I0620 22:47:16.326895 32183 net.cpp:129] Top shape: 10 32 112 112 (4014080)
I0620 22:47:16.326905 32183 net.cpp:137] Memory required for data: 54190120
I0620 22:47:16.326920 32183 layer_factory.hpp:77] Creating layer relu1
I0620 22:47:16.326937 32183 net.cpp:84] Creating Layer relu1
I0620 22:47:16.326947 32183 net.cpp:406] relu1 <- conv1
I0620 22:47:16.326958 32183 net.cpp:367] relu1 -> conv1 (in-place)
I0620 22:47:16.327380 32183 net.cpp:122] Setting up relu1
I0620 22:47:16.327402 32183 net.cpp:129] Top shape: 10 32 112 112 (4014080)
I0620 22:47:16.327411 32183 net.cpp:137] Memory required for data: 70246440
I0620 22:47:16.327420 32183 layer_factory.hpp:77] Creating layer conv2_1/dw
I0620 22:47:16.327457 32183 net.cpp:84] Creating Layer conv2_1/dw
I0620 22:47:16.327467 32183 net.cpp:406] conv2_1/dw <- conv1
I0620 22:47:16.327481 32183 net.cpp:380] conv2_1/dw -> conv2_1/dw
I0620 22:47:16.328522 32183 net.cpp:122] Setting up conv2_1/dw
I0620 22:47:16.328572 32183 net.cpp:129] Top shape: 10 32 112 112 (4014080)
I0620 22:47:16.328580 32183 net.cpp:137] Memory required for data: 86302760
I0620 22:47:16.328591 32183 layer_factory.hpp:77] Creating layer conv2_1/dw/bn
I0620 22:47:16.328606 32183 net.cpp:84] Creating Layer conv2_1/dw/bn
I0620 22:47:16.328615 32183 net.cpp:406] conv2_1/dw/bn <- conv2_1/dw
I0620 22:47:16.328627 32183 net.cpp:367] conv2_1/dw/bn -> conv2_1/dw (in-place)
I0620 22:47:16.328862 32183 net.cpp:122] Setting up conv2_1/dw/bn
I0620 22:47:16.328881 32183 net.cpp:129] Top shape: 10 32 112 112 (4014080)
I0620 22:47:16.328889 32183 net.cpp:137] Memory required for data: 102359080
I0620 22:47:16.328907 32183 layer_factory.hpp:77] Creating layer conv2_1/dw/scale
I0620 22:47:16.328920 32183 net.cpp:84] Creating Layer conv2_1/dw/scale
I0620 22:47:16.328929 32183 net.cpp:406] conv2_1/dw/scale <- conv2_1/dw
I0620 22:47:16.328940 32183 net.cpp:367] conv2_1/dw/scale -> conv2_1/dw (in-place)
I0620 22:47:16.328994 32183 layer_factory.hpp:77] Creating layer conv2_1/dw/scale
I0620 22:47:16.329141 32183 net.cpp:122] Setting up conv2_1/dw/scale
I0620 22:47:16.329159 32183 net.cpp:129] Top shape: 10 32 112 112 (4014080)
I0620 22:47:16.329167 32183 net.cpp:137] Memory required for data: 118415400
I0620 22:47:16.329180 32183 layer_factory.hpp:77] Creating layer relu2_1/dw
I0620 22:47:16.329193 32183 net.cpp:84] Creating Layer relu2_1/dw
I0620 22:47:16.329202 32183 net.cpp:406] relu2_1/dw <- conv2_1/dw
I0620 22:47:16.329212 32183 net.cpp:367] relu2_1/dw -> conv2_1/dw (in-place)
I0620 22:47:16.329419 32183 net.cpp:122] Setting up relu2_1/dw
I0620 22:47:16.329438 32183 net.cpp:129] Top shape: 10 32 112 112 (4014080)
I0620 22:47:16.329447 32183 net.cpp:137] Memory required for data: 134471720
I0620 22:47:16.329455 32183 layer_factory.hpp:77] Creating layer conv2_1/sep
I0620 22:47:16.329474 32183 net.cpp:84] Creating Layer conv2_1/sep
I0620 22:47:16.329484 32183 net.cpp:406] conv2_1/sep <- conv2_1/dw
I0620 22:47:16.329496 32183 net.cpp:380] conv2_1/sep -> conv2_1/sep
I0620 22:47:16.330644 32183 net.cpp:122] Setting up conv2_1/sep
I0620 22:47:16.330668 32183 net.cpp:129] Top shape: 10 64 112 112 (8028160)
I0620 22:47:16.330677 32183 net.cpp:137] Memory required for data: 166584360
I0620 22:47:16.330690 32183 layer_factory.hpp:77] Creating layer conv2_1/sep/bn
I0620 22:47:16.330704 32183 net.cpp:84] Creating Layer conv2_1/sep/bn
I0620 22:47:16.330713 32183 net.cpp:406] conv2_1/sep/bn <- conv2_1/sep
I0620 22:47:16.330725 32183 net.cpp:367] conv2_1/sep/bn -> conv2_1/sep (in-place)
I0620 22:47:16.330945 32183 net.cpp:122] Setting up conv2_1/sep/bn
I0620 22:47:16.330961 32183 net.cpp:129] Top shape: 10 64 112 112 (8028160)
I0620 22:47:16.330971 32183 net.cpp:137] Memory required for data: 198697000
I0620 22:47:16.330987 32183 layer_factory.hpp:77] Creating layer conv2_1/sep/scale
I0620 22:47:16.331001 32183 net.cpp:84] Creating Layer conv2_1/sep/scale
I0620 22:47:16.331010 32183 net.cpp:406] conv2_1/sep/scale <- conv2_1/sep
I0620 22:47:16.331022 32183 net.cpp:367] conv2_1/sep/scale -> conv2_1/sep (in-place)
I0620 22:47:16.331075 32183 layer_factory.hpp:77] Creating layer conv2_1/sep/scale
I0620 22:47:16.331230 32183 net.cpp:122] Setting up conv2_1/sep/scale
I0620 22:47:16.331248 32183 net.cpp:129] Top shape: 10 64 112 112 (8028160)
I0620 22:47:16.331256 32183 net.cpp:137] Memory required for data: 230809640
I0620 22:47:16.331269 32183 layer_factory.hpp:77] Creating layer relu2_1/sep
I0620 22:47:16.331279 32183 net.cpp:84] Creating Layer relu2_1/sep
I0620 22:47:16.331288 32183 net.cpp:406] relu2_1/sep <- conv2_1/sep
I0620 22:47:16.331300 32183 net.cpp:367] relu2_1/sep -> conv2_1/sep (in-place)
I0620 22:47:16.331729 32183 net.cpp:122] Setting up relu2_1/sep
I0620 22:47:16.331753 32183 net.cpp:129] Top shape: 10 64 112 112 (8028160)
I0620 22:47:16.331760 32183 net.cpp:137] Memory required for data: 262922280
I0620 22:47:16.331769 32183 layer_factory.hpp:77] Creating layer conv2_2/dw
I0620 22:47:16.331787 32183 net.cpp:84] Creating Layer conv2_2/dw
I0620 22:47:16.331797 32183 net.cpp:406] conv2_2/dw <- conv2_1/sep
I0620 22:47:16.331825 32183 net.cpp:380] conv2_2/dw -> conv2_2/dw
I0620 22:47:16.332798 32183 net.cpp:122] Setting up conv2_2/dw
I0620 22:47:16.332820 32183 net.cpp:129] Top shape: 10 64 56 56 (2007040)
I0620 22:47:16.332828 32183 net.cpp:137] Memory required for data: 270950440
I0620 22:47:16.332839 32183 layer_factory.hpp:77] Creating layer conv2_2/dw/bn
I0620 22:47:16.332852 32183 net.cpp:84] Creating Layer conv2_2/dw/bn
I0620 22:47:16.332870 32183 net.cpp:406] conv2_2/dw/bn <- conv2_2/dw
I0620 22:47:16.332885 32183 net.cpp:367] conv2_2/dw/bn -> conv2_2/dw (in-place)
I0620 22:47:16.333118 32183 net.cpp:122] Setting up conv2_2/dw/bn
I0620 22:47:16.333135 32183 net.cpp:129] Top shape: 10 64 56 56 (2007040)
I0620 22:47:16.333143 32183 net.cpp:137] Memory required for data: 278978600
I0620 22:47:16.333158 32183 layer_factory.hpp:77] Creating layer conv2_2/dw/scale
I0620 22:47:16.333170 32183 net.cpp:84] Creating Layer conv2_2/dw/scale
I0620 22:47:16.333179 32183 net.cpp:406] conv2_2/dw/scale <- conv2_2/dw
I0620 22:47:16.333194 32183 net.cpp:367] conv2_2/dw/scale -> conv2_2/dw (in-place)
I0620 22:47:16.333247 32183 layer_factory.hpp:77] Creating layer conv2_2/dw/scale
I0620 22:47:16.333406 32183 net.cpp:122] Setting up conv2_2/dw/scale
I0620 22:47:16.333423 32183 net.cpp:129] Top shape: 10 64 56 56 (2007040)
I0620 22:47:16.333432 32183 net.cpp:137] Memory required for data: 287006760
I0620 22:47:16.333444 32183 layer_factory.hpp:77] Creating layer relu2_2/dw
I0620 22:47:16.333458 32183 net.cpp:84] Creating Layer relu2_2/dw
I0620 22:47:16.333467 32183 net.cpp:406] relu2_2/dw <- conv2_2/dw
I0620 22:47:16.333485 32183 net.cpp:367] relu2_2/dw -> conv2_2/dw (in-place)
I0620 22:47:16.333724 32183 net.cpp:122] Setting up relu2_2/dw
I0620 22:47:16.333745 32183 net.cpp:129] Top shape: 10 64 56 56 (2007040)
I0620 22:47:16.333753 32183 net.cpp:137] Memory required for data: 295034920
I0620 22:47:16.333761 32183 layer_factory.hpp:77] Creating layer conv2_2/sep
I0620 22:47:16.333778 32183 net.cpp:84] Creating Layer conv2_2/sep
I0620 22:47:16.333788 32183 net.cpp:406] conv2_2/sep <- conv2_2/dw
I0620 22:47:16.333804 32183 net.cpp:380] conv2_2/sep -> conv2_2/sep
I0620 22:47:16.334208 32183 net.cpp:122] Setting up conv2_2/sep
I0620 22:47:16.334228 32183 net.cpp:129] Top shape: 10 128 56 56 (4014080)
I0620 22:47:16.334235 32183 net.cpp:137] Memory required for data: 311091240
I0620 22:47:16.334249 32183 layer_factory.hpp:77] Creating layer conv2_2/sep/bn
I0620 22:47:16.334264 32183 net.cpp:84] Creating Layer conv2_2/sep/bn
I0620 22:47:16.334273 32183 net.cpp:406] conv2_2/sep/bn <- conv2_2/sep
I0620 22:47:16.334285 32183 net.cpp:367] conv2_2/sep/bn -> conv2_2/sep (in-place)
I0620 22:47:16.334511 32183 net.cpp:122] Setting up conv2_2/sep/bn
I0620 22:47:16.334537 32183 net.cpp:129] Top shape: 10 128 56 56 (4014080)
I0620 22:47:16.334544 32183 net.cpp:137] Memory required for data: 327147560
I0620 22:47:16.334558 32183 layer_factory.hpp:77] Creating layer conv2_2/sep/scale
I0620 22:47:16.334574 32183 net.cpp:84] Creating Layer conv2_2/sep/scale
I0620 22:47:16.334583 32183 net.cpp:406] conv2_2/sep/scale <- conv2_2/sep
I0620 22:47:16.334594 32183 net.cpp:367] conv2_2/sep/scale -> conv2_2/sep (in-place)
I0620 22:47:16.334652 32183 layer_factory.hpp:77] Creating layer conv2_2/sep/scale
I0620 22:47:16.334803 32183 net.cpp:122] Setting up conv2_2/sep/scale
I0620 22:47:16.334820 32183 net.cpp:129] Top shape: 10 128 56 56 (4014080)
I0620 22:47:16.334828 32183 net.cpp:137] Memory required for data: 343203880
I0620 22:47:16.334841 32183 layer_factory.hpp:77] Creating layer relu2_2/sep
I0620 22:47:16.334852 32183 net.cpp:84] Creating Layer relu2_2/sep
I0620 22:47:16.334861 32183 net.cpp:406] relu2_2/sep <- conv2_2/sep
I0620 22:47:16.334872 32183 net.cpp:367] relu2_2/sep -> conv2_2/sep (in-place)
I0620 22:47:16.335299 32183 net.cpp:122] Setting up relu2_2/sep
I0620 22:47:16.335319 32183 net.cpp:129] Top shape: 10 128 56 56 (4014080)
I0620 22:47:16.335328 32183 net.cpp:137] Memory required for data: 359260200
I0620 22:47:16.335336 32183 layer_factory.hpp:77] Creating layer conv3_1/dw
I0620 22:47:16.335369 32183 net.cpp:84] Creating Layer conv3_1/dw
I0620 22:47:16.335381 32183 net.cpp:406] conv3_1/dw <- conv2_2/sep
I0620 22:47:16.335393 32183 net.cpp:380] conv3_1/dw -> conv3_1/dw
I0620 22:47:16.335575 32183 net.cpp:122] Setting up conv3_1/dw
I0620 22:47:16.335595 32183 net.cpp:129] Top shape: 10 128 56 56 (4014080)
I0620 22:47:16.335604 32183 net.cpp:137] Memory required for data: 375316520
I0620 22:47:16.335630 32183 layer_factory.hpp:77] Creating layer conv3_1/dw/bn
I0620 22:47:16.335645 32183 net.cpp:84] Creating Layer conv3_1/dw/bn
I0620 22:47:16.335654 32183 net.cpp:406] conv3_1/dw/bn <- conv3_1/dw
I0620 22:47:16.335669 32183 net.cpp:367] conv3_1/dw/bn -> conv3_1/dw (in-place)
I0620 22:47:16.335896 32183 net.cpp:122] Setting up conv3_1/dw/bn
I0620 22:47:16.335912 32183 net.cpp:129] Top shape: 10 128 56 56 (4014080)
I0620 22:47:16.335921 32183 net.cpp:137] Memory required for data: 391372840
I0620 22:47:16.335933 32183 layer_factory.hpp:77] Creating layer conv3_1/dw/scale
I0620 22:47:16.335947 32183 net.cpp:84] Creating Layer conv3_1/dw/scale
I0620 22:47:16.335954 32183 net.cpp:406] conv3_1/dw/scale <- conv3_1/dw
I0620 22:47:16.335965 32183 net.cpp:367] conv3_1/dw/scale -> conv3_1/dw (in-place)
I0620 22:47:16.336021 32183 layer_factory.hpp:77] Creating layer conv3_1/dw/scale
I0620 22:47:16.336174 32183 net.cpp:122] Setting up conv3_1/dw/scale
I0620 22:47:16.336190 32183 net.cpp:129] Top shape: 10 128 56 56 (4014080)
I0620 22:47:16.336199 32183 net.cpp:137] Memory required for data: 407429160
I0620 22:47:16.336210 32183 layer_factory.hpp:77] Creating layer relu3_1/dw
I0620 22:47:16.336222 32183 net.cpp:84] Creating Layer relu3_1/dw
I0620 22:47:16.336231 32183 net.cpp:406] relu3_1/dw <- conv3_1/dw
I0620 22:47:16.336241 32183 net.cpp:367] relu3_1/dw -> conv3_1/dw (in-place)
I0620 22:47:16.336473 32183 net.cpp:122] Setting up relu3_1/dw
I0620 22:47:16.336496 32183 net.cpp:129] Top shape: 10 128 56 56 (4014080)
I0620 22:47:16.336505 32183 net.cpp:137] Memory required for data: 423485480
I0620 22:47:16.336519 32183 layer_factory.hpp:77] Creating layer conv3_1/sep
I0620 22:47:16.336539 32183 net.cpp:84] Creating Layer conv3_1/sep
I0620 22:47:16.336549 32183 net.cpp:406] conv3_1/sep <- conv3_1/dw
I0620 22:47:16.336560 32183 net.cpp:380] conv3_1/sep -> conv3_1/sep
I0620 22:47:16.337080 32183 net.cpp:122] Setting up conv3_1/sep
I0620 22:47:16.337100 32183 net.cpp:129] Top shape: 10 128 56 56 (4014080)
I0620 22:47:16.337107 32183 net.cpp:137] Memory required for data: 439541800
I0620 22:47:16.337119 32183 layer_factory.hpp:77] Creating layer conv3_1/sep/bn
I0620 22:47:16.337138 32183 net.cpp:84] Creating Layer conv3_1/sep/bn
I0620 22:47:16.337148 32183 net.cpp:406] conv3_1/sep/bn <- conv3_1/sep
I0620 22:47:16.337170 32183 net.cpp:367] conv3_1/sep/bn -> conv3_1/sep (in-place)
I0620 22:47:16.337394 32183 net.cpp:122] Setting up conv3_1/sep/bn
I0620 22:47:16.337411 32183 net.cpp:129] Top shape: 10 128 56 56 (4014080)
I0620 22:47:16.337419 32183 net.cpp:137] Memory required for data: 455598120
I0620 22:47:16.337433 32183 layer_factory.hpp:77] Creating layer conv3_1/sep/scale
I0620 22:47:16.337445 32183 net.cpp:84] Creating Layer conv3_1/sep/scale
I0620 22:47:16.337455 32183 net.cpp:406] conv3_1/sep/scale <- conv3_1/sep
I0620 22:47:16.337469 32183 net.cpp:367] conv3_1/sep/scale -> conv3_1/sep (in-place)
I0620 22:47:16.337530 32183 layer_factory.hpp:77] Creating layer conv3_1/sep/scale
I0620 22:47:16.337684 32183 net.cpp:122] Setting up conv3_1/sep/scale
I0620 22:47:16.337702 32183 net.cpp:129] Top shape: 10 128 56 56 (4014080)
I0620 22:47:16.337710 32183 net.cpp:137] Memory required for data: 471654440
I0620 22:47:16.337723 32183 layer_factory.hpp:77] Creating layer relu3_1/sep
I0620 22:47:16.337733 32183 net.cpp:84] Creating Layer relu3_1/sep
I0620 22:47:16.337743 32183 net.cpp:406] relu3_1/sep <- conv3_1/sep
I0620 22:47:16.337752 32183 net.cpp:367] relu3_1/sep -> conv3_1/sep (in-place)
I0620 22:47:16.338184 32183 net.cpp:122] Setting up relu3_1/sep
I0620 22:47:16.338217 32183 net.cpp:129] Top shape: 10 128 56 56 (4014080)
I0620 22:47:16.338227 32183 net.cpp:137] Memory required for data: 487710760
I0620 22:47:16.338234 32183 layer_factory.hpp:77] Creating layer conv3_2/dw
I0620 22:47:16.338253 32183 net.cpp:84] Creating Layer conv3_2/dw
I0620 22:47:16.338263 32183 net.cpp:406] conv3_2/dw <- conv3_1/sep
I0620 22:47:16.338277 32183 net.cpp:380] conv3_2/dw -> conv3_2/dw
I0620 22:47:16.338434 32183 net.cpp:122] Setting up conv3_2/dw
I0620 22:47:16.338454 32183 net.cpp:129] Top shape: 10 128 28 28 (1003520)
I0620 22:47:16.338461 32183 net.cpp:137] Memory required for data: 491724840
I0620 22:47:16.338471 32183 layer_factory.hpp:77] Creating layer conv3_2/dw/bn
I0620 22:47:16.338488 32183 net.cpp:84] Creating Layer conv3_2/dw/bn
I0620 22:47:16.338497 32183 net.cpp:406] conv3_2/dw/bn <- conv3_2/dw
I0620 22:47:16.338511 32183 net.cpp:367] conv3_2/dw/bn -> conv3_2/dw (in-place)
I0620 22:47:16.338752 32183 net.cpp:122] Setting up conv3_2/dw/bn
I0620 22:47:16.338769 32183 net.cpp:129] Top shape: 10 128 28 28 (1003520)
I0620 22:47:16.338778 32183 net.cpp:137] Memory required for data: 495738920
I0620 22:47:16.338790 32183 layer_factory.hpp:77] Creating layer conv3_2/dw/scale
I0620 22:47:16.338806 32183 net.cpp:84] Creating Layer conv3_2/dw/scale
I0620 22:47:16.338816 32183 net.cpp:406] conv3_2/dw/scale <- conv3_2/dw
I0620 22:47:16.338827 32183 net.cpp:367] conv3_2/dw/scale -> conv3_2/dw (in-place)
I0620 22:47:16.338884 32183 layer_factory.hpp:77] Creating layer conv3_2/dw/scale
I0620 22:47:16.339040 32183 net.cpp:122] Setting up conv3_2/dw/scale
I0620 22:47:16.339056 32183 net.cpp:129] Top shape: 10 128 28 28 (1003520)
I0620 22:47:16.339064 32183 net.cpp:137] Memory required for data: 499753000
I0620 22:47:16.339076 32183 layer_factory.hpp:77] Creating layer relu3_2/dw
I0620 22:47:16.339092 32183 net.cpp:84] Creating Layer relu3_2/dw
I0620 22:47:16.339100 32183 net.cpp:406] relu3_2/dw <- conv3_2/dw
I0620 22:47:16.339114 32183 net.cpp:367] relu3_2/dw -> conv3_2/dw (in-place)
I0620 22:47:16.339337 32183 net.cpp:122] Setting up relu3_2/dw
I0620 22:47:16.339355 32183 net.cpp:129] Top shape: 10 128 28 28 (1003520)
I0620 22:47:16.339365 32183 net.cpp:137] Memory required for data: 503767080
I0620 22:47:16.339372 32183 layer_factory.hpp:77] Creating layer conv3_2/sep
I0620 22:47:16.339390 32183 net.cpp:84] Creating Layer conv3_2/sep
I0620 22:47:16.339399 32183 net.cpp:406] conv3_2/sep <- conv3_2/dw
I0620 22:47:16.339414 32183 net.cpp:380] conv3_2/sep -> conv3_2/sep
I0620 22:47:16.340189 32183 net.cpp:122] Setting up conv3_2/sep
I0620 22:47:16.340210 32183 net.cpp:129] Top shape: 10 256 28 28 (2007040)
I0620 22:47:16.340219 32183 net.cpp:137] Memory required for data: 511795240
I0620 22:47:16.340230 32183 layer_factory.hpp:77] Creating layer conv3_2/sep/bn
I0620 22:47:16.340242 32183 net.cpp:84] Creating Layer conv3_2/sep/bn
I0620 22:47:16.340251 32183 net.cpp:406] conv3_2/sep/bn <- conv3_2/sep
I0620 22:47:16.340266 32183 net.cpp:367] conv3_2/sep/bn -> conv3_2/sep (in-place)
I0620 22:47:16.340500 32183 net.cpp:122] Setting up conv3_2/sep/bn
I0620 22:47:16.340523 32183 net.cpp:129] Top shape: 10 256 28 28 (2007040)
I0620 22:47:16.340533 32183 net.cpp:137] Memory required for data: 519823400
I0620 22:47:16.340548 32183 layer_factory.hpp:77] Creating layer conv3_2/sep/scale
I0620 22:47:16.340559 32183 net.cpp:84] Creating Layer conv3_2/sep/scale
I0620 22:47:16.340569 32183 net.cpp:406] conv3_2/sep/scale <- conv3_2/sep
I0620 22:47:16.340579 32183 net.cpp:367] conv3_2/sep/scale -> conv3_2/sep (in-place)
I0620 22:47:16.340641 32183 layer_factory.hpp:77] Creating layer conv3_2/sep/scale
I0620 22:47:16.340792 32183 net.cpp:122] Setting up conv3_2/sep/scale
I0620 22:47:16.340812 32183 net.cpp:129] Top shape: 10 256 28 28 (2007040)
I0620 22:47:16.340821 32183 net.cpp:137] Memory required for data: 527851560
I0620 22:47:16.340833 32183 layer_factory.hpp:77] Creating layer relu3_2/sep
I0620 22:47:16.340844 32183 net.cpp:84] Creating Layer relu3_2/sep
I0620 22:47:16.340853 32183 net.cpp:406] relu3_2/sep <- conv3_2/sep
I0620 22:47:16.340879 32183 net.cpp:367] relu3_2/sep -> conv3_2/sep (in-place)
I0620 22:47:16.341310 32183 net.cpp:122] Setting up relu3_2/sep
I0620 22:47:16.341331 32183 net.cpp:129] Top shape: 10 256 28 28 (2007040)
I0620 22:47:16.341339 32183 net.cpp:137] Memory required for data: 535879720
I0620 22:47:16.341347 32183 layer_factory.hpp:77] Creating layer conv4_1/dw
I0620 22:47:16.341361 32183 net.cpp:84] Creating Layer conv4_1/dw
I0620 22:47:16.341379 32183 net.cpp:406] conv4_1/dw <- conv3_2/sep
I0620 22:47:16.341395 32183 net.cpp:380] conv4_1/dw -> conv4_1/dw
I0620 22:47:16.341580 32183 net.cpp:122] Setting up conv4_1/dw
I0620 22:47:16.341600 32183 net.cpp:129] Top shape: 10 256 28 28 (2007040)
I0620 22:47:16.341609 32183 net.cpp:137] Memory required for data: 543907880
I0620 22:47:16.341619 32183 layer_factory.hpp:77] Creating layer conv4_1/dw/bn
I0620 22:47:16.341630 32183 net.cpp:84] Creating Layer conv4_1/dw/bn
I0620 22:47:16.341639 32183 net.cpp:406] conv4_1/dw/bn <- conv4_1/dw
I0620 22:47:16.341655 32183 net.cpp:367] conv4_1/dw/bn -> conv4_1/dw (in-place)
I0620 22:47:16.341888 32183 net.cpp:122] Setting up conv4_1/dw/bn
I0620 22:47:16.341905 32183 net.cpp:129] Top shape: 10 256 28 28 (2007040)
I0620 22:47:16.341913 32183 net.cpp:137] Memory required for data: 551936040
I0620 22:47:16.341926 32183 layer_factory.hpp:77] Creating layer conv4_1/dw/scale
I0620 22:47:16.341939 32183 net.cpp:84] Creating Layer conv4_1/dw/scale
I0620 22:47:16.341948 32183 net.cpp:406] conv4_1/dw/scale <- conv4_1/dw
I0620 22:47:16.341959 32183 net.cpp:367] conv4_1/dw/scale -> conv4_1/dw (in-place)
I0620 22:47:16.342016 32183 layer_factory.hpp:77] Creating layer conv4_1/dw/scale
I0620 22:47:16.342165 32183 net.cpp:122] Setting up conv4_1/dw/scale
I0620 22:47:16.342182 32183 net.cpp:129] Top shape: 10 256 28 28 (2007040)
I0620 22:47:16.342190 32183 net.cpp:137] Memory required for data: 559964200
I0620 22:47:16.342202 32183 layer_factory.hpp:77] Creating layer relu4_1/dw
I0620 22:47:16.342213 32183 net.cpp:84] Creating Layer relu4_1/dw
I0620 22:47:16.342236 32183 net.cpp:406] relu4_1/dw <- conv4_1/dw
I0620 22:47:16.342247 32183 net.cpp:367] relu4_1/dw -> conv4_1/dw (in-place)
I0620 22:47:16.342471 32183 net.cpp:122] Setting up relu4_1/dw
I0620 22:47:16.342490 32183 net.cpp:129] Top shape: 10 256 28 28 (2007040)
I0620 22:47:16.342499 32183 net.cpp:137] Memory required for data: 567992360
I0620 22:47:16.342506 32183 layer_factory.hpp:77] Creating layer conv4_1/sep
I0620 22:47:16.342530 32183 net.cpp:84] Creating Layer conv4_1/sep
I0620 22:47:16.342543 32183 net.cpp:406] conv4_1/sep <- conv4_1/dw
I0620 22:47:16.342558 32183 net.cpp:380] conv4_1/sep -> conv4_1/sep
I0620 22:47:16.343827 32183 net.cpp:122] Setting up conv4_1/sep
I0620 22:47:16.343847 32183 net.cpp:129] Top shape: 10 256 28 28 (2007040)
I0620 22:47:16.343857 32183 net.cpp:137] Memory required for data: 576020520
I0620 22:47:16.343883 32183 layer_factory.hpp:77] Creating layer conv4_1/sep/bn
I0620 22:47:16.343902 32183 net.cpp:84] Creating Layer conv4_1/sep/bn
I0620 22:47:16.343914 32183 net.cpp:406] conv4_1/sep/bn <- conv4_1/sep
I0620 22:47:16.343927 32183 net.cpp:367] conv4_1/sep/bn -> conv4_1/sep (in-place)
I0620 22:47:16.344154 32183 net.cpp:122] Setting up conv4_1/sep/bn
I0620 22:47:16.344172 32183 net.cpp:129] Top shape: 10 256 28 28 (2007040)
I0620 22:47:16.344179 32183 net.cpp:137] Memory required for data: 584048680
I0620 22:47:16.344193 32183 layer_factory.hpp:77] Creating layer conv4_1/sep/scale
I0620 22:47:16.344207 32183 net.cpp:84] Creating Layer conv4_1/sep/scale
I0620 22:47:16.344215 32183 net.cpp:406] conv4_1/sep/scale <- conv4_1/sep
I0620 22:47:16.344229 32183 net.cpp:367] conv4_1/sep/scale -> conv4_1/sep (in-place)
I0620 22:47:16.344285 32183 layer_factory.hpp:77] Creating layer conv4_1/sep/scale
I0620 22:47:16.344444 32183 net.cpp:122] Setting up conv4_1/sep/scale
I0620 22:47:16.344462 32183 net.cpp:129] Top shape: 10 256 28 28 (2007040)
I0620 22:47:16.344470 32183 net.cpp:137] Memory required for data: 592076840
I0620 22:47:16.344482 32183 layer_factory.hpp:77] Creating layer relu4_1/sep
I0620 22:47:16.344511 32183 net.cpp:84] Creating Layer relu4_1/sep
I0620 22:47:16.344530 32183 net.cpp:406] relu4_1/sep <- conv4_1/sep
I0620 22:47:16.344542 32183 net.cpp:367] relu4_1/sep -> conv4_1/sep (in-place)
I0620 22:47:16.344969 32183 net.cpp:122] Setting up relu4_1/sep
I0620 22:47:16.344990 32183 net.cpp:129] Top shape: 10 256 28 28 (2007040)
I0620 22:47:16.345006 32183 net.cpp:137] Memory required for data: 600105000
I0620 22:47:16.345016 32183 layer_factory.hpp:77] Creating layer conv4_2/dw
I0620 22:47:16.345033 32183 net.cpp:84] Creating Layer conv4_2/dw
I0620 22:47:16.345043 32183 net.cpp:406] conv4_2/dw <- conv4_1/sep
I0620 22:47:16.345058 32183 net.cpp:380] conv4_2/dw -> conv4_2/dw
I0620 22:47:16.345243 32183 net.cpp:122] Setting up conv4_2/dw
I0620 22:47:16.345263 32183 net.cpp:129] Top shape: 10 256 14 14 (501760)
I0620 22:47:16.345271 32183 net.cpp:137] Memory required for data: 602112040
I0620 22:47:16.345281 32183 layer_factory.hpp:77] Creating layer conv4_2/dw/bn
I0620 22:47:16.345297 32183 net.cpp:84] Creating Layer conv4_2/dw/bn
I0620 22:47:16.345307 32183 net.cpp:406] conv4_2/dw/bn <- conv4_2/dw
I0620 22:47:16.345321 32183 net.cpp:367] conv4_2/dw/bn -> conv4_2/dw (in-place)
I0620 22:47:16.345559 32183 net.cpp:122] Setting up conv4_2/dw/bn
I0620 22:47:16.345578 32183 net.cpp:129] Top shape: 10 256 14 14 (501760)
I0620 22:47:16.345587 32183 net.cpp:137] Memory required for data: 604119080
I0620 22:47:16.345599 32183 layer_factory.hpp:77] Creating layer conv4_2/dw/scale
I0620 22:47:16.345613 32183 net.cpp:84] Creating Layer conv4_2/dw/scale
I0620 22:47:16.345621 32183 net.cpp:406] conv4_2/dw/scale <- conv4_2/dw
I0620 22:47:16.345635 32183 net.cpp:367] conv4_2/dw/scale -> conv4_2/dw (in-place)
I0620 22:47:16.345690 32183 layer_factory.hpp:77] Creating layer conv4_2/dw/scale
I0620 22:47:16.345839 32183 net.cpp:122] Setting up conv4_2/dw/scale
I0620 22:47:16.345855 32183 net.cpp:129] Top shape: 10 256 14 14 (501760)
I0620 22:47:16.345863 32183 net.cpp:137] Memory required for data: 606126120
I0620 22:47:16.345875 32183 layer_factory.hpp:77] Creating layer relu4_2/dw
I0620 22:47:16.345887 32183 net.cpp:84] Creating Layer relu4_2/dw
I0620 22:47:16.345896 32183 net.cpp:406] relu4_2/dw <- conv4_2/dw
I0620 22:47:16.345906 32183 net.cpp:367] relu4_2/dw -> conv4_2/dw (in-place)
I0620 22:47:16.346341 32183 net.cpp:122] Setting up relu4_2/dw
I0620 22:47:16.346362 32183 net.cpp:129] Top shape: 10 256 14 14 (501760)
I0620 22:47:16.346371 32183 net.cpp:137] Memory required for data: 608133160
I0620 22:47:16.346380 32183 layer_factory.hpp:77] Creating layer conv4_2/sep
I0620 22:47:16.346396 32183 net.cpp:84] Creating Layer conv4_2/sep
I0620 22:47:16.346407 32183 net.cpp:406] conv4_2/sep <- conv4_2/dw
I0620 22:47:16.346422 32183 net.cpp:380] conv4_2/sep -> conv4_2/sep
I0620 22:47:16.349500 32183 net.cpp:122] Setting up conv4_2/sep
I0620 22:47:16.349532 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.349544 32183 net.cpp:137] Memory required for data: 612147240
I0620 22:47:16.349556 32183 layer_factory.hpp:77] Creating layer conv4_2/sep/bn
I0620 22:47:16.349573 32183 net.cpp:84] Creating Layer conv4_2/sep/bn
I0620 22:47:16.349583 32183 net.cpp:406] conv4_2/sep/bn <- conv4_2/sep
I0620 22:47:16.349594 32183 net.cpp:367] conv4_2/sep/bn -> conv4_2/sep (in-place)
I0620 22:47:16.349835 32183 net.cpp:122] Setting up conv4_2/sep/bn
I0620 22:47:16.349853 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.349861 32183 net.cpp:137] Memory required for data: 616161320
I0620 22:47:16.349874 32183 layer_factory.hpp:77] Creating layer conv4_2/sep/scale
I0620 22:47:16.349894 32183 net.cpp:84] Creating Layer conv4_2/sep/scale
I0620 22:47:16.349903 32183 net.cpp:406] conv4_2/sep/scale <- conv4_2/sep
I0620 22:47:16.349915 32183 net.cpp:367] conv4_2/sep/scale -> conv4_2/sep (in-place)
I0620 22:47:16.349970 32183 layer_factory.hpp:77] Creating layer conv4_2/sep/scale
I0620 22:47:16.350126 32183 net.cpp:122] Setting up conv4_2/sep/scale
I0620 22:47:16.350142 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.350165 32183 net.cpp:137] Memory required for data: 620175400
I0620 22:47:16.350178 32183 layer_factory.hpp:77] Creating layer relu4_2/sep
I0620 22:47:16.350193 32183 net.cpp:84] Creating Layer relu4_2/sep
I0620 22:47:16.350203 32183 net.cpp:406] relu4_2/sep <- conv4_2/sep
I0620 22:47:16.350214 32183 net.cpp:367] relu4_2/sep -> conv4_2/sep (in-place)
I0620 22:47:16.350456 32183 net.cpp:122] Setting up relu4_2/sep
I0620 22:47:16.350476 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.350486 32183 net.cpp:137] Memory required for data: 624189480
I0620 22:47:16.350493 32183 layer_factory.hpp:77] Creating layer conv5_1/dw
I0620 22:47:16.350510 32183 net.cpp:84] Creating Layer conv5_1/dw
I0620 22:47:16.350530 32183 net.cpp:406] conv5_1/dw <- conv4_2/sep
I0620 22:47:16.350546 32183 net.cpp:380] conv5_1/dw -> conv5_1/dw
I0620 22:47:16.350755 32183 net.cpp:122] Setting up conv5_1/dw
I0620 22:47:16.350774 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.350781 32183 net.cpp:137] Memory required for data: 628203560
I0620 22:47:16.350792 32183 layer_factory.hpp:77] Creating layer conv5_1/dw/bn
I0620 22:47:16.350808 32183 net.cpp:84] Creating Layer conv5_1/dw/bn
I0620 22:47:16.350818 32183 net.cpp:406] conv5_1/dw/bn <- conv5_1/dw
I0620 22:47:16.350829 32183 net.cpp:367] conv5_1/dw/bn -> conv5_1/dw (in-place)
I0620 22:47:16.351063 32183 net.cpp:122] Setting up conv5_1/dw/bn
I0620 22:47:16.351079 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.351088 32183 net.cpp:137] Memory required for data: 632217640
I0620 22:47:16.351100 32183 layer_factory.hpp:77] Creating layer conv5_1/dw/scale
I0620 22:47:16.351116 32183 net.cpp:84] Creating Layer conv5_1/dw/scale
I0620 22:47:16.351126 32183 net.cpp:406] conv5_1/dw/scale <- conv5_1/dw
I0620 22:47:16.351137 32183 net.cpp:367] conv5_1/dw/scale -> conv5_1/dw (in-place)
I0620 22:47:16.351192 32183 layer_factory.hpp:77] Creating layer conv5_1/dw/scale
I0620 22:47:16.351344 32183 net.cpp:122] Setting up conv5_1/dw/scale
I0620 22:47:16.351361 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.351369 32183 net.cpp:137] Memory required for data: 636231720
I0620 22:47:16.351382 32183 layer_factory.hpp:77] Creating layer relu5_1/dw
I0620 22:47:16.351394 32183 net.cpp:84] Creating Layer relu5_1/dw
I0620 22:47:16.351403 32183 net.cpp:406] relu5_1/dw <- conv5_1/dw
I0620 22:47:16.351416 32183 net.cpp:367] relu5_1/dw -> conv5_1/dw (in-place)
I0620 22:47:16.351860 32183 net.cpp:122] Setting up relu5_1/dw
I0620 22:47:16.351882 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.351891 32183 net.cpp:137] Memory required for data: 640245800
I0620 22:47:16.351899 32183 layer_factory.hpp:77] Creating layer conv5_1/sep
I0620 22:47:16.351915 32183 net.cpp:84] Creating Layer conv5_1/sep
I0620 22:47:16.351927 32183 net.cpp:406] conv5_1/sep <- conv5_1/dw
I0620 22:47:16.351941 32183 net.cpp:380] conv5_1/sep -> conv5_1/sep
I0620 22:47:16.357659 32183 net.cpp:122] Setting up conv5_1/sep
I0620 22:47:16.357702 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.357712 32183 net.cpp:137] Memory required for data: 644259880
I0620 22:47:16.357725 32183 layer_factory.hpp:77] Creating layer conv5_1/sep/bn
I0620 22:47:16.357744 32183 net.cpp:84] Creating Layer conv5_1/sep/bn
I0620 22:47:16.357754 32183 net.cpp:406] conv5_1/sep/bn <- conv5_1/sep
I0620 22:47:16.357769 32183 net.cpp:367] conv5_1/sep/bn -> conv5_1/sep (in-place)
I0620 22:47:16.358019 32183 net.cpp:122] Setting up conv5_1/sep/bn
I0620 22:47:16.358037 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.358045 32183 net.cpp:137] Memory required for data: 648273960
I0620 22:47:16.358059 32183 layer_factory.hpp:77] Creating layer conv5_1/sep/scale
I0620 22:47:16.358073 32183 net.cpp:84] Creating Layer conv5_1/sep/scale
I0620 22:47:16.358083 32183 net.cpp:406] conv5_1/sep/scale <- conv5_1/sep
I0620 22:47:16.358099 32183 net.cpp:367] conv5_1/sep/scale -> conv5_1/sep (in-place)
I0620 22:47:16.358175 32183 layer_factory.hpp:77] Creating layer conv5_1/sep/scale
I0620 22:47:16.358330 32183 net.cpp:122] Setting up conv5_1/sep/scale
I0620 22:47:16.358346 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.358355 32183 net.cpp:137] Memory required for data: 652288040
I0620 22:47:16.358366 32183 layer_factory.hpp:77] Creating layer relu5_1/sep
I0620 22:47:16.358378 32183 net.cpp:84] Creating Layer relu5_1/sep
I0620 22:47:16.358397 32183 net.cpp:406] relu5_1/sep <- conv5_1/sep
I0620 22:47:16.358408 32183 net.cpp:367] relu5_1/sep -> conv5_1/sep (in-place)
I0620 22:47:16.358672 32183 net.cpp:122] Setting up relu5_1/sep
I0620 22:47:16.358692 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.358700 32183 net.cpp:137] Memory required for data: 656302120
I0620 22:47:16.358710 32183 layer_factory.hpp:77] Creating layer conv5_2/dw
I0620 22:47:16.358724 32183 net.cpp:84] Creating Layer conv5_2/dw
I0620 22:47:16.358733 32183 net.cpp:406] conv5_2/dw <- conv5_1/sep
I0620 22:47:16.358749 32183 net.cpp:380] conv5_2/dw -> conv5_2/dw
I0620 22:47:16.358963 32183 net.cpp:122] Setting up conv5_2/dw
I0620 22:47:16.358980 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.358989 32183 net.cpp:137] Memory required for data: 660316200
I0620 22:47:16.358999 32183 layer_factory.hpp:77] Creating layer conv5_2/dw/bn
I0620 22:47:16.359011 32183 net.cpp:84] Creating Layer conv5_2/dw/bn
I0620 22:47:16.359025 32183 net.cpp:406] conv5_2/dw/bn <- conv5_2/dw
I0620 22:47:16.359041 32183 net.cpp:367] conv5_2/dw/bn -> conv5_2/dw (in-place)
I0620 22:47:16.359277 32183 net.cpp:122] Setting up conv5_2/dw/bn
I0620 22:47:16.359293 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.359302 32183 net.cpp:137] Memory required for data: 664330280
I0620 22:47:16.359315 32183 layer_factory.hpp:77] Creating layer conv5_2/dw/scale
I0620 22:47:16.359328 32183 net.cpp:84] Creating Layer conv5_2/dw/scale
I0620 22:47:16.359338 32183 net.cpp:406] conv5_2/dw/scale <- conv5_2/dw
I0620 22:47:16.359349 32183 net.cpp:367] conv5_2/dw/scale -> conv5_2/dw (in-place)
I0620 22:47:16.359407 32183 layer_factory.hpp:77] Creating layer conv5_2/dw/scale
I0620 22:47:16.359573 32183 net.cpp:122] Setting up conv5_2/dw/scale
I0620 22:47:16.359592 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.359601 32183 net.cpp:137] Memory required for data: 668344360
I0620 22:47:16.359612 32183 layer_factory.hpp:77] Creating layer relu5_2/dw
I0620 22:47:16.359637 32183 net.cpp:84] Creating Layer relu5_2/dw
I0620 22:47:16.359647 32183 net.cpp:406] relu5_2/dw <- conv5_2/dw
I0620 22:47:16.359661 32183 net.cpp:367] relu5_2/dw -> conv5_2/dw (in-place)
I0620 22:47:16.360123 32183 net.cpp:122] Setting up relu5_2/dw
I0620 22:47:16.360148 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.360157 32183 net.cpp:137] Memory required for data: 672358440
I0620 22:47:16.360167 32183 layer_factory.hpp:77] Creating layer conv5_2/sep
I0620 22:47:16.360185 32183 net.cpp:84] Creating Layer conv5_2/sep
I0620 22:47:16.360195 32183 net.cpp:406] conv5_2/sep <- conv5_2/dw
I0620 22:47:16.360208 32183 net.cpp:380] conv5_2/sep -> conv5_2/sep
I0620 22:47:16.365936 32183 net.cpp:122] Setting up conv5_2/sep
I0620 22:47:16.365983 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.365993 32183 net.cpp:137] Memory required for data: 676372520
I0620 22:47:16.366008 32183 layer_factory.hpp:77] Creating layer conv5_2/sep/bn
I0620 22:47:16.366022 32183 net.cpp:84] Creating Layer conv5_2/sep/bn
I0620 22:47:16.366032 32183 net.cpp:406] conv5_2/sep/bn <- conv5_2/sep
I0620 22:47:16.366049 32183 net.cpp:367] conv5_2/sep/bn -> conv5_2/sep (in-place)
I0620 22:47:16.366295 32183 net.cpp:122] Setting up conv5_2/sep/bn
I0620 22:47:16.366312 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.366322 32183 net.cpp:137] Memory required for data: 680386600
I0620 22:47:16.366335 32183 layer_factory.hpp:77] Creating layer conv5_2/sep/scale
I0620 22:47:16.366348 32183 net.cpp:84] Creating Layer conv5_2/sep/scale
I0620 22:47:16.366379 32183 net.cpp:406] conv5_2/sep/scale <- conv5_2/sep
I0620 22:47:16.366392 32183 net.cpp:367] conv5_2/sep/scale -> conv5_2/sep (in-place)
I0620 22:47:16.366451 32183 layer_factory.hpp:77] Creating layer conv5_2/sep/scale
I0620 22:47:16.366611 32183 net.cpp:122] Setting up conv5_2/sep/scale
I0620 22:47:16.366633 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.366642 32183 net.cpp:137] Memory required for data: 684400680
I0620 22:47:16.366663 32183 layer_factory.hpp:77] Creating layer relu5_2/sep
I0620 22:47:16.366677 32183 net.cpp:84] Creating Layer relu5_2/sep
I0620 22:47:16.366686 32183 net.cpp:406] relu5_2/sep <- conv5_2/sep
I0620 22:47:16.366699 32183 net.cpp:367] relu5_2/sep -> conv5_2/sep (in-place)
I0620 22:47:16.366957 32183 net.cpp:122] Setting up relu5_2/sep
I0620 22:47:16.366976 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.366986 32183 net.cpp:137] Memory required for data: 688414760
I0620 22:47:16.366993 32183 layer_factory.hpp:77] Creating layer conv5_3/dw
I0620 22:47:16.367015 32183 net.cpp:84] Creating Layer conv5_3/dw
I0620 22:47:16.367025 32183 net.cpp:406] conv5_3/dw <- conv5_2/sep
I0620 22:47:16.367038 32183 net.cpp:380] conv5_3/dw -> conv5_3/dw
I0620 22:47:16.367252 32183 net.cpp:122] Setting up conv5_3/dw
I0620 22:47:16.367270 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.367280 32183 net.cpp:137] Memory required for data: 692428840
I0620 22:47:16.367290 32183 layer_factory.hpp:77] Creating layer conv5_3/dw/bn
I0620 22:47:16.367305 32183 net.cpp:84] Creating Layer conv5_3/dw/bn
I0620 22:47:16.367314 32183 net.cpp:406] conv5_3/dw/bn <- conv5_3/dw
I0620 22:47:16.367326 32183 net.cpp:367] conv5_3/dw/bn -> conv5_3/dw (in-place)
I0620 22:47:16.367571 32183 net.cpp:122] Setting up conv5_3/dw/bn
I0620 22:47:16.367590 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.367599 32183 net.cpp:137] Memory required for data: 696442920
I0620 22:47:16.367611 32183 layer_factory.hpp:77] Creating layer conv5_3/dw/scale
I0620 22:47:16.367629 32183 net.cpp:84] Creating Layer conv5_3/dw/scale
I0620 22:47:16.367637 32183 net.cpp:406] conv5_3/dw/scale <- conv5_3/dw
I0620 22:47:16.367650 32183 net.cpp:367] conv5_3/dw/scale -> conv5_3/dw (in-place)
I0620 22:47:16.367705 32183 layer_factory.hpp:77] Creating layer conv5_3/dw/scale
I0620 22:47:16.367864 32183 net.cpp:122] Setting up conv5_3/dw/scale
I0620 22:47:16.367882 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.367889 32183 net.cpp:137] Memory required for data: 700457000
I0620 22:47:16.367902 32183 layer_factory.hpp:77] Creating layer relu5_3/dw
I0620 22:47:16.367916 32183 net.cpp:84] Creating Layer relu5_3/dw
I0620 22:47:16.367926 32183 net.cpp:406] relu5_3/dw <- conv5_3/dw
I0620 22:47:16.367936 32183 net.cpp:367] relu5_3/dw -> conv5_3/dw (in-place)
I0620 22:47:16.368374 32183 net.cpp:122] Setting up relu5_3/dw
I0620 22:47:16.368396 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.368404 32183 net.cpp:137] Memory required for data: 704471080
I0620 22:47:16.368412 32183 layer_factory.hpp:77] Creating layer conv5_3/sep
I0620 22:47:16.368430 32183 net.cpp:84] Creating Layer conv5_3/sep
I0620 22:47:16.368440 32183 net.cpp:406] conv5_3/sep <- conv5_3/dw
I0620 22:47:16.368456 32183 net.cpp:380] conv5_3/sep -> conv5_3/sep
I0620 22:47:16.374182 32183 net.cpp:122] Setting up conv5_3/sep
I0620 22:47:16.374222 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.374230 32183 net.cpp:137] Memory required for data: 708485160
I0620 22:47:16.374244 32183 layer_factory.hpp:77] Creating layer conv5_3/sep/bn
I0620 22:47:16.374267 32183 net.cpp:84] Creating Layer conv5_3/sep/bn
I0620 22:47:16.374279 32183 net.cpp:406] conv5_3/sep/bn <- conv5_3/sep
I0620 22:47:16.374291 32183 net.cpp:367] conv5_3/sep/bn -> conv5_3/sep (in-place)
I0620 22:47:16.374550 32183 net.cpp:122] Setting up conv5_3/sep/bn
I0620 22:47:16.374569 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.374577 32183 net.cpp:137] Memory required for data: 712499240
I0620 22:47:16.374613 32183 layer_factory.hpp:77] Creating layer conv5_3/sep/scale
I0620 22:47:16.374627 32183 net.cpp:84] Creating Layer conv5_3/sep/scale
I0620 22:47:16.374636 32183 net.cpp:406] conv5_3/sep/scale <- conv5_3/sep
I0620 22:47:16.374651 32183 net.cpp:367] conv5_3/sep/scale -> conv5_3/sep (in-place)
I0620 22:47:16.374707 32183 layer_factory.hpp:77] Creating layer conv5_3/sep/scale
I0620 22:47:16.374874 32183 net.cpp:122] Setting up conv5_3/sep/scale
I0620 22:47:16.374900 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.374910 32183 net.cpp:137] Memory required for data: 716513320
I0620 22:47:16.374922 32183 layer_factory.hpp:77] Creating layer relu5_3/sep
I0620 22:47:16.374934 32183 net.cpp:84] Creating Layer relu5_3/sep
I0620 22:47:16.374943 32183 net.cpp:406] relu5_3/sep <- conv5_3/sep
I0620 22:47:16.374953 32183 net.cpp:367] relu5_3/sep -> conv5_3/sep (in-place)
I0620 22:47:16.375218 32183 net.cpp:122] Setting up relu5_3/sep
I0620 22:47:16.375242 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.375252 32183 net.cpp:137] Memory required for data: 720527400
I0620 22:47:16.375260 32183 layer_factory.hpp:77] Creating layer conv5_4/dw
I0620 22:47:16.375275 32183 net.cpp:84] Creating Layer conv5_4/dw
I0620 22:47:16.375285 32183 net.cpp:406] conv5_4/dw <- conv5_3/sep
I0620 22:47:16.375300 32183 net.cpp:380] conv5_4/dw -> conv5_4/dw
I0620 22:47:16.375524 32183 net.cpp:122] Setting up conv5_4/dw
I0620 22:47:16.375546 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.375555 32183 net.cpp:137] Memory required for data: 724541480
I0620 22:47:16.375564 32183 layer_factory.hpp:77] Creating layer conv5_4/dw/bn
I0620 22:47:16.375577 32183 net.cpp:84] Creating Layer conv5_4/dw/bn
I0620 22:47:16.375586 32183 net.cpp:406] conv5_4/dw/bn <- conv5_4/dw
I0620 22:47:16.375600 32183 net.cpp:367] conv5_4/dw/bn -> conv5_4/dw (in-place)
I0620 22:47:16.375839 32183 net.cpp:122] Setting up conv5_4/dw/bn
I0620 22:47:16.375856 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.375864 32183 net.cpp:137] Memory required for data: 728555560
I0620 22:47:16.375879 32183 layer_factory.hpp:77] Creating layer conv5_4/dw/scale
I0620 22:47:16.375890 32183 net.cpp:84] Creating Layer conv5_4/dw/scale
I0620 22:47:16.375900 32183 net.cpp:406] conv5_4/dw/scale <- conv5_4/dw
I0620 22:47:16.375910 32183 net.cpp:367] conv5_4/dw/scale -> conv5_4/dw (in-place)
I0620 22:47:16.375967 32183 layer_factory.hpp:77] Creating layer conv5_4/dw/scale
I0620 22:47:16.376129 32183 net.cpp:122] Setting up conv5_4/dw/scale
I0620 22:47:16.376147 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.376155 32183 net.cpp:137] Memory required for data: 732569640
I0620 22:47:16.376195 32183 layer_factory.hpp:77] Creating layer relu5_4/dw
I0620 22:47:16.376209 32183 net.cpp:84] Creating Layer relu5_4/dw
I0620 22:47:16.376219 32183 net.cpp:406] relu5_4/dw <- conv5_4/dw
I0620 22:47:16.376230 32183 net.cpp:367] relu5_4/dw -> conv5_4/dw (in-place)
I0620 22:47:16.376684 32183 net.cpp:122] Setting up relu5_4/dw
I0620 22:47:16.376706 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.376715 32183 net.cpp:137] Memory required for data: 736583720
I0620 22:47:16.376724 32183 layer_factory.hpp:77] Creating layer conv5_4/sep
I0620 22:47:16.376741 32183 net.cpp:84] Creating Layer conv5_4/sep
I0620 22:47:16.376751 32183 net.cpp:406] conv5_4/sep <- conv5_4/dw
I0620 22:47:16.376766 32183 net.cpp:380] conv5_4/sep -> conv5_4/sep
I0620 22:47:16.382493 32183 net.cpp:122] Setting up conv5_4/sep
I0620 22:47:16.382539 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.382550 32183 net.cpp:137] Memory required for data: 740597800
I0620 22:47:16.382563 32183 layer_factory.hpp:77] Creating layer conv5_4/sep/bn
I0620 22:47:16.382582 32183 net.cpp:84] Creating Layer conv5_4/sep/bn
I0620 22:47:16.382592 32183 net.cpp:406] conv5_4/sep/bn <- conv5_4/sep
I0620 22:47:16.382604 32183 net.cpp:367] conv5_4/sep/bn -> conv5_4/sep (in-place)
I0620 22:47:16.382864 32183 net.cpp:122] Setting up conv5_4/sep/bn
I0620 22:47:16.382901 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.382912 32183 net.cpp:137] Memory required for data: 744611880
I0620 22:47:16.382927 32183 layer_factory.hpp:77] Creating layer conv5_4/sep/scale
I0620 22:47:16.382941 32183 net.cpp:84] Creating Layer conv5_4/sep/scale
I0620 22:47:16.382949 32183 net.cpp:406] conv5_4/sep/scale <- conv5_4/sep
I0620 22:47:16.382973 32183 net.cpp:367] conv5_4/sep/scale -> conv5_4/sep (in-place)
I0620 22:47:16.383033 32183 layer_factory.hpp:77] Creating layer conv5_4/sep/scale
I0620 22:47:16.383188 32183 net.cpp:122] Setting up conv5_4/sep/scale
I0620 22:47:16.383205 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.383214 32183 net.cpp:137] Memory required for data: 748625960
I0620 22:47:16.383226 32183 layer_factory.hpp:77] Creating layer relu5_4/sep
I0620 22:47:16.383240 32183 net.cpp:84] Creating Layer relu5_4/sep
I0620 22:47:16.383250 32183 net.cpp:406] relu5_4/sep <- conv5_4/sep
I0620 22:47:16.383261 32183 net.cpp:367] relu5_4/sep -> conv5_4/sep (in-place)
I0620 22:47:16.383533 32183 net.cpp:122] Setting up relu5_4/sep
I0620 22:47:16.383554 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.383569 32183 net.cpp:137] Memory required for data: 752640040
I0620 22:47:16.383577 32183 layer_factory.hpp:77] Creating layer conv5_5/dw
I0620 22:47:16.383592 32183 net.cpp:84] Creating Layer conv5_5/dw
I0620 22:47:16.383601 32183 net.cpp:406] conv5_5/dw <- conv5_4/sep
I0620 22:47:16.383617 32183 net.cpp:380] conv5_5/dw -> conv5_5/dw
I0620 22:47:16.383836 32183 net.cpp:122] Setting up conv5_5/dw
I0620 22:47:16.383857 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.383867 32183 net.cpp:137] Memory required for data: 756654120
I0620 22:47:16.383877 32183 layer_factory.hpp:77] Creating layer conv5_5/dw/bn
I0620 22:47:16.383888 32183 net.cpp:84] Creating Layer conv5_5/dw/bn
I0620 22:47:16.383898 32183 net.cpp:406] conv5_5/dw/bn <- conv5_5/dw
I0620 22:47:16.383911 32183 net.cpp:367] conv5_5/dw/bn -> conv5_5/dw (in-place)
I0620 22:47:16.384158 32183 net.cpp:122] Setting up conv5_5/dw/bn
I0620 22:47:16.384176 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.384183 32183 net.cpp:137] Memory required for data: 760668200
I0620 22:47:16.384196 32183 layer_factory.hpp:77] Creating layer conv5_5/dw/scale
I0620 22:47:16.384209 32183 net.cpp:84] Creating Layer conv5_5/dw/scale
I0620 22:47:16.384218 32183 net.cpp:406] conv5_5/dw/scale <- conv5_5/dw
I0620 22:47:16.384229 32183 net.cpp:367] conv5_5/dw/scale -> conv5_5/dw (in-place)
I0620 22:47:16.384291 32183 layer_factory.hpp:77] Creating layer conv5_5/dw/scale
I0620 22:47:16.384456 32183 net.cpp:122] Setting up conv5_5/dw/scale
I0620 22:47:16.384474 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.384481 32183 net.cpp:137] Memory required for data: 764682280
I0620 22:47:16.384493 32183 layer_factory.hpp:77] Creating layer relu5_5/dw
I0620 22:47:16.384505 32183 net.cpp:84] Creating Layer relu5_5/dw
I0620 22:47:16.384521 32183 net.cpp:406] relu5_5/dw <- conv5_5/dw
I0620 22:47:16.384538 32183 net.cpp:367] relu5_5/dw -> conv5_5/dw (in-place)
I0620 22:47:16.384989 32183 net.cpp:122] Setting up relu5_5/dw
I0620 22:47:16.385010 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.385018 32183 net.cpp:137] Memory required for data: 768696360
I0620 22:47:16.385026 32183 layer_factory.hpp:77] Creating layer conv5_5/sep
I0620 22:47:16.385041 32183 net.cpp:84] Creating Layer conv5_5/sep
I0620 22:47:16.385051 32183 net.cpp:406] conv5_5/sep <- conv5_5/dw
I0620 22:47:16.385068 32183 net.cpp:380] conv5_5/sep -> conv5_5/sep
I0620 22:47:16.390939 32183 net.cpp:122] Setting up conv5_5/sep
I0620 22:47:16.390980 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.390988 32183 net.cpp:137] Memory required for data: 772710440
I0620 22:47:16.391002 32183 layer_factory.hpp:77] Creating layer conv5_5/sep/bn
I0620 22:47:16.391021 32183 net.cpp:84] Creating Layer conv5_5/sep/bn
I0620 22:47:16.391032 32183 net.cpp:406] conv5_5/sep/bn <- conv5_5/sep
I0620 22:47:16.391067 32183 net.cpp:367] conv5_5/sep/bn -> conv5_5/sep (in-place)
I0620 22:47:16.391327 32183 net.cpp:122] Setting up conv5_5/sep/bn
I0620 22:47:16.391345 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.391353 32183 net.cpp:137] Memory required for data: 776724520
I0620 22:47:16.391367 32183 layer_factory.hpp:77] Creating layer conv5_5/sep/scale
I0620 22:47:16.391391 32183 net.cpp:84] Creating Layer conv5_5/sep/scale
I0620 22:47:16.391402 32183 net.cpp:406] conv5_5/sep/scale <- conv5_5/sep
I0620 22:47:16.391417 32183 net.cpp:367] conv5_5/sep/scale -> conv5_5/sep (in-place)
I0620 22:47:16.391475 32183 layer_factory.hpp:77] Creating layer conv5_5/sep/scale
I0620 22:47:16.391649 32183 net.cpp:122] Setting up conv5_5/sep/scale
I0620 22:47:16.391669 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.391676 32183 net.cpp:137] Memory required for data: 780738600
I0620 22:47:16.391690 32183 layer_factory.hpp:77] Creating layer relu5_5/sep
I0620 22:47:16.391701 32183 net.cpp:84] Creating Layer relu5_5/sep
I0620 22:47:16.391710 32183 net.cpp:406] relu5_5/sep <- conv5_5/sep
I0620 22:47:16.391721 32183 net.cpp:367] relu5_5/sep -> conv5_5/sep (in-place)
I0620 22:47:16.391985 32183 net.cpp:122] Setting up relu5_5/sep
I0620 22:47:16.392004 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.392012 32183 net.cpp:137] Memory required for data: 784752680
I0620 22:47:16.392021 32183 layer_factory.hpp:77] Creating layer conv5_6/dw
I0620 22:47:16.392036 32183 net.cpp:84] Creating Layer conv5_6/dw
I0620 22:47:16.392045 32183 net.cpp:406] conv5_6/dw <- conv5_5/sep
I0620 22:47:16.392061 32183 net.cpp:380] conv5_6/dw -> conv5_6/dw
I0620 22:47:16.392277 32183 net.cpp:122] Setting up conv5_6/dw
I0620 22:47:16.392294 32183 net.cpp:129] Top shape: 10 512 7 7 (250880)
I0620 22:47:16.392302 32183 net.cpp:137] Memory required for data: 785756200
I0620 22:47:16.392313 32183 layer_factory.hpp:77] Creating layer conv5_6/dw/bn
I0620 22:47:16.392325 32183 net.cpp:84] Creating Layer conv5_6/dw/bn
I0620 22:47:16.392334 32183 net.cpp:406] conv5_6/dw/bn <- conv5_6/dw
I0620 22:47:16.392349 32183 net.cpp:367] conv5_6/dw/bn -> conv5_6/dw (in-place)
I0620 22:47:16.392627 32183 net.cpp:122] Setting up conv5_6/dw/bn
I0620 22:47:16.392645 32183 net.cpp:129] Top shape: 10 512 7 7 (250880)
I0620 22:47:16.392653 32183 net.cpp:137] Memory required for data: 786759720
I0620 22:47:16.392666 32183 layer_factory.hpp:77] Creating layer conv5_6/dw/scale
I0620 22:47:16.392679 32183 net.cpp:84] Creating Layer conv5_6/dw/scale
I0620 22:47:16.392688 32183 net.cpp:406] conv5_6/dw/scale <- conv5_6/dw
I0620 22:47:16.392699 32183 net.cpp:367] conv5_6/dw/scale -> conv5_6/dw (in-place)
I0620 22:47:16.392757 32183 layer_factory.hpp:77] Creating layer conv5_6/dw/scale
I0620 22:47:16.392921 32183 net.cpp:122] Setting up conv5_6/dw/scale
I0620 22:47:16.392938 32183 net.cpp:129] Top shape: 10 512 7 7 (250880)
I0620 22:47:16.392947 32183 net.cpp:137] Memory required for data: 787763240
I0620 22:47:16.392959 32183 layer_factory.hpp:77] Creating layer relu5_6/dw
I0620 22:47:16.392974 32183 net.cpp:84] Creating Layer relu5_6/dw
I0620 22:47:16.392983 32183 net.cpp:406] relu5_6/dw <- conv5_6/dw
I0620 22:47:16.392994 32183 net.cpp:367] relu5_6/dw -> conv5_6/dw (in-place)
I0620 22:47:16.393440 32183 net.cpp:122] Setting up relu5_6/dw
I0620 22:47:16.393460 32183 net.cpp:129] Top shape: 10 512 7 7 (250880)
I0620 22:47:16.393470 32183 net.cpp:137] Memory required for data: 788766760
I0620 22:47:16.393477 32183 layer_factory.hpp:77] Creating layer conv5_6/sep
I0620 22:47:16.393496 32183 net.cpp:84] Creating Layer conv5_6/sep
I0620 22:47:16.393506 32183 net.cpp:406] conv5_6/sep <- conv5_6/dw
I0620 22:47:16.393529 32183 net.cpp:380] conv5_6/sep -> conv5_6/sep
I0620 22:47:16.404863 32183 net.cpp:122] Setting up conv5_6/sep
I0620 22:47:16.404927 32183 net.cpp:129] Top shape: 10 1024 7 7 (501760)
I0620 22:47:16.404935 32183 net.cpp:137] Memory required for data: 790773800
I0620 22:47:16.404953 32183 layer_factory.hpp:77] Creating layer conv5_6/sep/bn
I0620 22:47:16.405004 32183 net.cpp:84] Creating Layer conv5_6/sep/bn
I0620 22:47:16.405016 32183 net.cpp:406] conv5_6/sep/bn <- conv5_6/sep
I0620 22:47:16.405030 32183 net.cpp:367] conv5_6/sep/bn -> conv5_6/sep (in-place)
I0620 22:47:16.405308 32183 net.cpp:122] Setting up conv5_6/sep/bn
I0620 22:47:16.405325 32183 net.cpp:129] Top shape: 10 1024 7 7 (501760)
I0620 22:47:16.405344 32183 net.cpp:137] Memory required for data: 792780840
I0620 22:47:16.405359 32183 layer_factory.hpp:77] Creating layer conv5_6/sep/scale
I0620 22:47:16.405377 32183 net.cpp:84] Creating Layer conv5_6/sep/scale
I0620 22:47:16.405386 32183 net.cpp:406] conv5_6/sep/scale <- conv5_6/sep
I0620 22:47:16.405398 32183 net.cpp:367] conv5_6/sep/scale -> conv5_6/sep (in-place)
I0620 22:47:16.405464 32183 layer_factory.hpp:77] Creating layer conv5_6/sep/scale
I0620 22:47:16.405652 32183 net.cpp:122] Setting up conv5_6/sep/scale
I0620 22:47:16.405671 32183 net.cpp:129] Top shape: 10 1024 7 7 (501760)
I0620 22:47:16.405680 32183 net.cpp:137] Memory required for data: 794787880
I0620 22:47:16.405692 32183 layer_factory.hpp:77] Creating layer relu5_6/sep
I0620 22:47:16.405704 32183 net.cpp:84] Creating Layer relu5_6/sep
I0620 22:47:16.405714 32183 net.cpp:406] relu5_6/sep <- conv5_6/sep
I0620 22:47:16.405727 32183 net.cpp:367] relu5_6/sep -> conv5_6/sep (in-place)
I0620 22:47:16.406023 32183 net.cpp:122] Setting up relu5_6/sep
I0620 22:47:16.406041 32183 net.cpp:129] Top shape: 10 1024 7 7 (501760)
I0620 22:47:16.406049 32183 net.cpp:137] Memory required for data: 796794920
I0620 22:47:16.406057 32183 layer_factory.hpp:77] Creating layer conv6/dw
I0620 22:47:16.406077 32183 net.cpp:84] Creating Layer conv6/dw
I0620 22:47:16.406087 32183 net.cpp:406] conv6/dw <- conv5_6/sep
I0620 22:47:16.406103 32183 net.cpp:380] conv6/dw -> conv6/dw
I0620 22:47:16.406381 32183 net.cpp:122] Setting up conv6/dw
I0620 22:47:16.406400 32183 net.cpp:129] Top shape: 10 1024 7 7 (501760)
I0620 22:47:16.406409 32183 net.cpp:137] Memory required for data: 798801960
I0620 22:47:16.406419 32183 layer_factory.hpp:77] Creating layer conv6/dw/bn
I0620 22:47:16.406435 32183 net.cpp:84] Creating Layer conv6/dw/bn
I0620 22:47:16.406445 32183 net.cpp:406] conv6/dw/bn <- conv6/dw
I0620 22:47:16.406455 32183 net.cpp:367] conv6/dw/bn -> conv6/dw (in-place)
I0620 22:47:16.406728 32183 net.cpp:122] Setting up conv6/dw/bn
I0620 22:47:16.406747 32183 net.cpp:129] Top shape: 10 1024 7 7 (501760)
I0620 22:47:16.406755 32183 net.cpp:137] Memory required for data: 800809000
I0620 22:47:16.406769 32183 layer_factory.hpp:77] Creating layer conv6/dw/scale
I0620 22:47:16.406781 32183 net.cpp:84] Creating Layer conv6/dw/scale
I0620 22:47:16.406790 32183 net.cpp:406] conv6/dw/scale <- conv6/dw
I0620 22:47:16.406805 32183 net.cpp:367] conv6/dw/scale -> conv6/dw (in-place)
I0620 22:47:16.406862 32183 layer_factory.hpp:77] Creating layer conv6/dw/scale
I0620 22:47:16.407024 32183 net.cpp:122] Setting up conv6/dw/scale
I0620 22:47:16.407042 32183 net.cpp:129] Top shape: 10 1024 7 7 (501760)
I0620 22:47:16.407050 32183 net.cpp:137] Memory required for data: 802816040
I0620 22:47:16.407063 32183 layer_factory.hpp:77] Creating layer relu6/dw
I0620 22:47:16.407073 32183 net.cpp:84] Creating Layer relu6/dw
I0620 22:47:16.407083 32183 net.cpp:406] relu6/dw <- conv6/dw
I0620 22:47:16.407093 32183 net.cpp:367] relu6/dw -> conv6/dw (in-place)
I0620 22:47:16.407572 32183 net.cpp:122] Setting up relu6/dw
I0620 22:47:16.407595 32183 net.cpp:129] Top shape: 10 1024 7 7 (501760)
I0620 22:47:16.407604 32183 net.cpp:137] Memory required for data: 804823080
I0620 22:47:16.407613 32183 layer_factory.hpp:77] Creating layer conv6/sep
I0620 22:47:16.407635 32183 net.cpp:84] Creating Layer conv6/sep
I0620 22:47:16.407645 32183 net.cpp:406] conv6/sep <- conv6/dw
I0620 22:47:16.407658 32183 net.cpp:380] conv6/sep -> conv6/sep
I0620 22:47:16.429451 32183 net.cpp:122] Setting up conv6/sep
I0620 22:47:16.429522 32183 net.cpp:129] Top shape: 10 1024 7 7 (501760)
I0620 22:47:16.429533 32183 net.cpp:137] Memory required for data: 806830120
I0620 22:47:16.429574 32183 layer_factory.hpp:77] Creating layer conv6/sep/bn
I0620 22:47:16.429600 32183 net.cpp:84] Creating Layer conv6/sep/bn
I0620 22:47:16.429613 32183 net.cpp:406] conv6/sep/bn <- conv6/sep
I0620 22:47:16.429630 32183 net.cpp:367] conv6/sep/bn -> conv6/sep (in-place)
I0620 22:47:16.429918 32183 net.cpp:122] Setting up conv6/sep/bn
I0620 22:47:16.429947 32183 net.cpp:129] Top shape: 10 1024 7 7 (501760)
I0620 22:47:16.429956 32183 net.cpp:137] Memory required for data: 808837160
I0620 22:47:16.429970 32183 layer_factory.hpp:77] Creating layer conv6/sep/scale
I0620 22:47:16.429986 32183 net.cpp:84] Creating Layer conv6/sep/scale
I0620 22:47:16.429994 32183 net.cpp:406] conv6/sep/scale <- conv6/sep
I0620 22:47:16.430006 32183 net.cpp:367] conv6/sep/scale -> conv6/sep (in-place)
I0620 22:47:16.430075 32183 layer_factory.hpp:77] Creating layer conv6/sep/scale
I0620 22:47:16.430244 32183 net.cpp:122] Setting up conv6/sep/scale
I0620 22:47:16.430263 32183 net.cpp:129] Top shape: 10 1024 7 7 (501760)
I0620 22:47:16.430270 32183 net.cpp:137] Memory required for data: 810844200
I0620 22:47:16.430282 32183 layer_factory.hpp:77] Creating layer relu6/sep
I0620 22:47:16.430299 32183 net.cpp:84] Creating Layer relu6/sep
I0620 22:47:16.430310 32183 net.cpp:406] relu6/sep <- conv6/sep
I0620 22:47:16.430320 32183 net.cpp:367] relu6/sep -> conv6/sep (in-place)
I0620 22:47:16.430879 32183 net.cpp:122] Setting up relu6/sep
I0620 22:47:16.430902 32183 net.cpp:129] Top shape: 10 1024 7 7 (501760)
I0620 22:47:16.430910 32183 net.cpp:137] Memory required for data: 812851240
I0620 22:47:16.430919 32183 layer_factory.hpp:77] Creating layer pool6
I0620 22:47:16.430940 32183 net.cpp:84] Creating Layer pool6
I0620 22:47:16.430950 32183 net.cpp:406] pool6 <- conv6/sep
I0620 22:47:16.430963 32183 net.cpp:380] pool6 -> pool6
I0620 22:47:16.431535 32183 net.cpp:122] Setting up pool6
I0620 22:47:16.431560 32183 net.cpp:129] Top shape: 10 1024 1 1 (10240)
I0620 22:47:16.431568 32183 net.cpp:137] Memory required for data: 812892200
I0620 22:47:16.431576 32183 layer_factory.hpp:77] Creating layer fc7_oxford
I0620 22:47:16.431593 32183 net.cpp:84] Creating Layer fc7_oxford
I0620 22:47:16.431602 32183 net.cpp:406] fc7_oxford <- pool6
I0620 22:47:16.431618 32183 net.cpp:380] fc7_oxford -> fc7
I0620 22:47:16.434361 32183 net.cpp:122] Setting up fc7_oxford
I0620 22:47:16.434388 32183 net.cpp:129] Top shape: 10 102 1 1 (1020)
I0620 22:47:16.434397 32183 net.cpp:137] Memory required for data: 812896280
I0620 22:47:16.434412 32183 layer_factory.hpp:77] Creating layer loss
I0620 22:47:16.434432 32183 net.cpp:84] Creating Layer loss
I0620 22:47:16.434442 32183 net.cpp:406] loss <- fc7
I0620 22:47:16.434453 32183 net.cpp:406] loss <- label
I0620 22:47:16.434464 32183 net.cpp:380] loss -> loss
I0620 22:47:16.434484 32183 layer_factory.hpp:77] Creating layer loss
I0620 22:47:16.435087 32183 net.cpp:122] Setting up loss
I0620 22:47:16.435111 32183 net.cpp:129] Top shape: (1)
I0620 22:47:16.435119 32183 net.cpp:132]     with loss weight 1
I0620 22:47:16.435187 32183 net.cpp:137] Memory required for data: 812896284
I0620 22:47:16.435197 32183 net.cpp:198] loss needs backward computation.
I0620 22:47:16.435206 32183 net.cpp:198] fc7_oxford needs backward computation.
I0620 22:47:16.435214 32183 net.cpp:198] pool6 needs backward computation.
I0620 22:47:16.435223 32183 net.cpp:198] relu6/sep needs backward computation.
I0620 22:47:16.435231 32183 net.cpp:198] conv6/sep/scale needs backward computation.
I0620 22:47:16.435240 32183 net.cpp:198] conv6/sep/bn needs backward computation.
I0620 22:47:16.435246 32183 net.cpp:198] conv6/sep needs backward computation.
I0620 22:47:16.435256 32183 net.cpp:198] relu6/dw needs backward computation.
I0620 22:47:16.435263 32183 net.cpp:198] conv6/dw/scale needs backward computation.
I0620 22:47:16.435271 32183 net.cpp:198] conv6/dw/bn needs backward computation.
I0620 22:47:16.435279 32183 net.cpp:198] conv6/dw needs backward computation.
I0620 22:47:16.435287 32183 net.cpp:198] relu5_6/sep needs backward computation.
I0620 22:47:16.435315 32183 net.cpp:198] conv5_6/sep/scale needs backward computation.
I0620 22:47:16.435324 32183 net.cpp:198] conv5_6/sep/bn needs backward computation.
I0620 22:47:16.435333 32183 net.cpp:198] conv5_6/sep needs backward computation.
I0620 22:47:16.435340 32183 net.cpp:198] relu5_6/dw needs backward computation.
I0620 22:47:16.435348 32183 net.cpp:198] conv5_6/dw/scale needs backward computation.
I0620 22:47:16.435365 32183 net.cpp:198] conv5_6/dw/bn needs backward computation.
I0620 22:47:16.435374 32183 net.cpp:198] conv5_6/dw needs backward computation.
I0620 22:47:16.435382 32183 net.cpp:198] relu5_5/sep needs backward computation.
I0620 22:47:16.435390 32183 net.cpp:198] conv5_5/sep/scale needs backward computation.
I0620 22:47:16.435398 32183 net.cpp:198] conv5_5/sep/bn needs backward computation.
I0620 22:47:16.435406 32183 net.cpp:198] conv5_5/sep needs backward computation.
I0620 22:47:16.435415 32183 net.cpp:198] relu5_5/dw needs backward computation.
I0620 22:47:16.435422 32183 net.cpp:198] conv5_5/dw/scale needs backward computation.
I0620 22:47:16.435431 32183 net.cpp:198] conv5_5/dw/bn needs backward computation.
I0620 22:47:16.435438 32183 net.cpp:198] conv5_5/dw needs backward computation.
I0620 22:47:16.435447 32183 net.cpp:198] relu5_4/sep needs backward computation.
I0620 22:47:16.435456 32183 net.cpp:198] conv5_4/sep/scale needs backward computation.
I0620 22:47:16.435463 32183 net.cpp:198] conv5_4/sep/bn needs backward computation.
I0620 22:47:16.435472 32183 net.cpp:198] conv5_4/sep needs backward computation.
I0620 22:47:16.435479 32183 net.cpp:198] relu5_4/dw needs backward computation.
I0620 22:47:16.435487 32183 net.cpp:198] conv5_4/dw/scale needs backward computation.
I0620 22:47:16.435495 32183 net.cpp:198] conv5_4/dw/bn needs backward computation.
I0620 22:47:16.435503 32183 net.cpp:198] conv5_4/dw needs backward computation.
I0620 22:47:16.435510 32183 net.cpp:198] relu5_3/sep needs backward computation.
I0620 22:47:16.435528 32183 net.cpp:198] conv5_3/sep/scale needs backward computation.
I0620 22:47:16.435536 32183 net.cpp:198] conv5_3/sep/bn needs backward computation.
I0620 22:47:16.435544 32183 net.cpp:198] conv5_3/sep needs backward computation.
I0620 22:47:16.435552 32183 net.cpp:198] relu5_3/dw needs backward computation.
I0620 22:47:16.435560 32183 net.cpp:198] conv5_3/dw/scale needs backward computation.
I0620 22:47:16.435567 32183 net.cpp:198] conv5_3/dw/bn needs backward computation.
I0620 22:47:16.435575 32183 net.cpp:198] conv5_3/dw needs backward computation.
I0620 22:47:16.435583 32183 net.cpp:198] relu5_2/sep needs backward computation.
I0620 22:47:16.435591 32183 net.cpp:198] conv5_2/sep/scale needs backward computation.
I0620 22:47:16.435600 32183 net.cpp:198] conv5_2/sep/bn needs backward computation.
I0620 22:47:16.435606 32183 net.cpp:198] conv5_2/sep needs backward computation.
I0620 22:47:16.435614 32183 net.cpp:198] relu5_2/dw needs backward computation.
I0620 22:47:16.435622 32183 net.cpp:198] conv5_2/dw/scale needs backward computation.
I0620 22:47:16.435631 32183 net.cpp:198] conv5_2/dw/bn needs backward computation.
I0620 22:47:16.435638 32183 net.cpp:198] conv5_2/dw needs backward computation.
I0620 22:47:16.435647 32183 net.cpp:198] relu5_1/sep needs backward computation.
I0620 22:47:16.435653 32183 net.cpp:198] conv5_1/sep/scale needs backward computation.
I0620 22:47:16.435662 32183 net.cpp:198] conv5_1/sep/bn needs backward computation.
I0620 22:47:16.435669 32183 net.cpp:198] conv5_1/sep needs backward computation.
I0620 22:47:16.435678 32183 net.cpp:198] relu5_1/dw needs backward computation.
I0620 22:47:16.435685 32183 net.cpp:198] conv5_1/dw/scale needs backward computation.
I0620 22:47:16.435693 32183 net.cpp:198] conv5_1/dw/bn needs backward computation.
I0620 22:47:16.435701 32183 net.cpp:198] conv5_1/dw needs backward computation.
I0620 22:47:16.435709 32183 net.cpp:198] relu4_2/sep needs backward computation.
I0620 22:47:16.435717 32183 net.cpp:198] conv4_2/sep/scale needs backward computation.
I0620 22:47:16.435739 32183 net.cpp:198] conv4_2/sep/bn needs backward computation.
I0620 22:47:16.435746 32183 net.cpp:198] conv4_2/sep needs backward computation.
I0620 22:47:16.435755 32183 net.cpp:198] relu4_2/dw needs backward computation.
I0620 22:47:16.435763 32183 net.cpp:198] conv4_2/dw/scale needs backward computation.
I0620 22:47:16.435771 32183 net.cpp:198] conv4_2/dw/bn needs backward computation.
I0620 22:47:16.435784 32183 net.cpp:198] conv4_2/dw needs backward computation.
I0620 22:47:16.435793 32183 net.cpp:198] relu4_1/sep needs backward computation.
I0620 22:47:16.435801 32183 net.cpp:198] conv4_1/sep/scale needs backward computation.
I0620 22:47:16.435809 32183 net.cpp:198] conv4_1/sep/bn needs backward computation.
I0620 22:47:16.435817 32183 net.cpp:198] conv4_1/sep needs backward computation.
I0620 22:47:16.435825 32183 net.cpp:198] relu4_1/dw needs backward computation.
I0620 22:47:16.435833 32183 net.cpp:198] conv4_1/dw/scale needs backward computation.
I0620 22:47:16.435840 32183 net.cpp:198] conv4_1/dw/bn needs backward computation.
I0620 22:47:16.435848 32183 net.cpp:198] conv4_1/dw needs backward computation.
I0620 22:47:16.435856 32183 net.cpp:198] relu3_2/sep needs backward computation.
I0620 22:47:16.435864 32183 net.cpp:198] conv3_2/sep/scale needs backward computation.
I0620 22:47:16.435873 32183 net.cpp:198] conv3_2/sep/bn needs backward computation.
I0620 22:47:16.435880 32183 net.cpp:198] conv3_2/sep needs backward computation.
I0620 22:47:16.435889 32183 net.cpp:198] relu3_2/dw needs backward computation.
I0620 22:47:16.435896 32183 net.cpp:198] conv3_2/dw/scale needs backward computation.
I0620 22:47:16.435904 32183 net.cpp:198] conv3_2/dw/bn needs backward computation.
I0620 22:47:16.435912 32183 net.cpp:198] conv3_2/dw needs backward computation.
I0620 22:47:16.435920 32183 net.cpp:198] relu3_1/sep needs backward computation.
I0620 22:47:16.435927 32183 net.cpp:198] conv3_1/sep/scale needs backward computation.
I0620 22:47:16.435935 32183 net.cpp:198] conv3_1/sep/bn needs backward computation.
I0620 22:47:16.435943 32183 net.cpp:198] conv3_1/sep needs backward computation.
I0620 22:47:16.435952 32183 net.cpp:198] relu3_1/dw needs backward computation.
I0620 22:47:16.435959 32183 net.cpp:198] conv3_1/dw/scale needs backward computation.
I0620 22:47:16.435967 32183 net.cpp:198] conv3_1/dw/bn needs backward computation.
I0620 22:47:16.435976 32183 net.cpp:198] conv3_1/dw needs backward computation.
I0620 22:47:16.435983 32183 net.cpp:198] relu2_2/sep needs backward computation.
I0620 22:47:16.435995 32183 net.cpp:198] conv2_2/sep/scale needs backward computation.
I0620 22:47:16.436004 32183 net.cpp:198] conv2_2/sep/bn needs backward computation.
I0620 22:47:16.436012 32183 net.cpp:198] conv2_2/sep needs backward computation.
I0620 22:47:16.436022 32183 net.cpp:198] relu2_2/dw needs backward computation.
I0620 22:47:16.436028 32183 net.cpp:198] conv2_2/dw/scale needs backward computation.
I0620 22:47:16.436053 32183 net.cpp:198] conv2_2/dw/bn needs backward computation.
I0620 22:47:16.436061 32183 net.cpp:198] conv2_2/dw needs backward computation.
I0620 22:47:16.436069 32183 net.cpp:198] relu2_1/sep needs backward computation.
I0620 22:47:16.436077 32183 net.cpp:198] conv2_1/sep/scale needs backward computation.
I0620 22:47:16.436085 32183 net.cpp:198] conv2_1/sep/bn needs backward computation.
I0620 22:47:16.436094 32183 net.cpp:198] conv2_1/sep needs backward computation.
I0620 22:47:16.436101 32183 net.cpp:198] relu2_1/dw needs backward computation.
I0620 22:47:16.436110 32183 net.cpp:198] conv2_1/dw/scale needs backward computation.
I0620 22:47:16.436117 32183 net.cpp:198] conv2_1/dw/bn needs backward computation.
I0620 22:47:16.436125 32183 net.cpp:198] conv2_1/dw needs backward computation.
I0620 22:47:16.436133 32183 net.cpp:198] relu1 needs backward computation.
I0620 22:47:16.436141 32183 net.cpp:198] conv1/scale needs backward computation.
I0620 22:47:16.436149 32183 net.cpp:198] conv1/bn needs backward computation.
I0620 22:47:16.436156 32183 net.cpp:198] conv1 needs backward computation.
I0620 22:47:16.436174 32183 net.cpp:200] data does not need backward computation.
I0620 22:47:16.436182 32183 net.cpp:242] This network produces output loss
I0620 22:47:16.436260 32183 net.cpp:255] Network initialization done.
I0620 22:47:16.439057 32183 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/xingzhaolong/caffe_project/Auto_prune/models/oxford/mobilenet/mobilenet_deploy.prototxt_pruning
I0620 22:47:16.439092 32183 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0620 22:47:16.439110 32183 solver.cpp:172] Creating test net (#0) specified by net file: /home/xingzhaolong/caffe_project/Auto_prune/models/oxford/mobilenet/mobilenet_deploy.prototxt_pruning
I0620 22:47:16.439249 32183 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0620 22:47:16.440228 32183 net.cpp:51] Initializing net from parameters: 
name: "MOBILENET"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_file: "/home/xingzhaolong/caffe_project/caffe/models/caffe-oxford102/imagenet_mean.binaryproto"
  }
  image_data_param {
    source: "/home/xingzhaolong/caffe_project/caffe/models/caffe-oxford102/train.txt"
    batch_size: 10
    new_height: 256
    new_width: 256
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv1/bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1/scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2_1/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv1"
  top: "conv2_1/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 32
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv2_1/dw"
  top: "conv2_1/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_1/dw/scale"
  type: "Scale"
  bottom: "conv2_1/dw"
  top: "conv2_1/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_1/dw"
  type: "ReLU"
  bottom: "conv2_1/dw"
  top: "conv2_1/dw"
}
layer {
  name: "conv2_1/sep"
  type: "CConvolution"
  bottom: "conv2_1/dw"
  top: "conv2_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv2_1/sep"
  top: "conv2_1/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_1/sep/scale"
  type: "Scale"
  bottom: "conv2_1/sep"
  top: "conv2_1/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_1/sep"
  type: "ReLU"
  bottom: "conv2_1/sep"
  top: "conv2_1/sep"
}
layer {
  name: "conv2_2/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv2_1/sep"
  top: "conv2_2/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 64
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv2_2/dw"
  top: "conv2_2/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_2/dw/scale"
  type: "Scale"
  bottom: "conv2_2/dw"
  top: "conv2_2/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_2/dw"
  type: "ReLU"
  bottom: "conv2_2/dw"
  top: "conv2_2/dw"
}
layer {
  name: "conv2_2/sep"
  type: "CConvolution"
  bottom: "conv2_2/dw"
  top: "conv2_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv2_2/sep"
  top: "conv2_2/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_2/sep/scale"
  type: "Scale"
  bottom: "conv2_2/sep"
  top: "conv2_2/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_2/sep"
  type: "ReLU"
  bottom: "conv2_2/sep"
  top: "conv2_2/sep"
}
layer {
  name: "conv3_1/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv2_2/sep"
  top: "conv3_1/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv3_1/dw"
  top: "conv3_1/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_1/dw/scale"
  type: "Scale"
  bottom: "conv3_1/dw"
  top: "conv3_1/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_1/dw"
  type: "ReLU"
  bottom: "conv3_1/dw"
  top: "conv3_1/dw"
}
layer {
  name: "conv3_1/sep"
  type: "CConvolution"
  bottom: "conv3_1/dw"
  top: "conv3_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv3_1/sep"
  top: "conv3_1/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_1/sep/scale"
  type: "Scale"
  bottom: "conv3_1/sep"
  top: "conv3_1/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_1/sep"
  type: "ReLU"
  bottom: "conv3_1/sep"
  top: "conv3_1/sep"
}
layer {
  name: "conv3_2/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv3_1/sep"
  top: "conv3_2/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv3_2/dw"
  top: "conv3_2/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_2/dw/scale"
  type: "Scale"
  bottom: "conv3_2/dw"
  top: "conv3_2/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_2/dw"
  type: "ReLU"
  bottom: "conv3_2/dw"
  top: "conv3_2/dw"
}
layer {
  name: "conv3_2/sep"
  type: "CConvolution"
  bottom: "conv3_2/dw"
  top: "conv3_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv3_2/sep"
  top: "conv3_2/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_2/sep/scale"
  type: "Scale"
  bottom: "conv3_2/sep"
  top: "conv3_2/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_2/sep"
  type: "ReLU"
  bottom: "conv3_2/sep"
  top: "conv3_2/sep"
}
layer {
  name: "conv4_1/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv3_2/sep"
  top: "conv4_1/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv4_1/dw"
  top: "conv4_1/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv4_1/dw/scale"
  type: "Scale"
  bottom: "conv4_1/dw"
  top: "conv4_1/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu4_1/dw"
  type: "ReLU"
  bottom: "conv4_1/dw"
  top: "conv4_1/dw"
}
layer {
  name: "conv4_1/sep"
  type: "CConvolution"
  bottom: "conv4_1/dw"
  top: "conv4_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv4_1/sep"
  top: "conv4_1/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv4_1/sep/scale"
  type: "Scale"
  bottom: "conv4_1/sep"
  top: "conv4_1/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu4_1/sep"
  type: "ReLU"
  bottom: "conv4_1/sep"
  top: "conv4_1/sep"
}
layer {
  name: "conv4_2/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv4_1/sep"
  top: "conv4_2/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv4_2/dw"
  top: "conv4_2/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv4_2/dw/scale"
  type: "Scale"
  bottom: "conv4_2/dw"
  top: "conv4_2/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu4_2/dw"
  type: "ReLU"
  bottom: "conv4_2/dw"
  top: "conv4_2/dw"
}
layer {
  name: "conv4_2/sep"
  type: "CConvolution"
  bottom: "conv4_2/dw"
  top: "conv4_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv4_2/sep"
  top: "conv4_2/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv4_2/sep/scale"
  type: "Scale"
  bottom: "conv4_2/sep"
  top: "conv4_2/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu4_2/sep"
  type: "ReLU"
  bottom: "conv4_2/sep"
  top: "conv4_2/sep"
}
layer {
  name: "conv5_1/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv4_2/sep"
  top: "conv5_1/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_1/dw"
  top: "conv5_1/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_1/dw/scale"
  type: "Scale"
  bottom: "conv5_1/dw"
  top: "conv5_1/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_1/dw"
  type: "ReLU"
  bottom: "conv5_1/dw"
  top: "conv5_1/dw"
}
layer {
  name: "conv5_1/sep"
  type: "CConvolution"
  bottom: "conv5_1/dw"
  top: "conv5_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_1/sep"
  top: "conv5_1/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_1/sep/scale"
  type: "Scale"
  bottom: "conv5_1/sep"
  top: "conv5_1/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_1/sep"
  type: "ReLU"
  bottom: "conv5_1/sep"
  top: "conv5_1/sep"
}
layer {
  name: "conv5_2/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_1/sep"
  top: "conv5_2/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_2/dw"
  top: "conv5_2/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_2/dw/scale"
  type: "Scale"
  bottom: "conv5_2/dw"
  top: "conv5_2/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_2/dw"
  type: "ReLU"
  bottom: "conv5_2/dw"
  top: "conv5_2/dw"
}
layer {
  name: "conv5_2/sep"
  type: "CConvolution"
  bottom: "conv5_2/dw"
  top: "conv5_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_2/sep"
  top: "conv5_2/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_2/sep/scale"
  type: "Scale"
  bottom: "conv5_2/sep"
  top: "conv5_2/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_2/sep"
  type: "ReLU"
  bottom: "conv5_2/sep"
  top: "conv5_2/sep"
}
layer {
  name: "conv5_3/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_2/sep"
  top: "conv5_3/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_3/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_3/dw"
  top: "conv5_3/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_3/dw/scale"
  type: "Scale"
  bottom: "conv5_3/dw"
  top: "conv5_3/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_3/dw"
  type: "ReLU"
  bottom: "conv5_3/dw"
  top: "conv5_3/dw"
}
layer {
  name: "conv5_3/sep"
  type: "CConvolution"
  bottom: "conv5_3/dw"
  top: "conv5_3/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_3/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_3/sep"
  top: "conv5_3/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_3/sep/scale"
  type: "Scale"
  bottom: "conv5_3/sep"
  top: "conv5_3/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_3/sep"
  type: "ReLU"
  bottom: "conv5_3/sep"
  top: "conv5_3/sep"
}
layer {
  name: "conv5_4/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_3/sep"
  top: "conv5_4/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_4/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_4/dw"
  top: "conv5_4/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_4/dw/scale"
  type: "Scale"
  bottom: "conv5_4/dw"
  top: "conv5_4/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_4/dw"
  type: "ReLU"
  bottom: "conv5_4/dw"
  top: "conv5_4/dw"
}
layer {
  name: "conv5_4/sep"
  type: "CConvolution"
  bottom: "conv5_4/dw"
  top: "conv5_4/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_4/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_4/sep"
  top: "conv5_4/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_4/sep/scale"
  type: "Scale"
  bottom: "conv5_4/sep"
  top: "conv5_4/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_4/sep"
  type: "ReLU"
  bottom: "conv5_4/sep"
  top: "conv5_4/sep"
}
layer {
  name: "conv5_5/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_4/sep"
  top: "conv5_5/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_5/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_5/dw"
  top: "conv5_5/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_5/dw/scale"
  type: "Scale"
  bottom: "conv5_5/dw"
  top: "conv5_5/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_5/dw"
  type: "ReLU"
  bottom: "conv5_5/dw"
  top: "conv5_5/dw"
}
layer {
  name: "conv5_5/sep"
  type: "CConvolution"
  bottom: "conv5_5/dw"
  top: "conv5_5/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_5/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_5/sep"
  top: "conv5_5/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_5/sep/scale"
  type: "Scale"
  bottom: "conv5_5/sep"
  top: "conv5_5/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_5/sep"
  type: "ReLU"
  bottom: "conv5_5/sep"
  top: "conv5_5/sep"
}
layer {
  name: "conv5_6/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_5/sep"
  top: "conv5_6/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_6/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_6/dw"
  top: "conv5_6/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_6/dw/scale"
  type: "Scale"
  bottom: "conv5_6/dw"
  top: "conv5_6/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_6/dw"
  type: "ReLU"
  bottom: "conv5_6/dw"
  top: "conv5_6/dw"
}
layer {
  name: "conv5_6/sep"
  type: "CConvolution"
  bottom: "conv5_6/dw"
  top: "conv5_6/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_6/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_6/sep"
  top: "conv5_6/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_6/sep/scale"
  type: "Scale"
  bottom: "conv5_6/sep"
  top: "conv5_6/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_6/sep"
  type: "ReLU"
  bottom: "conv5_6/sep"
  top: "conv5_6/sep"
}
layer {
  name: "conv6/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_6/sep"
  top: "conv6/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 1024
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv6/dw/bn"
  type: "BatchNorm"
  bottom: "conv6/dw"
  top: "conv6/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv6/dw/scale"
  type: "Scale"
  bottom: "conv6/dw"
  top: "conv6/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu6/dw"
  type: "ReLU"
  bottom: "conv6/dw"
  top: "conv6/dw"
}
layer {
  name: "conv6/sep"
  type: "CConvolution"
  bottom: "conv6/dw"
  top: "conv6/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv6/sep/bn"
  type: "BatchNorm"
  bottom: "conv6/sep"
  top: "conv6/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv6/sep/scale"
  type: "Scale"
  bottom: "conv6/sep"
  top: "conv6/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu6/sep"
  type: "ReLU"
  bottom: "conv6/sep"
  top: "conv6/sep"
}
layer {
  name: "pool6"
  type: "Pooling"
  bottom: "conv6/sep"
  top: "pool6"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc7_oxford"
  type: "CConvolution"
  bottom: "pool6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 102
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc7"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc7"
  bottom: "label"
  top: "loss"
}
I0620 22:47:16.440760 32183 layer_factory.hpp:77] Creating layer data
I0620 22:47:16.440793 32183 net.cpp:84] Creating Layer data
I0620 22:47:16.440806 32183 net.cpp:380] data -> data
I0620 22:47:16.440822 32183 net.cpp:380] data -> label
I0620 22:47:16.440838 32183 data_transformer.cpp:25] Loading mean file from: /home/xingzhaolong/caffe_project/caffe/models/caffe-oxford102/imagenet_mean.binaryproto
I0620 22:47:16.444700 32183 image_data_layer.cpp:38] Opening file /home/xingzhaolong/caffe_project/caffe/models/caffe-oxford102/train.txt
I0620 22:47:16.445117 32183 image_data_layer.cpp:63] A total of 1020 images.
I0620 22:47:16.451742 32183 image_data_layer.cpp:90] output data size: 10,3,224,224
I0620 22:47:16.474336 32183 net.cpp:122] Setting up data
I0620 22:47:16.474408 32183 net.cpp:129] Top shape: 10 3 224 224 (1505280)
I0620 22:47:16.474419 32183 net.cpp:129] Top shape: 10 (10)
I0620 22:47:16.474428 32183 net.cpp:137] Memory required for data: 6021160
I0620 22:47:16.474440 32183 layer_factory.hpp:77] Creating layer label_data_1_split
I0620 22:47:16.474468 32183 net.cpp:84] Creating Layer label_data_1_split
I0620 22:47:16.474479 32183 net.cpp:406] label_data_1_split <- label
I0620 22:47:16.474494 32183 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0620 22:47:16.474520 32183 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0620 22:47:16.474597 32183 net.cpp:122] Setting up label_data_1_split
I0620 22:47:16.474614 32183 net.cpp:129] Top shape: 10 (10)
I0620 22:47:16.474623 32183 net.cpp:129] Top shape: 10 (10)
I0620 22:47:16.474632 32183 net.cpp:137] Memory required for data: 6021240
I0620 22:47:16.474639 32183 layer_factory.hpp:77] Creating layer conv1
I0620 22:47:16.474661 32183 net.cpp:84] Creating Layer conv1
I0620 22:47:16.474670 32183 net.cpp:406] conv1 <- data
I0620 22:47:16.474684 32183 net.cpp:380] conv1 -> conv1
I0620 22:47:16.475982 32183 net.cpp:122] Setting up conv1
I0620 22:47:16.476008 32183 net.cpp:129] Top shape: 10 32 112 112 (4014080)
I0620 22:47:16.476018 32183 net.cpp:137] Memory required for data: 22077560
I0620 22:47:16.476032 32183 layer_factory.hpp:77] Creating layer conv1/bn
I0620 22:47:16.476047 32183 net.cpp:84] Creating Layer conv1/bn
I0620 22:47:16.476056 32183 net.cpp:406] conv1/bn <- conv1
I0620 22:47:16.476068 32183 net.cpp:367] conv1/bn -> conv1 (in-place)
I0620 22:47:16.476347 32183 net.cpp:122] Setting up conv1/bn
I0620 22:47:16.476366 32183 net.cpp:129] Top shape: 10 32 112 112 (4014080)
I0620 22:47:16.476374 32183 net.cpp:137] Memory required for data: 38133880
I0620 22:47:16.476392 32183 layer_factory.hpp:77] Creating layer conv1/scale
I0620 22:47:16.476408 32183 net.cpp:84] Creating Layer conv1/scale
I0620 22:47:16.476418 32183 net.cpp:406] conv1/scale <- conv1
I0620 22:47:16.476429 32183 net.cpp:367] conv1/scale -> conv1 (in-place)
I0620 22:47:16.476492 32183 layer_factory.hpp:77] Creating layer conv1/scale
I0620 22:47:16.476686 32183 net.cpp:122] Setting up conv1/scale
I0620 22:47:16.476706 32183 net.cpp:129] Top shape: 10 32 112 112 (4014080)
I0620 22:47:16.476713 32183 net.cpp:137] Memory required for data: 54190200
I0620 22:47:16.476729 32183 layer_factory.hpp:77] Creating layer relu1
I0620 22:47:16.476742 32183 net.cpp:84] Creating Layer relu1
I0620 22:47:16.476752 32183 net.cpp:406] relu1 <- conv1
I0620 22:47:16.476763 32183 net.cpp:367] relu1 -> conv1 (in-place)
I0620 22:47:16.477182 32183 net.cpp:122] Setting up relu1
I0620 22:47:16.477203 32183 net.cpp:129] Top shape: 10 32 112 112 (4014080)
I0620 22:47:16.477212 32183 net.cpp:137] Memory required for data: 70246520
I0620 22:47:16.477244 32183 layer_factory.hpp:77] Creating layer conv2_1/dw
I0620 22:47:16.477262 32183 net.cpp:84] Creating Layer conv2_1/dw
I0620 22:47:16.477270 32183 net.cpp:406] conv2_1/dw <- conv1
I0620 22:47:16.477283 32183 net.cpp:380] conv2_1/dw -> conv2_1/dw
I0620 22:47:16.477561 32183 net.cpp:122] Setting up conv2_1/dw
I0620 22:47:16.477582 32183 net.cpp:129] Top shape: 10 32 112 112 (4014080)
I0620 22:47:16.477603 32183 net.cpp:137] Memory required for data: 86302840
I0620 22:47:16.477614 32183 layer_factory.hpp:77] Creating layer conv2_1/dw/bn
I0620 22:47:16.477628 32183 net.cpp:84] Creating Layer conv2_1/dw/bn
I0620 22:47:16.477638 32183 net.cpp:406] conv2_1/dw/bn <- conv2_1/dw
I0620 22:47:16.477649 32183 net.cpp:367] conv2_1/dw/bn -> conv2_1/dw (in-place)
I0620 22:47:16.478767 32183 net.cpp:122] Setting up conv2_1/dw/bn
I0620 22:47:16.478791 32183 net.cpp:129] Top shape: 10 32 112 112 (4014080)
I0620 22:47:16.478801 32183 net.cpp:137] Memory required for data: 102359160
I0620 22:47:16.478818 32183 layer_factory.hpp:77] Creating layer conv2_1/dw/scale
I0620 22:47:16.478834 32183 net.cpp:84] Creating Layer conv2_1/dw/scale
I0620 22:47:16.478844 32183 net.cpp:406] conv2_1/dw/scale <- conv2_1/dw
I0620 22:47:16.478857 32183 net.cpp:367] conv2_1/dw/scale -> conv2_1/dw (in-place)
I0620 22:47:16.478920 32183 layer_factory.hpp:77] Creating layer conv2_1/dw/scale
I0620 22:47:16.479089 32183 net.cpp:122] Setting up conv2_1/dw/scale
I0620 22:47:16.479107 32183 net.cpp:129] Top shape: 10 32 112 112 (4014080)
I0620 22:47:16.479116 32183 net.cpp:137] Memory required for data: 118415480
I0620 22:47:16.479128 32183 layer_factory.hpp:77] Creating layer relu2_1/dw
I0620 22:47:16.479140 32183 net.cpp:84] Creating Layer relu2_1/dw
I0620 22:47:16.479148 32183 net.cpp:406] relu2_1/dw <- conv2_1/dw
I0620 22:47:16.479159 32183 net.cpp:367] relu2_1/dw -> conv2_1/dw (in-place)
I0620 22:47:16.479590 32183 net.cpp:122] Setting up relu2_1/dw
I0620 22:47:16.479614 32183 net.cpp:129] Top shape: 10 32 112 112 (4014080)
I0620 22:47:16.479622 32183 net.cpp:137] Memory required for data: 134471800
I0620 22:47:16.479630 32183 layer_factory.hpp:77] Creating layer conv2_1/sep
I0620 22:47:16.479645 32183 net.cpp:84] Creating Layer conv2_1/sep
I0620 22:47:16.479655 32183 net.cpp:406] conv2_1/sep <- conv2_1/dw
I0620 22:47:16.479667 32183 net.cpp:380] conv2_1/sep -> conv2_1/sep
I0620 22:47:16.480024 32183 net.cpp:122] Setting up conv2_1/sep
I0620 22:47:16.480042 32183 net.cpp:129] Top shape: 10 64 112 112 (8028160)
I0620 22:47:16.480051 32183 net.cpp:137] Memory required for data: 166584440
I0620 22:47:16.480063 32183 layer_factory.hpp:77] Creating layer conv2_1/sep/bn
I0620 22:47:16.480077 32183 net.cpp:84] Creating Layer conv2_1/sep/bn
I0620 22:47:16.480085 32183 net.cpp:406] conv2_1/sep/bn <- conv2_1/sep
I0620 22:47:16.480096 32183 net.cpp:367] conv2_1/sep/bn -> conv2_1/sep (in-place)
I0620 22:47:16.480358 32183 net.cpp:122] Setting up conv2_1/sep/bn
I0620 22:47:16.480376 32183 net.cpp:129] Top shape: 10 64 112 112 (8028160)
I0620 22:47:16.480384 32183 net.cpp:137] Memory required for data: 198697080
I0620 22:47:16.480402 32183 layer_factory.hpp:77] Creating layer conv2_1/sep/scale
I0620 22:47:16.480417 32183 net.cpp:84] Creating Layer conv2_1/sep/scale
I0620 22:47:16.480425 32183 net.cpp:406] conv2_1/sep/scale <- conv2_1/sep
I0620 22:47:16.480437 32183 net.cpp:367] conv2_1/sep/scale -> conv2_1/sep (in-place)
I0620 22:47:16.480499 32183 layer_factory.hpp:77] Creating layer conv2_1/sep/scale
I0620 22:47:16.480675 32183 net.cpp:122] Setting up conv2_1/sep/scale
I0620 22:47:16.480695 32183 net.cpp:129] Top shape: 10 64 112 112 (8028160)
I0620 22:47:16.480703 32183 net.cpp:137] Memory required for data: 230809720
I0620 22:47:16.480715 32183 layer_factory.hpp:77] Creating layer relu2_1/sep
I0620 22:47:16.480728 32183 net.cpp:84] Creating Layer relu2_1/sep
I0620 22:47:16.480736 32183 net.cpp:406] relu2_1/sep <- conv2_1/sep
I0620 22:47:16.480748 32183 net.cpp:367] relu2_1/sep -> conv2_1/sep (in-place)
I0620 22:47:16.480967 32183 net.cpp:122] Setting up relu2_1/sep
I0620 22:47:16.481000 32183 net.cpp:129] Top shape: 10 64 112 112 (8028160)
I0620 22:47:16.481010 32183 net.cpp:137] Memory required for data: 262922360
I0620 22:47:16.481019 32183 layer_factory.hpp:77] Creating layer conv2_2/dw
I0620 22:47:16.481034 32183 net.cpp:84] Creating Layer conv2_2/dw
I0620 22:47:16.481041 32183 net.cpp:406] conv2_2/dw <- conv2_1/sep
I0620 22:47:16.481062 32183 net.cpp:380] conv2_2/dw -> conv2_2/dw
I0620 22:47:16.482054 32183 net.cpp:122] Setting up conv2_2/dw
I0620 22:47:16.482077 32183 net.cpp:129] Top shape: 10 64 56 56 (2007040)
I0620 22:47:16.482086 32183 net.cpp:137] Memory required for data: 270950520
I0620 22:47:16.482097 32183 layer_factory.hpp:77] Creating layer conv2_2/dw/bn
I0620 22:47:16.482110 32183 net.cpp:84] Creating Layer conv2_2/dw/bn
I0620 22:47:16.482120 32183 net.cpp:406] conv2_2/dw/bn <- conv2_2/dw
I0620 22:47:16.482131 32183 net.cpp:367] conv2_2/dw/bn -> conv2_2/dw (in-place)
I0620 22:47:16.482398 32183 net.cpp:122] Setting up conv2_2/dw/bn
I0620 22:47:16.482415 32183 net.cpp:129] Top shape: 10 64 56 56 (2007040)
I0620 22:47:16.482424 32183 net.cpp:137] Memory required for data: 278978680
I0620 22:47:16.482437 32183 layer_factory.hpp:77] Creating layer conv2_2/dw/scale
I0620 22:47:16.482453 32183 net.cpp:84] Creating Layer conv2_2/dw/scale
I0620 22:47:16.482461 32183 net.cpp:406] conv2_2/dw/scale <- conv2_2/dw
I0620 22:47:16.482473 32183 net.cpp:367] conv2_2/dw/scale -> conv2_2/dw (in-place)
I0620 22:47:16.482545 32183 layer_factory.hpp:77] Creating layer conv2_2/dw/scale
I0620 22:47:16.482722 32183 net.cpp:122] Setting up conv2_2/dw/scale
I0620 22:47:16.482739 32183 net.cpp:129] Top shape: 10 64 56 56 (2007040)
I0620 22:47:16.482748 32183 net.cpp:137] Memory required for data: 287006840
I0620 22:47:16.482760 32183 layer_factory.hpp:77] Creating layer relu2_2/dw
I0620 22:47:16.482772 32183 net.cpp:84] Creating Layer relu2_2/dw
I0620 22:47:16.482780 32183 net.cpp:406] relu2_2/dw <- conv2_2/dw
I0620 22:47:16.482791 32183 net.cpp:367] relu2_2/dw -> conv2_2/dw (in-place)
I0620 22:47:16.483896 32183 net.cpp:122] Setting up relu2_2/dw
I0620 22:47:16.483919 32183 net.cpp:129] Top shape: 10 64 56 56 (2007040)
I0620 22:47:16.483928 32183 net.cpp:137] Memory required for data: 295035000
I0620 22:47:16.483937 32183 layer_factory.hpp:77] Creating layer conv2_2/sep
I0620 22:47:16.483952 32183 net.cpp:84] Creating Layer conv2_2/sep
I0620 22:47:16.483960 32183 net.cpp:406] conv2_2/sep <- conv2_2/dw
I0620 22:47:16.483973 32183 net.cpp:380] conv2_2/sep -> conv2_2/sep
I0620 22:47:16.484402 32183 net.cpp:122] Setting up conv2_2/sep
I0620 22:47:16.484422 32183 net.cpp:129] Top shape: 10 128 56 56 (4014080)
I0620 22:47:16.484431 32183 net.cpp:137] Memory required for data: 311091320
I0620 22:47:16.484442 32183 layer_factory.hpp:77] Creating layer conv2_2/sep/bn
I0620 22:47:16.484455 32183 net.cpp:84] Creating Layer conv2_2/sep/bn
I0620 22:47:16.484464 32183 net.cpp:406] conv2_2/sep/bn <- conv2_2/sep
I0620 22:47:16.484475 32183 net.cpp:367] conv2_2/sep/bn -> conv2_2/sep (in-place)
I0620 22:47:16.484738 32183 net.cpp:122] Setting up conv2_2/sep/bn
I0620 22:47:16.484756 32183 net.cpp:129] Top shape: 10 128 56 56 (4014080)
I0620 22:47:16.484764 32183 net.cpp:137] Memory required for data: 327147640
I0620 22:47:16.484778 32183 layer_factory.hpp:77] Creating layer conv2_2/sep/scale
I0620 22:47:16.484792 32183 net.cpp:84] Creating Layer conv2_2/sep/scale
I0620 22:47:16.484800 32183 net.cpp:406] conv2_2/sep/scale <- conv2_2/sep
I0620 22:47:16.484812 32183 net.cpp:367] conv2_2/sep/scale -> conv2_2/sep (in-place)
I0620 22:47:16.484872 32183 layer_factory.hpp:77] Creating layer conv2_2/sep/scale
I0620 22:47:16.485033 32183 net.cpp:122] Setting up conv2_2/sep/scale
I0620 22:47:16.485051 32183 net.cpp:129] Top shape: 10 128 56 56 (4014080)
I0620 22:47:16.485059 32183 net.cpp:137] Memory required for data: 343203960
I0620 22:47:16.485071 32183 layer_factory.hpp:77] Creating layer relu2_2/sep
I0620 22:47:16.485083 32183 net.cpp:84] Creating Layer relu2_2/sep
I0620 22:47:16.485105 32183 net.cpp:406] relu2_2/sep <- conv2_2/sep
I0620 22:47:16.485117 32183 net.cpp:367] relu2_2/sep -> conv2_2/sep (in-place)
I0620 22:47:16.485340 32183 net.cpp:122] Setting up relu2_2/sep
I0620 22:47:16.485358 32183 net.cpp:129] Top shape: 10 128 56 56 (4014080)
I0620 22:47:16.485368 32183 net.cpp:137] Memory required for data: 359260280
I0620 22:47:16.485375 32183 layer_factory.hpp:77] Creating layer conv3_1/dw
I0620 22:47:16.485399 32183 net.cpp:84] Creating Layer conv3_1/dw
I0620 22:47:16.485409 32183 net.cpp:406] conv3_1/dw <- conv2_2/sep
I0620 22:47:16.485421 32183 net.cpp:380] conv3_1/dw -> conv3_1/dw
I0620 22:47:16.485611 32183 net.cpp:122] Setting up conv3_1/dw
I0620 22:47:16.485631 32183 net.cpp:129] Top shape: 10 128 56 56 (4014080)
I0620 22:47:16.485641 32183 net.cpp:137] Memory required for data: 375316600
I0620 22:47:16.485657 32183 layer_factory.hpp:77] Creating layer conv3_1/dw/bn
I0620 22:47:16.485671 32183 net.cpp:84] Creating Layer conv3_1/dw/bn
I0620 22:47:16.485680 32183 net.cpp:406] conv3_1/dw/bn <- conv3_1/dw
I0620 22:47:16.485692 32183 net.cpp:367] conv3_1/dw/bn -> conv3_1/dw (in-place)
I0620 22:47:16.485937 32183 net.cpp:122] Setting up conv3_1/dw/bn
I0620 22:47:16.485954 32183 net.cpp:129] Top shape: 10 128 56 56 (4014080)
I0620 22:47:16.485962 32183 net.cpp:137] Memory required for data: 391372920
I0620 22:47:16.485976 32183 layer_factory.hpp:77] Creating layer conv3_1/dw/scale
I0620 22:47:16.485990 32183 net.cpp:84] Creating Layer conv3_1/dw/scale
I0620 22:47:16.485997 32183 net.cpp:406] conv3_1/dw/scale <- conv3_1/dw
I0620 22:47:16.486009 32183 net.cpp:367] conv3_1/dw/scale -> conv3_1/dw (in-place)
I0620 22:47:16.486068 32183 layer_factory.hpp:77] Creating layer conv3_1/dw/scale
I0620 22:47:16.486232 32183 net.cpp:122] Setting up conv3_1/dw/scale
I0620 22:47:16.486250 32183 net.cpp:129] Top shape: 10 128 56 56 (4014080)
I0620 22:47:16.486258 32183 net.cpp:137] Memory required for data: 407429240
I0620 22:47:16.486270 32183 layer_factory.hpp:77] Creating layer relu3_1/dw
I0620 22:47:16.486281 32183 net.cpp:84] Creating Layer relu3_1/dw
I0620 22:47:16.486290 32183 net.cpp:406] relu3_1/dw <- conv3_1/dw
I0620 22:47:16.486301 32183 net.cpp:367] relu3_1/dw -> conv3_1/dw (in-place)
I0620 22:47:16.486739 32183 net.cpp:122] Setting up relu3_1/dw
I0620 22:47:16.486763 32183 net.cpp:129] Top shape: 10 128 56 56 (4014080)
I0620 22:47:16.486771 32183 net.cpp:137] Memory required for data: 423485560
I0620 22:47:16.486779 32183 layer_factory.hpp:77] Creating layer conv3_1/sep
I0620 22:47:16.486794 32183 net.cpp:84] Creating Layer conv3_1/sep
I0620 22:47:16.486804 32183 net.cpp:406] conv3_1/sep <- conv3_1/dw
I0620 22:47:16.486815 32183 net.cpp:380] conv3_1/sep -> conv3_1/sep
I0620 22:47:16.487372 32183 net.cpp:122] Setting up conv3_1/sep
I0620 22:47:16.487390 32183 net.cpp:129] Top shape: 10 128 56 56 (4014080)
I0620 22:47:16.487398 32183 net.cpp:137] Memory required for data: 439541880
I0620 22:47:16.487411 32183 layer_factory.hpp:77] Creating layer conv3_1/sep/bn
I0620 22:47:16.487424 32183 net.cpp:84] Creating Layer conv3_1/sep/bn
I0620 22:47:16.487433 32183 net.cpp:406] conv3_1/sep/bn <- conv3_1/sep
I0620 22:47:16.487444 32183 net.cpp:367] conv3_1/sep/bn -> conv3_1/sep (in-place)
I0620 22:47:16.487710 32183 net.cpp:122] Setting up conv3_1/sep/bn
I0620 22:47:16.487730 32183 net.cpp:129] Top shape: 10 128 56 56 (4014080)
I0620 22:47:16.487737 32183 net.cpp:137] Memory required for data: 455598200
I0620 22:47:16.487751 32183 layer_factory.hpp:77] Creating layer conv3_1/sep/scale
I0620 22:47:16.487764 32183 net.cpp:84] Creating Layer conv3_1/sep/scale
I0620 22:47:16.487773 32183 net.cpp:406] conv3_1/sep/scale <- conv3_1/sep
I0620 22:47:16.487785 32183 net.cpp:367] conv3_1/sep/scale -> conv3_1/sep (in-place)
I0620 22:47:16.487845 32183 layer_factory.hpp:77] Creating layer conv3_1/sep/scale
I0620 22:47:16.488008 32183 net.cpp:122] Setting up conv3_1/sep/scale
I0620 22:47:16.488024 32183 net.cpp:129] Top shape: 10 128 56 56 (4014080)
I0620 22:47:16.488034 32183 net.cpp:137] Memory required for data: 471654520
I0620 22:47:16.488056 32183 layer_factory.hpp:77] Creating layer relu3_1/sep
I0620 22:47:16.488068 32183 net.cpp:84] Creating Layer relu3_1/sep
I0620 22:47:16.488077 32183 net.cpp:406] relu3_1/sep <- conv3_1/sep
I0620 22:47:16.488088 32183 net.cpp:367] relu3_1/sep -> conv3_1/sep (in-place)
I0620 22:47:16.488310 32183 net.cpp:122] Setting up relu3_1/sep
I0620 22:47:16.488328 32183 net.cpp:129] Top shape: 10 128 56 56 (4014080)
I0620 22:47:16.488344 32183 net.cpp:137] Memory required for data: 487710840
I0620 22:47:16.488353 32183 layer_factory.hpp:77] Creating layer conv3_2/dw
I0620 22:47:16.488368 32183 net.cpp:84] Creating Layer conv3_2/dw
I0620 22:47:16.488378 32183 net.cpp:406] conv3_2/dw <- conv3_1/sep
I0620 22:47:16.488389 32183 net.cpp:380] conv3_2/dw -> conv3_2/dw
I0620 22:47:16.488559 32183 net.cpp:122] Setting up conv3_2/dw
I0620 22:47:16.488577 32183 net.cpp:129] Top shape: 10 128 28 28 (1003520)
I0620 22:47:16.488585 32183 net.cpp:137] Memory required for data: 491724920
I0620 22:47:16.488596 32183 layer_factory.hpp:77] Creating layer conv3_2/dw/bn
I0620 22:47:16.488610 32183 net.cpp:84] Creating Layer conv3_2/dw/bn
I0620 22:47:16.488617 32183 net.cpp:406] conv3_2/dw/bn <- conv3_2/dw
I0620 22:47:16.488629 32183 net.cpp:367] conv3_2/dw/bn -> conv3_2/dw (in-place)
I0620 22:47:16.488889 32183 net.cpp:122] Setting up conv3_2/dw/bn
I0620 22:47:16.488906 32183 net.cpp:129] Top shape: 10 128 28 28 (1003520)
I0620 22:47:16.488914 32183 net.cpp:137] Memory required for data: 495739000
I0620 22:47:16.488927 32183 layer_factory.hpp:77] Creating layer conv3_2/dw/scale
I0620 22:47:16.488945 32183 net.cpp:84] Creating Layer conv3_2/dw/scale
I0620 22:47:16.488953 32183 net.cpp:406] conv3_2/dw/scale <- conv3_2/dw
I0620 22:47:16.488965 32183 net.cpp:367] conv3_2/dw/scale -> conv3_2/dw (in-place)
I0620 22:47:16.489025 32183 layer_factory.hpp:77] Creating layer conv3_2/dw/scale
I0620 22:47:16.489187 32183 net.cpp:122] Setting up conv3_2/dw/scale
I0620 22:47:16.489204 32183 net.cpp:129] Top shape: 10 128 28 28 (1003520)
I0620 22:47:16.489212 32183 net.cpp:137] Memory required for data: 499753080
I0620 22:47:16.489224 32183 layer_factory.hpp:77] Creating layer relu3_2/dw
I0620 22:47:16.489236 32183 net.cpp:84] Creating Layer relu3_2/dw
I0620 22:47:16.489245 32183 net.cpp:406] relu3_2/dw <- conv3_2/dw
I0620 22:47:16.489256 32183 net.cpp:367] relu3_2/dw -> conv3_2/dw (in-place)
I0620 22:47:16.489694 32183 net.cpp:122] Setting up relu3_2/dw
I0620 22:47:16.489717 32183 net.cpp:129] Top shape: 10 128 28 28 (1003520)
I0620 22:47:16.489725 32183 net.cpp:137] Memory required for data: 503767160
I0620 22:47:16.489733 32183 layer_factory.hpp:77] Creating layer conv3_2/sep
I0620 22:47:16.489748 32183 net.cpp:84] Creating Layer conv3_2/sep
I0620 22:47:16.489758 32183 net.cpp:406] conv3_2/sep <- conv3_2/dw
I0620 22:47:16.489770 32183 net.cpp:380] conv3_2/sep -> conv3_2/sep
I0620 22:47:16.490573 32183 net.cpp:122] Setting up conv3_2/sep
I0620 22:47:16.490593 32183 net.cpp:129] Top shape: 10 256 28 28 (2007040)
I0620 22:47:16.490602 32183 net.cpp:137] Memory required for data: 511795320
I0620 22:47:16.490617 32183 layer_factory.hpp:77] Creating layer conv3_2/sep/bn
I0620 22:47:16.490633 32183 net.cpp:84] Creating Layer conv3_2/sep/bn
I0620 22:47:16.490641 32183 net.cpp:406] conv3_2/sep/bn <- conv3_2/sep
I0620 22:47:16.490653 32183 net.cpp:367] conv3_2/sep/bn -> conv3_2/sep (in-place)
I0620 22:47:16.490905 32183 net.cpp:122] Setting up conv3_2/sep/bn
I0620 22:47:16.490921 32183 net.cpp:129] Top shape: 10 256 28 28 (2007040)
I0620 22:47:16.490929 32183 net.cpp:137] Memory required for data: 519823480
I0620 22:47:16.490943 32183 layer_factory.hpp:77] Creating layer conv3_2/sep/scale
I0620 22:47:16.490957 32183 net.cpp:84] Creating Layer conv3_2/sep/scale
I0620 22:47:16.490965 32183 net.cpp:406] conv3_2/sep/scale <- conv3_2/sep
I0620 22:47:16.490977 32183 net.cpp:367] conv3_2/sep/scale -> conv3_2/sep (in-place)
I0620 22:47:16.491037 32183 layer_factory.hpp:77] Creating layer conv3_2/sep/scale
I0620 22:47:16.491199 32183 net.cpp:122] Setting up conv3_2/sep/scale
I0620 22:47:16.491227 32183 net.cpp:129] Top shape: 10 256 28 28 (2007040)
I0620 22:47:16.491236 32183 net.cpp:137] Memory required for data: 527851640
I0620 22:47:16.491248 32183 layer_factory.hpp:77] Creating layer relu3_2/sep
I0620 22:47:16.491261 32183 net.cpp:84] Creating Layer relu3_2/sep
I0620 22:47:16.491269 32183 net.cpp:406] relu3_2/sep <- conv3_2/sep
I0620 22:47:16.491281 32183 net.cpp:367] relu3_2/sep -> conv3_2/sep (in-place)
I0620 22:47:16.491521 32183 net.cpp:122] Setting up relu3_2/sep
I0620 22:47:16.491542 32183 net.cpp:129] Top shape: 10 256 28 28 (2007040)
I0620 22:47:16.491551 32183 net.cpp:137] Memory required for data: 535879800
I0620 22:47:16.491559 32183 layer_factory.hpp:77] Creating layer conv4_1/dw
I0620 22:47:16.491575 32183 net.cpp:84] Creating Layer conv4_1/dw
I0620 22:47:16.491583 32183 net.cpp:406] conv4_1/dw <- conv3_2/sep
I0620 22:47:16.491595 32183 net.cpp:380] conv4_1/dw -> conv4_1/dw
I0620 22:47:16.491775 32183 net.cpp:122] Setting up conv4_1/dw
I0620 22:47:16.491794 32183 net.cpp:129] Top shape: 10 256 28 28 (2007040)
I0620 22:47:16.491802 32183 net.cpp:137] Memory required for data: 543907960
I0620 22:47:16.491812 32183 layer_factory.hpp:77] Creating layer conv4_1/dw/bn
I0620 22:47:16.491827 32183 net.cpp:84] Creating Layer conv4_1/dw/bn
I0620 22:47:16.491835 32183 net.cpp:406] conv4_1/dw/bn <- conv4_1/dw
I0620 22:47:16.491847 32183 net.cpp:367] conv4_1/dw/bn -> conv4_1/dw (in-place)
I0620 22:47:16.492103 32183 net.cpp:122] Setting up conv4_1/dw/bn
I0620 22:47:16.492120 32183 net.cpp:129] Top shape: 10 256 28 28 (2007040)
I0620 22:47:16.492128 32183 net.cpp:137] Memory required for data: 551936120
I0620 22:47:16.492141 32183 layer_factory.hpp:77] Creating layer conv4_1/dw/scale
I0620 22:47:16.492156 32183 net.cpp:84] Creating Layer conv4_1/dw/scale
I0620 22:47:16.492164 32183 net.cpp:406] conv4_1/dw/scale <- conv4_1/dw
I0620 22:47:16.492175 32183 net.cpp:367] conv4_1/dw/scale -> conv4_1/dw (in-place)
I0620 22:47:16.492235 32183 layer_factory.hpp:77] Creating layer conv4_1/dw/scale
I0620 22:47:16.492393 32183 net.cpp:122] Setting up conv4_1/dw/scale
I0620 22:47:16.492410 32183 net.cpp:129] Top shape: 10 256 28 28 (2007040)
I0620 22:47:16.492419 32183 net.cpp:137] Memory required for data: 559964280
I0620 22:47:16.492430 32183 layer_factory.hpp:77] Creating layer relu4_1/dw
I0620 22:47:16.492442 32183 net.cpp:84] Creating Layer relu4_1/dw
I0620 22:47:16.492451 32183 net.cpp:406] relu4_1/dw <- conv4_1/dw
I0620 22:47:16.492462 32183 net.cpp:367] relu4_1/dw -> conv4_1/dw (in-place)
I0620 22:47:16.492900 32183 net.cpp:122] Setting up relu4_1/dw
I0620 22:47:16.492923 32183 net.cpp:129] Top shape: 10 256 28 28 (2007040)
I0620 22:47:16.492931 32183 net.cpp:137] Memory required for data: 567992440
I0620 22:47:16.492939 32183 layer_factory.hpp:77] Creating layer conv4_1/sep
I0620 22:47:16.492954 32183 net.cpp:84] Creating Layer conv4_1/sep
I0620 22:47:16.492962 32183 net.cpp:406] conv4_1/sep <- conv4_1/dw
I0620 22:47:16.492975 32183 net.cpp:380] conv4_1/sep -> conv4_1/sep
I0620 22:47:16.494272 32183 net.cpp:122] Setting up conv4_1/sep
I0620 22:47:16.494293 32183 net.cpp:129] Top shape: 10 256 28 28 (2007040)
I0620 22:47:16.494302 32183 net.cpp:137] Memory required for data: 576020600
I0620 22:47:16.494328 32183 layer_factory.hpp:77] Creating layer conv4_1/sep/bn
I0620 22:47:16.494341 32183 net.cpp:84] Creating Layer conv4_1/sep/bn
I0620 22:47:16.494350 32183 net.cpp:406] conv4_1/sep/bn <- conv4_1/sep
I0620 22:47:16.494362 32183 net.cpp:367] conv4_1/sep/bn -> conv4_1/sep (in-place)
I0620 22:47:16.494623 32183 net.cpp:122] Setting up conv4_1/sep/bn
I0620 22:47:16.494642 32183 net.cpp:129] Top shape: 10 256 28 28 (2007040)
I0620 22:47:16.494652 32183 net.cpp:137] Memory required for data: 584048760
I0620 22:47:16.494665 32183 layer_factory.hpp:77] Creating layer conv4_1/sep/scale
I0620 22:47:16.494678 32183 net.cpp:84] Creating Layer conv4_1/sep/scale
I0620 22:47:16.494688 32183 net.cpp:406] conv4_1/sep/scale <- conv4_1/sep
I0620 22:47:16.494699 32183 net.cpp:367] conv4_1/sep/scale -> conv4_1/sep (in-place)
I0620 22:47:16.494774 32183 layer_factory.hpp:77] Creating layer conv4_1/sep/scale
I0620 22:47:16.494936 32183 net.cpp:122] Setting up conv4_1/sep/scale
I0620 22:47:16.494953 32183 net.cpp:129] Top shape: 10 256 28 28 (2007040)
I0620 22:47:16.494961 32183 net.cpp:137] Memory required for data: 592076920
I0620 22:47:16.494973 32183 layer_factory.hpp:77] Creating layer relu4_1/sep
I0620 22:47:16.494993 32183 net.cpp:84] Creating Layer relu4_1/sep
I0620 22:47:16.495003 32183 net.cpp:406] relu4_1/sep <- conv4_1/sep
I0620 22:47:16.495014 32183 net.cpp:367] relu4_1/sep -> conv4_1/sep (in-place)
I0620 22:47:16.495242 32183 net.cpp:122] Setting up relu4_1/sep
I0620 22:47:16.495261 32183 net.cpp:129] Top shape: 10 256 28 28 (2007040)
I0620 22:47:16.495270 32183 net.cpp:137] Memory required for data: 600105080
I0620 22:47:16.495277 32183 layer_factory.hpp:77] Creating layer conv4_2/dw
I0620 22:47:16.495292 32183 net.cpp:84] Creating Layer conv4_2/dw
I0620 22:47:16.495301 32183 net.cpp:406] conv4_2/dw <- conv4_1/sep
I0620 22:47:16.495314 32183 net.cpp:380] conv4_2/dw -> conv4_2/dw
I0620 22:47:16.495481 32183 net.cpp:122] Setting up conv4_2/dw
I0620 22:47:16.495498 32183 net.cpp:129] Top shape: 10 256 14 14 (501760)
I0620 22:47:16.495507 32183 net.cpp:137] Memory required for data: 602112120
I0620 22:47:16.496811 32183 layer_factory.hpp:77] Creating layer conv4_2/dw/bn
I0620 22:47:16.496845 32183 net.cpp:84] Creating Layer conv4_2/dw/bn
I0620 22:47:16.496865 32183 net.cpp:406] conv4_2/dw/bn <- conv4_2/dw
I0620 22:47:16.496881 32183 net.cpp:367] conv4_2/dw/bn -> conv4_2/dw (in-place)
I0620 22:47:16.497813 32183 net.cpp:122] Setting up conv4_2/dw/bn
I0620 22:47:16.497836 32183 net.cpp:129] Top shape: 10 256 14 14 (501760)
I0620 22:47:16.497846 32183 net.cpp:137] Memory required for data: 604119160
I0620 22:47:16.497862 32183 layer_factory.hpp:77] Creating layer conv4_2/dw/scale
I0620 22:47:16.497882 32183 net.cpp:84] Creating Layer conv4_2/dw/scale
I0620 22:47:16.497895 32183 net.cpp:406] conv4_2/dw/scale <- conv4_2/dw
I0620 22:47:16.497910 32183 net.cpp:367] conv4_2/dw/scale -> conv4_2/dw (in-place)
I0620 22:47:16.498008 32183 layer_factory.hpp:77] Creating layer conv4_2/dw/scale
I0620 22:47:16.498199 32183 net.cpp:122] Setting up conv4_2/dw/scale
I0620 22:47:16.498217 32183 net.cpp:129] Top shape: 10 256 14 14 (501760)
I0620 22:47:16.498226 32183 net.cpp:137] Memory required for data: 606126200
I0620 22:47:16.498241 32183 layer_factory.hpp:77] Creating layer relu4_2/dw
I0620 22:47:16.498258 32183 net.cpp:84] Creating Layer relu4_2/dw
I0620 22:47:16.498270 32183 net.cpp:406] relu4_2/dw <- conv4_2/dw
I0620 22:47:16.498282 32183 net.cpp:367] relu4_2/dw -> conv4_2/dw (in-place)
I0620 22:47:16.499574 32183 net.cpp:122] Setting up relu4_2/dw
I0620 22:47:16.499599 32183 net.cpp:129] Top shape: 10 256 14 14 (501760)
I0620 22:47:16.499609 32183 net.cpp:137] Memory required for data: 608133240
I0620 22:47:16.499621 32183 layer_factory.hpp:77] Creating layer conv4_2/sep
I0620 22:47:16.499642 32183 net.cpp:84] Creating Layer conv4_2/sep
I0620 22:47:16.499652 32183 net.cpp:406] conv4_2/sep <- conv4_2/dw
I0620 22:47:16.499670 32183 net.cpp:380] conv4_2/sep -> conv4_2/sep
I0620 22:47:16.502890 32183 net.cpp:122] Setting up conv4_2/sep
I0620 22:47:16.502919 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.502928 32183 net.cpp:137] Memory required for data: 612147320
I0620 22:47:16.502941 32183 layer_factory.hpp:77] Creating layer conv4_2/sep/bn
I0620 22:47:16.502959 32183 net.cpp:84] Creating Layer conv4_2/sep/bn
I0620 22:47:16.502969 32183 net.cpp:406] conv4_2/sep/bn <- conv4_2/sep
I0620 22:47:16.502981 32183 net.cpp:367] conv4_2/sep/bn -> conv4_2/sep (in-place)
I0620 22:47:16.503293 32183 net.cpp:122] Setting up conv4_2/sep/bn
I0620 22:47:16.503310 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.503319 32183 net.cpp:137] Memory required for data: 616161400
I0620 22:47:16.503332 32183 layer_factory.hpp:77] Creating layer conv4_2/sep/scale
I0620 22:47:16.503348 32183 net.cpp:84] Creating Layer conv4_2/sep/scale
I0620 22:47:16.503377 32183 net.cpp:406] conv4_2/sep/scale <- conv4_2/sep
I0620 22:47:16.503391 32183 net.cpp:367] conv4_2/sep/scale -> conv4_2/sep (in-place)
I0620 22:47:16.503456 32183 layer_factory.hpp:77] Creating layer conv4_2/sep/scale
I0620 22:47:16.503641 32183 net.cpp:122] Setting up conv4_2/sep/scale
I0620 22:47:16.503661 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.503679 32183 net.cpp:137] Memory required for data: 620175480
I0620 22:47:16.503691 32183 layer_factory.hpp:77] Creating layer relu4_2/sep
I0620 22:47:16.503706 32183 net.cpp:84] Creating Layer relu4_2/sep
I0620 22:47:16.503715 32183 net.cpp:406] relu4_2/sep <- conv4_2/sep
I0620 22:47:16.503727 32183 net.cpp:367] relu4_2/sep -> conv4_2/sep (in-place)
I0620 22:47:16.503973 32183 net.cpp:122] Setting up relu4_2/sep
I0620 22:47:16.503991 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.503999 32183 net.cpp:137] Memory required for data: 624189560
I0620 22:47:16.504007 32183 layer_factory.hpp:77] Creating layer conv5_1/dw
I0620 22:47:16.504027 32183 net.cpp:84] Creating Layer conv5_1/dw
I0620 22:47:16.504037 32183 net.cpp:406] conv5_1/dw <- conv4_2/sep
I0620 22:47:16.504050 32183 net.cpp:380] conv5_1/dw -> conv5_1/dw
I0620 22:47:16.504333 32183 net.cpp:122] Setting up conv5_1/dw
I0620 22:47:16.504350 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.504359 32183 net.cpp:137] Memory required for data: 628203640
I0620 22:47:16.504369 32183 layer_factory.hpp:77] Creating layer conv5_1/dw/bn
I0620 22:47:16.504384 32183 net.cpp:84] Creating Layer conv5_1/dw/bn
I0620 22:47:16.504393 32183 net.cpp:406] conv5_1/dw/bn <- conv5_1/dw
I0620 22:47:16.504405 32183 net.cpp:367] conv5_1/dw/bn -> conv5_1/dw (in-place)
I0620 22:47:16.504691 32183 net.cpp:122] Setting up conv5_1/dw/bn
I0620 22:47:16.504709 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.504717 32183 net.cpp:137] Memory required for data: 632217720
I0620 22:47:16.504731 32183 layer_factory.hpp:77] Creating layer conv5_1/dw/scale
I0620 22:47:16.504748 32183 net.cpp:84] Creating Layer conv5_1/dw/scale
I0620 22:47:16.504757 32183 net.cpp:406] conv5_1/dw/scale <- conv5_1/dw
I0620 22:47:16.504770 32183 net.cpp:367] conv5_1/dw/scale -> conv5_1/dw (in-place)
I0620 22:47:16.504832 32183 layer_factory.hpp:77] Creating layer conv5_1/dw/scale
I0620 22:47:16.505008 32183 net.cpp:122] Setting up conv5_1/dw/scale
I0620 22:47:16.505025 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.505033 32183 net.cpp:137] Memory required for data: 636231800
I0620 22:47:16.505048 32183 layer_factory.hpp:77] Creating layer relu5_1/dw
I0620 22:47:16.505062 32183 net.cpp:84] Creating Layer relu5_1/dw
I0620 22:47:16.505071 32183 net.cpp:406] relu5_1/dw <- conv5_1/dw
I0620 22:47:16.505082 32183 net.cpp:367] relu5_1/dw -> conv5_1/dw (in-place)
I0620 22:47:16.505549 32183 net.cpp:122] Setting up relu5_1/dw
I0620 22:47:16.505571 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.505580 32183 net.cpp:137] Memory required for data: 640245880
I0620 22:47:16.505589 32183 layer_factory.hpp:77] Creating layer conv5_1/sep
I0620 22:47:16.505606 32183 net.cpp:84] Creating Layer conv5_1/sep
I0620 22:47:16.505616 32183 net.cpp:406] conv5_1/sep <- conv5_1/dw
I0620 22:47:16.505630 32183 net.cpp:380] conv5_1/sep -> conv5_1/sep
I0620 22:47:16.511421 32183 net.cpp:122] Setting up conv5_1/sep
I0620 22:47:16.511468 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.511477 32183 net.cpp:137] Memory required for data: 644259960
I0620 22:47:16.511492 32183 layer_factory.hpp:77] Creating layer conv5_1/sep/bn
I0620 22:47:16.511518 32183 net.cpp:84] Creating Layer conv5_1/sep/bn
I0620 22:47:16.511533 32183 net.cpp:406] conv5_1/sep/bn <- conv5_1/sep
I0620 22:47:16.511546 32183 net.cpp:367] conv5_1/sep/bn -> conv5_1/sep (in-place)
I0620 22:47:16.511838 32183 net.cpp:122] Setting up conv5_1/sep/bn
I0620 22:47:16.511855 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.511864 32183 net.cpp:137] Memory required for data: 648274040
I0620 22:47:16.511900 32183 layer_factory.hpp:77] Creating layer conv5_1/sep/scale
I0620 22:47:16.511917 32183 net.cpp:84] Creating Layer conv5_1/sep/scale
I0620 22:47:16.511927 32183 net.cpp:406] conv5_1/sep/scale <- conv5_1/sep
I0620 22:47:16.511940 32183 net.cpp:367] conv5_1/sep/scale -> conv5_1/sep (in-place)
I0620 22:47:16.512006 32183 layer_factory.hpp:77] Creating layer conv5_1/sep/scale
I0620 22:47:16.512198 32183 net.cpp:122] Setting up conv5_1/sep/scale
I0620 22:47:16.512217 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.512226 32183 net.cpp:137] Memory required for data: 652288120
I0620 22:47:16.512239 32183 layer_factory.hpp:77] Creating layer relu5_1/sep
I0620 22:47:16.512253 32183 net.cpp:84] Creating Layer relu5_1/sep
I0620 22:47:16.512262 32183 net.cpp:406] relu5_1/sep <- conv5_1/sep
I0620 22:47:16.512274 32183 net.cpp:367] relu5_1/sep -> conv5_1/sep (in-place)
I0620 22:47:16.512572 32183 net.cpp:122] Setting up relu5_1/sep
I0620 22:47:16.512594 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.512603 32183 net.cpp:137] Memory required for data: 656302200
I0620 22:47:16.512611 32183 layer_factory.hpp:77] Creating layer conv5_2/dw
I0620 22:47:16.512630 32183 net.cpp:84] Creating Layer conv5_2/dw
I0620 22:47:16.512640 32183 net.cpp:406] conv5_2/dw <- conv5_1/sep
I0620 22:47:16.512655 32183 net.cpp:380] conv5_2/dw -> conv5_2/dw
I0620 22:47:16.512892 32183 net.cpp:122] Setting up conv5_2/dw
I0620 22:47:16.512910 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.512919 32183 net.cpp:137] Memory required for data: 660316280
I0620 22:47:16.512929 32183 layer_factory.hpp:77] Creating layer conv5_2/dw/bn
I0620 22:47:16.512944 32183 net.cpp:84] Creating Layer conv5_2/dw/bn
I0620 22:47:16.512953 32183 net.cpp:406] conv5_2/dw/bn <- conv5_2/dw
I0620 22:47:16.512966 32183 net.cpp:367] conv5_2/dw/bn -> conv5_2/dw (in-place)
I0620 22:47:16.513242 32183 net.cpp:122] Setting up conv5_2/dw/bn
I0620 22:47:16.513259 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.513267 32183 net.cpp:137] Memory required for data: 664330360
I0620 22:47:16.513281 32183 layer_factory.hpp:77] Creating layer conv5_2/dw/scale
I0620 22:47:16.513327 32183 net.cpp:84] Creating Layer conv5_2/dw/scale
I0620 22:47:16.513337 32183 net.cpp:406] conv5_2/dw/scale <- conv5_2/dw
I0620 22:47:16.513350 32183 net.cpp:367] conv5_2/dw/scale -> conv5_2/dw (in-place)
I0620 22:47:16.513411 32183 layer_factory.hpp:77] Creating layer conv5_2/dw/scale
I0620 22:47:16.513597 32183 net.cpp:122] Setting up conv5_2/dw/scale
I0620 22:47:16.513615 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.513623 32183 net.cpp:137] Memory required for data: 668344440
I0620 22:47:16.513635 32183 layer_factory.hpp:77] Creating layer relu5_2/dw
I0620 22:47:16.513648 32183 net.cpp:84] Creating Layer relu5_2/dw
I0620 22:47:16.513658 32183 net.cpp:406] relu5_2/dw <- conv5_2/dw
I0620 22:47:16.513667 32183 net.cpp:367] relu5_2/dw -> conv5_2/dw (in-place)
I0620 22:47:16.514123 32183 net.cpp:122] Setting up relu5_2/dw
I0620 22:47:16.514144 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.514153 32183 net.cpp:137] Memory required for data: 672358520
I0620 22:47:16.514161 32183 layer_factory.hpp:77] Creating layer conv5_2/sep
I0620 22:47:16.514179 32183 net.cpp:84] Creating Layer conv5_2/sep
I0620 22:47:16.514189 32183 net.cpp:406] conv5_2/sep <- conv5_2/dw
I0620 22:47:16.514204 32183 net.cpp:380] conv5_2/sep -> conv5_2/sep
I0620 22:47:16.520023 32183 net.cpp:122] Setting up conv5_2/sep
I0620 22:47:16.520074 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.520083 32183 net.cpp:137] Memory required for data: 676372600
I0620 22:47:16.520098 32183 layer_factory.hpp:77] Creating layer conv5_2/sep/bn
I0620 22:47:16.520117 32183 net.cpp:84] Creating Layer conv5_2/sep/bn
I0620 22:47:16.520128 32183 net.cpp:406] conv5_2/sep/bn <- conv5_2/sep
I0620 22:47:16.520144 32183 net.cpp:367] conv5_2/sep/bn -> conv5_2/sep (in-place)
I0620 22:47:16.520475 32183 net.cpp:122] Setting up conv5_2/sep/bn
I0620 22:47:16.520493 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.520501 32183 net.cpp:137] Memory required for data: 680386680
I0620 22:47:16.520525 32183 layer_factory.hpp:77] Creating layer conv5_2/sep/scale
I0620 22:47:16.520543 32183 net.cpp:84] Creating Layer conv5_2/sep/scale
I0620 22:47:16.520552 32183 net.cpp:406] conv5_2/sep/scale <- conv5_2/sep
I0620 22:47:16.520577 32183 net.cpp:367] conv5_2/sep/scale -> conv5_2/sep (in-place)
I0620 22:47:16.520650 32183 layer_factory.hpp:77] Creating layer conv5_2/sep/scale
I0620 22:47:16.520831 32183 net.cpp:122] Setting up conv5_2/sep/scale
I0620 22:47:16.520849 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.520858 32183 net.cpp:137] Memory required for data: 684400760
I0620 22:47:16.520869 32183 layer_factory.hpp:77] Creating layer relu5_2/sep
I0620 22:47:16.520884 32183 net.cpp:84] Creating Layer relu5_2/sep
I0620 22:47:16.520895 32183 net.cpp:406] relu5_2/sep <- conv5_2/sep
I0620 22:47:16.520905 32183 net.cpp:367] relu5_2/sep -> conv5_2/sep (in-place)
I0620 22:47:16.521405 32183 net.cpp:122] Setting up relu5_2/sep
I0620 22:47:16.521431 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.521440 32183 net.cpp:137] Memory required for data: 688414840
I0620 22:47:16.521450 32183 layer_factory.hpp:77] Creating layer conv5_3/dw
I0620 22:47:16.521466 32183 net.cpp:84] Creating Layer conv5_3/dw
I0620 22:47:16.521476 32183 net.cpp:406] conv5_3/dw <- conv5_2/sep
I0620 22:47:16.521491 32183 net.cpp:380] conv5_3/dw -> conv5_3/dw
I0620 22:47:16.521744 32183 net.cpp:122] Setting up conv5_3/dw
I0620 22:47:16.521764 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.521773 32183 net.cpp:137] Memory required for data: 692428920
I0620 22:47:16.521783 32183 layer_factory.hpp:77] Creating layer conv5_3/dw/bn
I0620 22:47:16.521796 32183 net.cpp:84] Creating Layer conv5_3/dw/bn
I0620 22:47:16.521806 32183 net.cpp:406] conv5_3/dw/bn <- conv5_3/dw
I0620 22:47:16.521819 32183 net.cpp:367] conv5_3/dw/bn -> conv5_3/dw (in-place)
I0620 22:47:16.522109 32183 net.cpp:122] Setting up conv5_3/dw/bn
I0620 22:47:16.522127 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.522135 32183 net.cpp:137] Memory required for data: 696443000
I0620 22:47:16.522151 32183 layer_factory.hpp:77] Creating layer conv5_3/dw/scale
I0620 22:47:16.522164 32183 net.cpp:84] Creating Layer conv5_3/dw/scale
I0620 22:47:16.522173 32183 net.cpp:406] conv5_3/dw/scale <- conv5_3/dw
I0620 22:47:16.522184 32183 net.cpp:367] conv5_3/dw/scale -> conv5_3/dw (in-place)
I0620 22:47:16.522249 32183 layer_factory.hpp:77] Creating layer conv5_3/dw/scale
I0620 22:47:16.522430 32183 net.cpp:122] Setting up conv5_3/dw/scale
I0620 22:47:16.522451 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.522460 32183 net.cpp:137] Memory required for data: 700457080
I0620 22:47:16.522472 32183 layer_factory.hpp:77] Creating layer relu5_3/dw
I0620 22:47:16.522483 32183 net.cpp:84] Creating Layer relu5_3/dw
I0620 22:47:16.522492 32183 net.cpp:406] relu5_3/dw <- conv5_3/dw
I0620 22:47:16.522506 32183 net.cpp:367] relu5_3/dw -> conv5_3/dw (in-place)
I0620 22:47:16.522752 32183 net.cpp:122] Setting up relu5_3/dw
I0620 22:47:16.522771 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.522780 32183 net.cpp:137] Memory required for data: 704471160
I0620 22:47:16.522790 32183 layer_factory.hpp:77] Creating layer conv5_3/sep
I0620 22:47:16.522811 32183 net.cpp:84] Creating Layer conv5_3/sep
I0620 22:47:16.522820 32183 net.cpp:406] conv5_3/sep <- conv5_3/dw
I0620 22:47:16.522836 32183 net.cpp:380] conv5_3/sep -> conv5_3/sep
I0620 22:47:16.528663 32183 net.cpp:122] Setting up conv5_3/sep
I0620 22:47:16.528709 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.528718 32183 net.cpp:137] Memory required for data: 708485240
I0620 22:47:16.528733 32183 layer_factory.hpp:77] Creating layer conv5_3/sep/bn
I0620 22:47:16.528749 32183 net.cpp:84] Creating Layer conv5_3/sep/bn
I0620 22:47:16.528781 32183 net.cpp:406] conv5_3/sep/bn <- conv5_3/sep
I0620 22:47:16.528800 32183 net.cpp:367] conv5_3/sep/bn -> conv5_3/sep (in-place)
I0620 22:47:16.529100 32183 net.cpp:122] Setting up conv5_3/sep/bn
I0620 22:47:16.529119 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.529126 32183 net.cpp:137] Memory required for data: 712499320
I0620 22:47:16.529140 32183 layer_factory.hpp:77] Creating layer conv5_3/sep/scale
I0620 22:47:16.529165 32183 net.cpp:84] Creating Layer conv5_3/sep/scale
I0620 22:47:16.529175 32183 net.cpp:406] conv5_3/sep/scale <- conv5_3/sep
I0620 22:47:16.529186 32183 net.cpp:367] conv5_3/sep/scale -> conv5_3/sep (in-place)
I0620 22:47:16.529256 32183 layer_factory.hpp:77] Creating layer conv5_3/sep/scale
I0620 22:47:16.529441 32183 net.cpp:122] Setting up conv5_3/sep/scale
I0620 22:47:16.529459 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.529467 32183 net.cpp:137] Memory required for data: 716513400
I0620 22:47:16.529482 32183 layer_factory.hpp:77] Creating layer relu5_3/sep
I0620 22:47:16.529495 32183 net.cpp:84] Creating Layer relu5_3/sep
I0620 22:47:16.529507 32183 net.cpp:406] relu5_3/sep <- conv5_3/sep
I0620 22:47:16.529526 32183 net.cpp:367] relu5_3/sep -> conv5_3/sep (in-place)
I0620 22:47:16.530040 32183 net.cpp:122] Setting up relu5_3/sep
I0620 22:47:16.530061 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.530071 32183 net.cpp:137] Memory required for data: 720527480
I0620 22:47:16.530078 32183 layer_factory.hpp:77] Creating layer conv5_4/dw
I0620 22:47:16.530098 32183 net.cpp:84] Creating Layer conv5_4/dw
I0620 22:47:16.530109 32183 net.cpp:406] conv5_4/dw <- conv5_3/sep
I0620 22:47:16.530122 32183 net.cpp:380] conv5_4/dw -> conv5_4/dw
I0620 22:47:16.530369 32183 net.cpp:122] Setting up conv5_4/dw
I0620 22:47:16.530387 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.530395 32183 net.cpp:137] Memory required for data: 724541560
I0620 22:47:16.530406 32183 layer_factory.hpp:77] Creating layer conv5_4/dw/bn
I0620 22:47:16.530423 32183 net.cpp:84] Creating Layer conv5_4/dw/bn
I0620 22:47:16.530434 32183 net.cpp:406] conv5_4/dw/bn <- conv5_4/dw
I0620 22:47:16.530445 32183 net.cpp:367] conv5_4/dw/bn -> conv5_4/dw (in-place)
I0620 22:47:16.530750 32183 net.cpp:122] Setting up conv5_4/dw/bn
I0620 22:47:16.530768 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.530776 32183 net.cpp:137] Memory required for data: 728555640
I0620 22:47:16.530792 32183 layer_factory.hpp:77] Creating layer conv5_4/dw/scale
I0620 22:47:16.530807 32183 net.cpp:84] Creating Layer conv5_4/dw/scale
I0620 22:47:16.530815 32183 net.cpp:406] conv5_4/dw/scale <- conv5_4/dw
I0620 22:47:16.530830 32183 net.cpp:367] conv5_4/dw/scale -> conv5_4/dw (in-place)
I0620 22:47:16.530892 32183 layer_factory.hpp:77] Creating layer conv5_4/dw/scale
I0620 22:47:16.531075 32183 net.cpp:122] Setting up conv5_4/dw/scale
I0620 22:47:16.531095 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.531103 32183 net.cpp:137] Memory required for data: 732569720
I0620 22:47:16.531157 32183 layer_factory.hpp:77] Creating layer relu5_4/dw
I0620 22:47:16.531172 32183 net.cpp:84] Creating Layer relu5_4/dw
I0620 22:47:16.531182 32183 net.cpp:406] relu5_4/dw <- conv5_4/dw
I0620 22:47:16.531193 32183 net.cpp:367] relu5_4/dw -> conv5_4/dw (in-place)
I0620 22:47:16.531442 32183 net.cpp:122] Setting up relu5_4/dw
I0620 22:47:16.531461 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.531469 32183 net.cpp:137] Memory required for data: 736583800
I0620 22:47:16.531478 32183 layer_factory.hpp:77] Creating layer conv5_4/sep
I0620 22:47:16.531496 32183 net.cpp:84] Creating Layer conv5_4/sep
I0620 22:47:16.531505 32183 net.cpp:406] conv5_4/sep <- conv5_4/dw
I0620 22:47:16.531527 32183 net.cpp:380] conv5_4/sep -> conv5_4/sep
I0620 22:47:16.537356 32183 net.cpp:122] Setting up conv5_4/sep
I0620 22:47:16.537400 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.537410 32183 net.cpp:137] Memory required for data: 740597880
I0620 22:47:16.537448 32183 layer_factory.hpp:77] Creating layer conv5_4/sep/bn
I0620 22:47:16.537466 32183 net.cpp:84] Creating Layer conv5_4/sep/bn
I0620 22:47:16.537475 32183 net.cpp:406] conv5_4/sep/bn <- conv5_4/sep
I0620 22:47:16.537492 32183 net.cpp:367] conv5_4/sep/bn -> conv5_4/sep (in-place)
I0620 22:47:16.537803 32183 net.cpp:122] Setting up conv5_4/sep/bn
I0620 22:47:16.537823 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.537842 32183 net.cpp:137] Memory required for data: 744611960
I0620 22:47:16.537858 32183 layer_factory.hpp:77] Creating layer conv5_4/sep/scale
I0620 22:47:16.537871 32183 net.cpp:84] Creating Layer conv5_4/sep/scale
I0620 22:47:16.537880 32183 net.cpp:406] conv5_4/sep/scale <- conv5_4/sep
I0620 22:47:16.537891 32183 net.cpp:367] conv5_4/sep/scale -> conv5_4/sep (in-place)
I0620 22:47:16.537961 32183 layer_factory.hpp:77] Creating layer conv5_4/sep/scale
I0620 22:47:16.538156 32183 net.cpp:122] Setting up conv5_4/sep/scale
I0620 22:47:16.538173 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.538182 32183 net.cpp:137] Memory required for data: 748626040
I0620 22:47:16.538193 32183 layer_factory.hpp:77] Creating layer relu5_4/sep
I0620 22:47:16.538205 32183 net.cpp:84] Creating Layer relu5_4/sep
I0620 22:47:16.538214 32183 net.cpp:406] relu5_4/sep <- conv5_4/sep
I0620 22:47:16.538228 32183 net.cpp:367] relu5_4/sep -> conv5_4/sep (in-place)
I0620 22:47:16.538758 32183 net.cpp:122] Setting up relu5_4/sep
I0620 22:47:16.538780 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.538789 32183 net.cpp:137] Memory required for data: 752640120
I0620 22:47:16.538797 32183 layer_factory.hpp:77] Creating layer conv5_5/dw
I0620 22:47:16.538817 32183 net.cpp:84] Creating Layer conv5_5/dw
I0620 22:47:16.538827 32183 net.cpp:406] conv5_5/dw <- conv5_4/sep
I0620 22:47:16.538841 32183 net.cpp:380] conv5_5/dw -> conv5_5/dw
I0620 22:47:16.539090 32183 net.cpp:122] Setting up conv5_5/dw
I0620 22:47:16.539108 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.539116 32183 net.cpp:137] Memory required for data: 756654200
I0620 22:47:16.539127 32183 layer_factory.hpp:77] Creating layer conv5_5/dw/bn
I0620 22:47:16.539144 32183 net.cpp:84] Creating Layer conv5_5/dw/bn
I0620 22:47:16.539153 32183 net.cpp:406] conv5_5/dw/bn <- conv5_5/dw
I0620 22:47:16.539165 32183 net.cpp:367] conv5_5/dw/bn -> conv5_5/dw (in-place)
I0620 22:47:16.539448 32183 net.cpp:122] Setting up conv5_5/dw/bn
I0620 22:47:16.539465 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.539474 32183 net.cpp:137] Memory required for data: 760668280
I0620 22:47:16.539486 32183 layer_factory.hpp:77] Creating layer conv5_5/dw/scale
I0620 22:47:16.539499 32183 net.cpp:84] Creating Layer conv5_5/dw/scale
I0620 22:47:16.539508 32183 net.cpp:406] conv5_5/dw/scale <- conv5_5/dw
I0620 22:47:16.539533 32183 net.cpp:367] conv5_5/dw/scale -> conv5_5/dw (in-place)
I0620 22:47:16.539597 32183 layer_factory.hpp:77] Creating layer conv5_5/dw/scale
I0620 22:47:16.539778 32183 net.cpp:122] Setting up conv5_5/dw/scale
I0620 22:47:16.539796 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.539804 32183 net.cpp:137] Memory required for data: 764682360
I0620 22:47:16.539816 32183 layer_factory.hpp:77] Creating layer relu5_5/dw
I0620 22:47:16.539831 32183 net.cpp:84] Creating Layer relu5_5/dw
I0620 22:47:16.539841 32183 net.cpp:406] relu5_5/dw <- conv5_5/dw
I0620 22:47:16.539851 32183 net.cpp:367] relu5_5/dw -> conv5_5/dw (in-place)
I0620 22:47:16.540097 32183 net.cpp:122] Setting up relu5_5/dw
I0620 22:47:16.540117 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.540128 32183 net.cpp:137] Memory required for data: 768696440
I0620 22:47:16.540138 32183 layer_factory.hpp:77] Creating layer conv5_5/sep
I0620 22:47:16.540151 32183 net.cpp:84] Creating Layer conv5_5/sep
I0620 22:47:16.540160 32183 net.cpp:406] conv5_5/sep <- conv5_5/dw
I0620 22:47:16.540176 32183 net.cpp:380] conv5_5/sep -> conv5_5/sep
I0620 22:47:16.546005 32183 net.cpp:122] Setting up conv5_5/sep
I0620 22:47:16.546072 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.546082 32183 net.cpp:137] Memory required for data: 772710520
I0620 22:47:16.546095 32183 layer_factory.hpp:77] Creating layer conv5_5/sep/bn
I0620 22:47:16.546115 32183 net.cpp:84] Creating Layer conv5_5/sep/bn
I0620 22:47:16.546126 32183 net.cpp:406] conv5_5/sep/bn <- conv5_5/sep
I0620 22:47:16.546154 32183 net.cpp:367] conv5_5/sep/bn -> conv5_5/sep (in-place)
I0620 22:47:16.546465 32183 net.cpp:122] Setting up conv5_5/sep/bn
I0620 22:47:16.546483 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.546492 32183 net.cpp:137] Memory required for data: 776724600
I0620 22:47:16.546509 32183 layer_factory.hpp:77] Creating layer conv5_5/sep/scale
I0620 22:47:16.546532 32183 net.cpp:84] Creating Layer conv5_5/sep/scale
I0620 22:47:16.546542 32183 net.cpp:406] conv5_5/sep/scale <- conv5_5/sep
I0620 22:47:16.546557 32183 net.cpp:367] conv5_5/sep/scale -> conv5_5/sep (in-place)
I0620 22:47:16.546625 32183 layer_factory.hpp:77] Creating layer conv5_5/sep/scale
I0620 22:47:16.546808 32183 net.cpp:122] Setting up conv5_5/sep/scale
I0620 22:47:16.546828 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.546836 32183 net.cpp:137] Memory required for data: 780738680
I0620 22:47:16.546850 32183 layer_factory.hpp:77] Creating layer relu5_5/sep
I0620 22:47:16.546862 32183 net.cpp:84] Creating Layer relu5_5/sep
I0620 22:47:16.546871 32183 net.cpp:406] relu5_5/sep <- conv5_5/sep
I0620 22:47:16.546882 32183 net.cpp:367] relu5_5/sep -> conv5_5/sep (in-place)
I0620 22:47:16.547407 32183 net.cpp:122] Setting up relu5_5/sep
I0620 22:47:16.547428 32183 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0620 22:47:16.547437 32183 net.cpp:137] Memory required for data: 784752760
I0620 22:47:16.547446 32183 layer_factory.hpp:77] Creating layer conv5_6/dw
I0620 22:47:16.547466 32183 net.cpp:84] Creating Layer conv5_6/dw
I0620 22:47:16.547477 32183 net.cpp:406] conv5_6/dw <- conv5_5/sep
I0620 22:47:16.547493 32183 net.cpp:380] conv5_6/dw -> conv5_6/dw
I0620 22:47:16.547751 32183 net.cpp:122] Setting up conv5_6/dw
I0620 22:47:16.547771 32183 net.cpp:129] Top shape: 10 512 7 7 (250880)
I0620 22:47:16.547780 32183 net.cpp:137] Memory required for data: 785756280
I0620 22:47:16.547791 32183 layer_factory.hpp:77] Creating layer conv5_6/dw/bn
I0620 22:47:16.547807 32183 net.cpp:84] Creating Layer conv5_6/dw/bn
I0620 22:47:16.547817 32183 net.cpp:406] conv5_6/dw/bn <- conv5_6/dw
I0620 22:47:16.547828 32183 net.cpp:367] conv5_6/dw/bn -> conv5_6/dw (in-place)
I0620 22:47:16.548238 32183 net.cpp:122] Setting up conv5_6/dw/bn
I0620 22:47:16.548256 32183 net.cpp:129] Top shape: 10 512 7 7 (250880)
I0620 22:47:16.548264 32183 net.cpp:137] Memory required for data: 786759800
I0620 22:47:16.548277 32183 layer_factory.hpp:77] Creating layer conv5_6/dw/scale
I0620 22:47:16.548293 32183 net.cpp:84] Creating Layer conv5_6/dw/scale
I0620 22:47:16.548302 32183 net.cpp:406] conv5_6/dw/scale <- conv5_6/dw
I0620 22:47:16.548321 32183 net.cpp:367] conv5_6/dw/scale -> conv5_6/dw (in-place)
I0620 22:47:16.548384 32183 layer_factory.hpp:77] Creating layer conv5_6/dw/scale
I0620 22:47:16.548584 32183 net.cpp:122] Setting up conv5_6/dw/scale
I0620 22:47:16.548604 32183 net.cpp:129] Top shape: 10 512 7 7 (250880)
I0620 22:47:16.548611 32183 net.cpp:137] Memory required for data: 787763320
I0620 22:47:16.548624 32183 layer_factory.hpp:77] Creating layer relu5_6/dw
I0620 22:47:16.548636 32183 net.cpp:84] Creating Layer relu5_6/dw
I0620 22:47:16.548645 32183 net.cpp:406] relu5_6/dw <- conv5_6/dw
I0620 22:47:16.548656 32183 net.cpp:367] relu5_6/dw -> conv5_6/dw (in-place)
I0620 22:47:16.548908 32183 net.cpp:122] Setting up relu5_6/dw
I0620 22:47:16.548928 32183 net.cpp:129] Top shape: 10 512 7 7 (250880)
I0620 22:47:16.548936 32183 net.cpp:137] Memory required for data: 788766840
I0620 22:47:16.548944 32183 layer_factory.hpp:77] Creating layer conv5_6/sep
I0620 22:47:16.548964 32183 net.cpp:84] Creating Layer conv5_6/sep
I0620 22:47:16.548987 32183 net.cpp:406] conv5_6/sep <- conv5_6/dw
I0620 22:47:16.549005 32183 net.cpp:380] conv5_6/sep -> conv5_6/sep
I0620 22:47:16.560878 32183 net.cpp:122] Setting up conv5_6/sep
I0620 22:47:16.560938 32183 net.cpp:129] Top shape: 10 1024 7 7 (501760)
I0620 22:47:16.560948 32183 net.cpp:137] Memory required for data: 790773880
I0620 22:47:16.560968 32183 layer_factory.hpp:77] Creating layer conv5_6/sep/bn
I0620 22:47:16.561009 32183 net.cpp:84] Creating Layer conv5_6/sep/bn
I0620 22:47:16.561024 32183 net.cpp:406] conv5_6/sep/bn <- conv5_6/sep
I0620 22:47:16.561043 32183 net.cpp:367] conv5_6/sep/bn -> conv5_6/sep (in-place)
I0620 22:47:16.561393 32183 net.cpp:122] Setting up conv5_6/sep/bn
I0620 22:47:16.561414 32183 net.cpp:129] Top shape: 10 1024 7 7 (501760)
I0620 22:47:16.561424 32183 net.cpp:137] Memory required for data: 792780920
I0620 22:47:16.561439 32183 layer_factory.hpp:77] Creating layer conv5_6/sep/scale
I0620 22:47:16.561491 32183 net.cpp:84] Creating Layer conv5_6/sep/scale
I0620 22:47:16.561502 32183 net.cpp:406] conv5_6/sep/scale <- conv5_6/sep
I0620 22:47:16.561520 32183 net.cpp:367] conv5_6/sep/scale -> conv5_6/sep (in-place)
I0620 22:47:16.561662 32183 layer_factory.hpp:77] Creating layer conv5_6/sep/scale
I0620 22:47:16.561864 32183 net.cpp:122] Setting up conv5_6/sep/scale
I0620 22:47:16.561882 32183 net.cpp:129] Top shape: 10 1024 7 7 (501760)
I0620 22:47:16.561892 32183 net.cpp:137] Memory required for data: 794787960
I0620 22:47:16.561904 32183 layer_factory.hpp:77] Creating layer relu5_6/sep
I0620 22:47:16.561918 32183 net.cpp:84] Creating Layer relu5_6/sep
I0620 22:47:16.561926 32183 net.cpp:406] relu5_6/sep <- conv5_6/sep
I0620 22:47:16.561941 32183 net.cpp:367] relu5_6/sep -> conv5_6/sep (in-place)
I0620 22:47:16.562572 32183 net.cpp:122] Setting up relu5_6/sep
I0620 22:47:16.562595 32183 net.cpp:129] Top shape: 10 1024 7 7 (501760)
I0620 22:47:16.562604 32183 net.cpp:137] Memory required for data: 796795000
I0620 22:47:16.562613 32183 layer_factory.hpp:77] Creating layer conv6/dw
I0620 22:47:16.562633 32183 net.cpp:84] Creating Layer conv6/dw
I0620 22:47:16.562644 32183 net.cpp:406] conv6/dw <- conv5_6/sep
I0620 22:47:16.562656 32183 net.cpp:380] conv6/dw -> conv6/dw
I0620 22:47:16.562975 32183 net.cpp:122] Setting up conv6/dw
I0620 22:47:16.562994 32183 net.cpp:129] Top shape: 10 1024 7 7 (501760)
I0620 22:47:16.563002 32183 net.cpp:137] Memory required for data: 798802040
I0620 22:47:16.563014 32183 layer_factory.hpp:77] Creating layer conv6/dw/bn
I0620 22:47:16.563032 32183 net.cpp:84] Creating Layer conv6/dw/bn
I0620 22:47:16.563043 32183 net.cpp:406] conv6/dw/bn <- conv6/dw
I0620 22:47:16.563057 32183 net.cpp:367] conv6/dw/bn -> conv6/dw (in-place)
I0620 22:47:16.563357 32183 net.cpp:122] Setting up conv6/dw/bn
I0620 22:47:16.563374 32183 net.cpp:129] Top shape: 10 1024 7 7 (501760)
I0620 22:47:16.563383 32183 net.cpp:137] Memory required for data: 800809080
I0620 22:47:16.563411 32183 layer_factory.hpp:77] Creating layer conv6/dw/scale
I0620 22:47:16.563438 32183 net.cpp:84] Creating Layer conv6/dw/scale
I0620 22:47:16.563448 32183 net.cpp:406] conv6/dw/scale <- conv6/dw
I0620 22:47:16.563460 32183 net.cpp:367] conv6/dw/scale -> conv6/dw (in-place)
I0620 22:47:16.563539 32183 layer_factory.hpp:77] Creating layer conv6/dw/scale
I0620 22:47:16.563733 32183 net.cpp:122] Setting up conv6/dw/scale
I0620 22:47:16.563751 32183 net.cpp:129] Top shape: 10 1024 7 7 (501760)
I0620 22:47:16.563760 32183 net.cpp:137] Memory required for data: 802816120
I0620 22:47:16.563771 32183 layer_factory.hpp:77] Creating layer relu6/dw
I0620 22:47:16.563794 32183 net.cpp:84] Creating Layer relu6/dw
I0620 22:47:16.563805 32183 net.cpp:406] relu6/dw <- conv6/dw
I0620 22:47:16.563818 32183 net.cpp:367] relu6/dw -> conv6/dw (in-place)
I0620 22:47:16.564062 32183 net.cpp:122] Setting up relu6/dw
I0620 22:47:16.564081 32183 net.cpp:129] Top shape: 10 1024 7 7 (501760)
I0620 22:47:16.564090 32183 net.cpp:137] Memory required for data: 804823160
I0620 22:47:16.564098 32183 layer_factory.hpp:77] Creating layer conv6/sep
I0620 22:47:16.564139 32183 net.cpp:84] Creating Layer conv6/sep
I0620 22:47:16.564151 32183 net.cpp:406] conv6/sep <- conv6/dw
I0620 22:47:16.564165 32183 net.cpp:380] conv6/sep -> conv6/sep
I0620 22:47:16.586156 32183 net.cpp:122] Setting up conv6/sep
I0620 22:47:16.586217 32183 net.cpp:129] Top shape: 10 1024 7 7 (501760)
I0620 22:47:16.586227 32183 net.cpp:137] Memory required for data: 806830200
I0620 22:47:16.586258 32183 layer_factory.hpp:77] Creating layer conv6/sep/bn
I0620 22:47:16.586288 32183 net.cpp:84] Creating Layer conv6/sep/bn
I0620 22:47:16.586302 32183 net.cpp:406] conv6/sep/bn <- conv6/sep
I0620 22:47:16.586316 32183 net.cpp:367] conv6/sep/bn -> conv6/sep (in-place)
I0620 22:47:16.586670 32183 net.cpp:122] Setting up conv6/sep/bn
I0620 22:47:16.586690 32183 net.cpp:129] Top shape: 10 1024 7 7 (501760)
I0620 22:47:16.586699 32183 net.cpp:137] Memory required for data: 808837240
I0620 22:47:16.586733 32183 layer_factory.hpp:77] Creating layer conv6/sep/scale
I0620 22:47:16.586756 32183 net.cpp:84] Creating Layer conv6/sep/scale
I0620 22:47:16.586767 32183 net.cpp:406] conv6/sep/scale <- conv6/sep
I0620 22:47:16.586778 32183 net.cpp:367] conv6/sep/scale -> conv6/sep (in-place)
I0620 22:47:16.586860 32183 layer_factory.hpp:77] Creating layer conv6/sep/scale
I0620 22:47:16.587057 32183 net.cpp:122] Setting up conv6/sep/scale
I0620 22:47:16.587075 32183 net.cpp:129] Top shape: 10 1024 7 7 (501760)
I0620 22:47:16.587083 32183 net.cpp:137] Memory required for data: 810844280
I0620 22:47:16.587095 32183 layer_factory.hpp:77] Creating layer relu6/sep
I0620 22:47:16.587121 32183 net.cpp:84] Creating Layer relu6/sep
I0620 22:47:16.587131 32183 net.cpp:406] relu6/sep <- conv6/sep
I0620 22:47:16.587146 32183 net.cpp:367] relu6/sep -> conv6/sep (in-place)
I0620 22:47:16.587950 32183 net.cpp:122] Setting up relu6/sep
I0620 22:47:16.587973 32183 net.cpp:129] Top shape: 10 1024 7 7 (501760)
I0620 22:47:16.587982 32183 net.cpp:137] Memory required for data: 812851320
I0620 22:47:16.587990 32183 layer_factory.hpp:77] Creating layer pool6
I0620 22:47:16.588006 32183 net.cpp:84] Creating Layer pool6
I0620 22:47:16.588014 32183 net.cpp:406] pool6 <- conv6/sep
I0620 22:47:16.588030 32183 net.cpp:380] pool6 -> pool6
I0620 22:47:16.588352 32183 net.cpp:122] Setting up pool6
I0620 22:47:16.588372 32183 net.cpp:129] Top shape: 10 1024 1 1 (10240)
I0620 22:47:16.588382 32183 net.cpp:137] Memory required for data: 812892280
I0620 22:47:16.588390 32183 layer_factory.hpp:77] Creating layer fc7_oxford
I0620 22:47:16.588410 32183 net.cpp:84] Creating Layer fc7_oxford
I0620 22:47:16.588421 32183 net.cpp:406] fc7_oxford <- pool6
I0620 22:47:16.588436 32183 net.cpp:380] fc7_oxford -> fc7
I0620 22:47:16.591285 32183 net.cpp:122] Setting up fc7_oxford
I0620 22:47:16.591313 32183 net.cpp:129] Top shape: 10 102 1 1 (1020)
I0620 22:47:16.591323 32183 net.cpp:137] Memory required for data: 812896360
I0620 22:47:16.591338 32183 layer_factory.hpp:77] Creating layer fc7_fc7_oxford_0_split
I0620 22:47:16.591358 32183 net.cpp:84] Creating Layer fc7_fc7_oxford_0_split
I0620 22:47:16.591368 32183 net.cpp:406] fc7_fc7_oxford_0_split <- fc7
I0620 22:47:16.591382 32183 net.cpp:380] fc7_fc7_oxford_0_split -> fc7_fc7_oxford_0_split_0
I0620 22:47:16.591395 32183 net.cpp:380] fc7_fc7_oxford_0_split -> fc7_fc7_oxford_0_split_1
I0620 22:47:16.591466 32183 net.cpp:122] Setting up fc7_fc7_oxford_0_split
I0620 22:47:16.591483 32183 net.cpp:129] Top shape: 10 102 1 1 (1020)
I0620 22:47:16.591493 32183 net.cpp:129] Top shape: 10 102 1 1 (1020)
I0620 22:47:16.591501 32183 net.cpp:137] Memory required for data: 812904520
I0620 22:47:16.591509 32183 layer_factory.hpp:77] Creating layer accuracy
I0620 22:47:16.591547 32183 net.cpp:84] Creating Layer accuracy
I0620 22:47:16.591559 32183 net.cpp:406] accuracy <- fc7_fc7_oxford_0_split_0
I0620 22:47:16.591570 32183 net.cpp:406] accuracy <- label_data_1_split_0
I0620 22:47:16.591585 32183 net.cpp:380] accuracy -> accuracy
I0620 22:47:16.591609 32183 net.cpp:122] Setting up accuracy
I0620 22:47:16.591621 32183 net.cpp:129] Top shape: (1)
I0620 22:47:16.591648 32183 net.cpp:137] Memory required for data: 812904524
I0620 22:47:16.591657 32183 layer_factory.hpp:77] Creating layer loss
I0620 22:47:16.591670 32183 net.cpp:84] Creating Layer loss
I0620 22:47:16.591682 32183 net.cpp:406] loss <- fc7_fc7_oxford_0_split_1
I0620 22:47:16.591692 32183 net.cpp:406] loss <- label_data_1_split_1
I0620 22:47:16.591702 32183 net.cpp:380] loss -> loss
I0620 22:47:16.591725 32183 layer_factory.hpp:77] Creating layer loss
I0620 22:47:16.592345 32183 net.cpp:122] Setting up loss
I0620 22:47:16.592370 32183 net.cpp:129] Top shape: (1)
I0620 22:47:16.592380 32183 net.cpp:132]     with loss weight 1
I0620 22:47:16.592396 32183 net.cpp:137] Memory required for data: 812904528
I0620 22:47:16.592406 32183 net.cpp:198] loss needs backward computation.
I0620 22:47:16.592414 32183 net.cpp:200] accuracy does not need backward computation.
I0620 22:47:16.592423 32183 net.cpp:198] fc7_fc7_oxford_0_split needs backward computation.
I0620 22:47:16.592432 32183 net.cpp:198] fc7_oxford needs backward computation.
I0620 22:47:16.592440 32183 net.cpp:198] pool6 needs backward computation.
I0620 22:47:16.592448 32183 net.cpp:198] relu6/sep needs backward computation.
I0620 22:47:16.592456 32183 net.cpp:198] conv6/sep/scale needs backward computation.
I0620 22:47:16.592463 32183 net.cpp:198] conv6/sep/bn needs backward computation.
I0620 22:47:16.592471 32183 net.cpp:198] conv6/sep needs backward computation.
I0620 22:47:16.592479 32183 net.cpp:198] relu6/dw needs backward computation.
I0620 22:47:16.592488 32183 net.cpp:198] conv6/dw/scale needs backward computation.
I0620 22:47:16.592495 32183 net.cpp:198] conv6/dw/bn needs backward computation.
I0620 22:47:16.592504 32183 net.cpp:198] conv6/dw needs backward computation.
I0620 22:47:16.592511 32183 net.cpp:198] relu5_6/sep needs backward computation.
I0620 22:47:16.592530 32183 net.cpp:198] conv5_6/sep/scale needs backward computation.
I0620 22:47:16.592538 32183 net.cpp:198] conv5_6/sep/bn needs backward computation.
I0620 22:47:16.592546 32183 net.cpp:198] conv5_6/sep needs backward computation.
I0620 22:47:16.592555 32183 net.cpp:198] relu5_6/dw needs backward computation.
I0620 22:47:16.592563 32183 net.cpp:198] conv5_6/dw/scale needs backward computation.
I0620 22:47:16.592571 32183 net.cpp:198] conv5_6/dw/bn needs backward computation.
I0620 22:47:16.592579 32183 net.cpp:198] conv5_6/dw needs backward computation.
I0620 22:47:16.592587 32183 net.cpp:198] relu5_5/sep needs backward computation.
I0620 22:47:16.592595 32183 net.cpp:198] conv5_5/sep/scale needs backward computation.
I0620 22:47:16.592603 32183 net.cpp:198] conv5_5/sep/bn needs backward computation.
I0620 22:47:16.592612 32183 net.cpp:198] conv5_5/sep needs backward computation.
I0620 22:47:16.592620 32183 net.cpp:198] relu5_5/dw needs backward computation.
I0620 22:47:16.592628 32183 net.cpp:198] conv5_5/dw/scale needs backward computation.
I0620 22:47:16.592635 32183 net.cpp:198] conv5_5/dw/bn needs backward computation.
I0620 22:47:16.592643 32183 net.cpp:198] conv5_5/dw needs backward computation.
I0620 22:47:16.592651 32183 net.cpp:198] relu5_4/sep needs backward computation.
I0620 22:47:16.592659 32183 net.cpp:198] conv5_4/sep/scale needs backward computation.
I0620 22:47:16.592667 32183 net.cpp:198] conv5_4/sep/bn needs backward computation.
I0620 22:47:16.592675 32183 net.cpp:198] conv5_4/sep needs backward computation.
I0620 22:47:16.592684 32183 net.cpp:198] relu5_4/dw needs backward computation.
I0620 22:47:16.592691 32183 net.cpp:198] conv5_4/dw/scale needs backward computation.
I0620 22:47:16.592700 32183 net.cpp:198] conv5_4/dw/bn needs backward computation.
I0620 22:47:16.592707 32183 net.cpp:198] conv5_4/dw needs backward computation.
I0620 22:47:16.592715 32183 net.cpp:198] relu5_3/sep needs backward computation.
I0620 22:47:16.592723 32183 net.cpp:198] conv5_3/sep/scale needs backward computation.
I0620 22:47:16.592731 32183 net.cpp:198] conv5_3/sep/bn needs backward computation.
I0620 22:47:16.592739 32183 net.cpp:198] conv5_3/sep needs backward computation.
I0620 22:47:16.592758 32183 net.cpp:198] relu5_3/dw needs backward computation.
I0620 22:47:16.592767 32183 net.cpp:198] conv5_3/dw/scale needs backward computation.
I0620 22:47:16.592775 32183 net.cpp:198] conv5_3/dw/bn needs backward computation.
I0620 22:47:16.592783 32183 net.cpp:198] conv5_3/dw needs backward computation.
I0620 22:47:16.592792 32183 net.cpp:198] relu5_2/sep needs backward computation.
I0620 22:47:16.592806 32183 net.cpp:198] conv5_2/sep/scale needs backward computation.
I0620 22:47:16.592815 32183 net.cpp:198] conv5_2/sep/bn needs backward computation.
I0620 22:47:16.592824 32183 net.cpp:198] conv5_2/sep needs backward computation.
I0620 22:47:16.592833 32183 net.cpp:198] relu5_2/dw needs backward computation.
I0620 22:47:16.592840 32183 net.cpp:198] conv5_2/dw/scale needs backward computation.
I0620 22:47:16.592849 32183 net.cpp:198] conv5_2/dw/bn needs backward computation.
I0620 22:47:16.592856 32183 net.cpp:198] conv5_2/dw needs backward computation.
I0620 22:47:16.592865 32183 net.cpp:198] relu5_1/sep needs backward computation.
I0620 22:47:16.592874 32183 net.cpp:198] conv5_1/sep/scale needs backward computation.
I0620 22:47:16.592881 32183 net.cpp:198] conv5_1/sep/bn needs backward computation.
I0620 22:47:16.592890 32183 net.cpp:198] conv5_1/sep needs backward computation.
I0620 22:47:16.592897 32183 net.cpp:198] relu5_1/dw needs backward computation.
I0620 22:47:16.592905 32183 net.cpp:198] conv5_1/dw/scale needs backward computation.
I0620 22:47:16.592913 32183 net.cpp:198] conv5_1/dw/bn needs backward computation.
I0620 22:47:16.592921 32183 net.cpp:198] conv5_1/dw needs backward computation.
I0620 22:47:16.592929 32183 net.cpp:198] relu4_2/sep needs backward computation.
I0620 22:47:16.592938 32183 net.cpp:198] conv4_2/sep/scale needs backward computation.
I0620 22:47:16.592947 32183 net.cpp:198] conv4_2/sep/bn needs backward computation.
I0620 22:47:16.592954 32183 net.cpp:198] conv4_2/sep needs backward computation.
I0620 22:47:16.592962 32183 net.cpp:198] relu4_2/dw needs backward computation.
I0620 22:47:16.592970 32183 net.cpp:198] conv4_2/dw/scale needs backward computation.
I0620 22:47:16.592978 32183 net.cpp:198] conv4_2/dw/bn needs backward computation.
I0620 22:47:16.592986 32183 net.cpp:198] conv4_2/dw needs backward computation.
I0620 22:47:16.592994 32183 net.cpp:198] relu4_1/sep needs backward computation.
I0620 22:47:16.593003 32183 net.cpp:198] conv4_1/sep/scale needs backward computation.
I0620 22:47:16.593010 32183 net.cpp:198] conv4_1/sep/bn needs backward computation.
I0620 22:47:16.593019 32183 net.cpp:198] conv4_1/sep needs backward computation.
I0620 22:47:16.593027 32183 net.cpp:198] relu4_1/dw needs backward computation.
I0620 22:47:16.593035 32183 net.cpp:198] conv4_1/dw/scale needs backward computation.
I0620 22:47:16.593044 32183 net.cpp:198] conv4_1/dw/bn needs backward computation.
I0620 22:47:16.593051 32183 net.cpp:198] conv4_1/dw needs backward computation.
I0620 22:47:16.593060 32183 net.cpp:198] relu3_2/sep needs backward computation.
I0620 22:47:16.593068 32183 net.cpp:198] conv3_2/sep/scale needs backward computation.
I0620 22:47:16.593076 32183 net.cpp:198] conv3_2/sep/bn needs backward computation.
I0620 22:47:16.593099 32183 net.cpp:198] conv3_2/sep needs backward computation.
I0620 22:47:16.593111 32183 net.cpp:198] relu3_2/dw needs backward computation.
I0620 22:47:16.593118 32183 net.cpp:198] conv3_2/dw/scale needs backward computation.
I0620 22:47:16.593127 32183 net.cpp:198] conv3_2/dw/bn needs backward computation.
I0620 22:47:16.593134 32183 net.cpp:198] conv3_2/dw needs backward computation.
I0620 22:47:16.593143 32183 net.cpp:198] relu3_1/sep needs backward computation.
I0620 22:47:16.593152 32183 net.cpp:198] conv3_1/sep/scale needs backward computation.
I0620 22:47:16.593159 32183 net.cpp:198] conv3_1/sep/bn needs backward computation.
I0620 22:47:16.593168 32183 net.cpp:198] conv3_1/sep needs backward computation.
I0620 22:47:16.593184 32183 net.cpp:198] relu3_1/dw needs backward computation.
I0620 22:47:16.593204 32183 net.cpp:198] conv3_1/dw/scale needs backward computation.
I0620 22:47:16.593212 32183 net.cpp:198] conv3_1/dw/bn needs backward computation.
I0620 22:47:16.593228 32183 net.cpp:198] conv3_1/dw needs backward computation.
I0620 22:47:16.593247 32183 net.cpp:198] relu2_2/sep needs backward computation.
I0620 22:47:16.593256 32183 net.cpp:198] conv2_2/sep/scale needs backward computation.
I0620 22:47:16.593271 32183 net.cpp:198] conv2_2/sep/bn needs backward computation.
I0620 22:47:16.593279 32183 net.cpp:198] conv2_2/sep needs backward computation.
I0620 22:47:16.593297 32183 net.cpp:198] relu2_2/dw needs backward computation.
I0620 22:47:16.593305 32183 net.cpp:198] conv2_2/dw/scale needs backward computation.
I0620 22:47:16.593314 32183 net.cpp:198] conv2_2/dw/bn needs backward computation.
I0620 22:47:16.593322 32183 net.cpp:198] conv2_2/dw needs backward computation.
I0620 22:47:16.593330 32183 net.cpp:198] relu2_1/sep needs backward computation.
I0620 22:47:16.593338 32183 net.cpp:198] conv2_1/sep/scale needs backward computation.
I0620 22:47:16.593346 32183 net.cpp:198] conv2_1/sep/bn needs backward computation.
I0620 22:47:16.593354 32183 net.cpp:198] conv2_1/sep needs backward computation.
I0620 22:47:16.593394 32183 net.cpp:198] relu2_1/dw needs backward computation.
I0620 22:47:16.593405 32183 net.cpp:198] conv2_1/dw/scale needs backward computation.
I0620 22:47:16.593413 32183 net.cpp:198] conv2_1/dw/bn needs backward computation.
I0620 22:47:16.593421 32183 net.cpp:198] conv2_1/dw needs backward computation.
I0620 22:47:16.593430 32183 net.cpp:198] relu1 needs backward computation.
I0620 22:47:16.593437 32183 net.cpp:198] conv1/scale needs backward computation.
I0620 22:47:16.593446 32183 net.cpp:198] conv1/bn needs backward computation.
I0620 22:47:16.593454 32183 net.cpp:198] conv1 needs backward computation.
I0620 22:47:16.593463 32183 net.cpp:200] label_data_1_split does not need backward computation.
I0620 22:47:16.593472 32183 net.cpp:200] data does not need backward computation.
I0620 22:47:16.593480 32183 net.cpp:242] This network produces output accuracy
I0620 22:47:16.593488 32183 net.cpp:242] This network produces output loss
I0620 22:47:16.593571 32183 net.cpp:255] Network initialization done.
I0620 22:47:16.594508 32183 solver.cpp:56] Solver scaffolding done.
I0620 22:47:16.604609 32183 caffe.cpp:155] Finetuning from mobilenet/mobile_1_iter_5001.caffemodel
I0620 22:47:16.622524 32183 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: mobilenet/mobile_1_iter_5001.caffemodel
I0620 22:47:16.622586 32183 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0620 22:47:16.640349 32183 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: mobilenet/mobile_1_iter_5001.caffemodel
I0620 22:47:16.640413 32183 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0620 22:47:16.645458 32183 caffe.cpp:248] Starting Optimization
I0620 22:47:16.645525 32183 solver.cpp:273] Solving MOBILENET
I0620 22:47:16.645537 32183 solver.cpp:274] Learning Rate Policy: step
I0620 22:47:16.655870 32183 solver.cpp:331] Iteration 0, Testing net (#0)
I0620 22:47:16.889353 32183 blocking_queue.cpp:49] Waiting for data
I0620 22:47:31.335603 32183 solver.cpp:398]     Test net output #0: accuracy = 0.00967742
I0620 22:47:31.335685 32183 solver.cpp:398]     Test net output #1: loss = 4.62491 (* 1 = 4.62491 loss)
I0620 22:47:31.344831 32183 compress_conv_layer.cu:174] 0.204766 1.92991e-10 0.991767
I0620 22:47:31.354374 32183 compress_conv_layer.cu:174] 0.204766 1.17708e-10 0.579639
I0620 22:47:31.363896 32183 compress_conv_layer.cu:174] 0.204766 2.11477e-11 0.777383
I0620 22:47:31.373713 32183 compress_conv_layer.cu:174] 0.204766 3.22113e-12 0.819851
I0620 22:47:31.387832 32183 compress_conv_layer.cu:174] 0.204766 1.0287e-11 0.478373
I0620 22:47:31.412245 32183 compress_conv_layer.cu:174] 0.204766 9.86794e-14 0.506516
I0620 22:47:31.516400 32183 compress_conv_layer.cu:174] 0.204766 1.79234e-13 0.499835
I0620 22:47:31.566073 32183 compress_conv_layer.cu:174] 0.204766 2.28223e-12 0.423805
I0620 22:47:31.615720 32183 compress_conv_layer.cu:174] 0.204766 1.9834e-12 0.448906
I0620 22:47:31.664930 32183 compress_conv_layer.cu:174] 0.204766 2.0847e-12 0.604792
I0620 22:47:31.713824 32183 compress_conv_layer.cu:174] 0.204766 5.74126e-12 0.479722
I0620 22:47:31.809401 32183 compress_conv_layer.cu:174] 0.204766 1.71721e-12 0.344721
I0620 22:47:32.050140 32183 compress_conv_layer.cu:174] 0.204766 3.53718e-12 0.306674
I0620 22:47:32.109972 32183 compress_conv_layer.cu:174] 0.204766 3.28916e-07 0.173393
I0620 22:47:32.367154 32183 compress_conv_layer.cu:174] 0.204766 1.92991e-10 0.991767
I0620 22:47:32.375111 32183 compress_conv_layer.cu:174] 0.204766 1.17708e-10 0.579639
I0620 22:47:32.383366 32183 compress_conv_layer.cu:174] 0.204766 2.11477e-11 0.777383
I0620 22:47:32.391444 32183 compress_conv_layer.cu:174] 0.204766 3.22113e-12 0.819851
I0620 22:47:32.403856 32183 compress_conv_layer.cu:174] 0.204766 1.0287e-11 0.478373
I0620 22:47:32.425560 32183 compress_conv_layer.cu:174] 0.204766 9.86794e-14 0.506516
I0620 22:47:32.469362 32183 compress_conv_layer.cu:174] 0.204766 1.79234e-13 0.499835
I0620 22:47:32.511822 32183 compress_conv_layer.cu:174] 0.204766 2.28223e-12 0.423805
I0620 22:47:32.554792 32183 compress_conv_layer.cu:174] 0.204766 1.9834e-12 0.448906
I0620 22:47:32.597270 32183 compress_conv_layer.cu:174] 0.204766 2.0847e-12 0.604792
I0620 22:47:32.640105 32183 compress_conv_layer.cu:174] 0.204766 5.74126e-12 0.479722
I0620 22:47:32.750031 32183 compress_conv_layer.cu:174] 0.204766 1.71721e-12 0.344721
I0620 22:47:32.936730 32183 compress_conv_layer.cu:174] 0.204766 3.53718e-12 0.306674
I0620 22:47:32.961019 32183 compress_conv_layer.cu:174] 0.204766 3.28916e-07 0.173393
I0620 22:47:33.199350 32183 compress_conv_layer.cu:174] 0.204766 1.92991e-10 0.991767
I0620 22:47:33.207324 32183 compress_conv_layer.cu:174] 0.204766 1.17708e-10 0.579639
I0620 22:47:33.215535 32183 compress_conv_layer.cu:174] 0.204766 2.11477e-11 0.777383
I0620 22:47:33.223680 32183 compress_conv_layer.cu:174] 0.204766 3.22113e-12 0.819851
I0620 22:47:33.236052 32183 compress_conv_layer.cu:174] 0.204766 1.0287e-11 0.478373
I0620 22:47:33.257618 32183 compress_conv_layer.cu:174] 0.204766 9.86794e-14 0.506516
I0620 22:47:33.301506 32183 compress_conv_layer.cu:174] 0.204766 1.79234e-13 0.499835
I0620 22:47:33.344141 32183 compress_conv_layer.cu:174] 0.204766 2.28223e-12 0.423805
I0620 22:47:33.387228 32183 compress_conv_layer.cu:174] 0.204766 1.9834e-12 0.448906
I0620 22:47:33.429929 32183 compress_conv_layer.cu:174] 0.204766 2.0847e-12 0.604792
I0620 22:47:33.472826 32183 compress_conv_layer.cu:174] 0.204766 5.74126e-12 0.479722
I0620 22:47:33.562058 32183 compress_conv_layer.cu:174] 0.204766 1.71721e-12 0.344721
I0620 22:47:33.746927 32183 compress_conv_layer.cu:174] 0.204766 3.53718e-12 0.306674
I0620 22:47:33.770836 32183 compress_conv_layer.cu:174] 0.204766 3.28916e-07 0.173393
I0620 22:47:34.009160 32183 compress_conv_layer.cu:174] 0.204766 1.92991e-10 0.991767
I0620 22:47:34.017496 32183 compress_conv_layer.cu:174] 0.204766 1.17708e-10 0.579639
I0620 22:47:34.025722 32183 compress_conv_layer.cu:174] 0.204766 2.11477e-11 0.777383
I0620 22:47:34.033766 32183 compress_conv_layer.cu:174] 0.204766 3.22113e-12 0.819851
I0620 22:47:34.046150 32183 compress_conv_layer.cu:174] 0.204766 1.0287e-11 0.478373
I0620 22:47:34.067909 32183 compress_conv_layer.cu:174] 0.204766 9.86794e-14 0.506516
I0620 22:47:34.111999 32183 compress_conv_layer.cu:174] 0.204766 1.79234e-13 0.499835
I0620 22:47:34.154707 32183 compress_conv_layer.cu:174] 0.204766 2.28223e-12 0.423805
I0620 22:47:34.197782 32183 compress_conv_layer.cu:174] 0.204766 1.9834e-12 0.448906
I0620 22:47:34.240425 32183 compress_conv_layer.cu:174] 0.204766 2.0847e-12 0.604792
I0620 22:47:34.283315 32183 compress_conv_layer.cu:174] 0.204766 5.74126e-12 0.479722
I0620 22:47:34.374713 32183 compress_conv_layer.cu:174] 0.204766 1.71721e-12 0.344721
I0620 22:47:34.560986 32183 compress_conv_layer.cu:174] 0.204766 3.53718e-12 0.306674
I0620 22:47:34.584420 32183 compress_conv_layer.cu:174] 0.204766 3.28916e-07 0.173393
I0620 22:47:34.822718 32183 compress_conv_layer.cu:174] 0.204766 1.92991e-10 0.991767
I0620 22:47:34.830677 32183 compress_conv_layer.cu:174] 0.204766 1.17708e-10 0.579639
I0620 22:47:34.838899 32183 compress_conv_layer.cu:174] 0.204766 2.11477e-11 0.777383
I0620 22:47:34.846979 32183 compress_conv_layer.cu:174] 0.204766 3.22113e-12 0.819851
I0620 22:47:34.859377 32183 compress_conv_layer.cu:174] 0.204766 1.0287e-11 0.478373
I0620 22:47:34.880873 32183 compress_conv_layer.cu:174] 0.204766 9.86794e-14 0.506516
I0620 22:47:34.924717 32183 compress_conv_layer.cu:174] 0.204766 1.79234e-13 0.499835
I0620 22:47:34.967303 32183 compress_conv_layer.cu:174] 0.204766 2.28223e-12 0.423805
I0620 22:47:35.010450 32183 compress_conv_layer.cu:174] 0.204766 1.9834e-12 0.448906
I0620 22:47:35.053243 32183 compress_conv_layer.cu:174] 0.204766 2.0847e-12 0.604792
I0620 22:47:35.096288 32183 compress_conv_layer.cu:174] 0.204766 5.74126e-12 0.479722
I0620 22:47:35.185425 32183 compress_conv_layer.cu:174] 0.204766 1.71721e-12 0.344721
I0620 22:47:35.370365 32183 compress_conv_layer.cu:174] 0.204766 3.53718e-12 0.306674
I0620 22:47:35.393867 32183 compress_conv_layer.cu:174] 0.204766 3.28916e-07 0.173393
I0620 22:47:35.623981 32183 solver.cpp:219] Iteration 0 (-5.60519e-45 iter/s, 18.9782s/50 iters), loss = 0.00479599
I0620 22:47:35.624050 32183 solver.cpp:238]     Train net output #0: loss = 0.00251622 (* 1 = 0.00251622 loss)
I0620 22:47:35.624104 32183 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I0620 22:48:46.518280 32183 solver.cpp:219] Iteration 50 (0.705283 iter/s, 70.8936s/50 iters), loss = 0.00555065
I0620 22:48:46.518542 32183 solver.cpp:238]     Train net output #0: loss = 0.00211107 (* 1 = 0.00211107 loss)
I0620 22:48:46.518568 32183 sgd_solver.cpp:105] Iteration 50, lr = 0.01
I0620 22:49:57.368990 32183 solver.cpp:219] Iteration 100 (0.705719 iter/s, 70.8497s/50 iters), loss = 0.00416261
I0620 22:49:57.369161 32183 solver.cpp:238]     Train net output #0: loss = 0.00161676 (* 1 = 0.00161676 loss)
I0620 22:49:57.369189 32183 sgd_solver.cpp:105] Iteration 100, lr = 0.01
I0620 22:51:08.210892 32183 solver.cpp:219] Iteration 150 (0.705806 iter/s, 70.841s/50 iters), loss = 0.00578981
I0620 22:51:08.211096 32183 solver.cpp:238]     Train net output #0: loss = 0.00323246 (* 1 = 0.00323246 loss)
I0620 22:51:08.211123 32183 sgd_solver.cpp:105] Iteration 150, lr = 0.01
I0620 22:52:19.067749 32183 solver.cpp:219] Iteration 200 (0.705657 iter/s, 70.8559s/50 iters), loss = 0.00514166
I0620 22:52:19.068341 32183 solver.cpp:238]     Train net output #0: loss = 0.0023526 (* 1 = 0.0023526 loss)
I0620 22:52:19.068368 32183 sgd_solver.cpp:105] Iteration 200, lr = 0.01
I0620 22:53:29.923331 32183 solver.cpp:219] Iteration 250 (0.705674 iter/s, 70.8542s/50 iters), loss = 0.00597772
I0620 22:53:29.923558 32183 solver.cpp:238]     Train net output #0: loss = 0.00671416 (* 1 = 0.00671416 loss)
I0620 22:53:29.923585 32183 sgd_solver.cpp:105] Iteration 250, lr = 0.01
I0620 22:54:40.764322 32183 solver.cpp:219] Iteration 300 (0.705816 iter/s, 70.84s/50 iters), loss = 0.00357991
I0620 22:54:40.764498 32183 solver.cpp:238]     Train net output #0: loss = 0.00425234 (* 1 = 0.00425234 loss)
I0620 22:54:40.764534 32183 sgd_solver.cpp:105] Iteration 300, lr = 0.01
I0620 22:55:51.623522 32183 solver.cpp:219] Iteration 350 (0.705634 iter/s, 70.8583s/50 iters), loss = 0.00476017
I0620 22:55:51.623708 32183 solver.cpp:238]     Train net output #0: loss = 0.0051342 (* 1 = 0.0051342 loss)
I0620 22:55:51.623734 32183 sgd_solver.cpp:105] Iteration 350, lr = 0.01
I0620 22:57:02.462877 32183 solver.cpp:219] Iteration 400 (0.705832 iter/s, 70.8384s/50 iters), loss = 0.00621714
I0620 22:57:02.463080 32183 solver.cpp:238]     Train net output #0: loss = 0.0112158 (* 1 = 0.0112158 loss)
I0620 22:57:02.463105 32183 sgd_solver.cpp:105] Iteration 400, lr = 0.01
I0620 22:58:13.313485 32183 solver.cpp:219] Iteration 450 (0.70572 iter/s, 70.8496s/50 iters), loss = 0.00804352
I0620 22:58:13.313812 32183 solver.cpp:238]     Train net output #0: loss = 0.00896481 (* 1 = 0.00896481 loss)
I0620 22:58:13.313839 32183 sgd_solver.cpp:105] Iteration 450, lr = 0.01
I0620 22:59:22.739619 32183 solver.cpp:331] Iteration 500, Testing net (#0)
I0620 22:59:37.637475 32183 solver.cpp:398]     Test net output #0: accuracy = 0.956452
I0620 22:59:37.637560 32183 solver.cpp:398]     Test net output #1: loss = 0.190991 (* 1 = 0.190991 loss)
I0620 22:59:39.047981 32183 solver.cpp:219] Iteration 500 (0.583204 iter/s, 85.7333s/50 iters), loss = 0.0104401
I0620 22:59:39.048085 32183 solver.cpp:238]     Train net output #0: loss = 0.00649287 (* 1 = 0.00649287 loss)
I0620 22:59:39.048116 32183 sgd_solver.cpp:105] Iteration 500, lr = 0.01
I0620 23:00:49.873745 32183 solver.cpp:219] Iteration 550 (0.705966 iter/s, 70.8249s/50 iters), loss = 0.00715516
I0620 23:00:49.873916 32183 solver.cpp:238]     Train net output #0: loss = 0.00763752 (* 1 = 0.00763752 loss)
I0620 23:00:49.873942 32183 sgd_solver.cpp:105] Iteration 550, lr = 0.01
I0620 23:02:00.725404 32183 solver.cpp:219] Iteration 600 (0.705709 iter/s, 70.8508s/50 iters), loss = 0.00463096
I0620 23:02:00.725559 32183 solver.cpp:238]     Train net output #0: loss = 0.00542942 (* 1 = 0.00542942 loss)
I0620 23:02:00.725592 32183 sgd_solver.cpp:105] Iteration 600, lr = 0.01
I0620 23:03:11.604815 32183 solver.cpp:219] Iteration 650 (0.705432 iter/s, 70.8785s/50 iters), loss = 0.00572734
I0620 23:03:11.604990 32183 solver.cpp:238]     Train net output #0: loss = 0.00717721 (* 1 = 0.00717721 loss)
I0620 23:03:11.605016 32183 sgd_solver.cpp:105] Iteration 650, lr = 0.01
I0620 23:04:22.482416 32183 solver.cpp:219] Iteration 700 (0.705451 iter/s, 70.8767s/50 iters), loss = 0.00372496
I0620 23:04:22.482643 32183 solver.cpp:238]     Train net output #0: loss = 0.00253421 (* 1 = 0.00253421 loss)
I0620 23:04:22.482676 32183 sgd_solver.cpp:105] Iteration 700, lr = 0.01
I0620 23:05:33.327931 32183 solver.cpp:219] Iteration 750 (0.705771 iter/s, 70.8445s/50 iters), loss = 0.00543153
I0620 23:05:33.328136 32183 solver.cpp:238]     Train net output #0: loss = 0.00629031 (* 1 = 0.00629031 loss)
I0620 23:05:33.328171 32183 sgd_solver.cpp:105] Iteration 750, lr = 0.01
I0620 23:06:44.177284 32183 solver.cpp:219] Iteration 800 (0.705732 iter/s, 70.8484s/50 iters), loss = 0.00684589
I0620 23:06:44.177599 32183 solver.cpp:238]     Train net output #0: loss = 0.00684965 (* 1 = 0.00684965 loss)
I0620 23:06:44.177626 32183 sgd_solver.cpp:105] Iteration 800, lr = 0.01
I0620 23:07:55.044651 32183 solver.cpp:219] Iteration 850 (0.705554 iter/s, 70.8663s/50 iters), loss = 0.00566939
I0620 23:07:55.044795 32183 solver.cpp:238]     Train net output #0: loss = 0.00307462 (* 1 = 0.00307462 loss)
I0620 23:07:55.044822 32183 sgd_solver.cpp:105] Iteration 850, lr = 0.01
I0620 23:09:05.919144 32183 solver.cpp:219] Iteration 900 (0.705481 iter/s, 70.8736s/50 iters), loss = 0.00550152
I0620 23:09:05.919301 32183 solver.cpp:238]     Train net output #0: loss = 0.00179898 (* 1 = 0.00179898 loss)
I0620 23:09:05.919328 32183 sgd_solver.cpp:105] Iteration 900, lr = 0.01
I0620 23:10:16.773519 32183 solver.cpp:219] Iteration 950 (0.705682 iter/s, 70.8534s/50 iters), loss = 0.0057983
I0620 23:10:16.773699 32183 solver.cpp:238]     Train net output #0: loss = 0.00650013 (* 1 = 0.00650013 loss)
I0620 23:10:16.773726 32183 sgd_solver.cpp:105] Iteration 950, lr = 0.01
I0620 23:11:26.216619 32183 solver.cpp:331] Iteration 1000, Testing net (#0)
I0620 23:11:41.078202 32183 solver.cpp:398]     Test net output #0: accuracy = 0.953226
I0620 23:11:41.078302 32183 solver.cpp:398]     Test net output #1: loss = 0.213325 (* 1 = 0.213325 loss)
I0620 23:11:41.085819 32183 compress_conv_layer.cu:174] 0.324547 1.83657e-10 0.943958
I0620 23:11:41.094596 32183 compress_conv_layer.cu:174] 0.324547 1.12015e-10 0.551723
I0620 23:11:41.103080 32183 compress_conv_layer.cu:174] 0.324547 2.01249e-11 0.740203
I0620 23:11:41.111580 32183 compress_conv_layer.cu:174] 0.324547 3.06535e-12 0.780432
I0620 23:11:41.124783 32183 compress_conv_layer.cu:174] 0.324547 9.78943e-12 0.455534
I0620 23:11:41.147526 32183 compress_conv_layer.cu:174] 0.324547 9.39068e-14 0.482223
I0620 23:11:41.192849 32183 compress_conv_layer.cu:174] 0.324547 1.70565e-13 0.475439
I0620 23:11:41.236603 32183 compress_conv_layer.cu:174] 0.324547 2.17185e-12 0.403248
I0620 23:11:41.280977 32183 compress_conv_layer.cu:174] 0.324547 1.88748e-12 0.427597
I0620 23:11:41.324767 32183 compress_conv_layer.cu:174] 0.324547 1.98388e-12 0.575203
I0620 23:11:41.368373 32183 compress_conv_layer.cu:174] 0.324547 5.46359e-12 0.456289
I0620 23:11:41.457759 32183 compress_conv_layer.cu:174] 0.324547 1.63416e-12 0.327747
I0620 23:11:41.644381 32183 compress_conv_layer.cu:174] 0.324547 3.36611e-12 0.291725
I0620 23:11:41.668364 32183 compress_conv_layer.cu:174] 0.324547 3.13008e-07 0.170216
I0620 23:11:41.907305 32183 compress_conv_layer.cu:174] 0.324547 1.83657e-10 0.943958
I0620 23:11:41.915349 32183 compress_conv_layer.cu:174] 0.324547 1.12015e-10 0.551723
I0620 23:11:41.923671 32183 compress_conv_layer.cu:174] 0.324547 2.01249e-11 0.740203
I0620 23:11:41.931905 32183 compress_conv_layer.cu:174] 0.324547 3.06535e-12 0.780432
I0620 23:11:41.944706 32183 compress_conv_layer.cu:174] 0.324547 9.78943e-12 0.455534
I0620 23:11:41.966886 32183 compress_conv_layer.cu:174] 0.324547 9.39068e-14 0.482223
I0620 23:11:42.011608 32183 compress_conv_layer.cu:174] 0.324547 1.70565e-13 0.475439
I0620 23:11:42.054831 32183 compress_conv_layer.cu:174] 0.324547 2.17185e-12 0.403248
I0620 23:11:42.098537 32183 compress_conv_layer.cu:174] 0.324547 1.88748e-12 0.427597
I0620 23:11:42.142004 32183 compress_conv_layer.cu:174] 0.324547 1.98388e-12 0.575203
I0620 23:11:42.185665 32183 compress_conv_layer.cu:174] 0.324547 5.46359e-12 0.456289
I0620 23:11:42.275092 32183 compress_conv_layer.cu:174] 0.324547 1.63416e-12 0.327747
I0620 23:11:42.462853 32183 compress_conv_layer.cu:174] 0.324547 3.36611e-12 0.291725
I0620 23:11:42.487195 32183 compress_conv_layer.cu:174] 0.324547 3.13008e-07 0.170216
I0620 23:11:42.726164 32183 compress_conv_layer.cu:174] 0.324547 1.83657e-10 0.943958
I0620 23:11:42.734122 32183 compress_conv_layer.cu:174] 0.324547 1.12015e-10 0.551723
I0620 23:11:42.742374 32183 compress_conv_layer.cu:174] 0.324547 2.01249e-11 0.740203
I0620 23:11:42.750480 32183 compress_conv_layer.cu:174] 0.324547 3.06535e-12 0.780432
I0620 23:11:42.763003 32183 compress_conv_layer.cu:174] 0.324547 9.78943e-12 0.455534
I0620 23:11:42.784744 32183 compress_conv_layer.cu:174] 0.324547 9.39068e-14 0.482223
I0620 23:11:42.828865 32183 compress_conv_layer.cu:174] 0.324547 1.70565e-13 0.475439
I0620 23:11:42.871599 32183 compress_conv_layer.cu:174] 0.324547 2.17185e-12 0.403248
I0620 23:11:42.914746 32183 compress_conv_layer.cu:174] 0.324547 1.88748e-12 0.427597
I0620 23:11:42.957631 32183 compress_conv_layer.cu:174] 0.324547 1.98388e-12 0.575203
I0620 23:11:43.000680 32183 compress_conv_layer.cu:174] 0.324547 5.46359e-12 0.456289
I0620 23:11:43.089516 32183 compress_conv_layer.cu:174] 0.324547 1.63416e-12 0.327747
I0620 23:11:43.275382 32183 compress_conv_layer.cu:174] 0.324547 3.36611e-12 0.291725
I0620 23:11:43.298913 32183 compress_conv_layer.cu:174] 0.324547 3.13008e-07 0.170216
I0620 23:11:43.537250 32183 compress_conv_layer.cu:174] 0.324547 1.83657e-10 0.943958
I0620 23:11:43.545189 32183 compress_conv_layer.cu:174] 0.324547 1.12015e-10 0.551723
I0620 23:11:43.553427 32183 compress_conv_layer.cu:174] 0.324547 2.01249e-11 0.740203
I0620 23:11:43.561532 32183 compress_conv_layer.cu:174] 0.324547 3.06535e-12 0.780432
I0620 23:11:43.574053 32183 compress_conv_layer.cu:174] 0.324547 9.78943e-12 0.455534
I0620 23:11:43.595705 32183 compress_conv_layer.cu:174] 0.324547 9.39068e-14 0.482223
I0620 23:11:43.639714 32183 compress_conv_layer.cu:174] 0.324547 1.70565e-13 0.475439
I0620 23:11:43.682446 32183 compress_conv_layer.cu:174] 0.324547 2.17185e-12 0.403248
I0620 23:11:43.725541 32183 compress_conv_layer.cu:174] 0.324547 1.88748e-12 0.427597
I0620 23:11:43.768494 32183 compress_conv_layer.cu:174] 0.324547 1.98388e-12 0.575203
I0620 23:11:43.811571 32183 compress_conv_layer.cu:174] 0.324547 5.46359e-12 0.456289
I0620 23:11:43.900135 32183 compress_conv_layer.cu:174] 0.324547 1.63416e-12 0.327747
I0620 23:11:44.085954 32183 compress_conv_layer.cu:174] 0.324547 3.36611e-12 0.291725
I0620 23:11:44.109552 32183 compress_conv_layer.cu:174] 0.324547 3.13008e-07 0.170216
I0620 23:11:44.347872 32183 compress_conv_layer.cu:174] 0.324547 1.83657e-10 0.943958
I0620 23:11:44.355844 32183 compress_conv_layer.cu:174] 0.324547 1.12015e-10 0.551723
I0620 23:11:44.364068 32183 compress_conv_layer.cu:174] 0.324547 2.01249e-11 0.740203
I0620 23:11:44.372162 32183 compress_conv_layer.cu:174] 0.324547 3.06535e-12 0.780432
I0620 23:11:44.384678 32183 compress_conv_layer.cu:174] 0.324547 9.78943e-12 0.455534
I0620 23:11:44.406364 32183 compress_conv_layer.cu:174] 0.324547 9.39068e-14 0.482223
I0620 23:11:44.450353 32183 compress_conv_layer.cu:174] 0.324547 1.70565e-13 0.475439
I0620 23:11:44.492985 32183 compress_conv_layer.cu:174] 0.324547 2.17185e-12 0.403248
I0620 23:11:44.536065 32183 compress_conv_layer.cu:174] 0.324547 1.88748e-12 0.427597
I0620 23:11:44.578797 32183 compress_conv_layer.cu:174] 0.324547 1.98388e-12 0.575203
I0620 23:11:44.621714 32183 compress_conv_layer.cu:174] 0.324547 5.46359e-12 0.456289
I0620 23:11:44.710149 32183 compress_conv_layer.cu:174] 0.324547 1.63416e-12 0.327747
I0620 23:11:44.895853 32183 compress_conv_layer.cu:174] 0.324547 3.36611e-12 0.291725
I0620 23:11:44.919482 32183 compress_conv_layer.cu:174] 0.324547 3.13008e-07 0.170216
I0620 23:11:45.149873 32183 solver.cpp:219] Iteration 1000 (0.565769 iter/s, 88.3753s/50 iters), loss = 0.00684917
I0620 23:11:45.149960 32183 solver.cpp:238]     Train net output #0: loss = 0.0190865 (* 1 = 0.0190865 loss)
I0620 23:11:45.149984 32183 sgd_solver.cpp:105] Iteration 1000, lr = 0.01
I0620 23:12:55.986063 32183 solver.cpp:219] Iteration 1050 (0.705862 iter/s, 70.8353s/50 iters), loss = 0.0056656
I0620 23:12:55.986344 32183 solver.cpp:238]     Train net output #0: loss = 0.00538958 (* 1 = 0.00538958 loss)
I0620 23:12:55.986373 32183 sgd_solver.cpp:105] Iteration 1050, lr = 0.01
I0620 23:14:06.827577 32183 solver.cpp:219] Iteration 1100 (0.705812 iter/s, 70.8404s/50 iters), loss = 0.00502668
I0620 23:14:06.827833 32183 solver.cpp:238]     Train net output #0: loss = 0.00231808 (* 1 = 0.00231808 loss)
I0620 23:14:06.827862 32183 sgd_solver.cpp:105] Iteration 1100, lr = 0.01
I0620 23:15:17.668781 32183 solver.cpp:219] Iteration 1150 (0.705814 iter/s, 70.8402s/50 iters), loss = 0.00614428
I0620 23:15:17.668963 32183 solver.cpp:238]     Train net output #0: loss = 0.00466045 (* 1 = 0.00466045 loss)
I0620 23:15:17.668994 32183 sgd_solver.cpp:105] Iteration 1150, lr = 0.01
I0620 23:16:28.519412 32183 solver.cpp:219] Iteration 1200 (0.70572 iter/s, 70.8497s/50 iters), loss = 0.0040616
I0620 23:16:28.519639 32183 solver.cpp:238]     Train net output #0: loss = 0.00596648 (* 1 = 0.00596648 loss)
I0620 23:16:28.519665 32183 sgd_solver.cpp:105] Iteration 1200, lr = 0.01
I0620 23:17:39.369659 32183 solver.cpp:219] Iteration 1250 (0.705724 iter/s, 70.8493s/50 iters), loss = 0.00500498
I0620 23:17:39.369804 32183 solver.cpp:238]     Train net output #0: loss = 0.00133244 (* 1 = 0.00133244 loss)
I0620 23:17:39.369832 32183 sgd_solver.cpp:105] Iteration 1250, lr = 0.01
I0620 23:18:50.239789 32183 solver.cpp:219] Iteration 1300 (0.705525 iter/s, 70.8692s/50 iters), loss = 0.00277933
I0620 23:18:50.239979 32183 solver.cpp:238]     Train net output #0: loss = 0.00429024 (* 1 = 0.00429024 loss)
I0620 23:18:50.240006 32183 sgd_solver.cpp:105] Iteration 1300, lr = 0.01
I0620 23:20:01.073248 32183 solver.cpp:219] Iteration 1350 (0.705891 iter/s, 70.8325s/50 iters), loss = 0.00516123
I0620 23:20:01.073441 32183 solver.cpp:238]     Train net output #0: loss = 0.00402357 (* 1 = 0.00402357 loss)
I0620 23:20:01.073468 32183 sgd_solver.cpp:105] Iteration 1350, lr = 0.01
I0620 23:21:11.913460 32183 solver.cpp:219] Iteration 1400 (0.705823 iter/s, 70.8392s/50 iters), loss = 0.00395026
I0620 23:21:11.913691 32183 solver.cpp:238]     Train net output #0: loss = 0.00289325 (* 1 = 0.00289325 loss)
I0620 23:21:11.913717 32183 sgd_solver.cpp:105] Iteration 1400, lr = 0.01
I0620 23:22:22.753926 32183 solver.cpp:219] Iteration 1450 (0.70582 iter/s, 70.8396s/50 iters), loss = 0.00723216
I0620 23:22:22.754081 32183 solver.cpp:238]     Train net output #0: loss = 0.00554609 (* 1 = 0.00554609 loss)
I0620 23:22:22.754106 32183 sgd_solver.cpp:105] Iteration 1450, lr = 0.01
I0620 23:23:32.189080 32183 solver.cpp:331] Iteration 1500, Testing net (#0)
I0620 23:23:46.859943 32183 solver.cpp:398]     Test net output #0: accuracy = 0.964516
I0620 23:23:46.860034 32183 solver.cpp:398]     Test net output #1: loss = 0.184842 (* 1 = 0.184842 loss)
I0620 23:23:48.273267 32183 solver.cpp:219] Iteration 1500 (0.584669 iter/s, 85.5185s/50 iters), loss = 0.00568579
I0620 23:23:48.273399 32183 solver.cpp:238]     Train net output #0: loss = 0.00364474 (* 1 = 0.00364474 loss)
I0620 23:23:48.273432 32183 sgd_solver.cpp:105] Iteration 1500, lr = 0.01
I0620 23:24:59.134511 32183 solver.cpp:219] Iteration 1550 (0.705611 iter/s, 70.8605s/50 iters), loss = 0.00798165
I0620 23:24:59.134666 32183 solver.cpp:238]     Train net output #0: loss = 0.00430502 (* 1 = 0.00430502 loss)
I0620 23:24:59.134693 32183 sgd_solver.cpp:105] Iteration 1550, lr = 0.01
I0620 23:26:10.002743 32183 solver.cpp:219] Iteration 1600 (0.705542 iter/s, 70.8675s/50 iters), loss = 0.00819772
I0620 23:26:10.002940 32183 solver.cpp:238]     Train net output #0: loss = 0.0132923 (* 1 = 0.0132923 loss)
I0620 23:26:10.002974 32183 sgd_solver.cpp:105] Iteration 1600, lr = 0.01
I0620 23:27:20.859922 32183 solver.cpp:219] Iteration 1650 (0.705652 iter/s, 70.8564s/50 iters), loss = 0.0097312
I0620 23:27:20.860072 32183 solver.cpp:238]     Train net output #0: loss = 0.00896811 (* 1 = 0.00896811 loss)
I0620 23:27:20.860100 32183 sgd_solver.cpp:105] Iteration 1650, lr = 0.01
I0620 23:28:31.690256 32183 solver.cpp:219] Iteration 1700 (0.70592 iter/s, 70.8296s/50 iters), loss = 0.00735855
I0620 23:28:31.690446 32183 solver.cpp:238]     Train net output #0: loss = 0.00788628 (* 1 = 0.00788628 loss)
I0620 23:28:31.690474 32183 sgd_solver.cpp:105] Iteration 1700, lr = 0.01
I0620 23:29:42.516911 32183 solver.cpp:219] Iteration 1750 (0.705957 iter/s, 70.8259s/50 iters), loss = 0.00945009
I0620 23:29:42.517123 32183 solver.cpp:238]     Train net output #0: loss = 0.00603704 (* 1 = 0.00603704 loss)
I0620 23:29:42.517150 32183 sgd_solver.cpp:105] Iteration 1750, lr = 0.01
I0620 23:30:53.348716 32183 solver.cpp:219] Iteration 1800 (0.705905 iter/s, 70.831s/50 iters), loss = 0.00602733
I0620 23:30:53.348845 32183 solver.cpp:238]     Train net output #0: loss = 0.0130162 (* 1 = 0.0130162 loss)
I0620 23:30:53.348872 32183 sgd_solver.cpp:105] Iteration 1800, lr = 0.01
I0620 23:32:04.241861 32183 solver.cpp:219] Iteration 1850 (0.705294 iter/s, 70.8924s/50 iters), loss = 0.004741
I0620 23:32:04.242027 32183 solver.cpp:238]     Train net output #0: loss = 0.00629722 (* 1 = 0.00629722 loss)
I0620 23:32:04.242053 32183 sgd_solver.cpp:105] Iteration 1850, lr = 0.01
I0620 23:33:15.115228 32183 solver.cpp:219] Iteration 1900 (0.705491 iter/s, 70.8726s/50 iters), loss = 0.0086633
I0620 23:33:15.115500 32183 solver.cpp:238]     Train net output #0: loss = 0.0119738 (* 1 = 0.0119738 loss)
I0620 23:33:15.115533 32183 sgd_solver.cpp:105] Iteration 1900, lr = 0.01
I0620 23:34:25.994655 32183 solver.cpp:219] Iteration 1950 (0.705432 iter/s, 70.8786s/50 iters), loss = 0.0108719
I0620 23:34:25.994853 32183 solver.cpp:238]     Train net output #0: loss = 0.00293331 (* 1 = 0.00293331 loss)
I0620 23:34:25.994880 32183 sgd_solver.cpp:105] Iteration 1950, lr = 0.01
I0620 23:35:35.433447 32183 solver.cpp:331] Iteration 2000, Testing net (#0)
I0620 23:35:50.287719 32183 solver.cpp:398]     Test net output #0: accuracy = 0.950807
I0620 23:35:50.287822 32183 solver.cpp:398]     Test net output #1: loss = 0.227474 (* 1 = 0.227474 loss)
I0620 23:35:50.295331 32183 compress_conv_layer.cu:174] 0.409533 1.74696e-10 0.898081
I0620 23:35:50.304157 32183 compress_conv_layer.cu:174] 0.409533 1.06549e-10 0.524647
I0620 23:35:50.312654 32183 compress_conv_layer.cu:174] 0.409533 1.91429e-11 0.704437
I0620 23:35:50.321182 32183 compress_conv_layer.cu:174] 0.409533 2.91578e-12 0.742262
I0620 23:35:50.334378 32183 compress_conv_layer.cu:174] 0.409533 9.31178e-12 0.433378
I0620 23:35:50.357856 32183 compress_conv_layer.cu:174] 0.409533 8.93248e-14 0.458659
I0620 23:35:50.403625 32183 compress_conv_layer.cu:174] 0.409533 1.62243e-13 0.451787
I0620 23:35:50.447885 32183 compress_conv_layer.cu:174] 0.409533 2.06588e-12 0.383544
I0620 23:35:50.492141 32183 compress_conv_layer.cu:174] 0.409533 1.79538e-12 0.406982
I0620 23:35:50.535436 32183 compress_conv_layer.cu:174] 0.409533 1.88708e-12 0.546636
I0620 23:35:50.578606 32183 compress_conv_layer.cu:174] 0.409533 5.197e-12 0.433659
I0620 23:35:50.669198 32183 compress_conv_layer.cu:174] 0.409533 1.55442e-12 0.311436
I0620 23:35:50.856113 32183 compress_conv_layer.cu:174] 0.409533 3.20186e-12 0.277371
I0620 23:35:50.880018 32183 compress_conv_layer.cu:174] 0.409533 2.97736e-07 0.168104
I0620 23:35:51.118790 32183 compress_conv_layer.cu:174] 0.409533 1.74696e-10 0.898081
I0620 23:35:51.126833 32183 compress_conv_layer.cu:174] 0.409533 1.06549e-10 0.524647
I0620 23:35:51.135174 32183 compress_conv_layer.cu:174] 0.409533 1.91429e-11 0.704437
I0620 23:35:51.143460 32183 compress_conv_layer.cu:174] 0.409533 2.91578e-12 0.742262
I0620 23:35:51.156292 32183 compress_conv_layer.cu:174] 0.409533 9.31178e-12 0.433378
I0620 23:35:51.178366 32183 compress_conv_layer.cu:174] 0.409533 8.93248e-14 0.458659
I0620 23:35:51.223286 32183 compress_conv_layer.cu:174] 0.409533 1.62243e-13 0.451787
I0620 23:35:51.266614 32183 compress_conv_layer.cu:174] 0.409533 2.06588e-12 0.383544
I0620 23:35:51.310655 32183 compress_conv_layer.cu:174] 0.409533 1.79538e-12 0.406982
I0620 23:35:51.354440 32183 compress_conv_layer.cu:174] 0.409533 1.88708e-12 0.546636
I0620 23:35:51.398161 32183 compress_conv_layer.cu:174] 0.409533 5.197e-12 0.433659
I0620 23:35:51.489259 32183 compress_conv_layer.cu:174] 0.409533 1.55442e-12 0.311436
I0620 23:35:51.679348 32183 compress_conv_layer.cu:174] 0.409533 3.20186e-12 0.277371
I0620 23:35:51.704978 32183 compress_conv_layer.cu:174] 0.409533 2.97736e-07 0.168104
I0620 23:35:51.944010 32183 compress_conv_layer.cu:174] 0.409533 1.74696e-10 0.898081
I0620 23:35:51.952082 32183 compress_conv_layer.cu:174] 0.409533 1.06549e-10 0.524647
I0620 23:35:51.960477 32183 compress_conv_layer.cu:174] 0.409533 1.91429e-11 0.704437
I0620 23:35:51.968863 32183 compress_conv_layer.cu:174] 0.409533 2.91578e-12 0.742262
I0620 23:35:51.981798 32183 compress_conv_layer.cu:174] 0.409533 9.31178e-12 0.433378
I0620 23:35:52.005580 32183 compress_conv_layer.cu:174] 0.409533 8.93248e-14 0.458659
I0620 23:35:52.050637 32183 compress_conv_layer.cu:174] 0.409533 1.62243e-13 0.451787
I0620 23:35:52.093922 32183 compress_conv_layer.cu:174] 0.409533 2.06588e-12 0.383544
I0620 23:35:52.137755 32183 compress_conv_layer.cu:174] 0.409533 1.79538e-12 0.406982
I0620 23:35:52.180887 32183 compress_conv_layer.cu:174] 0.409533 1.88708e-12 0.546636
I0620 23:35:52.224010 32183 compress_conv_layer.cu:174] 0.409533 5.197e-12 0.433659
I0620 23:35:52.314595 32183 compress_conv_layer.cu:174] 0.409533 1.55442e-12 0.311436
I0620 23:35:52.502424 32183 compress_conv_layer.cu:174] 0.409533 3.20186e-12 0.277371
I0620 23:35:52.526443 32183 compress_conv_layer.cu:174] 0.409533 2.97736e-07 0.168104
I0620 23:35:52.765247 32183 compress_conv_layer.cu:174] 0.409533 1.74696e-10 0.898081
I0620 23:35:52.773294 32183 compress_conv_layer.cu:174] 0.409533 1.06549e-10 0.524647
I0620 23:35:52.781638 32183 compress_conv_layer.cu:174] 0.409533 1.91429e-11 0.704437
I0620 23:35:52.789881 32183 compress_conv_layer.cu:174] 0.409533 2.91578e-12 0.742262
I0620 23:35:52.802783 32183 compress_conv_layer.cu:174] 0.409533 9.31178e-12 0.433378
I0620 23:35:52.824813 32183 compress_conv_layer.cu:174] 0.409533 8.93248e-14 0.458659
I0620 23:35:52.869726 32183 compress_conv_layer.cu:174] 0.409533 1.62243e-13 0.451787
I0620 23:35:52.913028 32183 compress_conv_layer.cu:174] 0.409533 2.06588e-12 0.383544
I0620 23:35:52.956969 32183 compress_conv_layer.cu:174] 0.409533 1.79538e-12 0.406982
I0620 23:35:53.001792 32183 compress_conv_layer.cu:174] 0.409533 1.88708e-12 0.546636
I0620 23:35:53.045259 32183 compress_conv_layer.cu:174] 0.409533 5.197e-12 0.433659
I0620 23:35:53.136469 32183 compress_conv_layer.cu:174] 0.409533 1.55442e-12 0.311436
I0620 23:35:53.323799 32183 compress_conv_layer.cu:174] 0.409533 3.20186e-12 0.277371
I0620 23:35:53.347560 32183 compress_conv_layer.cu:174] 0.409533 2.97736e-07 0.168104
I0620 23:35:53.586777 32183 compress_conv_layer.cu:174] 0.409533 1.74696e-10 0.898081
I0620 23:35:53.594761 32183 compress_conv_layer.cu:174] 0.409533 1.06549e-10 0.524647
I0620 23:35:53.602991 32183 compress_conv_layer.cu:174] 0.409533 1.91429e-11 0.704437
I0620 23:35:53.611062 32183 compress_conv_layer.cu:174] 0.409533 2.91578e-12 0.742262
I0620 23:35:53.623567 32183 compress_conv_layer.cu:174] 0.409533 9.31178e-12 0.433378
I0620 23:35:53.645336 32183 compress_conv_layer.cu:174] 0.409533 8.93248e-14 0.458659
I0620 23:35:53.689790 32183 compress_conv_layer.cu:174] 0.409533 1.62243e-13 0.451787
I0620 23:35:53.732702 32183 compress_conv_layer.cu:174] 0.409533 2.06588e-12 0.383544
I0620 23:35:53.776231 32183 compress_conv_layer.cu:174] 0.409533 1.79538e-12 0.406982
I0620 23:35:53.819077 32183 compress_conv_layer.cu:174] 0.409533 1.88708e-12 0.546636
I0620 23:35:53.862052 32183 compress_conv_layer.cu:174] 0.409533 5.197e-12 0.433659
I0620 23:35:53.952201 32183 compress_conv_layer.cu:174] 0.409533 1.55442e-12 0.311436
I0620 23:35:54.145261 32183 compress_conv_layer.cu:174] 0.409533 3.20186e-12 0.277371
I0620 23:35:54.168874 32183 compress_conv_layer.cu:174] 0.409533 2.97736e-07 0.168104
I0620 23:35:54.399065 32183 solver.cpp:219] Iteration 2000 (0.565589 iter/s, 88.4035s/50 iters), loss = 0.00613889
I0620 23:35:54.399157 32183 solver.cpp:238]     Train net output #0: loss = 0.00355894 (* 1 = 0.00355894 loss)
I0620 23:35:54.399181 32183 sgd_solver.cpp:105] Iteration 2000, lr = 0.01
I0620 23:37:05.225518 32183 solver.cpp:219] Iteration 2050 (0.705958 iter/s, 70.8258s/50 iters), loss = 0.00535538
I0620 23:37:05.225764 32183 solver.cpp:238]     Train net output #0: loss = 0.00341381 (* 1 = 0.00341381 loss)
I0620 23:37:05.225790 32183 sgd_solver.cpp:105] Iteration 2050, lr = 0.01
I0620 23:38:16.054018 32183 solver.cpp:219] Iteration 2100 (0.705939 iter/s, 70.8277s/50 iters), loss = 0.00574167
I0620 23:38:16.054172 32183 solver.cpp:238]     Train net output #0: loss = 0.00670887 (* 1 = 0.00670887 loss)
I0620 23:38:16.054199 32183 sgd_solver.cpp:105] Iteration 2100, lr = 0.01
I0620 23:39:26.904471 32183 solver.cpp:219] Iteration 2150 (0.70572 iter/s, 70.8497s/50 iters), loss = 0.00629668
I0620 23:39:26.904624 32183 solver.cpp:238]     Train net output #0: loss = 0.00920899 (* 1 = 0.00920899 loss)
I0620 23:39:26.904650 32183 sgd_solver.cpp:105] Iteration 2150, lr = 0.01
I0620 23:40:37.772994 32183 solver.cpp:219] Iteration 2200 (0.705541 iter/s, 70.8677s/50 iters), loss = 0.00966127
I0620 23:40:37.773136 32183 solver.cpp:238]     Train net output #0: loss = 0.0147756 (* 1 = 0.0147756 loss)
I0620 23:40:37.773164 32183 sgd_solver.cpp:105] Iteration 2200, lr = 0.01
I0620 23:41:48.608907 32183 solver.cpp:219] Iteration 2250 (0.705865 iter/s, 70.835s/50 iters), loss = 0.00562177
I0620 23:41:48.609122 32183 solver.cpp:238]     Train net output #0: loss = 0.00503105 (* 1 = 0.00503105 loss)
I0620 23:41:48.609149 32183 sgd_solver.cpp:105] Iteration 2250, lr = 0.01
I0620 23:42:59.453714 32183 solver.cpp:219] Iteration 2300 (0.705777 iter/s, 70.8439s/50 iters), loss = 0.00545788
I0620 23:42:59.453866 32183 solver.cpp:238]     Train net output #0: loss = 0.00749947 (* 1 = 0.00749947 loss)
I0620 23:42:59.453891 32183 sgd_solver.cpp:105] Iteration 2300, lr = 0.01
I0620 23:44:10.307062 32183 solver.cpp:219] Iteration 2350 (0.705692 iter/s, 70.8525s/50 iters), loss = 0.00867502
I0620 23:44:10.307370 32183 solver.cpp:238]     Train net output #0: loss = 0.00587433 (* 1 = 0.00587433 loss)
I0620 23:44:10.307399 32183 sgd_solver.cpp:105] Iteration 2350, lr = 0.01
I0620 23:45:21.136562 32183 solver.cpp:219] Iteration 2400 (0.705931 iter/s, 70.8285s/50 iters), loss = 0.0111334
I0620 23:45:21.136745 32183 solver.cpp:238]     Train net output #0: loss = 0.0071082 (* 1 = 0.0071082 loss)
I0620 23:45:21.136772 32183 sgd_solver.cpp:105] Iteration 2400, lr = 0.01
I0620 23:46:31.985371 32183 solver.cpp:219] Iteration 2450 (0.705737 iter/s, 70.8479s/50 iters), loss = 0.00514993
I0620 23:46:31.985571 32183 solver.cpp:238]     Train net output #0: loss = 0.00423524 (* 1 = 0.00423524 loss)
I0620 23:46:31.985599 32183 sgd_solver.cpp:105] Iteration 2450, lr = 0.01
I0620 23:47:41.454650 32183 solver.cpp:331] Iteration 2500, Testing net (#0)
I0620 23:47:56.117739 32183 solver.cpp:398]     Test net output #0: accuracy = 0.954839
I0620 23:47:56.117825 32183 solver.cpp:398]     Test net output #1: loss = 0.189828 (* 1 = 0.189828 loss)
I0620 23:47:57.528795 32183 solver.cpp:219] Iteration 2500 (0.584506 iter/s, 85.5424s/50 iters), loss = 0.00693543
I0620 23:47:57.528950 32183 solver.cpp:238]     Train net output #0: loss = 0.00391894 (* 1 = 0.00391894 loss)
I0620 23:47:57.528986 32183 sgd_solver.cpp:105] Iteration 2500, lr = 0.01
I0620 23:49:08.389209 32183 solver.cpp:219] Iteration 2550 (0.705621 iter/s, 70.8596s/50 iters), loss = 0.00906515
I0620 23:49:08.390321 32183 solver.cpp:238]     Train net output #0: loss = 0.00633217 (* 1 = 0.00633217 loss)
I0620 23:49:08.390347 32183 sgd_solver.cpp:105] Iteration 2550, lr = 0.01
I0620 23:50:19.232439 32183 solver.cpp:219] Iteration 2600 (0.705802 iter/s, 70.8414s/50 iters), loss = 0.00741176
I0620 23:50:19.232600 32183 solver.cpp:238]     Train net output #0: loss = 0.00862774 (* 1 = 0.00862774 loss)
I0620 23:50:19.232627 32183 sgd_solver.cpp:105] Iteration 2600, lr = 0.01
I0620 23:51:30.070948 32183 solver.cpp:219] Iteration 2650 (0.70584 iter/s, 70.8376s/50 iters), loss = 0.00272948
I0620 23:51:30.071177 32183 solver.cpp:238]     Train net output #0: loss = 0.00337966 (* 1 = 0.00337966 loss)
I0620 23:51:30.071203 32183 sgd_solver.cpp:105] Iteration 2650, lr = 0.01
I0620 23:52:41.990386 32183 solver.cpp:219] Iteration 2700 (0.695232 iter/s, 71.9185s/50 iters), loss = 0.00882646
I0620 23:52:41.990581 32183 solver.cpp:238]     Train net output #0: loss = 0.00374697 (* 1 = 0.00374697 loss)
I0620 23:52:41.990608 32183 sgd_solver.cpp:105] Iteration 2700, lr = 0.01
I0620 23:53:53.357168 32183 solver.cpp:219] Iteration 2750 (0.700615 iter/s, 71.3659s/50 iters), loss = 0.00531655
I0620 23:53:53.357352 32183 solver.cpp:238]     Train net output #0: loss = 0.00450909 (* 1 = 0.00450909 loss)
I0620 23:53:53.357378 32183 sgd_solver.cpp:105] Iteration 2750, lr = 0.01
I0620 23:55:04.229528 32183 solver.cpp:219] Iteration 2800 (0.705503 iter/s, 70.8715s/50 iters), loss = 0.00483129
I0620 23:55:04.229701 32183 solver.cpp:238]     Train net output #0: loss = 0.00331185 (* 1 = 0.00331185 loss)
I0620 23:55:04.229727 32183 sgd_solver.cpp:105] Iteration 2800, lr = 0.01
I0620 23:56:15.091698 32183 solver.cpp:219] Iteration 2850 (0.705604 iter/s, 70.8613s/50 iters), loss = 0.00715682
I0620 23:56:15.091861 32183 solver.cpp:238]     Train net output #0: loss = 0.00681582 (* 1 = 0.00681582 loss)
I0620 23:56:15.091888 32183 sgd_solver.cpp:105] Iteration 2850, lr = 0.01
I0620 23:57:25.941292 32183 solver.cpp:219] Iteration 2900 (0.705728 iter/s, 70.8488s/50 iters), loss = 0.00815847
I0620 23:57:25.941453 32183 solver.cpp:238]     Train net output #0: loss = 0.00692004 (* 1 = 0.00692004 loss)
I0620 23:57:25.941480 32183 sgd_solver.cpp:105] Iteration 2900, lr = 0.01
I0620 23:58:36.786324 32183 solver.cpp:219] Iteration 2950 (0.705773 iter/s, 70.8443s/50 iters), loss = 0.00926753
I0620 23:58:36.786697 32183 solver.cpp:238]     Train net output #0: loss = 0.00836307 (* 1 = 0.00836307 loss)
I0620 23:58:36.786723 32183 sgd_solver.cpp:105] Iteration 2950, lr = 0.01
I0620 23:59:46.257724 32183 solver.cpp:331] Iteration 3000, Testing net (#0)
I0621 00:00:01.094179 32183 solver.cpp:398]     Test net output #0: accuracy = 0.95242
I0621 00:00:01.094261 32183 solver.cpp:398]     Test net output #1: loss = 0.228982 (* 1 = 0.228982 loss)
I0621 00:00:01.101696 32183 compress_conv_layer.cu:174] 0.475453 1.66172e-10 0.854388
I0621 00:00:01.110368 32183 compress_conv_layer.cu:174] 0.475453 1.0135e-10 0.499456
I0621 00:00:01.118680 32183 compress_conv_layer.cu:174] 0.475453 1.82089e-11 0.670527
I0621 00:00:01.126912 32183 compress_conv_layer.cu:174] 0.475453 2.77351e-12 0.705934
I0621 00:00:01.139726 32183 compress_conv_layer.cu:174] 0.475453 8.85743e-12 0.412231
I0621 00:00:01.162137 32183 compress_conv_layer.cu:174] 0.475453 8.49663e-14 0.435578
I0621 00:00:01.206715 32183 compress_conv_layer.cu:174] 0.475453 1.54326e-13 0.42915
I0621 00:00:01.250331 32183 compress_conv_layer.cu:174] 0.475453 1.96508e-12 0.364733
I0621 00:00:01.294054 32183 compress_conv_layer.cu:174] 0.475453 1.70778e-12 0.387665
I0621 00:00:01.337463 32183 compress_conv_layer.cu:174] 0.475453 1.795e-12 0.51953
I0621 00:00:01.380403 32183 compress_conv_layer.cu:174] 0.475453 4.94343e-12 0.412299
I0621 00:00:01.469743 32183 compress_conv_layer.cu:174] 0.475453 1.47857e-12 0.295919
I0621 00:00:01.656791 32183 compress_conv_layer.cu:174] 0.475453 3.04563e-12 0.263737
I0621 00:00:01.680663 32183 compress_conv_layer.cu:174] 0.475453 2.83208e-07 0.166451
I0621 00:00:01.919512 32183 compress_conv_layer.cu:174] 0.475453 1.66172e-10 0.854388
I0621 00:00:01.927487 32183 compress_conv_layer.cu:174] 0.475453 1.0135e-10 0.499456
I0621 00:00:01.935744 32183 compress_conv_layer.cu:174] 0.475453 1.82089e-11 0.670527
I0621 00:00:01.943842 32183 compress_conv_layer.cu:174] 0.475453 2.77351e-12 0.705934
I0621 00:00:01.956284 32183 compress_conv_layer.cu:174] 0.475453 8.85743e-12 0.412231
I0621 00:00:01.978117 32183 compress_conv_layer.cu:174] 0.475453 8.49663e-14 0.435578
I0621 00:00:02.024036 32183 compress_conv_layer.cu:174] 0.475453 1.54326e-13 0.42915
I0621 00:00:02.067543 32183 compress_conv_layer.cu:174] 0.475453 1.96508e-12 0.364733
I0621 00:00:02.111316 32183 compress_conv_layer.cu:174] 0.475453 1.70778e-12 0.387665
I0621 00:00:02.154736 32183 compress_conv_layer.cu:174] 0.475453 1.795e-12 0.51953
I0621 00:00:02.197840 32183 compress_conv_layer.cu:174] 0.475453 4.94343e-12 0.412299
I0621 00:00:02.287389 32183 compress_conv_layer.cu:174] 0.475453 1.47857e-12 0.295919
I0621 00:00:02.474251 32183 compress_conv_layer.cu:174] 0.475453 3.04563e-12 0.263737
I0621 00:00:02.498405 32183 compress_conv_layer.cu:174] 0.475453 2.83208e-07 0.166451
I0621 00:00:02.737653 32183 compress_conv_layer.cu:174] 0.475453 1.66172e-10 0.854388
I0621 00:00:02.745755 32183 compress_conv_layer.cu:174] 0.475453 1.0135e-10 0.499456
I0621 00:00:02.754189 32183 compress_conv_layer.cu:174] 0.475453 1.82089e-11 0.670527
I0621 00:00:02.762665 32183 compress_conv_layer.cu:174] 0.475453 2.77351e-12 0.705934
I0621 00:00:02.775674 32183 compress_conv_layer.cu:174] 0.475453 8.85743e-12 0.412231
I0621 00:00:02.798487 32183 compress_conv_layer.cu:174] 0.475453 8.49663e-14 0.435578
I0621 00:00:02.843987 32183 compress_conv_layer.cu:174] 0.475453 1.54326e-13 0.42915
I0621 00:00:02.888295 32183 compress_conv_layer.cu:174] 0.475453 1.96508e-12 0.364733
I0621 00:00:02.932705 32183 compress_conv_layer.cu:174] 0.475453 1.70778e-12 0.387665
I0621 00:00:02.976348 32183 compress_conv_layer.cu:174] 0.475453 1.795e-12 0.51953
I0621 00:00:03.021250 32183 compress_conv_layer.cu:174] 0.475453 4.94343e-12 0.412299
I0621 00:00:03.112360 32183 compress_conv_layer.cu:174] 0.475453 1.47857e-12 0.295919
I0621 00:00:03.307234 32183 compress_conv_layer.cu:174] 0.475453 3.04563e-12 0.263737
I0621 00:00:03.333081 32183 compress_conv_layer.cu:174] 0.475453 2.83208e-07 0.166451
I0621 00:00:03.572165 32183 compress_conv_layer.cu:174] 0.475453 1.66172e-10 0.854388
I0621 00:00:03.580268 32183 compress_conv_layer.cu:174] 0.475453 1.0135e-10 0.499456
I0621 00:00:03.588737 32183 compress_conv_layer.cu:174] 0.475453 1.82089e-11 0.670527
I0621 00:00:03.597098 32183 compress_conv_layer.cu:174] 0.475453 2.77351e-12 0.705934
I0621 00:00:03.610091 32183 compress_conv_layer.cu:174] 0.475453 8.85743e-12 0.412231
I0621 00:00:03.632818 32183 compress_conv_layer.cu:174] 0.475453 8.49663e-14 0.435578
I0621 00:00:03.678356 32183 compress_conv_layer.cu:174] 0.475453 1.54326e-13 0.42915
I0621 00:00:03.722199 32183 compress_conv_layer.cu:174] 0.475453 1.96508e-12 0.364733
I0621 00:00:03.766155 32183 compress_conv_layer.cu:174] 0.475453 1.70778e-12 0.387665
I0621 00:00:03.809751 32183 compress_conv_layer.cu:174] 0.475453 1.795e-12 0.51953
I0621 00:00:03.853087 32183 compress_conv_layer.cu:174] 0.475453 4.94343e-12 0.412299
I0621 00:00:03.943259 32183 compress_conv_layer.cu:174] 0.475453 1.47857e-12 0.295919
I0621 00:00:04.131078 32183 compress_conv_layer.cu:174] 0.475453 3.04563e-12 0.263737
I0621 00:00:04.155159 32183 compress_conv_layer.cu:174] 0.475453 2.83208e-07 0.166451
I0621 00:00:04.393853 32183 compress_conv_layer.cu:174] 0.475453 1.66172e-10 0.854388
I0621 00:00:04.401921 32183 compress_conv_layer.cu:174] 0.475453 1.0135e-10 0.499456
I0621 00:00:04.410248 32183 compress_conv_layer.cu:174] 0.475453 1.82089e-11 0.670527
I0621 00:00:04.418505 32183 compress_conv_layer.cu:174] 0.475453 2.77351e-12 0.705934
I0621 00:00:04.431253 32183 compress_conv_layer.cu:174] 0.475453 8.85743e-12 0.412231
I0621 00:00:04.453528 32183 compress_conv_layer.cu:174] 0.475453 8.49663e-14 0.435578
I0621 00:00:04.498405 32183 compress_conv_layer.cu:174] 0.475453 1.54326e-13 0.42915
I0621 00:00:04.542282 32183 compress_conv_layer.cu:174] 0.475453 1.96508e-12 0.364733
I0621 00:00:04.586374 32183 compress_conv_layer.cu:174] 0.475453 1.70778e-12 0.387665
I0621 00:00:04.630019 32183 compress_conv_layer.cu:174] 0.475453 1.795e-12 0.51953
I0621 00:00:04.673353 32183 compress_conv_layer.cu:174] 0.475453 4.94343e-12 0.412299
I0621 00:00:04.764299 32183 compress_conv_layer.cu:174] 0.475453 1.47857e-12 0.295919
I0621 00:00:04.955188 32183 compress_conv_layer.cu:174] 0.475453 3.04563e-12 0.263737
I0621 00:00:04.980561 32183 compress_conv_layer.cu:174] 0.475453 2.83208e-07 0.166451
I0621 00:00:05.211598 32183 solver.cpp:219] Iteration 3000 (0.565456 iter/s, 88.4241s/50 iters), loss = 0.00905056
I0621 00:00:05.211721 32183 solver.cpp:238]     Train net output #0: loss = 0.0028362 (* 1 = 0.0028362 loss)
I0621 00:00:05.211750 32183 sgd_solver.cpp:105] Iteration 3000, lr = 0.01
I0621 00:01:16.079301 32183 solver.cpp:219] Iteration 3050 (0.705547 iter/s, 70.867s/50 iters), loss = 0.00832879
I0621 00:01:16.079699 32183 solver.cpp:238]     Train net output #0: loss = 0.00621905 (* 1 = 0.00621905 loss)
I0621 00:01:16.079725 32183 sgd_solver.cpp:105] Iteration 3050, lr = 0.01
I0621 00:02:26.934567 32183 solver.cpp:219] Iteration 3100 (0.705674 iter/s, 70.8543s/50 iters), loss = 0.00760572
I0621 00:02:26.934705 32183 solver.cpp:238]     Train net output #0: loss = 0.00430545 (* 1 = 0.00430545 loss)
I0621 00:02:26.934731 32183 sgd_solver.cpp:105] Iteration 3100, lr = 0.01
I0621 00:03:37.792932 32183 solver.cpp:219] Iteration 3150 (0.705641 iter/s, 70.8576s/50 iters), loss = 0.00821496
I0621 00:03:37.793160 32183 solver.cpp:238]     Train net output #0: loss = 0.00845014 (* 1 = 0.00845014 loss)
I0621 00:03:37.793200 32183 sgd_solver.cpp:105] Iteration 3150, lr = 0.01
I0621 00:04:48.637414 32183 solver.cpp:219] Iteration 3200 (0.70578 iter/s, 70.8437s/50 iters), loss = 0.00693509
I0621 00:04:48.637567 32183 solver.cpp:238]     Train net output #0: loss = 0.00674205 (* 1 = 0.00674205 loss)
I0621 00:04:48.637595 32183 sgd_solver.cpp:105] Iteration 3200, lr = 0.01
I0621 00:05:59.464490 32183 solver.cpp:219] Iteration 3250 (0.705952 iter/s, 70.8263s/50 iters), loss = 0.00743578
I0621 00:05:59.464634 32183 solver.cpp:238]     Train net output #0: loss = 0.00669686 (* 1 = 0.00669686 loss)
I0621 00:05:59.464660 32183 sgd_solver.cpp:105] Iteration 3250, lr = 0.01
I0621 00:07:10.303838 32183 solver.cpp:219] Iteration 3300 (0.70583 iter/s, 70.8386s/50 iters), loss = 0.00625233
I0621 00:07:10.304078 32183 solver.cpp:238]     Train net output #0: loss = 0.00481513 (* 1 = 0.00481513 loss)
I0621 00:07:10.304106 32183 sgd_solver.cpp:105] Iteration 3300, lr = 0.01
I0621 00:08:21.151368 32183 solver.cpp:219] Iteration 3350 (0.705749 iter/s, 70.8467s/50 iters), loss = 0.00778642
I0621 00:08:21.151582 32183 solver.cpp:238]     Train net output #0: loss = 0.00595767 (* 1 = 0.00595767 loss)
I0621 00:08:21.151608 32183 sgd_solver.cpp:105] Iteration 3350, lr = 0.01
I0621 00:09:32.005839 32183 solver.cpp:219] Iteration 3400 (0.70568 iter/s, 70.8536s/50 iters), loss = 0.0103523
I0621 00:09:32.006062 32183 solver.cpp:238]     Train net output #0: loss = 0.0146778 (* 1 = 0.0146778 loss)
I0621 00:09:32.006091 32183 sgd_solver.cpp:105] Iteration 3400, lr = 0.01
I0621 00:10:42.848754 32183 solver.cpp:219] Iteration 3450 (0.705796 iter/s, 70.842s/50 iters), loss = 0.0041556
I0621 00:10:42.848958 32183 solver.cpp:238]     Train net output #0: loss = 0.0041347 (* 1 = 0.0041347 loss)
I0621 00:10:42.848986 32183 sgd_solver.cpp:105] Iteration 3450, lr = 0.01
I0621 00:11:52.289796 32183 solver.cpp:331] Iteration 3500, Testing net (#0)
I0621 00:12:07.170267 32183 solver.cpp:398]     Test net output #0: accuracy = 0.947581
I0621 00:12:07.170347 32183 solver.cpp:398]     Test net output #1: loss = 0.220219 (* 1 = 0.220219 loss)
I0621 00:12:08.583389 32183 solver.cpp:219] Iteration 3500 (0.583201 iter/s, 85.7337s/50 iters), loss = 0.00908075
I0621 00:12:08.583550 32183 solver.cpp:238]     Train net output #0: loss = 0.00865297 (* 1 = 0.00865297 loss)
I0621 00:12:08.583586 32183 sgd_solver.cpp:105] Iteration 3500, lr = 0.01
I0621 00:13:19.418356 32183 solver.cpp:219] Iteration 3550 (0.705874 iter/s, 70.8342s/50 iters), loss = 0.0105766
I0621 00:13:19.418470 32183 solver.cpp:238]     Train net output #0: loss = 0.0138474 (* 1 = 0.0138474 loss)
I0621 00:13:19.418494 32183 sgd_solver.cpp:105] Iteration 3550, lr = 0.01
I0621 00:14:30.254287 32183 solver.cpp:219] Iteration 3600 (0.705864 iter/s, 70.8352s/50 iters), loss = 0.00528757
I0621 00:14:30.254473 32183 solver.cpp:238]     Train net output #0: loss = 0.00342268 (* 1 = 0.00342268 loss)
I0621 00:14:30.254500 32183 sgd_solver.cpp:105] Iteration 3600, lr = 0.01
I0621 00:15:41.102643 32183 solver.cpp:219] Iteration 3650 (0.705741 iter/s, 70.8475s/50 iters), loss = 0.0100914
I0621 00:15:41.102784 32183 solver.cpp:238]     Train net output #0: loss = 0.00726904 (* 1 = 0.00726904 loss)
I0621 00:15:41.102818 32183 sgd_solver.cpp:105] Iteration 3650, lr = 0.01
I0621 00:16:51.961063 32183 solver.cpp:219] Iteration 3700 (0.70564 iter/s, 70.8576s/50 iters), loss = 0.00783574
I0621 00:16:51.961233 32183 solver.cpp:238]     Train net output #0: loss = 0.0112856 (* 1 = 0.0112856 loss)
I0621 00:16:51.961259 32183 sgd_solver.cpp:105] Iteration 3700, lr = 0.01
I0621 00:18:02.808935 32183 solver.cpp:219] Iteration 3750 (0.705746 iter/s, 70.847s/50 iters), loss = 0.00949785
I0621 00:18:02.809126 32183 solver.cpp:238]     Train net output #0: loss = 0.0101647 (* 1 = 0.0101647 loss)
I0621 00:18:02.809154 32183 sgd_solver.cpp:105] Iteration 3750, lr = 0.01
I0621 00:19:13.663373 32183 solver.cpp:219] Iteration 3800 (0.70568 iter/s, 70.8536s/50 iters), loss = 0.00707266
I0621 00:19:13.663552 32183 solver.cpp:238]     Train net output #0: loss = 0.00486828 (* 1 = 0.00486828 loss)
I0621 00:19:13.663581 32183 sgd_solver.cpp:105] Iteration 3800, lr = 0.01
I0621 00:20:24.509536 32183 solver.cpp:219] Iteration 3850 (0.705763 iter/s, 70.8453s/50 iters), loss = 0.0113077
I0621 00:20:24.509697 32183 solver.cpp:238]     Train net output #0: loss = 0.0112781 (* 1 = 0.0112781 loss)
I0621 00:20:24.509723 32183 sgd_solver.cpp:105] Iteration 3850, lr = 0.01
I0621 00:21:35.375075 32183 solver.cpp:219] Iteration 3900 (0.70557 iter/s, 70.8647s/50 iters), loss = 0.0132246
I0621 00:21:35.375313 32183 solver.cpp:238]     Train net output #0: loss = 0.0165351 (* 1 = 0.0165351 loss)
I0621 00:21:35.375340 32183 sgd_solver.cpp:105] Iteration 3900, lr = 0.01
I0621 00:22:46.236028 32183 solver.cpp:219] Iteration 3950 (0.705616 iter/s, 70.8601s/50 iters), loss = 0.00675368
I0621 00:22:46.236286 32183 solver.cpp:238]     Train net output #0: loss = 0.0041147 (* 1 = 0.0041147 loss)
I0621 00:22:46.236313 32183 sgd_solver.cpp:105] Iteration 3950, lr = 0.01
I0621 00:23:55.697623 32183 solver.cpp:331] Iteration 4000, Testing net (#0)
I0621 00:23:57.554255 32183 blocking_queue.cpp:49] Waiting for data
I0621 00:24:10.358283 32183 solver.cpp:398]     Test net output #0: accuracy = 0.945968
I0621 00:24:10.358371 32183 solver.cpp:398]     Test net output #1: loss = 0.238082 (* 1 = 0.238082 loss)
I0621 00:24:10.365816 32183 compress_conv_layer.cu:174] 0.529314 1.58064e-10 0.812589
I0621 00:24:10.374459 32183 compress_conv_layer.cu:174] 0.529314 9.64051e-11 0.475099
I0621 00:24:10.382783 32183 compress_conv_layer.cu:174] 0.529314 1.73204e-11 0.637419
I0621 00:24:10.391104 32183 compress_conv_layer.cu:174] 0.529314 2.63818e-12 0.671459
I0621 00:24:10.404033 32183 compress_conv_layer.cu:174] 0.529314 8.42524e-12 0.392316
I0621 00:24:10.426326 32183 compress_conv_layer.cu:174] 0.529314 8.08206e-14 0.41488
I0621 00:24:10.470762 32183 compress_conv_layer.cu:174] 0.529314 1.46796e-13 0.406952
I0621 00:24:10.514225 32183 compress_conv_layer.cu:174] 0.529314 1.8692e-12 0.346921
I0621 00:24:10.558357 32183 compress_conv_layer.cu:174] 0.529314 1.62445e-12 0.369071
I0621 00:24:10.601752 32183 compress_conv_layer.cu:174] 0.529314 1.70742e-12 0.493649
I0621 00:24:10.644917 32183 compress_conv_layer.cu:174] 0.529314 4.70222e-12 0.391651
I0621 00:24:10.733949 32183 compress_conv_layer.cu:174] 0.529314 1.40643e-12 0.280988
I0621 00:24:10.920140 32183 compress_conv_layer.cu:174] 0.529314 2.89703e-12 0.250802
I0621 00:24:10.943270 32183 compress_conv_layer.cu:174] 0.529314 2.69389e-07 0.16633
I0621 00:24:11.181736 32183 compress_conv_layer.cu:174] 0.529314 1.58064e-10 0.812589
I0621 00:24:11.189713 32183 compress_conv_layer.cu:174] 0.529314 9.64051e-11 0.475099
I0621 00:24:11.197976 32183 compress_conv_layer.cu:174] 0.529314 1.73204e-11 0.637419
I0621 00:24:11.206082 32183 compress_conv_layer.cu:174] 0.529314 2.63818e-12 0.671459
I0621 00:24:11.218631 32183 compress_conv_layer.cu:174] 0.529314 8.42524e-12 0.392316
I0621 00:24:11.240283 32183 compress_conv_layer.cu:174] 0.529314 8.08206e-14 0.41488
I0621 00:24:11.284257 32183 compress_conv_layer.cu:174] 0.529314 1.46796e-13 0.406952
I0621 00:24:11.327402 32183 compress_conv_layer.cu:174] 0.529314 1.8692e-12 0.346921
I0621 00:24:11.370456 32183 compress_conv_layer.cu:174] 0.529314 1.62445e-12 0.369071
I0621 00:24:11.413444 32183 compress_conv_layer.cu:174] 0.529314 1.70742e-12 0.493649
I0621 00:24:11.456470 32183 compress_conv_layer.cu:174] 0.529314 4.70222e-12 0.391651
I0621 00:24:11.545416 32183 compress_conv_layer.cu:174] 0.529314 1.40643e-12 0.280988
I0621 00:24:11.731922 32183 compress_conv_layer.cu:174] 0.529314 2.89703e-12 0.250802
I0621 00:24:11.755044 32183 compress_conv_layer.cu:174] 0.529314 2.69389e-07 0.16633
I0621 00:24:11.993346 32183 compress_conv_layer.cu:174] 0.529314 1.58064e-10 0.812589
I0621 00:24:12.001354 32183 compress_conv_layer.cu:174] 0.529314 9.64051e-11 0.475099
I0621 00:24:12.009613 32183 compress_conv_layer.cu:174] 0.529314 1.73204e-11 0.637419
I0621 00:24:12.017724 32183 compress_conv_layer.cu:174] 0.529314 2.63818e-12 0.671459
I0621 00:24:12.030217 32183 compress_conv_layer.cu:174] 0.529314 8.42524e-12 0.392316
I0621 00:24:12.052080 32183 compress_conv_layer.cu:174] 0.529314 8.08206e-14 0.41488
I0621 00:24:12.096253 32183 compress_conv_layer.cu:174] 0.529314 1.46796e-13 0.406952
I0621 00:24:12.139689 32183 compress_conv_layer.cu:174] 0.529314 1.8692e-12 0.346921
I0621 00:24:12.183308 32183 compress_conv_layer.cu:174] 0.529314 1.62445e-12 0.369071
I0621 00:24:12.227031 32183 compress_conv_layer.cu:174] 0.529314 1.70742e-12 0.493649
I0621 00:24:12.271651 32183 compress_conv_layer.cu:174] 0.529314 4.70222e-12 0.391651
I0621 00:24:12.363116 32183 compress_conv_layer.cu:174] 0.529314 1.40643e-12 0.280988
I0621 00:24:12.553887 32183 compress_conv_layer.cu:174] 0.529314 2.89703e-12 0.250802
I0621 00:24:12.578351 32183 compress_conv_layer.cu:174] 0.529314 2.69389e-07 0.16633
I0621 00:24:12.816685 32183 compress_conv_layer.cu:174] 0.529314 1.58064e-10 0.812589
I0621 00:24:12.824725 32183 compress_conv_layer.cu:174] 0.529314 9.64051e-11 0.475099
I0621 00:24:12.833066 32183 compress_conv_layer.cu:174] 0.529314 1.73204e-11 0.637419
I0621 00:24:12.841258 32183 compress_conv_layer.cu:174] 0.529314 2.63818e-12 0.671459
I0621 00:24:12.853803 32183 compress_conv_layer.cu:174] 0.529314 8.42524e-12 0.392316
I0621 00:24:12.875524 32183 compress_conv_layer.cu:174] 0.529314 8.08206e-14 0.41488
I0621 00:24:12.919526 32183 compress_conv_layer.cu:174] 0.529314 1.46796e-13 0.406952
I0621 00:24:12.962633 32183 compress_conv_layer.cu:174] 0.529314 1.8692e-12 0.346921
I0621 00:24:13.006036 32183 compress_conv_layer.cu:174] 0.529314 1.62445e-12 0.369071
I0621 00:24:13.049449 32183 compress_conv_layer.cu:174] 0.529314 1.70742e-12 0.493649
I0621 00:24:13.093005 32183 compress_conv_layer.cu:174] 0.529314 4.70222e-12 0.391651
I0621 00:24:13.182421 32183 compress_conv_layer.cu:174] 0.529314 1.40643e-12 0.280988
I0621 00:24:13.368765 32183 compress_conv_layer.cu:174] 0.529314 2.89703e-12 0.250802
I0621 00:24:13.391885 32183 compress_conv_layer.cu:174] 0.529314 2.69389e-07 0.16633
I0621 00:24:13.630117 32183 compress_conv_layer.cu:174] 0.529314 1.58064e-10 0.812589
I0621 00:24:13.638113 32183 compress_conv_layer.cu:174] 0.529314 9.64051e-11 0.475099
I0621 00:24:13.646373 32183 compress_conv_layer.cu:174] 0.529314 1.73204e-11 0.637419
I0621 00:24:13.654510 32183 compress_conv_layer.cu:174] 0.529314 2.63818e-12 0.671459
I0621 00:24:13.666983 32183 compress_conv_layer.cu:174] 0.529314 8.42524e-12 0.392316
I0621 00:24:13.688678 32183 compress_conv_layer.cu:174] 0.529314 8.08206e-14 0.41488
I0621 00:24:13.732676 32183 compress_conv_layer.cu:174] 0.529314 1.46796e-13 0.406952
I0621 00:24:13.775691 32183 compress_conv_layer.cu:174] 0.529314 1.8692e-12 0.346921
I0621 00:24:13.818789 32183 compress_conv_layer.cu:174] 0.529314 1.62445e-12 0.369071
I0621 00:24:13.862151 32183 compress_conv_layer.cu:174] 0.529314 1.70742e-12 0.493649
I0621 00:24:13.905395 32183 compress_conv_layer.cu:174] 0.529314 4.70222e-12 0.391651
I0621 00:24:13.994597 32183 compress_conv_layer.cu:174] 0.529314 1.40643e-12 0.280988
I0621 00:24:14.181186 32183 compress_conv_layer.cu:174] 0.529314 2.89703e-12 0.250802
I0621 00:24:14.204272 32183 compress_conv_layer.cu:174] 0.529314 2.69389e-07 0.16633
I0621 00:24:14.434609 32183 solver.cpp:219] Iteration 4000 (0.566909 iter/s, 88.1975s/50 iters), loss = 0.0103951
I0621 00:24:14.434697 32183 solver.cpp:238]     Train net output #0: loss = 0.024979 (* 1 = 0.024979 loss)
I0621 00:24:14.434725 32183 sgd_solver.cpp:105] Iteration 4000, lr = 0.01
I0621 00:25:25.331460 32183 solver.cpp:219] Iteration 4050 (0.705257 iter/s, 70.8961s/50 iters), loss = 0.00853017
I0621 00:25:25.331620 32183 solver.cpp:238]     Train net output #0: loss = 0.0096204 (* 1 = 0.0096204 loss)
I0621 00:25:25.331648 32183 sgd_solver.cpp:105] Iteration 4050, lr = 0.01
I0621 00:26:36.191571 32183 solver.cpp:219] Iteration 4100 (0.705624 iter/s, 70.8593s/50 iters), loss = 0.00960512
I0621 00:26:36.191776 32183 solver.cpp:238]     Train net output #0: loss = 0.0043069 (* 1 = 0.0043069 loss)
I0621 00:26:36.191802 32183 sgd_solver.cpp:105] Iteration 4100, lr = 0.01
I0621 00:27:47.047628 32183 solver.cpp:219] Iteration 4150 (0.705665 iter/s, 70.8552s/50 iters), loss = 0.00796283
I0621 00:27:47.047940 32183 solver.cpp:238]     Train net output #0: loss = 0.00875677 (* 1 = 0.00875677 loss)
I0621 00:27:47.047967 32183 sgd_solver.cpp:105] Iteration 4150, lr = 0.01
I0621 00:28:57.892320 32183 solver.cpp:219] Iteration 4200 (0.705779 iter/s, 70.8437s/50 iters), loss = 0.00869012
I0621 00:28:57.892527 32183 solver.cpp:238]     Train net output #0: loss = 0.00394813 (* 1 = 0.00394813 loss)
I0621 00:28:57.892554 32183 sgd_solver.cpp:105] Iteration 4200, lr = 0.01
I0621 00:30:08.746541 32183 solver.cpp:219] Iteration 4250 (0.705683 iter/s, 70.8534s/50 iters), loss = 0.00775832
I0621 00:30:08.746744 32183 solver.cpp:238]     Train net output #0: loss = 0.00685847 (* 1 = 0.00685847 loss)
I0621 00:30:08.746772 32183 sgd_solver.cpp:105] Iteration 4250, lr = 0.01
I0621 00:31:19.608811 32183 solver.cpp:219] Iteration 4300 (0.705603 iter/s, 70.8613s/50 iters), loss = 0.0074023
I0621 00:31:19.609019 32183 solver.cpp:238]     Train net output #0: loss = 0.00432922 (* 1 = 0.00432922 loss)
I0621 00:31:19.609045 32183 sgd_solver.cpp:105] Iteration 4300, lr = 0.01
I0621 00:32:30.462270 32183 solver.cpp:219] Iteration 4350 (0.705691 iter/s, 70.8525s/50 iters), loss = 0.00674497
I0621 00:32:30.462473 32183 solver.cpp:238]     Train net output #0: loss = 0.0018536 (* 1 = 0.0018536 loss)
I0621 00:32:30.462501 32183 sgd_solver.cpp:105] Iteration 4350, lr = 0.01
I0621 00:33:41.290294 32183 solver.cpp:219] Iteration 4400 (0.705945 iter/s, 70.8271s/50 iters), loss = 0.00593968
I0621 00:33:41.290505 32183 solver.cpp:238]     Train net output #0: loss = 0.00446491 (* 1 = 0.00446491 loss)
I0621 00:33:41.290539 32183 sgd_solver.cpp:105] Iteration 4400, lr = 0.01
I0621 00:34:52.121428 32183 solver.cpp:219] Iteration 4450 (0.705914 iter/s, 70.8302s/50 iters), loss = 0.00858937
I0621 00:34:52.121675 32183 solver.cpp:238]     Train net output #0: loss = 0.00691989 (* 1 = 0.00691989 loss)
I0621 00:34:52.121702 32183 sgd_solver.cpp:105] Iteration 4450, lr = 0.01
I0621 00:36:01.550395 32183 solver.cpp:331] Iteration 4500, Testing net (#0)
I0621 00:36:16.380136 32183 solver.cpp:398]     Test net output #0: accuracy = 0.946775
I0621 00:36:16.380230 32183 solver.cpp:398]     Test net output #1: loss = 0.223074 (* 1 = 0.223074 loss)
I0621 00:36:17.793794 32183 solver.cpp:219] Iteration 4500 (0.583627 iter/s, 85.6712s/50 iters), loss = 0.0074632
I0621 00:36:17.793928 32183 solver.cpp:238]     Train net output #0: loss = 0.00391756 (* 1 = 0.00391756 loss)
I0621 00:36:17.793954 32183 sgd_solver.cpp:105] Iteration 4500, lr = 0.01
I0621 00:37:28.640949 32183 solver.cpp:219] Iteration 4550 (0.705753 iter/s, 70.8463s/50 iters), loss = 0.0100676
I0621 00:37:28.641286 32183 solver.cpp:238]     Train net output #0: loss = 0.00654068 (* 1 = 0.00654068 loss)
I0621 00:37:28.641314 32183 sgd_solver.cpp:105] Iteration 4550, lr = 0.01
I0621 00:38:39.487128 32183 solver.cpp:219] Iteration 4600 (0.705765 iter/s, 70.8451s/50 iters), loss = 0.00781563
I0621 00:38:39.487268 32183 solver.cpp:238]     Train net output #0: loss = 0.00577287 (* 1 = 0.00577287 loss)
I0621 00:38:39.487294 32183 sgd_solver.cpp:105] Iteration 4600, lr = 0.01
I0621 00:39:50.339970 32183 solver.cpp:219] Iteration 4650 (0.705697 iter/s, 70.852s/50 iters), loss = 0.0114948
I0621 00:39:50.340100 32183 solver.cpp:238]     Train net output #0: loss = 0.00384599 (* 1 = 0.00384599 loss)
I0621 00:39:50.340126 32183 sgd_solver.cpp:105] Iteration 4650, lr = 0.01
I0621 00:41:01.183230 32183 solver.cpp:219] Iteration 4700 (0.705792 iter/s, 70.8424s/50 iters), loss = 0.00902812
I0621 00:41:01.183375 32183 solver.cpp:238]     Train net output #0: loss = 0.0118799 (* 1 = 0.0118799 loss)
I0621 00:41:01.183401 32183 sgd_solver.cpp:105] Iteration 4700, lr = 0.01
I0621 00:42:12.037046 32183 solver.cpp:219] Iteration 4750 (0.705687 iter/s, 70.8529s/50 iters), loss = 0.00726058
I0621 00:42:12.037251 32183 solver.cpp:238]     Train net output #0: loss = 0.00863853 (* 1 = 0.00863853 loss)
I0621 00:42:12.037277 32183 sgd_solver.cpp:105] Iteration 4750, lr = 0.01
I0621 00:43:22.874866 32183 solver.cpp:219] Iteration 4800 (0.705847 iter/s, 70.8369s/50 iters), loss = 0.0071841
I0621 00:43:22.875041 32183 solver.cpp:238]     Train net output #0: loss = 0.00411344 (* 1 = 0.00411344 loss)
I0621 00:43:22.875067 32183 sgd_solver.cpp:105] Iteration 4800, lr = 0.01
I0621 00:44:33.694085 32183 solver.cpp:219] Iteration 4850 (0.706032 iter/s, 70.8183s/50 iters), loss = 0.00666846
I0621 00:44:33.694313 32183 solver.cpp:238]     Train net output #0: loss = 0.00302813 (* 1 = 0.00302813 loss)
I0621 00:44:33.694341 32183 sgd_solver.cpp:105] Iteration 4850, lr = 0.01
I0621 00:45:44.553318 32183 solver.cpp:219] Iteration 4900 (0.705634 iter/s, 70.8583s/50 iters), loss = 0.00808008
I0621 00:45:44.553519 32183 solver.cpp:238]     Train net output #0: loss = 0.0168651 (* 1 = 0.0168651 loss)
I0621 00:45:44.553549 32183 sgd_solver.cpp:105] Iteration 4900, lr = 0.01
I0621 00:46:55.419173 32183 solver.cpp:219] Iteration 4950 (0.705568 iter/s, 70.8649s/50 iters), loss = 0.00630175
I0621 00:46:55.419379 32183 solver.cpp:238]     Train net output #0: loss = 0.00365349 (* 1 = 0.00365349 loss)
I0621 00:46:55.419406 32183 sgd_solver.cpp:105] Iteration 4950, lr = 0.01
I0621 00:48:04.850304 32183 solver.cpp:331] Iteration 5000, Testing net (#0)
I0621 00:48:19.699270 32183 solver.cpp:398]     Test net output #0: accuracy = 0.942742
I0621 00:48:19.699357 32183 solver.cpp:398]     Test net output #1: loss = 0.251267 (* 1 = 0.251267 loss)
I0621 00:48:19.706818 32183 compress_conv_layer.cu:174] 0.574852 1.50351e-10 0.772888
I0621 00:48:19.715561 32183 compress_conv_layer.cu:174] 0.574852 9.17012e-11 0.451695
I0621 00:48:19.723999 32183 compress_conv_layer.cu:174] 0.574852 1.64753e-11 0.605855
I0621 00:48:19.732429 32183 compress_conv_layer.cu:174] 0.574852 2.50945e-12 0.638993
I0621 00:48:19.745565 32183 compress_conv_layer.cu:174] 0.574852 8.01415e-12 0.373224
I0621 00:48:19.768120 32183 compress_conv_layer.cu:174] 0.574852 7.68771e-14 0.395013
I0621 00:48:19.813428 32183 compress_conv_layer.cu:174] 0.574852 1.39634e-13 0.386596
I0621 00:48:19.857369 32183 compress_conv_layer.cu:174] 0.574852 1.77799e-12 0.329847
I0621 00:48:19.903870 32183 compress_conv_layer.cu:174] 0.574852 1.54519e-12 0.351429
I0621 00:48:19.949089 32183 compress_conv_layer.cu:174] 0.574852 1.62411e-12 0.468931
I0621 00:48:19.993693 32183 compress_conv_layer.cu:174] 0.574852 4.47278e-12 0.372331
I0621 00:48:20.086474 32183 compress_conv_layer.cu:174] 0.574852 1.33781e-12 0.266879
I0621 00:48:20.277009 32183 compress_conv_layer.cu:174] 0.574852 2.75567e-12 0.238508
I0621 00:48:20.300954 32183 compress_conv_layer.cu:174] 0.574852 2.56245e-07 0.166382
I0621 00:48:20.539820 32183 compress_conv_layer.cu:174] 0.574852 1.50351e-10 0.772888
I0621 00:48:20.547857 32183 compress_conv_layer.cu:174] 0.574852 9.17012e-11 0.451695
I0621 00:48:20.556210 32183 compress_conv_layer.cu:174] 0.574852 1.64753e-11 0.605855
I0621 00:48:20.564452 32183 compress_conv_layer.cu:174] 0.574852 2.50945e-12 0.638993
I0621 00:48:20.577271 32183 compress_conv_layer.cu:174] 0.574852 8.01415e-12 0.373224
I0621 00:48:20.599484 32183 compress_conv_layer.cu:174] 0.574852 7.68771e-14 0.395013
I0621 00:48:20.644389 32183 compress_conv_layer.cu:174] 0.574852 1.39634e-13 0.386596
I0621 00:48:20.688047 32183 compress_conv_layer.cu:174] 0.574852 1.77799e-12 0.329847
I0621 00:48:20.731986 32183 compress_conv_layer.cu:174] 0.574852 1.54519e-12 0.351429
I0621 00:48:20.775984 32183 compress_conv_layer.cu:174] 0.574852 1.62411e-12 0.468931
I0621 00:48:20.819813 32183 compress_conv_layer.cu:174] 0.574852 4.47278e-12 0.372331
I0621 00:48:20.911259 32183 compress_conv_layer.cu:174] 0.574852 1.33781e-12 0.266879
I0621 00:48:21.101583 32183 compress_conv_layer.cu:174] 0.574852 2.75567e-12 0.238508
I0621 00:48:21.125840 32183 compress_conv_layer.cu:174] 0.574852 2.56245e-07 0.166382
I0621 00:48:21.364766 32183 compress_conv_layer.cu:174] 0.574852 1.50351e-10 0.772888
I0621 00:48:21.372854 32183 compress_conv_layer.cu:174] 0.574852 9.17012e-11 0.451695
I0621 00:48:21.381346 32183 compress_conv_layer.cu:174] 0.574852 1.64753e-11 0.605855
I0621 00:48:21.389746 32183 compress_conv_layer.cu:174] 0.574852 2.50945e-12 0.638993
I0621 00:48:21.402582 32183 compress_conv_layer.cu:174] 0.574852 8.01415e-12 0.373224
I0621 00:48:21.424727 32183 compress_conv_layer.cu:174] 0.574852 7.68771e-14 0.395013
I0621 00:48:21.469864 32183 compress_conv_layer.cu:174] 0.574852 1.39634e-13 0.386596
I0621 00:48:21.513365 32183 compress_conv_layer.cu:174] 0.574852 1.77799e-12 0.329847
I0621 00:48:21.557160 32183 compress_conv_layer.cu:174] 0.574852 1.54519e-12 0.351429
I0621 00:48:21.600695 32183 compress_conv_layer.cu:174] 0.574852 1.62411e-12 0.468931
I0621 00:48:21.644341 32183 compress_conv_layer.cu:174] 0.574852 4.47278e-12 0.372331
I0621 00:48:21.735080 32183 compress_conv_layer.cu:174] 0.574852 1.33781e-12 0.266879
I0621 00:48:21.927070 32183 compress_conv_layer.cu:174] 0.574852 2.75567e-12 0.238508
I0621 00:48:21.952466 32183 compress_conv_layer.cu:174] 0.574852 2.56245e-07 0.166382
I0621 00:48:22.191567 32183 compress_conv_layer.cu:174] 0.574852 1.50351e-10 0.772888
I0621 00:48:22.199623 32183 compress_conv_layer.cu:174] 0.574852 9.17012e-11 0.451695
I0621 00:48:22.207999 32183 compress_conv_layer.cu:174] 0.574852 1.64753e-11 0.605855
I0621 00:48:22.216377 32183 compress_conv_layer.cu:174] 0.574852 2.50945e-12 0.638993
I0621 00:48:22.229173 32183 compress_conv_layer.cu:174] 0.574852 8.01415e-12 0.373224
I0621 00:48:22.251329 32183 compress_conv_layer.cu:174] 0.574852 7.68771e-14 0.395013
I0621 00:48:22.296296 32183 compress_conv_layer.cu:174] 0.574852 1.39634e-13 0.386596
I0621 00:48:22.339843 32183 compress_conv_layer.cu:174] 0.574852 1.77799e-12 0.329847
I0621 00:48:22.383610 32183 compress_conv_layer.cu:174] 0.574852 1.54519e-12 0.351429
I0621 00:48:22.427181 32183 compress_conv_layer.cu:174] 0.574852 1.62411e-12 0.468931
I0621 00:48:22.471104 32183 compress_conv_layer.cu:174] 0.574852 4.47278e-12 0.372331
I0621 00:48:22.561363 32183 compress_conv_layer.cu:174] 0.574852 1.33781e-12 0.266879
I0621 00:48:22.752094 32183 compress_conv_layer.cu:174] 0.574852 2.75567e-12 0.238508
I0621 00:48:22.776127 32183 compress_conv_layer.cu:174] 0.574852 2.56245e-07 0.166382
I0621 00:48:23.014922 32183 compress_conv_layer.cu:174] 0.574852 1.50351e-10 0.772888
I0621 00:48:23.022965 32183 compress_conv_layer.cu:174] 0.574852 9.17012e-11 0.451695
I0621 00:48:23.031335 32183 compress_conv_layer.cu:174] 0.574852 1.64753e-11 0.605855
I0621 00:48:23.039633 32183 compress_conv_layer.cu:174] 0.574852 2.50945e-12 0.638993
I0621 00:48:23.052511 32183 compress_conv_layer.cu:174] 0.574852 8.01415e-12 0.373224
I0621 00:48:23.075559 32183 compress_conv_layer.cu:174] 0.574852 7.68771e-14 0.395013
I0621 00:48:23.120579 32183 compress_conv_layer.cu:174] 0.574852 1.39634e-13 0.386596
I0621 00:48:23.164237 32183 compress_conv_layer.cu:174] 0.574852 1.77799e-12 0.329847
I0621 00:48:23.208535 32183 compress_conv_layer.cu:174] 0.574852 1.54519e-12 0.351429
I0621 00:48:23.272653 32183 compress_conv_layer.cu:174] 0.574852 1.62411e-12 0.468931
I0621 00:48:23.316746 32183 compress_conv_layer.cu:174] 0.574852 4.47278e-12 0.372331
I0621 00:48:23.408447 32183 compress_conv_layer.cu:174] 0.574852 1.33781e-12 0.266879
I0621 00:48:23.600692 32183 compress_conv_layer.cu:174] 0.574852 2.75567e-12 0.238508
I0621 00:48:23.624755 32183 compress_conv_layer.cu:174] 0.574852 2.56245e-07 0.166382
I0621 00:48:23.856475 32183 solver.cpp:219] Iteration 5000 (0.565379 iter/s, 88.4362s/50 iters), loss = 0.0103927
I0621 00:48:23.856590 32183 solver.cpp:238]     Train net output #0: loss = 0.00846071 (* 1 = 0.00846071 loss)
I0621 00:48:23.856619 32183 sgd_solver.cpp:105] Iteration 5000, lr = 0.01
I0621 00:49:34.694077 32183 solver.cpp:219] Iteration 5050 (0.705848 iter/s, 70.8368s/50 iters), loss = 0.0115873
I0621 00:49:34.694244 32183 solver.cpp:238]     Train net output #0: loss = 0.0179651 (* 1 = 0.0179651 loss)
I0621 00:49:34.694272 32183 sgd_solver.cpp:105] Iteration 5050, lr = 0.01
I0621 00:50:45.551831 32183 solver.cpp:219] Iteration 5100 (0.705648 iter/s, 70.8569s/50 iters), loss = 0.00506491
I0621 00:50:45.552044 32183 solver.cpp:238]     Train net output #0: loss = 0.00354204 (* 1 = 0.00354204 loss)
I0621 00:50:45.552076 32183 sgd_solver.cpp:105] Iteration 5100, lr = 0.01
I0621 00:51:56.394188 32183 solver.cpp:219] Iteration 5150 (0.705802 iter/s, 70.8414s/50 iters), loss = 0.0039655
I0621 00:51:56.394374 32183 solver.cpp:238]     Train net output #0: loss = 0.00328126 (* 1 = 0.00328126 loss)
I0621 00:51:56.394402 32183 sgd_solver.cpp:105] Iteration 5150, lr = 0.01
I0621 00:53:07.242033 32183 solver.cpp:219] Iteration 5200 (0.705747 iter/s, 70.847s/50 iters), loss = 0.00618279
I0621 00:53:07.242235 32183 solver.cpp:238]     Train net output #0: loss = 0.00331097 (* 1 = 0.00331097 loss)
I0621 00:53:07.242262 32183 sgd_solver.cpp:105] Iteration 5200, lr = 0.01
I0621 00:54:18.091353 32183 solver.cpp:219] Iteration 5250 (0.705732 iter/s, 70.8484s/50 iters), loss = 0.0060681
I0621 00:54:18.091511 32183 solver.cpp:238]     Train net output #0: loss = 0.00323707 (* 1 = 0.00323707 loss)
I0621 00:54:18.091545 32183 sgd_solver.cpp:105] Iteration 5250, lr = 0.01
I0621 00:55:28.949812 32183 solver.cpp:219] Iteration 5300 (0.705641 iter/s, 70.8576s/50 iters), loss = 0.00574172
I0621 00:55:28.949972 32183 solver.cpp:238]     Train net output #0: loss = 0.00607474 (* 1 = 0.00607474 loss)
I0621 00:55:28.950012 32183 sgd_solver.cpp:105] Iteration 5300, lr = 0.01
I0621 00:56:39.791488 32183 solver.cpp:219] Iteration 5350 (0.705808 iter/s, 70.8408s/50 iters), loss = 0.00893636
I0621 00:56:39.791643 32183 solver.cpp:238]     Train net output #0: loss = 0.0125077 (* 1 = 0.0125077 loss)
I0621 00:56:39.791676 32183 sgd_solver.cpp:105] Iteration 5350, lr = 0.01
I0621 00:57:50.637136 32183 solver.cpp:219] Iteration 5400 (0.705768 iter/s, 70.8448s/50 iters), loss = 0.00773751
I0621 00:57:50.637358 32183 solver.cpp:238]     Train net output #0: loss = 0.0041594 (* 1 = 0.0041594 loss)
I0621 00:57:50.637387 32183 sgd_solver.cpp:105] Iteration 5400, lr = 0.01
I0621 00:59:01.478566 32183 solver.cpp:219] Iteration 5450 (0.705811 iter/s, 70.8405s/50 iters), loss = 0.00711132
I0621 00:59:01.478763 32183 solver.cpp:238]     Train net output #0: loss = 0.00677744 (* 1 = 0.00677744 loss)
I0621 00:59:01.478790 32183 sgd_solver.cpp:105] Iteration 5450, lr = 0.01
I0621 01:00:10.891465 32183 solver.cpp:331] Iteration 5500, Testing net (#0)
I0621 01:00:25.687495 32183 solver.cpp:398]     Test net output #0: accuracy = 0.95
I0621 01:00:25.687594 32183 solver.cpp:398]     Test net output #1: loss = 0.220131 (* 1 = 0.220131 loss)
I0621 01:00:27.098618 32183 solver.cpp:219] Iteration 5500 (0.583982 iter/s, 85.619s/50 iters), loss = 0.00740333
I0621 01:00:27.098762 32183 solver.cpp:238]     Train net output #0: loss = 0.0096917 (* 1 = 0.0096917 loss)
I0621 01:00:27.098796 32183 sgd_solver.cpp:105] Iteration 5500, lr = 0.01
I0621 01:01:37.948695 32183 solver.cpp:219] Iteration 5550 (0.705724 iter/s, 70.8492s/50 iters), loss = 0.00982216
I0621 01:01:37.948844 32183 solver.cpp:238]     Train net output #0: loss = 0.0105869 (* 1 = 0.0105869 loss)
I0621 01:01:37.948869 32183 sgd_solver.cpp:105] Iteration 5550, lr = 0.01
I0621 01:02:48.812955 32183 solver.cpp:219] Iteration 5600 (0.705583 iter/s, 70.8634s/50 iters), loss = 0.00879723
I0621 01:02:48.813097 32183 solver.cpp:238]     Train net output #0: loss = 0.00706659 (* 1 = 0.00706659 loss)
I0621 01:02:48.813123 32183 sgd_solver.cpp:105] Iteration 5600, lr = 0.01
I0621 01:03:59.673115 32183 solver.cpp:219] Iteration 5650 (0.705624 iter/s, 70.8593s/50 iters), loss = 0.00908022
I0621 01:03:59.673290 32183 solver.cpp:238]     Train net output #0: loss = 0.00983347 (* 1 = 0.00983347 loss)
I0621 01:03:59.673316 32183 sgd_solver.cpp:105] Iteration 5650, lr = 0.01
I0621 01:05:10.506297 32183 solver.cpp:219] Iteration 5700 (0.705894 iter/s, 70.8322s/50 iters), loss = 0.00578419
I0621 01:05:10.506527 32183 solver.cpp:238]     Train net output #0: loss = 0.00609778 (* 1 = 0.00609778 loss)
I0621 01:05:10.506557 32183 sgd_solver.cpp:105] Iteration 5700, lr = 0.01
I0621 01:06:21.336150 32183 solver.cpp:219] Iteration 5750 (0.705927 iter/s, 70.8288s/50 iters), loss = 0.00560708
I0621 01:06:21.336299 32183 solver.cpp:238]     Train net output #0: loss = 0.00408015 (* 1 = 0.00408015 loss)
I0621 01:06:21.336334 32183 sgd_solver.cpp:105] Iteration 5750, lr = 0.01
I0621 01:07:32.180496 32183 solver.cpp:219] Iteration 5800 (0.705782 iter/s, 70.8434s/50 iters), loss = 0.00829426
I0621 01:07:32.180721 32183 solver.cpp:238]     Train net output #0: loss = 0.00547991 (* 1 = 0.00547991 loss)
I0621 01:07:32.180754 32183 sgd_solver.cpp:105] Iteration 5800, lr = 0.01
I0621 01:08:43.026757 32183 solver.cpp:219] Iteration 5850 (0.705764 iter/s, 70.8452s/50 iters), loss = 0.00952437
I0621 01:08:43.026947 32183 solver.cpp:238]     Train net output #0: loss = 0.0043269 (* 1 = 0.0043269 loss)
I0621 01:08:43.026974 32183 sgd_solver.cpp:105] Iteration 5850, lr = 0.01
I0621 01:09:53.875442 32183 solver.cpp:219] Iteration 5900 (0.705739 iter/s, 70.8477s/50 iters), loss = 0.0124191
I0621 01:09:53.875772 32183 solver.cpp:238]     Train net output #0: loss = 0.0108759 (* 1 = 0.0108759 loss)
I0621 01:09:53.875800 32183 sgd_solver.cpp:105] Iteration 5900, lr = 0.01
I0621 01:11:04.709547 32183 solver.cpp:219] Iteration 5950 (0.705886 iter/s, 70.833s/50 iters), loss = 0.0080843
I0621 01:11:04.709718 32183 solver.cpp:238]     Train net output #0: loss = 0.00579923 (* 1 = 0.00579923 loss)
I0621 01:11:04.709745 32183 sgd_solver.cpp:105] Iteration 5950, lr = 0.01
I0621 01:12:14.141881 32183 solver.cpp:331] Iteration 6000, Testing net (#0)
I0621 01:12:29.025754 32183 solver.cpp:398]     Test net output #0: accuracy = 0.937097
I0621 01:12:29.025838 32183 solver.cpp:398]     Test net output #1: loss = 0.278871 (* 1 = 0.278871 loss)
I0621 01:12:29.033939 32183 compress_conv_layer.cu:174] 0.614299 1.43015e-10 0.735472
I0621 01:12:29.042038 32183 compress_conv_layer.cu:174] 0.614299 8.72268e-11 0.429565
I0621 01:12:29.050552 32183 compress_conv_layer.cu:174] 0.614299 1.56714e-11 0.576326
I0621 01:12:29.059018 32183 compress_conv_layer.cu:174] 0.614299 2.38701e-12 0.608052
I0621 01:12:29.072399 32183 compress_conv_layer.cu:174] 0.614299 7.62311e-12 0.355705
I0621 01:12:29.095508 32183 compress_conv_layer.cu:174] 0.614299 7.3126e-14 0.375181
I0621 01:12:29.141293 32183 compress_conv_layer.cu:174] 0.614299 1.3282e-13 0.367095
I0621 01:12:29.185636 32183 compress_conv_layer.cu:174] 0.614299 1.69124e-12 0.313644
I0621 01:12:29.231012 32183 compress_conv_layer.cu:174] 0.614299 1.46979e-12 0.33423
I0621 01:12:29.275413 32183 compress_conv_layer.cu:174] 0.614299 1.54486e-12 0.445369
I0621 01:12:29.319695 32183 compress_conv_layer.cu:174] 0.614299 4.25454e-12 0.354112
I0621 01:12:29.411461 32183 compress_conv_layer.cu:174] 0.614299 1.27253e-12 0.253397
I0621 01:12:29.603838 32183 compress_conv_layer.cu:174] 0.614299 2.62121e-12 0.22683
I0621 01:12:29.628602 32183 compress_conv_layer.cu:174] 0.614299 2.43742e-07 0.167002
I0621 01:12:29.867004 32183 compress_conv_layer.cu:174] 0.614299 1.43015e-10 0.735472
I0621 01:12:29.875005 32183 compress_conv_layer.cu:174] 0.614299 8.72268e-11 0.429565
I0621 01:12:29.883240 32183 compress_conv_layer.cu:174] 0.614299 1.56714e-11 0.576326
I0621 01:12:29.891413 32183 compress_conv_layer.cu:174] 0.614299 2.38701e-12 0.608052
I0621 01:12:29.904008 32183 compress_conv_layer.cu:174] 0.614299 7.62311e-12 0.355705
I0621 01:12:29.925937 32183 compress_conv_layer.cu:174] 0.614299 7.3126e-14 0.375181
I0621 01:12:29.970352 32183 compress_conv_layer.cu:174] 0.614299 1.3282e-13 0.367095
I0621 01:12:30.013705 32183 compress_conv_layer.cu:174] 0.614299 1.69124e-12 0.313644
I0621 01:12:30.057837 32183 compress_conv_layer.cu:174] 0.614299 1.46979e-12 0.33423
I0621 01:12:30.101315 32183 compress_conv_layer.cu:174] 0.614299 1.54486e-12 0.445369
I0621 01:12:30.144978 32183 compress_conv_layer.cu:174] 0.614299 4.25454e-12 0.354112
I0621 01:12:30.235322 32183 compress_conv_layer.cu:174] 0.614299 1.27253e-12 0.253397
I0621 01:12:30.425294 32183 compress_conv_layer.cu:174] 0.614299 2.62121e-12 0.22683
I0621 01:12:30.450223 32183 compress_conv_layer.cu:174] 0.614299 2.43742e-07 0.167002
I0621 01:12:30.688729 32183 compress_conv_layer.cu:174] 0.614299 1.43015e-10 0.735472
I0621 01:12:30.696730 32183 compress_conv_layer.cu:174] 0.614299 8.72268e-11 0.429565
I0621 01:12:30.704952 32183 compress_conv_layer.cu:174] 0.614299 1.56714e-11 0.576326
I0621 01:12:30.713042 32183 compress_conv_layer.cu:174] 0.614299 2.38701e-12 0.608052
I0621 01:12:30.725615 32183 compress_conv_layer.cu:174] 0.614299 7.62311e-12 0.355705
I0621 01:12:30.747793 32183 compress_conv_layer.cu:174] 0.614299 7.3126e-14 0.375181
I0621 01:12:30.792279 32183 compress_conv_layer.cu:174] 0.614299 1.3282e-13 0.367095
I0621 01:12:30.835783 32183 compress_conv_layer.cu:174] 0.614299 1.69124e-12 0.313644
I0621 01:12:30.879962 32183 compress_conv_layer.cu:174] 0.614299 1.46979e-12 0.33423
I0621 01:12:30.923741 32183 compress_conv_layer.cu:174] 0.614299 1.54486e-12 0.445369
I0621 01:12:30.967149 32183 compress_conv_layer.cu:174] 0.614299 4.25454e-12 0.354112
I0621 01:12:31.057617 32183 compress_conv_layer.cu:174] 0.614299 1.27253e-12 0.253397
I0621 01:12:31.247665 32183 compress_conv_layer.cu:174] 0.614299 2.62121e-12 0.22683
I0621 01:12:31.270968 32183 compress_conv_layer.cu:174] 0.614299 2.43742e-07 0.167002
I0621 01:12:31.508635 32183 compress_conv_layer.cu:174] 0.614299 1.43015e-10 0.735472
I0621 01:12:31.517019 32183 compress_conv_layer.cu:174] 0.614299 8.72268e-11 0.429565
I0621 01:12:31.525329 32183 compress_conv_layer.cu:174] 0.614299 1.56714e-11 0.576326
I0621 01:12:31.533540 32183 compress_conv_layer.cu:174] 0.614299 2.38701e-12 0.608052
I0621 01:12:31.546165 32183 compress_conv_layer.cu:174] 0.614299 7.62311e-12 0.355705
I0621 01:12:31.567800 32183 compress_conv_layer.cu:174] 0.614299 7.3126e-14 0.375181
I0621 01:12:31.612833 32183 compress_conv_layer.cu:174] 0.614299 1.3282e-13 0.367095
I0621 01:12:31.656509 32183 compress_conv_layer.cu:174] 0.614299 1.69124e-12 0.313644
I0621 01:12:31.700984 32183 compress_conv_layer.cu:174] 0.614299 1.46979e-12 0.33423
I0621 01:12:31.744951 32183 compress_conv_layer.cu:174] 0.614299 1.54486e-12 0.445369
I0621 01:12:31.788796 32183 compress_conv_layer.cu:174] 0.614299 4.25454e-12 0.354112
I0621 01:12:31.879000 32183 compress_conv_layer.cu:174] 0.614299 1.27253e-12 0.253397
I0621 01:12:32.071077 32183 compress_conv_layer.cu:174] 0.614299 2.62121e-12 0.22683
I0621 01:12:32.095784 32183 compress_conv_layer.cu:174] 0.614299 2.43742e-07 0.167002
I0621 01:12:32.333546 32183 compress_conv_layer.cu:174] 0.614299 1.43015e-10 0.735472
I0621 01:12:32.341912 32183 compress_conv_layer.cu:174] 0.614299 8.72268e-11 0.429565
I0621 01:12:32.350142 32183 compress_conv_layer.cu:174] 0.614299 1.56714e-11 0.576326
I0621 01:12:32.358266 32183 compress_conv_layer.cu:174] 0.614299 2.38701e-12 0.608052
I0621 01:12:32.371063 32183 compress_conv_layer.cu:174] 0.614299 7.62311e-12 0.355705
I0621 01:12:32.392855 32183 compress_conv_layer.cu:174] 0.614299 7.3126e-14 0.375181
I0621 01:12:32.437613 32183 compress_conv_layer.cu:174] 0.614299 1.3282e-13 0.367095
I0621 01:12:32.481334 32183 compress_conv_layer.cu:174] 0.614299 1.69124e-12 0.313644
I0621 01:12:32.525075 32183 compress_conv_layer.cu:174] 0.614299 1.46979e-12 0.33423
I0621 01:12:32.568634 32183 compress_conv_layer.cu:174] 0.614299 1.54486e-12 0.445369
I0621 01:12:32.612556 32183 compress_conv_layer.cu:174] 0.614299 4.25454e-12 0.354112
I0621 01:12:32.702818 32183 compress_conv_layer.cu:174] 0.614299 1.27253e-12 0.253397
I0621 01:12:32.890262 32183 compress_conv_layer.cu:174] 0.614299 2.62121e-12 0.22683
I0621 01:12:32.913795 32183 compress_conv_layer.cu:174] 0.614299 2.43742e-07 0.167002
I0621 01:12:33.144284 32183 solver.cpp:219] Iteration 6000 (0.565396 iter/s, 88.4336s/50 iters), loss = 0.0143561
I0621 01:12:33.144397 32183 solver.cpp:238]     Train net output #0: loss = 0.0178695 (* 1 = 0.0178695 loss)
I0621 01:12:33.144420 32183 sgd_solver.cpp:105] Iteration 6000, lr = 0.01
I0621 01:13:43.951630 32183 solver.cpp:219] Iteration 6050 (0.706151 iter/s, 70.8064s/50 iters), loss = 0.0106007
I0621 01:13:43.951882 32183 solver.cpp:238]     Train net output #0: loss = 0.0076437 (* 1 = 0.0076437 loss)
I0621 01:13:43.951908 32183 sgd_solver.cpp:105] Iteration 6050, lr = 0.01
I0621 01:14:54.772027 32183 solver.cpp:219] Iteration 6100 (0.706022 iter/s, 70.8194s/50 iters), loss = 0.0158086
I0621 01:14:54.772224 32183 solver.cpp:238]     Train net output #0: loss = 0.0331718 (* 1 = 0.0331718 loss)
I0621 01:14:54.772260 32183 sgd_solver.cpp:105] Iteration 6100, lr = 0.01
I0621 01:16:05.632571 32183 solver.cpp:219] Iteration 6150 (0.705621 iter/s, 70.8596s/50 iters), loss = 0.0119059
I0621 01:16:05.632738 32183 solver.cpp:238]     Train net output #0: loss = 0.00863477 (* 1 = 0.00863477 loss)
I0621 01:16:05.632766 32183 sgd_solver.cpp:105] Iteration 6150, lr = 0.01
I0621 01:17:16.481948 32183 solver.cpp:219] Iteration 6200 (0.705732 iter/s, 70.8484s/50 iters), loss = 0.01252
I0621 01:17:16.482205 32183 solver.cpp:238]     Train net output #0: loss = 0.0172662 (* 1 = 0.0172662 loss)
I0621 01:17:16.482233 32183 sgd_solver.cpp:105] Iteration 6200, lr = 0.01
I0621 01:18:27.329196 32183 solver.cpp:219] Iteration 6250 (0.705754 iter/s, 70.8462s/50 iters), loss = 0.0118228
I0621 01:18:27.329399 32183 solver.cpp:238]     Train net output #0: loss = 0.030494 (* 1 = 0.030494 loss)
I0621 01:18:27.329444 32183 sgd_solver.cpp:105] Iteration 6250, lr = 0.01
I0621 01:19:38.170143 32183 solver.cpp:219] Iteration 6300 (0.705817 iter/s, 70.8399s/50 iters), loss = 0.00859184
I0621 01:19:38.170351 32183 solver.cpp:238]     Train net output #0: loss = 0.0082653 (* 1 = 0.0082653 loss)
I0621 01:19:38.170380 32183 sgd_solver.cpp:105] Iteration 6300, lr = 0.01
I0621 01:20:49.005785 32183 solver.cpp:219] Iteration 6350 (0.705869 iter/s, 70.8347s/50 iters), loss = 0.00849052
I0621 01:20:49.005919 32183 solver.cpp:238]     Train net output #0: loss = 0.0091837 (* 1 = 0.0091837 loss)
I0621 01:20:49.005951 32183 sgd_solver.cpp:105] Iteration 6350, lr = 0.01
I0621 01:21:59.841554 32183 solver.cpp:219] Iteration 6400 (0.705867 iter/s, 70.8349s/50 iters), loss = 0.00790076
I0621 01:21:59.841693 32183 solver.cpp:238]     Train net output #0: loss = 0.00628721 (* 1 = 0.00628721 loss)
I0621 01:21:59.841720 32183 sgd_solver.cpp:105] Iteration 6400, lr = 0.01
I0621 01:23:10.694119 32183 solver.cpp:219] Iteration 6450 (0.7057 iter/s, 70.8516s/50 iters), loss = 0.00694888
I0621 01:23:10.694263 32183 solver.cpp:238]     Train net output #0: loss = 0.00300716 (* 1 = 0.00300716 loss)
I0621 01:23:10.694289 32183 sgd_solver.cpp:105] Iteration 6450, lr = 0.01
I0621 01:24:20.132994 32183 solver.cpp:331] Iteration 6500, Testing net (#0)
I0621 01:24:34.896595 32183 solver.cpp:398]     Test net output #0: accuracy = 0.941936
I0621 01:24:34.896679 32183 solver.cpp:398]     Test net output #1: loss = 0.233479 (* 1 = 0.233479 loss)
I0621 01:24:36.307529 32183 solver.cpp:219] Iteration 6500 (0.584028 iter/s, 85.6123s/50 iters), loss = 0.00999181
I0621 01:24:36.307631 32183 solver.cpp:238]     Train net output #0: loss = 0.0117097 (* 1 = 0.0117097 loss)
I0621 01:24:36.307660 32183 sgd_solver.cpp:105] Iteration 6500, lr = 0.01
I0621 01:25:47.142808 32183 solver.cpp:219] Iteration 6550 (0.705872 iter/s, 70.8344s/50 iters), loss = 0.00895399
I0621 01:25:47.143031 32183 solver.cpp:238]     Train net output #0: loss = 0.00559121 (* 1 = 0.00559121 loss)
I0621 01:25:47.143059 32183 sgd_solver.cpp:105] Iteration 6550, lr = 0.01
I0621 01:26:57.980348 32183 solver.cpp:219] Iteration 6600 (0.70585 iter/s, 70.8365s/50 iters), loss = 0.00728616
I0621 01:26:57.980499 32183 solver.cpp:238]     Train net output #0: loss = 0.00653726 (* 1 = 0.00653726 loss)
I0621 01:26:57.980531 32183 sgd_solver.cpp:105] Iteration 6600, lr = 0.01
I0621 01:28:08.826853 32183 solver.cpp:219] Iteration 6650 (0.70576 iter/s, 70.8456s/50 iters), loss = 0.0124862
I0621 01:28:08.827013 32183 solver.cpp:238]     Train net output #0: loss = 0.0100593 (* 1 = 0.0100593 loss)
I0621 01:28:08.827039 32183 sgd_solver.cpp:105] Iteration 6650, lr = 0.01
I0621 01:29:19.661365 32183 solver.cpp:219] Iteration 6700 (0.70588 iter/s, 70.8336s/50 iters), loss = 0.00866443
I0621 01:29:19.661562 32183 solver.cpp:238]     Train net output #0: loss = 0.00726278 (* 1 = 0.00726278 loss)
I0621 01:29:19.661593 32183 sgd_solver.cpp:105] Iteration 6700, lr = 0.01
I0621 01:30:30.503640 32183 solver.cpp:219] Iteration 6750 (0.705803 iter/s, 70.8413s/50 iters), loss = 0.00709225
I0621 01:30:30.503778 32183 solver.cpp:238]     Train net output #0: loss = 0.0121488 (* 1 = 0.0121488 loss)
I0621 01:30:30.503804 32183 sgd_solver.cpp:105] Iteration 6750, lr = 0.01
I0621 01:31:41.364959 32183 solver.cpp:219] Iteration 6800 (0.705613 iter/s, 70.8604s/50 iters), loss = 0.00683798
I0621 01:31:41.365140 32183 solver.cpp:238]     Train net output #0: loss = 0.00393198 (* 1 = 0.00393198 loss)
I0621 01:31:41.365167 32183 sgd_solver.cpp:105] Iteration 6800, lr = 0.01
I0621 01:32:52.216384 32183 solver.cpp:219] Iteration 6850 (0.705712 iter/s, 70.8505s/50 iters), loss = 0.00779328
I0621 01:32:52.216603 32183 solver.cpp:238]     Train net output #0: loss = 0.00926792 (* 1 = 0.00926792 loss)
I0621 01:32:52.216630 32183 sgd_solver.cpp:105] Iteration 6850, lr = 0.01
I0621 01:34:03.055662 32183 solver.cpp:219] Iteration 6900 (0.705833 iter/s, 70.8383s/50 iters), loss = 0.0134648
I0621 01:34:03.055877 32183 solver.cpp:238]     Train net output #0: loss = 0.0098264 (* 1 = 0.0098264 loss)
I0621 01:34:03.055920 32183 sgd_solver.cpp:105] Iteration 6900, lr = 0.01
I0621 01:35:13.895196 32183 solver.cpp:219] Iteration 6950 (0.70583 iter/s, 70.8385s/50 iters), loss = 0.0170245
I0621 01:35:13.895337 32183 solver.cpp:238]     Train net output #0: loss = 0.0357461 (* 1 = 0.0357461 loss)
I0621 01:35:13.895364 32183 sgd_solver.cpp:105] Iteration 6950, lr = 0.01
I0621 01:36:23.337160 32183 solver.cpp:331] Iteration 7000, Testing net (#0)
I0621 01:36:38.202149 32183 solver.cpp:398]     Test net output #0: accuracy = 0.934678
I0621 01:36:38.202244 32183 solver.cpp:398]     Test net output #1: loss = 0.294411 (* 1 = 0.294411 loss)
I0621 01:36:38.210331 32183 compress_conv_layer.cu:174] 0.649094 1.36037e-10 0.699795
I0621 01:36:38.218508 32183 compress_conv_layer.cu:174] 0.649094 8.29707e-11 0.408286
I0621 01:36:38.227272 32183 compress_conv_layer.cu:174] 0.649094 1.49068e-11 0.548781
I0621 01:36:38.236246 32183 compress_conv_layer.cu:174] 0.649094 2.27054e-12 0.578201
I0621 01:36:38.250792 32183 compress_conv_layer.cu:174] 0.649094 7.25116e-12 0.338267
I0621 01:36:38.275609 32183 compress_conv_layer.cu:174] 0.649094 6.95579e-14 0.356781
I0621 01:36:38.320061 32183 compress_conv_layer.cu:174] 0.649094 1.2634e-13 0.348937
I0621 01:36:38.363534 32183 compress_conv_layer.cu:174] 0.649094 1.60872e-12 0.298252
I0621 01:36:38.407361 32183 compress_conv_layer.cu:174] 0.649094 1.39808e-12 0.317903
I0621 01:36:38.450791 32183 compress_conv_layer.cu:174] 0.649094 1.46948e-12 0.423218
I0621 01:36:38.494316 32183 compress_conv_layer.cu:174] 0.649094 4.04695e-12 0.336412
I0621 01:36:38.583904 32183 compress_conv_layer.cu:174] 0.649094 1.21044e-12 0.240569
I0621 01:36:38.770905 32183 compress_conv_layer.cu:174] 0.649094 2.49332e-12 0.215726
I0621 01:36:38.794080 32183 compress_conv_layer.cu:174] 0.649094 2.31849e-07 0.167917
I0621 01:36:39.032251 32183 compress_conv_layer.cu:174] 0.649094 1.36037e-10 0.699795
I0621 01:36:39.040242 32183 compress_conv_layer.cu:174] 0.649094 8.29707e-11 0.408286
I0621 01:36:39.048502 32183 compress_conv_layer.cu:174] 0.649094 1.49068e-11 0.548781
I0621 01:36:39.056634 32183 compress_conv_layer.cu:174] 0.649094 2.27054e-12 0.578201
I0621 01:36:39.069331 32183 compress_conv_layer.cu:174] 0.649094 7.25116e-12 0.338267
I0621 01:36:39.091394 32183 compress_conv_layer.cu:174] 0.649094 6.95579e-14 0.356781
I0621 01:36:39.136504 32183 compress_conv_layer.cu:174] 0.649094 1.2634e-13 0.348937
I0621 01:36:39.179890 32183 compress_conv_layer.cu:174] 0.649094 1.60872e-12 0.298252
I0621 01:36:39.225952 32183 compress_conv_layer.cu:174] 0.649094 1.39808e-12 0.317903
I0621 01:36:39.270198 32183 compress_conv_layer.cu:174] 0.649094 1.46948e-12 0.423218
I0621 01:36:39.314407 32183 compress_conv_layer.cu:174] 0.649094 4.04695e-12 0.336412
I0621 01:36:39.406075 32183 compress_conv_layer.cu:174] 0.649094 1.21044e-12 0.240569
I0621 01:36:39.603322 32183 compress_conv_layer.cu:174] 0.649094 2.49332e-12 0.215726
I0621 01:36:39.629284 32183 compress_conv_layer.cu:174] 0.649094 2.31849e-07 0.167917
I0621 01:36:39.868496 32183 compress_conv_layer.cu:174] 0.649094 1.36037e-10 0.699795
I0621 01:36:39.876613 32183 compress_conv_layer.cu:174] 0.649094 8.29707e-11 0.408286
I0621 01:36:39.885010 32183 compress_conv_layer.cu:174] 0.649094 1.49068e-11 0.548781
I0621 01:36:39.893419 32183 compress_conv_layer.cu:174] 0.649094 2.27054e-12 0.578201
I0621 01:36:39.906366 32183 compress_conv_layer.cu:174] 0.649094 7.25116e-12 0.338267
I0621 01:36:39.928639 32183 compress_conv_layer.cu:174] 0.649094 6.95579e-14 0.356781
I0621 01:36:39.974030 32183 compress_conv_layer.cu:174] 0.649094 1.2634e-13 0.348937
I0621 01:36:40.018070 32183 compress_conv_layer.cu:174] 0.649094 1.60872e-12 0.298252
I0621 01:36:40.063052 32183 compress_conv_layer.cu:174] 0.649094 1.39808e-12 0.317903
I0621 01:36:40.107895 32183 compress_conv_layer.cu:174] 0.649094 1.46948e-12 0.423218
I0621 01:36:40.153578 32183 compress_conv_layer.cu:174] 0.649094 4.04695e-12 0.336412
I0621 01:36:40.248468 32183 compress_conv_layer.cu:174] 0.649094 1.21044e-12 0.240569
I0621 01:36:40.442724 32183 compress_conv_layer.cu:174] 0.649094 2.49332e-12 0.215726
I0621 01:36:40.467269 32183 compress_conv_layer.cu:174] 0.649094 2.31849e-07 0.167917
I0621 01:36:40.706377 32183 compress_conv_layer.cu:174] 0.649094 1.36037e-10 0.699795
I0621 01:36:40.714432 32183 compress_conv_layer.cu:174] 0.649094 8.29707e-11 0.408286
I0621 01:36:40.722750 32183 compress_conv_layer.cu:174] 0.649094 1.49068e-11 0.548781
I0621 01:36:40.730986 32183 compress_conv_layer.cu:174] 0.649094 2.27054e-12 0.578201
I0621 01:36:40.743854 32183 compress_conv_layer.cu:174] 0.649094 7.25116e-12 0.338267
I0621 01:36:40.766103 32183 compress_conv_layer.cu:174] 0.649094 6.95579e-14 0.356781
I0621 01:36:40.810866 32183 compress_conv_layer.cu:174] 0.649094 1.2634e-13 0.348937
I0621 01:36:40.854557 32183 compress_conv_layer.cu:174] 0.649094 1.60872e-12 0.298252
I0621 01:36:40.898681 32183 compress_conv_layer.cu:174] 0.649094 1.39808e-12 0.317903
I0621 01:36:40.942507 32183 compress_conv_layer.cu:174] 0.649094 1.46948e-12 0.423218
I0621 01:36:40.986331 32183 compress_conv_layer.cu:174] 0.649094 4.04695e-12 0.336412
I0621 01:36:41.076954 32183 compress_conv_layer.cu:174] 0.649094 1.21044e-12 0.240569
I0621 01:36:41.266829 32183 compress_conv_layer.cu:174] 0.649094 2.49332e-12 0.215726
I0621 01:36:41.290498 32183 compress_conv_layer.cu:174] 0.649094 2.31849e-07 0.167917
I0621 01:36:41.529444 32183 compress_conv_layer.cu:174] 0.649094 1.36037e-10 0.699795
I0621 01:36:41.537526 32183 compress_conv_layer.cu:174] 0.649094 8.29707e-11 0.408286
I0621 01:36:41.545895 32183 compress_conv_layer.cu:174] 0.649094 1.49068e-11 0.548781
I0621 01:36:41.554178 32183 compress_conv_layer.cu:174] 0.649094 2.27054e-12 0.578201
I0621 01:36:41.567071 32183 compress_conv_layer.cu:174] 0.649094 7.25116e-12 0.338267
I0621 01:36:41.589305 32183 compress_conv_layer.cu:174] 0.649094 6.95579e-14 0.356781
I0621 01:36:41.633779 32183 compress_conv_layer.cu:174] 0.649094 1.2634e-13 0.348937
I0621 01:36:41.677726 32183 compress_conv_layer.cu:174] 0.649094 1.60872e-12 0.298252
I0621 01:36:41.722290 32183 compress_conv_layer.cu:174] 0.649094 1.39808e-12 0.317903
I0621 01:36:41.766696 32183 compress_conv_layer.cu:174] 0.649094 1.46948e-12 0.423218
I0621 01:36:41.811050 32183 compress_conv_layer.cu:174] 0.649094 4.04695e-12 0.336412
I0621 01:36:41.903165 32183 compress_conv_layer.cu:174] 0.649094 1.21044e-12 0.240569
I0621 01:36:42.098825 32183 compress_conv_layer.cu:174] 0.649094 2.49332e-12 0.215726
I0621 01:36:42.122992 32183 compress_conv_layer.cu:174] 0.649094 2.31849e-07 0.167917
I0621 01:36:42.353637 32183 solver.cpp:219] Iteration 7000 (0.565244 iter/s, 88.4573s/50 iters), loss = 0.0120985
I0621 01:36:42.353760 32183 solver.cpp:238]     Train net output #0: loss = 0.00897021 (* 1 = 0.00897021 loss)
I0621 01:36:42.353787 32183 sgd_solver.cpp:105] Iteration 7000, lr = 0.01
I0621 01:37:53.196478 32183 solver.cpp:219] Iteration 7050 (0.705796 iter/s, 70.842s/50 iters), loss = 0.00910542
I0621 01:37:53.196631 32183 solver.cpp:238]     Train net output #0: loss = 0.0075405 (* 1 = 0.0075405 loss)
I0621 01:37:53.196658 32183 sgd_solver.cpp:105] Iteration 7050, lr = 0.01
I0621 01:39:04.032789 32183 solver.cpp:219] Iteration 7100 (0.705862 iter/s, 70.8354s/50 iters), loss = 0.00720348
I0621 01:39:04.032948 32183 solver.cpp:238]     Train net output #0: loss = 0.00587578 (* 1 = 0.00587578 loss)
I0621 01:39:04.032975 32183 sgd_solver.cpp:105] Iteration 7100, lr = 0.01
I0621 01:40:14.891145 32183 solver.cpp:219] Iteration 7150 (0.705642 iter/s, 70.8574s/50 iters), loss = 0.00878763
I0621 01:40:14.891311 32183 solver.cpp:238]     Train net output #0: loss = 0.00922302 (* 1 = 0.00922302 loss)
I0621 01:40:14.891340 32183 sgd_solver.cpp:105] Iteration 7150, lr = 0.01
I0621 01:41:25.748559 32183 solver.cpp:219] Iteration 7200 (0.705652 iter/s, 70.8565s/50 iters), loss = 0.00653263
I0621 01:41:25.748733 32183 solver.cpp:238]     Train net output #0: loss = 0.00350809 (* 1 = 0.00350809 loss)
I0621 01:41:25.748759 32183 sgd_solver.cpp:105] Iteration 7200, lr = 0.01
I0621 01:42:36.607627 32183 solver.cpp:219] Iteration 7250 (0.705635 iter/s, 70.8581s/50 iters), loss = 0.00691769
I0621 01:42:36.607785 32183 solver.cpp:238]     Train net output #0: loss = 0.00695219 (* 1 = 0.00695219 loss)
I0621 01:42:36.607812 32183 sgd_solver.cpp:105] Iteration 7250, lr = 0.01
I0621 01:43:47.436419 32183 solver.cpp:219] Iteration 7300 (0.705937 iter/s, 70.8278s/50 iters), loss = 0.00785713
I0621 01:43:47.436617 32183 solver.cpp:238]     Train net output #0: loss = 0.007714 (* 1 = 0.007714 loss)
I0621 01:43:47.436650 32183 sgd_solver.cpp:105] Iteration 7300, lr = 0.01
I0621 01:44:58.270110 32183 solver.cpp:219] Iteration 7350 (0.705888 iter/s, 70.8327s/50 iters), loss = 0.00655949
I0621 01:44:58.270279 32183 solver.cpp:238]     Train net output #0: loss = 0.0130045 (* 1 = 0.0130045 loss)
I0621 01:44:58.270308 32183 sgd_solver.cpp:105] Iteration 7350, lr = 0.01
I0621 01:46:09.134272 32183 solver.cpp:219] Iteration 7400 (0.705585 iter/s, 70.8632s/50 iters), loss = 0.00963266
I0621 01:46:09.134474 32183 solver.cpp:238]     Train net output #0: loss = 0.00956346 (* 1 = 0.00956346 loss)
I0621 01:46:09.134543 32183 sgd_solver.cpp:105] Iteration 7400, lr = 0.01
I0621 01:47:19.990936 32183 solver.cpp:219] Iteration 7450 (0.70566 iter/s, 70.8557s/50 iters), loss = 0.0068494
I0621 01:47:19.991106 32183 solver.cpp:238]     Train net output #0: loss = 0.00400553 (* 1 = 0.00400553 loss)
I0621 01:47:19.991133 32183 sgd_solver.cpp:105] Iteration 7450, lr = 0.01
I0621 01:48:29.420147 32183 solver.cpp:331] Iteration 7500, Testing net (#0)
I0621 01:48:44.310609 32183 solver.cpp:398]     Test net output #0: accuracy = 0.945968
I0621 01:48:44.310737 32183 solver.cpp:398]     Test net output #1: loss = 0.260814 (* 1 = 0.260814 loss)
I0621 01:48:45.723860 32183 solver.cpp:219] Iteration 7500 (0.583214 iter/s, 85.7318s/50 iters), loss = 0.0103713
I0621 01:48:45.724001 32183 solver.cpp:238]     Train net output #0: loss = 0.0203991 (* 1 = 0.0203991 loss)
I0621 01:48:45.724035 32183 sgd_solver.cpp:105] Iteration 7500, lr = 0.01
I0621 01:49:56.558440 32183 solver.cpp:219] Iteration 7550 (0.705879 iter/s, 70.8337s/50 iters), loss = 0.0118387
I0621 01:49:56.558619 32183 solver.cpp:238]     Train net output #0: loss = 0.0149844 (* 1 = 0.0149844 loss)
I0621 01:49:56.558651 32183 sgd_solver.cpp:105] Iteration 7550, lr = 0.01
I0621 01:51:07.396767 32183 solver.cpp:219] Iteration 7600 (0.705842 iter/s, 70.8374s/50 iters), loss = 0.00839882
I0621 01:51:07.396926 32183 solver.cpp:238]     Train net output #0: loss = 0.00202659 (* 1 = 0.00202659 loss)
I0621 01:51:07.396951 32183 sgd_solver.cpp:105] Iteration 7600, lr = 0.01
I0621 01:52:18.253413 32183 solver.cpp:219] Iteration 7650 (0.705659 iter/s, 70.8557s/50 iters), loss = 0.0083972
I0621 01:52:18.253577 32183 solver.cpp:238]     Train net output #0: loss = 0.00992964 (* 1 = 0.00992964 loss)
I0621 01:52:18.253609 32183 sgd_solver.cpp:105] Iteration 7650, lr = 0.01
I0621 01:53:29.099704 32183 solver.cpp:219] Iteration 7700 (0.705762 iter/s, 70.8454s/50 iters), loss = 0.00862185
I0621 01:53:29.099853 32183 solver.cpp:238]     Train net output #0: loss = 0.0134525 (* 1 = 0.0134525 loss)
I0621 01:53:29.099880 32183 sgd_solver.cpp:105] Iteration 7700, lr = 0.01
I0621 01:54:39.995496 32183 solver.cpp:219] Iteration 7750 (0.70527 iter/s, 70.8949s/50 iters), loss = 0.0088126
I0621 01:54:39.995661 32183 solver.cpp:238]     Train net output #0: loss = 0.00811972 (* 1 = 0.00811972 loss)
I0621 01:54:39.995687 32183 sgd_solver.cpp:105] Iteration 7750, lr = 0.01
I0621 01:55:50.850399 32183 solver.cpp:219] Iteration 7800 (0.705677 iter/s, 70.854s/50 iters), loss = 0.007891
I0621 01:55:50.850694 32183 solver.cpp:238]     Train net output #0: loss = 0.0101042 (* 1 = 0.0101042 loss)
I0621 01:55:50.850729 32183 sgd_solver.cpp:105] Iteration 7800, lr = 0.01
I0621 01:57:01.693738 32183 solver.cpp:219] Iteration 7850 (0.705793 iter/s, 70.8423s/50 iters), loss = 0.00987272
I0621 01:57:01.693970 32183 solver.cpp:238]     Train net output #0: loss = 0.0147735 (* 1 = 0.0147735 loss)
I0621 01:57:01.694018 32183 sgd_solver.cpp:105] Iteration 7850, lr = 0.01
I0621 01:58:12.551738 32183 solver.cpp:219] Iteration 7900 (0.705646 iter/s, 70.8571s/50 iters), loss = 0.0132296
I0621 01:58:12.551880 32183 solver.cpp:238]     Train net output #0: loss = 0.00608393 (* 1 = 0.00608393 loss)
I0621 01:58:12.551906 32183 sgd_solver.cpp:105] Iteration 7900, lr = 0.01
I0621 01:59:23.392462 32183 solver.cpp:219] Iteration 7950 (0.705817 iter/s, 70.8399s/50 iters), loss = 0.0128264
I0621 01:59:23.392628 32183 solver.cpp:238]     Train net output #0: loss = 0.0110862 (* 1 = 0.0110862 loss)
I0621 01:59:23.392654 32183 sgd_solver.cpp:105] Iteration 7950, lr = 0.01
I0621 02:00:32.854244 32183 solver.cpp:331] Iteration 8000, Testing net (#0)
I0621 02:00:39.532469 32183 blocking_queue.cpp:49] Waiting for data
I0621 02:00:47.500880 32183 solver.cpp:398]     Test net output #0: accuracy = 0.926613
I0621 02:00:47.500960 32183 solver.cpp:398]     Test net output #1: loss = 0.328669 (* 1 = 0.328669 loss)
I0621 02:00:47.508910 32183 compress_conv_layer.cu:174] 0.680219 1.29399e-10 0.666147
I0621 02:00:47.516983 32183 compress_conv_layer.cu:174] 0.680219 7.89224e-11 0.388328
I0621 02:00:47.525279 32183 compress_conv_layer.cu:174] 0.680219 1.41794e-11 0.522324
I0621 02:00:47.533529 32183 compress_conv_layer.cu:174] 0.680219 2.15975e-12 0.548687
I0621 02:00:47.546438 32183 compress_conv_layer.cu:174] 0.680219 6.89735e-12 0.322781
I0621 02:00:47.568601 32183 compress_conv_layer.cu:174] 0.680219 6.6164e-14 0.338996
I0621 02:00:47.613240 32183 compress_conv_layer.cu:174] 0.680219 1.20175e-13 0.331016
I0621 02:00:47.656731 32183 compress_conv_layer.cu:174] 0.680219 1.53022e-12 0.283213
I0621 02:00:47.700641 32183 compress_conv_layer.cu:174] 0.680219 1.32986e-12 0.302209
I0621 02:00:47.744268 32183 compress_conv_layer.cu:174] 0.680219 1.39778e-12 0.402183
I0621 02:00:47.787253 32183 compress_conv_layer.cu:174] 0.680219 3.84949e-12 0.319299
I0621 02:00:47.876819 32183 compress_conv_layer.cu:174] 0.680219 1.15138e-12 0.228843
I0621 02:00:48.064520 32183 compress_conv_layer.cu:174] 0.680219 2.37166e-12 0.205183
I0621 02:00:48.087990 32183 compress_conv_layer.cu:174] 0.680219 2.20536e-07 0.168278
I0621 02:00:48.326405 32183 compress_conv_layer.cu:174] 0.680219 1.29399e-10 0.666147
I0621 02:00:48.334403 32183 compress_conv_layer.cu:174] 0.680219 7.89224e-11 0.388328
I0621 02:00:48.342669 32183 compress_conv_layer.cu:174] 0.680219 1.41794e-11 0.522324
I0621 02:00:48.350832 32183 compress_conv_layer.cu:174] 0.680219 2.15975e-12 0.548687
I0621 02:00:48.363435 32183 compress_conv_layer.cu:174] 0.680219 6.89735e-12 0.322781
I0621 02:00:48.385314 32183 compress_conv_layer.cu:174] 0.680219 6.6164e-14 0.338996
I0621 02:00:48.430027 32183 compress_conv_layer.cu:174] 0.680219 1.20175e-13 0.331016
I0621 02:00:48.473110 32183 compress_conv_layer.cu:174] 0.680219 1.53022e-12 0.283213
I0621 02:00:48.516636 32183 compress_conv_layer.cu:174] 0.680219 1.32986e-12 0.302209
I0621 02:00:48.559834 32183 compress_conv_layer.cu:174] 0.680219 1.39778e-12 0.402183
I0621 02:00:48.602845 32183 compress_conv_layer.cu:174] 0.680219 3.84949e-12 0.319299
I0621 02:00:48.692327 32183 compress_conv_layer.cu:174] 0.680219 1.15138e-12 0.228843
I0621 02:00:48.879706 32183 compress_conv_layer.cu:174] 0.680219 2.37166e-12 0.205183
I0621 02:00:48.904072 32183 compress_conv_layer.cu:174] 0.680219 2.20536e-07 0.168278
I0621 02:00:49.142606 32183 compress_conv_layer.cu:174] 0.680219 1.29399e-10 0.666147
I0621 02:00:49.150634 32183 compress_conv_layer.cu:174] 0.680219 7.89224e-11 0.388328
I0621 02:00:49.158929 32183 compress_conv_layer.cu:174] 0.680219 1.41794e-11 0.522324
I0621 02:00:49.167170 32183 compress_conv_layer.cu:174] 0.680219 2.15975e-12 0.548687
I0621 02:00:49.179947 32183 compress_conv_layer.cu:174] 0.680219 6.89735e-12 0.322781
I0621 02:00:49.201717 32183 compress_conv_layer.cu:174] 0.680219 6.6164e-14 0.338996
I0621 02:00:49.246253 32183 compress_conv_layer.cu:174] 0.680219 1.20175e-13 0.331016
I0621 02:00:49.289336 32183 compress_conv_layer.cu:174] 0.680219 1.53022e-12 0.283213
I0621 02:00:49.332950 32183 compress_conv_layer.cu:174] 0.680219 1.32986e-12 0.302209
I0621 02:00:49.376338 32183 compress_conv_layer.cu:174] 0.680219 1.39778e-12 0.402183
I0621 02:00:49.419438 32183 compress_conv_layer.cu:174] 0.680219 3.84949e-12 0.319299
I0621 02:00:49.508806 32183 compress_conv_layer.cu:174] 0.680219 1.15138e-12 0.228843
I0621 02:00:49.696494 32183 compress_conv_layer.cu:174] 0.680219 2.37166e-12 0.205183
I0621 02:00:49.719840 32183 compress_conv_layer.cu:174] 0.680219 2.20536e-07 0.168278
I0621 02:00:49.958163 32183 compress_conv_layer.cu:174] 0.680219 1.29399e-10 0.666147
I0621 02:00:49.966130 32183 compress_conv_layer.cu:174] 0.680219 7.89224e-11 0.388328
I0621 02:00:49.974403 32183 compress_conv_layer.cu:174] 0.680219 1.41794e-11 0.522324
I0621 02:00:49.982623 32183 compress_conv_layer.cu:174] 0.680219 2.15975e-12 0.548687
I0621 02:00:49.995220 32183 compress_conv_layer.cu:174] 0.680219 6.89735e-12 0.322781
I0621 02:00:50.017071 32183 compress_conv_layer.cu:174] 0.680219 6.6164e-14 0.338996
I0621 02:00:50.061826 32183 compress_conv_layer.cu:174] 0.680219 1.20175e-13 0.331016
I0621 02:00:50.105175 32183 compress_conv_layer.cu:174] 0.680219 1.53022e-12 0.283213
I0621 02:00:50.149024 32183 compress_conv_layer.cu:174] 0.680219 1.32986e-12 0.302209
I0621 02:00:50.192540 32183 compress_conv_layer.cu:174] 0.680219 1.39778e-12 0.402183
I0621 02:00:50.235951 32183 compress_conv_layer.cu:174] 0.680219 3.84949e-12 0.319299
I0621 02:00:50.325949 32183 compress_conv_layer.cu:174] 0.680219 1.15138e-12 0.228843
I0621 02:00:50.513509 32183 compress_conv_layer.cu:174] 0.680219 2.37166e-12 0.205183
I0621 02:00:50.536813 32183 compress_conv_layer.cu:174] 0.680219 2.20536e-07 0.168278
I0621 02:00:50.775285 32183 compress_conv_layer.cu:174] 0.680219 1.29399e-10 0.666147
I0621 02:00:50.783363 32183 compress_conv_layer.cu:174] 0.680219 7.89224e-11 0.388328
I0621 02:00:50.791831 32183 compress_conv_layer.cu:174] 0.680219 1.41794e-11 0.522324
I0621 02:00:50.800256 32183 compress_conv_layer.cu:174] 0.680219 2.15975e-12 0.548687
I0621 02:00:50.813386 32183 compress_conv_layer.cu:174] 0.680219 6.89735e-12 0.322781
I0621 02:00:50.836103 32183 compress_conv_layer.cu:174] 0.680219 6.6164e-14 0.338996
I0621 02:00:50.881427 32183 compress_conv_layer.cu:174] 0.680219 1.20175e-13 0.331016
I0621 02:00:50.925101 32183 compress_conv_layer.cu:174] 0.680219 1.53022e-12 0.283213
I0621 02:00:50.969293 32183 compress_conv_layer.cu:174] 0.680219 1.32986e-12 0.302209
I0621 02:00:51.013116 32183 compress_conv_layer.cu:174] 0.680219 1.39778e-12 0.402183
I0621 02:00:51.056664 32183 compress_conv_layer.cu:174] 0.680219 3.84949e-12 0.319299
I0621 02:00:51.146641 32183 compress_conv_layer.cu:174] 0.680219 1.15138e-12 0.228843
I0621 02:00:51.334156 32183 compress_conv_layer.cu:174] 0.680219 2.37166e-12 0.205183
I0621 02:00:51.357393 32183 compress_conv_layer.cu:174] 0.680219 2.20536e-07 0.168278
I0621 02:00:51.587795 32183 solver.cpp:219] Iteration 8000 (0.56693 iter/s, 88.1943s/50 iters), loss = 0.00689339
I0621 02:00:51.587894 32183 solver.cpp:238]     Train net output #0: loss = 0.00657723 (* 1 = 0.00657723 loss)
I0621 02:00:51.587921 32183 sgd_solver.cpp:105] Iteration 8000, lr = 0.01
I0621 02:02:02.443049 32183 solver.cpp:219] Iteration 8050 (0.705672 iter/s, 70.8545s/50 iters), loss = 0.0109566
I0621 02:02:02.443224 32183 solver.cpp:238]     Train net output #0: loss = 0.0087114 (* 1 = 0.0087114 loss)
I0621 02:02:02.443251 32183 sgd_solver.cpp:105] Iteration 8050, lr = 0.01
I0621 02:03:13.299567 32183 solver.cpp:219] Iteration 8100 (0.70566 iter/s, 70.8557s/50 iters), loss = 0.0736721
I0621 02:03:13.299777 32183 solver.cpp:238]     Train net output #0: loss = 0.0116985 (* 1 = 0.0116985 loss)
I0621 02:03:13.299803 32183 sgd_solver.cpp:105] Iteration 8100, lr = 0.01
I0621 02:04:24.163569 32183 solver.cpp:219] Iteration 8150 (0.705586 iter/s, 70.8631s/50 iters), loss = 0.0882465
I0621 02:04:24.163790 32183 solver.cpp:238]     Train net output #0: loss = 0.0442154 (* 1 = 0.0442154 loss)
I0621 02:04:24.163818 32183 sgd_solver.cpp:105] Iteration 8150, lr = 0.01
I0621 02:05:34.994997 32183 solver.cpp:219] Iteration 8200 (0.70591 iter/s, 70.8305s/50 iters), loss = 0.118988
I0621 02:05:34.995146 32183 solver.cpp:238]     Train net output #0: loss = 0.082897 (* 1 = 0.082897 loss)
I0621 02:05:34.995173 32183 sgd_solver.cpp:105] Iteration 8200, lr = 0.01
I0621 02:06:45.896447 32183 solver.cpp:219] Iteration 8250 (0.705213 iter/s, 70.9006s/50 iters), loss = 0.062897
I0621 02:06:45.896636 32183 solver.cpp:238]     Train net output #0: loss = 0.0820802 (* 1 = 0.0820802 loss)
I0621 02:06:45.896662 32183 sgd_solver.cpp:105] Iteration 8250, lr = 0.01
I0621 02:07:56.732098 32183 solver.cpp:219] Iteration 8300 (0.705868 iter/s, 70.8348s/50 iters), loss = 0.0315319
I0621 02:07:56.732254 32183 solver.cpp:238]     Train net output #0: loss = 0.0301818 (* 1 = 0.0301818 loss)
I0621 02:07:56.732280 32183 sgd_solver.cpp:105] Iteration 8300, lr = 0.01
I0621 02:09:07.577841 32183 solver.cpp:219] Iteration 8350 (0.705767 iter/s, 70.8449s/50 iters), loss = 0.0391543
I0621 02:09:07.577986 32183 solver.cpp:238]     Train net output #0: loss = 0.0455692 (* 1 = 0.0455692 loss)
I0621 02:09:07.578012 32183 sgd_solver.cpp:105] Iteration 8350, lr = 0.01
I0621 02:10:18.440788 32183 solver.cpp:219] Iteration 8400 (0.705596 iter/s, 70.8621s/50 iters), loss = 0.0323497
I0621 02:10:18.440935 32183 solver.cpp:238]     Train net output #0: loss = 0.0328528 (* 1 = 0.0328528 loss)
I0621 02:10:18.440961 32183 sgd_solver.cpp:105] Iteration 8400, lr = 0.01
I0621 02:11:29.281682 32183 solver.cpp:219] Iteration 8450 (0.705815 iter/s, 70.84s/50 iters), loss = 0.0133278
I0621 02:11:29.281891 32183 solver.cpp:238]     Train net output #0: loss = 0.00353599 (* 1 = 0.00353599 loss)
I0621 02:11:29.281919 32183 sgd_solver.cpp:105] Iteration 8450, lr = 0.01
I0621 02:12:38.697923 32183 solver.cpp:331] Iteration 8500, Testing net (#0)
I0621 02:12:53.514014 32183 solver.cpp:398]     Test net output #0: accuracy = 0.934678
I0621 02:12:53.514103 32183 solver.cpp:398]     Test net output #1: loss = 0.242633 (* 1 = 0.242633 loss)
I0621 02:12:54.925356 32183 solver.cpp:219] Iteration 8500 (0.583822 iter/s, 85.6426s/50 iters), loss = 0.0180517
I0621 02:12:54.925523 32183 solver.cpp:238]     Train net output #0: loss = 0.0317279 (* 1 = 0.0317279 loss)
I0621 02:12:54.925559 32183 sgd_solver.cpp:105] Iteration 8500, lr = 0.01
I0621 02:14:05.775949 32183 solver.cpp:219] Iteration 8550 (0.70572 iter/s, 70.8496s/50 iters), loss = 0.00798305
I0621 02:14:05.776145 32183 solver.cpp:238]     Train net output #0: loss = 0.00722825 (* 1 = 0.00722825 loss)
I0621 02:14:05.776172 32183 sgd_solver.cpp:105] Iteration 8550, lr = 0.01
I0621 02:15:16.605635 32183 solver.cpp:219] Iteration 8600 (0.705929 iter/s, 70.8287s/50 iters), loss = 0.00955999
I0621 02:15:16.605841 32183 solver.cpp:238]     Train net output #0: loss = 0.00394328 (* 1 = 0.00394328 loss)
I0621 02:15:16.605870 32183 sgd_solver.cpp:105] Iteration 8600, lr = 0.01
I0621 02:16:27.448505 32183 solver.cpp:219] Iteration 8650 (0.705797 iter/s, 70.8419s/50 iters), loss = 0.00946961
I0621 02:16:27.448671 32183 solver.cpp:238]     Train net output #0: loss = 0.0122339 (* 1 = 0.0122339 loss)
I0621 02:16:27.448698 32183 sgd_solver.cpp:105] Iteration 8650, lr = 0.01
I0621 02:17:38.306159 32183 solver.cpp:219] Iteration 8700 (0.70565 iter/s, 70.8567s/50 iters), loss = 0.00602109
I0621 02:17:38.306313 32183 solver.cpp:238]     Train net output #0: loss = 0.00708045 (* 1 = 0.00708045 loss)
I0621 02:17:38.306344 32183 sgd_solver.cpp:105] Iteration 8700, lr = 0.01
I0621 02:18:49.147783 32183 solver.cpp:219] Iteration 8750 (0.70581 iter/s, 70.8406s/50 iters), loss = 0.0076203
I0621 02:18:49.148036 32183 solver.cpp:238]     Train net output #0: loss = 0.0119179 (* 1 = 0.0119179 loss)
I0621 02:18:49.148064 32183 sgd_solver.cpp:105] Iteration 8750, lr = 0.01
I0621 02:19:59.997342 32183 solver.cpp:219] Iteration 8800 (0.705731 iter/s, 70.8485s/50 iters), loss = 0.00824096
I0621 02:19:59.997540 32183 solver.cpp:238]     Train net output #0: loss = 0.00442155 (* 1 = 0.00442155 loss)
I0621 02:19:59.997575 32183 sgd_solver.cpp:105] Iteration 8800, lr = 0.01
I0621 02:21:10.849766 32183 solver.cpp:219] Iteration 8850 (0.705702 iter/s, 70.8514s/50 iters), loss = 0.010053
I0621 02:21:10.849997 32183 solver.cpp:238]     Train net output #0: loss = 0.00649017 (* 1 = 0.00649017 loss)
I0621 02:21:10.850025 32183 sgd_solver.cpp:105] Iteration 8850, lr = 0.01
I0621 02:22:21.683845 32183 solver.cpp:219] Iteration 8900 (0.705885 iter/s, 70.8331s/50 iters), loss = 0.00791772
I0621 02:22:21.683991 32183 solver.cpp:238]     Train net output #0: loss = 0.00558248 (* 1 = 0.00558248 loss)
I0621 02:22:21.684017 32183 sgd_solver.cpp:105] Iteration 8900, lr = 0.01
I0621 02:23:32.528928 32183 solver.cpp:219] Iteration 8950 (0.705775 iter/s, 70.8441s/50 iters), loss = 0.00606489
I0621 02:23:32.529083 32183 solver.cpp:238]     Train net output #0: loss = 0.00356996 (* 1 = 0.00356996 loss)
I0621 02:23:32.529109 32183 sgd_solver.cpp:105] Iteration 8950, lr = 0.01
I0621 02:24:41.955471 32183 solver.cpp:331] Iteration 9000, Testing net (#0)
I0621 02:24:56.686008 32183 solver.cpp:398]     Test net output #0: accuracy = 0.926613
I0621 02:24:56.686113 32183 solver.cpp:398]     Test net output #1: loss = 0.32696 (* 1 = 0.32696 loss)
I0621 02:24:56.693617 32183 compress_conv_layer.cu:174] 0.708375 1.23085e-10 0.641093
I0621 02:24:56.702442 32183 compress_conv_layer.cu:174] 0.708375 7.50715e-11 0.369015
I0621 02:24:56.710989 32183 compress_conv_layer.cu:174] 0.708375 1.34875e-11 0.506454
I0621 02:24:56.719552 32183 compress_conv_layer.cu:174] 0.708375 2.05437e-12 0.52235
I0621 02:24:56.732874 32183 compress_conv_layer.cu:174] 0.708375 6.56081e-12 0.311203
I0621 02:24:56.756072 32183 compress_conv_layer.cu:174] 0.708375 6.29356e-14 0.325014
I0621 02:24:56.801255 32183 compress_conv_layer.cu:174] 0.708375 1.14311e-13 0.313527
I0621 02:24:56.845144 32183 compress_conv_layer.cu:174] 0.708375 1.45556e-12 0.26958
I0621 02:24:56.888983 32183 compress_conv_layer.cu:174] 0.708375 1.26497e-12 0.28745
I0621 02:24:56.932320 32183 compress_conv_layer.cu:174] 0.708375 1.32958e-12 0.379766
I0621 02:24:56.975339 32183 compress_conv_layer.cu:174] 0.708375 3.66166e-12 0.30201
I0621 02:24:57.065237 32183 compress_conv_layer.cu:174] 0.708375 1.0952e-12 0.21775
I0621 02:24:57.253268 32183 compress_conv_layer.cu:174] 0.708375 2.25594e-12 0.195153
I0621 02:24:57.276394 32183 compress_conv_layer.cu:174] 0.708375 2.09776e-07 0.176413
I0621 02:24:57.514628 32183 compress_conv_layer.cu:174] 0.708375 1.23085e-10 0.641093
I0621 02:24:57.522591 32183 compress_conv_layer.cu:174] 0.708375 7.50715e-11 0.369015
I0621 02:24:57.530850 32183 compress_conv_layer.cu:174] 0.708375 1.34875e-11 0.506454
I0621 02:24:57.538972 32183 compress_conv_layer.cu:174] 0.708375 2.05437e-12 0.52235
I0621 02:24:57.551578 32183 compress_conv_layer.cu:174] 0.708375 6.56081e-12 0.311203
I0621 02:24:57.573372 32183 compress_conv_layer.cu:174] 0.708375 6.29356e-14 0.325014
I0621 02:24:57.617590 32183 compress_conv_layer.cu:174] 0.708375 1.14311e-13 0.313527
I0621 02:24:57.660660 32183 compress_conv_layer.cu:174] 0.708375 1.45556e-12 0.26958
I0621 02:24:57.703881 32183 compress_conv_layer.cu:174] 0.708375 1.26497e-12 0.28745
I0621 02:24:57.746989 32183 compress_conv_layer.cu:174] 0.708375 1.32958e-12 0.379766
I0621 02:24:57.789906 32183 compress_conv_layer.cu:174] 0.708375 3.66166e-12 0.30201
I0621 02:24:57.879850 32183 compress_conv_layer.cu:174] 0.708375 1.0952e-12 0.21775
I0621 02:24:58.067612 32183 compress_conv_layer.cu:174] 0.708375 2.25594e-12 0.195153
I0621 02:24:58.090867 32183 compress_conv_layer.cu:174] 0.708375 2.09776e-07 0.176413
I0621 02:24:58.329222 32183 compress_conv_layer.cu:174] 0.708375 1.23085e-10 0.641093
I0621 02:24:58.337188 32183 compress_conv_layer.cu:174] 0.708375 7.50715e-11 0.369015
I0621 02:24:58.345412 32183 compress_conv_layer.cu:174] 0.708375 1.34875e-11 0.506454
I0621 02:24:58.353617 32183 compress_conv_layer.cu:174] 0.708375 2.05437e-12 0.52235
I0621 02:24:58.366205 32183 compress_conv_layer.cu:174] 0.708375 6.56081e-12 0.311203
I0621 02:24:58.387985 32183 compress_conv_layer.cu:174] 0.708375 6.29356e-14 0.325014
I0621 02:24:58.432137 32183 compress_conv_layer.cu:174] 0.708375 1.14311e-13 0.313527
I0621 02:24:58.475186 32183 compress_conv_layer.cu:174] 0.708375 1.45556e-12 0.26958
I0621 02:24:58.518398 32183 compress_conv_layer.cu:174] 0.708375 1.26497e-12 0.28745
I0621 02:24:58.561409 32183 compress_conv_layer.cu:174] 0.708375 1.32958e-12 0.379766
I0621 02:24:58.604622 32183 compress_conv_layer.cu:174] 0.708375 3.66166e-12 0.30201
I0621 02:24:58.694619 32183 compress_conv_layer.cu:174] 0.708375 1.0952e-12 0.21775
I0621 02:24:58.882262 32183 compress_conv_layer.cu:174] 0.708375 2.25594e-12 0.195153
I0621 02:24:58.905508 32183 compress_conv_layer.cu:174] 0.708375 2.09776e-07 0.176413
I0621 02:24:59.143784 32183 compress_conv_layer.cu:174] 0.708375 1.23085e-10 0.641093
I0621 02:24:59.151778 32183 compress_conv_layer.cu:174] 0.708375 7.50715e-11 0.369015
I0621 02:24:59.160046 32183 compress_conv_layer.cu:174] 0.708375 1.34875e-11 0.506454
I0621 02:24:59.168166 32183 compress_conv_layer.cu:174] 0.708375 2.05437e-12 0.52235
I0621 02:24:59.180771 32183 compress_conv_layer.cu:174] 0.708375 6.56081e-12 0.311203
I0621 02:24:59.202750 32183 compress_conv_layer.cu:174] 0.708375 6.29356e-14 0.325014
I0621 02:24:59.247130 32183 compress_conv_layer.cu:174] 0.708375 1.14311e-13 0.313527
I0621 02:24:59.290345 32183 compress_conv_layer.cu:174] 0.708375 1.45556e-12 0.26958
I0621 02:24:59.333792 32183 compress_conv_layer.cu:174] 0.708375 1.26497e-12 0.28745
I0621 02:24:59.378309 32183 compress_conv_layer.cu:174] 0.708375 1.32958e-12 0.379766
I0621 02:24:59.421597 32183 compress_conv_layer.cu:174] 0.708375 3.66166e-12 0.30201
I0621 02:24:59.512418 32183 compress_conv_layer.cu:174] 0.708375 1.0952e-12 0.21775
I0621 02:24:59.705332 32183 compress_conv_layer.cu:174] 0.708375 2.25594e-12 0.195153
I0621 02:24:59.728559 32183 compress_conv_layer.cu:174] 0.708375 2.09776e-07 0.176413
I0621 02:24:59.966954 32183 compress_conv_layer.cu:174] 0.708375 1.23085e-10 0.641093
I0621 02:24:59.974928 32183 compress_conv_layer.cu:174] 0.708375 7.50715e-11 0.369015
I0621 02:24:59.983180 32183 compress_conv_layer.cu:174] 0.708375 1.34875e-11 0.506454
I0621 02:24:59.991331 32183 compress_conv_layer.cu:174] 0.708375 2.05437e-12 0.52235
I0621 02:25:00.003913 32183 compress_conv_layer.cu:174] 0.708375 6.56081e-12 0.311203
I0621 02:25:00.025741 32183 compress_conv_layer.cu:174] 0.708375 6.29356e-14 0.325014
I0621 02:25:00.070186 32183 compress_conv_layer.cu:174] 0.708375 1.14311e-13 0.313527
I0621 02:25:00.113637 32183 compress_conv_layer.cu:174] 0.708375 1.45556e-12 0.26958
I0621 02:25:00.157361 32183 compress_conv_layer.cu:174] 0.708375 1.26497e-12 0.28745
I0621 02:25:00.200752 32183 compress_conv_layer.cu:174] 0.708375 1.32958e-12 0.379766
I0621 02:25:00.244140 32183 compress_conv_layer.cu:174] 0.708375 3.66166e-12 0.30201
I0621 02:25:00.334152 32183 compress_conv_layer.cu:174] 0.708375 1.0952e-12 0.21775
I0621 02:25:00.527091 32183 compress_conv_layer.cu:174] 0.708375 2.25594e-12 0.195153
I0621 02:25:00.550526 32183 compress_conv_layer.cu:174] 0.708375 2.09776e-07 0.176413
I0621 02:25:00.780982 32183 solver.cpp:219] Iteration 9000 (0.566566 iter/s, 88.2509s/50 iters), loss = 0.0141092
I0621 02:25:00.781076 32183 solver.cpp:238]     Train net output #0: loss = 0.00397499 (* 1 = 0.00397499 loss)
I0621 02:25:00.781103 32183 sgd_solver.cpp:105] Iteration 9000, lr = 0.01
I0621 02:26:11.625138 32183 solver.cpp:219] Iteration 9050 (0.705783 iter/s, 70.8433s/50 iters), loss = 0.0117383
I0621 02:26:11.625489 32183 solver.cpp:238]     Train net output #0: loss = 0.00883426 (* 1 = 0.00883426 loss)
I0621 02:26:11.625525 32183 sgd_solver.cpp:105] Iteration 9050, lr = 0.01
I0621 02:27:22.474303 32183 solver.cpp:219] Iteration 9100 (0.705736 iter/s, 70.848s/50 iters), loss = 0.00971645
I0621 02:27:22.474469 32183 solver.cpp:238]     Train net output #0: loss = 0.0149823 (* 1 = 0.0149823 loss)
I0621 02:27:22.474503 32183 sgd_solver.cpp:105] Iteration 9100, lr = 0.01
I0621 02:28:33.334529 32183 solver.cpp:219] Iteration 9150 (0.705624 iter/s, 70.8593s/50 iters), loss = 0.00928213
I0621 02:28:33.334744 32183 solver.cpp:238]     Train net output #0: loss = 0.00536111 (* 1 = 0.00536111 loss)
I0621 02:28:33.334775 32183 sgd_solver.cpp:105] Iteration 9150, lr = 0.01
I0621 02:29:44.183550 32183 solver.cpp:219] Iteration 9200 (0.705736 iter/s, 70.848s/50 iters), loss = 0.011333
I0621 02:29:44.183704 32183 solver.cpp:238]     Train net output #0: loss = 0.00568753 (* 1 = 0.00568753 loss)
I0621 02:29:44.183730 32183 sgd_solver.cpp:105] Iteration 9200, lr = 0.01
I0621 02:30:55.038199 32183 solver.cpp:219] Iteration 9250 (0.70568 iter/s, 70.8536s/50 iters), loss = 0.0135656
I0621 02:30:55.038337 32183 solver.cpp:238]     Train net output #0: loss = 0.0230765 (* 1 = 0.0230765 loss)
I0621 02:30:55.038363 32183 sgd_solver.cpp:105] Iteration 9250, lr = 0.01
I0621 02:32:05.914504 32183 solver.cpp:219] Iteration 9300 (0.705464 iter/s, 70.8753s/50 iters), loss = 0.00701146
I0621 02:32:05.914726 32183 solver.cpp:238]     Train net output #0: loss = 0.00320824 (* 1 = 0.00320824 loss)
I0621 02:32:05.914752 32183 sgd_solver.cpp:105] Iteration 9300, lr = 0.01
I0621 02:33:16.754663 32183 solver.cpp:219] Iteration 9350 (0.705825 iter/s, 70.8391s/50 iters), loss = 0.00696436
I0621 02:33:16.754860 32183 solver.cpp:238]     Train net output #0: loss = 0.00528858 (* 1 = 0.00528858 loss)
I0621 02:33:16.754889 32183 sgd_solver.cpp:105] Iteration 9350, lr = 0.01
I0621 02:34:27.596670 32183 solver.cpp:219] Iteration 9400 (0.705806 iter/s, 70.841s/50 iters), loss = 0.00782942
I0621 02:34:27.596822 32183 solver.cpp:238]     Train net output #0: loss = 0.0113545 (* 1 = 0.0113545 loss)
I0621 02:34:27.596848 32183 sgd_solver.cpp:105] Iteration 9400, lr = 0.01
I0621 02:35:38.431383 32183 solver.cpp:219] Iteration 9450 (0.705879 iter/s, 70.8337s/50 iters), loss = 0.00564656
I0621 02:35:38.431567 32183 solver.cpp:238]     Train net output #0: loss = 0.00831882 (* 1 = 0.00831882 loss)
I0621 02:35:38.431594 32183 sgd_solver.cpp:105] Iteration 9450, lr = 0.01
I0621 02:36:47.868638 32183 solver.cpp:331] Iteration 9500, Testing net (#0)
I0621 02:37:02.707026 32183 solver.cpp:398]     Test net output #0: accuracy = 0.950807
I0621 02:37:02.707125 32183 solver.cpp:398]     Test net output #1: loss = 0.21676 (* 1 = 0.21676 loss)
I0621 02:37:04.120985 32183 solver.cpp:219] Iteration 9500 (0.58351 iter/s, 85.6884s/50 iters), loss = 0.00803423
I0621 02:37:04.121114 32183 solver.cpp:238]     Train net output #0: loss = 0.00595336 (* 1 = 0.00595336 loss)
I0621 02:37:04.121146 32183 sgd_solver.cpp:105] Iteration 9500, lr = 0.01
I0621 02:38:14.958019 32183 solver.cpp:219] Iteration 9550 (0.705855 iter/s, 70.8361s/50 iters), loss = 0.00758805
I0621 02:38:14.958147 32183 solver.cpp:238]     Train net output #0: loss = 0.009584 (* 1 = 0.009584 loss)
I0621 02:38:14.958173 32183 sgd_solver.cpp:105] Iteration 9550, lr = 0.01
I0621 02:39:25.722522 32183 solver.cpp:219] Iteration 9600 (0.706578 iter/s, 70.7635s/50 iters), loss = 0.00875276
I0621 02:39:25.722666 32183 solver.cpp:238]     Train net output #0: loss = 0.00953533 (* 1 = 0.00953533 loss)
I0621 02:39:25.722692 32183 sgd_solver.cpp:105] Iteration 9600, lr = 0.01
I0621 02:40:36.479529 32183 solver.cpp:219] Iteration 9650 (0.706653 iter/s, 70.756s/50 iters), loss = 0.00822879
I0621 02:40:36.479663 32183 solver.cpp:238]     Train net output #0: loss = 0.00619761 (* 1 = 0.00619761 loss)
I0621 02:40:36.479689 32183 sgd_solver.cpp:105] Iteration 9650, lr = 0.01
I0621 02:41:47.242959 32183 solver.cpp:219] Iteration 9700 (0.706589 iter/s, 70.7625s/50 iters), loss = 0.00840845
I0621 02:41:47.245056 32183 solver.cpp:238]     Train net output #0: loss = 0.019578 (* 1 = 0.019578 loss)
I0621 02:41:47.245084 32183 sgd_solver.cpp:105] Iteration 9700, lr = 0.01
I0621 02:42:58.006752 32183 solver.cpp:219] Iteration 9750 (0.706605 iter/s, 70.7609s/50 iters), loss = 0.00830113
I0621 02:42:58.007026 32183 solver.cpp:238]     Train net output #0: loss = 0.0131372 (* 1 = 0.0131372 loss)
I0621 02:42:58.007052 32183 sgd_solver.cpp:105] Iteration 9750, lr = 0.01
I0621 02:44:08.778280 32183 solver.cpp:219] Iteration 9800 (0.70651 iter/s, 70.7704s/50 iters), loss = 0.00816912
I0621 02:44:08.778434 32183 solver.cpp:238]     Train net output #0: loss = 0.00319443 (* 1 = 0.00319443 loss)
I0621 02:44:08.778460 32183 sgd_solver.cpp:105] Iteration 9800, lr = 0.01
I0621 02:45:19.547950 32183 solver.cpp:219] Iteration 9850 (0.706527 iter/s, 70.7687s/50 iters), loss = 0.011402
I0621 02:45:19.548415 32183 solver.cpp:238]     Train net output #0: loss = 0.0120276 (* 1 = 0.0120276 loss)
I0621 02:45:19.548441 32183 sgd_solver.cpp:105] Iteration 9850, lr = 0.01
I0621 02:46:30.316818 32183 solver.cpp:219] Iteration 9900 (0.706538 iter/s, 70.7676s/50 iters), loss = 0.00809692
I0621 02:46:30.316953 32183 solver.cpp:238]     Train net output #0: loss = 0.00591048 (* 1 = 0.00591048 loss)
I0621 02:46:30.316980 32183 sgd_solver.cpp:105] Iteration 9900, lr = 0.01
I0621 02:47:41.077517 32183 solver.cpp:219] Iteration 9950 (0.706616 iter/s, 70.7598s/50 iters), loss = 0.00939686
I0621 02:47:41.077659 32183 solver.cpp:238]     Train net output #0: loss = 0.0304564 (* 1 = 0.0304564 loss)
I0621 02:47:41.077689 32183 sgd_solver.cpp:105] Iteration 9950, lr = 0.01
I0621 02:48:50.440807 32183 solver.cpp:448] Snapshotting to binary proto file mobilenet/mobile_pruning_iter_10000.caffemodel
I0621 02:48:50.598778 32183 sgd_solver.cpp:273] Snapshotting solver state to binary proto file mobilenet/mobile_pruning_iter_10000.solverstate
I0621 02:48:50.655107 32183 solver.cpp:331] Iteration 10000, Testing net (#0)
I0621 02:49:05.253707 32183 solver.cpp:398]     Test net output #0: accuracy = 0.939517
I0621 02:49:05.253784 32183 solver.cpp:398]     Test net output #1: loss = 0.277448 (* 1 = 0.277448 loss)
I0621 02:49:05.261837 32183 compress_conv_layer.cu:174] 0.73408 1.1708e-10 0.610305
I0621 02:49:05.269817 32183 compress_conv_layer.cu:174] 0.73408 7.14085e-11 0.351091
I0621 02:49:05.278110 32183 compress_conv_layer.cu:174] 0.73408 1.28294e-11 0.48188
I0621 02:49:05.286397 32183 compress_conv_layer.cu:174] 0.73408 1.95413e-12 0.496087
I0621 02:49:05.299216 32183 compress_conv_layer.cu:174] 0.73408 6.24068e-12 0.296533
I0621 02:49:05.321282 32183 compress_conv_layer.cu:174] 0.73408 5.98648e-14 0.309841
I0621 02:49:05.364760 32183 compress_conv_layer.cu:174] 0.73408 1.08734e-13 0.297391
I0621 02:49:05.408244 32183 compress_conv_layer.cu:174] 0.73408 1.38454e-12 0.256831
I0621 02:49:05.451689 32183 compress_conv_layer.cu:174] 0.73408 1.20325e-12 0.272659
I0621 02:49:05.495064 32183 compress_conv_layer.cu:174] 0.73408 1.26471e-12 0.361011
I0621 02:49:05.538059 32183 compress_conv_layer.cu:174] 0.73408 3.48299e-12 0.28723
I0621 02:49:05.625769 32183 compress_conv_layer.cu:174] 0.73408 1.04176e-12 0.206973
I0621 02:49:05.811029 32183 compress_conv_layer.cu:174] 0.73408 2.14586e-12 0.185612
I0621 02:49:05.829320 32183 compress_conv_layer.cu:174] 0.73408 1.9954e-07 0.17698
I0621 02:49:06.067591 32183 compress_conv_layer.cu:174] 0.73408 1.1708e-10 0.610305
I0621 02:49:06.075570 32183 compress_conv_layer.cu:174] 0.73408 7.14085e-11 0.351091
I0621 02:49:06.083823 32183 compress_conv_layer.cu:174] 0.73408 1.28294e-11 0.48188
I0621 02:49:06.091962 32183 compress_conv_layer.cu:174] 0.73408 1.95413e-12 0.496087
I0621 02:49:06.104519 32183 compress_conv_layer.cu:174] 0.73408 6.24068e-12 0.296533
I0621 02:49:06.126292 32183 compress_conv_layer.cu:174] 0.73408 5.98648e-14 0.309841
I0621 02:49:06.169033 32183 compress_conv_layer.cu:174] 0.73408 1.08734e-13 0.297391
I0621 02:49:06.212714 32183 compress_conv_layer.cu:174] 0.73408 1.38454e-12 0.256831
I0621 02:49:06.255491 32183 compress_conv_layer.cu:174] 0.73408 1.20325e-12 0.272659
I0621 02:49:06.298441 32183 compress_conv_layer.cu:174] 0.73408 1.26471e-12 0.361011
I0621 02:49:06.341079 32183 compress_conv_layer.cu:174] 0.73408 3.48299e-12 0.28723
I0621 02:49:06.427206 32183 compress_conv_layer.cu:174] 0.73408 1.04176e-12 0.206973
I0621 02:49:06.608772 32183 compress_conv_layer.cu:174] 0.73408 2.14586e-12 0.185612
I0621 02:49:06.627017 32183 compress_conv_layer.cu:174] 0.73408 1.9954e-07 0.17698
I0621 02:49:06.865276 32183 compress_conv_layer.cu:174] 0.73408 1.1708e-10 0.610305
I0621 02:49:06.873286 32183 compress_conv_layer.cu:174] 0.73408 7.14085e-11 0.351091
I0621 02:49:06.881538 32183 compress_conv_layer.cu:174] 0.73408 1.28294e-11 0.48188
I0621 02:49:06.889689 32183 compress_conv_layer.cu:174] 0.73408 1.95413e-12 0.496087
I0621 02:49:06.902245 32183 compress_conv_layer.cu:174] 0.73408 6.24068e-12 0.296533
I0621 02:49:06.923781 32183 compress_conv_layer.cu:174] 0.73408 5.98648e-14 0.309841
I0621 02:49:06.966375 32183 compress_conv_layer.cu:174] 0.73408 1.08734e-13 0.297391
I0621 02:49:07.010743 32183 compress_conv_layer.cu:174] 0.73408 1.38454e-12 0.256831
I0621 02:49:07.053946 32183 compress_conv_layer.cu:174] 0.73408 1.20325e-12 0.272659
I0621 02:49:07.097348 32183 compress_conv_layer.cu:174] 0.73408 1.26471e-12 0.361011
I0621 02:49:07.140689 32183 compress_conv_layer.cu:174] 0.73408 3.48299e-12 0.28723
I0621 02:49:07.227865 32183 compress_conv_layer.cu:174] 0.73408 1.04176e-12 0.206973
I0621 02:49:07.409185 32183 compress_conv_layer.cu:174] 0.73408 2.14586e-12 0.185612
I0621 02:49:07.427376 32183 compress_conv_layer.cu:174] 0.73408 1.9954e-07 0.17698
I0621 02:49:07.665567 32183 compress_conv_layer.cu:174] 0.73408 1.1708e-10 0.610305
I0621 02:49:07.673521 32183 compress_conv_layer.cu:174] 0.73408 7.14085e-11 0.351091
I0621 02:49:07.681815 32183 compress_conv_layer.cu:174] 0.73408 1.28294e-11 0.48188
I0621 02:49:07.689940 32183 compress_conv_layer.cu:174] 0.73408 1.95413e-12 0.496087
I0621 02:49:07.702504 32183 compress_conv_layer.cu:174] 0.73408 6.24068e-12 0.296533
I0621 02:49:07.724022 32183 compress_conv_layer.cu:174] 0.73408 5.98648e-14 0.309841
I0621 02:49:07.766537 32183 compress_conv_layer.cu:174] 0.73408 1.08734e-13 0.297391
I0621 02:49:07.809643 32183 compress_conv_layer.cu:174] 0.73408 1.38454e-12 0.256831
I0621 02:49:07.852479 32183 compress_conv_layer.cu:174] 0.73408 1.20325e-12 0.272659
I0621 02:49:07.895581 32183 compress_conv_layer.cu:174] 0.73408 1.26471e-12 0.361011
I0621 02:49:07.938588 32183 compress_conv_layer.cu:174] 0.73408 3.48299e-12 0.28723
I0621 02:49:08.026450 32183 compress_conv_layer.cu:174] 0.73408 1.04176e-12 0.206973
I0621 02:49:08.208896 32183 compress_conv_layer.cu:174] 0.73408 2.14586e-12 0.185612
I0621 02:49:08.227051 32183 compress_conv_layer.cu:174] 0.73408 1.9954e-07 0.17698
I0621 02:49:08.465246 32183 compress_conv_layer.cu:174] 0.73408 1.1708e-10 0.610305
I0621 02:49:08.473196 32183 compress_conv_layer.cu:174] 0.73408 7.14085e-11 0.351091
I0621 02:49:08.481436 32183 compress_conv_layer.cu:174] 0.73408 1.28294e-11 0.48188
I0621 02:49:08.489603 32183 compress_conv_layer.cu:174] 0.73408 1.95413e-12 0.496087
I0621 02:49:08.502140 32183 compress_conv_layer.cu:174] 0.73408 6.24068e-12 0.296533
I0621 02:49:08.523680 32183 compress_conv_layer.cu:174] 0.73408 5.98648e-14 0.309841
I0621 02:49:08.566232 32183 compress_conv_layer.cu:174] 0.73408 1.08734e-13 0.297391
I0621 02:49:08.609511 32183 compress_conv_layer.cu:174] 0.73408 1.38454e-12 0.256831
I0621 02:49:08.652844 32183 compress_conv_layer.cu:174] 0.73408 1.20325e-12 0.272659
I0621 02:49:08.695806 32183 compress_conv_layer.cu:174] 0.73408 1.26471e-12 0.361011
I0621 02:49:08.738400 32183 compress_conv_layer.cu:174] 0.73408 3.48299e-12 0.28723
I0621 02:49:08.824645 32183 compress_conv_layer.cu:174] 0.73408 1.04176e-12 0.206973
I0621 02:49:09.007794 32183 compress_conv_layer.cu:174] 0.73408 2.14586e-12 0.185612
I0621 02:49:09.026028 32183 compress_conv_layer.cu:174] 0.73408 1.9954e-07 0.17698
I0621 02:49:09.256300 32183 solver.cpp:219] Iteration 10000 (0.567037 iter/s, 88.1777s/50 iters), loss = 0.00687235
I0621 02:49:09.256381 32183 solver.cpp:238]     Train net output #0: loss = 0.00607898 (* 1 = 0.00607898 loss)
I0621 02:49:09.256408 32183 sgd_solver.cpp:105] Iteration 10000, lr = 0.01
I0621 02:50:20.029295 32183 solver.cpp:219] Iteration 10050 (0.706493 iter/s, 70.7721s/50 iters), loss = 0.0152696
I0621 02:50:20.029477 32183 solver.cpp:238]     Train net output #0: loss = 0.0235887 (* 1 = 0.0235887 loss)
I0621 02:50:20.029505 32183 sgd_solver.cpp:105] Iteration 10050, lr = 0.01
I0621 02:51:30.815729 32183 solver.cpp:219] Iteration 10100 (0.70636 iter/s, 70.7855s/50 iters), loss = 0.00667045
I0621 02:51:30.815871 32183 solver.cpp:238]     Train net output #0: loss = 0.00412544 (* 1 = 0.00412544 loss)
I0621 02:51:30.815896 32183 sgd_solver.cpp:105] Iteration 10100, lr = 0.01
I0621 02:52:41.581269 32183 solver.cpp:219] Iteration 10150 (0.706568 iter/s, 70.7646s/50 iters), loss = 0.011304
I0621 02:52:41.581415 32183 solver.cpp:238]     Train net output #0: loss = 0.0144093 (* 1 = 0.0144093 loss)
I0621 02:52:41.581442 32183 sgd_solver.cpp:105] Iteration 10150, lr = 0.01
I0621 02:53:52.381584 32183 solver.cpp:219] Iteration 10200 (0.706221 iter/s, 70.7994s/50 iters), loss = 0.00690551
I0621 02:53:52.381716 32183 solver.cpp:238]     Train net output #0: loss = 0.00765377 (* 1 = 0.00765377 loss)
I0621 02:53:52.381742 32183 sgd_solver.cpp:105] Iteration 10200, lr = 0.01
I0621 02:55:03.141639 32183 solver.cpp:219] Iteration 10250 (0.706622 iter/s, 70.7591s/50 iters), loss = 0.00985028
I0621 02:55:03.141793 32183 solver.cpp:238]     Train net output #0: loss = 0.00589484 (* 1 = 0.00589484 loss)
I0621 02:55:03.141819 32183 sgd_solver.cpp:105] Iteration 10250, lr = 0.01
I0621 02:56:13.901767 32183 solver.cpp:219] Iteration 10300 (0.706622 iter/s, 70.7592s/50 iters), loss = 0.00534206
I0621 02:56:13.901931 32183 solver.cpp:238]     Train net output #0: loss = 0.0107175 (* 1 = 0.0107175 loss)
I0621 02:56:13.901957 32183 sgd_solver.cpp:105] Iteration 10300, lr = 0.01
I0621 02:57:24.678555 32183 solver.cpp:219] Iteration 10350 (0.706456 iter/s, 70.7758s/50 iters), loss = 0.00539515
I0621 02:57:24.678656 32183 solver.cpp:238]     Train net output #0: loss = 0.00988495 (* 1 = 0.00988495 loss)
I0621 02:57:24.678678 32183 sgd_solver.cpp:105] Iteration 10350, lr = 0.01
I0621 02:58:35.441155 32183 solver.cpp:219] Iteration 10400 (0.706597 iter/s, 70.7617s/50 iters), loss = 0.00552213
I0621 02:58:35.441287 32183 solver.cpp:238]     Train net output #0: loss = 0.00689504 (* 1 = 0.00689504 loss)
I0621 02:58:35.441311 32183 sgd_solver.cpp:105] Iteration 10400, lr = 0.01
I0621 02:59:46.196885 32183 solver.cpp:219] Iteration 10450 (0.706666 iter/s, 70.7548s/50 iters), loss = 0.00982805
I0621 02:59:46.197034 32183 solver.cpp:238]     Train net output #0: loss = 0.00486739 (* 1 = 0.00486739 loss)
I0621 02:59:46.197062 32183 sgd_solver.cpp:105] Iteration 10450, lr = 0.01
I0621 03:00:55.564162 32183 solver.cpp:331] Iteration 10500, Testing net (#0)
I0621 03:01:10.120054 32183 solver.cpp:398]     Test net output #0: accuracy = 0.945162
I0621 03:01:10.120131 32183 solver.cpp:398]     Test net output #1: loss = 0.247658 (* 1 = 0.247658 loss)
I0621 03:01:11.531831 32183 solver.cpp:219] Iteration 10500 (0.585934 iter/s, 85.3339s/50 iters), loss = 0.0101676
I0621 03:01:11.531929 32183 solver.cpp:238]     Train net output #0: loss = 0.00590225 (* 1 = 0.00590225 loss)
I0621 03:01:11.531958 32183 sgd_solver.cpp:105] Iteration 10500, lr = 0.01
I0621 03:02:22.290287 32183 solver.cpp:219] Iteration 10550 (0.706638 iter/s, 70.7576s/50 iters), loss = 0.0123051
I0621 03:02:22.290439 32183 solver.cpp:238]     Train net output #0: loss = 0.0091748 (* 1 = 0.0091748 loss)
I0621 03:02:22.290465 32183 sgd_solver.cpp:105] Iteration 10550, lr = 0.01
I0621 03:03:33.048914 32183 solver.cpp:219] Iteration 10600 (0.706637 iter/s, 70.7577s/50 iters), loss = 0.00795682
I0621 03:03:33.049057 32183 solver.cpp:238]     Train net output #0: loss = 0.0140926 (* 1 = 0.0140926 loss)
I0621 03:03:33.049082 32183 sgd_solver.cpp:105] Iteration 10600, lr = 0.01
I0621 03:04:43.835263 32183 solver.cpp:219] Iteration 10650 (0.70636 iter/s, 70.7854s/50 iters), loss = 0.0120014
I0621 03:04:43.835444 32183 solver.cpp:238]     Train net output #0: loss = 0.00931575 (* 1 = 0.00931575 loss)
I0621 03:04:43.835470 32183 sgd_solver.cpp:105] Iteration 10650, lr = 0.01
I0621 03:05:54.604830 32183 solver.cpp:219] Iteration 10700 (0.706528 iter/s, 70.7686s/50 iters), loss = 0.00957495
I0621 03:05:54.604977 32183 solver.cpp:238]     Train net output #0: loss = 0.00734278 (* 1 = 0.00734278 loss)
I0621 03:05:54.605018 32183 sgd_solver.cpp:105] Iteration 10700, lr = 0.01
I0621 03:07:05.372426 32183 solver.cpp:219] Iteration 10750 (0.706547 iter/s, 70.7667s/50 iters), loss = 0.0104188
I0621 03:07:05.372654 32183 solver.cpp:238]     Train net output #0: loss = 0.00940512 (* 1 = 0.00940512 loss)
I0621 03:07:05.372680 32183 sgd_solver.cpp:105] Iteration 10750, lr = 0.01
I0621 03:08:16.134624 32183 solver.cpp:219] Iteration 10800 (0.706602 iter/s, 70.7612s/50 iters), loss = 0.00654721
I0621 03:08:16.134779 32183 solver.cpp:238]     Train net output #0: loss = 0.00357592 (* 1 = 0.00357592 loss)
I0621 03:08:16.134806 32183 sgd_solver.cpp:105] Iteration 10800, lr = 0.01
I0621 03:09:26.907140 32183 solver.cpp:219] Iteration 10850 (0.706498 iter/s, 70.7716s/50 iters), loss = 0.011241
I0621 03:09:26.907323 32183 solver.cpp:238]     Train net output #0: loss = 0.00574 (* 1 = 0.00574 loss)
I0621 03:09:26.907351 32183 sgd_solver.cpp:105] Iteration 10850, lr = 0.01
I0621 03:10:37.692296 32183 solver.cpp:219] Iteration 10900 (0.706372 iter/s, 70.7842s/50 iters), loss = 0.0100484
I0621 03:10:37.692432 32183 solver.cpp:238]     Train net output #0: loss = 0.0263655 (* 1 = 0.0263655 loss)
I0621 03:10:37.692457 32183 sgd_solver.cpp:105] Iteration 10900, lr = 0.01
I0621 03:11:48.457908 32183 solver.cpp:219] Iteration 10950 (0.706567 iter/s, 70.7647s/50 iters), loss = 0.00886966
I0621 03:11:48.458050 32183 solver.cpp:238]     Train net output #0: loss = 0.00582204 (* 1 = 0.00582204 loss)
I0621 03:11:48.458075 32183 sgd_solver.cpp:105] Iteration 10950, lr = 0.01
I0621 03:12:57.845690 32183 solver.cpp:331] Iteration 11000, Testing net (#0)
I0621 03:13:12.437114 32183 solver.cpp:398]     Test net output #0: accuracy = 0.937097
I0621 03:13:12.437194 32183 solver.cpp:398]     Test net output #1: loss = 0.300341 (* 1 = 0.300341 loss)
I0621 03:13:12.444584 32183 compress_conv_layer.cu:174] 0.757726 1.11367e-10 0.580609
I0621 03:13:12.453217 32183 compress_conv_layer.cu:174] 0.757726 6.79242e-11 0.333843
I0621 03:13:12.461585 32183 compress_conv_layer.cu:174] 0.757726 1.22035e-11 0.456892
I0621 03:13:12.469835 32183 compress_conv_layer.cu:174] 0.757726 1.85878e-12 0.472477
I0621 03:13:12.482808 32183 compress_conv_layer.cu:174] 0.757726 5.93618e-12 0.28133
I0621 03:13:12.505148 32183 compress_conv_layer.cu:174] 0.757726 5.69438e-14 0.294239
I0621 03:13:12.548286 32183 compress_conv_layer.cu:174] 0.757726 1.03428e-13 0.281468
I0621 03:13:12.591258 32183 compress_conv_layer.cu:174] 0.757726 1.31698e-12 0.244253
I0621 03:13:12.634096 32183 compress_conv_layer.cu:174] 0.757726 1.14454e-12 0.258173
I0621 03:13:12.677281 32183 compress_conv_layer.cu:174] 0.757726 1.203e-12 0.342988
I0621 03:13:12.720362 32183 compress_conv_layer.cu:174] 0.757726 3.31305e-12 0.27311
I0621 03:13:12.808220 32183 compress_conv_layer.cu:174] 0.757726 9.9093e-13 0.196875
I0621 03:13:12.992822 32183 compress_conv_layer.cu:174] 0.757726 2.04116e-12 0.17654
I0621 03:13:13.011162 32183 compress_conv_layer.cu:174] 0.757726 1.89804e-07 0.177354
I0621 03:13:13.249478 32183 compress_conv_layer.cu:174] 0.757726 1.11367e-10 0.580609
I0621 03:13:13.257465 32183 compress_conv_layer.cu:174] 0.757726 6.79242e-11 0.333843
I0621 03:13:13.265703 32183 compress_conv_layer.cu:174] 0.757726 1.22035e-11 0.456892
I0621 03:13:13.273829 32183 compress_conv_layer.cu:174] 0.757726 1.85878e-12 0.472477
I0621 03:13:13.286337 32183 compress_conv_layer.cu:174] 0.757726 5.93618e-12 0.28133
I0621 03:13:13.307960 32183 compress_conv_layer.cu:174] 0.757726 5.69438e-14 0.294239
I0621 03:13:13.350230 32183 compress_conv_layer.cu:174] 0.757726 1.03428e-13 0.281468
I0621 03:13:13.393364 32183 compress_conv_layer.cu:174] 0.757726 1.31698e-12 0.244253
I0621 03:13:13.436769 32183 compress_conv_layer.cu:174] 0.757726 1.14454e-12 0.258173
I0621 03:13:13.479745 32183 compress_conv_layer.cu:174] 0.757726 1.203e-12 0.342988
I0621 03:13:13.522707 32183 compress_conv_layer.cu:174] 0.757726 3.31305e-12 0.27311
I0621 03:13:13.609261 32183 compress_conv_layer.cu:174] 0.757726 9.9093e-13 0.196875
I0621 03:13:13.790908 32183 compress_conv_layer.cu:174] 0.757726 2.04116e-12 0.17654
I0621 03:13:13.809154 32183 compress_conv_layer.cu:174] 0.757726 1.89804e-07 0.177354
I0621 03:13:14.047333 32183 compress_conv_layer.cu:174] 0.757726 1.11367e-10 0.580609
I0621 03:13:14.055311 32183 compress_conv_layer.cu:174] 0.757726 6.79242e-11 0.333843
I0621 03:13:14.063542 32183 compress_conv_layer.cu:174] 0.757726 1.22035e-11 0.456892
I0621 03:13:14.071702 32183 compress_conv_layer.cu:174] 0.757726 1.85878e-12 0.472477
I0621 03:13:14.084231 32183 compress_conv_layer.cu:174] 0.757726 5.93618e-12 0.28133
I0621 03:13:14.106145 32183 compress_conv_layer.cu:174] 0.757726 5.69438e-14 0.294239
I0621 03:13:14.148838 32183 compress_conv_layer.cu:174] 0.757726 1.03428e-13 0.281468
I0621 03:13:14.192095 32183 compress_conv_layer.cu:174] 0.757726 1.31698e-12 0.244253
I0621 03:13:14.235308 32183 compress_conv_layer.cu:174] 0.757726 1.14454e-12 0.258173
I0621 03:13:14.278209 32183 compress_conv_layer.cu:174] 0.757726 1.203e-12 0.342988
I0621 03:13:14.320997 32183 compress_conv_layer.cu:174] 0.757726 3.31305e-12 0.27311
I0621 03:13:14.407315 32183 compress_conv_layer.cu:174] 0.757726 9.9093e-13 0.196875
I0621 03:13:14.589160 32183 compress_conv_layer.cu:174] 0.757726 2.04116e-12 0.17654
I0621 03:13:14.607332 32183 compress_conv_layer.cu:174] 0.757726 1.89804e-07 0.177354
I0621 03:13:14.845427 32183 compress_conv_layer.cu:174] 0.757726 1.11367e-10 0.580609
I0621 03:13:14.853391 32183 compress_conv_layer.cu:174] 0.757726 6.79242e-11 0.333843
I0621 03:13:14.861608 32183 compress_conv_layer.cu:174] 0.757726 1.22035e-11 0.456892
I0621 03:13:14.869740 32183 compress_conv_layer.cu:174] 0.757726 1.85878e-12 0.472477
I0621 03:13:14.882267 32183 compress_conv_layer.cu:174] 0.757726 5.93618e-12 0.28133
I0621 03:13:14.903903 32183 compress_conv_layer.cu:174] 0.757726 5.69438e-14 0.294239
I0621 03:13:14.946285 32183 compress_conv_layer.cu:174] 0.757726 1.03428e-13 0.281468
I0621 03:13:14.989213 32183 compress_conv_layer.cu:174] 0.757726 1.31698e-12 0.244253
I0621 03:13:15.032364 32183 compress_conv_layer.cu:174] 0.757726 1.14454e-12 0.258173
I0621 03:13:15.075734 32183 compress_conv_layer.cu:174] 0.757726 1.203e-12 0.342988
I0621 03:13:15.119158 32183 compress_conv_layer.cu:174] 0.757726 3.31305e-12 0.27311
I0621 03:13:15.205994 32183 compress_conv_layer.cu:174] 0.757726 9.9093e-13 0.196875
I0621 03:13:15.388012 32183 compress_conv_layer.cu:174] 0.757726 2.04116e-12 0.17654
I0621 03:13:15.406276 32183 compress_conv_layer.cu:174] 0.757726 1.89804e-07 0.177354
I0621 03:13:15.644428 32183 compress_conv_layer.cu:174] 0.757726 1.11367e-10 0.580609
I0621 03:13:15.652403 32183 compress_conv_layer.cu:174] 0.757726 6.79242e-11 0.333843
I0621 03:13:15.660653 32183 compress_conv_layer.cu:174] 0.757726 1.22035e-11 0.456892
I0621 03:13:15.668771 32183 compress_conv_layer.cu:174] 0.757726 1.85878e-12 0.472477
I0621 03:13:15.681277 32183 compress_conv_layer.cu:174] 0.757726 5.93618e-12 0.28133
I0621 03:13:15.702968 32183 compress_conv_layer.cu:174] 0.757726 5.69438e-14 0.294239
I0621 03:13:15.745283 32183 compress_conv_layer.cu:174] 0.757726 1.03428e-13 0.281468
I0621 03:13:15.788112 32183 compress_conv_layer.cu:174] 0.757726 1.31698e-12 0.244253
I0621 03:13:15.830926 32183 compress_conv_layer.cu:174] 0.757726 1.14454e-12 0.258173
I0621 03:13:15.873842 32183 compress_conv_layer.cu:174] 0.757726 1.203e-12 0.342988
I0621 03:13:15.916944 32183 compress_conv_layer.cu:174] 0.757726 3.31305e-12 0.27311
I0621 03:13:16.003790 32183 compress_conv_layer.cu:174] 0.757726 9.9093e-13 0.196875
I0621 03:13:16.185694 32183 compress_conv_layer.cu:174] 0.757726 2.04116e-12 0.17654
I0621 03:13:16.203919 32183 compress_conv_layer.cu:174] 0.757726 1.89804e-07 0.177354
I0621 03:13:16.434303 32183 solver.cpp:219] Iteration 11000 (0.568341 iter/s, 87.9753s/50 iters), loss = 0.010182
I0621 03:13:16.434377 32183 solver.cpp:238]     Train net output #0: loss = 0.005944 (* 1 = 0.005944 loss)
I0621 03:13:16.434403 32183 sgd_solver.cpp:105] Iteration 11000, lr = 0.01
I0621 03:14:27.224159 32183 solver.cpp:219] Iteration 11050 (0.706324 iter/s, 70.789s/50 iters), loss = 0.0104276
I0621 03:14:27.224380 32183 solver.cpp:238]     Train net output #0: loss = 0.0109951 (* 1 = 0.0109951 loss)
I0621 03:14:27.224412 32183 sgd_solver.cpp:105] Iteration 11050, lr = 0.01
I0621 03:15:37.995301 32183 solver.cpp:219] Iteration 11100 (0.706512 iter/s, 70.7702s/50 iters), loss = 0.0143726
I0621 03:15:37.995445 32183 solver.cpp:238]     Train net output #0: loss = 0.00714577 (* 1 = 0.00714577 loss)
I0621 03:15:37.995471 32183 sgd_solver.cpp:105] Iteration 11100, lr = 0.01
I0621 03:16:48.770869 32183 solver.cpp:219] Iteration 11150 (0.706467 iter/s, 70.7747s/50 iters), loss = 0.0189173
I0621 03:16:48.771009 32183 solver.cpp:238]     Train net output #0: loss = 0.0248126 (* 1 = 0.0248126 loss)
I0621 03:16:48.771035 32183 sgd_solver.cpp:105] Iteration 11150, lr = 0.01
I0621 03:17:59.540127 32183 solver.cpp:219] Iteration 11200 (0.706531 iter/s, 70.7683s/50 iters), loss = 0.0153249
I0621 03:17:59.540274 32183 solver.cpp:238]     Train net output #0: loss = 0.0169482 (* 1 = 0.0169482 loss)
I0621 03:17:59.540305 32183 sgd_solver.cpp:105] Iteration 11200, lr = 0.01
I0621 03:19:10.310003 32183 solver.cpp:219] Iteration 11250 (0.706524 iter/s, 70.769s/50 iters), loss = 0.00786212
I0621 03:19:10.310151 32183 solver.cpp:238]     Train net output #0: loss = 0.00695482 (* 1 = 0.00695482 loss)
I0621 03:19:10.310181 32183 sgd_solver.cpp:105] Iteration 11250, lr = 0.01
I0621 03:20:21.095393 32183 solver.cpp:219] Iteration 11300 (0.706369 iter/s, 70.7845s/50 iters), loss = 0.0111329
I0621 03:20:21.095537 32183 solver.cpp:238]     Train net output #0: loss = 0.0181641 (* 1 = 0.0181641 loss)
I0621 03:20:21.095564 32183 sgd_solver.cpp:105] Iteration 11300, lr = 0.01
I0621 03:21:31.860656 32183 solver.cpp:219] Iteration 11350 (0.706571 iter/s, 70.7643s/50 iters), loss = 0.00829071
I0621 03:21:31.860797 32183 solver.cpp:238]     Train net output #0: loss = 0.00799568 (* 1 = 0.00799568 loss)
I0621 03:21:31.860824 32183 sgd_solver.cpp:105] Iteration 11350, lr = 0.01
I0621 03:22:42.636838 32183 solver.cpp:219] Iteration 11400 (0.706462 iter/s, 70.7752s/50 iters), loss = 0.00692526
I0621 03:22:42.636991 32183 solver.cpp:238]     Train net output #0: loss = 0.00758461 (* 1 = 0.00758461 loss)
I0621 03:22:42.637017 32183 sgd_solver.cpp:105] Iteration 11400, lr = 0.01
I0621 03:23:53.416321 32183 solver.cpp:219] Iteration 11450 (0.706429 iter/s, 70.7785s/50 iters), loss = 0.0112712
I0621 03:23:53.416509 32183 solver.cpp:238]     Train net output #0: loss = 0.0208959 (* 1 = 0.0208959 loss)
I0621 03:23:53.416551 32183 sgd_solver.cpp:105] Iteration 11450, lr = 0.01
I0621 03:25:02.780701 32183 solver.cpp:331] Iteration 11500, Testing net (#0)
I0621 03:25:17.352133 32183 solver.cpp:398]     Test net output #0: accuracy = 0.897581
I0621 03:25:17.352214 32183 solver.cpp:398]     Test net output #1: loss = 0.40791 (* 1 = 0.40791 loss)
I0621 03:25:18.762759 32183 solver.cpp:219] Iteration 11500 (0.585856 iter/s, 85.3453s/50 iters), loss = 0.0109891
I0621 03:25:18.762848 32183 solver.cpp:238]     Train net output #0: loss = 0.0142062 (* 1 = 0.0142062 loss)
I0621 03:25:18.762874 32183 sgd_solver.cpp:105] Iteration 11500, lr = 0.01
I0621 03:26:29.536443 32183 solver.cpp:219] Iteration 11550 (0.706486 iter/s, 70.7728s/50 iters), loss = 0.00981959
I0621 03:26:29.536579 32183 solver.cpp:238]     Train net output #0: loss = 0.00977225 (* 1 = 0.00977225 loss)
I0621 03:26:29.536604 32183 sgd_solver.cpp:105] Iteration 11550, lr = 0.01
I0621 03:27:40.315222 32183 solver.cpp:219] Iteration 11600 (0.706436 iter/s, 70.7778s/50 iters), loss = 0.0111988
I0621 03:27:40.315421 32183 solver.cpp:238]     Train net output #0: loss = 0.00759363 (* 1 = 0.00759363 loss)
I0621 03:27:40.315448 32183 sgd_solver.cpp:105] Iteration 11600, lr = 0.01
I0621 03:28:51.099194 32183 solver.cpp:219] Iteration 11650 (0.706385 iter/s, 70.7829s/50 iters), loss = 0.00694135
I0621 03:28:51.099347 32183 solver.cpp:238]     Train net output #0: loss = 0.0145579 (* 1 = 0.0145579 loss)
I0621 03:28:51.099380 32183 sgd_solver.cpp:105] Iteration 11650, lr = 0.01
I0621 03:30:01.882766 32183 solver.cpp:219] Iteration 11700 (0.706388 iter/s, 70.7826s/50 iters), loss = 0.0116036
I0621 03:30:01.882926 32183 solver.cpp:238]     Train net output #0: loss = 0.0165461 (* 1 = 0.0165461 loss)
I0621 03:30:01.882953 32183 sgd_solver.cpp:105] Iteration 11700, lr = 0.01
I0621 03:31:12.655876 32183 solver.cpp:219] Iteration 11750 (0.706493 iter/s, 70.7721s/50 iters), loss = 0.00701031
I0621 03:31:12.656045 32183 solver.cpp:238]     Train net output #0: loss = 0.00773916 (* 1 = 0.00773916 loss)
I0621 03:31:12.656071 32183 sgd_solver.cpp:105] Iteration 11750, lr = 0.01
I0621 03:32:23.447463 32183 solver.cpp:219] Iteration 11800 (0.706309 iter/s, 70.7906s/50 iters), loss = 0.00859976
I0621 03:32:23.447630 32183 solver.cpp:238]     Train net output #0: loss = 0.010886 (* 1 = 0.010886 loss)
I0621 03:32:23.447656 32183 sgd_solver.cpp:105] Iteration 11800, lr = 0.01
I0621 03:33:34.245476 32183 solver.cpp:219] Iteration 11850 (0.706244 iter/s, 70.797s/50 iters), loss = 0.00890544
I0621 03:33:34.245640 32183 solver.cpp:238]     Train net output #0: loss = 0.00861042 (* 1 = 0.00861042 loss)
I0621 03:33:34.245667 32183 sgd_solver.cpp:105] Iteration 11850, lr = 0.01
I0621 03:34:45.056485 32183 solver.cpp:219] Iteration 11900 (0.706115 iter/s, 70.81s/50 iters), loss = 0.0090733
I0621 03:34:45.056679 32183 solver.cpp:238]     Train net output #0: loss = 0.00667071 (* 1 = 0.00667071 loss)
I0621 03:34:45.056706 32183 sgd_solver.cpp:105] Iteration 11900, lr = 0.01
I0621 03:35:55.858958 32183 solver.cpp:219] Iteration 11950 (0.7062 iter/s, 70.8015s/50 iters), loss = 0.00871357
I0621 03:35:55.859112 32183 solver.cpp:238]     Train net output #0: loss = 0.00894593 (* 1 = 0.00894593 loss)
I0621 03:35:55.859138 32183 sgd_solver.cpp:105] Iteration 11950, lr = 0.01
I0621 03:37:05.245299 32183 solver.cpp:331] Iteration 12000, Testing net (#0)
I0621 03:37:16.678093 32183 blocking_queue.cpp:49] Waiting for data
I0621 03:37:19.811019 32183 solver.cpp:398]     Test net output #0: accuracy = 0.930646
I0621 03:37:19.811101 32183 solver.cpp:398]     Test net output #1: loss = 0.306172 (* 1 = 0.306172 loss)
I0621 03:37:19.818506 32183 compress_conv_layer.cu:174] 0.779618 1.05933e-10 0.553304
I0621 03:37:19.827172 32183 compress_conv_layer.cu:174] 0.779618 6.461e-11 0.318364
I0621 03:37:19.835472 32183 compress_conv_layer.cu:174] 0.779618 1.1608e-11 0.435644
I0621 03:37:19.843758 32183 compress_conv_layer.cu:174] 0.779618 1.76809e-12 0.449277
I0621 03:37:19.856657 32183 compress_conv_layer.cu:174] 0.779618 5.64654e-12 0.268414
I0621 03:37:19.878911 32183 compress_conv_layer.cu:174] 0.779618 5.41653e-14 0.280632
I0621 03:37:19.922559 32183 compress_conv_layer.cu:174] 0.779618 9.83817e-14 0.267459
I0621 03:37:19.966212 32183 compress_conv_layer.cu:174] 0.779618 1.25272e-12 0.232228
I0621 03:37:20.009924 32183 compress_conv_layer.cu:174] 0.779618 1.08869e-12 0.245144
I0621 03:37:20.053588 32183 compress_conv_layer.cu:174] 0.779618 1.1443e-12 0.326482
I0621 03:37:20.097200 32183 compress_conv_layer.cu:174] 0.779618 3.15139e-12 0.259619
I0621 03:37:20.185734 32183 compress_conv_layer.cu:174] 0.779618 9.4258e-13 0.187343
I0621 03:37:20.370239 32183 compress_conv_layer.cu:174] 0.779618 1.94157e-12 0.167923
I0621 03:37:20.388440 32183 compress_conv_layer.cu:174] 0.779618 1.80543e-07 0.181075
I0621 03:37:20.626746 32183 compress_conv_layer.cu:174] 0.779618 1.05933e-10 0.553304
I0621 03:37:20.634663 32183 compress_conv_layer.cu:174] 0.779618 6.461e-11 0.318364
I0621 03:37:20.642886 32183 compress_conv_layer.cu:174] 0.779618 1.1608e-11 0.435644
I0621 03:37:20.650987 32183 compress_conv_layer.cu:174] 0.779618 1.76809e-12 0.449277
I0621 03:37:20.663528 32183 compress_conv_layer.cu:174] 0.779618 5.64654e-12 0.268414
I0621 03:37:20.685051 32183 compress_conv_layer.cu:174] 0.779618 5.41653e-14 0.280632
I0621 03:37:20.727517 32183 compress_conv_layer.cu:174] 0.779618 9.83817e-14 0.267459
I0621 03:37:20.770547 32183 compress_conv_layer.cu:174] 0.779618 1.25272e-12 0.232228
I0621 03:37:20.813361 32183 compress_conv_layer.cu:174] 0.779618 1.08869e-12 0.245144
I0621 03:37:20.856071 32183 compress_conv_layer.cu:174] 0.779618 1.1443e-12 0.326482
I0621 03:37:20.899206 32183 compress_conv_layer.cu:174] 0.779618 3.15139e-12 0.259619
I0621 03:37:20.985785 32183 compress_conv_layer.cu:174] 0.779618 9.4258e-13 0.187343
I0621 03:37:21.167434 32183 compress_conv_layer.cu:174] 0.779618 1.94157e-12 0.167923
I0621 03:37:21.185696 32183 compress_conv_layer.cu:174] 0.779618 1.80543e-07 0.181075
I0621 03:37:21.424098 32183 compress_conv_layer.cu:174] 0.779618 1.05933e-10 0.553304
I0621 03:37:21.432059 32183 compress_conv_layer.cu:174] 0.779618 6.461e-11 0.318364
I0621 03:37:21.440316 32183 compress_conv_layer.cu:174] 0.779618 1.1608e-11 0.435644
I0621 03:37:21.448467 32183 compress_conv_layer.cu:174] 0.779618 1.76809e-12 0.449277
I0621 03:37:21.461048 32183 compress_conv_layer.cu:174] 0.779618 5.64654e-12 0.268414
I0621 03:37:21.482611 32183 compress_conv_layer.cu:174] 0.779618 5.41653e-14 0.280632
I0621 03:37:21.525130 32183 compress_conv_layer.cu:174] 0.779618 9.83817e-14 0.267459
I0621 03:37:21.568464 32183 compress_conv_layer.cu:174] 0.779618 1.25272e-12 0.232228
I0621 03:37:21.612079 32183 compress_conv_layer.cu:174] 0.779618 1.08869e-12 0.245144
I0621 03:37:21.655187 32183 compress_conv_layer.cu:174] 0.779618 1.1443e-12 0.326482
I0621 03:37:21.697942 32183 compress_conv_layer.cu:174] 0.779618 3.15139e-12 0.259619
I0621 03:37:21.784265 32183 compress_conv_layer.cu:174] 0.779618 9.4258e-13 0.187343
I0621 03:37:21.965414 32183 compress_conv_layer.cu:174] 0.779618 1.94157e-12 0.167923
I0621 03:37:21.983713 32183 compress_conv_layer.cu:174] 0.779618 1.80543e-07 0.181075
I0621 03:37:22.222069 32183 compress_conv_layer.cu:174] 0.779618 1.05933e-10 0.553304
I0621 03:37:22.230038 32183 compress_conv_layer.cu:174] 0.779618 6.461e-11 0.318364
I0621 03:37:22.238263 32183 compress_conv_layer.cu:174] 0.779618 1.1608e-11 0.435644
I0621 03:37:22.246440 32183 compress_conv_layer.cu:174] 0.779618 1.76809e-12 0.449277
I0621 03:37:22.258988 32183 compress_conv_layer.cu:174] 0.779618 5.64654e-12 0.268414
I0621 03:37:22.280623 32183 compress_conv_layer.cu:174] 0.779618 5.41653e-14 0.280632
I0621 03:37:22.323031 32183 compress_conv_layer.cu:174] 0.779618 9.83817e-14 0.267459
I0621 03:37:22.365847 32183 compress_conv_layer.cu:174] 0.779618 1.25272e-12 0.232228
I0621 03:37:22.408666 32183 compress_conv_layer.cu:174] 0.779618 1.08869e-12 0.245144
I0621 03:37:22.451328 32183 compress_conv_layer.cu:174] 0.779618 1.1443e-12 0.326482
I0621 03:37:22.493973 32183 compress_conv_layer.cu:174] 0.779618 3.15139e-12 0.259619
I0621 03:37:22.580219 32183 compress_conv_layer.cu:174] 0.779618 9.4258e-13 0.187343
I0621 03:37:22.761554 32183 compress_conv_layer.cu:174] 0.779618 1.94157e-12 0.167923
I0621 03:37:22.779875 32183 compress_conv_layer.cu:174] 0.779618 1.80543e-07 0.181075
I0621 03:37:23.018129 32183 compress_conv_layer.cu:174] 0.779618 1.05933e-10 0.553304
I0621 03:37:23.026115 32183 compress_conv_layer.cu:174] 0.779618 6.461e-11 0.318364
I0621 03:37:23.034377 32183 compress_conv_layer.cu:174] 0.779618 1.1608e-11 0.435644
I0621 03:37:23.042516 32183 compress_conv_layer.cu:174] 0.779618 1.76809e-12 0.449277
I0621 03:37:23.055063 32183 compress_conv_layer.cu:174] 0.779618 5.64654e-12 0.268414
I0621 03:37:23.076856 32183 compress_conv_layer.cu:174] 0.779618 5.41653e-14 0.280632
I0621 03:37:23.119498 32183 compress_conv_layer.cu:174] 0.779618 9.83817e-14 0.267459
I0621 03:37:23.162955 32183 compress_conv_layer.cu:174] 0.779618 1.25272e-12 0.232228
I0621 03:37:23.206349 32183 compress_conv_layer.cu:174] 0.779618 1.08869e-12 0.245144
I0621 03:37:23.249671 32183 compress_conv_layer.cu:174] 0.779618 1.1443e-12 0.326482
I0621 03:37:23.292676 32183 compress_conv_layer.cu:174] 0.779618 3.15139e-12 0.259619
I0621 03:37:23.378852 32183 compress_conv_layer.cu:174] 0.779618 9.4258e-13 0.187343
I0621 03:37:23.560508 32183 compress_conv_layer.cu:174] 0.779618 1.94157e-12 0.167923
I0621 03:37:23.578822 32183 compress_conv_layer.cu:174] 0.779618 1.80543e-07 0.181075
I0621 03:37:23.809192 32183 solver.cpp:219] Iteration 12000 (0.568511 iter/s, 87.9491s/50 iters), loss = 0.0128086
I0621 03:37:23.809267 32183 solver.cpp:238]     Train net output #0: loss = 0.0138922 (* 1 = 0.0138922 loss)
I0621 03:37:23.809294 32183 sgd_solver.cpp:105] Iteration 12000, lr = 0.01
I0621 03:38:34.590837 32183 solver.cpp:219] Iteration 12050 (0.706406 iter/s, 70.7808s/50 iters), loss = 0.0156093
I0621 03:38:34.591060 32183 solver.cpp:238]     Train net output #0: loss = 0.0404657 (* 1 = 0.0404657 loss)
I0621 03:38:34.591092 32183 sgd_solver.cpp:105] Iteration 12050, lr = 0.01
I0621 03:39:45.365418 32183 solver.cpp:219] Iteration 12100 (0.706478 iter/s, 70.7736s/50 iters), loss = 0.119106
I0621 03:39:45.365607 32183 solver.cpp:238]     Train net output #0: loss = 0.114188 (* 1 = 0.114188 loss)
I0621 03:39:45.365638 32183 sgd_solver.cpp:105] Iteration 12100, lr = 0.01
I0621 03:40:56.160421 32183 solver.cpp:219] Iteration 12150 (0.706274 iter/s, 70.7941s/50 iters), loss = 0.2124
I0621 03:40:56.160997 32183 solver.cpp:238]     Train net output #0: loss = 0.440223 (* 1 = 0.440223 loss)
I0621 03:40:56.161025 32183 sgd_solver.cpp:105] Iteration 12150, lr = 0.01
I0621 03:42:06.953467 32183 solver.cpp:219] Iteration 12200 (0.706297 iter/s, 70.7917s/50 iters), loss = 0.147317
I0621 03:42:06.953615 32183 solver.cpp:238]     Train net output #0: loss = 0.179204 (* 1 = 0.179204 loss)
I0621 03:42:06.953646 32183 sgd_solver.cpp:105] Iteration 12200, lr = 0.01
I0621 03:43:17.728386 32183 solver.cpp:219] Iteration 12250 (0.706474 iter/s, 70.774s/50 iters), loss = 0.103244
I0621 03:43:17.728535 32183 solver.cpp:238]     Train net output #0: loss = 0.0588049 (* 1 = 0.0588049 loss)
I0621 03:43:17.728562 32183 sgd_solver.cpp:105] Iteration 12250, lr = 0.01
I0621 03:44:28.505035 32183 solver.cpp:219] Iteration 12300 (0.706456 iter/s, 70.7758s/50 iters), loss = 0.0674824
I0621 03:44:28.505175 32183 solver.cpp:238]     Train net output #0: loss = 0.166071 (* 1 = 0.166071 loss)
I0621 03:44:28.505201 32183 sgd_solver.cpp:105] Iteration 12300, lr = 0.01
I0621 03:45:39.288501 32183 solver.cpp:219] Iteration 12350 (0.706388 iter/s, 70.7826s/50 iters), loss = 0.0309436
I0621 03:45:39.288646 32183 solver.cpp:238]     Train net output #0: loss = 0.0311335 (* 1 = 0.0311335 loss)
I0621 03:45:39.288672 32183 sgd_solver.cpp:105] Iteration 12350, lr = 0.01
I0621 03:46:50.073909 32183 solver.cpp:219] Iteration 12400 (0.706369 iter/s, 70.7845s/50 iters), loss = 0.0267215
I0621 03:46:50.074043 32183 solver.cpp:238]     Train net output #0: loss = 0.0197535 (* 1 = 0.0197535 loss)
I0621 03:46:50.074076 32183 sgd_solver.cpp:105] Iteration 12400, lr = 0.01
I0621 03:48:00.863216 32183 solver.cpp:219] Iteration 12450 (0.70633 iter/s, 70.7884s/50 iters), loss = 0.0262661
I0621 03:48:00.863365 32183 solver.cpp:238]     Train net output #0: loss = 0.020963 (* 1 = 0.020963 loss)
I0621 03:48:00.863394 32183 sgd_solver.cpp:105] Iteration 12450, lr = 0.01
I0621 03:49:10.227382 32183 solver.cpp:331] Iteration 12500, Testing net (#0)
I0621 03:49:24.793658 32183 solver.cpp:398]     Test net output #0: accuracy = 0.933871
I0621 03:49:24.793745 32183 solver.cpp:398]     Test net output #1: loss = 0.306477 (* 1 = 0.306477 loss)
I0621 03:49:26.204751 32183 solver.cpp:219] Iteration 12500 (0.585888 iter/s, 85.3405s/50 iters), loss = 0.0147486
I0621 03:49:26.204854 32183 solver.cpp:238]     Train net output #0: loss = 0.015195 (* 1 = 0.015195 loss)
I0621 03:49:26.204885 32183 sgd_solver.cpp:105] Iteration 12500, lr = 0.01
I0621 03:50:36.990399 32183 solver.cpp:219] Iteration 12550 (0.706366 iter/s, 70.7848s/50 iters), loss = 0.00862774
I0621 03:50:36.990598 32183 solver.cpp:238]     Train net output #0: loss = 0.00786145 (* 1 = 0.00786145 loss)
I0621 03:50:36.990631 32183 sgd_solver.cpp:105] Iteration 12550, lr = 0.01
I0621 03:51:47.781447 32183 solver.cpp:219] Iteration 12600 (0.706313 iter/s, 70.7901s/50 iters), loss = 0.0276393
I0621 03:51:47.781603 32183 solver.cpp:238]     Train net output #0: loss = 0.0479744 (* 1 = 0.0479744 loss)
I0621 03:51:47.781630 32183 sgd_solver.cpp:105] Iteration 12600, lr = 0.01
I0621 03:52:58.562221 32183 solver.cpp:219] Iteration 12650 (0.706415 iter/s, 70.7799s/50 iters), loss = 0.0109317
I0621 03:52:58.562362 32183 solver.cpp:238]     Train net output #0: loss = 0.00967125 (* 1 = 0.00967125 loss)
I0621 03:52:58.562389 32183 sgd_solver.cpp:105] Iteration 12650, lr = 0.01
I0621 03:54:09.334281 32183 solver.cpp:219] Iteration 12700 (0.706502 iter/s, 70.7712s/50 iters), loss = 0.0174588
I0621 03:54:09.334461 32183 solver.cpp:238]     Train net output #0: loss = 0.0326451 (* 1 = 0.0326451 loss)
I0621 03:54:09.334487 32183 sgd_solver.cpp:105] Iteration 12700, lr = 0.01
I0621 03:55:20.110203 32183 solver.cpp:219] Iteration 12750 (0.706464 iter/s, 70.775s/50 iters), loss = 0.0114167
I0621 03:55:20.110802 32183 solver.cpp:238]     Train net output #0: loss = 0.00621573 (* 1 = 0.00621573 loss)
I0621 03:55:20.110829 32183 sgd_solver.cpp:105] Iteration 12750, lr = 0.01
I0621 03:56:30.887668 32183 solver.cpp:219] Iteration 12800 (0.706453 iter/s, 70.7761s/50 iters), loss = 0.00880319
I0621 03:56:30.887812 32183 solver.cpp:238]     Train net output #0: loss = 0.00730159 (* 1 = 0.00730159 loss)
I0621 03:56:30.887838 32183 sgd_solver.cpp:105] Iteration 12800, lr = 0.01
I0621 03:57:41.653240 32183 solver.cpp:219] Iteration 12850 (0.706567 iter/s, 70.7647s/50 iters), loss = 0.00579652
I0621 03:57:41.653388 32183 solver.cpp:238]     Train net output #0: loss = 0.00434539 (* 1 = 0.00434539 loss)
I0621 03:57:41.653419 32183 sgd_solver.cpp:105] Iteration 12850, lr = 0.01
I0621 03:58:52.425463 32183 solver.cpp:219] Iteration 12900 (0.706501 iter/s, 70.7713s/50 iters), loss = 0.0095071
I0621 03:58:52.425619 32183 solver.cpp:238]     Train net output #0: loss = 0.00792782 (* 1 = 0.00792782 loss)
I0621 03:58:52.425645 32183 sgd_solver.cpp:105] Iteration 12900, lr = 0.01
I0621 04:00:03.219014 32183 solver.cpp:219] Iteration 12950 (0.706288 iter/s, 70.7927s/50 iters), loss = 0.0172161
I0621 04:00:03.219173 32183 solver.cpp:238]     Train net output #0: loss = 0.0123898 (* 1 = 0.0123898 loss)
I0621 04:00:03.219200 32183 sgd_solver.cpp:105] Iteration 12950, lr = 0.01
I0621 04:01:12.582475 32183 solver.cpp:331] Iteration 13000, Testing net (#0)
I0621 04:01:27.156949 32183 solver.cpp:398]     Test net output #0: accuracy = 0.942742
I0621 04:01:27.157028 32183 solver.cpp:398]     Test net output #1: loss = 0.24251 (* 1 = 0.24251 loss)
I0621 04:01:27.164518 32183 compress_conv_layer.cu:174] 0.8 1.00764e-10 0.535445
I0621 04:01:27.173187 32183 compress_conv_layer.cu:174] 0.8 6.14575e-11 0.305002
I0621 04:01:27.181520 32183 compress_conv_layer.cu:174] 0.8 1.10416e-11 0.422049
I0621 04:01:27.189826 32183 compress_conv_layer.cu:174] 0.8 1.68182e-12 0.427229
I0621 04:01:27.202657 32183 compress_conv_layer.cu:174] 0.8 5.37102e-12 0.264023
I0621 04:01:27.224807 32183 compress_conv_layer.cu:174] 0.8 5.15224e-14 0.275579
I0621 04:01:27.268182 32183 compress_conv_layer.cu:174] 0.8 9.35814e-14 0.26547
I0621 04:01:27.311379 32183 compress_conv_layer.cu:174] 0.8 1.1916e-12 0.224078
I0621 04:01:27.354894 32183 compress_conv_layer.cu:174] 0.8 1.03557e-12 0.236085
I0621 04:01:27.398419 32183 compress_conv_layer.cu:174] 0.8 1.08847e-12 0.308934
I0621 04:01:27.441366 32183 compress_conv_layer.cu:174] 0.8 2.99763e-12 0.246157
I0621 04:01:27.529168 32183 compress_conv_layer.cu:174] 0.8 8.96588e-13 0.177564
I0621 04:01:27.713234 32183 compress_conv_layer.cu:174] 0.8 1.84683e-12 0.159728
I0621 04:01:27.731572 32183 compress_conv_layer.cu:174] 0.8 1.71733e-07 0.193701
I0621 04:01:27.969918 32183 compress_conv_layer.cu:174] 0.8 1.00764e-10 0.535445
I0621 04:01:27.977917 32183 compress_conv_layer.cu:174] 0.8 6.14575e-11 0.305002
I0621 04:01:27.986181 32183 compress_conv_layer.cu:174] 0.8 1.10416e-11 0.422049
I0621 04:01:27.994374 32183 compress_conv_layer.cu:174] 0.8 1.68182e-12 0.427229
I0621 04:01:28.008419 32183 compress_conv_layer.cu:174] 0.8 5.37102e-12 0.264023
I0621 04:01:28.030236 32183 compress_conv_layer.cu:174] 0.8 5.15224e-14 0.275579
I0621 04:01:28.072932 32183 compress_conv_layer.cu:174] 0.8 9.35814e-14 0.26547
I0621 04:01:28.116406 32183 compress_conv_layer.cu:174] 0.8 1.1916e-12 0.224078
I0621 04:01:28.159914 32183 compress_conv_layer.cu:174] 0.8 1.03557e-12 0.236085
I0621 04:01:28.203233 32183 compress_conv_layer.cu:174] 0.8 1.08847e-12 0.308934
I0621 04:01:28.246136 32183 compress_conv_layer.cu:174] 0.8 2.99763e-12 0.246157
I0621 04:01:28.333031 32183 compress_conv_layer.cu:174] 0.8 8.96588e-13 0.177564
I0621 04:01:28.514077 32183 compress_conv_layer.cu:174] 0.8 1.84683e-12 0.159728
I0621 04:01:28.532320 32183 compress_conv_layer.cu:174] 0.8 1.71733e-07 0.193701
I0621 04:01:28.770462 32183 compress_conv_layer.cu:174] 0.8 1.00764e-10 0.535445
I0621 04:01:28.778420 32183 compress_conv_layer.cu:174] 0.8 6.14575e-11 0.305002
I0621 04:01:28.786695 32183 compress_conv_layer.cu:174] 0.8 1.10416e-11 0.422049
I0621 04:01:28.794816 32183 compress_conv_layer.cu:174] 0.8 1.68182e-12 0.427229
I0621 04:01:28.807394 32183 compress_conv_layer.cu:174] 0.8 5.37102e-12 0.264023
I0621 04:01:28.829186 32183 compress_conv_layer.cu:174] 0.8 5.15224e-14 0.275579
I0621 04:01:28.871687 32183 compress_conv_layer.cu:174] 0.8 9.35814e-14 0.26547
I0621 04:01:28.914849 32183 compress_conv_layer.cu:174] 0.8 1.1916e-12 0.224078
I0621 04:01:28.957861 32183 compress_conv_layer.cu:174] 0.8 1.03557e-12 0.236085
I0621 04:01:29.002208 32183 compress_conv_layer.cu:174] 0.8 1.08847e-12 0.308934
I0621 04:01:29.045127 32183 compress_conv_layer.cu:174] 0.8 2.99763e-12 0.246157
I0621 04:01:29.131913 32183 compress_conv_layer.cu:174] 0.8 8.96588e-13 0.177564
I0621 04:01:29.313875 32183 compress_conv_layer.cu:174] 0.8 1.84683e-12 0.159728
I0621 04:01:29.332542 32183 compress_conv_layer.cu:174] 0.8 1.71733e-07 0.193701
I0621 04:01:29.570755 32183 compress_conv_layer.cu:174] 0.8 1.00764e-10 0.535445
I0621 04:01:29.578740 32183 compress_conv_layer.cu:174] 0.8 6.14575e-11 0.305002
I0621 04:01:29.587105 32183 compress_conv_layer.cu:174] 0.8 1.10416e-11 0.422049
I0621 04:01:29.595268 32183 compress_conv_layer.cu:174] 0.8 1.68182e-12 0.427229
I0621 04:01:29.607857 32183 compress_conv_layer.cu:174] 0.8 5.37102e-12 0.264023
I0621 04:01:29.629603 32183 compress_conv_layer.cu:174] 0.8 5.15224e-14 0.275579
I0621 04:01:29.671999 32183 compress_conv_layer.cu:174] 0.8 9.35814e-14 0.26547
I0621 04:01:29.715070 32183 compress_conv_layer.cu:174] 0.8 1.1916e-12 0.224078
I0621 04:01:29.757911 32183 compress_conv_layer.cu:174] 0.8 1.03557e-12 0.236085
I0621 04:01:29.800588 32183 compress_conv_layer.cu:174] 0.8 1.08847e-12 0.308934
I0621 04:01:29.843235 32183 compress_conv_layer.cu:174] 0.8 2.99763e-12 0.246157
I0621 04:01:29.929560 32183 compress_conv_layer.cu:174] 0.8 8.96588e-13 0.177564
I0621 04:01:30.116683 32183 compress_conv_layer.cu:174] 0.8 1.84683e-12 0.159728
I0621 04:01:30.136453 32183 compress_conv_layer.cu:174] 0.8 1.71733e-07 0.193701
I0621 04:01:30.374740 32183 compress_conv_layer.cu:174] 0.8 1.00764e-10 0.535445
I0621 04:01:30.382707 32183 compress_conv_layer.cu:174] 0.8 6.14575e-11 0.305002
I0621 04:01:30.390967 32183 compress_conv_layer.cu:174] 0.8 1.10416e-11 0.422049
I0621 04:01:30.399082 32183 compress_conv_layer.cu:174] 0.8 1.68182e-12 0.427229
I0621 04:01:30.411658 32183 compress_conv_layer.cu:174] 0.8 5.37102e-12 0.264023
I0621 04:01:30.433389 32183 compress_conv_layer.cu:174] 0.8 5.15224e-14 0.275579
I0621 04:01:30.475992 32183 compress_conv_layer.cu:174] 0.8 9.35814e-14 0.26547
I0621 04:01:30.519016 32183 compress_conv_layer.cu:174] 0.8 1.1916e-12 0.224078
I0621 04:01:30.561831 32183 compress_conv_layer.cu:174] 0.8 1.03557e-12 0.236085
I0621 04:01:30.604563 32183 compress_conv_layer.cu:174] 0.8 1.08847e-12 0.308934
I0621 04:01:30.647186 32183 compress_conv_layer.cu:174] 0.8 2.99763e-12 0.246157
I0621 04:01:30.755604 32183 compress_conv_layer.cu:174] 0.8 8.96588e-13 0.177564
I0621 04:01:30.937108 32183 compress_conv_layer.cu:174] 0.8 1.84683e-12 0.159728
I0621 04:01:30.955395 32183 compress_conv_layer.cu:174] 0.8 1.71733e-07 0.193701
I0621 04:01:31.185808 32183 solver.cpp:219] Iteration 13000 (0.568403 iter/s, 87.9657s/50 iters), loss = 0.0121608
I0621 04:01:31.185905 32183 solver.cpp:238]     Train net output #0: loss = 0.00724586 (* 1 = 0.00724586 loss)
I0621 04:01:31.185932 32183 sgd_solver.cpp:105] Iteration 13000, lr = 0.01
I0621 04:02:41.945536 32183 solver.cpp:219] Iteration 13050 (0.706625 iter/s, 70.7589s/50 iters), loss = 0.00739169
I0621 04:02:41.945749 32183 solver.cpp:238]     Train net output #0: loss = 0.0155682 (* 1 = 0.0155682 loss)
I0621 04:02:41.945775 32183 sgd_solver.cpp:105] Iteration 13050, lr = 0.01
I0621 04:03:52.736723 32183 solver.cpp:219] Iteration 13100 (0.706312 iter/s, 70.7903s/50 iters), loss = 0.0176148
I0621 04:03:52.736879 32183 solver.cpp:238]     Train net output #0: loss = 0.00721354 (* 1 = 0.00721354 loss)
I0621 04:03:52.736907 32183 sgd_solver.cpp:105] Iteration 13100, lr = 0.01
I0621 04:05:03.504487 32183 solver.cpp:219] Iteration 13150 (0.706545 iter/s, 70.7669s/50 iters), loss = 0.0112827
I0621 04:05:03.504647 32183 solver.cpp:238]     Train net output #0: loss = 0.0154425 (* 1 = 0.0154425 loss)
I0621 04:05:03.504673 32183 sgd_solver.cpp:105] Iteration 13150, lr = 0.01
I0621 04:06:14.297525 32183 solver.cpp:219] Iteration 13200 (0.706293 iter/s, 70.7921s/50 iters), loss = 0.0227364
I0621 04:06:14.297663 32183 solver.cpp:238]     Train net output #0: loss = 0.0628328 (* 1 = 0.0628328 loss)
I0621 04:06:14.297688 32183 sgd_solver.cpp:105] Iteration 13200, lr = 0.01
I0621 04:07:25.059777 32183 solver.cpp:219] Iteration 13250 (0.7066 iter/s, 70.7614s/50 iters), loss = 0.0128341
I0621 04:07:25.059916 32183 solver.cpp:238]     Train net output #0: loss = 0.0128969 (* 1 = 0.0128969 loss)
I0621 04:07:25.059942 32183 sgd_solver.cpp:105] Iteration 13250, lr = 0.01
I0621 04:08:35.829813 32183 solver.cpp:219] Iteration 13300 (0.706522 iter/s, 70.7692s/50 iters), loss = 0.0040606
I0621 04:08:35.829952 32183 solver.cpp:238]     Train net output #0: loss = 0.005398 (* 1 = 0.005398 loss)
I0621 04:08:35.829977 32183 sgd_solver.cpp:105] Iteration 13300, lr = 0.01
I0621 04:09:46.611819 32183 solver.cpp:219] Iteration 13350 (0.706403 iter/s, 70.7811s/50 iters), loss = 0.0331952
I0621 04:09:46.612687 32183 solver.cpp:238]     Train net output #0: loss = 0.1078 (* 1 = 0.1078 loss)
I0621 04:09:46.612715 32183 sgd_solver.cpp:105] Iteration 13350, lr = 0.01
I0621 04:10:57.385623 32183 solver.cpp:219] Iteration 13400 (0.706492 iter/s, 70.7722s/50 iters), loss = 0.0159025
I0621 04:10:57.385752 32183 solver.cpp:238]     Train net output #0: loss = 0.0180662 (* 1 = 0.0180662 loss)
I0621 04:10:57.385777 32183 sgd_solver.cpp:105] Iteration 13400, lr = 0.01
I0621 04:12:08.160898 32183 solver.cpp:219] Iteration 13450 (0.70647 iter/s, 70.7744s/50 iters), loss = 0.00853105
I0621 04:12:08.161056 32183 solver.cpp:238]     Train net output #0: loss = 0.00863948 (* 1 = 0.00863948 loss)
I0621 04:12:08.161082 32183 sgd_solver.cpp:105] Iteration 13450, lr = 0.01
I0621 04:13:17.533578 32183 solver.cpp:331] Iteration 13500, Testing net (#0)
I0621 04:13:32.096801 32183 solver.cpp:398]     Test net output #0: accuracy = 0.937904
I0621 04:13:32.096875 32183 solver.cpp:398]     Test net output #1: loss = 0.256227 (* 1 = 0.256227 loss)
I0621 04:13:33.507524 32183 solver.cpp:219] Iteration 13500 (0.585855 iter/s, 85.3454s/50 iters), loss = 0.0147731
I0621 04:13:33.507627 32183 solver.cpp:238]     Train net output #0: loss = 0.00664994 (* 1 = 0.00664994 loss)
I0621 04:13:33.507658 32183 sgd_solver.cpp:105] Iteration 13500, lr = 0.01
I0621 04:14:44.275511 32183 solver.cpp:219] Iteration 13550 (0.706544 iter/s, 70.767s/50 iters), loss = 0.0104496
I0621 04:14:44.275718 32183 solver.cpp:238]     Train net output #0: loss = 0.0123081 (* 1 = 0.0123081 loss)
I0621 04:14:44.275745 32183 sgd_solver.cpp:105] Iteration 13550, lr = 0.01
I0621 04:15:55.064188 32183 solver.cpp:219] Iteration 13600 (0.706338 iter/s, 70.7876s/50 iters), loss = 0.0132948
I0621 04:15:55.064344 32183 solver.cpp:238]     Train net output #0: loss = 0.00950401 (* 1 = 0.00950401 loss)
I0621 04:15:55.064370 32183 sgd_solver.cpp:105] Iteration 13600, lr = 0.01
I0621 04:17:05.838488 32183 solver.cpp:219] Iteration 13650 (0.706481 iter/s, 70.7733s/50 iters), loss = 0.0124592
I0621 04:17:05.838632 32183 solver.cpp:238]     Train net output #0: loss = 0.0103756 (* 1 = 0.0103756 loss)
I0621 04:17:05.838657 32183 sgd_solver.cpp:105] Iteration 13650, lr = 0.01
I0621 04:18:16.618424 32183 solver.cpp:219] Iteration 13700 (0.706425 iter/s, 70.7789s/50 iters), loss = 0.00987779
I0621 04:18:16.618567 32183 solver.cpp:238]     Train net output #0: loss = 0.02007 (* 1 = 0.02007 loss)
I0621 04:18:16.618594 32183 sgd_solver.cpp:105] Iteration 13700, lr = 0.01
I0621 04:19:27.390408 32183 solver.cpp:219] Iteration 13750 (0.706505 iter/s, 70.771s/50 iters), loss = 0.0085656
I0621 04:19:27.390543 32183 solver.cpp:238]     Train net output #0: loss = 0.00717767 (* 1 = 0.00717767 loss)
I0621 04:19:27.390575 32183 sgd_solver.cpp:105] Iteration 13750, lr = 0.01
I0621 04:20:38.163504 32183 solver.cpp:219] Iteration 13800 (0.706493 iter/s, 70.7721s/50 iters), loss = 0.0168524
I0621 04:20:38.163692 32183 solver.cpp:238]     Train net output #0: loss = 0.0414549 (* 1 = 0.0414549 loss)
I0621 04:20:38.163722 32183 sgd_solver.cpp:105] Iteration 13800, lr = 0.01
I0621 04:21:48.925736 32183 solver.cpp:219] Iteration 13850 (0.706602 iter/s, 70.7612s/50 iters), loss = 0.0149545
I0621 04:21:48.925882 32183 solver.cpp:238]     Train net output #0: loss = 0.0147376 (* 1 = 0.0147376 loss)
I0621 04:21:48.925909 32183 sgd_solver.cpp:105] Iteration 13850, lr = 0.01
I0621 04:22:59.694779 32183 solver.cpp:219] Iteration 13900 (0.706534 iter/s, 70.768s/50 iters), loss = 0.0117923
I0621 04:22:59.694922 32183 solver.cpp:238]     Train net output #0: loss = 0.0109186 (* 1 = 0.0109186 loss)
I0621 04:22:59.694946 32183 sgd_solver.cpp:105] Iteration 13900, lr = 0.01
I0621 04:24:10.460402 32183 solver.cpp:219] Iteration 13950 (0.706568 iter/s, 70.7646s/50 iters), loss = 0.00941001
I0621 04:24:10.460533 32183 solver.cpp:238]     Train net output #0: loss = 0.0047354 (* 1 = 0.0047354 loss)
I0621 04:24:10.460561 32183 sgd_solver.cpp:105] Iteration 13950, lr = 0.01
I0621 04:25:19.825635 32183 solver.cpp:331] Iteration 14000, Testing net (#0)
I0621 04:25:34.449057 32183 solver.cpp:398]     Test net output #0: accuracy = 0.932259
I0621 04:25:34.449134 32183 solver.cpp:398]     Test net output #1: loss = 0.316044 (* 1 = 0.316044 loss)
I0621 04:25:34.456545 32183 compress_conv_layer.cu:174] 0.819066 9.58476e-11 0.509986
I0621 04:25:34.465195 32183 compress_conv_layer.cu:174] 0.819066 5.84588e-11 0.292256
I0621 04:25:34.473484 32183 compress_conv_layer.cu:174] 0.819066 1.05029e-11 0.403449
I0621 04:25:34.481765 32183 compress_conv_layer.cu:174] 0.819066 1.59976e-12 0.407647
I0621 04:25:34.494482 32183 compress_conv_layer.cu:174] 0.819066 5.10896e-12 0.248503
I0621 04:25:34.516491 32183 compress_conv_layer.cu:174] 0.819066 4.90085e-14 0.261825
I0621 04:25:34.562228 32183 compress_conv_layer.cu:174] 0.819066 8.90152e-14 0.251132
I0621 04:25:34.606318 32183 compress_conv_layer.cu:174] 0.819066 1.13345e-12 0.212729
I0621 04:25:34.650266 32183 compress_conv_layer.cu:174] 0.819066 9.85044e-13 0.224498
I0621 04:25:34.693698 32183 compress_conv_layer.cu:174] 0.819066 1.03536e-12 0.292846
I0621 04:25:34.737247 32183 compress_conv_layer.cu:174] 0.819066 2.85136e-12 0.233097
I0621 04:25:34.826665 32183 compress_conv_layer.cu:174] 0.819066 8.5284e-13 0.168284
I0621 04:25:35.013227 32183 compress_conv_layer.cu:174] 0.819066 1.75672e-12 0.151935
I0621 04:25:35.031759 32183 compress_conv_layer.cu:174] 0.819066 1.63354e-07 0.19371
I0621 04:25:35.270238 32183 compress_conv_layer.cu:174] 0.819066 9.58476e-11 0.509986
I0621 04:25:35.278213 32183 compress_conv_layer.cu:174] 0.819066 5.84588e-11 0.292256
I0621 04:25:35.286471 32183 compress_conv_layer.cu:174] 0.819066 1.05029e-11 0.403449
I0621 04:25:35.294652 32183 compress_conv_layer.cu:174] 0.819066 1.59976e-12 0.407647
I0621 04:25:35.307196 32183 compress_conv_layer.cu:174] 0.819066 5.10896e-12 0.248503
I0621 04:25:35.328758 32183 compress_conv_layer.cu:174] 0.819066 4.90085e-14 0.261825
I0621 04:25:35.371598 32183 compress_conv_layer.cu:174] 0.819066 8.90152e-14 0.251132
I0621 04:25:35.414774 32183 compress_conv_layer.cu:174] 0.819066 1.13345e-12 0.212729
I0621 04:25:35.457623 32183 compress_conv_layer.cu:174] 0.819066 9.85044e-13 0.224498
I0621 04:25:35.500571 32183 compress_conv_layer.cu:174] 0.819066 1.03536e-12 0.292846
I0621 04:25:35.543797 32183 compress_conv_layer.cu:174] 0.819066 2.85136e-12 0.233097
I0621 04:25:35.630379 32183 compress_conv_layer.cu:174] 0.819066 8.5284e-13 0.168284
I0621 04:25:35.810504 32183 compress_conv_layer.cu:174] 0.819066 1.75672e-12 0.151935
I0621 04:25:35.828739 32183 compress_conv_layer.cu:174] 0.819066 1.63354e-07 0.19371
I0621 04:25:36.066905 32183 compress_conv_layer.cu:174] 0.819066 9.58476e-11 0.509986
I0621 04:25:36.074877 32183 compress_conv_layer.cu:174] 0.819066 5.84588e-11 0.292256
I0621 04:25:36.083132 32183 compress_conv_layer.cu:174] 0.819066 1.05029e-11 0.403449
I0621 04:25:36.091259 32183 compress_conv_layer.cu:174] 0.819066 1.59976e-12 0.407647
I0621 04:25:36.103900 32183 compress_conv_layer.cu:174] 0.819066 5.10896e-12 0.248503
I0621 04:25:36.125722 32183 compress_conv_layer.cu:174] 0.819066 4.90085e-14 0.261825
I0621 04:25:36.168699 32183 compress_conv_layer.cu:174] 0.819066 8.90152e-14 0.251132
I0621 04:25:36.212152 32183 compress_conv_layer.cu:174] 0.819066 1.13345e-12 0.212729
I0621 04:25:36.255210 32183 compress_conv_layer.cu:174] 0.819066 9.85044e-13 0.224498
I0621 04:25:36.298203 32183 compress_conv_layer.cu:174] 0.819066 1.03536e-12 0.292846
I0621 04:25:36.341300 32183 compress_conv_layer.cu:174] 0.819066 2.85136e-12 0.233097
I0621 04:25:36.427691 32183 compress_conv_layer.cu:174] 0.819066 8.5284e-13 0.168284
I0621 04:25:36.607578 32183 compress_conv_layer.cu:174] 0.819066 1.75672e-12 0.151935
I0621 04:25:36.625833 32183 compress_conv_layer.cu:174] 0.819066 1.63354e-07 0.19371
I0621 04:25:36.864053 32183 compress_conv_layer.cu:174] 0.819066 9.58476e-11 0.509986
I0621 04:25:36.872012 32183 compress_conv_layer.cu:174] 0.819066 5.84588e-11 0.292256
I0621 04:25:36.880240 32183 compress_conv_layer.cu:174] 0.819066 1.05029e-11 0.403449
I0621 04:25:36.888411 32183 compress_conv_layer.cu:174] 0.819066 1.59976e-12 0.407647
I0621 04:25:36.900964 32183 compress_conv_layer.cu:174] 0.819066 5.10896e-12 0.248503
I0621 04:25:36.922400 32183 compress_conv_layer.cu:174] 0.819066 4.90085e-14 0.261825
I0621 04:25:36.965117 32183 compress_conv_layer.cu:174] 0.819066 8.90152e-14 0.251132
I0621 04:25:37.008132 32183 compress_conv_layer.cu:174] 0.819066 1.13345e-12 0.212729
I0621 04:25:37.051367 32183 compress_conv_layer.cu:174] 0.819066 9.85044e-13 0.224498
I0621 04:25:37.094890 32183 compress_conv_layer.cu:174] 0.819066 1.03536e-12 0.292846
I0621 04:25:37.138538 32183 compress_conv_layer.cu:174] 0.819066 2.85136e-12 0.233097
I0621 04:25:37.225595 32183 compress_conv_layer.cu:174] 0.819066 8.5284e-13 0.168284
I0621 04:25:37.405709 32183 compress_conv_layer.cu:174] 0.819066 1.75672e-12 0.151935
I0621 04:25:37.423941 32183 compress_conv_layer.cu:174] 0.819066 1.63354e-07 0.19371
I0621 04:25:37.662075 32183 compress_conv_layer.cu:174] 0.819066 9.58476e-11 0.509986
I0621 04:25:37.670071 32183 compress_conv_layer.cu:174] 0.819066 5.84588e-11 0.292256
I0621 04:25:37.678318 32183 compress_conv_layer.cu:174] 0.819066 1.05029e-11 0.403449
I0621 04:25:37.686460 32183 compress_conv_layer.cu:174] 0.819066 1.59976e-12 0.407647
I0621 04:25:37.698942 32183 compress_conv_layer.cu:174] 0.819066 5.10896e-12 0.248503
I0621 04:25:37.720466 32183 compress_conv_layer.cu:174] 0.819066 4.90085e-14 0.261825
I0621 04:25:37.763141 32183 compress_conv_layer.cu:174] 0.819066 8.90152e-14 0.251132
I0621 04:25:37.806203 32183 compress_conv_layer.cu:174] 0.819066 1.13345e-12 0.212729
I0621 04:25:37.849125 32183 compress_conv_layer.cu:174] 0.819066 9.85044e-13 0.224498
I0621 04:25:37.892437 32183 compress_conv_layer.cu:174] 0.819066 1.03536e-12 0.292846
I0621 04:25:37.935719 32183 compress_conv_layer.cu:174] 0.819066 2.85136e-12 0.233097
I0621 04:25:38.022116 32183 compress_conv_layer.cu:174] 0.819066 8.5284e-13 0.168284
I0621 04:25:38.202103 32183 compress_conv_layer.cu:174] 0.819066 1.75672e-12 0.151935
I0621 04:25:38.220391 32183 compress_conv_layer.cu:174] 0.819066 1.63354e-07 0.19371
I0621 04:25:38.450705 32183 solver.cpp:219] Iteration 14000 (0.568252 iter/s, 87.9891s/50 iters), loss = 0.00728891
I0621 04:25:38.450781 32183 solver.cpp:238]     Train net output #0: loss = 0.0066126 (* 1 = 0.0066126 loss)
I0621 04:25:38.450810 32183 sgd_solver.cpp:105] Iteration 14000, lr = 0.01
I0621 04:26:49.201691 32183 solver.cpp:219] Iteration 14050 (0.706713 iter/s, 70.7501s/50 iters), loss = 0.0548711
I0621 04:26:49.201912 32183 solver.cpp:238]     Train net output #0: loss = 0.00470939 (* 1 = 0.00470939 loss)
I0621 04:26:49.201941 32183 sgd_solver.cpp:105] Iteration 14050, lr = 0.01
I0621 04:27:59.969730 32183 solver.cpp:219] Iteration 14100 (0.706544 iter/s, 70.767s/50 iters), loss = 0.0343381
I0621 04:27:59.969873 32183 solver.cpp:238]     Train net output #0: loss = 0.0296036 (* 1 = 0.0296036 loss)
I0621 04:27:59.969900 32183 sgd_solver.cpp:105] Iteration 14100, lr = 0.01
I0621 04:29:10.726300 32183 solver.cpp:219] Iteration 14150 (0.706658 iter/s, 70.7556s/50 iters), loss = 0.052035
I0621 04:29:10.726450 32183 solver.cpp:238]     Train net output #0: loss = 0.0891109 (* 1 = 0.0891109 loss)
I0621 04:29:10.726475 32183 sgd_solver.cpp:105] Iteration 14150, lr = 0.01
I0621 04:30:21.485036 32183 solver.cpp:219] Iteration 14200 (0.706634 iter/s, 70.758s/50 iters), loss = 0.0339828
I0621 04:30:21.485190 32183 solver.cpp:238]     Train net output #0: loss = 0.0402459 (* 1 = 0.0402459 loss)
I0621 04:30:21.485221 32183 sgd_solver.cpp:105] Iteration 14200, lr = 0.01
I0621 04:31:32.252473 32183 solver.cpp:219] Iteration 14250 (0.706547 iter/s, 70.7667s/50 iters), loss = 0.0654554
I0621 04:31:32.252630 32183 solver.cpp:238]     Train net output #0: loss = 0.0391463 (* 1 = 0.0391463 loss)
I0621 04:31:32.252657 32183 sgd_solver.cpp:105] Iteration 14250, lr = 0.01
I0621 04:32:43.007001 32183 solver.cpp:219] Iteration 14300 (0.706676 iter/s, 70.7538s/50 iters), loss = 0.0295994
I0621 04:32:43.007141 32183 solver.cpp:238]     Train net output #0: loss = 0.00988952 (* 1 = 0.00988952 loss)
I0621 04:32:43.007169 32183 sgd_solver.cpp:105] Iteration 14300, lr = 0.01
I0621 04:33:53.782454 32183 solver.cpp:219] Iteration 14350 (0.706467 iter/s, 70.7747s/50 iters), loss = 0.045479
I0621 04:33:53.782596 32183 solver.cpp:238]     Train net output #0: loss = 0.00856643 (* 1 = 0.00856643 loss)
I0621 04:33:53.782624 32183 sgd_solver.cpp:105] Iteration 14350, lr = 0.01
I0621 04:35:04.553933 32183 solver.cpp:219] Iteration 14400 (0.706507 iter/s, 70.7707s/50 iters), loss = 0.0581777
I0621 04:35:04.554069 32183 solver.cpp:238]     Train net output #0: loss = 0.0449247 (* 1 = 0.0449247 loss)
I0621 04:35:04.554095 32183 sgd_solver.cpp:105] Iteration 14400, lr = 0.01
I0621 04:36:15.319949 32183 solver.cpp:219] Iteration 14450 (0.706561 iter/s, 70.7653s/50 iters), loss = 0.0372397
I0621 04:36:15.320071 32183 solver.cpp:238]     Train net output #0: loss = 0.0211021 (* 1 = 0.0211021 loss)
I0621 04:36:15.320097 32183 sgd_solver.cpp:105] Iteration 14450, lr = 0.01
I0621 04:37:24.686471 32183 solver.cpp:331] Iteration 14500, Testing net (#0)
I0621 04:37:39.360579 32183 solver.cpp:398]     Test net output #0: accuracy = 0.737903
I0621 04:37:39.360657 32183 solver.cpp:398]     Test net output #1: loss = 1.12928 (* 1 = 1.12928 loss)
I0621 04:37:40.771708 32183 solver.cpp:219] Iteration 14500 (0.585131 iter/s, 85.4509s/50 iters), loss = 0.0226412
I0621 04:37:40.771800 32183 solver.cpp:238]     Train net output #0: loss = 0.0347542 (* 1 = 0.0347542 loss)
I0621 04:37:40.771831 32183 sgd_solver.cpp:105] Iteration 14500, lr = 0.01
I0621 04:38:51.544474 32183 solver.cpp:219] Iteration 14550 (0.706493 iter/s, 70.7721s/50 iters), loss = 0.011667
I0621 04:38:51.544682 32183 solver.cpp:238]     Train net output #0: loss = 0.0206433 (* 1 = 0.0206433 loss)
I0621 04:38:51.544708 32183 sgd_solver.cpp:105] Iteration 14550, lr = 0.01
I0621 04:40:02.322868 32183 solver.cpp:219] Iteration 14600 (0.706439 iter/s, 70.7776s/50 iters), loss = 0.0112118
I0621 04:40:02.323030 32183 solver.cpp:238]     Train net output #0: loss = 0.0091923 (* 1 = 0.0091923 loss)
I0621 04:40:02.323057 32183 sgd_solver.cpp:105] Iteration 14600, lr = 0.01
I0621 04:41:13.088260 32183 solver.cpp:219] Iteration 14650 (0.706568 iter/s, 70.7646s/50 iters), loss = 0.0109957
I0621 04:41:13.088402 32183 solver.cpp:238]     Train net output #0: loss = 0.0183547 (* 1 = 0.0183547 loss)
I0621 04:41:13.088428 32183 sgd_solver.cpp:105] Iteration 14650, lr = 0.01
I0621 04:42:23.845010 32183 solver.cpp:219] Iteration 14700 (0.706654 iter/s, 70.756s/50 iters), loss = 0.0166426
I0621 04:42:23.845199 32183 solver.cpp:238]     Train net output #0: loss = 0.0119436 (* 1 = 0.0119436 loss)
I0621 04:42:23.845226 32183 sgd_solver.cpp:105] Iteration 14700, lr = 0.01
I0621 04:43:34.602376 32183 solver.cpp:219] Iteration 14750 (0.706648 iter/s, 70.7565s/50 iters), loss = 0.0110392
I0621 04:43:34.602496 32183 solver.cpp:238]     Train net output #0: loss = 0.0104814 (* 1 = 0.0104814 loss)
I0621 04:43:34.602529 32183 sgd_solver.cpp:105] Iteration 14750, lr = 0.01
I0621 04:44:45.351755 32183 solver.cpp:219] Iteration 14800 (0.706728 iter/s, 70.7486s/50 iters), loss = 0.00986125
I0621 04:44:45.351892 32183 solver.cpp:238]     Train net output #0: loss = 0.00532494 (* 1 = 0.00532494 loss)
I0621 04:44:45.351924 32183 sgd_solver.cpp:105] Iteration 14800, lr = 0.01
I0621 04:45:56.118999 32183 solver.cpp:219] Iteration 14850 (0.706549 iter/s, 70.7665s/50 iters), loss = 0.0102671
I0621 04:45:56.119148 32183 solver.cpp:238]     Train net output #0: loss = 0.0137101 (* 1 = 0.0137101 loss)
I0621 04:45:56.119175 32183 sgd_solver.cpp:105] Iteration 14850, lr = 0.01
I0621 04:47:06.889250 32183 solver.cpp:219] Iteration 14900 (0.706519 iter/s, 70.7695s/50 iters), loss = 0.00848549
I0621 04:47:06.889381 32183 solver.cpp:238]     Train net output #0: loss = 0.00500091 (* 1 = 0.00500091 loss)
I0621 04:47:06.889406 32183 sgd_solver.cpp:105] Iteration 14900, lr = 0.01
I0621 04:48:17.656720 32183 solver.cpp:219] Iteration 14950 (0.706547 iter/s, 70.7667s/50 iters), loss = 0.00904988
I0621 04:48:17.656862 32183 solver.cpp:238]     Train net output #0: loss = 0.0111322 (* 1 = 0.0111322 loss)
I0621 04:48:17.656893 32183 sgd_solver.cpp:105] Iteration 14950, lr = 0.01
I0621 04:49:27.023041 32183 solver.cpp:331] Iteration 15000, Testing net (#0)
I0621 04:49:41.646726 32183 solver.cpp:398]     Test net output #0: accuracy = 0.945162
I0621 04:49:41.646806 32183 solver.cpp:398]     Test net output #1: loss = 0.257522 (* 1 = 0.257522 loss)
I0621 04:49:43.057348 32183 solver.cpp:219] Iteration 15000 (0.585482 iter/s, 85.3997s/50 iters), loss = 0.00600547
I0621 04:49:43.057438 32183 solver.cpp:238]     Train net output #0: loss = 0.0066229 (* 1 = 0.0066229 loss)
I0621 04:49:43.057469 32183 sgd_solver.cpp:105] Iteration 15000, lr = 0.01
I0621 04:50:53.843248 32183 solver.cpp:219] Iteration 15050 (0.706363 iter/s, 70.7852s/50 iters), loss = 0.00777169
I0621 04:50:53.843400 32183 solver.cpp:238]     Train net output #0: loss = 0.00762156 (* 1 = 0.00762156 loss)
I0621 04:50:53.843426 32183 sgd_solver.cpp:105] Iteration 15050, lr = 0.01
I0621 04:52:04.607117 32183 solver.cpp:219] Iteration 15100 (0.706583 iter/s, 70.7631s/50 iters), loss = 0.012925
I0621 04:52:04.607247 32183 solver.cpp:238]     Train net output #0: loss = 0.00844095 (* 1 = 0.00844095 loss)
I0621 04:52:04.607272 32183 sgd_solver.cpp:105] Iteration 15100, lr = 0.01
I0621 04:53:15.372083 32183 solver.cpp:219] Iteration 15150 (0.706572 iter/s, 70.7642s/50 iters), loss = 0.0100587
I0621 04:53:15.372269 32183 solver.cpp:238]     Train net output #0: loss = 0.00580051 (* 1 = 0.00580051 loss)
I0621 04:53:15.372297 32183 sgd_solver.cpp:105] Iteration 15150, lr = 0.01
I0621 04:54:26.129825 32183 solver.cpp:219] Iteration 15200 (0.706645 iter/s, 70.7569s/50 iters), loss = 0.011575
I0621 04:54:26.129974 32183 solver.cpp:238]     Train net output #0: loss = 0.0105412 (* 1 = 0.0105412 loss)
I0621 04:54:26.130002 32183 sgd_solver.cpp:105] Iteration 15200, lr = 0.01
I0621 04:55:36.894052 32183 solver.cpp:219] Iteration 15250 (0.70658 iter/s, 70.7634s/50 iters), loss = 0.0101459
I0621 04:55:36.894163 32183 solver.cpp:238]     Train net output #0: loss = 0.012173 (* 1 = 0.012173 loss)
I0621 04:55:36.894193 32183 sgd_solver.cpp:105] Iteration 15250, lr = 0.01
I0621 04:56:47.658028 32183 solver.cpp:219] Iteration 15300 (0.706582 iter/s, 70.7632s/50 iters), loss = 0.0088768
I0621 04:56:47.658171 32183 solver.cpp:238]     Train net output #0: loss = 0.0182944 (* 1 = 0.0182944 loss)
I0621 04:56:47.658196 32183 sgd_solver.cpp:105] Iteration 15300, lr = 0.01
I0621 04:57:58.425843 32183 solver.cpp:219] Iteration 15350 (0.706544 iter/s, 70.767s/50 iters), loss = 0.0105531
I0621 04:57:58.425988 32183 solver.cpp:238]     Train net output #0: loss = 0.00901939 (* 1 = 0.00901939 loss)
I0621 04:57:58.426020 32183 sgd_solver.cpp:105] Iteration 15350, lr = 0.01
I0621 04:59:09.207067 32183 solver.cpp:219] Iteration 15400 (0.70641 iter/s, 70.7804s/50 iters), loss = 0.0144322
I0621 04:59:09.207212 32183 solver.cpp:238]     Train net output #0: loss = 0.00833547 (* 1 = 0.00833547 loss)
I0621 04:59:09.207238 32183 sgd_solver.cpp:105] Iteration 15400, lr = 0.01
I0621 05:00:19.984858 32183 solver.cpp:219] Iteration 15450 (0.706444 iter/s, 70.777s/50 iters), loss = 0.00627644
I0621 05:00:19.985002 32183 solver.cpp:238]     Train net output #0: loss = 0.00526239 (* 1 = 0.00526239 loss)
I0621 05:00:19.985029 32183 sgd_solver.cpp:105] Iteration 15450, lr = 0.01
I0621 05:01:29.352494 32183 solver.cpp:331] Iteration 15500, Testing net (#0)
I0621 05:01:43.966866 32183 solver.cpp:398]     Test net output #0: accuracy = 0.940323
I0621 05:01:43.966948 32183 solver.cpp:398]     Test net output #1: loss = 0.310693 (* 1 = 0.310693 loss)
I0621 05:01:45.377550 32183 solver.cpp:219] Iteration 15500 (0.585537 iter/s, 85.3917s/50 iters), loss = 0.0100405
I0621 05:01:45.377650 32183 solver.cpp:238]     Train net output #0: loss = 0.00906893 (* 1 = 0.00906893 loss)
I0621 05:01:45.377679 32183 sgd_solver.cpp:105] Iteration 15500, lr = 0.01
I0621 05:02:56.154062 32183 solver.cpp:219] Iteration 15550 (0.706457 iter/s, 70.7757s/50 iters), loss = 0.00873049
I0621 05:02:56.154222 32183 solver.cpp:238]     Train net output #0: loss = 0.00764098 (* 1 = 0.00764098 loss)
I0621 05:02:56.154248 32183 sgd_solver.cpp:105] Iteration 15550, lr = 0.01
I0621 05:04:06.943135 32183 solver.cpp:219] Iteration 15600 (0.706333 iter/s, 70.7882s/50 iters), loss = 0.0135345
I0621 05:04:06.943276 32183 solver.cpp:238]     Train net output #0: loss = 0.0154531 (* 1 = 0.0154531 loss)
I0621 05:04:06.943303 32183 sgd_solver.cpp:105] Iteration 15600, lr = 0.01
I0621 05:05:17.706156 32183 solver.cpp:219] Iteration 15650 (0.706593 iter/s, 70.7621s/50 iters), loss = 0.0110322
I0621 05:05:17.706295 32183 solver.cpp:238]     Train net output #0: loss = 0.00879396 (* 1 = 0.00879396 loss)
I0621 05:05:17.706321 32183 sgd_solver.cpp:105] Iteration 15650, lr = 0.01
I0621 05:06:28.470608 32183 solver.cpp:219] Iteration 15700 (0.706579 iter/s, 70.7635s/50 iters), loss = 0.0111844
I0621 05:06:28.470746 32183 solver.cpp:238]     Train net output #0: loss = 0.00954628 (* 1 = 0.00954628 loss)
I0621 05:06:28.470773 32183 sgd_solver.cpp:105] Iteration 15700, lr = 0.01
I0621 05:07:39.243119 32183 solver.cpp:219] Iteration 15750 (0.706498 iter/s, 70.7716s/50 iters), loss = 0.0124318
I0621 05:07:39.243264 32183 solver.cpp:238]     Train net output #0: loss = 0.00732144 (* 1 = 0.00732144 loss)
I0621 05:07:39.243290 32183 sgd_solver.cpp:105] Iteration 15750, lr = 0.01
I0621 05:08:50.027638 32183 solver.cpp:219] Iteration 15800 (0.706379 iter/s, 70.7836s/50 iters), loss = 0.00962752
I0621 05:08:50.027837 32183 solver.cpp:238]     Train net output #0: loss = 0.0130192 (* 1 = 0.0130192 loss)
I0621 05:08:50.027863 32183 sgd_solver.cpp:105] Iteration 15800, lr = 0.01
I0621 05:10:00.793494 32183 solver.cpp:219] Iteration 15850 (0.706565 iter/s, 70.7649s/50 iters), loss = 0.0110899
I0621 05:10:00.794116 32183 solver.cpp:238]     Train net output #0: loss = 0.0174688 (* 1 = 0.0174688 loss)
I0621 05:10:00.794143 32183 sgd_solver.cpp:105] Iteration 15850, lr = 0.01
I0621 05:11:11.555979 32183 solver.cpp:219] Iteration 15900 (0.706603 iter/s, 70.7611s/50 iters), loss = 0.00539528
I0621 05:11:11.556116 32183 solver.cpp:238]     Train net output #0: loss = 0.00730966 (* 1 = 0.00730966 loss)
I0621 05:11:11.556143 32183 sgd_solver.cpp:105] Iteration 15900, lr = 0.01
I0621 05:12:22.335988 32183 solver.cpp:219] Iteration 15950 (0.706424 iter/s, 70.7791s/50 iters), loss = 0.00827153
I0621 05:12:22.336139 32183 solver.cpp:238]     Train net output #0: loss = 0.0076599 (* 1 = 0.0076599 loss)
I0621 05:12:22.336166 32183 sgd_solver.cpp:105] Iteration 15950, lr = 0.01
I0621 05:13:31.693799 32183 solver.cpp:331] Iteration 16000, Testing net (#0)
I0621 05:13:46.215957 32183 solver.cpp:398]     Test net output #0: accuracy = 0.926613
I0621 05:13:46.216034 32183 solver.cpp:398]     Test net output #1: loss = 0.320309 (* 1 = 0.320309 loss)
I0621 05:13:47.626818 32183 solver.cpp:219] Iteration 16000 (0.586237 iter/s, 85.2897s/50 iters), loss = 0.0118926
I0621 05:13:47.626910 32183 solver.cpp:238]     Train net output #0: loss = 0.0197314 (* 1 = 0.0197314 loss)
I0621 05:13:47.626940 32183 sgd_solver.cpp:105] Iteration 16000, lr = 0.01
I0621 05:14:58.413806 32183 solver.cpp:219] Iteration 16050 (0.706353 iter/s, 70.7861s/50 iters), loss = 0.0111931
I0621 05:14:58.413961 32183 solver.cpp:238]     Train net output #0: loss = 0.00807298 (* 1 = 0.00807298 loss)
I0621 05:14:58.413987 32183 sgd_solver.cpp:105] Iteration 16050, lr = 0.01
I0621 05:16:09.196817 32183 solver.cpp:219] Iteration 16100 (0.706394 iter/s, 70.7821s/50 iters), loss = 0.011187
I0621 05:16:09.197064 32183 solver.cpp:238]     Train net output #0: loss = 0.0154043 (* 1 = 0.0154043 loss)
I0621 05:16:09.197090 32183 sgd_solver.cpp:105] Iteration 16100, lr = 0.01
I0621 05:17:19.972410 32183 solver.cpp:219] Iteration 16150 (0.706469 iter/s, 70.7745s/50 iters), loss = 0.0194858
I0621 05:17:19.972563 32183 solver.cpp:238]     Train net output #0: loss = 0.0605338 (* 1 = 0.0605338 loss)
I0621 05:17:19.972591 32183 sgd_solver.cpp:105] Iteration 16150, lr = 0.01
I0621 05:18:30.741282 32183 solver.cpp:219] Iteration 16200 (0.706535 iter/s, 70.7679s/50 iters), loss = 0.0141294
I0621 05:18:30.741410 32183 solver.cpp:238]     Train net output #0: loss = 0.0359855 (* 1 = 0.0359855 loss)
I0621 05:18:30.741436 32183 sgd_solver.cpp:105] Iteration 16200, lr = 0.01
I0621 05:19:41.515866 32183 solver.cpp:219] Iteration 16250 (0.706478 iter/s, 70.7737s/50 iters), loss = 0.0175331
I0621 05:19:41.516054 32183 solver.cpp:238]     Train net output #0: loss = 0.00824402 (* 1 = 0.00824402 loss)
I0621 05:19:41.516084 32183 sgd_solver.cpp:105] Iteration 16250, lr = 0.01
I0621 05:20:52.298224 32183 solver.cpp:219] Iteration 16300 (0.706401 iter/s, 70.7814s/50 iters), loss = 0.00932942
I0621 05:20:52.298364 32183 solver.cpp:238]     Train net output #0: loss = 0.00381035 (* 1 = 0.00381035 loss)
I0621 05:20:52.298391 32183 sgd_solver.cpp:105] Iteration 16300, lr = 0.01
I0621 05:22:03.106946 32183 solver.cpp:219] Iteration 16350 (0.706137 iter/s, 70.8078s/50 iters), loss = 0.00763696
I0621 05:22:03.107106 32183 solver.cpp:238]     Train net output #0: loss = 0.00494032 (* 1 = 0.00494032 loss)
I0621 05:22:03.107133 32183 sgd_solver.cpp:105] Iteration 16350, lr = 0.01
I0621 05:23:13.887887 32183 solver.cpp:219] Iteration 16400 (0.706414 iter/s, 70.78s/50 iters), loss = 0.0104811
I0621 05:23:13.888028 32183 solver.cpp:238]     Train net output #0: loss = 0.0140604 (* 1 = 0.0140604 loss)
I0621 05:23:13.888054 32183 sgd_solver.cpp:105] Iteration 16400, lr = 0.01
I0621 05:24:24.658195 32183 solver.cpp:219] Iteration 16450 (0.70652 iter/s, 70.7694s/50 iters), loss = 0.0155254
I0621 05:24:24.658397 32183 solver.cpp:238]     Train net output #0: loss = 0.0111074 (* 1 = 0.0111074 loss)
I0621 05:24:24.658424 32183 sgd_solver.cpp:105] Iteration 16450, lr = 0.01
I0621 05:25:34.027067 32183 solver.cpp:331] Iteration 16500, Testing net (#0)
I0621 05:25:35.888525 32183 blocking_queue.cpp:49] Waiting for data
I0621 05:25:48.598526 32183 solver.cpp:398]     Test net output #0: accuracy = 0.937097
I0621 05:25:48.598629 32183 solver.cpp:398]     Test net output #1: loss = 0.310749 (* 1 = 0.310749 loss)
I0621 05:25:50.008689 32183 solver.cpp:219] Iteration 16500 (0.585828 iter/s, 85.3493s/50 iters), loss = 0.0154923
I0621 05:25:50.008767 32183 solver.cpp:238]     Train net output #0: loss = 0.0133042 (* 1 = 0.0133042 loss)
I0621 05:25:50.008791 32183 sgd_solver.cpp:105] Iteration 16500, lr = 0.01
I0621 05:27:00.787722 32183 solver.cpp:219] Iteration 16550 (0.706433 iter/s, 70.7782s/50 iters), loss = 0.0123729
I0621 05:27:00.787864 32183 solver.cpp:238]     Train net output #0: loss = 0.0162045 (* 1 = 0.0162045 loss)
I0621 05:27:00.787891 32183 sgd_solver.cpp:105] Iteration 16550, lr = 0.01
I0621 05:28:11.582892 32183 solver.cpp:219] Iteration 16600 (0.706272 iter/s, 70.7942s/50 iters), loss = 0.0403355
I0621 05:28:11.583039 32183 solver.cpp:238]     Train net output #0: loss = 0.163691 (* 1 = 0.163691 loss)
I0621 05:28:11.583065 32183 sgd_solver.cpp:105] Iteration 16600, lr = 0.01
I0621 05:29:22.359129 32183 solver.cpp:219] Iteration 16650 (0.706461 iter/s, 70.7753s/50 iters), loss = 0.0251627
I0621 05:29:22.359269 32183 solver.cpp:238]     Train net output #0: loss = 0.0298128 (* 1 = 0.0298128 loss)
I0621 05:29:22.359295 32183 sgd_solver.cpp:105] Iteration 16650, lr = 0.01
I0621 05:30:33.142714 32183 solver.cpp:219] Iteration 16700 (0.706388 iter/s, 70.7826s/50 iters), loss = 0.0313864
I0621 05:30:33.142868 32183 solver.cpp:238]     Train net output #0: loss = 0.0705733 (* 1 = 0.0705733 loss)
I0621 05:30:33.142894 32183 sgd_solver.cpp:105] Iteration 16700, lr = 0.01
I0621 05:31:43.912840 32183 solver.cpp:219] Iteration 16750 (0.706522 iter/s, 70.7692s/50 iters), loss = 0.0111754
I0621 05:31:43.912986 32183 solver.cpp:238]     Train net output #0: loss = 0.0102167 (* 1 = 0.0102167 loss)
I0621 05:31:43.913012 32183 sgd_solver.cpp:105] Iteration 16750, lr = 0.01
I0621 05:32:54.685648 32183 solver.cpp:219] Iteration 16800 (0.706495 iter/s, 70.7719s/50 iters), loss = 0.0229048
I0621 05:32:54.685806 32183 solver.cpp:238]     Train net output #0: loss = 0.0536938 (* 1 = 0.0536938 loss)
I0621 05:32:54.685832 32183 sgd_solver.cpp:105] Iteration 16800, lr = 0.01
I0621 05:34:05.449146 32183 solver.cpp:219] Iteration 16850 (0.706588 iter/s, 70.7626s/50 iters), loss = 0.0145752
I0621 05:34:05.449292 32183 solver.cpp:238]     Train net output #0: loss = 0.00596576 (* 1 = 0.00596576 loss)
I0621 05:34:05.449318 32183 sgd_solver.cpp:105] Iteration 16850, lr = 0.01
I0621 05:35:16.208550 32183 solver.cpp:219] Iteration 16900 (0.706629 iter/s, 70.7585s/50 iters), loss = 0.0148202
I0621 05:35:16.208691 32183 solver.cpp:238]     Train net output #0: loss = 0.0076273 (* 1 = 0.0076273 loss)
I0621 05:35:16.208717 32183 sgd_solver.cpp:105] Iteration 16900, lr = 0.01
I0621 05:36:26.978170 32183 solver.cpp:219] Iteration 16950 (0.706527 iter/s, 70.7687s/50 iters), loss = 0.0160569
I0621 05:36:26.978312 32183 solver.cpp:238]     Train net output #0: loss = 0.0105297 (* 1 = 0.0105297 loss)
I0621 05:36:26.978339 32183 sgd_solver.cpp:105] Iteration 16950, lr = 0.01
I0621 05:37:36.346211 32183 solver.cpp:331] Iteration 17000, Testing net (#0)
I0621 05:37:50.933010 32183 solver.cpp:398]     Test net output #0: accuracy = 0.947581
I0621 05:37:50.933089 32183 solver.cpp:398]     Test net output #1: loss = 0.287333 (* 1 = 0.287333 loss)
I0621 05:37:52.343296 32183 solver.cpp:219] Iteration 17000 (0.585727 iter/s, 85.364s/50 iters), loss = 0.0195009
I0621 05:37:52.343380 32183 solver.cpp:238]     Train net output #0: loss = 0.0121227 (* 1 = 0.0121227 loss)
I0621 05:37:52.343406 32183 sgd_solver.cpp:105] Iteration 17000, lr = 0.01
I0621 05:39:03.102293 32183 solver.cpp:219] Iteration 17050 (0.706634 iter/s, 70.758s/50 iters), loss = 0.0177176
I0621 05:39:03.102510 32183 solver.cpp:238]     Train net output #0: loss = 0.014097 (* 1 = 0.014097 loss)
I0621 05:39:03.102545 32183 sgd_solver.cpp:105] Iteration 17050, lr = 0.01
I0621 05:40:13.881450 32183 solver.cpp:219] Iteration 17100 (0.706434 iter/s, 70.7781s/50 iters), loss = 0.00887741
I0621 05:40:13.881628 32183 solver.cpp:238]     Train net output #0: loss = 0.00567771 (* 1 = 0.00567771 loss)
I0621 05:40:13.881654 32183 sgd_solver.cpp:105] Iteration 17100, lr = 0.01
I0621 05:41:24.671645 32183 solver.cpp:219] Iteration 17150 (0.706323 iter/s, 70.7891s/50 iters), loss = 0.0115734
I0621 05:41:24.671802 32183 solver.cpp:238]     Train net output #0: loss = 0.0140693 (* 1 = 0.0140693 loss)
I0621 05:41:24.671828 32183 sgd_solver.cpp:105] Iteration 17150, lr = 0.01
I0621 05:42:35.457134 32183 solver.cpp:219] Iteration 17200 (0.70637 iter/s, 70.7844s/50 iters), loss = 0.0183632
I0621 05:42:35.457267 32183 solver.cpp:238]     Train net output #0: loss = 0.0122798 (* 1 = 0.0122798 loss)
I0621 05:42:35.457293 32183 sgd_solver.cpp:105] Iteration 17200, lr = 0.01
I0621 05:43:46.245304 32183 solver.cpp:219] Iteration 17250 (0.706343 iter/s, 70.7871s/50 iters), loss = 0.0167142
I0621 05:43:46.245451 32183 solver.cpp:238]     Train net output #0: loss = 0.0107077 (* 1 = 0.0107077 loss)
I0621 05:43:46.245479 32183 sgd_solver.cpp:105] Iteration 17250, lr = 0.01
I0621 05:44:57.037537 32183 solver.cpp:219] Iteration 17300 (0.706303 iter/s, 70.7912s/50 iters), loss = 0.0178735
I0621 05:44:57.037696 32183 solver.cpp:238]     Train net output #0: loss = 0.0204499 (* 1 = 0.0204499 loss)
I0621 05:44:57.037722 32183 sgd_solver.cpp:105] Iteration 17300, lr = 0.01
I0621 05:46:07.809960 32183 solver.cpp:219] Iteration 17350 (0.7065 iter/s, 70.7714s/50 iters), loss = 0.0140241
I0621 05:46:07.810101 32183 solver.cpp:238]     Train net output #0: loss = 0.0131904 (* 1 = 0.0131904 loss)
I0621 05:46:07.810128 32183 sgd_solver.cpp:105] Iteration 17350, lr = 0.01
I0621 05:47:18.590881 32183 solver.cpp:219] Iteration 17400 (0.706415 iter/s, 70.7799s/50 iters), loss = 0.00971082
I0621 05:47:18.591039 32183 solver.cpp:238]     Train net output #0: loss = 0.00956169 (* 1 = 0.00956169 loss)
I0621 05:47:18.591070 32183 sgd_solver.cpp:105] Iteration 17400, lr = 0.01
I0621 05:48:29.384074 32183 solver.cpp:219] Iteration 17450 (0.706293 iter/s, 70.7921s/50 iters), loss = 0.0233438
I0621 05:48:29.384217 32183 solver.cpp:238]     Train net output #0: loss = 0.0428146 (* 1 = 0.0428146 loss)
I0621 05:48:29.384243 32183 sgd_solver.cpp:105] Iteration 17450, lr = 0.01
I0621 05:49:38.759269 32183 solver.cpp:331] Iteration 17500, Testing net (#0)
I0621 05:49:53.345651 32183 solver.cpp:398]     Test net output #0: accuracy = 0.928226
I0621 05:49:53.345736 32183 solver.cpp:398]     Test net output #1: loss = 0.348814 (* 1 = 0.348814 loss)
I0621 05:49:54.756489 32183 solver.cpp:219] Iteration 17500 (0.585678 iter/s, 85.3712s/50 iters), loss = 0.0223881
I0621 05:49:54.756594 32183 solver.cpp:238]     Train net output #0: loss = 0.0220577 (* 1 = 0.0220577 loss)
I0621 05:49:54.756616 32183 sgd_solver.cpp:105] Iteration 17500, lr = 0.01
I0621 05:51:05.525821 32183 solver.cpp:219] Iteration 17550 (0.706531 iter/s, 70.7683s/50 iters), loss = 0.0238114
I0621 05:51:05.525979 32183 solver.cpp:238]     Train net output #0: loss = 0.0120971 (* 1 = 0.0120971 loss)
I0621 05:51:05.526005 32183 sgd_solver.cpp:105] Iteration 17550, lr = 0.01
I0621 05:52:16.281268 32183 solver.cpp:219] Iteration 17600 (0.70667 iter/s, 70.7544s/50 iters), loss = 0.0160737
I0621 05:52:16.281422 32183 solver.cpp:238]     Train net output #0: loss = 0.00678729 (* 1 = 0.00678729 loss)
I0621 05:52:16.281450 32183 sgd_solver.cpp:105] Iteration 17600, lr = 0.01
I0621 05:53:27.068588 32183 solver.cpp:219] Iteration 17650 (0.706352 iter/s, 70.7863s/50 iters), loss = 0.0264699
I0621 05:53:27.068783 32183 solver.cpp:238]     Train net output #0: loss = 0.0119532 (* 1 = 0.0119532 loss)
I0621 05:53:27.068809 32183 sgd_solver.cpp:105] Iteration 17650, lr = 0.01
I0621 05:54:37.832738 32183 solver.cpp:219] Iteration 17700 (0.706583 iter/s, 70.7631s/50 iters), loss = 0.018426
I0621 05:54:37.832898 32183 solver.cpp:238]     Train net output #0: loss = 0.0325118 (* 1 = 0.0325118 loss)
I0621 05:54:37.832926 32183 sgd_solver.cpp:105] Iteration 17700, lr = 0.01
I0621 05:55:48.591400 32183 solver.cpp:219] Iteration 17750 (0.706638 iter/s, 70.7576s/50 iters), loss = 0.0175873
I0621 05:55:48.591549 32183 solver.cpp:238]     Train net output #0: loss = 0.0519673 (* 1 = 0.0519673 loss)
I0621 05:55:48.591578 32183 sgd_solver.cpp:105] Iteration 17750, lr = 0.01
I0621 05:56:59.355079 32183 solver.cpp:219] Iteration 17800 (0.706587 iter/s, 70.7626s/50 iters), loss = 0.0153709
I0621 05:56:59.355226 32183 solver.cpp:238]     Train net output #0: loss = 0.00913138 (* 1 = 0.00913138 loss)
I0621 05:56:59.355252 32183 sgd_solver.cpp:105] Iteration 17800, lr = 0.01
I0621 05:58:10.112795 32183 solver.cpp:219] Iteration 17850 (0.706647 iter/s, 70.7567s/50 iters), loss = 0.0110767
I0621 05:58:10.113143 32183 solver.cpp:238]     Train net output #0: loss = 0.0145118 (* 1 = 0.0145118 loss)
I0621 05:58:10.113169 32183 sgd_solver.cpp:105] Iteration 17850, lr = 0.01
I0621 05:59:20.874555 32183 solver.cpp:219] Iteration 17900 (0.706609 iter/s, 70.7605s/50 iters), loss = 0.0206961
I0621 05:59:20.874698 32183 solver.cpp:238]     Train net output #0: loss = 0.0157353 (* 1 = 0.0157353 loss)
I0621 05:59:20.874725 32183 sgd_solver.cpp:105] Iteration 17900, lr = 0.01
I0621 06:00:31.626950 32183 solver.cpp:219] Iteration 17950 (0.7067 iter/s, 70.7514s/50 iters), loss = 0.00945988
I0621 06:00:31.627079 32183 solver.cpp:238]     Train net output #0: loss = 0.0119029 (* 1 = 0.0119029 loss)
I0621 06:00:31.627105 32183 sgd_solver.cpp:105] Iteration 17950, lr = 0.01
I0621 06:01:40.982753 32183 solver.cpp:331] Iteration 18000, Testing net (#0)
I0621 06:01:55.580340 32183 solver.cpp:398]     Test net output #0: accuracy = 0.925807
I0621 06:01:55.580415 32183 solver.cpp:398]     Test net output #1: loss = 0.345752 (* 1 = 0.345752 loss)
I0621 06:01:56.990334 32183 solver.cpp:219] Iteration 18000 (0.585739 iter/s, 85.3622s/50 iters), loss = 0.0119579
I0621 06:01:56.990419 32183 solver.cpp:238]     Train net output #0: loss = 0.00812144 (* 1 = 0.00812144 loss)
I0621 06:01:56.990442 32183 sgd_solver.cpp:105] Iteration 18000, lr = 0.01
I0621 06:03:07.736565 32183 solver.cpp:219] Iteration 18050 (0.706761 iter/s, 70.7453s/50 iters), loss = 0.0217631
I0621 06:03:07.736709 32183 solver.cpp:238]     Train net output #0: loss = 0.0398527 (* 1 = 0.0398527 loss)
I0621 06:03:07.736735 32183 sgd_solver.cpp:105] Iteration 18050, lr = 0.01
I0621 06:04:18.499878 32183 solver.cpp:219] Iteration 18100 (0.706591 iter/s, 70.7623s/50 iters), loss = 0.0195721
I0621 06:04:18.500011 32183 solver.cpp:238]     Train net output #0: loss = 0.0236333 (* 1 = 0.0236333 loss)
I0621 06:04:18.500037 32183 sgd_solver.cpp:105] Iteration 18100, lr = 0.01
I0621 06:05:29.262660 32183 solver.cpp:219] Iteration 18150 (0.706596 iter/s, 70.7618s/50 iters), loss = 0.0185865
I0621 06:05:29.262812 32183 solver.cpp:238]     Train net output #0: loss = 0.0290528 (* 1 = 0.0290528 loss)
I0621 06:05:29.262840 32183 sgd_solver.cpp:105] Iteration 18150, lr = 0.01
I0621 06:06:40.031746 32183 solver.cpp:219] Iteration 18200 (0.706534 iter/s, 70.768s/50 iters), loss = 0.0224771
I0621 06:06:40.034313 32183 solver.cpp:238]     Train net output #0: loss = 0.0220981 (* 1 = 0.0220981 loss)
I0621 06:06:40.034345 32183 sgd_solver.cpp:105] Iteration 18200, lr = 0.01
I0621 06:07:50.803293 32183 solver.cpp:219] Iteration 18250 (0.706533 iter/s, 70.7681s/50 iters), loss = 0.0161022
I0621 06:07:50.803438 32183 solver.cpp:238]     Train net output #0: loss = 0.0148167 (* 1 = 0.0148167 loss)
I0621 06:07:50.803464 32183 sgd_solver.cpp:105] Iteration 18250, lr = 0.01
I0621 06:09:01.570621 32183 solver.cpp:219] Iteration 18300 (0.706551 iter/s, 70.7663s/50 iters), loss = 0.0242501
I0621 06:09:01.570817 32183 solver.cpp:238]     Train net output #0: loss = 0.0494948 (* 1 = 0.0494948 loss)
I0621 06:09:01.570843 32183 sgd_solver.cpp:105] Iteration 18300, lr = 0.01
I0621 06:10:12.342830 32183 solver.cpp:219] Iteration 18350 (0.706503 iter/s, 70.7711s/50 iters), loss = 0.0182879
I0621 06:10:12.342964 32183 solver.cpp:238]     Train net output #0: loss = 0.0156136 (* 1 = 0.0156136 loss)
I0621 06:10:12.342990 32183 sgd_solver.cpp:105] Iteration 18350, lr = 0.01
I0621 06:11:23.105767 32183 solver.cpp:219] Iteration 18400 (0.706595 iter/s, 70.7619s/50 iters), loss = 0.0244565
I0621 06:11:23.105916 32183 solver.cpp:238]     Train net output #0: loss = 0.013567 (* 1 = 0.013567 loss)
I0621 06:11:23.105942 32183 sgd_solver.cpp:105] Iteration 18400, lr = 0.01
I0621 06:12:33.872982 32183 solver.cpp:219] Iteration 18450 (0.706551 iter/s, 70.7663s/50 iters), loss = 0.0226819
I0621 06:12:33.873142 32183 solver.cpp:238]     Train net output #0: loss = 0.0652346 (* 1 = 0.0652346 loss)
I0621 06:12:33.873167 32183 sgd_solver.cpp:105] Iteration 18450, lr = 0.01
I0621 06:13:43.226868 32183 solver.cpp:331] Iteration 18500, Testing net (#0)
I0621 06:13:57.801367 32183 solver.cpp:398]     Test net output #0: accuracy = 0.932259
I0621 06:13:57.801450 32183 solver.cpp:398]     Test net output #1: loss = 0.344454 (* 1 = 0.344454 loss)
I0621 06:13:59.212131 32183 solver.cpp:219] Iteration 18500 (0.585905 iter/s, 85.338s/50 iters), loss = 0.0211953
I0621 06:13:59.212224 32183 solver.cpp:238]     Train net output #0: loss = 0.0256434 (* 1 = 0.0256434 loss)
I0621 06:13:59.212252 32183 sgd_solver.cpp:105] Iteration 18500, lr = 0.01
I0621 06:15:09.981602 32183 solver.cpp:219] Iteration 18550 (0.706528 iter/s, 70.7686s/50 iters), loss = 0.0260075
I0621 06:15:09.981747 32183 solver.cpp:238]     Train net output #0: loss = 0.00620368 (* 1 = 0.00620368 loss)
I0621 06:15:09.981775 32183 sgd_solver.cpp:105] Iteration 18550, lr = 0.01
I0621 06:16:20.752187 32183 solver.cpp:219] Iteration 18600 (0.706518 iter/s, 70.7696s/50 iters), loss = 0.0226547
I0621 06:16:20.752331 32183 solver.cpp:238]     Train net output #0: loss = 0.0211258 (* 1 = 0.0211258 loss)
I0621 06:16:20.752357 32183 sgd_solver.cpp:105] Iteration 18600, lr = 0.01
I0621 06:17:31.513471 32183 solver.cpp:219] Iteration 18650 (0.70661 iter/s, 70.7603s/50 iters), loss = 0.027717
I0621 06:17:31.513608 32183 solver.cpp:238]     Train net output #0: loss = 0.029227 (* 1 = 0.029227 loss)
I0621 06:17:31.513640 32183 sgd_solver.cpp:105] Iteration 18650, lr = 0.01
I0621 06:18:42.292994 32183 solver.cpp:219] Iteration 18700 (0.706428 iter/s, 70.7786s/50 iters), loss = 0.0162495
I0621 06:18:42.293135 32183 solver.cpp:238]     Train net output #0: loss = 0.0157276 (* 1 = 0.0157276 loss)
I0621 06:18:42.293161 32183 sgd_solver.cpp:105] Iteration 18700, lr = 0.01
I0621 06:19:53.070096 32183 solver.cpp:219] Iteration 18750 (0.706453 iter/s, 70.7762s/50 iters), loss = 0.0153863
I0621 06:19:53.070238 32183 solver.cpp:238]     Train net output #0: loss = 0.0118399 (* 1 = 0.0118399 loss)
I0621 06:19:53.070266 32183 sgd_solver.cpp:105] Iteration 18750, lr = 0.01
I0621 06:21:03.846786 32183 solver.cpp:219] Iteration 18800 (0.706457 iter/s, 70.7757s/50 iters), loss = 0.0189563
I0621 06:21:03.846922 32183 solver.cpp:238]     Train net output #0: loss = 0.0292785 (* 1 = 0.0292785 loss)
I0621 06:21:03.846948 32183 sgd_solver.cpp:105] Iteration 18800, lr = 0.01
I0621 06:22:14.615777 32183 solver.cpp:219] Iteration 18850 (0.706533 iter/s, 70.7681s/50 iters), loss = 0.0168548
I0621 06:22:14.615937 32183 solver.cpp:238]     Train net output #0: loss = 0.0269202 (* 1 = 0.0269202 loss)
I0621 06:22:14.615963 32183 sgd_solver.cpp:105] Iteration 18850, lr = 0.01
I0621 06:23:25.393941 32183 solver.cpp:219] Iteration 18900 (0.706442 iter/s, 70.7772s/50 iters), loss = 0.0201585
I0621 06:23:25.394111 32183 solver.cpp:238]     Train net output #0: loss = 0.017988 (* 1 = 0.017988 loss)
I0621 06:23:25.394138 32183 sgd_solver.cpp:105] Iteration 18900, lr = 0.01
I0621 06:24:36.153363 32183 solver.cpp:219] Iteration 18950 (0.706629 iter/s, 70.7584s/50 iters), loss = 0.292613
I0621 06:24:36.153578 32183 solver.cpp:238]     Train net output #0: loss = 0.174939 (* 1 = 0.174939 loss)
I0621 06:24:36.153607 32183 sgd_solver.cpp:105] Iteration 18950, lr = 0.01
I0621 06:25:45.504828 32183 solver.cpp:331] Iteration 19000, Testing net (#0)
I0621 06:26:00.118682 32183 solver.cpp:398]     Test net output #0: accuracy = 0.0217742
I0621 06:26:00.118755 32183 solver.cpp:398]     Test net output #1: loss = 8.63095 (* 1 = 8.63095 loss)
I0621 06:26:01.530228 32183 solver.cpp:219] Iteration 19000 (0.585647 iter/s, 85.3757s/50 iters), loss = 0.298571
I0621 06:26:01.530321 32183 solver.cpp:238]     Train net output #0: loss = 0.408946 (* 1 = 0.408946 loss)
I0621 06:26:01.530350 32183 sgd_solver.cpp:105] Iteration 19000, lr = 0.01
I0621 06:27:12.304922 32183 solver.cpp:219] Iteration 19050 (0.706476 iter/s, 70.7738s/50 iters), loss = 0.161176
I0621 06:27:12.305071 32183 solver.cpp:238]     Train net output #0: loss = 0.211178 (* 1 = 0.211178 loss)
I0621 06:27:12.305097 32183 sgd_solver.cpp:105] Iteration 19050, lr = 0.01
I0621 06:28:23.073299 32183 solver.cpp:219] Iteration 19100 (0.70654 iter/s, 70.7674s/50 iters), loss = 0.122243
I0621 06:28:23.073426 32183 solver.cpp:238]     Train net output #0: loss = 0.0878233 (* 1 = 0.0878233 loss)
I0621 06:28:23.073452 32183 sgd_solver.cpp:105] Iteration 19100, lr = 0.01
I0621 06:29:33.835400 32183 solver.cpp:219] Iteration 19150 (0.706602 iter/s, 70.7612s/50 iters), loss = 0.129957
I0621 06:29:33.835546 32183 solver.cpp:238]     Train net output #0: loss = 0.0306245 (* 1 = 0.0306245 loss)
I0621 06:29:33.835577 32183 sgd_solver.cpp:105] Iteration 19150, lr = 0.01
I0621 06:30:44.610738 32183 solver.cpp:219] Iteration 19200 (0.70647 iter/s, 70.7744s/50 iters), loss = 0.0708956
I0621 06:30:44.610875 32183 solver.cpp:238]     Train net output #0: loss = 0.096691 (* 1 = 0.096691 loss)
I0621 06:30:44.610903 32183 sgd_solver.cpp:105] Iteration 19200, lr = 0.01
I0621 06:31:55.383849 32183 solver.cpp:219] Iteration 19250 (0.706493 iter/s, 70.7722s/50 iters), loss = 0.0856774
I0621 06:31:55.383993 32183 solver.cpp:238]     Train net output #0: loss = 0.0305315 (* 1 = 0.0305315 loss)
I0621 06:31:55.384024 32183 sgd_solver.cpp:105] Iteration 19250, lr = 0.01
I0621 06:33:06.138626 32183 solver.cpp:219] Iteration 19300 (0.706676 iter/s, 70.7538s/50 iters), loss = 0.0291669
I0621 06:33:06.138782 32183 solver.cpp:238]     Train net output #0: loss = 0.026534 (* 1 = 0.026534 loss)
I0621 06:33:06.138808 32183 sgd_solver.cpp:105] Iteration 19300, lr = 0.01
I0621 06:34:16.897614 32183 solver.cpp:219] Iteration 19350 (0.706634 iter/s, 70.758s/50 iters), loss = 0.022934
I0621 06:34:16.897758 32183 solver.cpp:238]     Train net output #0: loss = 0.0168847 (* 1 = 0.0168847 loss)
I0621 06:34:16.897785 32183 sgd_solver.cpp:105] Iteration 19350, lr = 0.01
I0621 06:35:27.651417 32183 solver.cpp:219] Iteration 19400 (0.706685 iter/s, 70.7529s/50 iters), loss = 0.0397054
I0621 06:35:27.651582 32183 solver.cpp:238]     Train net output #0: loss = 0.0143327 (* 1 = 0.0143327 loss)
I0621 06:35:27.651608 32183 sgd_solver.cpp:105] Iteration 19400, lr = 0.01
I0621 06:36:38.402734 32183 solver.cpp:219] Iteration 19450 (0.70671 iter/s, 70.7503s/50 iters), loss = 0.0310632
I0621 06:36:38.402873 32183 solver.cpp:238]     Train net output #0: loss = 0.0101376 (* 1 = 0.0101376 loss)
I0621 06:36:38.402899 32183 sgd_solver.cpp:105] Iteration 19450, lr = 0.01
I0621 06:37:47.755832 32183 solver.cpp:331] Iteration 19500, Testing net (#0)
I0621 06:38:02.353976 32183 solver.cpp:398]     Test net output #0: accuracy = 0.942742
I0621 06:38:02.354055 32183 solver.cpp:398]     Test net output #1: loss = 0.224284 (* 1 = 0.224284 loss)
I0621 06:38:03.763708 32183 solver.cpp:219] Iteration 19500 (0.585755 iter/s, 85.3599s/50 iters), loss = 0.0363097
I0621 06:38:03.763804 32183 solver.cpp:238]     Train net output #0: loss = 0.0232881 (* 1 = 0.0232881 loss)
I0621 06:38:03.763829 32183 sgd_solver.cpp:105] Iteration 19500, lr = 0.01
I0621 06:39:14.520232 32183 solver.cpp:219] Iteration 19550 (0.706658 iter/s, 70.7556s/50 iters), loss = 0.0241381
I0621 06:39:14.520428 32183 solver.cpp:238]     Train net output #0: loss = 0.0150739 (* 1 = 0.0150739 loss)
I0621 06:39:14.520454 32183 sgd_solver.cpp:105] Iteration 19550, lr = 0.01
I0621 06:40:25.288656 32183 solver.cpp:219] Iteration 19600 (0.70654 iter/s, 70.7674s/50 iters), loss = 0.0323806
I0621 06:40:25.288815 32183 solver.cpp:238]     Train net output #0: loss = 0.0261274 (* 1 = 0.0261274 loss)
I0621 06:40:25.288856 32183 sgd_solver.cpp:105] Iteration 19600, lr = 0.01
I0621 06:41:36.050586 32183 solver.cpp:219] Iteration 19650 (0.706604 iter/s, 70.761s/50 iters), loss = 0.0271926
I0621 06:41:36.050737 32183 solver.cpp:238]     Train net output #0: loss = 0.0117984 (* 1 = 0.0117984 loss)
I0621 06:41:36.050762 32183 sgd_solver.cpp:105] Iteration 19650, lr = 0.01
I0621 06:42:46.830193 32183 solver.cpp:219] Iteration 19700 (0.706428 iter/s, 70.7786s/50 iters), loss = 0.0194833
I0621 06:42:46.830332 32183 solver.cpp:238]     Train net output #0: loss = 0.0176055 (* 1 = 0.0176055 loss)
I0621 06:42:46.830358 32183 sgd_solver.cpp:105] Iteration 19700, lr = 0.01
I0621 06:43:57.616930 32183 solver.cpp:219] Iteration 19750 (0.706356 iter/s, 70.7858s/50 iters), loss = 0.0164111
I0621 06:43:57.617074 32183 solver.cpp:238]     Train net output #0: loss = 0.028627 (* 1 = 0.028627 loss)
I0621 06:43:57.617100 32183 sgd_solver.cpp:105] Iteration 19750, lr = 0.01
I0621 06:45:08.386080 32183 solver.cpp:219] Iteration 19800 (0.706532 iter/s, 70.7682s/50 iters), loss = 0.0231075
I0621 06:45:08.386216 32183 solver.cpp:238]     Train net output #0: loss = 0.0404546 (* 1 = 0.0404546 loss)
I0621 06:45:08.386241 32183 sgd_solver.cpp:105] Iteration 19800, lr = 0.01
I0621 06:46:19.151646 32183 solver.cpp:219] Iteration 19850 (0.706567 iter/s, 70.7647s/50 iters), loss = 0.0368593
I0621 06:46:19.151792 32183 solver.cpp:238]     Train net output #0: loss = 0.0299677 (* 1 = 0.0299677 loss)
I0621 06:46:19.151818 32183 sgd_solver.cpp:105] Iteration 19850, lr = 0.01
I0621 06:47:29.942632 32183 solver.cpp:219] Iteration 19900 (0.706311 iter/s, 70.7903s/50 iters), loss = 0.072714
I0621 06:47:29.942770 32183 solver.cpp:238]     Train net output #0: loss = 0.104975 (* 1 = 0.104975 loss)
I0621 06:47:29.942796 32183 sgd_solver.cpp:105] Iteration 19900, lr = 0.01
I0621 06:48:40.720203 32183 solver.cpp:219] Iteration 19950 (0.706446 iter/s, 70.7768s/50 iters), loss = 0.0185622
I0621 06:48:40.720343 32183 solver.cpp:238]     Train net output #0: loss = 0.0228491 (* 1 = 0.0228491 loss)
I0621 06:48:40.720376 32183 sgd_solver.cpp:105] Iteration 19950, lr = 0.01
I0621 06:49:50.077672 32183 solver.cpp:448] Snapshotting to binary proto file mobilenet/mobile_pruning_iter_20000.caffemodel
I0621 06:49:50.201212 32183 sgd_solver.cpp:273] Snapshotting solver state to binary proto file mobilenet/mobile_pruning_iter_20000.solverstate
I0621 06:49:50.257503 32183 solver.cpp:331] Iteration 20000, Testing net (#0)
I0621 06:50:04.867161 32183 solver.cpp:398]     Test net output #0: accuracy = 0.91371
I0621 06:50:04.867241 32183 solver.cpp:398]     Test net output #1: loss = 0.4208 (* 1 = 0.4208 loss)
I0621 06:50:06.277500 32183 solver.cpp:219] Iteration 20000 (0.584409 iter/s, 85.5565s/50 iters), loss = 0.0152755
I0621 06:50:06.277588 32183 solver.cpp:238]     Train net output #0: loss = 0.0117427 (* 1 = 0.0117427 loss)
I0621 06:50:06.277617 32183 sgd_solver.cpp:105] Iteration 20000, lr = 0.01
I0621 06:51:17.037056 32183 solver.cpp:219] Iteration 20050 (0.706625 iter/s, 70.7589s/50 iters), loss = 0.0392373
I0621 06:51:17.037220 32183 solver.cpp:238]     Train net output #0: loss = 0.0346716 (* 1 = 0.0346716 loss)
I0621 06:51:17.037245 32183 sgd_solver.cpp:105] Iteration 20050, lr = 0.01
I0621 06:52:27.798148 32183 solver.cpp:219] Iteration 20100 (0.70661 iter/s, 70.7604s/50 iters), loss = 0.0189234
I0621 06:52:27.798508 32183 solver.cpp:238]     Train net output #0: loss = 0.013106 (* 1 = 0.013106 loss)
I0621 06:52:27.798543 32183 sgd_solver.cpp:105] Iteration 20100, lr = 0.01
I0621 06:53:38.580284 32183 solver.cpp:219] Iteration 20150 (0.706402 iter/s, 70.7812s/50 iters), loss = 0.0234485
I0621 06:53:38.580452 32183 solver.cpp:238]     Train net output #0: loss = 0.0117789 (* 1 = 0.0117789 loss)
I0621 06:53:38.580477 32183 sgd_solver.cpp:105] Iteration 20150, lr = 0.01
I0621 06:54:49.346027 32183 solver.cpp:219] Iteration 20200 (0.706564 iter/s, 70.765s/50 iters), loss = 0.020317
I0621 06:54:49.346173 32183 solver.cpp:238]     Train net output #0: loss = 0.0131597 (* 1 = 0.0131597 loss)
I0621 06:54:49.346211 32183 sgd_solver.cpp:105] Iteration 20200, lr = 0.01
I0621 06:56:00.122475 32183 solver.cpp:219] Iteration 20250 (0.706457 iter/s, 70.7757s/50 iters), loss = 0.0247845
I0621 06:56:00.123939 32183 solver.cpp:238]     Train net output #0: loss = 0.0243993 (* 1 = 0.0243993 loss)
I0621 06:56:00.123966 32183 sgd_solver.cpp:105] Iteration 20250, lr = 0.01
I0621 06:57:10.925863 32183 solver.cpp:219] Iteration 20300 (0.706201 iter/s, 70.8014s/50 iters), loss = 0.022769
I0621 06:57:10.926028 32183 solver.cpp:238]     Train net output #0: loss = 0.020533 (* 1 = 0.020533 loss)
I0621 06:57:10.926060 32183 sgd_solver.cpp:105] Iteration 20300, lr = 0.01
I0621 06:58:21.699214 32183 solver.cpp:219] Iteration 20350 (0.706488 iter/s, 70.7726s/50 iters), loss = 0.0262382
I0621 06:58:21.699864 32183 solver.cpp:238]     Train net output #0: loss = 0.0137698 (* 1 = 0.0137698 loss)
I0621 06:58:21.699890 32183 sgd_solver.cpp:105] Iteration 20350, lr = 0.01
I0621 06:59:32.468114 32183 solver.cpp:219] Iteration 20400 (0.706537 iter/s, 70.7677s/50 iters), loss = 0.0134711
I0621 06:59:32.468260 32183 solver.cpp:238]     Train net output #0: loss = 0.011271 (* 1 = 0.011271 loss)
I0621 06:59:32.468286 32183 sgd_solver.cpp:105] Iteration 20400, lr = 0.01
I0621 07:00:43.240447 32183 solver.cpp:219] Iteration 20450 (0.706498 iter/s, 70.7716s/50 iters), loss = 0.0139163
I0621 07:00:43.240603 32183 solver.cpp:238]     Train net output #0: loss = 0.0128015 (* 1 = 0.0128015 loss)
I0621 07:00:43.240630 32183 sgd_solver.cpp:105] Iteration 20450, lr = 0.01
I0621 07:01:52.586906 32183 solver.cpp:331] Iteration 20500, Testing net (#0)
I0621 07:01:59.244341 32183 blocking_queue.cpp:49] Waiting for data
I0621 07:02:07.165438 32183 solver.cpp:398]     Test net output #0: accuracy = 0.935484
I0621 07:02:07.165529 32183 solver.cpp:398]     Test net output #1: loss = 0.284983 (* 1 = 0.284983 loss)
I0621 07:02:08.576262 32183 solver.cpp:219] Iteration 20500 (0.585926 iter/s, 85.335s/50 iters), loss = 0.0112302
I0621 07:02:08.576364 32183 solver.cpp:238]     Train net output #0: loss = 0.0141592 (* 1 = 0.0141592 loss)
I0621 07:02:08.576395 32183 sgd_solver.cpp:105] Iteration 20500, lr = 0.01
I0621 07:03:19.336241 32183 solver.cpp:219] Iteration 20550 (0.706622 iter/s, 70.7592s/50 iters), loss = 0.0178435
I0621 07:03:19.336990 32183 solver.cpp:238]     Train net output #0: loss = 0.0163145 (* 1 = 0.0163145 loss)
I0621 07:03:19.337021 32183 sgd_solver.cpp:105] Iteration 20550, lr = 0.01
I0621 07:04:30.104015 32183 solver.cpp:219] Iteration 20600 (0.706552 iter/s, 70.7662s/50 iters), loss = 0.0152531
I0621 07:04:30.104149 32183 solver.cpp:238]     Train net output #0: loss = 0.0304492 (* 1 = 0.0304492 loss)
I0621 07:04:30.104182 32183 sgd_solver.cpp:105] Iteration 20600, lr = 0.01
I0621 07:05:40.887120 32183 solver.cpp:219] Iteration 20650 (0.706393 iter/s, 70.7822s/50 iters), loss = 0.0120584
I0621 07:05:40.887274 32183 solver.cpp:238]     Train net output #0: loss = 0.0202139 (* 1 = 0.0202139 loss)
I0621 07:05:40.887305 32183 sgd_solver.cpp:105] Iteration 20650, lr = 0.01
I0621 07:06:51.658481 32183 solver.cpp:219] Iteration 20700 (0.70651 iter/s, 70.7704s/50 iters), loss = 0.0134817
I0621 07:06:51.658640 32183 solver.cpp:238]     Train net output #0: loss = 0.0115696 (* 1 = 0.0115696 loss)
I0621 07:06:51.658668 32183 sgd_solver.cpp:105] Iteration 20700, lr = 0.01
I0621 07:08:02.441107 32183 solver.cpp:219] Iteration 20750 (0.706398 iter/s, 70.7817s/50 iters), loss = 0.0166339
I0621 07:08:02.441318 32183 solver.cpp:238]     Train net output #0: loss = 0.0230443 (* 1 = 0.0230443 loss)
I0621 07:08:02.441345 32183 sgd_solver.cpp:105] Iteration 20750, lr = 0.01
I0621 07:09:13.229341 32183 solver.cpp:219] Iteration 20800 (0.706342 iter/s, 70.7872s/50 iters), loss = 0.020167
I0621 07:09:13.229501 32183 solver.cpp:238]     Train net output #0: loss = 0.019482 (* 1 = 0.019482 loss)
I0621 07:09:13.229532 32183 sgd_solver.cpp:105] Iteration 20800, lr = 0.01
I0621 07:10:24.000550 32183 solver.cpp:219] Iteration 20850 (0.706512 iter/s, 70.7702s/50 iters), loss = 0.0192606
I0621 07:10:24.000707 32183 solver.cpp:238]     Train net output #0: loss = 0.0166436 (* 1 = 0.0166436 loss)
I0621 07:10:24.000735 32183 sgd_solver.cpp:105] Iteration 20850, lr = 0.01
I0621 07:11:34.783648 32183 solver.cpp:219] Iteration 20900 (0.706393 iter/s, 70.7821s/50 iters), loss = 0.0228636
I0621 07:11:34.783785 32183 solver.cpp:238]     Train net output #0: loss = 0.0217472 (* 1 = 0.0217472 loss)
I0621 07:11:34.783812 32183 sgd_solver.cpp:105] Iteration 20900, lr = 0.01
I0621 07:12:45.557667 32183 solver.cpp:219] Iteration 20950 (0.706483 iter/s, 70.7731s/50 iters), loss = 0.0148801
I0621 07:12:45.557826 32183 solver.cpp:238]     Train net output #0: loss = 0.00959255 (* 1 = 0.00959255 loss)
I0621 07:12:45.557852 32183 sgd_solver.cpp:105] Iteration 20950, lr = 0.01
I0621 07:13:54.925724 32183 solver.cpp:331] Iteration 21000, Testing net (#0)
I0621 07:14:09.487958 32183 solver.cpp:398]     Test net output #0: accuracy = 0.931452
I0621 07:14:09.488047 32183 solver.cpp:398]     Test net output #1: loss = 0.329045 (* 1 = 0.329045 loss)
I0621 07:14:10.898551 32183 solver.cpp:219] Iteration 21000 (0.585893 iter/s, 85.3398s/50 iters), loss = 0.0212605
I0621 07:14:10.898643 32183 solver.cpp:238]     Train net output #0: loss = 0.0115352 (* 1 = 0.0115352 loss)
I0621 07:14:10.898672 32183 sgd_solver.cpp:105] Iteration 21000, lr = 0.01
I0621 07:15:21.667300 32183 solver.cpp:219] Iteration 21050 (0.706535 iter/s, 70.7679s/50 iters), loss = 0.0293922
I0621 07:15:21.667454 32183 solver.cpp:238]     Train net output #0: loss = 0.0534246 (* 1 = 0.0534246 loss)
I0621 07:15:21.667480 32183 sgd_solver.cpp:105] Iteration 21050, lr = 0.01
I0621 07:16:32.427691 32183 solver.cpp:219] Iteration 21100 (0.706619 iter/s, 70.7594s/50 iters), loss = 0.0221749
I0621 07:16:32.427834 32183 solver.cpp:238]     Train net output #0: loss = 0.018354 (* 1 = 0.018354 loss)
I0621 07:16:32.427860 32183 sgd_solver.cpp:105] Iteration 21100, lr = 0.01
I0621 07:17:43.185103 32183 solver.cpp:219] Iteration 21150 (0.706649 iter/s, 70.7565s/50 iters), loss = 0.03196
I0621 07:17:43.185240 32183 solver.cpp:238]     Train net output #0: loss = 0.0119401 (* 1 = 0.0119401 loss)
I0621 07:17:43.185266 32183 sgd_solver.cpp:105] Iteration 21150, lr = 0.01
I0621 07:18:53.951527 32183 solver.cpp:219] Iteration 21200 (0.706559 iter/s, 70.7655s/50 iters), loss = 0.0227388
I0621 07:18:53.951658 32183 solver.cpp:238]     Train net output #0: loss = 0.0307871 (* 1 = 0.0307871 loss)
I0621 07:18:53.951683 32183 sgd_solver.cpp:105] Iteration 21200, lr = 0.01
I0621 07:20:04.731472 32183 solver.cpp:219] Iteration 21250 (0.706424 iter/s, 70.779s/50 iters), loss = 0.0192389
I0621 07:20:04.731631 32183 solver.cpp:238]     Train net output #0: loss = 0.0186499 (* 1 = 0.0186499 loss)
I0621 07:20:04.731657 32183 sgd_solver.cpp:105] Iteration 21250, lr = 0.01
I0621 07:21:15.518512 32183 solver.cpp:219] Iteration 21300 (0.706354 iter/s, 70.786s/50 iters), loss = 0.022269
I0621 07:21:15.518693 32183 solver.cpp:238]     Train net output #0: loss = 0.0150506 (* 1 = 0.0150506 loss)
I0621 07:21:15.518729 32183 sgd_solver.cpp:105] Iteration 21300, lr = 0.01
I0621 07:22:26.332285 32183 solver.cpp:219] Iteration 21350 (0.706087 iter/s, 70.8128s/50 iters), loss = 0.0220303
I0621 07:22:26.332432 32183 solver.cpp:238]     Train net output #0: loss = 0.0105326 (* 1 = 0.0105326 loss)
I0621 07:22:26.332458 32183 sgd_solver.cpp:105] Iteration 21350, lr = 0.01
I0621 07:23:37.107867 32183 solver.cpp:219] Iteration 21400 (0.706468 iter/s, 70.7746s/50 iters), loss = 0.0250192
I0621 07:23:37.108079 32183 solver.cpp:238]     Train net output #0: loss = 0.0406645 (* 1 = 0.0406645 loss)
I0621 07:23:37.108108 32183 sgd_solver.cpp:105] Iteration 21400, lr = 0.01
I0621 07:24:47.910200 32183 solver.cpp:219] Iteration 21450 (0.706202 iter/s, 70.8013s/50 iters), loss = 0.0413401
I0621 07:24:47.910359 32183 solver.cpp:238]     Train net output #0: loss = 0.0755398 (* 1 = 0.0755398 loss)
I0621 07:24:47.910387 32183 sgd_solver.cpp:105] Iteration 21450, lr = 0.01
I0621 07:25:57.266909 32183 solver.cpp:331] Iteration 21500, Testing net (#0)
I0621 07:26:11.889066 32183 solver.cpp:398]     Test net output #0: accuracy = 0.946775
I0621 07:26:11.889156 32183 solver.cpp:398]     Test net output #1: loss = 0.305878 (* 1 = 0.305878 loss)
I0621 07:26:13.299813 32183 solver.cpp:219] Iteration 21500 (0.585559 iter/s, 85.3885s/50 iters), loss = 0.0202117
I0621 07:26:13.299921 32183 solver.cpp:238]     Train net output #0: loss = 0.0300732 (* 1 = 0.0300732 loss)
I0621 07:26:13.299952 32183 sgd_solver.cpp:105] Iteration 21500, lr = 0.01
I0621 07:27:24.073014 32183 solver.cpp:219] Iteration 21550 (0.706491 iter/s, 70.7723s/50 iters), loss = 0.0426059
I0621 07:27:24.073189 32183 solver.cpp:238]     Train net output #0: loss = 0.0100587 (* 1 = 0.0100587 loss)
I0621 07:27:24.073221 32183 sgd_solver.cpp:105] Iteration 21550, lr = 0.01
I0621 07:28:34.880127 32183 solver.cpp:219] Iteration 21600 (0.706154 iter/s, 70.8061s/50 iters), loss = 0.0264768
I0621 07:28:34.880270 32183 solver.cpp:238]     Train net output #0: loss = 0.0227847 (* 1 = 0.0227847 loss)
I0621 07:28:34.880302 32183 sgd_solver.cpp:105] Iteration 21600, lr = 0.01
I0621 07:29:45.660929 32183 solver.cpp:219] Iteration 21650 (0.706416 iter/s, 70.7798s/50 iters), loss = 0.0148644
I0621 07:29:45.661072 32183 solver.cpp:238]     Train net output #0: loss = 0.0115756 (* 1 = 0.0115756 loss)
I0621 07:29:45.661099 32183 sgd_solver.cpp:105] Iteration 21650, lr = 0.01
I0621 07:30:56.437835 32183 solver.cpp:219] Iteration 21700 (0.706455 iter/s, 70.7759s/50 iters), loss = 0.0287623
I0621 07:30:56.437985 32183 solver.cpp:238]     Train net output #0: loss = 0.024858 (* 1 = 0.024858 loss)
I0621 07:30:56.438019 32183 sgd_solver.cpp:105] Iteration 21700, lr = 0.01
I0621 07:32:07.195778 32183 solver.cpp:219] Iteration 21750 (0.706644 iter/s, 70.757s/50 iters), loss = 0.0233825
I0621 07:32:07.195925 32183 solver.cpp:238]     Train net output #0: loss = 0.0199479 (* 1 = 0.0199479 loss)
I0621 07:32:07.195952 32183 sgd_solver.cpp:105] Iteration 21750, lr = 0.01
I0621 07:33:17.986335 32183 solver.cpp:219] Iteration 21800 (0.706318 iter/s, 70.7896s/50 iters), loss = 0.0288892
I0621 07:33:17.986470 32183 solver.cpp:238]     Train net output #0: loss = 0.0553962 (* 1 = 0.0553962 loss)
I0621 07:33:17.986501 32183 sgd_solver.cpp:105] Iteration 21800, lr = 0.01
I0621 07:34:28.792863 32183 solver.cpp:219] Iteration 21850 (0.706159 iter/s, 70.8056s/50 iters), loss = 0.0305789
I0621 07:34:28.793009 32183 solver.cpp:238]     Train net output #0: loss = 0.0291383 (* 1 = 0.0291383 loss)
I0621 07:34:28.793035 32183 sgd_solver.cpp:105] Iteration 21850, lr = 0.01
I0621 07:35:39.570137 32183 solver.cpp:219] Iteration 21900 (0.706451 iter/s, 70.7763s/50 iters), loss = 0.0209265
I0621 07:35:39.570283 32183 solver.cpp:238]     Train net output #0: loss = 0.017523 (* 1 = 0.017523 loss)
I0621 07:35:39.570314 32183 sgd_solver.cpp:105] Iteration 21900, lr = 0.01
I0621 07:36:50.340471 32183 solver.cpp:219] Iteration 21950 (0.70652 iter/s, 70.7694s/50 iters), loss = 0.0206592
I0621 07:36:50.340611 32183 solver.cpp:238]     Train net output #0: loss = 0.0213996 (* 1 = 0.0213996 loss)
I0621 07:36:50.340638 32183 sgd_solver.cpp:105] Iteration 21950, lr = 0.01
I0621 07:37:59.699095 32183 solver.cpp:331] Iteration 22000, Testing net (#0)
I0621 07:38:14.293735 32183 solver.cpp:398]     Test net output #0: accuracy = 0.934678
I0621 07:38:14.293815 32183 solver.cpp:398]     Test net output #1: loss = 0.318397 (* 1 = 0.318397 loss)
I0621 07:38:15.704064 32183 solver.cpp:219] Iteration 22000 (0.585737 iter/s, 85.3625s/50 iters), loss = 0.0296606
I0621 07:38:15.704155 32183 solver.cpp:238]     Train net output #0: loss = 0.0258932 (* 1 = 0.0258932 loss)
I0621 07:38:15.704180 32183 sgd_solver.cpp:105] Iteration 22000, lr = 0.01
I0621 07:39:26.471355 32183 solver.cpp:219] Iteration 22050 (0.70655 iter/s, 70.7664s/50 iters), loss = 0.0266572
I0621 07:39:26.471541 32183 solver.cpp:238]     Train net output #0: loss = 0.0459131 (* 1 = 0.0459131 loss)
I0621 07:39:26.471570 32183 sgd_solver.cpp:105] Iteration 22050, lr = 0.01
I0621 07:40:37.244555 32183 solver.cpp:219] Iteration 22100 (0.706492 iter/s, 70.7722s/50 iters), loss = 0.025218
I0621 07:40:37.244714 32183 solver.cpp:238]     Train net output #0: loss = 0.0159842 (* 1 = 0.0159842 loss)
I0621 07:40:37.244741 32183 sgd_solver.cpp:105] Iteration 22100, lr = 0.01
I0621 07:41:48.028751 32183 solver.cpp:219] Iteration 22150 (0.706382 iter/s, 70.7832s/50 iters), loss = 0.0304494
I0621 07:41:48.028884 32183 solver.cpp:238]     Train net output #0: loss = 0.0113465 (* 1 = 0.0113465 loss)
I0621 07:41:48.028910 32183 sgd_solver.cpp:105] Iteration 22150, lr = 0.01
I0621 07:42:58.823055 32183 solver.cpp:219] Iteration 22200 (0.706281 iter/s, 70.7934s/50 iters), loss = 0.0588118
I0621 07:42:58.823220 32183 solver.cpp:238]     Train net output #0: loss = 0.0302249 (* 1 = 0.0302249 loss)
I0621 07:42:58.823246 32183 sgd_solver.cpp:105] Iteration 22200, lr = 0.01
I0621 07:44:09.591387 32183 solver.cpp:219] Iteration 22250 (0.70654 iter/s, 70.7674s/50 iters), loss = 0.0233022
I0621 07:44:09.591521 32183 solver.cpp:238]     Train net output #0: loss = 0.0288212 (* 1 = 0.0288212 loss)
I0621 07:44:09.591549 32183 sgd_solver.cpp:105] Iteration 22250, lr = 0.01
I0621 07:45:20.359876 32183 solver.cpp:219] Iteration 22300 (0.706538 iter/s, 70.7676s/50 iters), loss = 0.0199289
I0621 07:45:20.360026 32183 solver.cpp:238]     Train net output #0: loss = 0.0143351 (* 1 = 0.0143351 loss)
I0621 07:45:20.360054 32183 sgd_solver.cpp:105] Iteration 22300, lr = 0.01
I0621 07:46:31.141229 32183 solver.cpp:219] Iteration 22350 (0.70641 iter/s, 70.7804s/50 iters), loss = 0.0289656
I0621 07:46:31.141427 32183 solver.cpp:238]     Train net output #0: loss = 0.0167578 (* 1 = 0.0167578 loss)
I0621 07:46:31.141454 32183 sgd_solver.cpp:105] Iteration 22350, lr = 0.01
I0621 07:47:41.924105 32183 solver.cpp:219] Iteration 22400 (0.706395 iter/s, 70.7819s/50 iters), loss = 0.0358237
I0621 07:47:41.924242 32183 solver.cpp:238]     Train net output #0: loss = 0.034392 (* 1 = 0.034392 loss)
I0621 07:47:41.924268 32183 sgd_solver.cpp:105] Iteration 22400, lr = 0.01
I0621 07:48:52.703636 32183 solver.cpp:219] Iteration 22450 (0.706428 iter/s, 70.7786s/50 iters), loss = 0.025766
I0621 07:48:52.703801 32183 solver.cpp:238]     Train net output #0: loss = 0.0259001 (* 1 = 0.0259001 loss)
I0621 07:48:52.703827 32183 sgd_solver.cpp:105] Iteration 22450, lr = 0.01
I0621 07:50:02.063935 32183 solver.cpp:331] Iteration 22500, Testing net (#0)
I0621 07:50:16.643636 32183 solver.cpp:398]     Test net output #0: accuracy = 0.905646
I0621 07:50:16.643713 32183 solver.cpp:398]     Test net output #1: loss = 0.460938 (* 1 = 0.460938 loss)
I0621 07:50:18.054044 32183 solver.cpp:219] Iteration 22500 (0.585828 iter/s, 85.3493s/50 iters), loss = 0.0265733
I0621 07:50:18.054129 32183 solver.cpp:238]     Train net output #0: loss = 0.0216114 (* 1 = 0.0216114 loss)
I0621 07:50:18.054154 32183 sgd_solver.cpp:105] Iteration 22500, lr = 0.01
I0621 07:51:28.797359 32183 solver.cpp:219] Iteration 22550 (0.706789 iter/s, 70.7424s/50 iters), loss = 0.0274911
I0621 07:51:28.797533 32183 solver.cpp:238]     Train net output #0: loss = 0.0360341 (* 1 = 0.0360341 loss)
I0621 07:51:28.797559 32183 sgd_solver.cpp:105] Iteration 22550, lr = 0.01
I0621 07:52:39.551947 32183 solver.cpp:219] Iteration 22600 (0.706677 iter/s, 70.7536s/50 iters), loss = 0.0227076
I0621 07:52:39.552088 32183 solver.cpp:238]     Train net output #0: loss = 0.0305749 (* 1 = 0.0305749 loss)
I0621 07:52:39.552114 32183 sgd_solver.cpp:105] Iteration 22600, lr = 0.01
I0621 07:53:50.306838 32183 solver.cpp:219] Iteration 22650 (0.706674 iter/s, 70.754s/50 iters), loss = 0.0296228
I0621 07:53:50.307004 32183 solver.cpp:238]     Train net output #0: loss = 0.037786 (* 1 = 0.037786 loss)
I0621 07:53:50.307031 32183 sgd_solver.cpp:105] Iteration 22650, lr = 0.01
I0621 07:55:01.056357 32183 solver.cpp:219] Iteration 22700 (0.706726 iter/s, 70.7487s/50 iters), loss = 0.0260689
I0621 07:55:01.056579 32183 solver.cpp:238]     Train net output #0: loss = 0.0323829 (* 1 = 0.0323829 loss)
I0621 07:55:01.056632 32183 sgd_solver.cpp:105] Iteration 22700, lr = 0.01
I0621 07:56:11.803882 32183 solver.cpp:219] Iteration 22750 (0.706746 iter/s, 70.7468s/50 iters), loss = 0.0394975
I0621 07:56:11.804018 32183 solver.cpp:238]     Train net output #0: loss = 0.0239481 (* 1 = 0.0239481 loss)
I0621 07:56:11.804045 32183 sgd_solver.cpp:105] Iteration 22750, lr = 0.01
I0621 07:57:22.549815 32183 solver.cpp:219] Iteration 22800 (0.706761 iter/s, 70.7452s/50 iters), loss = 0.0353129
I0621 07:57:22.549964 32183 solver.cpp:238]     Train net output #0: loss = 0.044524 (* 1 = 0.044524 loss)
I0621 07:57:22.549990 32183 sgd_solver.cpp:105] Iteration 22800, lr = 0.01
I0621 07:58:33.297739 32183 solver.cpp:219] Iteration 22850 (0.706742 iter/s, 70.7472s/50 iters), loss = 0.0504793
I0621 07:58:33.297881 32183 solver.cpp:238]     Train net output #0: loss = 0.0543633 (* 1 = 0.0543633 loss)
I0621 07:58:33.297907 32183 sgd_solver.cpp:105] Iteration 22850, lr = 0.01
I0621 07:59:44.050254 32183 solver.cpp:219] Iteration 22900 (0.706696 iter/s, 70.7518s/50 iters), loss = 0.0391541
I0621 07:59:44.050400 32183 solver.cpp:238]     Train net output #0: loss = 0.0293875 (* 1 = 0.0293875 loss)
I0621 07:59:44.050426 32183 sgd_solver.cpp:105] Iteration 22900, lr = 0.01
I0621 08:00:54.797608 32183 solver.cpp:219] Iteration 22950 (0.706747 iter/s, 70.7466s/50 iters), loss = 0.163291
I0621 08:00:54.797761 32183 solver.cpp:238]     Train net output #0: loss = 0.267938 (* 1 = 0.267938 loss)
I0621 08:00:54.797792 32183 sgd_solver.cpp:105] Iteration 22950, lr = 0.01
I0621 08:02:04.137701 32183 solver.cpp:331] Iteration 23000, Testing net (#0)
I0621 08:02:18.684322 32183 solver.cpp:398]     Test net output #0: accuracy = 0.231452
I0621 08:02:18.684406 32183 solver.cpp:398]     Test net output #1: loss = 3.57426 (* 1 = 3.57426 loss)
I0621 08:02:20.094583 32183 solver.cpp:219] Iteration 23000 (0.586193 iter/s, 85.2962s/50 iters), loss = 0.128803
I0621 08:02:20.094661 32183 solver.cpp:238]     Train net output #0: loss = 0.087655 (* 1 = 0.087655 loss)
I0621 08:02:20.094691 32183 sgd_solver.cpp:105] Iteration 23000, lr = 0.01
I0621 08:03:30.836804 32183 solver.cpp:219] Iteration 23050 (0.706798 iter/s, 70.7416s/50 iters), loss = 0.13666
I0621 08:03:30.837050 32183 solver.cpp:238]     Train net output #0: loss = 0.157702 (* 1 = 0.157702 loss)
I0621 08:03:30.837077 32183 sgd_solver.cpp:105] Iteration 23050, lr = 0.01
I0621 08:04:41.582271 32183 solver.cpp:219] Iteration 23100 (0.706767 iter/s, 70.7447s/50 iters), loss = 0.232446
I0621 08:04:41.582397 32183 solver.cpp:238]     Train net output #0: loss = 0.0904794 (* 1 = 0.0904794 loss)
I0621 08:04:41.582422 32183 sgd_solver.cpp:105] Iteration 23100, lr = 0.01
I0621 08:05:52.325978 32183 solver.cpp:219] Iteration 23150 (0.706783 iter/s, 70.743s/50 iters), loss = 0.184522
I0621 08:05:52.326117 32183 solver.cpp:238]     Train net output #0: loss = 0.117191 (* 1 = 0.117191 loss)
I0621 08:05:52.326143 32183 sgd_solver.cpp:105] Iteration 23150, lr = 0.01
I0621 08:07:03.067668 32183 solver.cpp:219] Iteration 23200 (0.706804 iter/s, 70.741s/50 iters), loss = 0.421855
I0621 08:07:03.067844 32183 solver.cpp:238]     Train net output #0: loss = 0.439677 (* 1 = 0.439677 loss)
I0621 08:07:03.067870 32183 sgd_solver.cpp:105] Iteration 23200, lr = 0.01
I0621 08:08:13.811506 32183 solver.cpp:219] Iteration 23250 (0.706783 iter/s, 70.7431s/50 iters), loss = 0.211409
I0621 08:08:13.811699 32183 solver.cpp:238]     Train net output #0: loss = 0.0909691 (* 1 = 0.0909691 loss)
I0621 08:08:13.811727 32183 sgd_solver.cpp:105] Iteration 23250, lr = 0.01
I0621 08:09:24.561257 32183 solver.cpp:219] Iteration 23300 (0.706724 iter/s, 70.749s/50 iters), loss = 0.198729
I0621 08:09:24.561408 32183 solver.cpp:238]     Train net output #0: loss = 0.131263 (* 1 = 0.131263 loss)
I0621 08:09:24.561434 32183 sgd_solver.cpp:105] Iteration 23300, lr = 0.01
I0621 08:10:35.308229 32183 solver.cpp:219] Iteration 23350 (0.706751 iter/s, 70.7463s/50 iters), loss = 0.150788
I0621 08:10:35.308379 32183 solver.cpp:238]     Train net output #0: loss = 0.078708 (* 1 = 0.078708 loss)
I0621 08:10:35.308416 32183 sgd_solver.cpp:105] Iteration 23350, lr = 0.01
I0621 08:11:46.069056 32183 solver.cpp:219] Iteration 23400 (0.706613 iter/s, 70.7601s/50 iters), loss = 0.105167
I0621 08:11:46.069207 32183 solver.cpp:238]     Train net output #0: loss = 0.140118 (* 1 = 0.140118 loss)
I0621 08:11:46.069233 32183 sgd_solver.cpp:105] Iteration 23400, lr = 0.01
I0621 08:12:56.829795 32183 solver.cpp:219] Iteration 23450 (0.706614 iter/s, 70.76s/50 iters), loss = 0.0770094
I0621 08:12:56.829946 32183 solver.cpp:238]     Train net output #0: loss = 0.0382832 (* 1 = 0.0382832 loss)
I0621 08:12:56.829972 32183 sgd_solver.cpp:105] Iteration 23450, lr = 0.01
I0621 08:14:06.175262 32183 solver.cpp:331] Iteration 23500, Testing net (#0)
I0621 08:14:20.783756 32183 solver.cpp:398]     Test net output #0: accuracy = 0.476613
I0621 08:14:20.783838 32183 solver.cpp:398]     Test net output #1: loss = 2.51643 (* 1 = 2.51643 loss)
I0621 08:14:22.194286 32183 solver.cpp:219] Iteration 23500 (0.585729 iter/s, 85.3637s/50 iters), loss = 0.0776583
I0621 08:14:22.194386 32183 solver.cpp:238]     Train net output #0: loss = 0.0589603 (* 1 = 0.0589603 loss)
I0621 08:14:22.194416 32183 sgd_solver.cpp:105] Iteration 23500, lr = 0.01
I0621 08:15:32.947888 32183 solver.cpp:219] Iteration 23550 (0.706684 iter/s, 70.7529s/50 iters), loss = 0.0629885
I0621 08:15:32.948040 32183 solver.cpp:238]     Train net output #0: loss = 0.028794 (* 1 = 0.028794 loss)
I0621 08:15:32.948067 32183 sgd_solver.cpp:105] Iteration 23550, lr = 0.01
I0621 08:16:43.700906 32183 solver.cpp:219] Iteration 23600 (0.706691 iter/s, 70.7523s/50 iters), loss = 0.0782309
I0621 08:16:43.701071 32183 solver.cpp:238]     Train net output #0: loss = 0.0451563 (* 1 = 0.0451563 loss)
I0621 08:16:43.701097 32183 sgd_solver.cpp:105] Iteration 23600, lr = 0.01
I0621 08:17:54.452157 32183 solver.cpp:219] Iteration 23650 (0.706709 iter/s, 70.7505s/50 iters), loss = 0.0631007
I0621 08:17:54.452322 32183 solver.cpp:238]     Train net output #0: loss = 0.0334204 (* 1 = 0.0334204 loss)
I0621 08:17:54.452348 32183 sgd_solver.cpp:105] Iteration 23650, lr = 0.01
I0621 08:19:05.210155 32183 solver.cpp:219] Iteration 23700 (0.706641 iter/s, 70.7573s/50 iters), loss = 0.0364863
I0621 08:19:05.210299 32183 solver.cpp:238]     Train net output #0: loss = 0.0134738 (* 1 = 0.0134738 loss)
I0621 08:19:05.210325 32183 sgd_solver.cpp:105] Iteration 23700, lr = 0.01
I0621 08:20:15.964998 32183 solver.cpp:219] Iteration 23750 (0.706673 iter/s, 70.7541s/50 iters), loss = 0.0213049
I0621 08:20:15.965139 32183 solver.cpp:238]     Train net output #0: loss = 0.0114212 (* 1 = 0.0114212 loss)
I0621 08:20:15.965171 32183 sgd_solver.cpp:105] Iteration 23750, lr = 0.01
I0621 08:21:26.716722 32183 solver.cpp:219] Iteration 23800 (0.706704 iter/s, 70.751s/50 iters), loss = 0.0315378
I0621 08:21:26.716845 32183 solver.cpp:238]     Train net output #0: loss = 0.0282646 (* 1 = 0.0282646 loss)
I0621 08:21:26.716871 32183 sgd_solver.cpp:105] Iteration 23800, lr = 0.01
I0621 08:22:37.459616 32183 solver.cpp:219] Iteration 23850 (0.706792 iter/s, 70.7422s/50 iters), loss = 0.0359677
I0621 08:22:37.459753 32183 solver.cpp:238]     Train net output #0: loss = 0.0548799 (* 1 = 0.0548799 loss)
I0621 08:22:37.459779 32183 sgd_solver.cpp:105] Iteration 23850, lr = 0.01
I0621 08:23:48.206724 32183 solver.cpp:219] Iteration 23900 (0.70675 iter/s, 70.7464s/50 iters), loss = 0.0399065
I0621 08:23:48.206928 32183 solver.cpp:238]     Train net output #0: loss = 0.0290092 (* 1 = 0.0290092 loss)
I0621 08:23:48.206954 32183 sgd_solver.cpp:105] Iteration 23900, lr = 0.01
I0621 08:24:58.957196 32183 solver.cpp:219] Iteration 23950 (0.706717 iter/s, 70.7497s/50 iters), loss = 0.0346665
I0621 08:24:58.957341 32183 solver.cpp:238]     Train net output #0: loss = 0.0225289 (* 1 = 0.0225289 loss)
I0621 08:24:58.957367 32183 sgd_solver.cpp:105] Iteration 23950, lr = 0.01
I0621 08:26:08.300365 32183 solver.cpp:331] Iteration 24000, Testing net (#0)
I0621 08:26:22.877024 32183 solver.cpp:398]     Test net output #0: accuracy = 0.895968
I0621 08:26:22.877125 32183 solver.cpp:398]     Test net output #1: loss = 0.40702 (* 1 = 0.40702 loss)
I0621 08:26:24.287547 32183 solver.cpp:219] Iteration 24000 (0.585964 iter/s, 85.3295s/50 iters), loss = 0.0368537
I0621 08:26:24.287632 32183 solver.cpp:238]     Train net output #0: loss = 0.0310209 (* 1 = 0.0310209 loss)
I0621 08:26:24.287662 32183 sgd_solver.cpp:105] Iteration 24000, lr = 0.01
I0621 08:27:35.028581 32183 solver.cpp:219] Iteration 24050 (0.70681 iter/s, 70.7404s/50 iters), loss = 0.024684
I0621 08:27:35.038596 32183 solver.cpp:238]     Train net output #0: loss = 0.00913596 (* 1 = 0.00913596 loss)
I0621 08:27:35.038622 32183 sgd_solver.cpp:105] Iteration 24050, lr = 0.01
I0621 08:28:45.779510 32183 solver.cpp:219] Iteration 24100 (0.706811 iter/s, 70.7403s/50 iters), loss = 0.0335426
I0621 08:28:45.779661 32183 solver.cpp:238]     Train net output #0: loss = 0.0174689 (* 1 = 0.0174689 loss)
I0621 08:28:45.779688 32183 sgd_solver.cpp:105] Iteration 24100, lr = 0.01
I0621 08:29:56.529604 32183 solver.cpp:219] Iteration 24150 (0.706721 iter/s, 70.7493s/50 iters), loss = 0.0500069
I0621 08:29:56.529747 32183 solver.cpp:238]     Train net output #0: loss = 0.143744 (* 1 = 0.143744 loss)
I0621 08:29:56.529773 32183 sgd_solver.cpp:105] Iteration 24150, lr = 0.01
I0621 08:31:07.276415 32183 solver.cpp:219] Iteration 24200 (0.706754 iter/s, 70.746s/50 iters), loss = 0.0201183
I0621 08:31:07.276557 32183 solver.cpp:238]     Train net output #0: loss = 0.0214383 (* 1 = 0.0214383 loss)
I0621 08:31:07.276584 32183 sgd_solver.cpp:105] Iteration 24200, lr = 0.01
I0621 08:32:18.025459 32183 solver.cpp:219] Iteration 24250 (0.706732 iter/s, 70.7482s/50 iters), loss = 0.0485581
I0621 08:32:18.025595 32183 solver.cpp:238]     Train net output #0: loss = 0.0246869 (* 1 = 0.0246869 loss)
I0621 08:32:18.025621 32183 sgd_solver.cpp:105] Iteration 24250, lr = 0.01
I0621 08:33:28.766367 32183 solver.cpp:219] Iteration 24300 (0.706813 iter/s, 70.7401s/50 iters), loss = 0.0382058
I0621 08:33:28.766510 32183 solver.cpp:238]     Train net output #0: loss = 0.0337883 (* 1 = 0.0337883 loss)
I0621 08:33:28.766543 32183 sgd_solver.cpp:105] Iteration 24300, lr = 0.01
I0621 08:34:39.511337 32183 solver.cpp:219] Iteration 24350 (0.706772 iter/s, 70.7441s/50 iters), loss = 0.0303921
I0621 08:34:39.511474 32183 solver.cpp:238]     Train net output #0: loss = 0.0210479 (* 1 = 0.0210479 loss)
I0621 08:34:39.511500 32183 sgd_solver.cpp:105] Iteration 24350, lr = 0.01
I0621 08:35:50.252874 32183 solver.cpp:219] Iteration 24400 (0.706807 iter/s, 70.7407s/50 iters), loss = 0.0355471
I0621 08:35:50.253005 32183 solver.cpp:238]     Train net output #0: loss = 0.0155442 (* 1 = 0.0155442 loss)
I0621 08:35:50.253031 32183 sgd_solver.cpp:105] Iteration 24400, lr = 0.01
I0621 08:37:01.000483 32183 solver.cpp:219] Iteration 24450 (0.706746 iter/s, 70.7468s/50 iters), loss = 0.0366621
I0621 08:37:01.000630 32183 solver.cpp:238]     Train net output #0: loss = 0.0126104 (* 1 = 0.0126104 loss)
I0621 08:37:01.000656 32183 sgd_solver.cpp:105] Iteration 24450, lr = 0.01
I0621 08:38:10.332234 32183 solver.cpp:331] Iteration 24500, Testing net (#0)
I0621 08:38:21.793728 32183 blocking_queue.cpp:49] Waiting for data
I0621 08:38:24.913934 32183 solver.cpp:398]     Test net output #0: accuracy = 0.923387
I0621 08:38:24.914013 32183 solver.cpp:398]     Test net output #1: loss = 0.337315 (* 1 = 0.337315 loss)
I0621 08:38:26.323523 32183 solver.cpp:219] Iteration 24500 (0.586015 iter/s, 85.3221s/50 iters), loss = 0.034328
I0621 08:38:26.323609 32183 solver.cpp:238]     Train net output #0: loss = 0.0156464 (* 1 = 0.0156464 loss)
I0621 08:38:26.323638 32183 sgd_solver.cpp:105] Iteration 24500, lr = 0.01
I0621 08:39:37.060866 32183 solver.cpp:219] Iteration 24550 (0.706848 iter/s, 70.7366s/50 iters), loss = 0.0244182
I0621 08:39:37.061064 32183 solver.cpp:238]     Train net output #0: loss = 0.0368937 (* 1 = 0.0368937 loss)
I0621 08:39:37.061090 32183 sgd_solver.cpp:105] Iteration 24550, lr = 0.01
I0621 08:40:47.793133 32183 solver.cpp:219] Iteration 24600 (0.7069 iter/s, 70.7314s/50 iters), loss = 0.0331058
I0621 08:40:47.793290 32183 solver.cpp:238]     Train net output #0: loss = 0.0426978 (* 1 = 0.0426978 loss)
I0621 08:40:47.793316 32183 sgd_solver.cpp:105] Iteration 24600, lr = 0.01
I0621 08:41:58.525889 32183 solver.cpp:219] Iteration 24650 (0.706894 iter/s, 70.7319s/50 iters), loss = 0.0314938
I0621 08:41:58.526023 32183 solver.cpp:238]     Train net output #0: loss = 0.0765227 (* 1 = 0.0765227 loss)
I0621 08:41:58.526049 32183 sgd_solver.cpp:105] Iteration 24650, lr = 0.01
I0621 08:43:09.266095 32183 solver.cpp:219] Iteration 24700 (0.70682 iter/s, 70.7394s/50 iters), loss = 0.0390371
I0621 08:43:09.266234 32183 solver.cpp:238]     Train net output #0: loss = 0.112572 (* 1 = 0.112572 loss)
I0621 08:43:09.266260 32183 sgd_solver.cpp:105] Iteration 24700, lr = 0.01
I0621 08:44:20.006160 32183 solver.cpp:219] Iteration 24750 (0.706821 iter/s, 70.7392s/50 iters), loss = 0.0358362
I0621 08:44:20.006305 32183 solver.cpp:238]     Train net output #0: loss = 0.0239021 (* 1 = 0.0239021 loss)
I0621 08:44:20.006331 32183 sgd_solver.cpp:105] Iteration 24750, lr = 0.01
I0621 08:45:30.749617 32183 solver.cpp:219] Iteration 24800 (0.706787 iter/s, 70.7426s/50 iters), loss = 0.0358906
I0621 08:45:30.749833 32183 solver.cpp:238]     Train net output #0: loss = 0.0185624 (* 1 = 0.0185624 loss)
I0621 08:45:30.749861 32183 sgd_solver.cpp:105] Iteration 24800, lr = 0.01
I0621 08:46:41.492266 32183 solver.cpp:219] Iteration 24850 (0.706796 iter/s, 70.7418s/50 iters), loss = 0.0342115
I0621 08:46:41.492398 32183 solver.cpp:238]     Train net output #0: loss = 0.0189594 (* 1 = 0.0189594 loss)
I0621 08:46:41.492424 32183 sgd_solver.cpp:105] Iteration 24850, lr = 0.01
I0621 08:47:52.228399 32183 solver.cpp:219] Iteration 24900 (0.70686 iter/s, 70.7353s/50 iters), loss = 0.0256079
I0621 08:47:52.228538 32183 solver.cpp:238]     Train net output #0: loss = 0.0295823 (* 1 = 0.0295823 loss)
I0621 08:47:52.228564 32183 sgd_solver.cpp:105] Iteration 24900, lr = 0.01
I0621 08:49:02.970504 32183 solver.cpp:219] Iteration 24950 (0.706801 iter/s, 70.7413s/50 iters), loss = 0.0194406
I0621 08:49:02.970646 32183 solver.cpp:238]     Train net output #0: loss = 0.0169045 (* 1 = 0.0169045 loss)
I0621 08:49:02.970672 32183 sgd_solver.cpp:105] Iteration 24950, lr = 0.01
I0621 08:50:12.294263 32183 solver.cpp:331] Iteration 25000, Testing net (#0)
I0621 08:50:26.843276 32183 solver.cpp:398]     Test net output #0: accuracy = 0.925
I0621 08:50:26.843344 32183 solver.cpp:398]     Test net output #1: loss = 0.36822 (* 1 = 0.36822 loss)
I0621 08:50:28.253213 32183 solver.cpp:219] Iteration 25000 (0.586292 iter/s, 85.2818s/50 iters), loss = 0.0302677
I0621 08:50:28.253306 32183 solver.cpp:238]     Train net output #0: loss = 0.0241216 (* 1 = 0.0241216 loss)
I0621 08:50:28.253331 32183 sgd_solver.cpp:105] Iteration 25000, lr = 0.01
I0621 08:51:38.985882 32183 solver.cpp:219] Iteration 25050 (0.706895 iter/s, 70.7319s/50 iters), loss = 0.0219557
I0621 08:51:38.986017 32183 solver.cpp:238]     Train net output #0: loss = 0.0195912 (* 1 = 0.0195912 loss)
I0621 08:51:38.986043 32183 sgd_solver.cpp:105] Iteration 25050, lr = 0.01
I0621 08:52:49.720227 32183 solver.cpp:219] Iteration 25100 (0.706878 iter/s, 70.7335s/50 iters), loss = 0.0432257
I0621 08:52:49.720357 32183 solver.cpp:238]     Train net output #0: loss = 0.0241559 (* 1 = 0.0241559 loss)
I0621 08:52:49.720383 32183 sgd_solver.cpp:105] Iteration 25100, lr = 0.01
I0621 08:54:00.452638 32183 solver.cpp:219] Iteration 25150 (0.706898 iter/s, 70.7316s/50 iters), loss = 0.0289942
I0621 08:54:00.452821 32183 solver.cpp:238]     Train net output #0: loss = 0.0196306 (* 1 = 0.0196306 loss)
I0621 08:54:00.452849 32183 sgd_solver.cpp:105] Iteration 25150, lr = 0.01
I0621 08:55:11.189756 32183 solver.cpp:219] Iteration 25200 (0.706851 iter/s, 70.7363s/50 iters), loss = 0.0322605
I0621 08:55:11.189908 32183 solver.cpp:238]     Train net output #0: loss = 0.0215749 (* 1 = 0.0215749 loss)
I0621 08:55:11.189939 32183 sgd_solver.cpp:105] Iteration 25200, lr = 0.01
I0621 08:56:21.936616 32183 solver.cpp:219] Iteration 25250 (0.706753 iter/s, 70.746s/50 iters), loss = 0.0212404
I0621 08:56:21.936750 32183 solver.cpp:238]     Train net output #0: loss = 0.0185338 (* 1 = 0.0185338 loss)
I0621 08:56:21.936776 32183 sgd_solver.cpp:105] Iteration 25250, lr = 0.01
I0621 08:57:32.678798 32183 solver.cpp:219] Iteration 25300 (0.7068 iter/s, 70.7414s/50 iters), loss = 0.0239131
I0621 08:57:32.678936 32183 solver.cpp:238]     Train net output #0: loss = 0.0118633 (* 1 = 0.0118633 loss)
I0621 08:57:32.678961 32183 sgd_solver.cpp:105] Iteration 25300, lr = 0.01
I0621 08:58:43.423022 32183 solver.cpp:219] Iteration 25350 (0.70678 iter/s, 70.7434s/50 iters), loss = 0.121065
I0621 08:58:43.423161 32183 solver.cpp:238]     Train net output #0: loss = 0.0234845 (* 1 = 0.0234845 loss)
I0621 08:58:43.423187 32183 sgd_solver.cpp:105] Iteration 25350, lr = 0.01
I0621 08:59:54.167855 32183 solver.cpp:219] Iteration 25400 (0.706774 iter/s, 70.744s/50 iters), loss = 0.0395216
I0621 08:59:54.168020 32183 solver.cpp:238]     Train net output #0: loss = 0.0686693 (* 1 = 0.0686693 loss)
I0621 08:59:54.168052 32183 sgd_solver.cpp:105] Iteration 25400, lr = 0.01
I0621 09:01:04.913658 32183 solver.cpp:219] Iteration 25450 (0.706764 iter/s, 70.745s/50 iters), loss = 0.0395622
I0621 09:01:04.913800 32183 solver.cpp:238]     Train net output #0: loss = 0.0439241 (* 1 = 0.0439241 loss)
I0621 09:01:04.913825 32183 sgd_solver.cpp:105] Iteration 25450, lr = 0.01
I0621 09:02:14.254954 32183 solver.cpp:331] Iteration 25500, Testing net (#0)
I0621 09:02:28.817569 32183 solver.cpp:398]     Test net output #0: accuracy = 0.912097
I0621 09:02:28.817653 32183 solver.cpp:398]     Test net output #1: loss = 0.408487 (* 1 = 0.408487 loss)
I0621 09:02:30.227759 32183 solver.cpp:219] Iteration 25500 (0.586076 iter/s, 85.3132s/50 iters), loss = 0.0336517
I0621 09:02:30.227849 32183 solver.cpp:238]     Train net output #0: loss = 0.0179785 (* 1 = 0.0179785 loss)
I0621 09:02:30.227879 32183 sgd_solver.cpp:105] Iteration 25500, lr = 0.01
I0621 09:03:40.973047 32183 solver.cpp:219] Iteration 25550 (0.706769 iter/s, 70.7445s/50 iters), loss = 0.028422
I0621 09:03:40.973181 32183 solver.cpp:238]     Train net output #0: loss = 0.0510501 (* 1 = 0.0510501 loss)
I0621 09:03:40.973207 32183 sgd_solver.cpp:105] Iteration 25550, lr = 0.01
I0621 09:04:51.718786 32183 solver.cpp:219] Iteration 25600 (0.706764 iter/s, 70.7449s/50 iters), loss = 0.0274612
I0621 09:04:51.718936 32183 solver.cpp:238]     Train net output #0: loss = 0.0110673 (* 1 = 0.0110673 loss)
I0621 09:04:51.718962 32183 sgd_solver.cpp:105] Iteration 25600, lr = 0.01
I0621 09:06:02.457382 32183 solver.cpp:219] Iteration 25650 (0.706836 iter/s, 70.7378s/50 iters), loss = 0.028909
I0621 09:06:02.457528 32183 solver.cpp:238]     Train net output #0: loss = 0.021397 (* 1 = 0.021397 loss)
I0621 09:06:02.457556 32183 sgd_solver.cpp:105] Iteration 25650, lr = 0.01
I0621 09:07:13.194640 32183 solver.cpp:219] Iteration 25700 (0.706849 iter/s, 70.7364s/50 iters), loss = 0.0278987
I0621 09:07:13.194780 32183 solver.cpp:238]     Train net output #0: loss = 0.0229259 (* 1 = 0.0229259 loss)
I0621 09:07:13.194804 32183 sgd_solver.cpp:105] Iteration 25700, lr = 0.01
I0621 09:08:23.931021 32183 solver.cpp:219] Iteration 25750 (0.706858 iter/s, 70.7355s/50 iters), loss = 0.0283781
I0621 09:08:23.931198 32183 solver.cpp:238]     Train net output #0: loss = 0.0132418 (* 1 = 0.0132418 loss)
I0621 09:08:23.931232 32183 sgd_solver.cpp:105] Iteration 25750, lr = 0.01
I0621 09:09:34.670375 32183 solver.cpp:219] Iteration 25800 (0.706829 iter/s, 70.7385s/50 iters), loss = 0.0490588
I0621 09:09:34.670562 32183 solver.cpp:238]     Train net output #0: loss = 0.0231379 (* 1 = 0.0231379 loss)
I0621 09:09:34.670594 32183 sgd_solver.cpp:105] Iteration 25800, lr = 0.01
I0621 09:10:45.406808 32183 solver.cpp:219] Iteration 25850 (0.706858 iter/s, 70.7356s/50 iters), loss = 0.0335689
I0621 09:10:45.406950 32183 solver.cpp:238]     Train net output #0: loss = 0.0319294 (* 1 = 0.0319294 loss)
I0621 09:10:45.406990 32183 sgd_solver.cpp:105] Iteration 25850, lr = 0.01
I0621 09:11:56.146484 32183 solver.cpp:219] Iteration 25900 (0.706825 iter/s, 70.7389s/50 iters), loss = 0.0549314
I0621 09:11:56.146646 32183 solver.cpp:238]     Train net output #0: loss = 0.0189731 (* 1 = 0.0189731 loss)
I0621 09:11:56.146673 32183 sgd_solver.cpp:105] Iteration 25900, lr = 0.01
I0621 09:13:06.888667 32183 solver.cpp:219] Iteration 25950 (0.7068 iter/s, 70.7413s/50 iters), loss = 0.0692976
I0621 09:13:06.888810 32183 solver.cpp:238]     Train net output #0: loss = 0.0778536 (* 1 = 0.0778536 loss)
I0621 09:13:06.888836 32183 sgd_solver.cpp:105] Iteration 25950, lr = 0.01
I0621 09:14:16.229771 32183 solver.cpp:331] Iteration 26000, Testing net (#0)
I0621 09:14:30.822859 32183 solver.cpp:398]     Test net output #0: accuracy = 0.826613
I0621 09:14:30.822937 32183 solver.cpp:398]     Test net output #1: loss = 0.857481 (* 1 = 0.857481 loss)
I0621 09:14:32.232686 32183 solver.cpp:219] Iteration 26000 (0.585871 iter/s, 85.3431s/50 iters), loss = 0.072224
I0621 09:14:32.232764 32183 solver.cpp:238]     Train net output #0: loss = 0.0316138 (* 1 = 0.0316138 loss)
I0621 09:14:32.232785 32183 sgd_solver.cpp:105] Iteration 26000, lr = 0.01
I0621 09:15:42.974014 32183 solver.cpp:219] Iteration 26050 (0.706808 iter/s, 70.7406s/50 iters), loss = 0.0455436
I0621 09:15:42.974154 32183 solver.cpp:238]     Train net output #0: loss = 0.0428637 (* 1 = 0.0428637 loss)
I0621 09:15:42.974180 32183 sgd_solver.cpp:105] Iteration 26050, lr = 0.01
I0621 09:16:53.720582 32183 solver.cpp:219] Iteration 26100 (0.706756 iter/s, 70.7458s/50 iters), loss = 0.0730403
I0621 09:16:53.720727 32183 solver.cpp:238]     Train net output #0: loss = 0.0814489 (* 1 = 0.0814489 loss)
I0621 09:16:53.720753 32183 sgd_solver.cpp:105] Iteration 26100, lr = 0.01
I0621 09:18:04.454090 32183 solver.cpp:219] Iteration 26150 (0.706887 iter/s, 70.7327s/50 iters), loss = 0.0573875
I0621 09:18:04.454227 32183 solver.cpp:238]     Train net output #0: loss = 0.0834956 (* 1 = 0.0834956 loss)
I0621 09:18:04.454252 32183 sgd_solver.cpp:105] Iteration 26150, lr = 0.01
I0621 09:19:15.190013 32183 solver.cpp:219] Iteration 26200 (0.706863 iter/s, 70.7351s/50 iters), loss = 0.045489
I0621 09:19:15.190160 32183 solver.cpp:238]     Train net output #0: loss = 0.022503 (* 1 = 0.022503 loss)
I0621 09:19:15.190186 32183 sgd_solver.cpp:105] Iteration 26200, lr = 0.01
I0621 09:20:25.930670 32183 solver.cpp:219] Iteration 26250 (0.706815 iter/s, 70.7399s/50 iters), loss = 0.0811997
I0621 09:20:25.930824 32183 solver.cpp:238]     Train net output #0: loss = 0.150145 (* 1 = 0.150145 loss)
I0621 09:20:25.930855 32183 sgd_solver.cpp:105] Iteration 26250, lr = 0.01
I0621 09:21:36.681546 32183 solver.cpp:219] Iteration 26300 (0.706713 iter/s, 70.7501s/50 iters), loss = 0.0682018
I0621 09:21:36.681684 32183 solver.cpp:238]     Train net output #0: loss = 0.0485887 (* 1 = 0.0485887 loss)
I0621 09:21:36.681709 32183 sgd_solver.cpp:105] Iteration 26300, lr = 0.01
I0621 09:22:47.429991 32183 solver.cpp:219] Iteration 26350 (0.706737 iter/s, 70.7477s/50 iters), loss = 0.0956764
I0621 09:22:47.430119 32183 solver.cpp:238]     Train net output #0: loss = 0.0811798 (* 1 = 0.0811798 loss)
I0621 09:22:47.430145 32183 sgd_solver.cpp:105] Iteration 26350, lr = 0.01
I0621 09:23:58.172655 32183 solver.cpp:219] Iteration 26400 (0.706795 iter/s, 70.7419s/50 iters), loss = 0.0431542
I0621 09:23:58.172864 32183 solver.cpp:238]     Train net output #0: loss = 0.0276989 (* 1 = 0.0276989 loss)
I0621 09:23:58.172894 32183 sgd_solver.cpp:105] Iteration 26400, lr = 0.01
I0621 09:25:08.922621 32183 solver.cpp:219] Iteration 26450 (0.706723 iter/s, 70.7491s/50 iters), loss = 0.0564297
I0621 09:25:08.922770 32183 solver.cpp:238]     Train net output #0: loss = 0.0244927 (* 1 = 0.0244927 loss)
I0621 09:25:08.922801 32183 sgd_solver.cpp:105] Iteration 26450, lr = 0.01
I0621 09:26:18.271085 32183 solver.cpp:331] Iteration 26500, Testing net (#0)
I0621 09:26:32.863059 32183 solver.cpp:398]     Test net output #0: accuracy = 0.679839
I0621 09:26:32.863153 32183 solver.cpp:398]     Test net output #1: loss = 1.3777 (* 1 = 1.3777 loss)
I0621 09:26:34.273613 32183 solver.cpp:219] Iteration 26500 (0.585823 iter/s, 85.3501s/50 iters), loss = 0.0482933
I0621 09:26:34.273703 32183 solver.cpp:238]     Train net output #0: loss = 0.0417446 (* 1 = 0.0417446 loss)
I0621 09:26:34.273730 32183 sgd_solver.cpp:105] Iteration 26500, lr = 0.01
I0621 09:27:45.022964 32183 solver.cpp:219] Iteration 26550 (0.706728 iter/s, 70.7486s/50 iters), loss = 0.111025
I0621 09:27:45.023077 32183 solver.cpp:238]     Train net output #0: loss = 0.379915 (* 1 = 0.379915 loss)
I0621 09:27:45.023103 32183 sgd_solver.cpp:105] Iteration 26550, lr = 0.01
I0621 09:28:55.770407 32183 solver.cpp:219] Iteration 26600 (0.706747 iter/s, 70.7467s/50 iters), loss = 0.0781417
I0621 09:28:55.770555 32183 solver.cpp:238]     Train net output #0: loss = 0.0807002 (* 1 = 0.0807002 loss)
I0621 09:28:55.770581 32183 sgd_solver.cpp:105] Iteration 26600, lr = 0.01
I0621 09:30:06.511540 32183 solver.cpp:219] Iteration 26650 (0.70681 iter/s, 70.7403s/50 iters), loss = 0.0479981
I0621 09:30:06.511682 32183 solver.cpp:238]     Train net output #0: loss = 0.0466957 (* 1 = 0.0466957 loss)
I0621 09:30:06.511708 32183 sgd_solver.cpp:105] Iteration 26650, lr = 0.01
I0621 09:31:17.248069 32183 solver.cpp:219] Iteration 26700 (0.706856 iter/s, 70.7357s/50 iters), loss = 0.0811335
I0621 09:31:17.248198 32183 solver.cpp:238]     Train net output #0: loss = 0.0648825 (* 1 = 0.0648825 loss)
I0621 09:31:17.248224 32183 sgd_solver.cpp:105] Iteration 26700, lr = 0.01
I0621 09:32:27.991394 32183 solver.cpp:219] Iteration 26750 (0.706788 iter/s, 70.7425s/50 iters), loss = 0.106866
I0621 09:32:27.991544 32183 solver.cpp:238]     Train net output #0: loss = 0.0655525 (* 1 = 0.0655525 loss)
I0621 09:32:27.991570 32183 sgd_solver.cpp:105] Iteration 26750, lr = 0.01
I0621 09:33:38.737277 32183 solver.cpp:219] Iteration 26800 (0.706763 iter/s, 70.7451s/50 iters), loss = 0.0587964
I0621 09:33:38.737426 32183 solver.cpp:238]     Train net output #0: loss = 0.033562 (* 1 = 0.033562 loss)
I0621 09:33:38.737452 32183 sgd_solver.cpp:105] Iteration 26800, lr = 0.01
I0621 09:34:49.480933 32183 solver.cpp:219] Iteration 26850 (0.706785 iter/s, 70.7429s/50 iters), loss = 0.0672206
I0621 09:34:49.481087 32183 solver.cpp:238]     Train net output #0: loss = 0.0432381 (* 1 = 0.0432381 loss)
I0621 09:34:49.481113 32183 sgd_solver.cpp:105] Iteration 26850, lr = 0.01
I0621 09:36:00.220587 32183 solver.cpp:219] Iteration 26900 (0.706825 iter/s, 70.7388s/50 iters), loss = 0.0497906
I0621 09:36:00.222769 32183 solver.cpp:238]     Train net output #0: loss = 0.0246075 (* 1 = 0.0246075 loss)
I0621 09:36:00.222796 32183 sgd_solver.cpp:105] Iteration 26900, lr = 0.01
I0621 09:37:10.962374 32183 solver.cpp:219] Iteration 26950 (0.706825 iter/s, 70.7389s/50 iters), loss = 0.0645377
I0621 09:37:10.963274 32183 solver.cpp:238]     Train net output #0: loss = 0.0242413 (* 1 = 0.0242413 loss)
I0621 09:37:10.963302 32183 sgd_solver.cpp:105] Iteration 26950, lr = 0.01
I0621 09:38:20.292759 32183 solver.cpp:331] Iteration 27000, Testing net (#0)
I0621 09:38:34.870700 32183 solver.cpp:398]     Test net output #0: accuracy = 0.641935
I0621 09:38:34.870772 32183 solver.cpp:398]     Test net output #1: loss = 1.7129 (* 1 = 1.7129 loss)
I0621 09:38:36.280750 32183 solver.cpp:219] Iteration 27000 (0.586052 iter/s, 85.3166s/50 iters), loss = 0.0425318
I0621 09:38:36.280838 32183 solver.cpp:238]     Train net output #0: loss = 0.0568807 (* 1 = 0.0568807 loss)
I0621 09:38:36.280867 32183 sgd_solver.cpp:105] Iteration 27000, lr = 0.01
I0621 09:39:47.027093 32183 solver.cpp:219] Iteration 27050 (0.706758 iter/s, 70.7455s/50 iters), loss = 0.0890787
I0621 09:39:47.027312 32183 solver.cpp:238]     Train net output #0: loss = 0.0425577 (* 1 = 0.0425577 loss)
I0621 09:39:47.027339 32183 sgd_solver.cpp:105] Iteration 27050, lr = 0.01
I0621 09:40:57.763391 32183 solver.cpp:219] Iteration 27100 (0.70686 iter/s, 70.7354s/50 iters), loss = 0.0606853
I0621 09:40:57.763541 32183 solver.cpp:238]     Train net output #0: loss = 0.029684 (* 1 = 0.029684 loss)
I0621 09:40:57.763581 32183 sgd_solver.cpp:105] Iteration 27100, lr = 0.01
I0621 09:42:08.500176 32183 solver.cpp:219] Iteration 27150 (0.706854 iter/s, 70.7359s/50 iters), loss = 0.0472023
I0621 09:42:08.500318 32183 solver.cpp:238]     Train net output #0: loss = 0.0428318 (* 1 = 0.0428318 loss)
I0621 09:42:08.500344 32183 sgd_solver.cpp:105] Iteration 27150, lr = 0.01
I0621 09:43:19.232839 32183 solver.cpp:219] Iteration 27200 (0.706896 iter/s, 70.7318s/50 iters), loss = 0.0821627
I0621 09:43:19.232980 32183 solver.cpp:238]     Train net output #0: loss = 0.0900781 (* 1 = 0.0900781 loss)
I0621 09:43:19.233007 32183 sgd_solver.cpp:105] Iteration 27200, lr = 0.01
I0621 09:44:29.969408 32183 solver.cpp:219] Iteration 27250 (0.706857 iter/s, 70.7357s/50 iters), loss = 0.0785518
I0621 09:44:29.969557 32183 solver.cpp:238]     Train net output #0: loss = 0.0710717 (* 1 = 0.0710717 loss)
I0621 09:44:29.969583 32183 sgd_solver.cpp:105] Iteration 27250, lr = 0.01
I0621 09:45:40.711792 32183 solver.cpp:219] Iteration 27300 (0.706798 iter/s, 70.7415s/50 iters), loss = 0.0864993
I0621 09:45:40.711922 32183 solver.cpp:238]     Train net output #0: loss = 0.0571358 (* 1 = 0.0571358 loss)
I0621 09:45:40.711948 32183 sgd_solver.cpp:105] Iteration 27300, lr = 0.01
I0621 09:46:51.453407 32183 solver.cpp:219] Iteration 27350 (0.706806 iter/s, 70.7408s/50 iters), loss = 0.0612288
I0621 09:46:51.453546 32183 solver.cpp:238]     Train net output #0: loss = 0.0334758 (* 1 = 0.0334758 loss)
I0621 09:46:51.453572 32183 sgd_solver.cpp:105] Iteration 27350, lr = 0.01
I0621 09:48:02.188129 32183 solver.cpp:219] Iteration 27400 (0.706875 iter/s, 70.7339s/50 iters), loss = 0.0844924
I0621 09:48:02.188305 32183 solver.cpp:238]     Train net output #0: loss = 0.0221787 (* 1 = 0.0221787 loss)
I0621 09:48:02.188330 32183 sgd_solver.cpp:105] Iteration 27400, lr = 0.01
I0621 09:49:15.709199 32183 solver.cpp:219] Iteration 27450 (0.680096 iter/s, 73.519s/50 iters), loss = 0.0517367
I0621 09:49:15.709367 32183 solver.cpp:238]     Train net output #0: loss = 0.0433472 (* 1 = 0.0433472 loss)
I0621 09:49:15.709391 32183 sgd_solver.cpp:105] Iteration 27450, lr = 0.01
I0621 09:50:26.492722 32183 solver.cpp:331] Iteration 27500, Testing net (#0)
I0621 09:50:44.029089 32183 solver.cpp:398]     Test net output #0: accuracy = 0.882258
I0621 09:50:44.029209 32183 solver.cpp:398]     Test net output #1: loss = 0.52186 (* 1 = 0.52186 loss)
I0621 09:50:45.513051 32183 solver.cpp:219] Iteration 27500 (0.556776 iter/s, 89.8028s/50 iters), loss = 0.0796935
I0621 09:50:45.513171 32183 solver.cpp:238]     Train net output #0: loss = 0.0418432 (* 1 = 0.0418432 loss)
I0621 09:50:45.513203 32183 sgd_solver.cpp:105] Iteration 27500, lr = 0.01
I0621 09:51:56.584781 32183 solver.cpp:219] Iteration 27550 (0.703523 iter/s, 71.0709s/50 iters), loss = 0.0315851
I0621 09:51:56.584945 32183 solver.cpp:238]     Train net output #0: loss = 0.0286375 (* 1 = 0.0286375 loss)
I0621 09:51:56.584974 32183 sgd_solver.cpp:105] Iteration 27550, lr = 0.01
I0621 09:53:07.353605 32183 solver.cpp:219] Iteration 27600 (0.706535 iter/s, 70.7679s/50 iters), loss = 0.0354903
I0621 09:53:07.353762 32183 solver.cpp:238]     Train net output #0: loss = 0.0388013 (* 1 = 0.0388013 loss)
I0621 09:53:07.353787 32183 sgd_solver.cpp:105] Iteration 27600, lr = 0.01
I0621 09:54:18.112798 32183 solver.cpp:219] Iteration 27650 (0.706631 iter/s, 70.7583s/50 iters), loss = 0.054038
I0621 09:54:18.112984 32183 solver.cpp:238]     Train net output #0: loss = 0.0334629 (* 1 = 0.0334629 loss)
I0621 09:54:18.113011 32183 sgd_solver.cpp:105] Iteration 27650, lr = 0.01
I0621 09:55:28.927067 32183 solver.cpp:219] Iteration 27700 (0.706082 iter/s, 70.8133s/50 iters), loss = 0.0586153
I0621 09:55:28.927230 32183 solver.cpp:238]     Train net output #0: loss = 0.065268 (* 1 = 0.065268 loss)
I0621 09:55:28.927258 32183 sgd_solver.cpp:105] Iteration 27700, lr = 0.01
I0621 09:56:39.677981 32183 solver.cpp:219] Iteration 27750 (0.706713 iter/s, 70.75s/50 iters), loss = 0.0660117
I0621 09:56:39.678133 32183 solver.cpp:238]     Train net output #0: loss = 0.0325728 (* 1 = 0.0325728 loss)
I0621 09:56:39.678158 32183 sgd_solver.cpp:105] Iteration 27750, lr = 0.01
I0621 09:57:51.398831 32183 solver.cpp:219] Iteration 27800 (0.697156 iter/s, 71.72s/50 iters), loss = 0.0269988
I0621 09:57:51.402634 32183 solver.cpp:238]     Train net output #0: loss = 0.0178209 (* 1 = 0.0178209 loss)
I0621 09:57:51.402667 32183 sgd_solver.cpp:105] Iteration 27800, lr = 0.01
I0621 09:59:02.927474 32183 solver.cpp:219] Iteration 27850 (0.699065 iter/s, 71.5241s/50 iters), loss = 0.0395598
I0621 09:59:02.927613 32183 solver.cpp:238]     Train net output #0: loss = 0.0543141 (* 1 = 0.0543141 loss)
I0621 09:59:02.927645 32183 sgd_solver.cpp:105] Iteration 27850, lr = 0.01
I0621 10:00:13.670178 32183 solver.cpp:219] Iteration 27900 (0.706796 iter/s, 70.7418s/50 iters), loss = 0.175157
I0621 10:00:13.670352 32183 solver.cpp:238]     Train net output #0: loss = 0.143858 (* 1 = 0.143858 loss)
I0621 10:00:13.670377 32183 sgd_solver.cpp:105] Iteration 27900, lr = 0.01
I0621 10:01:24.410611 32183 solver.cpp:219] Iteration 27950 (0.706818 iter/s, 70.7396s/50 iters), loss = 0.0753145
I0621 10:01:24.410758 32183 solver.cpp:238]     Train net output #0: loss = 0.0423945 (* 1 = 0.0423945 loss)
I0621 10:01:24.410784 32183 sgd_solver.cpp:105] Iteration 27950, lr = 0.01
I0621 10:02:33.755199 32183 solver.cpp:331] Iteration 28000, Testing net (#0)
I0621 10:02:48.333732 32183 solver.cpp:398]     Test net output #0: accuracy = 0.168548
I0621 10:02:48.333814 32183 solver.cpp:398]     Test net output #1: loss = 4.19089 (* 1 = 4.19089 loss)
I0621 10:02:49.743928 32183 solver.cpp:219] Iteration 28000 (0.585944 iter/s, 85.3323s/50 iters), loss = 0.222725
I0621 10:02:49.744021 32183 solver.cpp:238]     Train net output #0: loss = 0.313731 (* 1 = 0.313731 loss)
I0621 10:02:49.744051 32183 sgd_solver.cpp:105] Iteration 28000, lr = 0.01
I0621 10:04:00.504940 32183 solver.cpp:219] Iteration 28050 (0.706612 iter/s, 70.7602s/50 iters), loss = 0.247304
I0621 10:04:00.505077 32183 solver.cpp:238]     Train net output #0: loss = 0.3733 (* 1 = 0.3733 loss)
I0621 10:04:00.505103 32183 sgd_solver.cpp:105] Iteration 28050, lr = 0.01
I0621 10:05:11.261019 32183 solver.cpp:219] Iteration 28100 (0.706661 iter/s, 70.7552s/50 iters), loss = 0.163513
I0621 10:05:11.261158 32183 solver.cpp:238]     Train net output #0: loss = 0.265508 (* 1 = 0.265508 loss)
I0621 10:05:11.261179 32183 sgd_solver.cpp:105] Iteration 28100, lr = 0.01
I0621 10:06:22.013622 32183 solver.cpp:219] Iteration 28150 (0.706697 iter/s, 70.7517s/50 iters), loss = 0.173486
I0621 10:06:22.013752 32183 solver.cpp:238]     Train net output #0: loss = 0.0984393 (* 1 = 0.0984393 loss)
I0621 10:06:22.013774 32183 sgd_solver.cpp:105] Iteration 28150, lr = 0.01
I0621 10:07:32.781332 32183 solver.cpp:219] Iteration 28200 (0.706545 iter/s, 70.7669s/50 iters), loss = 0.218155
I0621 10:07:32.781461 32183 solver.cpp:238]     Train net output #0: loss = 0.108327 (* 1 = 0.108327 loss)
I0621 10:07:32.781483 32183 sgd_solver.cpp:105] Iteration 28200, lr = 0.01
I0621 10:08:43.534539 32183 solver.cpp:219] Iteration 28250 (0.70669 iter/s, 70.7524s/50 iters), loss = 0.0894166
I0621 10:08:43.534670 32183 solver.cpp:238]     Train net output #0: loss = 0.130085 (* 1 = 0.130085 loss)
I0621 10:08:43.534693 32183 sgd_solver.cpp:105] Iteration 28250, lr = 0.01
I0621 10:09:54.297248 32183 solver.cpp:219] Iteration 28300 (0.706595 iter/s, 70.7619s/50 iters), loss = 0.203453
I0621 10:09:54.297467 32183 solver.cpp:238]     Train net output #0: loss = 0.159327 (* 1 = 0.159327 loss)
I0621 10:09:54.297490 32183 sgd_solver.cpp:105] Iteration 28300, lr = 0.01
I0621 10:11:05.046471 32183 solver.cpp:219] Iteration 28350 (0.706731 iter/s, 70.7483s/50 iters), loss = 0.108643
I0621 10:11:05.046609 32183 solver.cpp:238]     Train net output #0: loss = 0.128109 (* 1 = 0.128109 loss)
I0621 10:11:05.046631 32183 sgd_solver.cpp:105] Iteration 28350, lr = 0.01
I0621 10:12:15.797096 32183 solver.cpp:219] Iteration 28400 (0.706715 iter/s, 70.7498s/50 iters), loss = 0.123692
I0621 10:12:15.797245 32183 solver.cpp:238]     Train net output #0: loss = 0.0522547 (* 1 = 0.0522547 loss)
I0621 10:12:15.797271 32183 sgd_solver.cpp:105] Iteration 28400, lr = 0.01
I0621 10:13:26.672559 32183 solver.cpp:219] Iteration 28450 (0.705471 iter/s, 70.8747s/50 iters), loss = 0.128462
I0621 10:13:26.673528 32183 solver.cpp:238]     Train net output #0: loss = 0.0748929 (* 1 = 0.0748929 loss)
I0621 10:13:26.673558 32183 sgd_solver.cpp:105] Iteration 28450, lr = 0.01
I0621 10:14:37.074476 32183 solver.cpp:331] Iteration 28500, Testing net (#0)
I0621 10:14:48.006083 32183 blocking_queue.cpp:49] Waiting for data
I0621 10:14:54.514158 32183 solver.cpp:398]     Test net output #0: accuracy = 0.204032
I0621 10:14:54.514240 32183 solver.cpp:398]     Test net output #1: loss = 6.20023 (* 1 = 6.20023 loss)
I0621 10:14:55.957132 32183 solver.cpp:219] Iteration 28500 (0.560018 iter/s, 89.2828s/50 iters), loss = 0.0896328
I0621 10:14:55.957252 32183 solver.cpp:238]     Train net output #0: loss = 0.0758936 (* 1 = 0.0758936 loss)
I0621 10:14:55.957274 32183 sgd_solver.cpp:105] Iteration 28500, lr = 0.01
I0621 10:16:08.175065 32183 solver.cpp:219] Iteration 28550 (0.692357 iter/s, 72.2171s/50 iters), loss = 0.133388
I0621 10:16:08.176615 32183 solver.cpp:238]     Train net output #0: loss = 0.103957 (* 1 = 0.103957 loss)
I0621 10:16:08.176642 32183 sgd_solver.cpp:105] Iteration 28550, lr = 0.01
I0621 10:17:19.438244 32183 solver.cpp:219] Iteration 28600 (0.701646 iter/s, 71.261s/50 iters), loss = 0.185122
I0621 10:17:19.438367 32183 solver.cpp:238]     Train net output #0: loss = 0.281881 (* 1 = 0.281881 loss)
I0621 10:17:19.438390 32183 sgd_solver.cpp:105] Iteration 28600, lr = 0.01
I0621 10:18:06.938280 17579 caffe.cpp:218] Using GPUs 1
I0621 10:18:06.988070 17579 caffe.cpp:223] GPU 1: Tesla K40m
I0621 10:18:07.598569 17579 solver.cpp:44] Initializing solver from parameters: 
test_iter: 102
test_interval: 500
base_lr: 0.005
display: 50
max_iter: 40000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 5e-05
stepsize: 20000
snapshot: 4000
snapshot_prefix: "mobilenet/mobile_pruning"
solver_mode: GPU
device_id: 1
net: "/home/xingzhaolong/caffe_project/Auto_prune/models/oxford/mobilenet/mobilenet_deploy.prototxt_pruning"
train_state {
  level: 0
  stage: ""
}
iter_size: 5
I0621 10:18:07.598919 17579 solver.cpp:87] Creating training net from net file: /home/xingzhaolong/caffe_project/Auto_prune/models/oxford/mobilenet/mobilenet_deploy.prototxt_pruning
I0621 10:18:07.601574 17579 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/xingzhaolong/caffe_project/Auto_prune/models/oxford/mobilenet/mobilenet_deploy.prototxt_pruning
I0621 10:18:07.601604 17579 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0621 10:18:07.601902 17579 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0621 10:18:07.601999 17579 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0621 10:18:07.602936 17579 net.cpp:51] Initializing net from parameters: 
name: "MOBILENET"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_file: "/home/xingzhaolong/caffe_project/caffe/models/caffe-oxford102/imagenet_mean.binaryproto"
  }
  image_data_param {
    source: "/home/xingzhaolong/caffe_project/caffe/models/caffe-oxford102/test.txt"
    batch_size: 10
    new_height: 256
    new_width: 256
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv1/bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1/scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2_1/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv1"
  top: "conv2_1/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 32
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv2_1/dw"
  top: "conv2_1/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_1/dw/scale"
  type: "Scale"
  bottom: "conv2_1/dw"
  top: "conv2_1/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_1/dw"
  type: "ReLU"
  bottom: "conv2_1/dw"
  top: "conv2_1/dw"
}
layer {
  name: "conv2_1/sep"
  type: "CConvolution"
  bottom: "conv2_1/dw"
  top: "conv2_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv2_1/sep"
  top: "conv2_1/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_1/sep/scale"
  type: "Scale"
  bottom: "conv2_1/sep"
  top: "conv2_1/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_1/sep"
  type: "ReLU"
  bottom: "conv2_1/sep"
  top: "conv2_1/sep"
}
layer {
  name: "conv2_2/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv2_1/sep"
  top: "conv2_2/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 64
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv2_2/dw"
  top: "conv2_2/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_2/dw/scale"
  type: "Scale"
  bottom: "conv2_2/dw"
  top: "conv2_2/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_2/dw"
  type: "ReLU"
  bottom: "conv2_2/dw"
  top: "conv2_2/dw"
}
layer {
  name: "conv2_2/sep"
  type: "CConvolution"
  bottom: "conv2_2/dw"
  top: "conv2_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv2_2/sep"
  top: "conv2_2/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_2/sep/scale"
  type: "Scale"
  bottom: "conv2_2/sep"
  top: "conv2_2/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_2/sep"
  type: "ReLU"
  bottom: "conv2_2/sep"
  top: "conv2_2/sep"
}
layer {
  name: "conv3_1/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv2_2/sep"
  top: "conv3_1/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv3_1/dw"
  top: "conv3_1/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_1/dw/scale"
  type: "Scale"
  bottom: "conv3_1/dw"
  top: "conv3_1/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_1/dw"
  type: "ReLU"
  bottom: "conv3_1/dw"
  top: "conv3_1/dw"
}
layer {
  name: "conv3_1/sep"
  type: "CConvolution"
  bottom: "conv3_1/dw"
  top: "conv3_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv3_1/sep"
  top: "conv3_1/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_1/sep/scale"
  type: "Scale"
  bottom: "conv3_1/sep"
  top: "conv3_1/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_1/sep"
  type: "ReLU"
  bottom: "conv3_1/sep"
  top: "conv3_1/sep"
}
layer {
  name: "conv3_2/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv3_1/sep"
  top: "conv3_2/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv3_2/dw"
  top: "conv3_2/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_2/dw/scale"
  type: "Scale"
  bottom: "conv3_2/dw"
  top: "conv3_2/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_2/dw"
  type: "ReLU"
  bottom: "conv3_2/dw"
  top: "conv3_2/dw"
}
layer {
  name: "conv3_2/sep"
  type: "CConvolution"
  bottom: "conv3_2/dw"
  top: "conv3_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv3_2/sep"
  top: "conv3_2/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_2/sep/scale"
  type: "Scale"
  bottom: "conv3_2/sep"
  top: "conv3_2/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_2/sep"
  type: "ReLU"
  bottom: "conv3_2/sep"
  top: "conv3_2/sep"
}
layer {
  name: "conv4_1/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv3_2/sep"
  top: "conv4_1/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv4_1/dw"
  top: "conv4_1/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv4_1/dw/scale"
  type: "Scale"
  bottom: "conv4_1/dw"
  top: "conv4_1/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu4_1/dw"
  type: "ReLU"
  bottom: "conv4_1/dw"
  top: "conv4_1/dw"
}
layer {
  name: "conv4_1/sep"
  type: "CConvolution"
  bottom: "conv4_1/dw"
  top: "conv4_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv4_1/sep"
  top: "conv4_1/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv4_1/sep/scale"
  type: "Scale"
  bottom: "conv4_1/sep"
  top: "conv4_1/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu4_1/sep"
  type: "ReLU"
  bottom: "conv4_1/sep"
  top: "conv4_1/sep"
}
layer {
  name: "conv4_2/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv4_1/sep"
  top: "conv4_2/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv4_2/dw"
  top: "conv4_2/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv4_2/dw/scale"
  type: "Scale"
  bottom: "conv4_2/dw"
  top: "conv4_2/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu4_2/dw"
  type: "ReLU"
  bottom: "conv4_2/dw"
  top: "conv4_2/dw"
}
layer {
  name: "conv4_2/sep"
  type: "CConvolution"
  bottom: "conv4_2/dw"
  top: "conv4_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv4_2/sep"
  top: "conv4_2/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv4_2/sep/scale"
  type: "Scale"
  bottom: "conv4_2/sep"
  top: "conv4_2/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu4_2/sep"
  type: "ReLU"
  bottom: "conv4_2/sep"
  top: "conv4_2/sep"
}
layer {
  name: "conv5_1/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv4_2/sep"
  top: "conv5_1/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_1/dw"
  top: "conv5_1/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_1/dw/scale"
  type: "Scale"
  bottom: "conv5_1/dw"
  top: "conv5_1/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_1/dw"
  type: "ReLU"
  bottom: "conv5_1/dw"
  top: "conv5_1/dw"
}
layer {
  name: "conv5_1/sep"
  type: "CConvolution"
  bottom: "conv5_1/dw"
  top: "conv5_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_1/sep"
  top: "conv5_1/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_1/sep/scale"
  type: "Scale"
  bottom: "conv5_1/sep"
  top: "conv5_1/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_1/sep"
  type: "ReLU"
  bottom: "conv5_1/sep"
  top: "conv5_1/sep"
}
layer {
  name: "conv5_2/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_1/sep"
  top: "conv5_2/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_2/dw"
  top: "conv5_2/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_2/dw/scale"
  type: "Scale"
  bottom: "conv5_2/dw"
  top: "conv5_2/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_2/dw"
  type: "ReLU"
  bottom: "conv5_2/dw"
  top: "conv5_2/dw"
}
layer {
  name: "conv5_2/sep"
  type: "CConvolution"
  bottom: "conv5_2/dw"
  top: "conv5_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_2/sep"
  top: "conv5_2/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_2/sep/scale"
  type: "Scale"
  bottom: "conv5_2/sep"
  top: "conv5_2/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_2/sep"
  type: "ReLU"
  bottom: "conv5_2/sep"
  top: "conv5_2/sep"
}
layer {
  name: "conv5_3/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_2/sep"
  top: "conv5_3/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_3/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_3/dw"
  top: "conv5_3/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_3/dw/scale"
  type: "Scale"
  bottom: "conv5_3/dw"
  top: "conv5_3/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_3/dw"
  type: "ReLU"
  bottom: "conv5_3/dw"
  top: "conv5_3/dw"
}
layer {
  name: "conv5_3/sep"
  type: "CConvolution"
  bottom: "conv5_3/dw"
  top: "conv5_3/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_3/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_3/sep"
  top: "conv5_3/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_3/sep/scale"
  type: "Scale"
  bottom: "conv5_3/sep"
  top: "conv5_3/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_3/sep"
  type: "ReLU"
  bottom: "conv5_3/sep"
  top: "conv5_3/sep"
}
layer {
  name: "conv5_4/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_3/sep"
  top: "conv5_4/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_4/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_4/dw"
  top: "conv5_4/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_4/dw/scale"
  type: "Scale"
  bottom: "conv5_4/dw"
  top: "conv5_4/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_4/dw"
  type: "ReLU"
  bottom: "conv5_4/dw"
  top: "conv5_4/dw"
}
layer {
  name: "conv5_4/sep"
  type: "CConvolution"
  bottom: "conv5_4/dw"
  top: "conv5_4/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_4/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_4/sep"
  top: "conv5_4/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_4/sep/scale"
  type: "Scale"
  bottom: "conv5_4/sep"
  top: "conv5_4/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_4/sep"
  type: "ReLU"
  bottom: "conv5_4/sep"
  top: "conv5_4/sep"
}
layer {
  name: "conv5_5/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_4/sep"
  top: "conv5_5/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_5/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_5/dw"
  top: "conv5_5/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_5/dw/scale"
  type: "Scale"
  bottom: "conv5_5/dw"
  top: "conv5_5/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_5/dw"
  type: "ReLU"
  bottom: "conv5_5/dw"
  top: "conv5_5/dw"
}
layer {
  name: "conv5_5/sep"
  type: "CConvolution"
  bottom: "conv5_5/dw"
  top: "conv5_5/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_5/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_5/sep"
  top: "conv5_5/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_5/sep/scale"
  type: "Scale"
  bottom: "conv5_5/sep"
  top: "conv5_5/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_5/sep"
  type: "ReLU"
  bottom: "conv5_5/sep"
  top: "conv5_5/sep"
}
layer {
  name: "conv5_6/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_5/sep"
  top: "conv5_6/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_6/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_6/dw"
  top: "conv5_6/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_6/dw/scale"
  type: "Scale"
  bottom: "conv5_6/dw"
  top: "conv5_6/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_6/dw"
  type: "ReLU"
  bottom: "conv5_6/dw"
  top: "conv5_6/dw"
}
layer {
  name: "conv5_6/sep"
  type: "CConvolution"
  bottom: "conv5_6/dw"
  top: "conv5_6/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_6/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_6/sep"
  top: "conv5_6/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_6/sep/scale"
  type: "Scale"
  bottom: "conv5_6/sep"
  top: "conv5_6/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_6/sep"
  type: "ReLU"
  bottom: "conv5_6/sep"
  top: "conv5_6/sep"
}
layer {
  name: "conv6/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_6/sep"
  top: "conv6/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 1024
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv6/dw/bn"
  type: "BatchNorm"
  bottom: "conv6/dw"
  top: "conv6/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv6/dw/scale"
  type: "Scale"
  bottom: "conv6/dw"
  top: "conv6/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu6/dw"
  type: "ReLU"
  bottom: "conv6/dw"
  top: "conv6/dw"
}
layer {
  name: "conv6/sep"
  type: "CConvolution"
  bottom: "conv6/dw"
  top: "conv6/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv6/sep/bn"
  type: "BatchNorm"
  bottom: "conv6/sep"
  top: "conv6/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv6/sep/scale"
  type: "Scale"
  bottom: "conv6/sep"
  top: "conv6/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu6/sep"
  type: "ReLU"
  bottom: "conv6/sep"
  top: "conv6/sep"
}
layer {
  name: "pool6"
  type: "Pooling"
  bottom: "conv6/sep"
  top: "pool6"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc7_oxford"
  type: "CConvolution"
  bottom: "pool6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 102
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc7"
  bottom: "label"
  top: "loss"
}
I0621 10:18:07.603446 17579 layer_factory.hpp:77] Creating layer data
I0621 10:18:07.603552 17579 net.cpp:84] Creating Layer data
I0621 10:18:07.603582 17579 net.cpp:380] data -> data
I0621 10:18:07.603629 17579 net.cpp:380] data -> label
I0621 10:18:07.603664 17579 data_transformer.cpp:25] Loading mean file from: /home/xingzhaolong/caffe_project/caffe/models/caffe-oxford102/imagenet_mean.binaryproto
I0621 10:18:07.608745 17579 image_data_layer.cpp:38] Opening file /home/xingzhaolong/caffe_project/caffe/models/caffe-oxford102/test.txt
I0621 10:18:07.611069 17579 image_data_layer.cpp:63] A total of 6149 images.
I0621 10:18:07.619652 17579 image_data_layer.cpp:90] output data size: 10,3,224,224
I0621 10:18:07.646211 17579 net.cpp:122] Setting up data
I0621 10:18:07.646276 17579 net.cpp:129] Top shape: 10 3 224 224 (1505280)
I0621 10:18:07.646291 17579 net.cpp:129] Top shape: 10 (10)
I0621 10:18:07.646301 17579 net.cpp:137] Memory required for data: 6021160
I0621 10:18:07.646313 17579 layer_factory.hpp:77] Creating layer conv1
I0621 10:18:07.646361 17579 net.cpp:84] Creating Layer conv1
I0621 10:18:07.646376 17579 net.cpp:406] conv1 <- data
I0621 10:18:07.646414 17579 net.cpp:380] conv1 -> conv1
I0621 10:18:07.997114 17579 net.cpp:122] Setting up conv1
I0621 10:18:07.997202 17579 net.cpp:129] Top shape: 10 32 112 112 (4014080)
I0621 10:18:07.997220 17579 net.cpp:137] Memory required for data: 22077480
I0621 10:18:07.997272 17579 layer_factory.hpp:77] Creating layer conv1/bn
I0621 10:18:07.997334 17579 net.cpp:84] Creating Layer conv1/bn
I0621 10:18:07.997349 17579 net.cpp:406] conv1/bn <- conv1
I0621 10:18:07.997385 17579 net.cpp:367] conv1/bn -> conv1 (in-place)
I0621 10:18:07.998652 17579 net.cpp:122] Setting up conv1/bn
I0621 10:18:07.998675 17579 net.cpp:129] Top shape: 10 32 112 112 (4014080)
I0621 10:18:07.998685 17579 net.cpp:137] Memory required for data: 38133800
I0621 10:18:07.998706 17579 layer_factory.hpp:77] Creating layer conv1/scale
I0621 10:18:07.998747 17579 net.cpp:84] Creating Layer conv1/scale
I0621 10:18:07.998760 17579 net.cpp:406] conv1/scale <- conv1
I0621 10:18:07.998772 17579 net.cpp:367] conv1/scale -> conv1 (in-place)
I0621 10:18:07.998847 17579 layer_factory.hpp:77] Creating layer conv1/scale
I0621 10:18:07.999025 17579 net.cpp:122] Setting up conv1/scale
I0621 10:18:07.999044 17579 net.cpp:129] Top shape: 10 32 112 112 (4014080)
I0621 10:18:07.999053 17579 net.cpp:137] Memory required for data: 54190120
I0621 10:18:07.999069 17579 layer_factory.hpp:77] Creating layer relu1
I0621 10:18:07.999099 17579 net.cpp:84] Creating Layer relu1
I0621 10:18:07.999111 17579 net.cpp:406] relu1 <- conv1
I0621 10:18:07.999122 17579 net.cpp:367] relu1 -> conv1 (in-place)
I0621 10:18:07.999668 17579 net.cpp:122] Setting up relu1
I0621 10:18:07.999691 17579 net.cpp:129] Top shape: 10 32 112 112 (4014080)
I0621 10:18:07.999704 17579 net.cpp:137] Memory required for data: 70246440
I0621 10:18:07.999713 17579 layer_factory.hpp:77] Creating layer conv2_1/dw
I0621 10:18:07.999743 17579 net.cpp:84] Creating Layer conv2_1/dw
I0621 10:18:07.999755 17579 net.cpp:406] conv2_1/dw <- conv1
I0621 10:18:07.999771 17579 net.cpp:380] conv2_1/dw -> conv2_1/dw
I0621 10:18:08.000838 17579 net.cpp:122] Setting up conv2_1/dw
I0621 10:18:08.000883 17579 net.cpp:129] Top shape: 10 32 112 112 (4014080)
I0621 10:18:08.000893 17579 net.cpp:137] Memory required for data: 86302760
I0621 10:18:08.000905 17579 layer_factory.hpp:77] Creating layer conv2_1/dw/bn
I0621 10:18:08.000926 17579 net.cpp:84] Creating Layer conv2_1/dw/bn
I0621 10:18:08.000936 17579 net.cpp:406] conv2_1/dw/bn <- conv2_1/dw
I0621 10:18:08.000952 17579 net.cpp:367] conv2_1/dw/bn -> conv2_1/dw (in-place)
I0621 10:18:08.001186 17579 net.cpp:122] Setting up conv2_1/dw/bn
I0621 10:18:08.001204 17579 net.cpp:129] Top shape: 10 32 112 112 (4014080)
I0621 10:18:08.001214 17579 net.cpp:137] Memory required for data: 102359080
I0621 10:18:08.001231 17579 layer_factory.hpp:77] Creating layer conv2_1/dw/scale
I0621 10:18:08.001260 17579 net.cpp:84] Creating Layer conv2_1/dw/scale
I0621 10:18:08.001272 17579 net.cpp:406] conv2_1/dw/scale <- conv2_1/dw
I0621 10:18:08.001283 17579 net.cpp:367] conv2_1/dw/scale -> conv2_1/dw (in-place)
I0621 10:18:08.001343 17579 layer_factory.hpp:77] Creating layer conv2_1/dw/scale
I0621 10:18:08.001502 17579 net.cpp:122] Setting up conv2_1/dw/scale
I0621 10:18:08.001528 17579 net.cpp:129] Top shape: 10 32 112 112 (4014080)
I0621 10:18:08.001538 17579 net.cpp:137] Memory required for data: 118415400
I0621 10:18:08.001551 17579 layer_factory.hpp:77] Creating layer relu2_1/dw
I0621 10:18:08.001577 17579 net.cpp:84] Creating Layer relu2_1/dw
I0621 10:18:08.001590 17579 net.cpp:406] relu2_1/dw <- conv2_1/dw
I0621 10:18:08.001600 17579 net.cpp:367] relu2_1/dw -> conv2_1/dw (in-place)
I0621 10:18:08.001830 17579 net.cpp:122] Setting up relu2_1/dw
I0621 10:18:08.001850 17579 net.cpp:129] Top shape: 10 32 112 112 (4014080)
I0621 10:18:08.001859 17579 net.cpp:137] Memory required for data: 134471720
I0621 10:18:08.001868 17579 layer_factory.hpp:77] Creating layer conv2_1/sep
I0621 10:18:08.001889 17579 net.cpp:84] Creating Layer conv2_1/sep
I0621 10:18:08.001902 17579 net.cpp:406] conv2_1/sep <- conv2_1/dw
I0621 10:18:08.001914 17579 net.cpp:380] conv2_1/sep -> conv2_1/sep
I0621 10:18:08.003048 17579 net.cpp:122] Setting up conv2_1/sep
I0621 10:18:08.003073 17579 net.cpp:129] Top shape: 10 64 112 112 (8028160)
I0621 10:18:08.003082 17579 net.cpp:137] Memory required for data: 166584360
I0621 10:18:08.003105 17579 layer_factory.hpp:77] Creating layer conv2_1/sep/bn
I0621 10:18:08.003123 17579 net.cpp:84] Creating Layer conv2_1/sep/bn
I0621 10:18:08.003132 17579 net.cpp:406] conv2_1/sep/bn <- conv2_1/sep
I0621 10:18:08.003144 17579 net.cpp:367] conv2_1/sep/bn -> conv2_1/sep (in-place)
I0621 10:18:08.003384 17579 net.cpp:122] Setting up conv2_1/sep/bn
I0621 10:18:08.003401 17579 net.cpp:129] Top shape: 10 64 112 112 (8028160)
I0621 10:18:08.003410 17579 net.cpp:137] Memory required for data: 198697000
I0621 10:18:08.003432 17579 layer_factory.hpp:77] Creating layer conv2_1/sep/scale
I0621 10:18:08.003464 17579 net.cpp:84] Creating Layer conv2_1/sep/scale
I0621 10:18:08.003474 17579 net.cpp:406] conv2_1/sep/scale <- conv2_1/sep
I0621 10:18:08.003485 17579 net.cpp:367] conv2_1/sep/scale -> conv2_1/sep (in-place)
I0621 10:18:08.003556 17579 layer_factory.hpp:77] Creating layer conv2_1/sep/scale
I0621 10:18:08.003718 17579 net.cpp:122] Setting up conv2_1/sep/scale
I0621 10:18:08.003736 17579 net.cpp:129] Top shape: 10 64 112 112 (8028160)
I0621 10:18:08.003746 17579 net.cpp:137] Memory required for data: 230809640
I0621 10:18:08.003757 17579 layer_factory.hpp:77] Creating layer relu2_1/sep
I0621 10:18:08.003769 17579 net.cpp:84] Creating Layer relu2_1/sep
I0621 10:18:08.003778 17579 net.cpp:406] relu2_1/sep <- conv2_1/sep
I0621 10:18:08.003793 17579 net.cpp:367] relu2_1/sep -> conv2_1/sep (in-place)
I0621 10:18:08.004312 17579 net.cpp:122] Setting up relu2_1/sep
I0621 10:18:08.004333 17579 net.cpp:129] Top shape: 10 64 112 112 (8028160)
I0621 10:18:08.004343 17579 net.cpp:137] Memory required for data: 262922280
I0621 10:18:08.004351 17579 layer_factory.hpp:77] Creating layer conv2_2/dw
I0621 10:18:08.004372 17579 net.cpp:84] Creating Layer conv2_2/dw
I0621 10:18:08.004384 17579 net.cpp:406] conv2_2/dw <- conv2_1/sep
I0621 10:18:08.004410 17579 net.cpp:380] conv2_2/dw -> conv2_2/dw
I0621 10:18:08.005383 17579 net.cpp:122] Setting up conv2_2/dw
I0621 10:18:08.005405 17579 net.cpp:129] Top shape: 10 64 56 56 (2007040)
I0621 10:18:08.005414 17579 net.cpp:137] Memory required for data: 270950440
I0621 10:18:08.005425 17579 layer_factory.hpp:77] Creating layer conv2_2/dw/bn
I0621 10:18:08.005441 17579 net.cpp:84] Creating Layer conv2_2/dw/bn
I0621 10:18:08.005452 17579 net.cpp:406] conv2_2/dw/bn <- conv2_2/dw
I0621 10:18:08.005463 17579 net.cpp:367] conv2_2/dw/bn -> conv2_2/dw (in-place)
I0621 10:18:08.005710 17579 net.cpp:122] Setting up conv2_2/dw/bn
I0621 10:18:08.005729 17579 net.cpp:129] Top shape: 10 64 56 56 (2007040)
I0621 10:18:08.005738 17579 net.cpp:137] Memory required for data: 278978600
I0621 10:18:08.005753 17579 layer_factory.hpp:77] Creating layer conv2_2/dw/scale
I0621 10:18:08.005779 17579 net.cpp:84] Creating Layer conv2_2/dw/scale
I0621 10:18:08.005789 17579 net.cpp:406] conv2_2/dw/scale <- conv2_2/dw
I0621 10:18:08.005801 17579 net.cpp:367] conv2_2/dw/scale -> conv2_2/dw (in-place)
I0621 10:18:08.005866 17579 layer_factory.hpp:77] Creating layer conv2_2/dw/scale
I0621 10:18:08.006022 17579 net.cpp:122] Setting up conv2_2/dw/scale
I0621 10:18:08.006039 17579 net.cpp:129] Top shape: 10 64 56 56 (2007040)
I0621 10:18:08.006047 17579 net.cpp:137] Memory required for data: 287006760
I0621 10:18:08.006060 17579 layer_factory.hpp:77] Creating layer relu2_2/dw
I0621 10:18:08.006078 17579 net.cpp:84] Creating Layer relu2_2/dw
I0621 10:18:08.006088 17579 net.cpp:406] relu2_2/dw <- conv2_2/dw
I0621 10:18:08.006098 17579 net.cpp:367] relu2_2/dw -> conv2_2/dw (in-place)
I0621 10:18:08.006328 17579 net.cpp:122] Setting up relu2_2/dw
I0621 10:18:08.006348 17579 net.cpp:129] Top shape: 10 64 56 56 (2007040)
I0621 10:18:08.006357 17579 net.cpp:137] Memory required for data: 295034920
I0621 10:18:08.006379 17579 layer_factory.hpp:77] Creating layer conv2_2/sep
I0621 10:18:08.006407 17579 net.cpp:84] Creating Layer conv2_2/sep
I0621 10:18:08.006418 17579 net.cpp:406] conv2_2/sep <- conv2_2/dw
I0621 10:18:08.006434 17579 net.cpp:380] conv2_2/sep -> conv2_2/sep
I0621 10:18:08.006846 17579 net.cpp:122] Setting up conv2_2/sep
I0621 10:18:08.006873 17579 net.cpp:129] Top shape: 10 128 56 56 (4014080)
I0621 10:18:08.006882 17579 net.cpp:137] Memory required for data: 311091240
I0621 10:18:08.006906 17579 layer_factory.hpp:77] Creating layer conv2_2/sep/bn
I0621 10:18:08.006920 17579 net.cpp:84] Creating Layer conv2_2/sep/bn
I0621 10:18:08.006929 17579 net.cpp:406] conv2_2/sep/bn <- conv2_2/sep
I0621 10:18:08.006947 17579 net.cpp:367] conv2_2/sep/bn -> conv2_2/sep (in-place)
I0621 10:18:08.007181 17579 net.cpp:122] Setting up conv2_2/sep/bn
I0621 10:18:08.007200 17579 net.cpp:129] Top shape: 10 128 56 56 (4014080)
I0621 10:18:08.007207 17579 net.cpp:137] Memory required for data: 327147560
I0621 10:18:08.007221 17579 layer_factory.hpp:77] Creating layer conv2_2/sep/scale
I0621 10:18:08.007235 17579 net.cpp:84] Creating Layer conv2_2/sep/scale
I0621 10:18:08.007242 17579 net.cpp:406] conv2_2/sep/scale <- conv2_2/sep
I0621 10:18:08.007253 17579 net.cpp:367] conv2_2/sep/scale -> conv2_2/sep (in-place)
I0621 10:18:08.007310 17579 layer_factory.hpp:77] Creating layer conv2_2/sep/scale
I0621 10:18:08.007457 17579 net.cpp:122] Setting up conv2_2/sep/scale
I0621 10:18:08.007473 17579 net.cpp:129] Top shape: 10 128 56 56 (4014080)
I0621 10:18:08.007481 17579 net.cpp:137] Memory required for data: 343203880
I0621 10:18:08.007494 17579 layer_factory.hpp:77] Creating layer relu2_2/sep
I0621 10:18:08.007505 17579 net.cpp:84] Creating Layer relu2_2/sep
I0621 10:18:08.007527 17579 net.cpp:406] relu2_2/sep <- conv2_2/sep
I0621 10:18:08.007539 17579 net.cpp:367] relu2_2/sep -> conv2_2/sep (in-place)
I0621 10:18:08.008065 17579 net.cpp:122] Setting up relu2_2/sep
I0621 10:18:08.008086 17579 net.cpp:129] Top shape: 10 128 56 56 (4014080)
I0621 10:18:08.008095 17579 net.cpp:137] Memory required for data: 359260200
I0621 10:18:08.008105 17579 layer_factory.hpp:77] Creating layer conv3_1/dw
I0621 10:18:08.008143 17579 net.cpp:84] Creating Layer conv3_1/dw
I0621 10:18:08.008157 17579 net.cpp:406] conv3_1/dw <- conv2_2/sep
I0621 10:18:08.008169 17579 net.cpp:380] conv3_1/dw -> conv3_1/dw
I0621 10:18:08.008354 17579 net.cpp:122] Setting up conv3_1/dw
I0621 10:18:08.008373 17579 net.cpp:129] Top shape: 10 128 56 56 (4014080)
I0621 10:18:08.008383 17579 net.cpp:137] Memory required for data: 375316520
I0621 10:18:08.008410 17579 layer_factory.hpp:77] Creating layer conv3_1/dw/bn
I0621 10:18:08.008429 17579 net.cpp:84] Creating Layer conv3_1/dw/bn
I0621 10:18:08.008438 17579 net.cpp:406] conv3_1/dw/bn <- conv3_1/dw
I0621 10:18:08.008450 17579 net.cpp:367] conv3_1/dw/bn -> conv3_1/dw (in-place)
I0621 10:18:08.008683 17579 net.cpp:122] Setting up conv3_1/dw/bn
I0621 10:18:08.008702 17579 net.cpp:129] Top shape: 10 128 56 56 (4014080)
I0621 10:18:08.008710 17579 net.cpp:137] Memory required for data: 391372840
I0621 10:18:08.008724 17579 layer_factory.hpp:77] Creating layer conv3_1/dw/scale
I0621 10:18:08.008751 17579 net.cpp:84] Creating Layer conv3_1/dw/scale
I0621 10:18:08.008762 17579 net.cpp:406] conv3_1/dw/scale <- conv3_1/dw
I0621 10:18:08.008774 17579 net.cpp:367] conv3_1/dw/scale -> conv3_1/dw (in-place)
I0621 10:18:08.008833 17579 layer_factory.hpp:77] Creating layer conv3_1/dw/scale
I0621 10:18:08.008986 17579 net.cpp:122] Setting up conv3_1/dw/scale
I0621 10:18:08.009003 17579 net.cpp:129] Top shape: 10 128 56 56 (4014080)
I0621 10:18:08.009012 17579 net.cpp:137] Memory required for data: 407429160
I0621 10:18:08.009024 17579 layer_factory.hpp:77] Creating layer relu3_1/dw
I0621 10:18:08.009037 17579 net.cpp:84] Creating Layer relu3_1/dw
I0621 10:18:08.009044 17579 net.cpp:406] relu3_1/dw <- conv3_1/dw
I0621 10:18:08.009058 17579 net.cpp:367] relu3_1/dw -> conv3_1/dw (in-place)
I0621 10:18:08.009289 17579 net.cpp:122] Setting up relu3_1/dw
I0621 10:18:08.009308 17579 net.cpp:129] Top shape: 10 128 56 56 (4014080)
I0621 10:18:08.009317 17579 net.cpp:137] Memory required for data: 423485480
I0621 10:18:08.009325 17579 layer_factory.hpp:77] Creating layer conv3_1/sep
I0621 10:18:08.009356 17579 net.cpp:84] Creating Layer conv3_1/sep
I0621 10:18:08.009374 17579 net.cpp:406] conv3_1/sep <- conv3_1/dw
I0621 10:18:08.009392 17579 net.cpp:380] conv3_1/sep -> conv3_1/sep
I0621 10:18:08.009933 17579 net.cpp:122] Setting up conv3_1/sep
I0621 10:18:08.009954 17579 net.cpp:129] Top shape: 10 128 56 56 (4014080)
I0621 10:18:08.009963 17579 net.cpp:137] Memory required for data: 439541800
I0621 10:18:08.009975 17579 layer_factory.hpp:77] Creating layer conv3_1/sep/bn
I0621 10:18:08.010000 17579 net.cpp:84] Creating Layer conv3_1/sep/bn
I0621 10:18:08.010011 17579 net.cpp:406] conv3_1/sep/bn <- conv3_1/sep
I0621 10:18:08.010025 17579 net.cpp:367] conv3_1/sep/bn -> conv3_1/sep (in-place)
I0621 10:18:08.010263 17579 net.cpp:122] Setting up conv3_1/sep/bn
I0621 10:18:08.010280 17579 net.cpp:129] Top shape: 10 128 56 56 (4014080)
I0621 10:18:08.010288 17579 net.cpp:137] Memory required for data: 455598120
I0621 10:18:08.010303 17579 layer_factory.hpp:77] Creating layer conv3_1/sep/scale
I0621 10:18:08.010315 17579 net.cpp:84] Creating Layer conv3_1/sep/scale
I0621 10:18:08.010324 17579 net.cpp:406] conv3_1/sep/scale <- conv3_1/sep
I0621 10:18:08.010334 17579 net.cpp:367] conv3_1/sep/scale -> conv3_1/sep (in-place)
I0621 10:18:08.010390 17579 layer_factory.hpp:77] Creating layer conv3_1/sep/scale
I0621 10:18:08.010550 17579 net.cpp:122] Setting up conv3_1/sep/scale
I0621 10:18:08.010568 17579 net.cpp:129] Top shape: 10 128 56 56 (4014080)
I0621 10:18:08.010576 17579 net.cpp:137] Memory required for data: 471654440
I0621 10:18:08.010588 17579 layer_factory.hpp:77] Creating layer relu3_1/sep
I0621 10:18:08.010601 17579 net.cpp:84] Creating Layer relu3_1/sep
I0621 10:18:08.010609 17579 net.cpp:406] relu3_1/sep <- conv3_1/sep
I0621 10:18:08.010623 17579 net.cpp:367] relu3_1/sep -> conv3_1/sep (in-place)
I0621 10:18:08.011144 17579 net.cpp:122] Setting up relu3_1/sep
I0621 10:18:08.011175 17579 net.cpp:129] Top shape: 10 128 56 56 (4014080)
I0621 10:18:08.011184 17579 net.cpp:137] Memory required for data: 487710760
I0621 10:18:08.011193 17579 layer_factory.hpp:77] Creating layer conv3_2/dw
I0621 10:18:08.011227 17579 net.cpp:84] Creating Layer conv3_2/dw
I0621 10:18:08.011240 17579 net.cpp:406] conv3_2/dw <- conv3_1/sep
I0621 10:18:08.011255 17579 net.cpp:380] conv3_2/dw -> conv3_2/dw
I0621 10:18:08.011409 17579 net.cpp:122] Setting up conv3_2/dw
I0621 10:18:08.011427 17579 net.cpp:129] Top shape: 10 128 28 28 (1003520)
I0621 10:18:08.011435 17579 net.cpp:137] Memory required for data: 491724840
I0621 10:18:08.011446 17579 layer_factory.hpp:77] Creating layer conv3_2/dw/bn
I0621 10:18:08.011458 17579 net.cpp:84] Creating Layer conv3_2/dw/bn
I0621 10:18:08.011467 17579 net.cpp:406] conv3_2/dw/bn <- conv3_2/dw
I0621 10:18:08.011488 17579 net.cpp:367] conv3_2/dw/bn -> conv3_2/dw (in-place)
I0621 10:18:08.011819 17579 net.cpp:122] Setting up conv3_2/dw/bn
I0621 10:18:08.011840 17579 net.cpp:129] Top shape: 10 128 28 28 (1003520)
I0621 10:18:08.011848 17579 net.cpp:137] Memory required for data: 495738920
I0621 10:18:08.011862 17579 layer_factory.hpp:77] Creating layer conv3_2/dw/scale
I0621 10:18:08.011875 17579 net.cpp:84] Creating Layer conv3_2/dw/scale
I0621 10:18:08.011884 17579 net.cpp:406] conv3_2/dw/scale <- conv3_2/dw
I0621 10:18:08.011896 17579 net.cpp:367] conv3_2/dw/scale -> conv3_2/dw (in-place)
I0621 10:18:08.011955 17579 layer_factory.hpp:77] Creating layer conv3_2/dw/scale
I0621 10:18:08.012100 17579 net.cpp:122] Setting up conv3_2/dw/scale
I0621 10:18:08.012117 17579 net.cpp:129] Top shape: 10 128 28 28 (1003520)
I0621 10:18:08.012125 17579 net.cpp:137] Memory required for data: 499753000
I0621 10:18:08.012138 17579 layer_factory.hpp:77] Creating layer relu3_2/dw
I0621 10:18:08.012156 17579 net.cpp:84] Creating Layer relu3_2/dw
I0621 10:18:08.012166 17579 net.cpp:406] relu3_2/dw <- conv3_2/dw
I0621 10:18:08.012177 17579 net.cpp:367] relu3_2/dw -> conv3_2/dw (in-place)
I0621 10:18:08.012405 17579 net.cpp:122] Setting up relu3_2/dw
I0621 10:18:08.012431 17579 net.cpp:129] Top shape: 10 128 28 28 (1003520)
I0621 10:18:08.012441 17579 net.cpp:137] Memory required for data: 503767080
I0621 10:18:08.012473 17579 layer_factory.hpp:77] Creating layer conv3_2/sep
I0621 10:18:08.012498 17579 net.cpp:84] Creating Layer conv3_2/sep
I0621 10:18:08.012509 17579 net.cpp:406] conv3_2/sep <- conv3_2/dw
I0621 10:18:08.012534 17579 net.cpp:380] conv3_2/sep -> conv3_2/sep
I0621 10:18:08.013301 17579 net.cpp:122] Setting up conv3_2/sep
I0621 10:18:08.013320 17579 net.cpp:129] Top shape: 10 256 28 28 (2007040)
I0621 10:18:08.013329 17579 net.cpp:137] Memory required for data: 511795240
I0621 10:18:08.013342 17579 layer_factory.hpp:77] Creating layer conv3_2/sep/bn
I0621 10:18:08.013355 17579 net.cpp:84] Creating Layer conv3_2/sep/bn
I0621 10:18:08.013363 17579 net.cpp:406] conv3_2/sep/bn <- conv3_2/sep
I0621 10:18:08.013375 17579 net.cpp:367] conv3_2/sep/bn -> conv3_2/sep (in-place)
I0621 10:18:08.013617 17579 net.cpp:122] Setting up conv3_2/sep/bn
I0621 10:18:08.013635 17579 net.cpp:129] Top shape: 10 256 28 28 (2007040)
I0621 10:18:08.013643 17579 net.cpp:137] Memory required for data: 519823400
I0621 10:18:08.013658 17579 layer_factory.hpp:77] Creating layer conv3_2/sep/scale
I0621 10:18:08.013672 17579 net.cpp:84] Creating Layer conv3_2/sep/scale
I0621 10:18:08.013682 17579 net.cpp:406] conv3_2/sep/scale <- conv3_2/sep
I0621 10:18:08.013695 17579 net.cpp:367] conv3_2/sep/scale -> conv3_2/sep (in-place)
I0621 10:18:08.013753 17579 layer_factory.hpp:77] Creating layer conv3_2/sep/scale
I0621 10:18:08.013903 17579 net.cpp:122] Setting up conv3_2/sep/scale
I0621 10:18:08.013921 17579 net.cpp:129] Top shape: 10 256 28 28 (2007040)
I0621 10:18:08.013929 17579 net.cpp:137] Memory required for data: 527851560
I0621 10:18:08.013942 17579 layer_factory.hpp:77] Creating layer relu3_2/sep
I0621 10:18:08.013963 17579 net.cpp:84] Creating Layer relu3_2/sep
I0621 10:18:08.013974 17579 net.cpp:406] relu3_2/sep <- conv3_2/sep
I0621 10:18:08.013999 17579 net.cpp:367] relu3_2/sep -> conv3_2/sep (in-place)
I0621 10:18:08.014525 17579 net.cpp:122] Setting up relu3_2/sep
I0621 10:18:08.014547 17579 net.cpp:129] Top shape: 10 256 28 28 (2007040)
I0621 10:18:08.014556 17579 net.cpp:137] Memory required for data: 535879720
I0621 10:18:08.014576 17579 layer_factory.hpp:77] Creating layer conv4_1/dw
I0621 10:18:08.014595 17579 net.cpp:84] Creating Layer conv4_1/dw
I0621 10:18:08.014605 17579 net.cpp:406] conv4_1/dw <- conv3_2/sep
I0621 10:18:08.014618 17579 net.cpp:380] conv4_1/dw -> conv4_1/dw
I0621 10:18:08.014788 17579 net.cpp:122] Setting up conv4_1/dw
I0621 10:18:08.014806 17579 net.cpp:129] Top shape: 10 256 28 28 (2007040)
I0621 10:18:08.014814 17579 net.cpp:137] Memory required for data: 543907880
I0621 10:18:08.014825 17579 layer_factory.hpp:77] Creating layer conv4_1/dw/bn
I0621 10:18:08.014842 17579 net.cpp:84] Creating Layer conv4_1/dw/bn
I0621 10:18:08.014852 17579 net.cpp:406] conv4_1/dw/bn <- conv4_1/dw
I0621 10:18:08.014863 17579 net.cpp:367] conv4_1/dw/bn -> conv4_1/dw (in-place)
I0621 10:18:08.015099 17579 net.cpp:122] Setting up conv4_1/dw/bn
I0621 10:18:08.015115 17579 net.cpp:129] Top shape: 10 256 28 28 (2007040)
I0621 10:18:08.015123 17579 net.cpp:137] Memory required for data: 551936040
I0621 10:18:08.015137 17579 layer_factory.hpp:77] Creating layer conv4_1/dw/scale
I0621 10:18:08.015167 17579 net.cpp:84] Creating Layer conv4_1/dw/scale
I0621 10:18:08.015178 17579 net.cpp:406] conv4_1/dw/scale <- conv4_1/dw
I0621 10:18:08.015190 17579 net.cpp:367] conv4_1/dw/scale -> conv4_1/dw (in-place)
I0621 10:18:08.015249 17579 layer_factory.hpp:77] Creating layer conv4_1/dw/scale
I0621 10:18:08.015413 17579 net.cpp:122] Setting up conv4_1/dw/scale
I0621 10:18:08.015432 17579 net.cpp:129] Top shape: 10 256 28 28 (2007040)
I0621 10:18:08.015440 17579 net.cpp:137] Memory required for data: 559964200
I0621 10:18:08.015453 17579 layer_factory.hpp:77] Creating layer relu4_1/dw
I0621 10:18:08.015480 17579 net.cpp:84] Creating Layer relu4_1/dw
I0621 10:18:08.015489 17579 net.cpp:406] relu4_1/dw <- conv4_1/dw
I0621 10:18:08.015501 17579 net.cpp:367] relu4_1/dw -> conv4_1/dw (in-place)
I0621 10:18:08.015748 17579 net.cpp:122] Setting up relu4_1/dw
I0621 10:18:08.015780 17579 net.cpp:129] Top shape: 10 256 28 28 (2007040)
I0621 10:18:08.015790 17579 net.cpp:137] Memory required for data: 567992360
I0621 10:18:08.015799 17579 layer_factory.hpp:77] Creating layer conv4_1/sep
I0621 10:18:08.015816 17579 net.cpp:84] Creating Layer conv4_1/sep
I0621 10:18:08.015826 17579 net.cpp:406] conv4_1/sep <- conv4_1/dw
I0621 10:18:08.015842 17579 net.cpp:380] conv4_1/sep -> conv4_1/sep
I0621 10:18:08.017102 17579 net.cpp:122] Setting up conv4_1/sep
I0621 10:18:08.017122 17579 net.cpp:129] Top shape: 10 256 28 28 (2007040)
I0621 10:18:08.017130 17579 net.cpp:137] Memory required for data: 576020520
I0621 10:18:08.017158 17579 layer_factory.hpp:77] Creating layer conv4_1/sep/bn
I0621 10:18:08.017187 17579 net.cpp:84] Creating Layer conv4_1/sep/bn
I0621 10:18:08.017197 17579 net.cpp:406] conv4_1/sep/bn <- conv4_1/sep
I0621 10:18:08.017212 17579 net.cpp:367] conv4_1/sep/bn -> conv4_1/sep (in-place)
I0621 10:18:08.017452 17579 net.cpp:122] Setting up conv4_1/sep/bn
I0621 10:18:08.017469 17579 net.cpp:129] Top shape: 10 256 28 28 (2007040)
I0621 10:18:08.017477 17579 net.cpp:137] Memory required for data: 584048680
I0621 10:18:08.017493 17579 layer_factory.hpp:77] Creating layer conv4_1/sep/scale
I0621 10:18:08.017505 17579 net.cpp:84] Creating Layer conv4_1/sep/scale
I0621 10:18:08.017520 17579 net.cpp:406] conv4_1/sep/scale <- conv4_1/sep
I0621 10:18:08.017534 17579 net.cpp:367] conv4_1/sep/scale -> conv4_1/sep (in-place)
I0621 10:18:08.017594 17579 layer_factory.hpp:77] Creating layer conv4_1/sep/scale
I0621 10:18:08.017750 17579 net.cpp:122] Setting up conv4_1/sep/scale
I0621 10:18:08.017767 17579 net.cpp:129] Top shape: 10 256 28 28 (2007040)
I0621 10:18:08.017776 17579 net.cpp:137] Memory required for data: 592076840
I0621 10:18:08.017799 17579 layer_factory.hpp:77] Creating layer relu4_1/sep
I0621 10:18:08.017832 17579 net.cpp:84] Creating Layer relu4_1/sep
I0621 10:18:08.017843 17579 net.cpp:406] relu4_1/sep <- conv4_1/sep
I0621 10:18:08.017856 17579 net.cpp:367] relu4_1/sep -> conv4_1/sep (in-place)
I0621 10:18:08.018358 17579 net.cpp:122] Setting up relu4_1/sep
I0621 10:18:08.018379 17579 net.cpp:129] Top shape: 10 256 28 28 (2007040)
I0621 10:18:08.018388 17579 net.cpp:137] Memory required for data: 600105000
I0621 10:18:08.018398 17579 layer_factory.hpp:77] Creating layer conv4_2/dw
I0621 10:18:08.018422 17579 net.cpp:84] Creating Layer conv4_2/dw
I0621 10:18:08.018435 17579 net.cpp:406] conv4_2/dw <- conv4_1/sep
I0621 10:18:08.018450 17579 net.cpp:380] conv4_2/dw -> conv4_2/dw
I0621 10:18:08.018626 17579 net.cpp:122] Setting up conv4_2/dw
I0621 10:18:08.018648 17579 net.cpp:129] Top shape: 10 256 14 14 (501760)
I0621 10:18:08.018657 17579 net.cpp:137] Memory required for data: 602112040
I0621 10:18:08.018668 17579 layer_factory.hpp:77] Creating layer conv4_2/dw/bn
I0621 10:18:08.018681 17579 net.cpp:84] Creating Layer conv4_2/dw/bn
I0621 10:18:08.018689 17579 net.cpp:406] conv4_2/dw/bn <- conv4_2/dw
I0621 10:18:08.018703 17579 net.cpp:367] conv4_2/dw/bn -> conv4_2/dw (in-place)
I0621 10:18:08.018975 17579 net.cpp:122] Setting up conv4_2/dw/bn
I0621 10:18:08.018993 17579 net.cpp:129] Top shape: 10 256 14 14 (501760)
I0621 10:18:08.019001 17579 net.cpp:137] Memory required for data: 604119080
I0621 10:18:08.019016 17579 layer_factory.hpp:77] Creating layer conv4_2/dw/scale
I0621 10:18:08.019028 17579 net.cpp:84] Creating Layer conv4_2/dw/scale
I0621 10:18:08.019037 17579 net.cpp:406] conv4_2/dw/scale <- conv4_2/dw
I0621 10:18:08.019048 17579 net.cpp:367] conv4_2/dw/scale -> conv4_2/dw (in-place)
I0621 10:18:08.019106 17579 layer_factory.hpp:77] Creating layer conv4_2/dw/scale
I0621 10:18:08.019250 17579 net.cpp:122] Setting up conv4_2/dw/scale
I0621 10:18:08.019268 17579 net.cpp:129] Top shape: 10 256 14 14 (501760)
I0621 10:18:08.019275 17579 net.cpp:137] Memory required for data: 606126120
I0621 10:18:08.019297 17579 layer_factory.hpp:77] Creating layer relu4_2/dw
I0621 10:18:08.019311 17579 net.cpp:84] Creating Layer relu4_2/dw
I0621 10:18:08.019320 17579 net.cpp:406] relu4_2/dw <- conv4_2/dw
I0621 10:18:08.019340 17579 net.cpp:367] relu4_2/dw -> conv4_2/dw (in-place)
I0621 10:18:08.019867 17579 net.cpp:122] Setting up relu4_2/dw
I0621 10:18:08.019889 17579 net.cpp:129] Top shape: 10 256 14 14 (501760)
I0621 10:18:08.019898 17579 net.cpp:137] Memory required for data: 608133160
I0621 10:18:08.019907 17579 layer_factory.hpp:77] Creating layer conv4_2/sep
I0621 10:18:08.019933 17579 net.cpp:84] Creating Layer conv4_2/sep
I0621 10:18:08.019945 17579 net.cpp:406] conv4_2/sep <- conv4_2/dw
I0621 10:18:08.019959 17579 net.cpp:380] conv4_2/sep -> conv4_2/sep
I0621 10:18:08.023026 17579 net.cpp:122] Setting up conv4_2/sep
I0621 10:18:08.023051 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.023061 17579 net.cpp:137] Memory required for data: 612147240
I0621 10:18:08.023074 17579 layer_factory.hpp:77] Creating layer conv4_2/sep/bn
I0621 10:18:08.023090 17579 net.cpp:84] Creating Layer conv4_2/sep/bn
I0621 10:18:08.023100 17579 net.cpp:406] conv4_2/sep/bn <- conv4_2/sep
I0621 10:18:08.023113 17579 net.cpp:367] conv4_2/sep/bn -> conv4_2/sep (in-place)
I0621 10:18:08.023362 17579 net.cpp:122] Setting up conv4_2/sep/bn
I0621 10:18:08.023380 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.023388 17579 net.cpp:137] Memory required for data: 616161320
I0621 10:18:08.023402 17579 layer_factory.hpp:77] Creating layer conv4_2/sep/scale
I0621 10:18:08.023429 17579 net.cpp:84] Creating Layer conv4_2/sep/scale
I0621 10:18:08.023442 17579 net.cpp:406] conv4_2/sep/scale <- conv4_2/sep
I0621 10:18:08.023458 17579 net.cpp:367] conv4_2/sep/scale -> conv4_2/sep (in-place)
I0621 10:18:08.023511 17579 layer_factory.hpp:77] Creating layer conv4_2/sep/scale
I0621 10:18:08.023684 17579 net.cpp:122] Setting up conv4_2/sep/scale
I0621 10:18:08.023700 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.023721 17579 net.cpp:137] Memory required for data: 620175400
I0621 10:18:08.023736 17579 layer_factory.hpp:77] Creating layer relu4_2/sep
I0621 10:18:08.023759 17579 net.cpp:84] Creating Layer relu4_2/sep
I0621 10:18:08.023771 17579 net.cpp:406] relu4_2/sep <- conv4_2/sep
I0621 10:18:08.023782 17579 net.cpp:367] relu4_2/sep -> conv4_2/sep (in-place)
I0621 10:18:08.024015 17579 net.cpp:122] Setting up relu4_2/sep
I0621 10:18:08.024035 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.024044 17579 net.cpp:137] Memory required for data: 624189480
I0621 10:18:08.024052 17579 layer_factory.hpp:77] Creating layer conv5_1/dw
I0621 10:18:08.024066 17579 net.cpp:84] Creating Layer conv5_1/dw
I0621 10:18:08.024075 17579 net.cpp:406] conv5_1/dw <- conv4_2/sep
I0621 10:18:08.024091 17579 net.cpp:380] conv5_1/dw -> conv5_1/dw
I0621 10:18:08.024302 17579 net.cpp:122] Setting up conv5_1/dw
I0621 10:18:08.024320 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.024328 17579 net.cpp:137] Memory required for data: 628203560
I0621 10:18:08.024339 17579 layer_factory.hpp:77] Creating layer conv5_1/dw/bn
I0621 10:18:08.024354 17579 net.cpp:84] Creating Layer conv5_1/dw/bn
I0621 10:18:08.024365 17579 net.cpp:406] conv5_1/dw/bn <- conv5_1/dw
I0621 10:18:08.024376 17579 net.cpp:367] conv5_1/dw/bn -> conv5_1/dw (in-place)
I0621 10:18:08.024626 17579 net.cpp:122] Setting up conv5_1/dw/bn
I0621 10:18:08.024644 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.024653 17579 net.cpp:137] Memory required for data: 632217640
I0621 10:18:08.024667 17579 layer_factory.hpp:77] Creating layer conv5_1/dw/scale
I0621 10:18:08.024698 17579 net.cpp:84] Creating Layer conv5_1/dw/scale
I0621 10:18:08.024709 17579 net.cpp:406] conv5_1/dw/scale <- conv5_1/dw
I0621 10:18:08.024724 17579 net.cpp:367] conv5_1/dw/scale -> conv5_1/dw (in-place)
I0621 10:18:08.024777 17579 layer_factory.hpp:77] Creating layer conv5_1/dw/scale
I0621 10:18:08.024930 17579 net.cpp:122] Setting up conv5_1/dw/scale
I0621 10:18:08.024955 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.024963 17579 net.cpp:137] Memory required for data: 636231720
I0621 10:18:08.024984 17579 layer_factory.hpp:77] Creating layer relu5_1/dw
I0621 10:18:08.024996 17579 net.cpp:84] Creating Layer relu5_1/dw
I0621 10:18:08.025005 17579 net.cpp:406] relu5_1/dw <- conv5_1/dw
I0621 10:18:08.025017 17579 net.cpp:367] relu5_1/dw -> conv5_1/dw (in-place)
I0621 10:18:08.025591 17579 net.cpp:122] Setting up relu5_1/dw
I0621 10:18:08.025614 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.025624 17579 net.cpp:137] Memory required for data: 640245800
I0621 10:18:08.025632 17579 layer_factory.hpp:77] Creating layer conv5_1/sep
I0621 10:18:08.025650 17579 net.cpp:84] Creating Layer conv5_1/sep
I0621 10:18:08.025660 17579 net.cpp:406] conv5_1/sep <- conv5_1/dw
I0621 10:18:08.025676 17579 net.cpp:380] conv5_1/sep -> conv5_1/sep
I0621 10:18:08.031195 17579 net.cpp:122] Setting up conv5_1/sep
I0621 10:18:08.031221 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.031230 17579 net.cpp:137] Memory required for data: 644259880
I0621 10:18:08.031244 17579 layer_factory.hpp:77] Creating layer conv5_1/sep/bn
I0621 10:18:08.031270 17579 net.cpp:84] Creating Layer conv5_1/sep/bn
I0621 10:18:08.031281 17579 net.cpp:406] conv5_1/sep/bn <- conv5_1/sep
I0621 10:18:08.031296 17579 net.cpp:367] conv5_1/sep/bn -> conv5_1/sep (in-place)
I0621 10:18:08.031556 17579 net.cpp:122] Setting up conv5_1/sep/bn
I0621 10:18:08.031575 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.031584 17579 net.cpp:137] Memory required for data: 648273960
I0621 10:18:08.031606 17579 layer_factory.hpp:77] Creating layer conv5_1/sep/scale
I0621 10:18:08.031621 17579 net.cpp:84] Creating Layer conv5_1/sep/scale
I0621 10:18:08.031630 17579 net.cpp:406] conv5_1/sep/scale <- conv5_1/sep
I0621 10:18:08.031642 17579 net.cpp:367] conv5_1/sep/scale -> conv5_1/sep (in-place)
I0621 10:18:08.031713 17579 layer_factory.hpp:77] Creating layer conv5_1/sep/scale
I0621 10:18:08.031867 17579 net.cpp:122] Setting up conv5_1/sep/scale
I0621 10:18:08.031886 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.031895 17579 net.cpp:137] Memory required for data: 652288040
I0621 10:18:08.031908 17579 layer_factory.hpp:77] Creating layer relu5_1/sep
I0621 10:18:08.031919 17579 net.cpp:84] Creating Layer relu5_1/sep
I0621 10:18:08.031929 17579 net.cpp:406] relu5_1/sep <- conv5_1/sep
I0621 10:18:08.031942 17579 net.cpp:367] relu5_1/sep -> conv5_1/sep (in-place)
I0621 10:18:08.032169 17579 net.cpp:122] Setting up relu5_1/sep
I0621 10:18:08.032188 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.032197 17579 net.cpp:137] Memory required for data: 656302120
I0621 10:18:08.032207 17579 layer_factory.hpp:77] Creating layer conv5_2/dw
I0621 10:18:08.032232 17579 net.cpp:84] Creating Layer conv5_2/dw
I0621 10:18:08.032243 17579 net.cpp:406] conv5_2/dw <- conv5_1/sep
I0621 10:18:08.032255 17579 net.cpp:380] conv5_2/dw -> conv5_2/dw
I0621 10:18:08.032457 17579 net.cpp:122] Setting up conv5_2/dw
I0621 10:18:08.032476 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.032485 17579 net.cpp:137] Memory required for data: 660316200
I0621 10:18:08.032495 17579 layer_factory.hpp:77] Creating layer conv5_2/dw/bn
I0621 10:18:08.032522 17579 net.cpp:84] Creating Layer conv5_2/dw/bn
I0621 10:18:08.032536 17579 net.cpp:406] conv5_2/dw/bn <- conv5_2/dw
I0621 10:18:08.032547 17579 net.cpp:367] conv5_2/dw/bn -> conv5_2/dw (in-place)
I0621 10:18:08.032791 17579 net.cpp:122] Setting up conv5_2/dw/bn
I0621 10:18:08.032809 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.032816 17579 net.cpp:137] Memory required for data: 664330280
I0621 10:18:08.032840 17579 layer_factory.hpp:77] Creating layer conv5_2/dw/scale
I0621 10:18:08.032857 17579 net.cpp:84] Creating Layer conv5_2/dw/scale
I0621 10:18:08.032867 17579 net.cpp:406] conv5_2/dw/scale <- conv5_2/dw
I0621 10:18:08.032878 17579 net.cpp:367] conv5_2/dw/scale -> conv5_2/dw (in-place)
I0621 10:18:08.032934 17579 layer_factory.hpp:77] Creating layer conv5_2/dw/scale
I0621 10:18:08.033087 17579 net.cpp:122] Setting up conv5_2/dw/scale
I0621 10:18:08.033112 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.033120 17579 net.cpp:137] Memory required for data: 668344360
I0621 10:18:08.033133 17579 layer_factory.hpp:77] Creating layer relu5_2/dw
I0621 10:18:08.033170 17579 net.cpp:84] Creating Layer relu5_2/dw
I0621 10:18:08.033182 17579 net.cpp:406] relu5_2/dw <- conv5_2/dw
I0621 10:18:08.033193 17579 net.cpp:367] relu5_2/dw -> conv5_2/dw (in-place)
I0621 10:18:08.033731 17579 net.cpp:122] Setting up relu5_2/dw
I0621 10:18:08.033754 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.033763 17579 net.cpp:137] Memory required for data: 672358440
I0621 10:18:08.033772 17579 layer_factory.hpp:77] Creating layer conv5_2/sep
I0621 10:18:08.033789 17579 net.cpp:84] Creating Layer conv5_2/sep
I0621 10:18:08.033800 17579 net.cpp:406] conv5_2/sep <- conv5_2/dw
I0621 10:18:08.033816 17579 net.cpp:380] conv5_2/sep -> conv5_2/sep
I0621 10:18:08.039490 17579 net.cpp:122] Setting up conv5_2/sep
I0621 10:18:08.039523 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.039535 17579 net.cpp:137] Memory required for data: 676372520
I0621 10:18:08.039548 17579 layer_factory.hpp:77] Creating layer conv5_2/sep/bn
I0621 10:18:08.039580 17579 net.cpp:84] Creating Layer conv5_2/sep/bn
I0621 10:18:08.039592 17579 net.cpp:406] conv5_2/sep/bn <- conv5_2/sep
I0621 10:18:08.039602 17579 net.cpp:367] conv5_2/sep/bn -> conv5_2/sep (in-place)
I0621 10:18:08.039854 17579 net.cpp:122] Setting up conv5_2/sep/bn
I0621 10:18:08.039871 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.039880 17579 net.cpp:137] Memory required for data: 680386600
I0621 10:18:08.039894 17579 layer_factory.hpp:77] Creating layer conv5_2/sep/scale
I0621 10:18:08.039911 17579 net.cpp:84] Creating Layer conv5_2/sep/scale
I0621 10:18:08.039932 17579 net.cpp:406] conv5_2/sep/scale <- conv5_2/sep
I0621 10:18:08.039945 17579 net.cpp:367] conv5_2/sep/scale -> conv5_2/sep (in-place)
I0621 10:18:08.040002 17579 layer_factory.hpp:77] Creating layer conv5_2/sep/scale
I0621 10:18:08.040163 17579 net.cpp:122] Setting up conv5_2/sep/scale
I0621 10:18:08.040179 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.040189 17579 net.cpp:137] Memory required for data: 684400680
I0621 10:18:08.040200 17579 layer_factory.hpp:77] Creating layer relu5_2/sep
I0621 10:18:08.040212 17579 net.cpp:84] Creating Layer relu5_2/sep
I0621 10:18:08.040221 17579 net.cpp:406] relu5_2/sep <- conv5_2/sep
I0621 10:18:08.040235 17579 net.cpp:367] relu5_2/sep -> conv5_2/sep (in-place)
I0621 10:18:08.040463 17579 net.cpp:122] Setting up relu5_2/sep
I0621 10:18:08.040482 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.040491 17579 net.cpp:137] Memory required for data: 688414760
I0621 10:18:08.040499 17579 layer_factory.hpp:77] Creating layer conv5_3/dw
I0621 10:18:08.040524 17579 net.cpp:84] Creating Layer conv5_3/dw
I0621 10:18:08.040537 17579 net.cpp:406] conv5_3/dw <- conv5_2/sep
I0621 10:18:08.040555 17579 net.cpp:380] conv5_3/dw -> conv5_3/dw
I0621 10:18:08.040751 17579 net.cpp:122] Setting up conv5_3/dw
I0621 10:18:08.040769 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.040777 17579 net.cpp:137] Memory required for data: 692428840
I0621 10:18:08.040796 17579 layer_factory.hpp:77] Creating layer conv5_3/dw/bn
I0621 10:18:08.040820 17579 net.cpp:84] Creating Layer conv5_3/dw/bn
I0621 10:18:08.040832 17579 net.cpp:406] conv5_3/dw/bn <- conv5_3/dw
I0621 10:18:08.040848 17579 net.cpp:367] conv5_3/dw/bn -> conv5_3/dw (in-place)
I0621 10:18:08.041085 17579 net.cpp:122] Setting up conv5_3/dw/bn
I0621 10:18:08.041103 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.041111 17579 net.cpp:137] Memory required for data: 696442920
I0621 10:18:08.041126 17579 layer_factory.hpp:77] Creating layer conv5_3/dw/scale
I0621 10:18:08.041137 17579 net.cpp:84] Creating Layer conv5_3/dw/scale
I0621 10:18:08.041146 17579 net.cpp:406] conv5_3/dw/scale <- conv5_3/dw
I0621 10:18:08.041160 17579 net.cpp:367] conv5_3/dw/scale -> conv5_3/dw (in-place)
I0621 10:18:08.041223 17579 layer_factory.hpp:77] Creating layer conv5_3/dw/scale
I0621 10:18:08.041381 17579 net.cpp:122] Setting up conv5_3/dw/scale
I0621 10:18:08.041399 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.041406 17579 net.cpp:137] Memory required for data: 700457000
I0621 10:18:08.041419 17579 layer_factory.hpp:77] Creating layer relu5_3/dw
I0621 10:18:08.041430 17579 net.cpp:84] Creating Layer relu5_3/dw
I0621 10:18:08.041440 17579 net.cpp:406] relu5_3/dw <- conv5_3/dw
I0621 10:18:08.041450 17579 net.cpp:367] relu5_3/dw -> conv5_3/dw (in-place)
I0621 10:18:08.041991 17579 net.cpp:122] Setting up relu5_3/dw
I0621 10:18:08.042013 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.042022 17579 net.cpp:137] Memory required for data: 704471080
I0621 10:18:08.042032 17579 layer_factory.hpp:77] Creating layer conv5_3/sep
I0621 10:18:08.042057 17579 net.cpp:84] Creating Layer conv5_3/sep
I0621 10:18:08.042069 17579 net.cpp:406] conv5_3/sep <- conv5_3/dw
I0621 10:18:08.042085 17579 net.cpp:380] conv5_3/sep -> conv5_3/sep
I0621 10:18:08.047726 17579 net.cpp:122] Setting up conv5_3/sep
I0621 10:18:08.047751 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.047760 17579 net.cpp:137] Memory required for data: 708485160
I0621 10:18:08.047787 17579 layer_factory.hpp:77] Creating layer conv5_3/sep/bn
I0621 10:18:08.047806 17579 net.cpp:84] Creating Layer conv5_3/sep/bn
I0621 10:18:08.047816 17579 net.cpp:406] conv5_3/sep/bn <- conv5_3/sep
I0621 10:18:08.047827 17579 net.cpp:367] conv5_3/sep/bn -> conv5_3/sep (in-place)
I0621 10:18:08.048079 17579 net.cpp:122] Setting up conv5_3/sep/bn
I0621 10:18:08.048097 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.048105 17579 net.cpp:137] Memory required for data: 712499240
I0621 10:18:08.048135 17579 layer_factory.hpp:77] Creating layer conv5_3/sep/scale
I0621 10:18:08.048149 17579 net.cpp:84] Creating Layer conv5_3/sep/scale
I0621 10:18:08.048158 17579 net.cpp:406] conv5_3/sep/scale <- conv5_3/sep
I0621 10:18:08.048169 17579 net.cpp:367] conv5_3/sep/scale -> conv5_3/sep (in-place)
I0621 10:18:08.048228 17579 layer_factory.hpp:77] Creating layer conv5_3/sep/scale
I0621 10:18:08.048385 17579 net.cpp:122] Setting up conv5_3/sep/scale
I0621 10:18:08.048403 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.048410 17579 net.cpp:137] Memory required for data: 716513320
I0621 10:18:08.048424 17579 layer_factory.hpp:77] Creating layer relu5_3/sep
I0621 10:18:08.048446 17579 net.cpp:84] Creating Layer relu5_3/sep
I0621 10:18:08.048457 17579 net.cpp:406] relu5_3/sep <- conv5_3/sep
I0621 10:18:08.048468 17579 net.cpp:367] relu5_3/sep -> conv5_3/sep (in-place)
I0621 10:18:08.048707 17579 net.cpp:122] Setting up relu5_3/sep
I0621 10:18:08.048728 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.048737 17579 net.cpp:137] Memory required for data: 720527400
I0621 10:18:08.048745 17579 layer_factory.hpp:77] Creating layer conv5_4/dw
I0621 10:18:08.048770 17579 net.cpp:84] Creating Layer conv5_4/dw
I0621 10:18:08.048781 17579 net.cpp:406] conv5_4/dw <- conv5_3/sep
I0621 10:18:08.048799 17579 net.cpp:380] conv5_4/dw -> conv5_4/dw
I0621 10:18:08.049005 17579 net.cpp:122] Setting up conv5_4/dw
I0621 10:18:08.049024 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.049032 17579 net.cpp:137] Memory required for data: 724541480
I0621 10:18:08.049043 17579 layer_factory.hpp:77] Creating layer conv5_4/dw/bn
I0621 10:18:08.049055 17579 net.cpp:84] Creating Layer conv5_4/dw/bn
I0621 10:18:08.049073 17579 net.cpp:406] conv5_4/dw/bn <- conv5_4/dw
I0621 10:18:08.049085 17579 net.cpp:367] conv5_4/dw/bn -> conv5_4/dw (in-place)
I0621 10:18:08.049326 17579 net.cpp:122] Setting up conv5_4/dw/bn
I0621 10:18:08.049343 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.049351 17579 net.cpp:137] Memory required for data: 728555560
I0621 10:18:08.049365 17579 layer_factory.hpp:77] Creating layer conv5_4/dw/scale
I0621 10:18:08.049391 17579 net.cpp:84] Creating Layer conv5_4/dw/scale
I0621 10:18:08.049408 17579 net.cpp:406] conv5_4/dw/scale <- conv5_4/dw
I0621 10:18:08.049420 17579 net.cpp:367] conv5_4/dw/scale -> conv5_4/dw (in-place)
I0621 10:18:08.049477 17579 layer_factory.hpp:77] Creating layer conv5_4/dw/scale
I0621 10:18:08.049659 17579 net.cpp:122] Setting up conv5_4/dw/scale
I0621 10:18:08.049679 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.049686 17579 net.cpp:137] Memory required for data: 732569640
I0621 10:18:08.049726 17579 layer_factory.hpp:77] Creating layer relu5_4/dw
I0621 10:18:08.049744 17579 net.cpp:84] Creating Layer relu5_4/dw
I0621 10:18:08.049754 17579 net.cpp:406] relu5_4/dw <- conv5_4/dw
I0621 10:18:08.049767 17579 net.cpp:367] relu5_4/dw -> conv5_4/dw (in-place)
I0621 10:18:08.050278 17579 net.cpp:122] Setting up relu5_4/dw
I0621 10:18:08.050299 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.050309 17579 net.cpp:137] Memory required for data: 736583720
I0621 10:18:08.050318 17579 layer_factory.hpp:77] Creating layer conv5_4/sep
I0621 10:18:08.050343 17579 net.cpp:84] Creating Layer conv5_4/sep
I0621 10:18:08.050355 17579 net.cpp:406] conv5_4/sep <- conv5_4/dw
I0621 10:18:08.050371 17579 net.cpp:380] conv5_4/sep -> conv5_4/sep
I0621 10:18:08.056030 17579 net.cpp:122] Setting up conv5_4/sep
I0621 10:18:08.056054 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.056064 17579 net.cpp:137] Memory required for data: 740597800
I0621 10:18:08.056078 17579 layer_factory.hpp:77] Creating layer conv5_4/sep/bn
I0621 10:18:08.056104 17579 net.cpp:84] Creating Layer conv5_4/sep/bn
I0621 10:18:08.056115 17579 net.cpp:406] conv5_4/sep/bn <- conv5_4/sep
I0621 10:18:08.056126 17579 net.cpp:367] conv5_4/sep/bn -> conv5_4/sep (in-place)
I0621 10:18:08.056385 17579 net.cpp:122] Setting up conv5_4/sep/bn
I0621 10:18:08.056413 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.056422 17579 net.cpp:137] Memory required for data: 744611880
I0621 10:18:08.056437 17579 layer_factory.hpp:77] Creating layer conv5_4/sep/scale
I0621 10:18:08.056453 17579 net.cpp:84] Creating Layer conv5_4/sep/scale
I0621 10:18:08.056463 17579 net.cpp:406] conv5_4/sep/scale <- conv5_4/sep
I0621 10:18:08.056475 17579 net.cpp:367] conv5_4/sep/scale -> conv5_4/sep (in-place)
I0621 10:18:08.056545 17579 layer_factory.hpp:77] Creating layer conv5_4/sep/scale
I0621 10:18:08.056710 17579 net.cpp:122] Setting up conv5_4/sep/scale
I0621 10:18:08.056728 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.056736 17579 net.cpp:137] Memory required for data: 748625960
I0621 10:18:08.056749 17579 layer_factory.hpp:77] Creating layer relu5_4/sep
I0621 10:18:08.056763 17579 net.cpp:84] Creating Layer relu5_4/sep
I0621 10:18:08.056773 17579 net.cpp:406] relu5_4/sep <- conv5_4/sep
I0621 10:18:08.056784 17579 net.cpp:367] relu5_4/sep -> conv5_4/sep (in-place)
I0621 10:18:08.057013 17579 net.cpp:122] Setting up relu5_4/sep
I0621 10:18:08.057031 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.057040 17579 net.cpp:137] Memory required for data: 752640040
I0621 10:18:08.057049 17579 layer_factory.hpp:77] Creating layer conv5_5/dw
I0621 10:18:08.057081 17579 net.cpp:84] Creating Layer conv5_5/dw
I0621 10:18:08.057092 17579 net.cpp:406] conv5_5/dw <- conv5_4/sep
I0621 10:18:08.057108 17579 net.cpp:380] conv5_5/dw -> conv5_5/dw
I0621 10:18:08.057314 17579 net.cpp:122] Setting up conv5_5/dw
I0621 10:18:08.057332 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.057341 17579 net.cpp:137] Memory required for data: 756654120
I0621 10:18:08.057353 17579 layer_factory.hpp:77] Creating layer conv5_5/dw/bn
I0621 10:18:08.057368 17579 net.cpp:84] Creating Layer conv5_5/dw/bn
I0621 10:18:08.057377 17579 net.cpp:406] conv5_5/dw/bn <- conv5_5/dw
I0621 10:18:08.057391 17579 net.cpp:367] conv5_5/dw/bn -> conv5_5/dw (in-place)
I0621 10:18:08.057651 17579 net.cpp:122] Setting up conv5_5/dw/bn
I0621 10:18:08.057669 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.057678 17579 net.cpp:137] Memory required for data: 760668200
I0621 10:18:08.057699 17579 layer_factory.hpp:77] Creating layer conv5_5/dw/scale
I0621 10:18:08.057716 17579 net.cpp:84] Creating Layer conv5_5/dw/scale
I0621 10:18:08.057726 17579 net.cpp:406] conv5_5/dw/scale <- conv5_5/dw
I0621 10:18:08.057739 17579 net.cpp:367] conv5_5/dw/scale -> conv5_5/dw (in-place)
I0621 10:18:08.057796 17579 layer_factory.hpp:77] Creating layer conv5_5/dw/scale
I0621 10:18:08.057956 17579 net.cpp:122] Setting up conv5_5/dw/scale
I0621 10:18:08.057973 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.057982 17579 net.cpp:137] Memory required for data: 764682280
I0621 10:18:08.057994 17579 layer_factory.hpp:77] Creating layer relu5_5/dw
I0621 10:18:08.058006 17579 net.cpp:84] Creating Layer relu5_5/dw
I0621 10:18:08.058014 17579 net.cpp:406] relu5_5/dw <- conv5_5/dw
I0621 10:18:08.058028 17579 net.cpp:367] relu5_5/dw -> conv5_5/dw (in-place)
I0621 10:18:08.058568 17579 net.cpp:122] Setting up relu5_5/dw
I0621 10:18:08.058591 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.058600 17579 net.cpp:137] Memory required for data: 768696360
I0621 10:18:08.058617 17579 layer_factory.hpp:77] Creating layer conv5_5/sep
I0621 10:18:08.058642 17579 net.cpp:84] Creating Layer conv5_5/sep
I0621 10:18:08.058653 17579 net.cpp:406] conv5_5/sep <- conv5_5/dw
I0621 10:18:08.058666 17579 net.cpp:380] conv5_5/sep -> conv5_5/sep
I0621 10:18:08.064342 17579 net.cpp:122] Setting up conv5_5/sep
I0621 10:18:08.064366 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.064375 17579 net.cpp:137] Memory required for data: 772710440
I0621 10:18:08.064389 17579 layer_factory.hpp:77] Creating layer conv5_5/sep/bn
I0621 10:18:08.064401 17579 net.cpp:84] Creating Layer conv5_5/sep/bn
I0621 10:18:08.064411 17579 net.cpp:406] conv5_5/sep/bn <- conv5_5/sep
I0621 10:18:08.064442 17579 net.cpp:367] conv5_5/sep/bn -> conv5_5/sep (in-place)
I0621 10:18:08.064713 17579 net.cpp:122] Setting up conv5_5/sep/bn
I0621 10:18:08.064731 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.064740 17579 net.cpp:137] Memory required for data: 776724520
I0621 10:18:08.064754 17579 layer_factory.hpp:77] Creating layer conv5_5/sep/scale
I0621 10:18:08.064767 17579 net.cpp:84] Creating Layer conv5_5/sep/scale
I0621 10:18:08.064776 17579 net.cpp:406] conv5_5/sep/scale <- conv5_5/sep
I0621 10:18:08.064787 17579 net.cpp:367] conv5_5/sep/scale -> conv5_5/sep (in-place)
I0621 10:18:08.064846 17579 layer_factory.hpp:77] Creating layer conv5_5/sep/scale
I0621 10:18:08.065006 17579 net.cpp:122] Setting up conv5_5/sep/scale
I0621 10:18:08.065022 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.065032 17579 net.cpp:137] Memory required for data: 780738600
I0621 10:18:08.065043 17579 layer_factory.hpp:77] Creating layer relu5_5/sep
I0621 10:18:08.065064 17579 net.cpp:84] Creating Layer relu5_5/sep
I0621 10:18:08.065076 17579 net.cpp:406] relu5_5/sep <- conv5_5/sep
I0621 10:18:08.065090 17579 net.cpp:367] relu5_5/sep -> conv5_5/sep (in-place)
I0621 10:18:08.065330 17579 net.cpp:122] Setting up relu5_5/sep
I0621 10:18:08.065348 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.065357 17579 net.cpp:137] Memory required for data: 784752680
I0621 10:18:08.065374 17579 layer_factory.hpp:77] Creating layer conv5_6/dw
I0621 10:18:08.065392 17579 net.cpp:84] Creating Layer conv5_6/dw
I0621 10:18:08.065403 17579 net.cpp:406] conv5_6/dw <- conv5_5/sep
I0621 10:18:08.065415 17579 net.cpp:380] conv5_6/dw -> conv5_6/dw
I0621 10:18:08.065644 17579 net.cpp:122] Setting up conv5_6/dw
I0621 10:18:08.065665 17579 net.cpp:129] Top shape: 10 512 7 7 (250880)
I0621 10:18:08.065673 17579 net.cpp:137] Memory required for data: 785756200
I0621 10:18:08.065685 17579 layer_factory.hpp:77] Creating layer conv5_6/dw/bn
I0621 10:18:08.065699 17579 net.cpp:84] Creating Layer conv5_6/dw/bn
I0621 10:18:08.065709 17579 net.cpp:406] conv5_6/dw/bn <- conv5_6/dw
I0621 10:18:08.065721 17579 net.cpp:367] conv5_6/dw/bn -> conv5_6/dw (in-place)
I0621 10:18:08.066143 17579 net.cpp:122] Setting up conv5_6/dw/bn
I0621 10:18:08.066161 17579 net.cpp:129] Top shape: 10 512 7 7 (250880)
I0621 10:18:08.066170 17579 net.cpp:137] Memory required for data: 786759720
I0621 10:18:08.066184 17579 layer_factory.hpp:77] Creating layer conv5_6/dw/scale
I0621 10:18:08.066210 17579 net.cpp:84] Creating Layer conv5_6/dw/scale
I0621 10:18:08.066220 17579 net.cpp:406] conv5_6/dw/scale <- conv5_6/dw
I0621 10:18:08.066231 17579 net.cpp:367] conv5_6/dw/scale -> conv5_6/dw (in-place)
I0621 10:18:08.066289 17579 layer_factory.hpp:77] Creating layer conv5_6/dw/scale
I0621 10:18:08.066455 17579 net.cpp:122] Setting up conv5_6/dw/scale
I0621 10:18:08.066473 17579 net.cpp:129] Top shape: 10 512 7 7 (250880)
I0621 10:18:08.066480 17579 net.cpp:137] Memory required for data: 787763240
I0621 10:18:08.066504 17579 layer_factory.hpp:77] Creating layer relu5_6/dw
I0621 10:18:08.066527 17579 net.cpp:84] Creating Layer relu5_6/dw
I0621 10:18:08.066540 17579 net.cpp:406] relu5_6/dw <- conv5_6/dw
I0621 10:18:08.066550 17579 net.cpp:367] relu5_6/dw -> conv5_6/dw (in-place)
I0621 10:18:08.067066 17579 net.cpp:122] Setting up relu5_6/dw
I0621 10:18:08.067088 17579 net.cpp:129] Top shape: 10 512 7 7 (250880)
I0621 10:18:08.067097 17579 net.cpp:137] Memory required for data: 788766760
I0621 10:18:08.067106 17579 layer_factory.hpp:77] Creating layer conv5_6/sep
I0621 10:18:08.067123 17579 net.cpp:84] Creating Layer conv5_6/sep
I0621 10:18:08.067133 17579 net.cpp:406] conv5_6/sep <- conv5_6/dw
I0621 10:18:08.067149 17579 net.cpp:380] conv5_6/sep -> conv5_6/sep
I0621 10:18:08.078218 17579 net.cpp:122] Setting up conv5_6/sep
I0621 10:18:08.078245 17579 net.cpp:129] Top shape: 10 1024 7 7 (501760)
I0621 10:18:08.078255 17579 net.cpp:137] Memory required for data: 790773800
I0621 10:18:08.078269 17579 layer_factory.hpp:77] Creating layer conv5_6/sep/bn
I0621 10:18:08.078306 17579 net.cpp:84] Creating Layer conv5_6/sep/bn
I0621 10:18:08.078318 17579 net.cpp:406] conv5_6/sep/bn <- conv5_6/sep
I0621 10:18:08.078330 17579 net.cpp:367] conv5_6/sep/bn -> conv5_6/sep (in-place)
I0621 10:18:08.078604 17579 net.cpp:122] Setting up conv5_6/sep/bn
I0621 10:18:08.078624 17579 net.cpp:129] Top shape: 10 1024 7 7 (501760)
I0621 10:18:08.078634 17579 net.cpp:137] Memory required for data: 792780840
I0621 10:18:08.078647 17579 layer_factory.hpp:77] Creating layer conv5_6/sep/scale
I0621 10:18:08.078660 17579 net.cpp:84] Creating Layer conv5_6/sep/scale
I0621 10:18:08.078670 17579 net.cpp:406] conv5_6/sep/scale <- conv5_6/sep
I0621 10:18:08.078689 17579 net.cpp:367] conv5_6/sep/scale -> conv5_6/sep (in-place)
I0621 10:18:08.078747 17579 layer_factory.hpp:77] Creating layer conv5_6/sep/scale
I0621 10:18:08.078910 17579 net.cpp:122] Setting up conv5_6/sep/scale
I0621 10:18:08.078932 17579 net.cpp:129] Top shape: 10 1024 7 7 (501760)
I0621 10:18:08.078940 17579 net.cpp:137] Memory required for data: 794787880
I0621 10:18:08.078963 17579 layer_factory.hpp:77] Creating layer relu5_6/sep
I0621 10:18:08.078977 17579 net.cpp:84] Creating Layer relu5_6/sep
I0621 10:18:08.078986 17579 net.cpp:406] relu5_6/sep <- conv5_6/sep
I0621 10:18:08.078997 17579 net.cpp:367] relu5_6/sep -> conv5_6/sep (in-place)
I0621 10:18:08.079237 17579 net.cpp:122] Setting up relu5_6/sep
I0621 10:18:08.079259 17579 net.cpp:129] Top shape: 10 1024 7 7 (501760)
I0621 10:18:08.079269 17579 net.cpp:137] Memory required for data: 796794920
I0621 10:18:08.079277 17579 layer_factory.hpp:77] Creating layer conv6/dw
I0621 10:18:08.079300 17579 net.cpp:84] Creating Layer conv6/dw
I0621 10:18:08.079313 17579 net.cpp:406] conv6/dw <- conv5_6/sep
I0621 10:18:08.079329 17579 net.cpp:380] conv6/dw -> conv6/dw
I0621 10:18:08.079605 17579 net.cpp:122] Setting up conv6/dw
I0621 10:18:08.079624 17579 net.cpp:129] Top shape: 10 1024 7 7 (501760)
I0621 10:18:08.079633 17579 net.cpp:137] Memory required for data: 798801960
I0621 10:18:08.079644 17579 layer_factory.hpp:77] Creating layer conv6/dw/bn
I0621 10:18:08.079672 17579 net.cpp:84] Creating Layer conv6/dw/bn
I0621 10:18:08.079684 17579 net.cpp:406] conv6/dw/bn <- conv6/dw
I0621 10:18:08.079702 17579 net.cpp:367] conv6/dw/bn -> conv6/dw (in-place)
I0621 10:18:08.079960 17579 net.cpp:122] Setting up conv6/dw/bn
I0621 10:18:08.079977 17579 net.cpp:129] Top shape: 10 1024 7 7 (501760)
I0621 10:18:08.079985 17579 net.cpp:137] Memory required for data: 800809000
I0621 10:18:08.079999 17579 layer_factory.hpp:77] Creating layer conv6/dw/scale
I0621 10:18:08.080013 17579 net.cpp:84] Creating Layer conv6/dw/scale
I0621 10:18:08.080021 17579 net.cpp:406] conv6/dw/scale <- conv6/dw
I0621 10:18:08.080032 17579 net.cpp:367] conv6/dw/scale -> conv6/dw (in-place)
I0621 10:18:08.080092 17579 layer_factory.hpp:77] Creating layer conv6/dw/scale
I0621 10:18:08.080258 17579 net.cpp:122] Setting up conv6/dw/scale
I0621 10:18:08.080278 17579 net.cpp:129] Top shape: 10 1024 7 7 (501760)
I0621 10:18:08.080287 17579 net.cpp:137] Memory required for data: 802816040
I0621 10:18:08.080310 17579 layer_factory.hpp:77] Creating layer relu6/dw
I0621 10:18:08.080324 17579 net.cpp:84] Creating Layer relu6/dw
I0621 10:18:08.080333 17579 net.cpp:406] relu6/dw <- conv6/dw
I0621 10:18:08.080348 17579 net.cpp:367] relu6/dw -> conv6/dw (in-place)
I0621 10:18:08.080873 17579 net.cpp:122] Setting up relu6/dw
I0621 10:18:08.080894 17579 net.cpp:129] Top shape: 10 1024 7 7 (501760)
I0621 10:18:08.080904 17579 net.cpp:137] Memory required for data: 804823080
I0621 10:18:08.080912 17579 layer_factory.hpp:77] Creating layer conv6/sep
I0621 10:18:08.080938 17579 net.cpp:84] Creating Layer conv6/sep
I0621 10:18:08.080950 17579 net.cpp:406] conv6/sep <- conv6/dw
I0621 10:18:08.080963 17579 net.cpp:380] conv6/sep -> conv6/sep
I0621 10:18:08.102334 17579 net.cpp:122] Setting up conv6/sep
I0621 10:18:08.102371 17579 net.cpp:129] Top shape: 10 1024 7 7 (501760)
I0621 10:18:08.102381 17579 net.cpp:137] Memory required for data: 806830120
I0621 10:18:08.102411 17579 layer_factory.hpp:77] Creating layer conv6/sep/bn
I0621 10:18:08.102432 17579 net.cpp:84] Creating Layer conv6/sep/bn
I0621 10:18:08.102443 17579 net.cpp:406] conv6/sep/bn <- conv6/sep
I0621 10:18:08.102459 17579 net.cpp:367] conv6/sep/bn -> conv6/sep (in-place)
I0621 10:18:08.102736 17579 net.cpp:122] Setting up conv6/sep/bn
I0621 10:18:08.102756 17579 net.cpp:129] Top shape: 10 1024 7 7 (501760)
I0621 10:18:08.102764 17579 net.cpp:137] Memory required for data: 808837160
I0621 10:18:08.102778 17579 layer_factory.hpp:77] Creating layer conv6/sep/scale
I0621 10:18:08.102821 17579 net.cpp:84] Creating Layer conv6/sep/scale
I0621 10:18:08.102833 17579 net.cpp:406] conv6/sep/scale <- conv6/sep
I0621 10:18:08.102843 17579 net.cpp:367] conv6/sep/scale -> conv6/sep (in-place)
I0621 10:18:08.102902 17579 layer_factory.hpp:77] Creating layer conv6/sep/scale
I0621 10:18:08.103070 17579 net.cpp:122] Setting up conv6/sep/scale
I0621 10:18:08.103087 17579 net.cpp:129] Top shape: 10 1024 7 7 (501760)
I0621 10:18:08.103096 17579 net.cpp:137] Memory required for data: 810844200
I0621 10:18:08.103108 17579 layer_factory.hpp:77] Creating layer relu6/sep
I0621 10:18:08.103121 17579 net.cpp:84] Creating Layer relu6/sep
I0621 10:18:08.103129 17579 net.cpp:406] relu6/sep <- conv6/sep
I0621 10:18:08.103142 17579 net.cpp:367] relu6/sep -> conv6/sep (in-place)
I0621 10:18:08.103694 17579 net.cpp:122] Setting up relu6/sep
I0621 10:18:08.103718 17579 net.cpp:129] Top shape: 10 1024 7 7 (501760)
I0621 10:18:08.103726 17579 net.cpp:137] Memory required for data: 812851240
I0621 10:18:08.103735 17579 layer_factory.hpp:77] Creating layer pool6
I0621 10:18:08.103757 17579 net.cpp:84] Creating Layer pool6
I0621 10:18:08.103768 17579 net.cpp:406] pool6 <- conv6/sep
I0621 10:18:08.103783 17579 net.cpp:380] pool6 -> pool6
I0621 10:18:08.105000 17579 net.cpp:122] Setting up pool6
I0621 10:18:08.105024 17579 net.cpp:129] Top shape: 10 1024 1 1 (10240)
I0621 10:18:08.105034 17579 net.cpp:137] Memory required for data: 812892200
I0621 10:18:08.105042 17579 layer_factory.hpp:77] Creating layer fc7_oxford
I0621 10:18:08.105069 17579 net.cpp:84] Creating Layer fc7_oxford
I0621 10:18:08.105082 17579 net.cpp:406] fc7_oxford <- pool6
I0621 10:18:08.105103 17579 net.cpp:380] fc7_oxford -> fc7
I0621 10:18:08.107866 17579 net.cpp:122] Setting up fc7_oxford
I0621 10:18:08.107889 17579 net.cpp:129] Top shape: 10 102 1 1 (1020)
I0621 10:18:08.107898 17579 net.cpp:137] Memory required for data: 812896280
I0621 10:18:08.107913 17579 layer_factory.hpp:77] Creating layer loss
I0621 10:18:08.107933 17579 net.cpp:84] Creating Layer loss
I0621 10:18:08.107944 17579 net.cpp:406] loss <- fc7
I0621 10:18:08.107954 17579 net.cpp:406] loss <- label
I0621 10:18:08.107967 17579 net.cpp:380] loss -> loss
I0621 10:18:08.107988 17579 layer_factory.hpp:77] Creating layer loss
I0621 10:18:08.108678 17579 net.cpp:122] Setting up loss
I0621 10:18:08.108701 17579 net.cpp:129] Top shape: (1)
I0621 10:18:08.108711 17579 net.cpp:132]     with loss weight 1
I0621 10:18:08.108772 17579 net.cpp:137] Memory required for data: 812896284
I0621 10:18:08.108783 17579 net.cpp:198] loss needs backward computation.
I0621 10:18:08.108793 17579 net.cpp:198] fc7_oxford needs backward computation.
I0621 10:18:08.108801 17579 net.cpp:198] pool6 needs backward computation.
I0621 10:18:08.108810 17579 net.cpp:198] relu6/sep needs backward computation.
I0621 10:18:08.108819 17579 net.cpp:198] conv6/sep/scale needs backward computation.
I0621 10:18:08.108827 17579 net.cpp:198] conv6/sep/bn needs backward computation.
I0621 10:18:08.108835 17579 net.cpp:198] conv6/sep needs backward computation.
I0621 10:18:08.108844 17579 net.cpp:198] relu6/dw needs backward computation.
I0621 10:18:08.108852 17579 net.cpp:198] conv6/dw/scale needs backward computation.
I0621 10:18:08.108860 17579 net.cpp:198] conv6/dw/bn needs backward computation.
I0621 10:18:08.108870 17579 net.cpp:198] conv6/dw needs backward computation.
I0621 10:18:08.108877 17579 net.cpp:198] relu5_6/sep needs backward computation.
I0621 10:18:08.108897 17579 net.cpp:198] conv5_6/sep/scale needs backward computation.
I0621 10:18:08.108906 17579 net.cpp:198] conv5_6/sep/bn needs backward computation.
I0621 10:18:08.108914 17579 net.cpp:198] conv5_6/sep needs backward computation.
I0621 10:18:08.108923 17579 net.cpp:198] relu5_6/dw needs backward computation.
I0621 10:18:08.108932 17579 net.cpp:198] conv5_6/dw/scale needs backward computation.
I0621 10:18:08.108940 17579 net.cpp:198] conv5_6/dw/bn needs backward computation.
I0621 10:18:08.108948 17579 net.cpp:198] conv5_6/dw needs backward computation.
I0621 10:18:08.108958 17579 net.cpp:198] relu5_5/sep needs backward computation.
I0621 10:18:08.108965 17579 net.cpp:198] conv5_5/sep/scale needs backward computation.
I0621 10:18:08.108973 17579 net.cpp:198] conv5_5/sep/bn needs backward computation.
I0621 10:18:08.108983 17579 net.cpp:198] conv5_5/sep needs backward computation.
I0621 10:18:08.108990 17579 net.cpp:198] relu5_5/dw needs backward computation.
I0621 10:18:08.108999 17579 net.cpp:198] conv5_5/dw/scale needs backward computation.
I0621 10:18:08.109007 17579 net.cpp:198] conv5_5/dw/bn needs backward computation.
I0621 10:18:08.109015 17579 net.cpp:198] conv5_5/dw needs backward computation.
I0621 10:18:08.109025 17579 net.cpp:198] relu5_4/sep needs backward computation.
I0621 10:18:08.109032 17579 net.cpp:198] conv5_4/sep/scale needs backward computation.
I0621 10:18:08.109040 17579 net.cpp:198] conv5_4/sep/bn needs backward computation.
I0621 10:18:08.109050 17579 net.cpp:198] conv5_4/sep needs backward computation.
I0621 10:18:08.109058 17579 net.cpp:198] relu5_4/dw needs backward computation.
I0621 10:18:08.109066 17579 net.cpp:198] conv5_4/dw/scale needs backward computation.
I0621 10:18:08.109074 17579 net.cpp:198] conv5_4/dw/bn needs backward computation.
I0621 10:18:08.109083 17579 net.cpp:198] conv5_4/dw needs backward computation.
I0621 10:18:08.109091 17579 net.cpp:198] relu5_3/sep needs backward computation.
I0621 10:18:08.109099 17579 net.cpp:198] conv5_3/sep/scale needs backward computation.
I0621 10:18:08.109108 17579 net.cpp:198] conv5_3/sep/bn needs backward computation.
I0621 10:18:08.109117 17579 net.cpp:198] conv5_3/sep needs backward computation.
I0621 10:18:08.109131 17579 net.cpp:198] relu5_3/dw needs backward computation.
I0621 10:18:08.109140 17579 net.cpp:198] conv5_3/dw/scale needs backward computation.
I0621 10:18:08.109149 17579 net.cpp:198] conv5_3/dw/bn needs backward computation.
I0621 10:18:08.109158 17579 net.cpp:198] conv5_3/dw needs backward computation.
I0621 10:18:08.109165 17579 net.cpp:198] relu5_2/sep needs backward computation.
I0621 10:18:08.109174 17579 net.cpp:198] conv5_2/sep/scale needs backward computation.
I0621 10:18:08.109182 17579 net.cpp:198] conv5_2/sep/bn needs backward computation.
I0621 10:18:08.109190 17579 net.cpp:198] conv5_2/sep needs backward computation.
I0621 10:18:08.109200 17579 net.cpp:198] relu5_2/dw needs backward computation.
I0621 10:18:08.109207 17579 net.cpp:198] conv5_2/dw/scale needs backward computation.
I0621 10:18:08.109215 17579 net.cpp:198] conv5_2/dw/bn needs backward computation.
I0621 10:18:08.109223 17579 net.cpp:198] conv5_2/dw needs backward computation.
I0621 10:18:08.109232 17579 net.cpp:198] relu5_1/sep needs backward computation.
I0621 10:18:08.109241 17579 net.cpp:198] conv5_1/sep/scale needs backward computation.
I0621 10:18:08.109248 17579 net.cpp:198] conv5_1/sep/bn needs backward computation.
I0621 10:18:08.109256 17579 net.cpp:198] conv5_1/sep needs backward computation.
I0621 10:18:08.109264 17579 net.cpp:198] relu5_1/dw needs backward computation.
I0621 10:18:08.109272 17579 net.cpp:198] conv5_1/dw/scale needs backward computation.
I0621 10:18:08.109282 17579 net.cpp:198] conv5_1/dw/bn needs backward computation.
I0621 10:18:08.109289 17579 net.cpp:198] conv5_1/dw needs backward computation.
I0621 10:18:08.109298 17579 net.cpp:198] relu4_2/sep needs backward computation.
I0621 10:18:08.109307 17579 net.cpp:198] conv4_2/sep/scale needs backward computation.
I0621 10:18:08.109323 17579 net.cpp:198] conv4_2/sep/bn needs backward computation.
I0621 10:18:08.109333 17579 net.cpp:198] conv4_2/sep needs backward computation.
I0621 10:18:08.109341 17579 net.cpp:198] relu4_2/dw needs backward computation.
I0621 10:18:08.109349 17579 net.cpp:198] conv4_2/dw/scale needs backward computation.
I0621 10:18:08.109357 17579 net.cpp:198] conv4_2/dw/bn needs backward computation.
I0621 10:18:08.109365 17579 net.cpp:198] conv4_2/dw needs backward computation.
I0621 10:18:08.109375 17579 net.cpp:198] relu4_1/sep needs backward computation.
I0621 10:18:08.109382 17579 net.cpp:198] conv4_1/sep/scale needs backward computation.
I0621 10:18:08.109391 17579 net.cpp:198] conv4_1/sep/bn needs backward computation.
I0621 10:18:08.109400 17579 net.cpp:198] conv4_1/sep needs backward computation.
I0621 10:18:08.109407 17579 net.cpp:198] relu4_1/dw needs backward computation.
I0621 10:18:08.109416 17579 net.cpp:198] conv4_1/dw/scale needs backward computation.
I0621 10:18:08.109428 17579 net.cpp:198] conv4_1/dw/bn needs backward computation.
I0621 10:18:08.109437 17579 net.cpp:198] conv4_1/dw needs backward computation.
I0621 10:18:08.109447 17579 net.cpp:198] relu3_2/sep needs backward computation.
I0621 10:18:08.109454 17579 net.cpp:198] conv3_2/sep/scale needs backward computation.
I0621 10:18:08.109463 17579 net.cpp:198] conv3_2/sep/bn needs backward computation.
I0621 10:18:08.109472 17579 net.cpp:198] conv3_2/sep needs backward computation.
I0621 10:18:08.109479 17579 net.cpp:198] relu3_2/dw needs backward computation.
I0621 10:18:08.109488 17579 net.cpp:198] conv3_2/dw/scale needs backward computation.
I0621 10:18:08.109496 17579 net.cpp:198] conv3_2/dw/bn needs backward computation.
I0621 10:18:08.109504 17579 net.cpp:198] conv3_2/dw needs backward computation.
I0621 10:18:08.109519 17579 net.cpp:198] relu3_1/sep needs backward computation.
I0621 10:18:08.109530 17579 net.cpp:198] conv3_1/sep/scale needs backward computation.
I0621 10:18:08.109539 17579 net.cpp:198] conv3_1/sep/bn needs backward computation.
I0621 10:18:08.109547 17579 net.cpp:198] conv3_1/sep needs backward computation.
I0621 10:18:08.109556 17579 net.cpp:198] relu3_1/dw needs backward computation.
I0621 10:18:08.109565 17579 net.cpp:198] conv3_1/dw/scale needs backward computation.
I0621 10:18:08.109583 17579 net.cpp:198] conv3_1/dw/bn needs backward computation.
I0621 10:18:08.109592 17579 net.cpp:198] conv3_1/dw needs backward computation.
I0621 10:18:08.109601 17579 net.cpp:198] relu2_2/sep needs backward computation.
I0621 10:18:08.109611 17579 net.cpp:198] conv2_2/sep/scale needs backward computation.
I0621 10:18:08.109618 17579 net.cpp:198] conv2_2/sep/bn needs backward computation.
I0621 10:18:08.109627 17579 net.cpp:198] conv2_2/sep needs backward computation.
I0621 10:18:08.109635 17579 net.cpp:198] relu2_2/dw needs backward computation.
I0621 10:18:08.109643 17579 net.cpp:198] conv2_2/dw/scale needs backward computation.
I0621 10:18:08.109652 17579 net.cpp:198] conv2_2/dw/bn needs backward computation.
I0621 10:18:08.109660 17579 net.cpp:198] conv2_2/dw needs backward computation.
I0621 10:18:08.109668 17579 net.cpp:198] relu2_1/sep needs backward computation.
I0621 10:18:08.109678 17579 net.cpp:198] conv2_1/sep/scale needs backward computation.
I0621 10:18:08.109685 17579 net.cpp:198] conv2_1/sep/bn needs backward computation.
I0621 10:18:08.109694 17579 net.cpp:198] conv2_1/sep needs backward computation.
I0621 10:18:08.109702 17579 net.cpp:198] relu2_1/dw needs backward computation.
I0621 10:18:08.109710 17579 net.cpp:198] conv2_1/dw/scale needs backward computation.
I0621 10:18:08.109719 17579 net.cpp:198] conv2_1/dw/bn needs backward computation.
I0621 10:18:08.109726 17579 net.cpp:198] conv2_1/dw needs backward computation.
I0621 10:18:08.109735 17579 net.cpp:198] relu1 needs backward computation.
I0621 10:18:08.109743 17579 net.cpp:198] conv1/scale needs backward computation.
I0621 10:18:08.109751 17579 net.cpp:198] conv1/bn needs backward computation.
I0621 10:18:08.109760 17579 net.cpp:198] conv1 needs backward computation.
I0621 10:18:08.109777 17579 net.cpp:200] data does not need backward computation.
I0621 10:18:08.109786 17579 net.cpp:242] This network produces output loss
I0621 10:18:08.109861 17579 net.cpp:255] Network initialization done.
I0621 10:18:08.112959 17579 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/xingzhaolong/caffe_project/Auto_prune/models/oxford/mobilenet/mobilenet_deploy.prototxt_pruning
I0621 10:18:08.112985 17579 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0621 10:18:08.113003 17579 solver.cpp:172] Creating test net (#0) specified by net file: /home/xingzhaolong/caffe_project/Auto_prune/models/oxford/mobilenet/mobilenet_deploy.prototxt_pruning
I0621 10:18:08.113143 17579 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0621 10:18:08.114116 17579 net.cpp:51] Initializing net from parameters: 
name: "MOBILENET"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_file: "/home/xingzhaolong/caffe_project/caffe/models/caffe-oxford102/imagenet_mean.binaryproto"
  }
  image_data_param {
    source: "/home/xingzhaolong/caffe_project/caffe/models/caffe-oxford102/train.txt"
    batch_size: 10
    new_height: 256
    new_width: 256
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv1/bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1/scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2_1/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv1"
  top: "conv2_1/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 32
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv2_1/dw"
  top: "conv2_1/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_1/dw/scale"
  type: "Scale"
  bottom: "conv2_1/dw"
  top: "conv2_1/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_1/dw"
  type: "ReLU"
  bottom: "conv2_1/dw"
  top: "conv2_1/dw"
}
layer {
  name: "conv2_1/sep"
  type: "CConvolution"
  bottom: "conv2_1/dw"
  top: "conv2_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv2_1/sep"
  top: "conv2_1/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_1/sep/scale"
  type: "Scale"
  bottom: "conv2_1/sep"
  top: "conv2_1/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_1/sep"
  type: "ReLU"
  bottom: "conv2_1/sep"
  top: "conv2_1/sep"
}
layer {
  name: "conv2_2/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv2_1/sep"
  top: "conv2_2/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 64
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv2_2/dw"
  top: "conv2_2/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_2/dw/scale"
  type: "Scale"
  bottom: "conv2_2/dw"
  top: "conv2_2/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_2/dw"
  type: "ReLU"
  bottom: "conv2_2/dw"
  top: "conv2_2/dw"
}
layer {
  name: "conv2_2/sep"
  type: "CConvolution"
  bottom: "conv2_2/dw"
  top: "conv2_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv2_2/sep"
  top: "conv2_2/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2_2/sep/scale"
  type: "Scale"
  bottom: "conv2_2/sep"
  top: "conv2_2/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_2/sep"
  type: "ReLU"
  bottom: "conv2_2/sep"
  top: "conv2_2/sep"
}
layer {
  name: "conv3_1/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv2_2/sep"
  top: "conv3_1/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv3_1/dw"
  top: "conv3_1/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_1/dw/scale"
  type: "Scale"
  bottom: "conv3_1/dw"
  top: "conv3_1/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_1/dw"
  type: "ReLU"
  bottom: "conv3_1/dw"
  top: "conv3_1/dw"
}
layer {
  name: "conv3_1/sep"
  type: "CConvolution"
  bottom: "conv3_1/dw"
  top: "conv3_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv3_1/sep"
  top: "conv3_1/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_1/sep/scale"
  type: "Scale"
  bottom: "conv3_1/sep"
  top: "conv3_1/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_1/sep"
  type: "ReLU"
  bottom: "conv3_1/sep"
  top: "conv3_1/sep"
}
layer {
  name: "conv3_2/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv3_1/sep"
  top: "conv3_2/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv3_2/dw"
  top: "conv3_2/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_2/dw/scale"
  type: "Scale"
  bottom: "conv3_2/dw"
  top: "conv3_2/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_2/dw"
  type: "ReLU"
  bottom: "conv3_2/dw"
  top: "conv3_2/dw"
}
layer {
  name: "conv3_2/sep"
  type: "CConvolution"
  bottom: "conv3_2/dw"
  top: "conv3_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv3_2/sep"
  top: "conv3_2/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3_2/sep/scale"
  type: "Scale"
  bottom: "conv3_2/sep"
  top: "conv3_2/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_2/sep"
  type: "ReLU"
  bottom: "conv3_2/sep"
  top: "conv3_2/sep"
}
layer {
  name: "conv4_1/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv3_2/sep"
  top: "conv4_1/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv4_1/dw"
  top: "conv4_1/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv4_1/dw/scale"
  type: "Scale"
  bottom: "conv4_1/dw"
  top: "conv4_1/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu4_1/dw"
  type: "ReLU"
  bottom: "conv4_1/dw"
  top: "conv4_1/dw"
}
layer {
  name: "conv4_1/sep"
  type: "CConvolution"
  bottom: "conv4_1/dw"
  top: "conv4_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv4_1/sep"
  top: "conv4_1/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv4_1/sep/scale"
  type: "Scale"
  bottom: "conv4_1/sep"
  top: "conv4_1/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu4_1/sep"
  type: "ReLU"
  bottom: "conv4_1/sep"
  top: "conv4_1/sep"
}
layer {
  name: "conv4_2/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv4_1/sep"
  top: "conv4_2/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv4_2/dw"
  top: "conv4_2/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv4_2/dw/scale"
  type: "Scale"
  bottom: "conv4_2/dw"
  top: "conv4_2/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu4_2/dw"
  type: "ReLU"
  bottom: "conv4_2/dw"
  top: "conv4_2/dw"
}
layer {
  name: "conv4_2/sep"
  type: "CConvolution"
  bottom: "conv4_2/dw"
  top: "conv4_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv4_2/sep"
  top: "conv4_2/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv4_2/sep/scale"
  type: "Scale"
  bottom: "conv4_2/sep"
  top: "conv4_2/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu4_2/sep"
  type: "ReLU"
  bottom: "conv4_2/sep"
  top: "conv4_2/sep"
}
layer {
  name: "conv5_1/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv4_2/sep"
  top: "conv5_1/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_1/dw"
  top: "conv5_1/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_1/dw/scale"
  type: "Scale"
  bottom: "conv5_1/dw"
  top: "conv5_1/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_1/dw"
  type: "ReLU"
  bottom: "conv5_1/dw"
  top: "conv5_1/dw"
}
layer {
  name: "conv5_1/sep"
  type: "CConvolution"
  bottom: "conv5_1/dw"
  top: "conv5_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_1/sep"
  top: "conv5_1/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_1/sep/scale"
  type: "Scale"
  bottom: "conv5_1/sep"
  top: "conv5_1/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_1/sep"
  type: "ReLU"
  bottom: "conv5_1/sep"
  top: "conv5_1/sep"
}
layer {
  name: "conv5_2/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_1/sep"
  top: "conv5_2/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_2/dw"
  top: "conv5_2/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_2/dw/scale"
  type: "Scale"
  bottom: "conv5_2/dw"
  top: "conv5_2/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_2/dw"
  type: "ReLU"
  bottom: "conv5_2/dw"
  top: "conv5_2/dw"
}
layer {
  name: "conv5_2/sep"
  type: "CConvolution"
  bottom: "conv5_2/dw"
  top: "conv5_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_2/sep"
  top: "conv5_2/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_2/sep/scale"
  type: "Scale"
  bottom: "conv5_2/sep"
  top: "conv5_2/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_2/sep"
  type: "ReLU"
  bottom: "conv5_2/sep"
  top: "conv5_2/sep"
}
layer {
  name: "conv5_3/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_2/sep"
  top: "conv5_3/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_3/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_3/dw"
  top: "conv5_3/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_3/dw/scale"
  type: "Scale"
  bottom: "conv5_3/dw"
  top: "conv5_3/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_3/dw"
  type: "ReLU"
  bottom: "conv5_3/dw"
  top: "conv5_3/dw"
}
layer {
  name: "conv5_3/sep"
  type: "CConvolution"
  bottom: "conv5_3/dw"
  top: "conv5_3/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_3/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_3/sep"
  top: "conv5_3/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_3/sep/scale"
  type: "Scale"
  bottom: "conv5_3/sep"
  top: "conv5_3/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_3/sep"
  type: "ReLU"
  bottom: "conv5_3/sep"
  top: "conv5_3/sep"
}
layer {
  name: "conv5_4/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_3/sep"
  top: "conv5_4/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_4/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_4/dw"
  top: "conv5_4/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_4/dw/scale"
  type: "Scale"
  bottom: "conv5_4/dw"
  top: "conv5_4/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_4/dw"
  type: "ReLU"
  bottom: "conv5_4/dw"
  top: "conv5_4/dw"
}
layer {
  name: "conv5_4/sep"
  type: "CConvolution"
  bottom: "conv5_4/dw"
  top: "conv5_4/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_4/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_4/sep"
  top: "conv5_4/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_4/sep/scale"
  type: "Scale"
  bottom: "conv5_4/sep"
  top: "conv5_4/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_4/sep"
  type: "ReLU"
  bottom: "conv5_4/sep"
  top: "conv5_4/sep"
}
layer {
  name: "conv5_5/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_4/sep"
  top: "conv5_5/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_5/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_5/dw"
  top: "conv5_5/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_5/dw/scale"
  type: "Scale"
  bottom: "conv5_5/dw"
  top: "conv5_5/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_5/dw"
  type: "ReLU"
  bottom: "conv5_5/dw"
  top: "conv5_5/dw"
}
layer {
  name: "conv5_5/sep"
  type: "CConvolution"
  bottom: "conv5_5/dw"
  top: "conv5_5/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_5/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_5/sep"
  top: "conv5_5/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_5/sep/scale"
  type: "Scale"
  bottom: "conv5_5/sep"
  top: "conv5_5/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_5/sep"
  type: "ReLU"
  bottom: "conv5_5/sep"
  top: "conv5_5/sep"
}
layer {
  name: "conv5_6/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_5/sep"
  top: "conv5_6/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_6/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_6/dw"
  top: "conv5_6/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_6/dw/scale"
  type: "Scale"
  bottom: "conv5_6/dw"
  top: "conv5_6/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_6/dw"
  type: "ReLU"
  bottom: "conv5_6/dw"
  top: "conv5_6/dw"
}
layer {
  name: "conv5_6/sep"
  type: "CConvolution"
  bottom: "conv5_6/dw"
  top: "conv5_6/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_6/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_6/sep"
  top: "conv5_6/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv5_6/sep/scale"
  type: "Scale"
  bottom: "conv5_6/sep"
  top: "conv5_6/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_6/sep"
  type: "ReLU"
  bottom: "conv5_6/sep"
  top: "conv5_6/sep"
}
layer {
  name: "conv6/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_6/sep"
  top: "conv6/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 1024
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv6/dw/bn"
  type: "BatchNorm"
  bottom: "conv6/dw"
  top: "conv6/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv6/dw/scale"
  type: "Scale"
  bottom: "conv6/dw"
  top: "conv6/dw"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu6/dw"
  type: "ReLU"
  bottom: "conv6/dw"
  top: "conv6/dw"
}
layer {
  name: "conv6/sep"
  type: "CConvolution"
  bottom: "conv6/dw"
  top: "conv6/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv6/sep/bn"
  type: "BatchNorm"
  bottom: "conv6/sep"
  top: "conv6/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv6/sep/scale"
  type: "Scale"
  bottom: "conv6/sep"
  top: "conv6/sep"
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu6/sep"
  type: "ReLU"
  bottom: "conv6/sep"
  top: "conv6/sep"
}
layer {
  name: "pool6"
  type: "Pooling"
  bottom: "conv6/sep"
  top: "pool6"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc7_oxford"
  type: "CConvolution"
  bottom: "pool6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 102
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc7"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc7"
  bottom: "label"
  top: "loss"
}
I0621 10:18:08.114640 17579 layer_factory.hpp:77] Creating layer data
I0621 10:18:08.114673 17579 net.cpp:84] Creating Layer data
I0621 10:18:08.114686 17579 net.cpp:380] data -> data
I0621 10:18:08.114703 17579 net.cpp:380] data -> label
I0621 10:18:08.114719 17579 data_transformer.cpp:25] Loading mean file from: /home/xingzhaolong/caffe_project/caffe/models/caffe-oxford102/imagenet_mean.binaryproto
I0621 10:18:08.118320 17579 image_data_layer.cpp:38] Opening file /home/xingzhaolong/caffe_project/caffe/models/caffe-oxford102/train.txt
I0621 10:18:08.118741 17579 image_data_layer.cpp:63] A total of 1020 images.
I0621 10:18:08.125250 17579 image_data_layer.cpp:90] output data size: 10,3,224,224
I0621 10:18:08.152518 17579 net.cpp:122] Setting up data
I0621 10:18:08.152557 17579 net.cpp:129] Top shape: 10 3 224 224 (1505280)
I0621 10:18:08.152571 17579 net.cpp:129] Top shape: 10 (10)
I0621 10:18:08.152580 17579 net.cpp:137] Memory required for data: 6021160
I0621 10:18:08.152591 17579 layer_factory.hpp:77] Creating layer label_data_1_split
I0621 10:18:08.152619 17579 net.cpp:84] Creating Layer label_data_1_split
I0621 10:18:08.152631 17579 net.cpp:406] label_data_1_split <- label
I0621 10:18:08.152647 17579 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0621 10:18:08.152667 17579 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0621 10:18:08.152752 17579 net.cpp:122] Setting up label_data_1_split
I0621 10:18:08.152770 17579 net.cpp:129] Top shape: 10 (10)
I0621 10:18:08.152781 17579 net.cpp:129] Top shape: 10 (10)
I0621 10:18:08.152788 17579 net.cpp:137] Memory required for data: 6021240
I0621 10:18:08.152797 17579 layer_factory.hpp:77] Creating layer conv1
I0621 10:18:08.152822 17579 net.cpp:84] Creating Layer conv1
I0621 10:18:08.152845 17579 net.cpp:406] conv1 <- data
I0621 10:18:08.152859 17579 net.cpp:380] conv1 -> conv1
I0621 10:18:08.158243 17579 net.cpp:122] Setting up conv1
I0621 10:18:08.158270 17579 net.cpp:129] Top shape: 10 32 112 112 (4014080)
I0621 10:18:08.158279 17579 net.cpp:137] Memory required for data: 22077560
I0621 10:18:08.158295 17579 layer_factory.hpp:77] Creating layer conv1/bn
I0621 10:18:08.158310 17579 net.cpp:84] Creating Layer conv1/bn
I0621 10:18:08.158320 17579 net.cpp:406] conv1/bn <- conv1
I0621 10:18:08.158331 17579 net.cpp:367] conv1/bn -> conv1 (in-place)
I0621 10:18:08.158625 17579 net.cpp:122] Setting up conv1/bn
I0621 10:18:08.158644 17579 net.cpp:129] Top shape: 10 32 112 112 (4014080)
I0621 10:18:08.158653 17579 net.cpp:137] Memory required for data: 38133880
I0621 10:18:08.158673 17579 layer_factory.hpp:77] Creating layer conv1/scale
I0621 10:18:08.158689 17579 net.cpp:84] Creating Layer conv1/scale
I0621 10:18:08.158699 17579 net.cpp:406] conv1/scale <- conv1
I0621 10:18:08.158710 17579 net.cpp:367] conv1/scale -> conv1 (in-place)
I0621 10:18:08.158774 17579 layer_factory.hpp:77] Creating layer conv1/scale
I0621 10:18:08.158959 17579 net.cpp:122] Setting up conv1/scale
I0621 10:18:08.158977 17579 net.cpp:129] Top shape: 10 32 112 112 (4014080)
I0621 10:18:08.158985 17579 net.cpp:137] Memory required for data: 54190200
I0621 10:18:08.159001 17579 layer_factory.hpp:77] Creating layer relu1
I0621 10:18:08.159015 17579 net.cpp:84] Creating Layer relu1
I0621 10:18:08.159024 17579 net.cpp:406] relu1 <- conv1
I0621 10:18:08.159035 17579 net.cpp:367] relu1 -> conv1 (in-place)
I0621 10:18:08.160029 17579 net.cpp:122] Setting up relu1
I0621 10:18:08.160051 17579 net.cpp:129] Top shape: 10 32 112 112 (4014080)
I0621 10:18:08.160060 17579 net.cpp:137] Memory required for data: 70246520
I0621 10:18:08.160092 17579 layer_factory.hpp:77] Creating layer conv2_1/dw
I0621 10:18:08.160109 17579 net.cpp:84] Creating Layer conv2_1/dw
I0621 10:18:08.160118 17579 net.cpp:406] conv2_1/dw <- conv1
I0621 10:18:08.160131 17579 net.cpp:380] conv2_1/dw -> conv2_1/dw
I0621 10:18:08.160403 17579 net.cpp:122] Setting up conv2_1/dw
I0621 10:18:08.160423 17579 net.cpp:129] Top shape: 10 32 112 112 (4014080)
I0621 10:18:08.160431 17579 net.cpp:137] Memory required for data: 86302840
I0621 10:18:08.160442 17579 layer_factory.hpp:77] Creating layer conv2_1/dw/bn
I0621 10:18:08.160456 17579 net.cpp:84] Creating Layer conv2_1/dw/bn
I0621 10:18:08.160465 17579 net.cpp:406] conv2_1/dw/bn <- conv2_1/dw
I0621 10:18:08.160476 17579 net.cpp:367] conv2_1/dw/bn -> conv2_1/dw (in-place)
I0621 10:18:08.162554 17579 net.cpp:122] Setting up conv2_1/dw/bn
I0621 10:18:08.162580 17579 net.cpp:129] Top shape: 10 32 112 112 (4014080)
I0621 10:18:08.162588 17579 net.cpp:137] Memory required for data: 102359160
I0621 10:18:08.162607 17579 layer_factory.hpp:77] Creating layer conv2_1/dw/scale
I0621 10:18:08.162622 17579 net.cpp:84] Creating Layer conv2_1/dw/scale
I0621 10:18:08.162632 17579 net.cpp:406] conv2_1/dw/scale <- conv2_1/dw
I0621 10:18:08.162644 17579 net.cpp:367] conv2_1/dw/scale -> conv2_1/dw (in-place)
I0621 10:18:08.162709 17579 layer_factory.hpp:77] Creating layer conv2_1/dw/scale
I0621 10:18:08.162878 17579 net.cpp:122] Setting up conv2_1/dw/scale
I0621 10:18:08.162895 17579 net.cpp:129] Top shape: 10 32 112 112 (4014080)
I0621 10:18:08.162904 17579 net.cpp:137] Memory required for data: 118415480
I0621 10:18:08.162916 17579 layer_factory.hpp:77] Creating layer relu2_1/dw
I0621 10:18:08.162928 17579 net.cpp:84] Creating Layer relu2_1/dw
I0621 10:18:08.162937 17579 net.cpp:406] relu2_1/dw <- conv2_1/dw
I0621 10:18:08.162948 17579 net.cpp:367] relu2_1/dw -> conv2_1/dw (in-place)
I0621 10:18:08.163457 17579 net.cpp:122] Setting up relu2_1/dw
I0621 10:18:08.163480 17579 net.cpp:129] Top shape: 10 32 112 112 (4014080)
I0621 10:18:08.163488 17579 net.cpp:137] Memory required for data: 134471800
I0621 10:18:08.163496 17579 layer_factory.hpp:77] Creating layer conv2_1/sep
I0621 10:18:08.163512 17579 net.cpp:84] Creating Layer conv2_1/sep
I0621 10:18:08.163540 17579 net.cpp:406] conv2_1/sep <- conv2_1/dw
I0621 10:18:08.163555 17579 net.cpp:380] conv2_1/sep -> conv2_1/sep
I0621 10:18:08.163907 17579 net.cpp:122] Setting up conv2_1/sep
I0621 10:18:08.163924 17579 net.cpp:129] Top shape: 10 64 112 112 (8028160)
I0621 10:18:08.163933 17579 net.cpp:137] Memory required for data: 166584440
I0621 10:18:08.163945 17579 layer_factory.hpp:77] Creating layer conv2_1/sep/bn
I0621 10:18:08.163959 17579 net.cpp:84] Creating Layer conv2_1/sep/bn
I0621 10:18:08.163969 17579 net.cpp:406] conv2_1/sep/bn <- conv2_1/sep
I0621 10:18:08.163980 17579 net.cpp:367] conv2_1/sep/bn -> conv2_1/sep (in-place)
I0621 10:18:08.164242 17579 net.cpp:122] Setting up conv2_1/sep/bn
I0621 10:18:08.164258 17579 net.cpp:129] Top shape: 10 64 112 112 (8028160)
I0621 10:18:08.164266 17579 net.cpp:137] Memory required for data: 198697080
I0621 10:18:08.164285 17579 layer_factory.hpp:77] Creating layer conv2_1/sep/scale
I0621 10:18:08.164299 17579 net.cpp:84] Creating Layer conv2_1/sep/scale
I0621 10:18:08.164309 17579 net.cpp:406] conv2_1/sep/scale <- conv2_1/sep
I0621 10:18:08.164319 17579 net.cpp:367] conv2_1/sep/scale -> conv2_1/sep (in-place)
I0621 10:18:08.164381 17579 layer_factory.hpp:77] Creating layer conv2_1/sep/scale
I0621 10:18:08.164562 17579 net.cpp:122] Setting up conv2_1/sep/scale
I0621 10:18:08.164582 17579 net.cpp:129] Top shape: 10 64 112 112 (8028160)
I0621 10:18:08.164589 17579 net.cpp:137] Memory required for data: 230809720
I0621 10:18:08.164602 17579 layer_factory.hpp:77] Creating layer relu2_1/sep
I0621 10:18:08.164614 17579 net.cpp:84] Creating Layer relu2_1/sep
I0621 10:18:08.164623 17579 net.cpp:406] relu2_1/sep <- conv2_1/sep
I0621 10:18:08.164634 17579 net.cpp:367] relu2_1/sep -> conv2_1/sep (in-place)
I0621 10:18:08.164851 17579 net.cpp:122] Setting up relu2_1/sep
I0621 10:18:08.164883 17579 net.cpp:129] Top shape: 10 64 112 112 (8028160)
I0621 10:18:08.164892 17579 net.cpp:137] Memory required for data: 262922360
I0621 10:18:08.164901 17579 layer_factory.hpp:77] Creating layer conv2_2/dw
I0621 10:18:08.164916 17579 net.cpp:84] Creating Layer conv2_2/dw
I0621 10:18:08.164924 17579 net.cpp:406] conv2_2/dw <- conv2_1/sep
I0621 10:18:08.164937 17579 net.cpp:380] conv2_2/dw -> conv2_2/dw
I0621 10:18:08.165926 17579 net.cpp:122] Setting up conv2_2/dw
I0621 10:18:08.165949 17579 net.cpp:129] Top shape: 10 64 56 56 (2007040)
I0621 10:18:08.165958 17579 net.cpp:137] Memory required for data: 270950520
I0621 10:18:08.165969 17579 layer_factory.hpp:77] Creating layer conv2_2/dw/bn
I0621 10:18:08.165984 17579 net.cpp:84] Creating Layer conv2_2/dw/bn
I0621 10:18:08.165993 17579 net.cpp:406] conv2_2/dw/bn <- conv2_2/dw
I0621 10:18:08.166005 17579 net.cpp:367] conv2_2/dw/bn -> conv2_2/dw (in-place)
I0621 10:18:08.166275 17579 net.cpp:122] Setting up conv2_2/dw/bn
I0621 10:18:08.166292 17579 net.cpp:129] Top shape: 10 64 56 56 (2007040)
I0621 10:18:08.166301 17579 net.cpp:137] Memory required for data: 278978680
I0621 10:18:08.166314 17579 layer_factory.hpp:77] Creating layer conv2_2/dw/scale
I0621 10:18:08.166332 17579 net.cpp:84] Creating Layer conv2_2/dw/scale
I0621 10:18:08.166340 17579 net.cpp:406] conv2_2/dw/scale <- conv2_2/dw
I0621 10:18:08.166352 17579 net.cpp:367] conv2_2/dw/scale -> conv2_2/dw (in-place)
I0621 10:18:08.166415 17579 layer_factory.hpp:77] Creating layer conv2_2/dw/scale
I0621 10:18:08.166600 17579 net.cpp:122] Setting up conv2_2/dw/scale
I0621 10:18:08.166620 17579 net.cpp:129] Top shape: 10 64 56 56 (2007040)
I0621 10:18:08.166628 17579 net.cpp:137] Memory required for data: 287006840
I0621 10:18:08.166640 17579 layer_factory.hpp:77] Creating layer relu2_2/dw
I0621 10:18:08.166653 17579 net.cpp:84] Creating Layer relu2_2/dw
I0621 10:18:08.166662 17579 net.cpp:406] relu2_2/dw <- conv2_2/dw
I0621 10:18:08.166673 17579 net.cpp:367] relu2_2/dw -> conv2_2/dw (in-place)
I0621 10:18:08.167189 17579 net.cpp:122] Setting up relu2_2/dw
I0621 10:18:08.167212 17579 net.cpp:129] Top shape: 10 64 56 56 (2007040)
I0621 10:18:08.167220 17579 net.cpp:137] Memory required for data: 295035000
I0621 10:18:08.167239 17579 layer_factory.hpp:77] Creating layer conv2_2/sep
I0621 10:18:08.167255 17579 net.cpp:84] Creating Layer conv2_2/sep
I0621 10:18:08.167265 17579 net.cpp:406] conv2_2/sep <- conv2_2/dw
I0621 10:18:08.167279 17579 net.cpp:380] conv2_2/sep -> conv2_2/sep
I0621 10:18:08.167723 17579 net.cpp:122] Setting up conv2_2/sep
I0621 10:18:08.167744 17579 net.cpp:129] Top shape: 10 128 56 56 (4014080)
I0621 10:18:08.167753 17579 net.cpp:137] Memory required for data: 311091320
I0621 10:18:08.167767 17579 layer_factory.hpp:77] Creating layer conv2_2/sep/bn
I0621 10:18:08.167779 17579 net.cpp:84] Creating Layer conv2_2/sep/bn
I0621 10:18:08.167789 17579 net.cpp:406] conv2_2/sep/bn <- conv2_2/sep
I0621 10:18:08.167800 17579 net.cpp:367] conv2_2/sep/bn -> conv2_2/sep (in-place)
I0621 10:18:08.168057 17579 net.cpp:122] Setting up conv2_2/sep/bn
I0621 10:18:08.168074 17579 net.cpp:129] Top shape: 10 128 56 56 (4014080)
I0621 10:18:08.168082 17579 net.cpp:137] Memory required for data: 327147640
I0621 10:18:08.168097 17579 layer_factory.hpp:77] Creating layer conv2_2/sep/scale
I0621 10:18:08.168110 17579 net.cpp:84] Creating Layer conv2_2/sep/scale
I0621 10:18:08.168119 17579 net.cpp:406] conv2_2/sep/scale <- conv2_2/sep
I0621 10:18:08.168130 17579 net.cpp:367] conv2_2/sep/scale -> conv2_2/sep (in-place)
I0621 10:18:08.168190 17579 layer_factory.hpp:77] Creating layer conv2_2/sep/scale
I0621 10:18:08.168352 17579 net.cpp:122] Setting up conv2_2/sep/scale
I0621 10:18:08.168370 17579 net.cpp:129] Top shape: 10 128 56 56 (4014080)
I0621 10:18:08.168378 17579 net.cpp:137] Memory required for data: 343203960
I0621 10:18:08.168390 17579 layer_factory.hpp:77] Creating layer relu2_2/sep
I0621 10:18:08.168403 17579 net.cpp:84] Creating Layer relu2_2/sep
I0621 10:18:08.168423 17579 net.cpp:406] relu2_2/sep <- conv2_2/sep
I0621 10:18:08.168437 17579 net.cpp:367] relu2_2/sep -> conv2_2/sep (in-place)
I0621 10:18:08.168669 17579 net.cpp:122] Setting up relu2_2/sep
I0621 10:18:08.168689 17579 net.cpp:129] Top shape: 10 128 56 56 (4014080)
I0621 10:18:08.168699 17579 net.cpp:137] Memory required for data: 359260280
I0621 10:18:08.168707 17579 layer_factory.hpp:77] Creating layer conv3_1/dw
I0621 10:18:08.168722 17579 net.cpp:84] Creating Layer conv3_1/dw
I0621 10:18:08.168731 17579 net.cpp:406] conv3_1/dw <- conv2_2/sep
I0621 10:18:08.168745 17579 net.cpp:380] conv3_1/dw -> conv3_1/dw
I0621 10:18:08.168922 17579 net.cpp:122] Setting up conv3_1/dw
I0621 10:18:08.168941 17579 net.cpp:129] Top shape: 10 128 56 56 (4014080)
I0621 10:18:08.168949 17579 net.cpp:137] Memory required for data: 375316600
I0621 10:18:08.168967 17579 layer_factory.hpp:77] Creating layer conv3_1/dw/bn
I0621 10:18:08.168982 17579 net.cpp:84] Creating Layer conv3_1/dw/bn
I0621 10:18:08.168990 17579 net.cpp:406] conv3_1/dw/bn <- conv3_1/dw
I0621 10:18:08.169003 17579 net.cpp:367] conv3_1/dw/bn -> conv3_1/dw (in-place)
I0621 10:18:08.169255 17579 net.cpp:122] Setting up conv3_1/dw/bn
I0621 10:18:08.169271 17579 net.cpp:129] Top shape: 10 128 56 56 (4014080)
I0621 10:18:08.169279 17579 net.cpp:137] Memory required for data: 391372920
I0621 10:18:08.169294 17579 layer_factory.hpp:77] Creating layer conv3_1/dw/scale
I0621 10:18:08.169307 17579 net.cpp:84] Creating Layer conv3_1/dw/scale
I0621 10:18:08.169317 17579 net.cpp:406] conv3_1/dw/scale <- conv3_1/dw
I0621 10:18:08.169328 17579 net.cpp:367] conv3_1/dw/scale -> conv3_1/dw (in-place)
I0621 10:18:08.169387 17579 layer_factory.hpp:77] Creating layer conv3_1/dw/scale
I0621 10:18:08.169567 17579 net.cpp:122] Setting up conv3_1/dw/scale
I0621 10:18:08.169586 17579 net.cpp:129] Top shape: 10 128 56 56 (4014080)
I0621 10:18:08.169595 17579 net.cpp:137] Memory required for data: 407429240
I0621 10:18:08.169607 17579 layer_factory.hpp:77] Creating layer relu3_1/dw
I0621 10:18:08.169620 17579 net.cpp:84] Creating Layer relu3_1/dw
I0621 10:18:08.169628 17579 net.cpp:406] relu3_1/dw <- conv3_1/dw
I0621 10:18:08.169639 17579 net.cpp:367] relu3_1/dw -> conv3_1/dw (in-place)
I0621 10:18:08.170166 17579 net.cpp:122] Setting up relu3_1/dw
I0621 10:18:08.170186 17579 net.cpp:129] Top shape: 10 128 56 56 (4014080)
I0621 10:18:08.170195 17579 net.cpp:137] Memory required for data: 423485560
I0621 10:18:08.170204 17579 layer_factory.hpp:77] Creating layer conv3_1/sep
I0621 10:18:08.170219 17579 net.cpp:84] Creating Layer conv3_1/sep
I0621 10:18:08.170229 17579 net.cpp:406] conv3_1/sep <- conv3_1/dw
I0621 10:18:08.170243 17579 net.cpp:380] conv3_1/sep -> conv3_1/sep
I0621 10:18:08.170810 17579 net.cpp:122] Setting up conv3_1/sep
I0621 10:18:08.170831 17579 net.cpp:129] Top shape: 10 128 56 56 (4014080)
I0621 10:18:08.170840 17579 net.cpp:137] Memory required for data: 439541880
I0621 10:18:08.170852 17579 layer_factory.hpp:77] Creating layer conv3_1/sep/bn
I0621 10:18:08.170866 17579 net.cpp:84] Creating Layer conv3_1/sep/bn
I0621 10:18:08.170876 17579 net.cpp:406] conv3_1/sep/bn <- conv3_1/sep
I0621 10:18:08.170887 17579 net.cpp:367] conv3_1/sep/bn -> conv3_1/sep (in-place)
I0621 10:18:08.171144 17579 net.cpp:122] Setting up conv3_1/sep/bn
I0621 10:18:08.171161 17579 net.cpp:129] Top shape: 10 128 56 56 (4014080)
I0621 10:18:08.171170 17579 net.cpp:137] Memory required for data: 455598200
I0621 10:18:08.171185 17579 layer_factory.hpp:77] Creating layer conv3_1/sep/scale
I0621 10:18:08.171198 17579 net.cpp:84] Creating Layer conv3_1/sep/scale
I0621 10:18:08.171207 17579 net.cpp:406] conv3_1/sep/scale <- conv3_1/sep
I0621 10:18:08.171219 17579 net.cpp:367] conv3_1/sep/scale -> conv3_1/sep (in-place)
I0621 10:18:08.171279 17579 layer_factory.hpp:77] Creating layer conv3_1/sep/scale
I0621 10:18:08.171440 17579 net.cpp:122] Setting up conv3_1/sep/scale
I0621 10:18:08.171458 17579 net.cpp:129] Top shape: 10 128 56 56 (4014080)
I0621 10:18:08.171466 17579 net.cpp:137] Memory required for data: 471654520
I0621 10:18:08.171490 17579 layer_factory.hpp:77] Creating layer relu3_1/sep
I0621 10:18:08.171504 17579 net.cpp:84] Creating Layer relu3_1/sep
I0621 10:18:08.171520 17579 net.cpp:406] relu3_1/sep <- conv3_1/sep
I0621 10:18:08.171533 17579 net.cpp:367] relu3_1/sep -> conv3_1/sep (in-place)
I0621 10:18:08.171756 17579 net.cpp:122] Setting up relu3_1/sep
I0621 10:18:08.171775 17579 net.cpp:129] Top shape: 10 128 56 56 (4014080)
I0621 10:18:08.171784 17579 net.cpp:137] Memory required for data: 487710840
I0621 10:18:08.171793 17579 layer_factory.hpp:77] Creating layer conv3_2/dw
I0621 10:18:08.171808 17579 net.cpp:84] Creating Layer conv3_2/dw
I0621 10:18:08.171818 17579 net.cpp:406] conv3_2/dw <- conv3_1/sep
I0621 10:18:08.171830 17579 net.cpp:380] conv3_2/dw -> conv3_2/dw
I0621 10:18:08.171989 17579 net.cpp:122] Setting up conv3_2/dw
I0621 10:18:08.172006 17579 net.cpp:129] Top shape: 10 128 28 28 (1003520)
I0621 10:18:08.172014 17579 net.cpp:137] Memory required for data: 491724920
I0621 10:18:08.172025 17579 layer_factory.hpp:77] Creating layer conv3_2/dw/bn
I0621 10:18:08.172039 17579 net.cpp:84] Creating Layer conv3_2/dw/bn
I0621 10:18:08.172049 17579 net.cpp:406] conv3_2/dw/bn <- conv3_2/dw
I0621 10:18:08.172060 17579 net.cpp:367] conv3_2/dw/bn -> conv3_2/dw (in-place)
I0621 10:18:08.172318 17579 net.cpp:122] Setting up conv3_2/dw/bn
I0621 10:18:08.172335 17579 net.cpp:129] Top shape: 10 128 28 28 (1003520)
I0621 10:18:08.172343 17579 net.cpp:137] Memory required for data: 495739000
I0621 10:18:08.172358 17579 layer_factory.hpp:77] Creating layer conv3_2/dw/scale
I0621 10:18:08.172375 17579 net.cpp:84] Creating Layer conv3_2/dw/scale
I0621 10:18:08.172384 17579 net.cpp:406] conv3_2/dw/scale <- conv3_2/dw
I0621 10:18:08.172396 17579 net.cpp:367] conv3_2/dw/scale -> conv3_2/dw (in-place)
I0621 10:18:08.172456 17579 layer_factory.hpp:77] Creating layer conv3_2/dw/scale
I0621 10:18:08.172627 17579 net.cpp:122] Setting up conv3_2/dw/scale
I0621 10:18:08.172646 17579 net.cpp:129] Top shape: 10 128 28 28 (1003520)
I0621 10:18:08.172655 17579 net.cpp:137] Memory required for data: 499753080
I0621 10:18:08.172667 17579 layer_factory.hpp:77] Creating layer relu3_2/dw
I0621 10:18:08.172680 17579 net.cpp:84] Creating Layer relu3_2/dw
I0621 10:18:08.172696 17579 net.cpp:406] relu3_2/dw <- conv3_2/dw
I0621 10:18:08.172708 17579 net.cpp:367] relu3_2/dw -> conv3_2/dw (in-place)
I0621 10:18:08.173228 17579 net.cpp:122] Setting up relu3_2/dw
I0621 10:18:08.173249 17579 net.cpp:129] Top shape: 10 128 28 28 (1003520)
I0621 10:18:08.173259 17579 net.cpp:137] Memory required for data: 503767160
I0621 10:18:08.173267 17579 layer_factory.hpp:77] Creating layer conv3_2/sep
I0621 10:18:08.173283 17579 net.cpp:84] Creating Layer conv3_2/sep
I0621 10:18:08.173292 17579 net.cpp:406] conv3_2/sep <- conv3_2/dw
I0621 10:18:08.173306 17579 net.cpp:380] conv3_2/sep -> conv3_2/sep
I0621 10:18:08.174120 17579 net.cpp:122] Setting up conv3_2/sep
I0621 10:18:08.174141 17579 net.cpp:129] Top shape: 10 256 28 28 (2007040)
I0621 10:18:08.174149 17579 net.cpp:137] Memory required for data: 511795320
I0621 10:18:08.174162 17579 layer_factory.hpp:77] Creating layer conv3_2/sep/bn
I0621 10:18:08.174176 17579 net.cpp:84] Creating Layer conv3_2/sep/bn
I0621 10:18:08.174185 17579 net.cpp:406] conv3_2/sep/bn <- conv3_2/sep
I0621 10:18:08.174197 17579 net.cpp:367] conv3_2/sep/bn -> conv3_2/sep (in-place)
I0621 10:18:08.174449 17579 net.cpp:122] Setting up conv3_2/sep/bn
I0621 10:18:08.174466 17579 net.cpp:129] Top shape: 10 256 28 28 (2007040)
I0621 10:18:08.174474 17579 net.cpp:137] Memory required for data: 519823480
I0621 10:18:08.174489 17579 layer_factory.hpp:77] Creating layer conv3_2/sep/scale
I0621 10:18:08.174504 17579 net.cpp:84] Creating Layer conv3_2/sep/scale
I0621 10:18:08.174512 17579 net.cpp:406] conv3_2/sep/scale <- conv3_2/sep
I0621 10:18:08.174532 17579 net.cpp:367] conv3_2/sep/scale -> conv3_2/sep (in-place)
I0621 10:18:08.174594 17579 layer_factory.hpp:77] Creating layer conv3_2/sep/scale
I0621 10:18:08.174753 17579 net.cpp:122] Setting up conv3_2/sep/scale
I0621 10:18:08.174782 17579 net.cpp:129] Top shape: 10 256 28 28 (2007040)
I0621 10:18:08.174792 17579 net.cpp:137] Memory required for data: 527851640
I0621 10:18:08.174804 17579 layer_factory.hpp:77] Creating layer relu3_2/sep
I0621 10:18:08.174818 17579 net.cpp:84] Creating Layer relu3_2/sep
I0621 10:18:08.174826 17579 net.cpp:406] relu3_2/sep <- conv3_2/sep
I0621 10:18:08.174837 17579 net.cpp:367] relu3_2/sep -> conv3_2/sep (in-place)
I0621 10:18:08.175062 17579 net.cpp:122] Setting up relu3_2/sep
I0621 10:18:08.175081 17579 net.cpp:129] Top shape: 10 256 28 28 (2007040)
I0621 10:18:08.175089 17579 net.cpp:137] Memory required for data: 535879800
I0621 10:18:08.175097 17579 layer_factory.hpp:77] Creating layer conv4_1/dw
I0621 10:18:08.175113 17579 net.cpp:84] Creating Layer conv4_1/dw
I0621 10:18:08.175122 17579 net.cpp:406] conv4_1/dw <- conv3_2/sep
I0621 10:18:08.175135 17579 net.cpp:380] conv4_1/dw -> conv4_1/dw
I0621 10:18:08.175312 17579 net.cpp:122] Setting up conv4_1/dw
I0621 10:18:08.175330 17579 net.cpp:129] Top shape: 10 256 28 28 (2007040)
I0621 10:18:08.175338 17579 net.cpp:137] Memory required for data: 543907960
I0621 10:18:08.175349 17579 layer_factory.hpp:77] Creating layer conv4_1/dw/bn
I0621 10:18:08.175364 17579 net.cpp:84] Creating Layer conv4_1/dw/bn
I0621 10:18:08.175372 17579 net.cpp:406] conv4_1/dw/bn <- conv4_1/dw
I0621 10:18:08.175384 17579 net.cpp:367] conv4_1/dw/bn -> conv4_1/dw (in-place)
I0621 10:18:08.175665 17579 net.cpp:122] Setting up conv4_1/dw/bn
I0621 10:18:08.175683 17579 net.cpp:129] Top shape: 10 256 28 28 (2007040)
I0621 10:18:08.175693 17579 net.cpp:137] Memory required for data: 551936120
I0621 10:18:08.175706 17579 layer_factory.hpp:77] Creating layer conv4_1/dw/scale
I0621 10:18:08.175720 17579 net.cpp:84] Creating Layer conv4_1/dw/scale
I0621 10:18:08.175729 17579 net.cpp:406] conv4_1/dw/scale <- conv4_1/dw
I0621 10:18:08.175740 17579 net.cpp:367] conv4_1/dw/scale -> conv4_1/dw (in-place)
I0621 10:18:08.175802 17579 layer_factory.hpp:77] Creating layer conv4_1/dw/scale
I0621 10:18:08.175961 17579 net.cpp:122] Setting up conv4_1/dw/scale
I0621 10:18:08.175978 17579 net.cpp:129] Top shape: 10 256 28 28 (2007040)
I0621 10:18:08.175987 17579 net.cpp:137] Memory required for data: 559964280
I0621 10:18:08.176008 17579 layer_factory.hpp:77] Creating layer relu4_1/dw
I0621 10:18:08.176021 17579 net.cpp:84] Creating Layer relu4_1/dw
I0621 10:18:08.176030 17579 net.cpp:406] relu4_1/dw <- conv4_1/dw
I0621 10:18:08.176041 17579 net.cpp:367] relu4_1/dw -> conv4_1/dw (in-place)
I0621 10:18:08.176571 17579 net.cpp:122] Setting up relu4_1/dw
I0621 10:18:08.176594 17579 net.cpp:129] Top shape: 10 256 28 28 (2007040)
I0621 10:18:08.176602 17579 net.cpp:137] Memory required for data: 567992440
I0621 10:18:08.176611 17579 layer_factory.hpp:77] Creating layer conv4_1/sep
I0621 10:18:08.176626 17579 net.cpp:84] Creating Layer conv4_1/sep
I0621 10:18:08.176636 17579 net.cpp:406] conv4_1/sep <- conv4_1/dw
I0621 10:18:08.176650 17579 net.cpp:380] conv4_1/sep -> conv4_1/sep
I0621 10:18:08.177953 17579 net.cpp:122] Setting up conv4_1/sep
I0621 10:18:08.177974 17579 net.cpp:129] Top shape: 10 256 28 28 (2007040)
I0621 10:18:08.177983 17579 net.cpp:137] Memory required for data: 576020600
I0621 10:18:08.178007 17579 layer_factory.hpp:77] Creating layer conv4_1/sep/bn
I0621 10:18:08.178021 17579 net.cpp:84] Creating Layer conv4_1/sep/bn
I0621 10:18:08.178031 17579 net.cpp:406] conv4_1/sep/bn <- conv4_1/sep
I0621 10:18:08.178043 17579 net.cpp:367] conv4_1/sep/bn -> conv4_1/sep (in-place)
I0621 10:18:08.178300 17579 net.cpp:122] Setting up conv4_1/sep/bn
I0621 10:18:08.178318 17579 net.cpp:129] Top shape: 10 256 28 28 (2007040)
I0621 10:18:08.178325 17579 net.cpp:137] Memory required for data: 584048760
I0621 10:18:08.178340 17579 layer_factory.hpp:77] Creating layer conv4_1/sep/scale
I0621 10:18:08.178354 17579 net.cpp:84] Creating Layer conv4_1/sep/scale
I0621 10:18:08.178364 17579 net.cpp:406] conv4_1/sep/scale <- conv4_1/sep
I0621 10:18:08.178375 17579 net.cpp:367] conv4_1/sep/scale -> conv4_1/sep (in-place)
I0621 10:18:08.178449 17579 layer_factory.hpp:77] Creating layer conv4_1/sep/scale
I0621 10:18:08.178622 17579 net.cpp:122] Setting up conv4_1/sep/scale
I0621 10:18:08.178642 17579 net.cpp:129] Top shape: 10 256 28 28 (2007040)
I0621 10:18:08.178650 17579 net.cpp:137] Memory required for data: 592076920
I0621 10:18:08.178663 17579 layer_factory.hpp:77] Creating layer relu4_1/sep
I0621 10:18:08.178674 17579 net.cpp:84] Creating Layer relu4_1/sep
I0621 10:18:08.178683 17579 net.cpp:406] relu4_1/sep <- conv4_1/sep
I0621 10:18:08.178694 17579 net.cpp:367] relu4_1/sep -> conv4_1/sep (in-place)
I0621 10:18:08.178920 17579 net.cpp:122] Setting up relu4_1/sep
I0621 10:18:08.178939 17579 net.cpp:129] Top shape: 10 256 28 28 (2007040)
I0621 10:18:08.178948 17579 net.cpp:137] Memory required for data: 600105080
I0621 10:18:08.178957 17579 layer_factory.hpp:77] Creating layer conv4_2/dw
I0621 10:18:08.178972 17579 net.cpp:84] Creating Layer conv4_2/dw
I0621 10:18:08.178982 17579 net.cpp:406] conv4_2/dw <- conv4_1/sep
I0621 10:18:08.178995 17579 net.cpp:380] conv4_2/dw -> conv4_2/dw
I0621 10:18:08.179162 17579 net.cpp:122] Setting up conv4_2/dw
I0621 10:18:08.179178 17579 net.cpp:129] Top shape: 10 256 14 14 (501760)
I0621 10:18:08.179188 17579 net.cpp:137] Memory required for data: 602112120
I0621 10:18:08.179198 17579 layer_factory.hpp:77] Creating layer conv4_2/dw/bn
I0621 10:18:08.179211 17579 net.cpp:84] Creating Layer conv4_2/dw/bn
I0621 10:18:08.179220 17579 net.cpp:406] conv4_2/dw/bn <- conv4_2/dw
I0621 10:18:08.179232 17579 net.cpp:367] conv4_2/dw/bn -> conv4_2/dw (in-place)
I0621 10:18:08.179491 17579 net.cpp:122] Setting up conv4_2/dw/bn
I0621 10:18:08.179508 17579 net.cpp:129] Top shape: 10 256 14 14 (501760)
I0621 10:18:08.179525 17579 net.cpp:137] Memory required for data: 604119160
I0621 10:18:08.179541 17579 layer_factory.hpp:77] Creating layer conv4_2/dw/scale
I0621 10:18:08.179555 17579 net.cpp:84] Creating Layer conv4_2/dw/scale
I0621 10:18:08.179564 17579 net.cpp:406] conv4_2/dw/scale <- conv4_2/dw
I0621 10:18:08.179576 17579 net.cpp:367] conv4_2/dw/scale -> conv4_2/dw (in-place)
I0621 10:18:08.179637 17579 layer_factory.hpp:77] Creating layer conv4_2/dw/scale
I0621 10:18:08.179791 17579 net.cpp:122] Setting up conv4_2/dw/scale
I0621 10:18:08.179816 17579 net.cpp:129] Top shape: 10 256 14 14 (501760)
I0621 10:18:08.179826 17579 net.cpp:137] Memory required for data: 606126200
I0621 10:18:08.179838 17579 layer_factory.hpp:77] Creating layer relu4_2/dw
I0621 10:18:08.179850 17579 net.cpp:84] Creating Layer relu4_2/dw
I0621 10:18:08.179859 17579 net.cpp:406] relu4_2/dw <- conv4_2/dw
I0621 10:18:08.179870 17579 net.cpp:367] relu4_2/dw -> conv4_2/dw (in-place)
I0621 10:18:08.180389 17579 net.cpp:122] Setting up relu4_2/dw
I0621 10:18:08.180410 17579 net.cpp:129] Top shape: 10 256 14 14 (501760)
I0621 10:18:08.180419 17579 net.cpp:137] Memory required for data: 608133240
I0621 10:18:08.180428 17579 layer_factory.hpp:77] Creating layer conv4_2/sep
I0621 10:18:08.180444 17579 net.cpp:84] Creating Layer conv4_2/sep
I0621 10:18:08.180454 17579 net.cpp:406] conv4_2/sep <- conv4_2/dw
I0621 10:18:08.180466 17579 net.cpp:380] conv4_2/sep -> conv4_2/sep
I0621 10:18:08.183444 17579 net.cpp:122] Setting up conv4_2/sep
I0621 10:18:08.183468 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.183477 17579 net.cpp:137] Memory required for data: 612147320
I0621 10:18:08.183490 17579 layer_factory.hpp:77] Creating layer conv4_2/sep/bn
I0621 10:18:08.183504 17579 net.cpp:84] Creating Layer conv4_2/sep/bn
I0621 10:18:08.183521 17579 net.cpp:406] conv4_2/sep/bn <- conv4_2/sep
I0621 10:18:08.183534 17579 net.cpp:367] conv4_2/sep/bn -> conv4_2/sep (in-place)
I0621 10:18:08.183806 17579 net.cpp:122] Setting up conv4_2/sep/bn
I0621 10:18:08.183823 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.183831 17579 net.cpp:137] Memory required for data: 616161400
I0621 10:18:08.183846 17579 layer_factory.hpp:77] Creating layer conv4_2/sep/scale
I0621 10:18:08.183859 17579 net.cpp:84] Creating Layer conv4_2/sep/scale
I0621 10:18:08.183881 17579 net.cpp:406] conv4_2/sep/scale <- conv4_2/sep
I0621 10:18:08.183893 17579 net.cpp:367] conv4_2/sep/scale -> conv4_2/sep (in-place)
I0621 10:18:08.183954 17579 layer_factory.hpp:77] Creating layer conv4_2/sep/scale
I0621 10:18:08.184121 17579 net.cpp:122] Setting up conv4_2/sep/scale
I0621 10:18:08.184139 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.184146 17579 net.cpp:137] Memory required for data: 620175480
I0621 10:18:08.184159 17579 layer_factory.hpp:77] Creating layer relu4_2/sep
I0621 10:18:08.184171 17579 net.cpp:84] Creating Layer relu4_2/sep
I0621 10:18:08.184180 17579 net.cpp:406] relu4_2/sep <- conv4_2/sep
I0621 10:18:08.184191 17579 net.cpp:367] relu4_2/sep -> conv4_2/sep (in-place)
I0621 10:18:08.184420 17579 net.cpp:122] Setting up relu4_2/sep
I0621 10:18:08.184439 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.184448 17579 net.cpp:137] Memory required for data: 624189560
I0621 10:18:08.184456 17579 layer_factory.hpp:77] Creating layer conv5_1/dw
I0621 10:18:08.184471 17579 net.cpp:84] Creating Layer conv5_1/dw
I0621 10:18:08.184481 17579 net.cpp:406] conv5_1/dw <- conv4_2/sep
I0621 10:18:08.184494 17579 net.cpp:380] conv5_1/dw -> conv5_1/dw
I0621 10:18:08.184721 17579 net.cpp:122] Setting up conv5_1/dw
I0621 10:18:08.184741 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.184749 17579 net.cpp:137] Memory required for data: 628203640
I0621 10:18:08.184761 17579 layer_factory.hpp:77] Creating layer conv5_1/dw/bn
I0621 10:18:08.184773 17579 net.cpp:84] Creating Layer conv5_1/dw/bn
I0621 10:18:08.184783 17579 net.cpp:406] conv5_1/dw/bn <- conv5_1/dw
I0621 10:18:08.184794 17579 net.cpp:367] conv5_1/dw/bn -> conv5_1/dw (in-place)
I0621 10:18:08.185058 17579 net.cpp:122] Setting up conv5_1/dw/bn
I0621 10:18:08.185075 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.185082 17579 net.cpp:137] Memory required for data: 632217720
I0621 10:18:08.185097 17579 layer_factory.hpp:77] Creating layer conv5_1/dw/scale
I0621 10:18:08.185111 17579 net.cpp:84] Creating Layer conv5_1/dw/scale
I0621 10:18:08.185119 17579 net.cpp:406] conv5_1/dw/scale <- conv5_1/dw
I0621 10:18:08.185132 17579 net.cpp:367] conv5_1/dw/scale -> conv5_1/dw (in-place)
I0621 10:18:08.185206 17579 layer_factory.hpp:77] Creating layer conv5_1/dw/scale
I0621 10:18:08.185377 17579 net.cpp:122] Setting up conv5_1/dw/scale
I0621 10:18:08.185395 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.185403 17579 net.cpp:137] Memory required for data: 636231800
I0621 10:18:08.185416 17579 layer_factory.hpp:77] Creating layer relu5_1/dw
I0621 10:18:08.185428 17579 net.cpp:84] Creating Layer relu5_1/dw
I0621 10:18:08.185437 17579 net.cpp:406] relu5_1/dw <- conv5_1/dw
I0621 10:18:08.185449 17579 net.cpp:367] relu5_1/dw -> conv5_1/dw (in-place)
I0621 10:18:08.185976 17579 net.cpp:122] Setting up relu5_1/dw
I0621 10:18:08.185998 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.186007 17579 net.cpp:137] Memory required for data: 640245880
I0621 10:18:08.186015 17579 layer_factory.hpp:77] Creating layer conv5_1/sep
I0621 10:18:08.186030 17579 net.cpp:84] Creating Layer conv5_1/sep
I0621 10:18:08.186039 17579 net.cpp:406] conv5_1/sep <- conv5_1/dw
I0621 10:18:08.186053 17579 net.cpp:380] conv5_1/sep -> conv5_1/sep
I0621 10:18:08.191736 17579 net.cpp:122] Setting up conv5_1/sep
I0621 10:18:08.191761 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.191771 17579 net.cpp:137] Memory required for data: 644259960
I0621 10:18:08.191783 17579 layer_factory.hpp:77] Creating layer conv5_1/sep/bn
I0621 10:18:08.191798 17579 net.cpp:84] Creating Layer conv5_1/sep/bn
I0621 10:18:08.191807 17579 net.cpp:406] conv5_1/sep/bn <- conv5_1/sep
I0621 10:18:08.191819 17579 net.cpp:367] conv5_1/sep/bn -> conv5_1/sep (in-place)
I0621 10:18:08.192090 17579 net.cpp:122] Setting up conv5_1/sep/bn
I0621 10:18:08.192107 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.192116 17579 net.cpp:137] Memory required for data: 648274040
I0621 10:18:08.192142 17579 layer_factory.hpp:77] Creating layer conv5_1/sep/scale
I0621 10:18:08.192157 17579 net.cpp:84] Creating Layer conv5_1/sep/scale
I0621 10:18:08.192167 17579 net.cpp:406] conv5_1/sep/scale <- conv5_1/sep
I0621 10:18:08.192178 17579 net.cpp:367] conv5_1/sep/scale -> conv5_1/sep (in-place)
I0621 10:18:08.192239 17579 layer_factory.hpp:77] Creating layer conv5_1/sep/scale
I0621 10:18:08.192409 17579 net.cpp:122] Setting up conv5_1/sep/scale
I0621 10:18:08.192425 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.192435 17579 net.cpp:137] Memory required for data: 652288120
I0621 10:18:08.192446 17579 layer_factory.hpp:77] Creating layer relu5_1/sep
I0621 10:18:08.192459 17579 net.cpp:84] Creating Layer relu5_1/sep
I0621 10:18:08.192468 17579 net.cpp:406] relu5_1/sep <- conv5_1/sep
I0621 10:18:08.192479 17579 net.cpp:367] relu5_1/sep -> conv5_1/sep (in-place)
I0621 10:18:08.192718 17579 net.cpp:122] Setting up relu5_1/sep
I0621 10:18:08.192739 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.192747 17579 net.cpp:137] Memory required for data: 656302200
I0621 10:18:08.192755 17579 layer_factory.hpp:77] Creating layer conv5_2/dw
I0621 10:18:08.192771 17579 net.cpp:84] Creating Layer conv5_2/dw
I0621 10:18:08.192780 17579 net.cpp:406] conv5_2/dw <- conv5_1/sep
I0621 10:18:08.192795 17579 net.cpp:380] conv5_2/dw -> conv5_2/dw
I0621 10:18:08.193012 17579 net.cpp:122] Setting up conv5_2/dw
I0621 10:18:08.193032 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.193040 17579 net.cpp:137] Memory required for data: 660316280
I0621 10:18:08.193051 17579 layer_factory.hpp:77] Creating layer conv5_2/dw/bn
I0621 10:18:08.193065 17579 net.cpp:84] Creating Layer conv5_2/dw/bn
I0621 10:18:08.193074 17579 net.cpp:406] conv5_2/dw/bn <- conv5_2/dw
I0621 10:18:08.193086 17579 net.cpp:367] conv5_2/dw/bn -> conv5_2/dw (in-place)
I0621 10:18:08.193358 17579 net.cpp:122] Setting up conv5_2/dw/bn
I0621 10:18:08.193375 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.193384 17579 net.cpp:137] Memory required for data: 664330360
I0621 10:18:08.193398 17579 layer_factory.hpp:77] Creating layer conv5_2/dw/scale
I0621 10:18:08.193429 17579 net.cpp:84] Creating Layer conv5_2/dw/scale
I0621 10:18:08.193440 17579 net.cpp:406] conv5_2/dw/scale <- conv5_2/dw
I0621 10:18:08.193452 17579 net.cpp:367] conv5_2/dw/scale -> conv5_2/dw (in-place)
I0621 10:18:08.193521 17579 layer_factory.hpp:77] Creating layer conv5_2/dw/scale
I0621 10:18:08.193691 17579 net.cpp:122] Setting up conv5_2/dw/scale
I0621 10:18:08.193708 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.193717 17579 net.cpp:137] Memory required for data: 668344440
I0621 10:18:08.193729 17579 layer_factory.hpp:77] Creating layer relu5_2/dw
I0621 10:18:08.193742 17579 net.cpp:84] Creating Layer relu5_2/dw
I0621 10:18:08.193752 17579 net.cpp:406] relu5_2/dw <- conv5_2/dw
I0621 10:18:08.193763 17579 net.cpp:367] relu5_2/dw -> conv5_2/dw (in-place)
I0621 10:18:08.194274 17579 net.cpp:122] Setting up relu5_2/dw
I0621 10:18:08.194296 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.194305 17579 net.cpp:137] Memory required for data: 672358520
I0621 10:18:08.194314 17579 layer_factory.hpp:77] Creating layer conv5_2/sep
I0621 10:18:08.194329 17579 net.cpp:84] Creating Layer conv5_2/sep
I0621 10:18:08.194339 17579 net.cpp:406] conv5_2/sep <- conv5_2/dw
I0621 10:18:08.194351 17579 net.cpp:380] conv5_2/sep -> conv5_2/sep
I0621 10:18:08.200090 17579 net.cpp:122] Setting up conv5_2/sep
I0621 10:18:08.200114 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.200124 17579 net.cpp:137] Memory required for data: 676372600
I0621 10:18:08.200137 17579 layer_factory.hpp:77] Creating layer conv5_2/sep/bn
I0621 10:18:08.200155 17579 net.cpp:84] Creating Layer conv5_2/sep/bn
I0621 10:18:08.200165 17579 net.cpp:406] conv5_2/sep/bn <- conv5_2/sep
I0621 10:18:08.200177 17579 net.cpp:367] conv5_2/sep/bn -> conv5_2/sep (in-place)
I0621 10:18:08.200472 17579 net.cpp:122] Setting up conv5_2/sep/bn
I0621 10:18:08.200490 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.200498 17579 net.cpp:137] Memory required for data: 680386680
I0621 10:18:08.200521 17579 layer_factory.hpp:77] Creating layer conv5_2/sep/scale
I0621 10:18:08.200541 17579 net.cpp:84] Creating Layer conv5_2/sep/scale
I0621 10:18:08.200551 17579 net.cpp:406] conv5_2/sep/scale <- conv5_2/sep
I0621 10:18:08.200563 17579 net.cpp:367] conv5_2/sep/scale -> conv5_2/sep (in-place)
I0621 10:18:08.200628 17579 layer_factory.hpp:77] Creating layer conv5_2/sep/scale
I0621 10:18:08.200814 17579 net.cpp:122] Setting up conv5_2/sep/scale
I0621 10:18:08.200831 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.200839 17579 net.cpp:137] Memory required for data: 684400760
I0621 10:18:08.200851 17579 layer_factory.hpp:77] Creating layer relu5_2/sep
I0621 10:18:08.200863 17579 net.cpp:84] Creating Layer relu5_2/sep
I0621 10:18:08.200872 17579 net.cpp:406] relu5_2/sep <- conv5_2/sep
I0621 10:18:08.200886 17579 net.cpp:367] relu5_2/sep -> conv5_2/sep (in-place)
I0621 10:18:08.201424 17579 net.cpp:122] Setting up relu5_2/sep
I0621 10:18:08.201445 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.201455 17579 net.cpp:137] Memory required for data: 688414840
I0621 10:18:08.201463 17579 layer_factory.hpp:77] Creating layer conv5_3/dw
I0621 10:18:08.201481 17579 net.cpp:84] Creating Layer conv5_3/dw
I0621 10:18:08.201493 17579 net.cpp:406] conv5_3/dw <- conv5_2/sep
I0621 10:18:08.201504 17579 net.cpp:380] conv5_3/dw -> conv5_3/dw
I0621 10:18:08.201736 17579 net.cpp:122] Setting up conv5_3/dw
I0621 10:18:08.201756 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.201764 17579 net.cpp:137] Memory required for data: 692428920
I0621 10:18:08.201776 17579 layer_factory.hpp:77] Creating layer conv5_3/dw/bn
I0621 10:18:08.201792 17579 net.cpp:84] Creating Layer conv5_3/dw/bn
I0621 10:18:08.201802 17579 net.cpp:406] conv5_3/dw/bn <- conv5_3/dw
I0621 10:18:08.201813 17579 net.cpp:367] conv5_3/dw/bn -> conv5_3/dw (in-place)
I0621 10:18:08.202100 17579 net.cpp:122] Setting up conv5_3/dw/bn
I0621 10:18:08.202118 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.202133 17579 net.cpp:137] Memory required for data: 696443000
I0621 10:18:08.202149 17579 layer_factory.hpp:77] Creating layer conv5_3/dw/scale
I0621 10:18:08.202165 17579 net.cpp:84] Creating Layer conv5_3/dw/scale
I0621 10:18:08.202175 17579 net.cpp:406] conv5_3/dw/scale <- conv5_3/dw
I0621 10:18:08.202186 17579 net.cpp:367] conv5_3/dw/scale -> conv5_3/dw (in-place)
I0621 10:18:08.202252 17579 layer_factory.hpp:77] Creating layer conv5_3/dw/scale
I0621 10:18:08.202437 17579 net.cpp:122] Setting up conv5_3/dw/scale
I0621 10:18:08.202455 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.202463 17579 net.cpp:137] Memory required for data: 700457080
I0621 10:18:08.202476 17579 layer_factory.hpp:77] Creating layer relu5_3/dw
I0621 10:18:08.202488 17579 net.cpp:84] Creating Layer relu5_3/dw
I0621 10:18:08.202497 17579 net.cpp:406] relu5_3/dw <- conv5_3/dw
I0621 10:18:08.202512 17579 net.cpp:367] relu5_3/dw -> conv5_3/dw (in-place)
I0621 10:18:08.202764 17579 net.cpp:122] Setting up relu5_3/dw
I0621 10:18:08.202782 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.202791 17579 net.cpp:137] Memory required for data: 704471160
I0621 10:18:08.202800 17579 layer_factory.hpp:77] Creating layer conv5_3/sep
I0621 10:18:08.202817 17579 net.cpp:84] Creating Layer conv5_3/sep
I0621 10:18:08.202827 17579 net.cpp:406] conv5_3/sep <- conv5_3/dw
I0621 10:18:08.202843 17579 net.cpp:380] conv5_3/sep -> conv5_3/sep
I0621 10:18:08.208570 17579 net.cpp:122] Setting up conv5_3/sep
I0621 10:18:08.208595 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.208603 17579 net.cpp:137] Memory required for data: 708485240
I0621 10:18:08.208617 17579 layer_factory.hpp:77] Creating layer conv5_3/sep/bn
I0621 10:18:08.208634 17579 net.cpp:84] Creating Layer conv5_3/sep/bn
I0621 10:18:08.208655 17579 net.cpp:406] conv5_3/sep/bn <- conv5_3/sep
I0621 10:18:08.208668 17579 net.cpp:367] conv5_3/sep/bn -> conv5_3/sep (in-place)
I0621 10:18:08.208961 17579 net.cpp:122] Setting up conv5_3/sep/bn
I0621 10:18:08.208978 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.208986 17579 net.cpp:137] Memory required for data: 712499320
I0621 10:18:08.209000 17579 layer_factory.hpp:77] Creating layer conv5_3/sep/scale
I0621 10:18:08.209019 17579 net.cpp:84] Creating Layer conv5_3/sep/scale
I0621 10:18:08.209030 17579 net.cpp:406] conv5_3/sep/scale <- conv5_3/sep
I0621 10:18:08.209043 17579 net.cpp:367] conv5_3/sep/scale -> conv5_3/sep (in-place)
I0621 10:18:08.209107 17579 layer_factory.hpp:77] Creating layer conv5_3/sep/scale
I0621 10:18:08.209298 17579 net.cpp:122] Setting up conv5_3/sep/scale
I0621 10:18:08.209316 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.209324 17579 net.cpp:137] Memory required for data: 716513400
I0621 10:18:08.209336 17579 layer_factory.hpp:77] Creating layer relu5_3/sep
I0621 10:18:08.209352 17579 net.cpp:84] Creating Layer relu5_3/sep
I0621 10:18:08.209362 17579 net.cpp:406] relu5_3/sep <- conv5_3/sep
I0621 10:18:08.209372 17579 net.cpp:367] relu5_3/sep -> conv5_3/sep (in-place)
I0621 10:18:08.209916 17579 net.cpp:122] Setting up relu5_3/sep
I0621 10:18:08.209939 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.209949 17579 net.cpp:137] Memory required for data: 720527480
I0621 10:18:08.209957 17579 layer_factory.hpp:77] Creating layer conv5_4/dw
I0621 10:18:08.209975 17579 net.cpp:84] Creating Layer conv5_4/dw
I0621 10:18:08.209985 17579 net.cpp:406] conv5_4/dw <- conv5_3/sep
I0621 10:18:08.210003 17579 net.cpp:380] conv5_4/dw -> conv5_4/dw
I0621 10:18:08.210225 17579 net.cpp:122] Setting up conv5_4/dw
I0621 10:18:08.210247 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.210255 17579 net.cpp:137] Memory required for data: 724541560
I0621 10:18:08.210268 17579 layer_factory.hpp:77] Creating layer conv5_4/dw/bn
I0621 10:18:08.210279 17579 net.cpp:84] Creating Layer conv5_4/dw/bn
I0621 10:18:08.210289 17579 net.cpp:406] conv5_4/dw/bn <- conv5_4/dw
I0621 10:18:08.210304 17579 net.cpp:367] conv5_4/dw/bn -> conv5_4/dw (in-place)
I0621 10:18:08.210609 17579 net.cpp:122] Setting up conv5_4/dw/bn
I0621 10:18:08.210628 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.210638 17579 net.cpp:137] Memory required for data: 728555640
I0621 10:18:08.210651 17579 layer_factory.hpp:77] Creating layer conv5_4/dw/scale
I0621 10:18:08.210664 17579 net.cpp:84] Creating Layer conv5_4/dw/scale
I0621 10:18:08.210675 17579 net.cpp:406] conv5_4/dw/scale <- conv5_4/dw
I0621 10:18:08.210685 17579 net.cpp:367] conv5_4/dw/scale -> conv5_4/dw (in-place)
I0621 10:18:08.210750 17579 layer_factory.hpp:77] Creating layer conv5_4/dw/scale
I0621 10:18:08.210937 17579 net.cpp:122] Setting up conv5_4/dw/scale
I0621 10:18:08.210954 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.210963 17579 net.cpp:137] Memory required for data: 732569720
I0621 10:18:08.211000 17579 layer_factory.hpp:77] Creating layer relu5_4/dw
I0621 10:18:08.211014 17579 net.cpp:84] Creating Layer relu5_4/dw
I0621 10:18:08.211024 17579 net.cpp:406] relu5_4/dw <- conv5_4/dw
I0621 10:18:08.211035 17579 net.cpp:367] relu5_4/dw -> conv5_4/dw (in-place)
I0621 10:18:08.211284 17579 net.cpp:122] Setting up relu5_4/dw
I0621 10:18:08.211304 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.211313 17579 net.cpp:137] Memory required for data: 736583800
I0621 10:18:08.211321 17579 layer_factory.hpp:77] Creating layer conv5_4/sep
I0621 10:18:08.211338 17579 net.cpp:84] Creating Layer conv5_4/sep
I0621 10:18:08.211349 17579 net.cpp:406] conv5_4/sep <- conv5_4/dw
I0621 10:18:08.211364 17579 net.cpp:380] conv5_4/sep -> conv5_4/sep
I0621 10:18:08.217051 17579 net.cpp:122] Setting up conv5_4/sep
I0621 10:18:08.217075 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.217084 17579 net.cpp:137] Memory required for data: 740597880
I0621 10:18:08.217109 17579 layer_factory.hpp:77] Creating layer conv5_4/sep/bn
I0621 10:18:08.217128 17579 net.cpp:84] Creating Layer conv5_4/sep/bn
I0621 10:18:08.217139 17579 net.cpp:406] conv5_4/sep/bn <- conv5_4/sep
I0621 10:18:08.217149 17579 net.cpp:367] conv5_4/sep/bn -> conv5_4/sep (in-place)
I0621 10:18:08.217448 17579 net.cpp:122] Setting up conv5_4/sep/bn
I0621 10:18:08.217466 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.217474 17579 net.cpp:137] Memory required for data: 744611960
I0621 10:18:08.217489 17579 layer_factory.hpp:77] Creating layer conv5_4/sep/scale
I0621 10:18:08.217507 17579 net.cpp:84] Creating Layer conv5_4/sep/scale
I0621 10:18:08.217525 17579 net.cpp:406] conv5_4/sep/scale <- conv5_4/sep
I0621 10:18:08.217540 17579 net.cpp:367] conv5_4/sep/scale -> conv5_4/sep (in-place)
I0621 10:18:08.217605 17579 layer_factory.hpp:77] Creating layer conv5_4/sep/scale
I0621 10:18:08.217788 17579 net.cpp:122] Setting up conv5_4/sep/scale
I0621 10:18:08.217806 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.217814 17579 net.cpp:137] Memory required for data: 748626040
I0621 10:18:08.217828 17579 layer_factory.hpp:77] Creating layer relu5_4/sep
I0621 10:18:08.217844 17579 net.cpp:84] Creating Layer relu5_4/sep
I0621 10:18:08.217852 17579 net.cpp:406] relu5_4/sep <- conv5_4/sep
I0621 10:18:08.217864 17579 net.cpp:367] relu5_4/sep -> conv5_4/sep (in-place)
I0621 10:18:08.218400 17579 net.cpp:122] Setting up relu5_4/sep
I0621 10:18:08.218421 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.218430 17579 net.cpp:137] Memory required for data: 752640120
I0621 10:18:08.218439 17579 layer_factory.hpp:77] Creating layer conv5_5/dw
I0621 10:18:08.218456 17579 net.cpp:84] Creating Layer conv5_5/dw
I0621 10:18:08.218467 17579 net.cpp:406] conv5_5/dw <- conv5_4/sep
I0621 10:18:08.218485 17579 net.cpp:380] conv5_5/dw -> conv5_5/dw
I0621 10:18:08.218720 17579 net.cpp:122] Setting up conv5_5/dw
I0621 10:18:08.218741 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.218750 17579 net.cpp:137] Memory required for data: 756654200
I0621 10:18:08.218760 17579 layer_factory.hpp:77] Creating layer conv5_5/dw/bn
I0621 10:18:08.218776 17579 net.cpp:84] Creating Layer conv5_5/dw/bn
I0621 10:18:08.218793 17579 net.cpp:406] conv5_5/dw/bn <- conv5_5/dw
I0621 10:18:08.218806 17579 net.cpp:367] conv5_5/dw/bn -> conv5_5/dw (in-place)
I0621 10:18:08.219099 17579 net.cpp:122] Setting up conv5_5/dw/bn
I0621 10:18:08.219115 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.219125 17579 net.cpp:137] Memory required for data: 760668280
I0621 10:18:08.219138 17579 layer_factory.hpp:77] Creating layer conv5_5/dw/scale
I0621 10:18:08.219151 17579 net.cpp:84] Creating Layer conv5_5/dw/scale
I0621 10:18:08.219161 17579 net.cpp:406] conv5_5/dw/scale <- conv5_5/dw
I0621 10:18:08.219172 17579 net.cpp:367] conv5_5/dw/scale -> conv5_5/dw (in-place)
I0621 10:18:08.219236 17579 layer_factory.hpp:77] Creating layer conv5_5/dw/scale
I0621 10:18:08.219424 17579 net.cpp:122] Setting up conv5_5/dw/scale
I0621 10:18:08.219441 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.219449 17579 net.cpp:137] Memory required for data: 764682360
I0621 10:18:08.219461 17579 layer_factory.hpp:77] Creating layer relu5_5/dw
I0621 10:18:08.219476 17579 net.cpp:84] Creating Layer relu5_5/dw
I0621 10:18:08.219486 17579 net.cpp:406] relu5_5/dw <- conv5_5/dw
I0621 10:18:08.219496 17579 net.cpp:367] relu5_5/dw -> conv5_5/dw (in-place)
I0621 10:18:08.219741 17579 net.cpp:122] Setting up relu5_5/dw
I0621 10:18:08.219761 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.219770 17579 net.cpp:137] Memory required for data: 768696440
I0621 10:18:08.219779 17579 layer_factory.hpp:77] Creating layer conv5_5/sep
I0621 10:18:08.219797 17579 net.cpp:84] Creating Layer conv5_5/sep
I0621 10:18:08.219808 17579 net.cpp:406] conv5_5/sep <- conv5_5/dw
I0621 10:18:08.219820 17579 net.cpp:380] conv5_5/sep -> conv5_5/sep
I0621 10:18:08.225544 17579 net.cpp:122] Setting up conv5_5/sep
I0621 10:18:08.225581 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.225591 17579 net.cpp:137] Memory required for data: 772710520
I0621 10:18:08.225605 17579 layer_factory.hpp:77] Creating layer conv5_5/sep/bn
I0621 10:18:08.225618 17579 net.cpp:84] Creating Layer conv5_5/sep/bn
I0621 10:18:08.225628 17579 net.cpp:406] conv5_5/sep/bn <- conv5_5/sep
I0621 10:18:08.225642 17579 net.cpp:367] conv5_5/sep/bn -> conv5_5/sep (in-place)
I0621 10:18:08.225945 17579 net.cpp:122] Setting up conv5_5/sep/bn
I0621 10:18:08.225963 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.225971 17579 net.cpp:137] Memory required for data: 776724600
I0621 10:18:08.225986 17579 layer_factory.hpp:77] Creating layer conv5_5/sep/scale
I0621 10:18:08.225999 17579 net.cpp:84] Creating Layer conv5_5/sep/scale
I0621 10:18:08.226008 17579 net.cpp:406] conv5_5/sep/scale <- conv5_5/sep
I0621 10:18:08.226019 17579 net.cpp:367] conv5_5/sep/scale -> conv5_5/sep (in-place)
I0621 10:18:08.226085 17579 layer_factory.hpp:77] Creating layer conv5_5/sep/scale
I0621 10:18:08.226270 17579 net.cpp:122] Setting up conv5_5/sep/scale
I0621 10:18:08.226287 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.226296 17579 net.cpp:137] Memory required for data: 780738680
I0621 10:18:08.226308 17579 layer_factory.hpp:77] Creating layer relu5_5/sep
I0621 10:18:08.226320 17579 net.cpp:84] Creating Layer relu5_5/sep
I0621 10:18:08.226330 17579 net.cpp:406] relu5_5/sep <- conv5_5/sep
I0621 10:18:08.226343 17579 net.cpp:367] relu5_5/sep -> conv5_5/sep (in-place)
I0621 10:18:08.226886 17579 net.cpp:122] Setting up relu5_5/sep
I0621 10:18:08.226909 17579 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0621 10:18:08.226918 17579 net.cpp:137] Memory required for data: 784752760
I0621 10:18:08.226927 17579 layer_factory.hpp:77] Creating layer conv5_6/dw
I0621 10:18:08.226941 17579 net.cpp:84] Creating Layer conv5_6/dw
I0621 10:18:08.226951 17579 net.cpp:406] conv5_6/dw <- conv5_5/sep
I0621 10:18:08.226969 17579 net.cpp:380] conv5_6/dw -> conv5_6/dw
I0621 10:18:08.227200 17579 net.cpp:122] Setting up conv5_6/dw
I0621 10:18:08.227221 17579 net.cpp:129] Top shape: 10 512 7 7 (250880)
I0621 10:18:08.227236 17579 net.cpp:137] Memory required for data: 785756280
I0621 10:18:08.227248 17579 layer_factory.hpp:77] Creating layer conv5_6/dw/bn
I0621 10:18:08.227262 17579 net.cpp:84] Creating Layer conv5_6/dw/bn
I0621 10:18:08.227270 17579 net.cpp:406] conv5_6/dw/bn <- conv5_6/dw
I0621 10:18:08.227284 17579 net.cpp:367] conv5_6/dw/bn -> conv5_6/dw (in-place)
I0621 10:18:08.227603 17579 net.cpp:122] Setting up conv5_6/dw/bn
I0621 10:18:08.227622 17579 net.cpp:129] Top shape: 10 512 7 7 (250880)
I0621 10:18:08.227632 17579 net.cpp:137] Memory required for data: 786759800
I0621 10:18:08.227645 17579 layer_factory.hpp:77] Creating layer conv5_6/dw/scale
I0621 10:18:08.227658 17579 net.cpp:84] Creating Layer conv5_6/dw/scale
I0621 10:18:08.227668 17579 net.cpp:406] conv5_6/dw/scale <- conv5_6/dw
I0621 10:18:08.227679 17579 net.cpp:367] conv5_6/dw/scale -> conv5_6/dw (in-place)
I0621 10:18:08.227744 17579 layer_factory.hpp:77] Creating layer conv5_6/dw/scale
I0621 10:18:08.227934 17579 net.cpp:122] Setting up conv5_6/dw/scale
I0621 10:18:08.227952 17579 net.cpp:129] Top shape: 10 512 7 7 (250880)
I0621 10:18:08.227960 17579 net.cpp:137] Memory required for data: 787763320
I0621 10:18:08.227972 17579 layer_factory.hpp:77] Creating layer relu5_6/dw
I0621 10:18:08.227984 17579 net.cpp:84] Creating Layer relu5_6/dw
I0621 10:18:08.227993 17579 net.cpp:406] relu5_6/dw <- conv5_6/dw
I0621 10:18:08.228008 17579 net.cpp:367] relu5_6/dw -> conv5_6/dw (in-place)
I0621 10:18:08.228256 17579 net.cpp:122] Setting up relu5_6/dw
I0621 10:18:08.228274 17579 net.cpp:129] Top shape: 10 512 7 7 (250880)
I0621 10:18:08.228283 17579 net.cpp:137] Memory required for data: 788766840
I0621 10:18:08.228292 17579 layer_factory.hpp:77] Creating layer conv5_6/sep
I0621 10:18:08.228309 17579 net.cpp:84] Creating Layer conv5_6/sep
I0621 10:18:08.228319 17579 net.cpp:406] conv5_6/sep <- conv5_6/dw
I0621 10:18:08.228346 17579 net.cpp:380] conv5_6/sep -> conv5_6/sep
I0621 10:18:08.239347 17579 net.cpp:122] Setting up conv5_6/sep
I0621 10:18:08.239377 17579 net.cpp:129] Top shape: 10 1024 7 7 (501760)
I0621 10:18:08.239385 17579 net.cpp:137] Memory required for data: 790773880
I0621 10:18:08.239399 17579 layer_factory.hpp:77] Creating layer conv5_6/sep/bn
I0621 10:18:08.239416 17579 net.cpp:84] Creating Layer conv5_6/sep/bn
I0621 10:18:08.239428 17579 net.cpp:406] conv5_6/sep/bn <- conv5_6/sep
I0621 10:18:08.239439 17579 net.cpp:367] conv5_6/sep/bn -> conv5_6/sep (in-place)
I0621 10:18:08.239758 17579 net.cpp:122] Setting up conv5_6/sep/bn
I0621 10:18:08.239778 17579 net.cpp:129] Top shape: 10 1024 7 7 (501760)
I0621 10:18:08.239786 17579 net.cpp:137] Memory required for data: 792780920
I0621 10:18:08.239800 17579 layer_factory.hpp:77] Creating layer conv5_6/sep/scale
I0621 10:18:08.239814 17579 net.cpp:84] Creating Layer conv5_6/sep/scale
I0621 10:18:08.239823 17579 net.cpp:406] conv5_6/sep/scale <- conv5_6/sep
I0621 10:18:08.239837 17579 net.cpp:367] conv5_6/sep/scale -> conv5_6/sep (in-place)
I0621 10:18:08.239902 17579 layer_factory.hpp:77] Creating layer conv5_6/sep/scale
I0621 10:18:08.240092 17579 net.cpp:122] Setting up conv5_6/sep/scale
I0621 10:18:08.240110 17579 net.cpp:129] Top shape: 10 1024 7 7 (501760)
I0621 10:18:08.240118 17579 net.cpp:137] Memory required for data: 794787960
I0621 10:18:08.240131 17579 layer_factory.hpp:77] Creating layer relu5_6/sep
I0621 10:18:08.240146 17579 net.cpp:84] Creating Layer relu5_6/sep
I0621 10:18:08.240156 17579 net.cpp:406] relu5_6/sep <- conv5_6/sep
I0621 10:18:08.240166 17579 net.cpp:367] relu5_6/sep -> conv5_6/sep (in-place)
I0621 10:18:08.240727 17579 net.cpp:122] Setting up relu5_6/sep
I0621 10:18:08.240749 17579 net.cpp:129] Top shape: 10 1024 7 7 (501760)
I0621 10:18:08.240759 17579 net.cpp:137] Memory required for data: 796795000
I0621 10:18:08.240767 17579 layer_factory.hpp:77] Creating layer conv6/dw
I0621 10:18:08.240787 17579 net.cpp:84] Creating Layer conv6/dw
I0621 10:18:08.240797 17579 net.cpp:406] conv6/dw <- conv5_6/sep
I0621 10:18:08.240813 17579 net.cpp:380] conv6/dw -> conv6/dw
I0621 10:18:08.241109 17579 net.cpp:122] Setting up conv6/dw
I0621 10:18:08.241128 17579 net.cpp:129] Top shape: 10 1024 7 7 (501760)
I0621 10:18:08.241137 17579 net.cpp:137] Memory required for data: 798802040
I0621 10:18:08.241147 17579 layer_factory.hpp:77] Creating layer conv6/dw/bn
I0621 10:18:08.241166 17579 net.cpp:84] Creating Layer conv6/dw/bn
I0621 10:18:08.241178 17579 net.cpp:406] conv6/dw/bn <- conv6/dw
I0621 10:18:08.241189 17579 net.cpp:367] conv6/dw/bn -> conv6/dw (in-place)
I0621 10:18:08.241497 17579 net.cpp:122] Setting up conv6/dw/bn
I0621 10:18:08.241520 17579 net.cpp:129] Top shape: 10 1024 7 7 (501760)
I0621 10:18:08.241531 17579 net.cpp:137] Memory required for data: 800809080
I0621 10:18:08.241546 17579 layer_factory.hpp:77] Creating layer conv6/dw/scale
I0621 10:18:08.241559 17579 net.cpp:84] Creating Layer conv6/dw/scale
I0621 10:18:08.241569 17579 net.cpp:406] conv6/dw/scale <- conv6/dw
I0621 10:18:08.241585 17579 net.cpp:367] conv6/dw/scale -> conv6/dw (in-place)
I0621 10:18:08.241648 17579 layer_factory.hpp:77] Creating layer conv6/dw/scale
I0621 10:18:08.241843 17579 net.cpp:122] Setting up conv6/dw/scale
I0621 10:18:08.241861 17579 net.cpp:129] Top shape: 10 1024 7 7 (501760)
I0621 10:18:08.241869 17579 net.cpp:137] Memory required for data: 802816120
I0621 10:18:08.241883 17579 layer_factory.hpp:77] Creating layer relu6/dw
I0621 10:18:08.241894 17579 net.cpp:84] Creating Layer relu6/dw
I0621 10:18:08.241902 17579 net.cpp:406] relu6/dw <- conv6/dw
I0621 10:18:08.241914 17579 net.cpp:367] relu6/dw -> conv6/dw (in-place)
I0621 10:18:08.242153 17579 net.cpp:122] Setting up relu6/dw
I0621 10:18:08.242172 17579 net.cpp:129] Top shape: 10 1024 7 7 (501760)
I0621 10:18:08.242182 17579 net.cpp:137] Memory required for data: 804823160
I0621 10:18:08.242190 17579 layer_factory.hpp:77] Creating layer conv6/sep
I0621 10:18:08.242220 17579 net.cpp:84] Creating Layer conv6/sep
I0621 10:18:08.242233 17579 net.cpp:406] conv6/sep <- conv6/dw
I0621 10:18:08.242247 17579 net.cpp:380] conv6/sep -> conv6/sep
I0621 10:18:08.263679 17579 net.cpp:122] Setting up conv6/sep
I0621 10:18:08.263730 17579 net.cpp:129] Top shape: 10 1024 7 7 (501760)
I0621 10:18:08.263739 17579 net.cpp:137] Memory required for data: 806830200
I0621 10:18:08.263756 17579 layer_factory.hpp:77] Creating layer conv6/sep/bn
I0621 10:18:08.263782 17579 net.cpp:84] Creating Layer conv6/sep/bn
I0621 10:18:08.263792 17579 net.cpp:406] conv6/sep/bn <- conv6/sep
I0621 10:18:08.263808 17579 net.cpp:367] conv6/sep/bn -> conv6/sep (in-place)
I0621 10:18:08.264140 17579 net.cpp:122] Setting up conv6/sep/bn
I0621 10:18:08.264159 17579 net.cpp:129] Top shape: 10 1024 7 7 (501760)
I0621 10:18:08.264168 17579 net.cpp:137] Memory required for data: 808837240
I0621 10:18:08.264183 17579 layer_factory.hpp:77] Creating layer conv6/sep/scale
I0621 10:18:08.264197 17579 net.cpp:84] Creating Layer conv6/sep/scale
I0621 10:18:08.264206 17579 net.cpp:406] conv6/sep/scale <- conv6/sep
I0621 10:18:08.264221 17579 net.cpp:367] conv6/sep/scale -> conv6/sep (in-place)
I0621 10:18:08.264293 17579 layer_factory.hpp:77] Creating layer conv6/sep/scale
I0621 10:18:08.264492 17579 net.cpp:122] Setting up conv6/sep/scale
I0621 10:18:08.264518 17579 net.cpp:129] Top shape: 10 1024 7 7 (501760)
I0621 10:18:08.264530 17579 net.cpp:137] Memory required for data: 810844280
I0621 10:18:08.264544 17579 layer_factory.hpp:77] Creating layer relu6/sep
I0621 10:18:08.264556 17579 net.cpp:84] Creating Layer relu6/sep
I0621 10:18:08.264565 17579 net.cpp:406] relu6/sep <- conv6/sep
I0621 10:18:08.264575 17579 net.cpp:367] relu6/sep -> conv6/sep (in-place)
I0621 10:18:08.265522 17579 net.cpp:122] Setting up relu6/sep
I0621 10:18:08.265544 17579 net.cpp:129] Top shape: 10 1024 7 7 (501760)
I0621 10:18:08.265554 17579 net.cpp:137] Memory required for data: 812851320
I0621 10:18:08.265563 17579 layer_factory.hpp:77] Creating layer pool6
I0621 10:18:08.265581 17579 net.cpp:84] Creating Layer pool6
I0621 10:18:08.265592 17579 net.cpp:406] pool6 <- conv6/sep
I0621 10:18:08.265604 17579 net.cpp:380] pool6 -> pool6
I0621 10:18:08.266150 17579 net.cpp:122] Setting up pool6
I0621 10:18:08.266171 17579 net.cpp:129] Top shape: 10 1024 1 1 (10240)
I0621 10:18:08.266180 17579 net.cpp:137] Memory required for data: 812892280
I0621 10:18:08.266188 17579 layer_factory.hpp:77] Creating layer fc7_oxford
I0621 10:18:08.266209 17579 net.cpp:84] Creating Layer fc7_oxford
I0621 10:18:08.266221 17579 net.cpp:406] fc7_oxford <- pool6
I0621 10:18:08.266233 17579 net.cpp:380] fc7_oxford -> fc7
I0621 10:18:08.269013 17579 net.cpp:122] Setting up fc7_oxford
I0621 10:18:08.269038 17579 net.cpp:129] Top shape: 10 102 1 1 (1020)
I0621 10:18:08.269047 17579 net.cpp:137] Memory required for data: 812896360
I0621 10:18:08.269062 17579 layer_factory.hpp:77] Creating layer fc7_fc7_oxford_0_split
I0621 10:18:08.269078 17579 net.cpp:84] Creating Layer fc7_fc7_oxford_0_split
I0621 10:18:08.269089 17579 net.cpp:406] fc7_fc7_oxford_0_split <- fc7
I0621 10:18:08.269104 17579 net.cpp:380] fc7_fc7_oxford_0_split -> fc7_fc7_oxford_0_split_0
I0621 10:18:08.269120 17579 net.cpp:380] fc7_fc7_oxford_0_split -> fc7_fc7_oxford_0_split_1
I0621 10:18:08.269187 17579 net.cpp:122] Setting up fc7_fc7_oxford_0_split
I0621 10:18:08.269204 17579 net.cpp:129] Top shape: 10 102 1 1 (1020)
I0621 10:18:08.269215 17579 net.cpp:129] Top shape: 10 102 1 1 (1020)
I0621 10:18:08.269223 17579 net.cpp:137] Memory required for data: 812904520
I0621 10:18:08.269232 17579 layer_factory.hpp:77] Creating layer accuracy
I0621 10:18:08.269253 17579 net.cpp:84] Creating Layer accuracy
I0621 10:18:08.269264 17579 net.cpp:406] accuracy <- fc7_fc7_oxford_0_split_0
I0621 10:18:08.269274 17579 net.cpp:406] accuracy <- label_data_1_split_0
I0621 10:18:08.269285 17579 net.cpp:380] accuracy -> accuracy
I0621 10:18:08.269307 17579 net.cpp:122] Setting up accuracy
I0621 10:18:08.269320 17579 net.cpp:129] Top shape: (1)
I0621 10:18:08.269346 17579 net.cpp:137] Memory required for data: 812904524
I0621 10:18:08.269356 17579 layer_factory.hpp:77] Creating layer loss
I0621 10:18:08.269371 17579 net.cpp:84] Creating Layer loss
I0621 10:18:08.269381 17579 net.cpp:406] loss <- fc7_fc7_oxford_0_split_1
I0621 10:18:08.269390 17579 net.cpp:406] loss <- label_data_1_split_1
I0621 10:18:08.269402 17579 net.cpp:380] loss -> loss
I0621 10:18:08.269417 17579 layer_factory.hpp:77] Creating layer loss
I0621 10:18:08.270117 17579 net.cpp:122] Setting up loss
I0621 10:18:08.270138 17579 net.cpp:129] Top shape: (1)
I0621 10:18:08.270148 17579 net.cpp:132]     with loss weight 1
I0621 10:18:08.270165 17579 net.cpp:137] Memory required for data: 812904528
I0621 10:18:08.270174 17579 net.cpp:198] loss needs backward computation.
I0621 10:18:08.270184 17579 net.cpp:200] accuracy does not need backward computation.
I0621 10:18:08.270193 17579 net.cpp:198] fc7_fc7_oxford_0_split needs backward computation.
I0621 10:18:08.270202 17579 net.cpp:198] fc7_oxford needs backward computation.
I0621 10:18:08.270211 17579 net.cpp:198] pool6 needs backward computation.
I0621 10:18:08.270220 17579 net.cpp:198] relu6/sep needs backward computation.
I0621 10:18:08.270227 17579 net.cpp:198] conv6/sep/scale needs backward computation.
I0621 10:18:08.270236 17579 net.cpp:198] conv6/sep/bn needs backward computation.
I0621 10:18:08.270243 17579 net.cpp:198] conv6/sep needs backward computation.
I0621 10:18:08.270252 17579 net.cpp:198] relu6/dw needs backward computation.
I0621 10:18:08.270262 17579 net.cpp:198] conv6/dw/scale needs backward computation.
I0621 10:18:08.270269 17579 net.cpp:198] conv6/dw/bn needs backward computation.
I0621 10:18:08.270277 17579 net.cpp:198] conv6/dw needs backward computation.
I0621 10:18:08.270287 17579 net.cpp:198] relu5_6/sep needs backward computation.
I0621 10:18:08.270295 17579 net.cpp:198] conv5_6/sep/scale needs backward computation.
I0621 10:18:08.270303 17579 net.cpp:198] conv5_6/sep/bn needs backward computation.
I0621 10:18:08.270311 17579 net.cpp:198] conv5_6/sep needs backward computation.
I0621 10:18:08.270320 17579 net.cpp:198] relu5_6/dw needs backward computation.
I0621 10:18:08.270328 17579 net.cpp:198] conv5_6/dw/scale needs backward computation.
I0621 10:18:08.270344 17579 net.cpp:198] conv5_6/dw/bn needs backward computation.
I0621 10:18:08.270354 17579 net.cpp:198] conv5_6/dw needs backward computation.
I0621 10:18:08.270362 17579 net.cpp:198] relu5_5/sep needs backward computation.
I0621 10:18:08.270370 17579 net.cpp:198] conv5_5/sep/scale needs backward computation.
I0621 10:18:08.270378 17579 net.cpp:198] conv5_5/sep/bn needs backward computation.
I0621 10:18:08.270386 17579 net.cpp:198] conv5_5/sep needs backward computation.
I0621 10:18:08.270395 17579 net.cpp:198] relu5_5/dw needs backward computation.
I0621 10:18:08.270403 17579 net.cpp:198] conv5_5/dw/scale needs backward computation.
I0621 10:18:08.270411 17579 net.cpp:198] conv5_5/dw/bn needs backward computation.
I0621 10:18:08.270421 17579 net.cpp:198] conv5_5/dw needs backward computation.
I0621 10:18:08.270428 17579 net.cpp:198] relu5_4/sep needs backward computation.
I0621 10:18:08.270437 17579 net.cpp:198] conv5_4/sep/scale needs backward computation.
I0621 10:18:08.270445 17579 net.cpp:198] conv5_4/sep/bn needs backward computation.
I0621 10:18:08.270453 17579 net.cpp:198] conv5_4/sep needs backward computation.
I0621 10:18:08.270462 17579 net.cpp:198] relu5_4/dw needs backward computation.
I0621 10:18:08.270470 17579 net.cpp:198] conv5_4/dw/scale needs backward computation.
I0621 10:18:08.270478 17579 net.cpp:198] conv5_4/dw/bn needs backward computation.
I0621 10:18:08.270486 17579 net.cpp:198] conv5_4/dw needs backward computation.
I0621 10:18:08.270495 17579 net.cpp:198] relu5_3/sep needs backward computation.
I0621 10:18:08.270503 17579 net.cpp:198] conv5_3/sep/scale needs backward computation.
I0621 10:18:08.270511 17579 net.cpp:198] conv5_3/sep/bn needs backward computation.
I0621 10:18:08.270530 17579 net.cpp:198] conv5_3/sep needs backward computation.
I0621 10:18:08.270550 17579 net.cpp:198] relu5_3/dw needs backward computation.
I0621 10:18:08.270558 17579 net.cpp:198] conv5_3/dw/scale needs backward computation.
I0621 10:18:08.270566 17579 net.cpp:198] conv5_3/dw/bn needs backward computation.
I0621 10:18:08.270576 17579 net.cpp:198] conv5_3/dw needs backward computation.
I0621 10:18:08.270583 17579 net.cpp:198] relu5_2/sep needs backward computation.
I0621 10:18:08.270591 17579 net.cpp:198] conv5_2/sep/scale needs backward computation.
I0621 10:18:08.270599 17579 net.cpp:198] conv5_2/sep/bn needs backward computation.
I0621 10:18:08.270608 17579 net.cpp:198] conv5_2/sep needs backward computation.
I0621 10:18:08.270617 17579 net.cpp:198] relu5_2/dw needs backward computation.
I0621 10:18:08.270624 17579 net.cpp:198] conv5_2/dw/scale needs backward computation.
I0621 10:18:08.270632 17579 net.cpp:198] conv5_2/dw/bn needs backward computation.
I0621 10:18:08.270640 17579 net.cpp:198] conv5_2/dw needs backward computation.
I0621 10:18:08.270649 17579 net.cpp:198] relu5_1/sep needs backward computation.
I0621 10:18:08.270658 17579 net.cpp:198] conv5_1/sep/scale needs backward computation.
I0621 10:18:08.270665 17579 net.cpp:198] conv5_1/sep/bn needs backward computation.
I0621 10:18:08.270673 17579 net.cpp:198] conv5_1/sep needs backward computation.
I0621 10:18:08.270683 17579 net.cpp:198] relu5_1/dw needs backward computation.
I0621 10:18:08.270690 17579 net.cpp:198] conv5_1/dw/scale needs backward computation.
I0621 10:18:08.270699 17579 net.cpp:198] conv5_1/dw/bn needs backward computation.
I0621 10:18:08.270707 17579 net.cpp:198] conv5_1/dw needs backward computation.
I0621 10:18:08.270715 17579 net.cpp:198] relu4_2/sep needs backward computation.
I0621 10:18:08.270723 17579 net.cpp:198] conv4_2/sep/scale needs backward computation.
I0621 10:18:08.270732 17579 net.cpp:198] conv4_2/sep/bn needs backward computation.
I0621 10:18:08.270740 17579 net.cpp:198] conv4_2/sep needs backward computation.
I0621 10:18:08.270748 17579 net.cpp:198] relu4_2/dw needs backward computation.
I0621 10:18:08.270757 17579 net.cpp:198] conv4_2/dw/scale needs backward computation.
I0621 10:18:08.270766 17579 net.cpp:198] conv4_2/dw/bn needs backward computation.
I0621 10:18:08.270778 17579 net.cpp:198] conv4_2/dw needs backward computation.
I0621 10:18:08.270787 17579 net.cpp:198] relu4_1/sep needs backward computation.
I0621 10:18:08.270797 17579 net.cpp:198] conv4_1/sep/scale needs backward computation.
I0621 10:18:08.270804 17579 net.cpp:198] conv4_1/sep/bn needs backward computation.
I0621 10:18:08.270812 17579 net.cpp:198] conv4_1/sep needs backward computation.
I0621 10:18:08.270822 17579 net.cpp:198] relu4_1/dw needs backward computation.
I0621 10:18:08.270829 17579 net.cpp:198] conv4_1/dw/scale needs backward computation.
I0621 10:18:08.270838 17579 net.cpp:198] conv4_1/dw/bn needs backward computation.
I0621 10:18:08.270846 17579 net.cpp:198] conv4_1/dw needs backward computation.
I0621 10:18:08.270854 17579 net.cpp:198] relu3_2/sep needs backward computation.
I0621 10:18:08.270864 17579 net.cpp:198] conv3_2/sep/scale needs backward computation.
I0621 10:18:08.270871 17579 net.cpp:198] conv3_2/sep/bn needs backward computation.
I0621 10:18:08.270879 17579 net.cpp:198] conv3_2/sep needs backward computation.
I0621 10:18:08.270889 17579 net.cpp:198] relu3_2/dw needs backward computation.
I0621 10:18:08.270896 17579 net.cpp:198] conv3_2/dw/scale needs backward computation.
I0621 10:18:08.270905 17579 net.cpp:198] conv3_2/dw/bn needs backward computation.
I0621 10:18:08.270912 17579 net.cpp:198] conv3_2/dw needs backward computation.
I0621 10:18:08.270921 17579 net.cpp:198] relu3_1/sep needs backward computation.
I0621 10:18:08.270929 17579 net.cpp:198] conv3_1/sep/scale needs backward computation.
I0621 10:18:08.270938 17579 net.cpp:198] conv3_1/sep/bn needs backward computation.
I0621 10:18:08.270946 17579 net.cpp:198] conv3_1/sep needs backward computation.
I0621 10:18:08.270954 17579 net.cpp:198] relu3_1/dw needs backward computation.
I0621 10:18:08.270963 17579 net.cpp:198] conv3_1/dw/scale needs backward computation.
I0621 10:18:08.270978 17579 net.cpp:198] conv3_1/dw/bn needs backward computation.
I0621 10:18:08.270988 17579 net.cpp:198] conv3_1/dw needs backward computation.
I0621 10:18:08.270997 17579 net.cpp:198] relu2_2/sep needs backward computation.
I0621 10:18:08.271005 17579 net.cpp:198] conv2_2/sep/scale needs backward computation.
I0621 10:18:08.271013 17579 net.cpp:198] conv2_2/sep/bn needs backward computation.
I0621 10:18:08.271021 17579 net.cpp:198] conv2_2/sep needs backward computation.
I0621 10:18:08.271030 17579 net.cpp:198] relu2_2/dw needs backward computation.
I0621 10:18:08.271039 17579 net.cpp:198] conv2_2/dw/scale needs backward computation.
I0621 10:18:08.271046 17579 net.cpp:198] conv2_2/dw/bn needs backward computation.
I0621 10:18:08.271054 17579 net.cpp:198] conv2_2/dw needs backward computation.
I0621 10:18:08.271064 17579 net.cpp:198] relu2_1/sep needs backward computation.
I0621 10:18:08.271082 17579 net.cpp:198] conv2_1/sep/scale needs backward computation.
I0621 10:18:08.271091 17579 net.cpp:198] conv2_1/sep/bn needs backward computation.
I0621 10:18:08.271100 17579 net.cpp:198] conv2_1/sep needs backward computation.
I0621 10:18:08.271108 17579 net.cpp:198] relu2_1/dw needs backward computation.
I0621 10:18:08.271116 17579 net.cpp:198] conv2_1/dw/scale needs backward computation.
I0621 10:18:08.271126 17579 net.cpp:198] conv2_1/dw/bn needs backward computation.
I0621 10:18:08.271133 17579 net.cpp:198] conv2_1/dw needs backward computation.
I0621 10:18:08.271142 17579 net.cpp:198] relu1 needs backward computation.
I0621 10:18:08.271150 17579 net.cpp:198] conv1/scale needs backward computation.
I0621 10:18:08.271159 17579 net.cpp:198] conv1/bn needs backward computation.
I0621 10:18:08.271167 17579 net.cpp:198] conv1 needs backward computation.
I0621 10:18:08.271178 17579 net.cpp:200] label_data_1_split does not need backward computation.
I0621 10:18:08.271186 17579 net.cpp:200] data does not need backward computation.
I0621 10:18:08.271194 17579 net.cpp:242] This network produces output accuracy
I0621 10:18:08.271203 17579 net.cpp:242] This network produces output loss
I0621 10:18:08.271275 17579 net.cpp:255] Network initialization done.
I0621 10:18:08.271662 17579 solver.cpp:56] Solver scaffolding done.
I0621 10:18:08.280199 17579 caffe.cpp:155] Finetuning from mobilenet/mobile_1_iter_5001.caffemodel
I0621 10:18:08.297181 17579 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: mobilenet/mobile_1_iter_5001.caffemodel
I0621 10:18:08.297250 17579 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0621 10:18:08.313355 17579 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: mobilenet/mobile_1_iter_5001.caffemodel
I0621 10:18:08.313422 17579 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0621 10:18:08.318281 17579 caffe.cpp:248] Starting Optimization
I0621 10:18:08.318344 17579 solver.cpp:273] Solving MOBILENET
I0621 10:18:08.318353 17579 solver.cpp:274] Learning Rate Policy: step
I0621 10:18:08.329629 17579 solver.cpp:331] Iteration 0, Testing net (#0)
I0621 10:18:09.353241 17579 blocking_queue.cpp:49] Waiting for data
I0621 10:18:11.488462 32183 solver.cpp:448] Snapshotting to binary proto file mobilenet/mobile_pruning_iter_28637.caffemodel
I0621 10:18:11.617445 32183 sgd_solver.cpp:273] Snapshotting solver state to binary proto file mobilenet/mobile_pruning_iter_28637.solverstate
I0621 10:18:11.673260 32183 solver.cpp:295] Optimization stopped early.
I0621 10:18:11.673300 32183 caffe.cpp:259] Optimization Done.
I0621 10:18:21.225181 17579 solver.cpp:398]     Test net output #0: accuracy = 0.00980392
I0621 10:18:21.225263 17579 solver.cpp:398]     Test net output #1: loss = 4.62499 (* 1 = 4.62499 loss)
I0621 10:18:21.234395 17579 compress_conv_layer.cu:174] 0.161965 1.92991e-10 0.991767
I0621 10:18:21.244000 17579 compress_conv_layer.cu:174] 0.161965 1.17708e-10 0.579639
I0621 10:18:21.253602 17579 compress_conv_layer.cu:174] 0.161965 2.11477e-11 0.777383
I0621 10:18:21.263391 17579 compress_conv_layer.cu:174] 0.161965 3.22113e-12 0.819851
I0621 10:18:21.277581 17579 compress_conv_layer.cu:174] 0.161965 1.0287e-11 0.478373
I0621 10:18:21.302067 17579 compress_conv_layer.cu:174] 0.161965 9.86794e-14 0.506516
I0621 10:18:21.349638 17579 compress_conv_layer.cu:174] 0.161965 1.79234e-13 0.499835
I0621 10:18:21.399329 17579 compress_conv_layer.cu:174] 0.161965 2.28223e-12 0.423805
I0621 10:18:21.449095 17579 compress_conv_layer.cu:174] 0.161965 1.9834e-12 0.448906
I0621 10:18:21.498476 17579 compress_conv_layer.cu:174] 0.161965 2.0847e-12 0.604792
I0621 10:18:21.547770 17579 compress_conv_layer.cu:174] 0.161965 5.74126e-12 0.479722
I0621 10:18:21.642518 17579 compress_conv_layer.cu:174] 0.161965 1.71721e-12 0.344721
I0621 10:18:21.838292 17579 compress_conv_layer.cu:174] 0.161965 3.53718e-12 0.306674
I0621 10:18:21.861248 17579 compress_conv_layer.cu:174] 0.161965 3.28916e-07 0.173393
I0621 10:18:22.113389 17579 compress_conv_layer.cu:174] 0.161965 1.92991e-10 0.991767
I0621 10:18:22.121373 17579 compress_conv_layer.cu:174] 0.161965 1.17708e-10 0.579639
I0621 10:18:22.129613 17579 compress_conv_layer.cu:174] 0.161965 2.11477e-11 0.777383
I0621 10:18:22.137673 17579 compress_conv_layer.cu:174] 0.161965 3.22113e-12 0.819851
I0621 10:18:22.150045 17579 compress_conv_layer.cu:174] 0.161965 1.0287e-11 0.478373
I0621 10:18:22.171558 17579 compress_conv_layer.cu:174] 0.161965 9.86794e-14 0.506516
I0621 10:18:22.215445 17579 compress_conv_layer.cu:174] 0.161965 1.79234e-13 0.499835
I0621 10:18:22.257987 17579 compress_conv_layer.cu:174] 0.161965 2.28223e-12 0.423805
I0621 10:18:22.300947 17579 compress_conv_layer.cu:174] 0.161965 1.9834e-12 0.448906
I0621 10:18:22.343432 17579 compress_conv_layer.cu:174] 0.161965 2.0847e-12 0.604792
I0621 10:18:22.386109 17579 compress_conv_layer.cu:174] 0.161965 5.74126e-12 0.479722
I0621 10:18:22.475119 17579 compress_conv_layer.cu:174] 0.161965 1.71721e-12 0.344721
I0621 10:18:22.659672 17579 compress_conv_layer.cu:174] 0.161965 3.53718e-12 0.306674
I0621 10:18:22.682924 17579 compress_conv_layer.cu:174] 0.161965 3.28916e-07 0.173393
I0621 10:18:22.921192 17579 compress_conv_layer.cu:174] 0.161965 1.92991e-10 0.991767
I0621 10:18:22.929162 17579 compress_conv_layer.cu:174] 0.161965 1.17708e-10 0.579639
I0621 10:18:22.937391 17579 compress_conv_layer.cu:174] 0.161965 2.11477e-11 0.777383
I0621 10:18:22.945472 17579 compress_conv_layer.cu:174] 0.161965 3.22113e-12 0.819851
I0621 10:18:22.957855 17579 compress_conv_layer.cu:174] 0.161965 1.0287e-11 0.478373
I0621 10:18:22.979393 17579 compress_conv_layer.cu:174] 0.161965 9.86794e-14 0.506516
I0621 10:18:23.023578 17579 compress_conv_layer.cu:174] 0.161965 1.79234e-13 0.499835
I0621 10:18:23.066150 17579 compress_conv_layer.cu:174] 0.161965 2.28223e-12 0.423805
I0621 10:18:23.108748 17579 compress_conv_layer.cu:174] 0.161965 1.9834e-12 0.448906
I0621 10:18:23.150779 17579 compress_conv_layer.cu:174] 0.161965 2.0847e-12 0.604792
I0621 10:18:23.193049 17579 compress_conv_layer.cu:174] 0.161965 5.74126e-12 0.479722
I0621 10:18:23.282104 17579 compress_conv_layer.cu:174] 0.161965 1.71721e-12 0.344721
I0621 10:18:23.466493 17579 compress_conv_layer.cu:174] 0.161965 3.53718e-12 0.306674
I0621 10:18:23.489754 17579 compress_conv_layer.cu:174] 0.161965 3.28916e-07 0.173393
I0621 10:18:23.727905 17579 compress_conv_layer.cu:174] 0.161965 1.92991e-10 0.991767
I0621 10:18:23.735826 17579 compress_conv_layer.cu:174] 0.161965 1.17708e-10 0.579639
I0621 10:18:23.744050 17579 compress_conv_layer.cu:174] 0.161965 2.11477e-11 0.777383
I0621 10:18:23.752105 17579 compress_conv_layer.cu:174] 0.161965 3.22113e-12 0.819851
I0621 10:18:23.764524 17579 compress_conv_layer.cu:174] 0.161965 1.0287e-11 0.478373
I0621 10:18:23.785995 17579 compress_conv_layer.cu:174] 0.161965 9.86794e-14 0.506516
I0621 10:18:23.829939 17579 compress_conv_layer.cu:174] 0.161965 1.79234e-13 0.499835
I0621 10:18:23.872056 17579 compress_conv_layer.cu:174] 0.161965 2.28223e-12 0.423805
I0621 10:18:23.914443 17579 compress_conv_layer.cu:174] 0.161965 1.9834e-12 0.448906
I0621 10:18:23.956907 17579 compress_conv_layer.cu:174] 0.161965 2.0847e-12 0.604792
I0621 10:18:23.999755 17579 compress_conv_layer.cu:174] 0.161965 5.74126e-12 0.479722
I0621 10:18:24.088940 17579 compress_conv_layer.cu:174] 0.161965 1.71721e-12 0.344721
I0621 10:18:24.276089 17579 compress_conv_layer.cu:174] 0.161965 3.53718e-12 0.306674
I0621 10:18:24.299592 17579 compress_conv_layer.cu:174] 0.161965 3.28916e-07 0.173393
I0621 10:18:24.537948 17579 compress_conv_layer.cu:174] 0.161965 1.92991e-10 0.991767
I0621 10:18:24.545902 17579 compress_conv_layer.cu:174] 0.161965 1.17708e-10 0.579639
I0621 10:18:24.554143 17579 compress_conv_layer.cu:174] 0.161965 2.11477e-11 0.777383
I0621 10:18:24.562228 17579 compress_conv_layer.cu:174] 0.161965 3.22113e-12 0.819851
I0621 10:18:24.574661 17579 compress_conv_layer.cu:174] 0.161965 1.0287e-11 0.478373
I0621 10:18:24.596105 17579 compress_conv_layer.cu:174] 0.161965 9.86794e-14 0.506516
I0621 10:18:24.640000 17579 compress_conv_layer.cu:174] 0.161965 1.79234e-13 0.499835
I0621 10:18:24.682296 17579 compress_conv_layer.cu:174] 0.161965 2.28223e-12 0.423805
I0621 10:18:24.724802 17579 compress_conv_layer.cu:174] 0.161965 1.9834e-12 0.448906
I0621 10:18:24.766871 17579 compress_conv_layer.cu:174] 0.161965 2.0847e-12 0.604792
I0621 10:18:24.809564 17579 compress_conv_layer.cu:174] 0.161965 5.74126e-12 0.479722
I0621 10:18:24.898686 17579 compress_conv_layer.cu:174] 0.161965 1.71721e-12 0.344721
I0621 10:18:25.084048 17579 compress_conv_layer.cu:174] 0.161965 3.53718e-12 0.306674
I0621 10:18:25.107378 17579 compress_conv_layer.cu:174] 0.161965 3.28916e-07 0.173393
I0621 10:18:25.337560 17579 solver.cpp:219] Iteration 0 (0 iter/s, 17.0189s/50 iters), loss = 0.0038783
I0621 10:18:25.337625 17579 solver.cpp:238]     Train net output #0: loss = 0.00124112 (* 1 = 0.00124112 loss)
I0621 10:18:25.337680 17579 sgd_solver.cpp:105] Iteration 0, lr = 0.005
I0621 10:19:36.103674 17579 solver.cpp:219] Iteration 50 (0.70656 iter/s, 70.7654s/50 iters), loss = 0.00430911
I0621 10:19:36.103906 17579 solver.cpp:238]     Train net output #0: loss = 0.00262119 (* 1 = 0.00262119 loss)
I0621 10:19:36.103935 17579 sgd_solver.cpp:105] Iteration 50, lr = 0.005
I0621 10:20:46.849915 17579 solver.cpp:219] Iteration 100 (0.70676 iter/s, 70.7454s/50 iters), loss = 0.00375912
I0621 10:20:46.850052 17579 solver.cpp:238]     Train net output #0: loss = 0.00206974 (* 1 = 0.00206974 loss)
I0621 10:20:46.850081 17579 sgd_solver.cpp:105] Iteration 100, lr = 0.005
I0621 10:21:57.599840 17579 solver.cpp:219] Iteration 150 (0.706722 iter/s, 70.7491s/50 iters), loss = 0.00431772
I0621 10:21:57.599989 17579 solver.cpp:238]     Train net output #0: loss = 0.00221248 (* 1 = 0.00221248 loss)
I0621 10:21:57.600019 17579 sgd_solver.cpp:105] Iteration 150, lr = 0.005
I0621 10:23:08.351106 17579 solver.cpp:219] Iteration 200 (0.706709 iter/s, 70.7505s/50 iters), loss = 0.00359828
I0621 10:23:08.351241 17579 solver.cpp:238]     Train net output #0: loss = 0.00167577 (* 1 = 0.00167577 loss)
I0621 10:23:08.351269 17579 sgd_solver.cpp:105] Iteration 200, lr = 0.005
I0621 10:24:19.096920 17579 solver.cpp:219] Iteration 250 (0.706763 iter/s, 70.745s/50 iters), loss = 0.00506163
I0621 10:24:19.097146 17579 solver.cpp:238]     Train net output #0: loss = 0.00512034 (* 1 = 0.00512034 loss)
I0621 10:24:19.097175 17579 sgd_solver.cpp:105] Iteration 250, lr = 0.005
I0621 10:25:29.847177 17579 solver.cpp:219] Iteration 300 (0.70672 iter/s, 70.7494s/50 iters), loss = 0.0030089
I0621 10:25:29.847319 17579 solver.cpp:238]     Train net output #0: loss = 0.00311794 (* 1 = 0.00311794 loss)
I0621 10:25:29.847348 17579 sgd_solver.cpp:105] Iteration 300, lr = 0.005
I0621 10:26:40.590571 17579 solver.cpp:219] Iteration 350 (0.706788 iter/s, 70.7426s/50 iters), loss = 0.00353885
I0621 10:26:40.590713 17579 solver.cpp:238]     Train net output #0: loss = 0.00456155 (* 1 = 0.00456155 loss)
I0621 10:26:40.590741 17579 sgd_solver.cpp:105] Iteration 350, lr = 0.005
I0621 10:27:51.335244 17579 solver.cpp:219] Iteration 400 (0.706775 iter/s, 70.7439s/50 iters), loss = 0.00535308
I0621 10:27:51.335384 17579 solver.cpp:238]     Train net output #0: loss = 0.00689011 (* 1 = 0.00689011 loss)
I0621 10:27:51.335413 17579 sgd_solver.cpp:105] Iteration 400, lr = 0.005
I0621 10:29:02.109948 17579 solver.cpp:219] Iteration 450 (0.706477 iter/s, 70.7737s/50 iters), loss = 0.0064147
I0621 10:29:02.110152 17579 solver.cpp:238]     Train net output #0: loss = 0.0083289 (* 1 = 0.0083289 loss)
I0621 10:29:02.110182 17579 sgd_solver.cpp:105] Iteration 450, lr = 0.005
I0621 10:30:11.459674 17579 solver.cpp:331] Iteration 500, Testing net (#0)
I0621 10:30:23.432687 17579 solver.cpp:398]     Test net output #0: accuracy = 0.979412
I0621 10:30:23.432763 17579 solver.cpp:398]     Test net output #1: loss = 0.0783341 (* 1 = 0.0783341 loss)
I0621 10:30:24.842969 17579 solver.cpp:219] Iteration 500 (0.604362 iter/s, 82.7318s/50 iters), loss = 0.00644356
I0621 10:30:24.843067 17579 solver.cpp:238]     Train net output #0: loss = 0.0065444 (* 1 = 0.0065444 loss)
I0621 10:30:24.843094 17579 sgd_solver.cpp:105] Iteration 500, lr = 0.005
I0621 10:31:35.595129 17579 solver.cpp:219] Iteration 550 (0.706702 iter/s, 70.7512s/50 iters), loss = 0.00473306
I0621 10:31:35.595271 17579 solver.cpp:238]     Train net output #0: loss = 0.00368356 (* 1 = 0.00368356 loss)
I0621 10:31:35.595302 17579 sgd_solver.cpp:105] Iteration 550, lr = 0.005
I0621 10:32:46.338932 17579 solver.cpp:219] Iteration 600 (0.706786 iter/s, 70.7428s/50 iters), loss = 0.00301145
I0621 10:32:46.339061 17579 solver.cpp:238]     Train net output #0: loss = 0.00367854 (* 1 = 0.00367854 loss)
I0621 10:32:46.339089 17579 sgd_solver.cpp:105] Iteration 600, lr = 0.005
I0621 10:33:57.084978 17579 solver.cpp:219] Iteration 650 (0.706763 iter/s, 70.7451s/50 iters), loss = 0.00229182
I0621 10:33:57.085122 17579 solver.cpp:238]     Train net output #0: loss = 0.0029332 (* 1 = 0.0029332 loss)
I0621 10:33:57.085151 17579 sgd_solver.cpp:105] Iteration 650, lr = 0.005
I0621 10:35:07.833528 17579 solver.cpp:219] Iteration 700 (0.706738 iter/s, 70.7476s/50 iters), loss = 0.00257853
I0621 10:35:07.833652 17579 solver.cpp:238]     Train net output #0: loss = 0.00223906 (* 1 = 0.00223906 loss)
I0621 10:35:07.833690 17579 sgd_solver.cpp:105] Iteration 700, lr = 0.005
I0621 10:36:18.580399 17579 solver.cpp:219] Iteration 750 (0.706755 iter/s, 70.7459s/50 iters), loss = 0.00399999
I0621 10:36:18.580552 17579 solver.cpp:238]     Train net output #0: loss = 0.00589695 (* 1 = 0.00589695 loss)
I0621 10:36:18.580581 17579 sgd_solver.cpp:105] Iteration 750, lr = 0.005
I0621 10:37:29.335861 17579 solver.cpp:219] Iteration 800 (0.706669 iter/s, 70.7545s/50 iters), loss = 0.00405995
I0621 10:37:29.336009 17579 solver.cpp:238]     Train net output #0: loss = 0.00297241 (* 1 = 0.00297241 loss)
I0621 10:37:29.336038 17579 sgd_solver.cpp:105] Iteration 800, lr = 0.005
I0621 10:38:40.096343 17579 solver.cpp:219] Iteration 850 (0.706619 iter/s, 70.7595s/50 iters), loss = 0.0027598
I0621 10:38:40.096484 17579 solver.cpp:238]     Train net output #0: loss = 0.00273177 (* 1 = 0.00273177 loss)
I0621 10:38:40.096518 17579 sgd_solver.cpp:105] Iteration 850, lr = 0.005
I0621 10:39:53.878837 17579 solver.cpp:219] Iteration 900 (0.677677 iter/s, 73.7815s/50 iters), loss = 0.00309152
I0621 10:39:53.878971 17579 solver.cpp:238]     Train net output #0: loss = 0.000758792 (* 1 = 0.000758792 loss)
I0621 10:39:53.879000 17579 sgd_solver.cpp:105] Iteration 900, lr = 0.005
I0621 10:41:04.643770 17579 solver.cpp:219] Iteration 950 (0.706574 iter/s, 70.764s/50 iters), loss = 0.00333887
I0621 10:41:04.643928 17579 solver.cpp:238]     Train net output #0: loss = 0.00277962 (* 1 = 0.00277962 loss)
I0621 10:41:04.643955 17579 sgd_solver.cpp:105] Iteration 950, lr = 0.005
I0621 10:42:14.005683 17579 solver.cpp:331] Iteration 1000, Testing net (#0)
I0621 10:42:25.988688 17579 solver.cpp:398]     Test net output #0: accuracy = 0.981373
I0621 10:42:25.988771 17579 solver.cpp:398]     Test net output #1: loss = 0.0801 (* 1 = 0.0801 loss)
I0621 10:42:27.399088 17579 solver.cpp:219] Iteration 1000 (0.604199 iter/s, 82.7542s/50 iters), loss = 0.00375916
I0621 10:42:27.399176 17579 solver.cpp:238]     Train net output #0: loss = 0.00998058 (* 1 = 0.00998058 loss)
I0621 10:42:27.399202 17579 sgd_solver.cpp:105] Iteration 1000, lr = 0.005
I0621 10:43:38.178539 17579 solver.cpp:219] Iteration 1050 (0.706429 iter/s, 70.7785s/50 iters), loss = 0.00361036
I0621 10:43:38.178743 17579 solver.cpp:238]     Train net output #0: loss = 0.00326565 (* 1 = 0.00326565 loss)
I0621 10:43:38.178776 17579 sgd_solver.cpp:105] Iteration 1050, lr = 0.005
I0621 10:44:49.088857 17579 solver.cpp:219] Iteration 1100 (0.705126 iter/s, 70.9093s/50 iters), loss = 0.00323511
I0621 10:44:49.100610 17579 solver.cpp:238]     Train net output #0: loss = 0.00133619 (* 1 = 0.00133619 loss)
I0621 10:44:49.100644 17579 sgd_solver.cpp:105] Iteration 1100, lr = 0.005
I0621 10:46:00.275650 17579 solver.cpp:219] Iteration 1150 (0.702502 iter/s, 71.1742s/50 iters), loss = 0.00350351
I0621 10:46:00.275889 17579 solver.cpp:238]     Train net output #0: loss = 0.00330711 (* 1 = 0.00330711 loss)
I0621 10:46:00.275923 17579 sgd_solver.cpp:105] Iteration 1150, lr = 0.005
I0621 10:47:11.352063 17579 solver.cpp:219] Iteration 1200 (0.703479 iter/s, 71.0753s/50 iters), loss = 0.00246008
I0621 10:47:11.352672 17579 solver.cpp:238]     Train net output #0: loss = 0.00305691 (* 1 = 0.00305691 loss)
I0621 10:47:11.352705 17579 sgd_solver.cpp:105] Iteration 1200, lr = 0.005
I0621 10:48:24.191323 17579 solver.cpp:219] Iteration 1250 (0.686457 iter/s, 72.8378s/50 iters), loss = 0.00288219
I0621 10:48:24.191457 17579 solver.cpp:238]     Train net output #0: loss = 0.000543677 (* 1 = 0.000543677 loss)
I0621 10:48:24.191484 17579 sgd_solver.cpp:105] Iteration 1250, lr = 0.005
I0621 10:49:35.134433 17579 solver.cpp:219] Iteration 1300 (0.7048 iter/s, 70.9422s/50 iters), loss = 0.00178636
I0621 10:49:35.134577 17579 solver.cpp:238]     Train net output #0: loss = 0.00166084 (* 1 = 0.00166084 loss)
I0621 10:49:35.134608 17579 sgd_solver.cpp:105] Iteration 1300, lr = 0.005
I0621 10:50:45.960974 17579 solver.cpp:219] Iteration 1350 (0.70596 iter/s, 70.8256s/50 iters), loss = 0.00232611
I0621 10:50:45.961233 17579 solver.cpp:238]     Train net output #0: loss = 0.00188831 (* 1 = 0.00188831 loss)
I0621 10:50:45.961264 17579 sgd_solver.cpp:105] Iteration 1350, lr = 0.005
I0621 10:51:56.739425 17579 solver.cpp:219] Iteration 1400 (0.70644 iter/s, 70.7774s/50 iters), loss = 0.00237317
I0621 10:51:56.739576 17579 solver.cpp:238]     Train net output #0: loss = 0.000683278 (* 1 = 0.000683278 loss)
I0621 10:51:56.739606 17579 sgd_solver.cpp:105] Iteration 1400, lr = 0.005
I0621 10:53:07.516433 17579 solver.cpp:219] Iteration 1450 (0.706454 iter/s, 70.776s/50 iters), loss = 0.00360784
I0621 10:53:07.516563 17579 solver.cpp:238]     Train net output #0: loss = 0.0025374 (* 1 = 0.0025374 loss)
I0621 10:53:07.516592 17579 sgd_solver.cpp:105] Iteration 1450, lr = 0.005
I0621 10:54:16.871975 17579 solver.cpp:331] Iteration 1500, Testing net (#0)
I0621 10:54:28.826233 17579 solver.cpp:398]     Test net output #0: accuracy = 0.978432
I0621 10:54:28.826319 17579 solver.cpp:398]     Test net output #1: loss = 0.0796045 (* 1 = 0.0796045 loss)
I0621 10:54:28.833654 17579 compress_conv_layer.cu:174] 0.256708 1.92267e-10 0.988232
I0621 10:54:28.842281 17579 compress_conv_layer.cu:174] 0.256708 1.17273e-10 0.577459
I0621 10:54:28.850589 17579 compress_conv_layer.cu:174] 0.256708 2.10701e-11 0.774643
I0621 10:54:28.858767 17579 compress_conv_layer.cu:174] 0.256708 3.20917e-12 0.816825
I0621 10:54:28.871445 17579 compress_conv_layer.cu:174] 0.256708 1.02482e-11 0.476563
I0621 10:54:28.893581 17579 compress_conv_layer.cu:174] 0.256708 9.83155e-14 0.504837
I0621 10:54:28.937786 17579 compress_conv_layer.cu:174] 0.256708 1.78567e-13 0.497844
I0621 10:54:28.980641 17579 compress_conv_layer.cu:174] 0.256708 2.27382e-12 0.422231
I0621 10:54:29.024399 17579 compress_conv_layer.cu:174] 0.256708 1.97597e-12 0.447553
I0621 10:54:29.067483 17579 compress_conv_layer.cu:174] 0.256708 2.07694e-12 0.602392
I0621 10:54:29.110035 17579 compress_conv_layer.cu:174] 0.256708 5.71992e-12 0.47774
I0621 10:54:29.198508 17579 compress_conv_layer.cu:174] 0.256708 1.7108e-12 0.34324
I0621 10:54:29.384891 17579 compress_conv_layer.cu:174] 0.256708 3.52393e-12 0.305477
I0621 10:54:29.408268 17579 compress_conv_layer.cu:174] 0.256708 3.27687e-07 0.175541
I0621 10:54:29.646517 17579 compress_conv_layer.cu:174] 0.256708 1.92267e-10 0.988232
I0621 10:54:29.654485 17579 compress_conv_layer.cu:174] 0.256708 1.17273e-10 0.577459
I0621 10:54:29.662755 17579 compress_conv_layer.cu:174] 0.256708 2.10701e-11 0.774643
I0621 10:54:29.670811 17579 compress_conv_layer.cu:174] 0.256708 3.20917e-12 0.816825
I0621 10:54:29.683267 17579 compress_conv_layer.cu:174] 0.256708 1.02482e-11 0.476563
I0621 10:54:29.704955 17579 compress_conv_layer.cu:174] 0.256708 9.83155e-14 0.504837
I0621 10:54:29.749063 17579 compress_conv_layer.cu:174] 0.256708 1.78567e-13 0.497844
I0621 10:54:29.791759 17579 compress_conv_layer.cu:174] 0.256708 2.27382e-12 0.422231
I0621 10:54:29.834635 17579 compress_conv_layer.cu:174] 0.256708 1.97597e-12 0.447553
I0621 10:54:29.878000 17579 compress_conv_layer.cu:174] 0.256708 2.07694e-12 0.602392
I0621 10:54:29.920351 17579 compress_conv_layer.cu:174] 0.256708 5.71992e-12 0.47774
I0621 10:54:30.009865 17579 compress_conv_layer.cu:174] 0.256708 1.7108e-12 0.34324
I0621 10:54:30.196101 17579 compress_conv_layer.cu:174] 0.256708 3.52393e-12 0.305477
I0621 10:54:30.219852 17579 compress_conv_layer.cu:174] 0.256708 3.27687e-07 0.175541
I0621 10:54:30.458076 17579 compress_conv_layer.cu:174] 0.256708 1.92267e-10 0.988232
I0621 10:54:30.466037 17579 compress_conv_layer.cu:174] 0.256708 1.17273e-10 0.577459
I0621 10:54:30.474285 17579 compress_conv_layer.cu:174] 0.256708 2.10701e-11 0.774643
I0621 10:54:30.482367 17579 compress_conv_layer.cu:174] 0.256708 3.20917e-12 0.816825
I0621 10:54:30.494874 17579 compress_conv_layer.cu:174] 0.256708 1.02482e-11 0.476563
I0621 10:54:30.516517 17579 compress_conv_layer.cu:174] 0.256708 9.83155e-14 0.504837
I0621 10:54:30.560586 17579 compress_conv_layer.cu:174] 0.256708 1.78567e-13 0.497844
I0621 10:54:30.602967 17579 compress_conv_layer.cu:174] 0.256708 2.27382e-12 0.422231
I0621 10:54:30.645748 17579 compress_conv_layer.cu:174] 0.256708 1.97597e-12 0.447553
I0621 10:54:30.688304 17579 compress_conv_layer.cu:174] 0.256708 2.07694e-12 0.602392
I0621 10:54:30.730578 17579 compress_conv_layer.cu:174] 0.256708 5.71992e-12 0.47774
I0621 10:54:30.819205 17579 compress_conv_layer.cu:174] 0.256708 1.7108e-12 0.34324
I0621 10:54:31.005511 17579 compress_conv_layer.cu:174] 0.256708 3.52393e-12 0.305477
I0621 10:54:31.029062 17579 compress_conv_layer.cu:174] 0.256708 3.27687e-07 0.175541
I0621 10:54:31.267354 17579 compress_conv_layer.cu:174] 0.256708 1.92267e-10 0.988232
I0621 10:54:31.275295 17579 compress_conv_layer.cu:174] 0.256708 1.17273e-10 0.577459
I0621 10:54:31.283574 17579 compress_conv_layer.cu:174] 0.256708 2.10701e-11 0.774643
I0621 10:54:31.291823 17579 compress_conv_layer.cu:174] 0.256708 3.20917e-12 0.816825
I0621 10:54:31.304347 17579 compress_conv_layer.cu:174] 0.256708 1.02482e-11 0.476563
I0621 10:54:31.326064 17579 compress_conv_layer.cu:174] 0.256708 9.83155e-14 0.504837
I0621 10:54:31.370235 17579 compress_conv_layer.cu:174] 0.256708 1.78567e-13 0.497844
I0621 10:54:31.412894 17579 compress_conv_layer.cu:174] 0.256708 2.27382e-12 0.422231
I0621 10:54:31.455807 17579 compress_conv_layer.cu:174] 0.256708 1.97597e-12 0.447553
I0621 10:54:31.498205 17579 compress_conv_layer.cu:174] 0.256708 2.07694e-12 0.602392
I0621 10:54:31.540474 17579 compress_conv_layer.cu:174] 0.256708 5.71992e-12 0.47774
I0621 10:54:31.628968 17579 compress_conv_layer.cu:174] 0.256708 1.7108e-12 0.34324
I0621 10:54:31.814932 17579 compress_conv_layer.cu:174] 0.256708 3.52393e-12 0.305477
I0621 10:54:31.838459 17579 compress_conv_layer.cu:174] 0.256708 3.27687e-07 0.175541
I0621 10:54:32.076777 17579 compress_conv_layer.cu:174] 0.256708 1.92267e-10 0.988232
I0621 10:54:32.084753 17579 compress_conv_layer.cu:174] 0.256708 1.17273e-10 0.577459
I0621 10:54:32.093024 17579 compress_conv_layer.cu:174] 0.256708 2.10701e-11 0.774643
I0621 10:54:32.101084 17579 compress_conv_layer.cu:174] 0.256708 3.20917e-12 0.816825
I0621 10:54:32.113585 17579 compress_conv_layer.cu:174] 0.256708 1.02482e-11 0.476563
I0621 10:54:32.135299 17579 compress_conv_layer.cu:174] 0.256708 9.83155e-14 0.504837
I0621 10:54:32.179553 17579 compress_conv_layer.cu:174] 0.256708 1.78567e-13 0.497844
I0621 10:54:32.222057 17579 compress_conv_layer.cu:174] 0.256708 2.27382e-12 0.422231
I0621 10:54:32.264737 17579 compress_conv_layer.cu:174] 0.256708 1.97597e-12 0.447553
I0621 10:54:32.307972 17579 compress_conv_layer.cu:174] 0.256708 2.07694e-12 0.602392
I0621 10:54:32.350430 17579 compress_conv_layer.cu:174] 0.256708 5.71992e-12 0.47774
I0621 10:54:32.439548 17579 compress_conv_layer.cu:174] 0.256708 1.7108e-12 0.34324
I0621 10:54:32.628309 17579 compress_conv_layer.cu:174] 0.256708 3.52393e-12 0.305477
I0621 10:54:32.651763 17579 compress_conv_layer.cu:174] 0.256708 3.27687e-07 0.175541
I0621 10:54:32.882136 17579 solver.cpp:219] Iteration 1500 (0.585723 iter/s, 85.3646s/50 iters), loss = 0.00318467
I0621 10:54:32.882197 17579 solver.cpp:238]     Train net output #0: loss = 0.0019117 (* 1 = 0.0019117 loss)
I0621 10:54:32.882222 17579 sgd_solver.cpp:105] Iteration 1500, lr = 0.005
I0621 10:55:43.658053 17579 solver.cpp:219] Iteration 1550 (0.706464 iter/s, 70.775s/50 iters), loss = 0.00384466
I0621 10:55:43.658252 17579 solver.cpp:238]     Train net output #0: loss = 0.00124677 (* 1 = 0.00124677 loss)
I0621 10:55:43.658282 17579 sgd_solver.cpp:105] Iteration 1550, lr = 0.005
I0621 10:56:54.426785 17579 solver.cpp:219] Iteration 1600 (0.706537 iter/s, 70.7677s/50 iters), loss = 0.00348278
I0621 10:56:54.426928 17579 solver.cpp:238]     Train net output #0: loss = 0.00473383 (* 1 = 0.00473383 loss)
I0621 10:56:54.426955 17579 sgd_solver.cpp:105] Iteration 1600, lr = 0.005
I0621 10:58:05.359519 17579 solver.cpp:219] Iteration 1650 (0.704903 iter/s, 70.9318s/50 iters), loss = 0.00453439
I0621 10:58:05.359668 17579 solver.cpp:238]     Train net output #0: loss = 0.00365012 (* 1 = 0.00365012 loss)
I0621 10:58:05.359711 17579 sgd_solver.cpp:105] Iteration 1650, lr = 0.005
I0621 10:59:19.108211 17579 solver.cpp:219] Iteration 1700 (0.677987 iter/s, 73.7477s/50 iters), loss = 0.00313698
I0621 10:59:19.108357 17579 solver.cpp:238]     Train net output #0: loss = 0.00280209 (* 1 = 0.00280209 loss)
I0621 10:59:19.108386 17579 sgd_solver.cpp:105] Iteration 1700, lr = 0.005
I0621 11:00:29.940860 17579 solver.cpp:219] Iteration 1750 (0.705899 iter/s, 70.8317s/50 iters), loss = 0.0038013
I0621 11:00:29.941018 17579 solver.cpp:238]     Train net output #0: loss = 0.00253193 (* 1 = 0.00253193 loss)
I0621 11:00:29.941047 17579 sgd_solver.cpp:105] Iteration 1750, lr = 0.005
I0621 11:01:40.730206 17579 solver.cpp:219] Iteration 1800 (0.706331 iter/s, 70.7884s/50 iters), loss = 0.00226297
I0621 11:01:40.730371 17579 solver.cpp:238]     Train net output #0: loss = 0.00495922 (* 1 = 0.00495922 loss)
I0621 11:01:40.730399 17579 sgd_solver.cpp:105] Iteration 1800, lr = 0.005
I0621 11:02:51.532446 17579 solver.cpp:219] Iteration 1850 (0.706203 iter/s, 70.8011s/50 iters), loss = 0.00168427
I0621 11:02:51.532575 17579 solver.cpp:238]     Train net output #0: loss = 0.00242555 (* 1 = 0.00242555 loss)
I0621 11:02:51.532603 17579 sgd_solver.cpp:105] Iteration 1850, lr = 0.005
I0621 11:04:02.449509 17579 solver.cpp:219] Iteration 1900 (0.70506 iter/s, 70.9159s/50 iters), loss = 0.00342022
I0621 11:04:02.449653 17579 solver.cpp:238]     Train net output #0: loss = 0.00363783 (* 1 = 0.00363783 loss)
I0621 11:04:02.449682 17579 sgd_solver.cpp:105] Iteration 1900, lr = 0.005
I0621 11:05:13.300961 17579 solver.cpp:219] Iteration 1950 (0.705713 iter/s, 70.8503s/50 iters), loss = 0.00479966
I0621 11:05:13.301192 17579 solver.cpp:238]     Train net output #0: loss = 0.00108724 (* 1 = 0.00108724 loss)
I0621 11:05:13.301223 17579 sgd_solver.cpp:105] Iteration 1950, lr = 0.005
I0621 11:06:22.742736 17579 solver.cpp:331] Iteration 2000, Testing net (#0)
I0621 11:06:34.795357 17579 solver.cpp:398]     Test net output #0: accuracy = 0.979412
I0621 11:06:34.795441 17579 solver.cpp:398]     Test net output #1: loss = 0.0765914 (* 1 = 0.0765914 loss)
I0621 11:06:36.207080 17579 solver.cpp:219] Iteration 2000 (0.603102 iter/s, 82.9047s/50 iters), loss = 0.00198209
I0621 11:06:36.207209 17579 solver.cpp:238]     Train net output #0: loss = 0.00124191 (* 1 = 0.00124191 loss)
I0621 11:06:36.207237 17579 sgd_solver.cpp:105] Iteration 2000, lr = 0.005
I0621 11:07:47.041121 17579 solver.cpp:219] Iteration 2050 (0.705886 iter/s, 70.8329s/50 iters), loss = 0.00273628
I0621 11:07:47.041357 17579 solver.cpp:238]     Train net output #0: loss = 0.0015951 (* 1 = 0.0015951 loss)
I0621 11:07:47.041386 17579 sgd_solver.cpp:105] Iteration 2050, lr = 0.005
I0621 11:08:57.913743 17579 solver.cpp:219] Iteration 2100 (0.705503 iter/s, 70.8714s/50 iters), loss = 0.00381171
I0621 11:08:57.913925 17579 solver.cpp:238]     Train net output #0: loss = 0.00348343 (* 1 = 0.00348343 loss)
I0621 11:08:57.913957 17579 sgd_solver.cpp:105] Iteration 2100, lr = 0.005
I0621 11:10:11.957725 17579 solver.cpp:219] Iteration 2150 (0.675285 iter/s, 74.0428s/50 iters), loss = 0.00301176
I0621 11:10:11.958591 17579 solver.cpp:238]     Train net output #0: loss = 0.0040778 (* 1 = 0.0040778 loss)
I0621 11:10:11.958619 17579 sgd_solver.cpp:105] Iteration 2150, lr = 0.005
I0621 11:11:22.957422 17579 solver.cpp:219] Iteration 2200 (0.704247 iter/s, 70.9978s/50 iters), loss = 0.00318138
I0621 11:11:22.960741 17579 solver.cpp:238]     Train net output #0: loss = 0.00385909 (* 1 = 0.00385909 loss)
I0621 11:11:22.960777 17579 sgd_solver.cpp:105] Iteration 2200, lr = 0.005
I0621 11:12:33.829778 17579 solver.cpp:219] Iteration 2250 (0.705536 iter/s, 70.8681s/50 iters), loss = 0.00264048
I0621 11:12:33.829918 17579 solver.cpp:238]     Train net output #0: loss = 0.00240174 (* 1 = 0.00240174 loss)
I0621 11:12:33.829946 17579 sgd_solver.cpp:105] Iteration 2250, lr = 0.005
I0621 11:13:44.685468 17579 solver.cpp:219] Iteration 2300 (0.705671 iter/s, 70.8546s/50 iters), loss = 0.00302617
I0621 11:13:44.685654 17579 solver.cpp:238]     Train net output #0: loss = 0.00516005 (* 1 = 0.00516005 loss)
I0621 11:13:44.685699 17579 sgd_solver.cpp:105] Iteration 2300, lr = 0.005
I0621 11:14:58.573740 17579 solver.cpp:219] Iteration 2350 (0.676708 iter/s, 73.8871s/50 iters), loss = 0.00305715
I0621 11:14:58.577286 17579 solver.cpp:238]     Train net output #0: loss = 0.00202245 (* 1 = 0.00202245 loss)
I0621 11:14:58.577317 17579 sgd_solver.cpp:105] Iteration 2350, lr = 0.005
I0621 11:16:09.607087 17579 solver.cpp:219] Iteration 2400 (0.70394 iter/s, 71.0288s/50 iters), loss = 0.00504588
I0621 11:16:09.607270 17579 solver.cpp:238]     Train net output #0: loss = 0.00272387 (* 1 = 0.00272387 loss)
I0621 11:16:09.607300 17579 sgd_solver.cpp:105] Iteration 2400, lr = 0.005
I0621 11:17:20.592267 17579 solver.cpp:219] Iteration 2450 (0.704384 iter/s, 70.984s/50 iters), loss = 0.00207316
I0621 11:17:20.592435 17579 solver.cpp:238]     Train net output #0: loss = 0.00148312 (* 1 = 0.00148312 loss)
I0621 11:17:20.592464 17579 sgd_solver.cpp:105] Iteration 2450, lr = 0.005
I0621 11:18:30.016310 17579 solver.cpp:331] Iteration 2500, Testing net (#0)
I0621 11:18:42.453972 17579 solver.cpp:398]     Test net output #0: accuracy = 0.979412
I0621 11:18:42.454077 17579 solver.cpp:398]     Test net output #1: loss = 0.0788729 (* 1 = 0.0788729 loss)
I0621 11:18:43.915012 17579 solver.cpp:219] Iteration 2500 (0.600085 iter/s, 83.3215s/50 iters), loss = 0.00197618
I0621 11:18:43.915138 17579 solver.cpp:238]     Train net output #0: loss = 0.00192447 (* 1 = 0.00192447 loss)
I0621 11:18:43.915169 17579 sgd_solver.cpp:105] Iteration 2500, lr = 0.005
I0621 11:19:54.876593 17579 solver.cpp:219] Iteration 2550 (0.704617 iter/s, 70.9605s/50 iters), loss = 0.0035142
I0621 11:19:54.876740 17579 solver.cpp:238]     Train net output #0: loss = 0.00137651 (* 1 = 0.00137651 loss)
I0621 11:19:54.876771 17579 sgd_solver.cpp:105] Iteration 2550, lr = 0.005
I0621 11:21:05.644167 17579 solver.cpp:219] Iteration 2600 (0.706549 iter/s, 70.7665s/50 iters), loss = 0.0024317
I0621 11:21:05.644387 17579 solver.cpp:238]     Train net output #0: loss = 0.00320017 (* 1 = 0.00320017 loss)
I0621 11:21:05.644415 17579 sgd_solver.cpp:105] Iteration 2600, lr = 0.005
I0621 11:22:16.442881 17579 solver.cpp:219] Iteration 2650 (0.706239 iter/s, 70.7975s/50 iters), loss = 0.00118596
I0621 11:22:16.443058 17579 solver.cpp:238]     Train net output #0: loss = 0.00230695 (* 1 = 0.00230695 loss)
I0621 11:22:16.443087 17579 sgd_solver.cpp:105] Iteration 2650, lr = 0.005
I0621 11:23:27.241044 17579 solver.cpp:219] Iteration 2700 (0.706244 iter/s, 70.797s/50 iters), loss = 0.00224027
I0621 11:23:27.241181 17579 solver.cpp:238]     Train net output #0: loss = 0.00101309 (* 1 = 0.00101309 loss)
I0621 11:23:27.241210 17579 sgd_solver.cpp:105] Iteration 2700, lr = 0.005
I0621 11:24:38.356299 17579 solver.cpp:219] Iteration 2750 (0.703095 iter/s, 71.1142s/50 iters), loss = 0.00194309
I0621 11:24:38.356453 17579 solver.cpp:238]     Train net output #0: loss = 0.00150482 (* 1 = 0.00150482 loss)
I0621 11:24:38.356482 17579 sgd_solver.cpp:105] Iteration 2750, lr = 0.005
I0621 11:25:50.375216 17579 solver.cpp:219] Iteration 2800 (0.694273 iter/s, 72.0178s/50 iters), loss = 0.00222996
I0621 11:25:50.378028 17579 solver.cpp:238]     Train net output #0: loss = 0.00142453 (* 1 = 0.00142453 loss)
I0621 11:25:50.378059 17579 sgd_solver.cpp:105] Iteration 2800, lr = 0.005
I0621 11:27:02.835213 17579 solver.cpp:219] Iteration 2850 (0.690072 iter/s, 72.4562s/50 iters), loss = 0.00200228
I0621 11:27:02.835376 17579 solver.cpp:238]     Train net output #0: loss = 0.00178959 (* 1 = 0.00178959 loss)
I0621 11:27:02.835407 17579 sgd_solver.cpp:105] Iteration 2850, lr = 0.005
I0621 11:28:13.633980 17579 solver.cpp:219] Iteration 2900 (0.706238 iter/s, 70.7977s/50 iters), loss = 0.002385
I0621 11:28:13.634131 17579 solver.cpp:238]     Train net output #0: loss = 0.00210367 (* 1 = 0.00210367 loss)
I0621 11:28:13.634160 17579 sgd_solver.cpp:105] Iteration 2900, lr = 0.005
I0621 11:29:24.464977 17579 solver.cpp:219] Iteration 2950 (0.705917 iter/s, 70.8298s/50 iters), loss = 0.00258718
I0621 11:29:24.470702 17579 solver.cpp:238]     Train net output #0: loss = 0.00232405 (* 1 = 0.00232405 loss)
I0621 11:29:24.470748 17579 sgd_solver.cpp:105] Iteration 2950, lr = 0.005
I0621 11:29:59.794683 17579 blocking_queue.cpp:49] Waiting for data
I0621 11:30:39.850298 17579 solver.cpp:331] Iteration 3000, Testing net (#0)
I0621 11:30:51.866484 17579 solver.cpp:398]     Test net output #0: accuracy = 0.981373
I0621 11:30:51.866562 17579 solver.cpp:398]     Test net output #1: loss = 0.0786779 (* 1 = 0.0786779 loss)
I0621 11:30:51.873914 17579 compress_conv_layer.cu:174] 0.323929 1.91538e-10 0.984637
I0621 11:30:51.882542 17579 compress_conv_layer.cu:174] 0.323929 1.16836e-10 0.575422
I0621 11:30:51.890841 17579 compress_conv_layer.cu:174] 0.323929 2.0992e-11 0.7717
I0621 11:30:51.899112 17579 compress_conv_layer.cu:174] 0.323929 3.19713e-12 0.813866
I0621 11:30:51.911861 17579 compress_conv_layer.cu:174] 0.323929 1.021e-11 0.474899
I0621 11:30:51.934032 17579 compress_conv_layer.cu:174] 0.323929 9.79496e-14 0.503016
I0621 11:30:51.978265 17579 compress_conv_layer.cu:174] 0.323929 1.77896e-13 0.495882
I0621 11:30:52.021854 17579 compress_conv_layer.cu:174] 0.323929 2.26536e-12 0.420632
I0621 11:30:52.065817 17579 compress_conv_layer.cu:174] 0.323929 1.96849e-12 0.446094
I0621 11:30:52.109310 17579 compress_conv_layer.cu:174] 0.323929 2.06914e-12 0.599952
I0621 11:30:52.152776 17579 compress_conv_layer.cu:174] 0.323929 5.69845e-12 0.475767
I0621 11:30:52.242559 17579 compress_conv_layer.cu:174] 0.323929 1.70446e-12 0.341791
I0621 11:30:52.429148 17579 compress_conv_layer.cu:174] 0.323929 3.51064e-12 0.304287
I0621 11:30:52.453347 17579 compress_conv_layer.cu:174] 0.323929 3.26451e-07 0.176893
I0621 11:30:52.691534 17579 compress_conv_layer.cu:174] 0.323929 1.91538e-10 0.984637
I0621 11:30:52.699508 17579 compress_conv_layer.cu:174] 0.323929 1.16836e-10 0.575422
I0621 11:30:52.707734 17579 compress_conv_layer.cu:174] 0.323929 2.0992e-11 0.7717
I0621 11:30:52.715838 17579 compress_conv_layer.cu:174] 0.323929 3.19713e-12 0.813866
I0621 11:30:52.728298 17579 compress_conv_layer.cu:174] 0.323929 1.021e-11 0.474899
I0621 11:30:52.749855 17579 compress_conv_layer.cu:174] 0.323929 9.79496e-14 0.503016
I0621 11:30:52.795024 17579 compress_conv_layer.cu:174] 0.323929 1.77896e-13 0.495882
I0621 11:30:52.838434 17579 compress_conv_layer.cu:174] 0.323929 2.26536e-12 0.420632
I0621 11:30:52.881937 17579 compress_conv_layer.cu:174] 0.323929 1.96849e-12 0.446094
I0621 11:30:52.924908 17579 compress_conv_layer.cu:174] 0.323929 2.06914e-12 0.599952
I0621 11:30:52.967212 17579 compress_conv_layer.cu:174] 0.323929 5.69845e-12 0.475767
I0621 11:30:53.056591 17579 compress_conv_layer.cu:174] 0.323929 1.70446e-12 0.341791
I0621 11:30:53.243913 17579 compress_conv_layer.cu:174] 0.323929 3.51064e-12 0.304287
I0621 11:30:53.267706 17579 compress_conv_layer.cu:174] 0.323929 3.26451e-07 0.176893
I0621 11:30:53.505990 17579 compress_conv_layer.cu:174] 0.323929 1.91538e-10 0.984637
I0621 11:30:53.513954 17579 compress_conv_layer.cu:174] 0.323929 1.16836e-10 0.575422
I0621 11:30:53.522195 17579 compress_conv_layer.cu:174] 0.323929 2.0992e-11 0.7717
I0621 11:30:53.530277 17579 compress_conv_layer.cu:174] 0.323929 3.19713e-12 0.813866
I0621 11:30:53.542748 17579 compress_conv_layer.cu:174] 0.323929 1.021e-11 0.474899
I0621 11:30:53.564263 17579 compress_conv_layer.cu:174] 0.323929 9.79496e-14 0.503016
I0621 11:30:53.608294 17579 compress_conv_layer.cu:174] 0.323929 1.77896e-13 0.495882
I0621 11:30:53.651358 17579 compress_conv_layer.cu:174] 0.323929 2.26536e-12 0.420632
I0621 11:30:53.694437 17579 compress_conv_layer.cu:174] 0.323929 1.96849e-12 0.446094
I0621 11:30:53.737138 17579 compress_conv_layer.cu:174] 0.323929 2.06914e-12 0.599952
I0621 11:30:53.779422 17579 compress_conv_layer.cu:174] 0.323929 5.69845e-12 0.475767
I0621 11:30:53.868700 17579 compress_conv_layer.cu:174] 0.323929 1.70446e-12 0.341791
I0621 11:30:54.054767 17579 compress_conv_layer.cu:174] 0.323929 3.51064e-12 0.304287
I0621 11:30:54.078315 17579 compress_conv_layer.cu:174] 0.323929 3.26451e-07 0.176893
I0621 11:30:54.316679 17579 compress_conv_layer.cu:174] 0.323929 1.91538e-10 0.984637
I0621 11:30:54.324648 17579 compress_conv_layer.cu:174] 0.323929 1.16836e-10 0.575422
I0621 11:30:54.332883 17579 compress_conv_layer.cu:174] 0.323929 2.0992e-11 0.7717
I0621 11:30:54.340955 17579 compress_conv_layer.cu:174] 0.323929 3.19713e-12 0.813866
I0621 11:30:54.353449 17579 compress_conv_layer.cu:174] 0.323929 1.021e-11 0.474899
I0621 11:30:54.375282 17579 compress_conv_layer.cu:174] 0.323929 9.79496e-14 0.503016
I0621 11:30:54.419888 17579 compress_conv_layer.cu:174] 0.323929 1.77896e-13 0.495882
I0621 11:30:54.462954 17579 compress_conv_layer.cu:174] 0.323929 2.26536e-12 0.420632
I0621 11:30:54.505913 17579 compress_conv_layer.cu:174] 0.323929 1.96849e-12 0.446094
I0621 11:30:54.548336 17579 compress_conv_layer.cu:174] 0.323929 2.06914e-12 0.599952
I0621 11:30:54.590492 17579 compress_conv_layer.cu:174] 0.323929 5.69845e-12 0.475767
I0621 11:30:54.679620 17579 compress_conv_layer.cu:174] 0.323929 1.70446e-12 0.341791
I0621 11:30:54.865854 17579 compress_conv_layer.cu:174] 0.323929 3.51064e-12 0.304287
I0621 11:30:54.889482 17579 compress_conv_layer.cu:174] 0.323929 3.26451e-07 0.176893
I0621 11:30:55.127760 17579 compress_conv_layer.cu:174] 0.323929 1.91538e-10 0.984637
I0621 11:30:55.135679 17579 compress_conv_layer.cu:174] 0.323929 1.16836e-10 0.575422
I0621 11:30:55.143913 17579 compress_conv_layer.cu:174] 0.323929 2.0992e-11 0.7717
I0621 11:30:55.151975 17579 compress_conv_layer.cu:174] 0.323929 3.19713e-12 0.813866
I0621 11:30:55.164504 17579 compress_conv_layer.cu:174] 0.323929 1.021e-11 0.474899
I0621 11:30:55.186209 17579 compress_conv_layer.cu:174] 0.323929 9.79496e-14 0.503016
I0621 11:30:55.230407 17579 compress_conv_layer.cu:174] 0.323929 1.77896e-13 0.495882
I0621 11:30:55.273561 17579 compress_conv_layer.cu:174] 0.323929 2.26536e-12 0.420632
I0621 11:30:55.316892 17579 compress_conv_layer.cu:174] 0.323929 1.96849e-12 0.446094
I0621 11:30:55.360023 17579 compress_conv_layer.cu:174] 0.323929 2.06914e-12 0.599952
I0621 11:30:55.403005 17579 compress_conv_layer.cu:174] 0.323929 5.69845e-12 0.475767
I0621 11:30:55.492611 17579 compress_conv_layer.cu:174] 0.323929 1.70446e-12 0.341791
I0621 11:30:55.678119 17579 compress_conv_layer.cu:174] 0.323929 3.51064e-12 0.304287
I0621 11:30:55.701669 17579 compress_conv_layer.cu:174] 0.323929 3.26451e-07 0.176893
I0621 11:30:55.931864 17579 solver.cpp:219] Iteration 3000 (0.546687 iter/s, 91.46s/50 iters), loss = 0.00246997
I0621 11:30:55.931936 17579 solver.cpp:238]     Train net output #0: loss = 0.00187802 (* 1 = 0.00187802 loss)
I0621 11:30:55.931959 17579 sgd_solver.cpp:105] Iteration 3000, lr = 0.005
I0621 11:32:06.844420 17579 solver.cpp:219] Iteration 3050 (0.705104 iter/s, 70.9116s/50 iters), loss = 0.00391567
I0621 11:32:06.844624 17579 solver.cpp:238]     Train net output #0: loss = 0.00284487 (* 1 = 0.00284487 loss)
I0621 11:32:06.844653 17579 sgd_solver.cpp:105] Iteration 3050, lr = 0.005
I0621 11:33:17.644836 17579 solver.cpp:219] Iteration 3100 (0.706222 iter/s, 70.7993s/50 iters), loss = 0.00306193
I0621 11:33:17.645011 17579 solver.cpp:238]     Train net output #0: loss = 0.00387965 (* 1 = 0.00387965 loss)
I0621 11:33:17.645040 17579 sgd_solver.cpp:105] Iteration 3100, lr = 0.005
I0621 11:34:28.476788 17579 solver.cpp:219] Iteration 3150 (0.705907 iter/s, 70.8308s/50 iters), loss = 0.00315238
I0621 11:34:28.476927 17579 solver.cpp:238]     Train net output #0: loss = 0.00376621 (* 1 = 0.00376621 loss)
I0621 11:34:28.476954 17579 sgd_solver.cpp:105] Iteration 3150, lr = 0.005
I0621 11:35:39.249481 17579 solver.cpp:219] Iteration 3200 (0.706498 iter/s, 70.7716s/50 iters), loss = 0.00284357
I0621 11:35:39.249637 17579 solver.cpp:238]     Train net output #0: loss = 0.00155363 (* 1 = 0.00155363 loss)
I0621 11:35:39.249665 17579 sgd_solver.cpp:105] Iteration 3200, lr = 0.005
I0621 11:36:52.017904 17579 solver.cpp:219] Iteration 3250 (0.687123 iter/s, 72.7672s/50 iters), loss = 0.00308077
I0621 11:36:52.018497 17579 solver.cpp:238]     Train net output #0: loss = 0.00269208 (* 1 = 0.00269208 loss)
I0621 11:36:52.018539 17579 sgd_solver.cpp:105] Iteration 3250, lr = 0.005
I0621 11:38:09.425947 17579 solver.cpp:219] Iteration 3300 (0.645942 iter/s, 77.4063s/50 iters), loss = 0.00214618
I0621 11:38:09.426192 17579 solver.cpp:238]     Train net output #0: loss = 0.00178197 (* 1 = 0.00178197 loss)
I0621 11:38:09.426219 17579 sgd_solver.cpp:105] Iteration 3300, lr = 0.005
I0621 11:39:25.149216 17579 solver.cpp:219] Iteration 3350 (0.660311 iter/s, 75.7219s/50 iters), loss = 0.00290918
I0621 11:39:25.149425 17579 solver.cpp:238]     Train net output #0: loss = 0.00671448 (* 1 = 0.00671448 loss)
I0621 11:39:25.149456 17579 sgd_solver.cpp:105] Iteration 3350, lr = 0.005
I0621 11:40:41.457720 17579 solver.cpp:219] Iteration 3400 (0.655246 iter/s, 76.3072s/50 iters), loss = 0.0033154
I0621 11:40:41.461657 17579 solver.cpp:238]     Train net output #0: loss = 0.00503646 (* 1 = 0.00503646 loss)
I0621 11:40:41.461701 17579 sgd_solver.cpp:105] Iteration 3400, lr = 0.005
I0621 11:41:57.377038 17579 solver.cpp:219] Iteration 3450 (0.658637 iter/s, 75.9143s/50 iters), loss = 0.00117074
I0621 11:41:57.377652 17579 solver.cpp:238]     Train net output #0: loss = 0.00137553 (* 1 = 0.00137553 loss)
I0621 11:41:57.377737 17579 sgd_solver.cpp:105] Iteration 3450, lr = 0.005
I0621 11:43:06.818183 17579 solver.cpp:331] Iteration 3500, Testing net (#0)
I0621 11:43:18.783308 17579 solver.cpp:398]     Test net output #0: accuracy = 0.977451
I0621 11:43:18.783375 17579 solver.cpp:398]     Test net output #1: loss = 0.0797597 (* 1 = 0.0797597 loss)
I0621 11:43:20.195067 17579 solver.cpp:219] Iteration 3500 (0.603746 iter/s, 82.8162s/50 iters), loss = 0.00268359
I0621 11:43:20.195174 17579 solver.cpp:238]     Train net output #0: loss = 0.0036539 (* 1 = 0.0036539 loss)
I0621 11:43:20.195205 17579 sgd_solver.cpp:105] Iteration 3500, lr = 0.005
I0621 11:44:31.040814 17579 solver.cpp:219] Iteration 3550 (0.70577 iter/s, 70.8446s/50 iters), loss = 0.00355177
I0621 11:44:31.041023 17579 solver.cpp:238]     Train net output #0: loss = 0.00386827 (* 1 = 0.00386827 loss)
I0621 11:44:31.041051 17579 sgd_solver.cpp:105] Iteration 3550, lr = 0.005
I0621 11:45:42.348086 17579 solver.cpp:219] Iteration 3600 (0.701203 iter/s, 71.306s/50 iters), loss = 0.00166361
I0621 11:45:42.348256 17579 solver.cpp:238]     Train net output #0: loss = 0.00125095 (* 1 = 0.00125095 loss)
I0621 11:45:42.348284 17579 sgd_solver.cpp:105] Iteration 3600, lr = 0.005
I0621 11:46:53.201289 17579 solver.cpp:219] Iteration 3650 (0.705696 iter/s, 70.852s/50 iters), loss = 0.00323064
I0621 11:46:53.201423 17579 solver.cpp:238]     Train net output #0: loss = 0.0025709 (* 1 = 0.0025709 loss)
I0621 11:46:53.201453 17579 sgd_solver.cpp:105] Iteration 3650, lr = 0.005
I0621 11:48:04.027652 17579 solver.cpp:219] Iteration 3700 (0.705963 iter/s, 70.8252s/50 iters), loss = 0.0020727
I0621 11:48:04.027818 17579 solver.cpp:238]     Train net output #0: loss = 0.00173863 (* 1 = 0.00173863 loss)
I0621 11:48:04.027850 17579 sgd_solver.cpp:105] Iteration 3700, lr = 0.005
I0621 11:49:14.824316 17579 solver.cpp:219] Iteration 3750 (0.70626 iter/s, 70.7955s/50 iters), loss = 0.00310863
I0621 11:49:14.824462 17579 solver.cpp:238]     Train net output #0: loss = 0.00247835 (* 1 = 0.00247835 loss)
I0621 11:49:14.824491 17579 sgd_solver.cpp:105] Iteration 3750, lr = 0.005
I0621 11:50:25.594763 17579 solver.cpp:219] Iteration 3800 (0.706521 iter/s, 70.7693s/50 iters), loss = 0.00179716
I0621 11:50:25.594902 17579 solver.cpp:238]     Train net output #0: loss = 0.0010411 (* 1 = 0.0010411 loss)
I0621 11:50:25.594931 17579 sgd_solver.cpp:105] Iteration 3800, lr = 0.005
I0621 11:51:36.386308 17579 solver.cpp:219] Iteration 3850 (0.706311 iter/s, 70.7904s/50 iters), loss = 0.00304764
I0621 11:51:36.386495 17579 solver.cpp:238]     Train net output #0: loss = 0.00522496 (* 1 = 0.00522496 loss)
I0621 11:51:36.386533 17579 sgd_solver.cpp:105] Iteration 3850, lr = 0.005
I0621 11:52:47.165462 17579 solver.cpp:219] Iteration 3900 (0.706434 iter/s, 70.778s/50 iters), loss = 0.00294836
I0621 11:52:47.165632 17579 solver.cpp:238]     Train net output #0: loss = 0.005756 (* 1 = 0.005756 loss)
I0621 11:52:47.165662 17579 sgd_solver.cpp:105] Iteration 3900, lr = 0.005
I0621 11:53:57.951894 17579 solver.cpp:219] Iteration 3950 (0.70636 iter/s, 70.7854s/50 iters), loss = 0.00168945
I0621 11:53:57.952044 17579 solver.cpp:238]     Train net output #0: loss = 0.00105897 (* 1 = 0.00105897 loss)
I0621 11:53:57.952074 17579 sgd_solver.cpp:105] Iteration 3950, lr = 0.005
I0621 11:55:07.331409 17579 solver.cpp:448] Snapshotting to binary proto file mobilenet/mobile_pruning_iter_4000.caffemodel
I0621 11:55:07.491160 17579 sgd_solver.cpp:273] Snapshotting solver state to binary proto file mobilenet/mobile_pruning_iter_4000.solverstate
I0621 11:55:07.547739 17579 solver.cpp:331] Iteration 4000, Testing net (#0)
I0621 11:55:19.545940 17579 solver.cpp:398]     Test net output #0: accuracy = 0.982353
I0621 11:55:19.546025 17579 solver.cpp:398]     Test net output #1: loss = 0.0770386 (* 1 = 0.0770386 loss)
I0621 11:55:20.957375 17579 solver.cpp:219] Iteration 4000 (0.602378 iter/s, 83.0044s/50 iters), loss = 0.00327334
I0621 11:55:20.957473 17579 solver.cpp:238]     Train net output #0: loss = 0.00921942 (* 1 = 0.00921942 loss)
I0621 11:55:20.957504 17579 sgd_solver.cpp:105] Iteration 4000, lr = 0.005
I0621 11:56:31.745682 17579 solver.cpp:219] Iteration 4050 (0.70634 iter/s, 70.7874s/50 iters), loss = 0.0028533
I0621 11:56:31.745833 17579 solver.cpp:238]     Train net output #0: loss = 0.00445091 (* 1 = 0.00445091 loss)
I0621 11:56:31.745862 17579 sgd_solver.cpp:105] Iteration 4050, lr = 0.005
I0621 11:57:42.521642 17579 solver.cpp:219] Iteration 4100 (0.706464 iter/s, 70.775s/50 iters), loss = 0.00302006
I0621 11:57:42.521795 17579 solver.cpp:238]     Train net output #0: loss = 0.00160178 (* 1 = 0.00160178 loss)
I0621 11:57:42.521822 17579 sgd_solver.cpp:105] Iteration 4100, lr = 0.005
I0621 11:58:53.304738 17579 solver.cpp:219] Iteration 4150 (0.706393 iter/s, 70.7821s/50 iters), loss = 0.00213103
I0621 11:58:53.304939 17579 solver.cpp:238]     Train net output #0: loss = 0.00253607 (* 1 = 0.00253607 loss)
I0621 11:58:53.304968 17579 sgd_solver.cpp:105] Iteration 4150, lr = 0.005
I0621 12:00:04.241652 17579 solver.cpp:219] Iteration 4200 (0.704862 iter/s, 70.9359s/50 iters), loss = 0.00262985
I0621 12:00:04.243463 17579 solver.cpp:238]     Train net output #0: loss = 0.00105525 (* 1 = 0.00105525 loss)
I0621 12:00:04.243491 17579 sgd_solver.cpp:105] Iteration 4200, lr = 0.005
I0621 12:01:15.041491 17579 solver.cpp:219] Iteration 4250 (0.706242 iter/s, 70.7972s/50 iters), loss = 0.00235682
I0621 12:01:15.041651 17579 solver.cpp:238]     Train net output #0: loss = 0.00142185 (* 1 = 0.00142185 loss)
I0621 12:01:15.041679 17579 sgd_solver.cpp:105] Iteration 4250, lr = 0.005
I0621 12:02:25.840332 17579 solver.cpp:219] Iteration 4300 (0.706236 iter/s, 70.7979s/50 iters), loss = 0.00219455
I0621 12:02:25.840487 17579 solver.cpp:238]     Train net output #0: loss = 0.000576983 (* 1 = 0.000576983 loss)
I0621 12:02:25.840523 17579 sgd_solver.cpp:105] Iteration 4300, lr = 0.005
I0621 12:03:36.629597 17579 solver.cpp:219] Iteration 4350 (0.706331 iter/s, 70.7883s/50 iters), loss = 0.00229253
I0621 12:03:36.629765 17579 solver.cpp:238]     Train net output #0: loss = 0.000486601 (* 1 = 0.000486601 loss)
I0621 12:03:36.629794 17579 sgd_solver.cpp:105] Iteration 4350, lr = 0.005
I0621 12:04:47.408718 17579 solver.cpp:219] Iteration 4400 (0.706433 iter/s, 70.7781s/50 iters), loss = 0.00175551
I0621 12:04:47.408880 17579 solver.cpp:238]     Train net output #0: loss = 0.00121612 (* 1 = 0.00121612 loss)
I0621 12:04:47.408910 17579 sgd_solver.cpp:105] Iteration 4400, lr = 0.005
I0621 12:05:58.192369 17579 solver.cpp:219] Iteration 4450 (0.706388 iter/s, 70.7827s/50 iters), loss = 0.00245097
I0621 12:05:58.192530 17579 solver.cpp:238]     Train net output #0: loss = 0.00180759 (* 1 = 0.00180759 loss)
I0621 12:05:58.192561 17579 sgd_solver.cpp:105] Iteration 4450, lr = 0.005
I0621 12:07:07.578462 17579 solver.cpp:331] Iteration 4500, Testing net (#0)
I0621 12:07:19.556493 17579 solver.cpp:398]     Test net output #0: accuracy = 0.983333
I0621 12:07:19.556587 17579 solver.cpp:398]     Test net output #1: loss = 0.0778625 (* 1 = 0.0778625 loss)
I0621 12:07:19.564010 17579 compress_conv_layer.cu:174] 0.37607 1.90829e-10 0.980992
I0621 12:07:19.572677 17579 compress_conv_layer.cu:174] 0.37607 1.16399e-10 0.573237
I0621 12:07:19.580981 17579 compress_conv_layer.cu:174] 0.37607 2.09139e-11 0.768673
I0621 12:07:19.589309 17579 compress_conv_layer.cu:174] 0.37607 3.1851e-12 0.81089
I0621 12:07:19.602061 17579 compress_conv_layer.cu:174] 0.37607 1.01723e-11 0.473067
I0621 12:07:19.624222 17579 compress_conv_layer.cu:174] 0.37607 9.75837e-14 0.500961
I0621 12:07:19.667847 17579 compress_conv_layer.cu:174] 0.37607 1.77225e-13 0.493819
I0621 12:07:19.711046 17579 compress_conv_layer.cu:174] 0.37607 2.25691e-12 0.419026
I0621 12:07:19.754391 17579 compress_conv_layer.cu:174] 0.37607 1.96101e-12 0.444678
I0621 12:07:19.797463 17579 compress_conv_layer.cu:174] 0.37607 2.06133e-12 0.597538
I0621 12:07:19.840232 17579 compress_conv_layer.cu:174] 0.37607 5.67699e-12 0.473912
I0621 12:07:19.927606 17579 compress_conv_layer.cu:174] 0.37607 1.69811e-12 0.340409
I0621 12:07:20.111213 17579 compress_conv_layer.cu:174] 0.37607 3.49763e-12 0.303101
I0621 12:07:20.129367 17579 compress_conv_layer.cu:174] 0.37607 3.25214e-07 0.178071
I0621 12:07:20.367923 17579 compress_conv_layer.cu:174] 0.37607 1.90829e-10 0.980992
I0621 12:07:20.375941 17579 compress_conv_layer.cu:174] 0.37607 1.16399e-10 0.573237
I0621 12:07:20.384243 17579 compress_conv_layer.cu:174] 0.37607 2.09139e-11 0.768673
I0621 12:07:20.392458 17579 compress_conv_layer.cu:174] 0.37607 3.1851e-12 0.81089
I0621 12:07:20.405019 17579 compress_conv_layer.cu:174] 0.37607 1.01723e-11 0.473067
I0621 12:07:20.426738 17579 compress_conv_layer.cu:174] 0.37607 9.75837e-14 0.500961
I0621 12:07:20.469523 17579 compress_conv_layer.cu:174] 0.37607 1.77225e-13 0.493819
I0621 12:07:20.512797 17579 compress_conv_layer.cu:174] 0.37607 2.25691e-12 0.419026
I0621 12:07:20.556291 17579 compress_conv_layer.cu:174] 0.37607 1.96101e-12 0.444678
I0621 12:07:20.599534 17579 compress_conv_layer.cu:174] 0.37607 2.06133e-12 0.597538
I0621 12:07:20.642465 17579 compress_conv_layer.cu:174] 0.37607 5.67699e-12 0.473912
I0621 12:07:20.728776 17579 compress_conv_layer.cu:174] 0.37607 1.69811e-12 0.340409
I0621 12:07:20.909104 17579 compress_conv_layer.cu:174] 0.37607 3.49763e-12 0.303101
I0621 12:07:20.927209 17579 compress_conv_layer.cu:174] 0.37607 3.25214e-07 0.178071
I0621 12:07:21.165388 17579 compress_conv_layer.cu:174] 0.37607 1.90829e-10 0.980992
I0621 12:07:21.173393 17579 compress_conv_layer.cu:174] 0.37607 1.16399e-10 0.573237
I0621 12:07:21.181629 17579 compress_conv_layer.cu:174] 0.37607 2.09139e-11 0.768673
I0621 12:07:21.189756 17579 compress_conv_layer.cu:174] 0.37607 3.1851e-12 0.81089
I0621 12:07:21.202179 17579 compress_conv_layer.cu:174] 0.37607 1.01723e-11 0.473067
I0621 12:07:21.223836 17579 compress_conv_layer.cu:174] 0.37607 9.75837e-14 0.500961
I0621 12:07:21.266518 17579 compress_conv_layer.cu:174] 0.37607 1.77225e-13 0.493819
I0621 12:07:21.309684 17579 compress_conv_layer.cu:174] 0.37607 2.25691e-12 0.419026
I0621 12:07:21.353279 17579 compress_conv_layer.cu:174] 0.37607 1.96101e-12 0.444678
I0621 12:07:21.396508 17579 compress_conv_layer.cu:174] 0.37607 2.06133e-12 0.597538
I0621 12:07:21.439419 17579 compress_conv_layer.cu:174] 0.37607 5.67699e-12 0.473912
I0621 12:07:21.525415 17579 compress_conv_layer.cu:174] 0.37607 1.69811e-12 0.340409
I0621 12:07:21.705379 17579 compress_conv_layer.cu:174] 0.37607 3.49763e-12 0.303101
I0621 12:07:21.723470 17579 compress_conv_layer.cu:174] 0.37607 3.25214e-07 0.178071
I0621 12:07:21.961696 17579 compress_conv_layer.cu:174] 0.37607 1.90829e-10 0.980992
I0621 12:07:21.969686 17579 compress_conv_layer.cu:174] 0.37607 1.16399e-10 0.573237
I0621 12:07:21.977916 17579 compress_conv_layer.cu:174] 0.37607 2.09139e-11 0.768673
I0621 12:07:21.986052 17579 compress_conv_layer.cu:174] 0.37607 3.1851e-12 0.81089
I0621 12:07:21.998507 17579 compress_conv_layer.cu:174] 0.37607 1.01723e-11 0.473067
I0621 12:07:22.020153 17579 compress_conv_layer.cu:174] 0.37607 9.75837e-14 0.500961
I0621 12:07:22.062897 17579 compress_conv_layer.cu:174] 0.37607 1.77225e-13 0.493819
I0621 12:07:22.105846 17579 compress_conv_layer.cu:174] 0.37607 2.25691e-12 0.419026
I0621 12:07:22.148846 17579 compress_conv_layer.cu:174] 0.37607 1.96101e-12 0.444678
I0621 12:07:22.191416 17579 compress_conv_layer.cu:174] 0.37607 2.06133e-12 0.597538
I0621 12:07:22.233739 17579 compress_conv_layer.cu:174] 0.37607 5.67699e-12 0.473912
I0621 12:07:22.319572 17579 compress_conv_layer.cu:174] 0.37607 1.69811e-12 0.340409
I0621 12:07:22.499382 17579 compress_conv_layer.cu:174] 0.37607 3.49763e-12 0.303101
I0621 12:07:22.517473 17579 compress_conv_layer.cu:174] 0.37607 3.25214e-07 0.178071
I0621 12:07:22.755652 17579 compress_conv_layer.cu:174] 0.37607 1.90829e-10 0.980992
I0621 12:07:22.763614 17579 compress_conv_layer.cu:174] 0.37607 1.16399e-10 0.573237
I0621 12:07:22.771842 17579 compress_conv_layer.cu:174] 0.37607 2.09139e-11 0.768673
I0621 12:07:22.779981 17579 compress_conv_layer.cu:174] 0.37607 3.1851e-12 0.81089
I0621 12:07:22.792368 17579 compress_conv_layer.cu:174] 0.37607 1.01723e-11 0.473067
I0621 12:07:22.813827 17579 compress_conv_layer.cu:174] 0.37607 9.75837e-14 0.500961
I0621 12:07:22.856370 17579 compress_conv_layer.cu:174] 0.37607 1.77225e-13 0.493819
I0621 12:07:22.899420 17579 compress_conv_layer.cu:174] 0.37607 2.25691e-12 0.419026
I0621 12:07:22.942530 17579 compress_conv_layer.cu:174] 0.37607 1.96101e-12 0.444678
I0621 12:07:22.985162 17579 compress_conv_layer.cu:174] 0.37607 2.06133e-12 0.597538
I0621 12:07:23.027451 17579 compress_conv_layer.cu:174] 0.37607 5.67699e-12 0.473912
I0621 12:07:23.113152 17579 compress_conv_layer.cu:174] 0.37607 1.69811e-12 0.340409
I0621 12:07:23.293030 17579 compress_conv_layer.cu:174] 0.37607 3.49763e-12 0.303101
I0621 12:07:23.311172 17579 compress_conv_layer.cu:174] 0.37607 3.25214e-07 0.178071
I0621 12:07:23.541589 17579 solver.cpp:219] Iteration 4500 (0.585836 iter/s, 85.3481s/50 iters), loss = 0.00283076
I0621 12:07:23.541677 17579 solver.cpp:238]     Train net output #0: loss = 0.00156368 (* 1 = 0.00156368 loss)
I0621 12:07:23.541703 17579 sgd_solver.cpp:105] Iteration 4500, lr = 0.005
I0621 12:08:34.328599 17579 solver.cpp:219] Iteration 4550 (0.706353 iter/s, 70.7861s/50 iters), loss = 0.0029659
I0621 12:08:34.328819 17579 solver.cpp:238]     Train net output #0: loss = 0.000971686 (* 1 = 0.000971686 loss)
I0621 12:08:34.328848 17579 sgd_solver.cpp:105] Iteration 4550, lr = 0.005
I0621 12:09:45.104526 17579 solver.cpp:219] Iteration 4600 (0.706465 iter/s, 70.7749s/50 iters), loss = 0.00200009
I0621 12:09:45.104682 17579 solver.cpp:238]     Train net output #0: loss = 0.0021864 (* 1 = 0.0021864 loss)
I0621 12:09:45.104712 17579 sgd_solver.cpp:105] Iteration 4600, lr = 0.005
I0621 12:10:55.891993 17579 solver.cpp:219] Iteration 4650 (0.706349 iter/s, 70.7865s/50 iters), loss = 0.00286287
I0621 12:10:55.892141 17579 solver.cpp:238]     Train net output #0: loss = 0.00123052 (* 1 = 0.00123052 loss)
I0621 12:10:55.892170 17579 sgd_solver.cpp:105] Iteration 4650, lr = 0.005
I0621 12:12:06.665060 17579 solver.cpp:219] Iteration 4700 (0.706493 iter/s, 70.7721s/50 iters), loss = 0.00251057
I0621 12:12:06.665228 17579 solver.cpp:238]     Train net output #0: loss = 0.00478464 (* 1 = 0.00478464 loss)
I0621 12:12:06.665262 17579 sgd_solver.cpp:105] Iteration 4700, lr = 0.005
I0621 12:13:17.473696 17579 solver.cpp:219] Iteration 4750 (0.706138 iter/s, 70.8077s/50 iters), loss = 0.00211972
I0621 12:13:17.473852 17579 solver.cpp:238]     Train net output #0: loss = 0.00169089 (* 1 = 0.00169089 loss)
I0621 12:13:17.473881 17579 sgd_solver.cpp:105] Iteration 4750, lr = 0.005
I0621 12:14:28.261354 17579 solver.cpp:219] Iteration 4800 (0.706347 iter/s, 70.7867s/50 iters), loss = 0.00205304
I0621 12:14:28.261622 17579 solver.cpp:238]     Train net output #0: loss = 0.000922882 (* 1 = 0.000922882 loss)
I0621 12:14:28.261667 17579 sgd_solver.cpp:105] Iteration 4800, lr = 0.005
I0621 12:15:39.041105 17579 solver.cpp:219] Iteration 4850 (0.706427 iter/s, 70.7787s/50 iters), loss = 0.00176352
I0621 12:15:39.041246 17579 solver.cpp:238]     Train net output #0: loss = 0.00101799 (* 1 = 0.00101799 loss)
I0621 12:15:39.041275 17579 sgd_solver.cpp:105] Iteration 4850, lr = 0.005
I0621 12:16:49.823446 17579 solver.cpp:219] Iteration 4900 (0.7064 iter/s, 70.7814s/50 iters), loss = 0.00182758
I0621 12:16:49.824394 17579 solver.cpp:238]     Train net output #0: loss = 0.00271933 (* 1 = 0.00271933 loss)
I0621 12:16:49.824424 17579 sgd_solver.cpp:105] Iteration 4900, lr = 0.005
I0621 12:18:00.617331 17579 solver.cpp:219] Iteration 4950 (0.706293 iter/s, 70.7921s/50 iters), loss = 0.00192799
I0621 12:18:00.617497 17579 solver.cpp:238]     Train net output #0: loss = 0.00114702 (* 1 = 0.00114702 loss)
I0621 12:18:00.617533 17579 sgd_solver.cpp:105] Iteration 4950, lr = 0.005
I0621 12:19:10.008721 17579 solver.cpp:331] Iteration 5000, Testing net (#0)
I0621 12:19:15.018729 17579 blocking_queue.cpp:49] Waiting for data
I0621 12:19:22.003432 17579 solver.cpp:398]     Test net output #0: accuracy = 0.982353
I0621 12:19:22.003509 17579 solver.cpp:398]     Test net output #1: loss = 0.0758237 (* 1 = 0.0758237 loss)
I0621 12:19:23.414554 17579 solver.cpp:219] Iteration 5000 (0.603893 iter/s, 82.7961s/50 iters), loss = 0.00208122
I0621 12:19:23.414657 17579 solver.cpp:238]     Train net output #0: loss = 0.00190694 (* 1 = 0.00190694 loss)
I0621 12:19:23.414685 17579 sgd_solver.cpp:105] Iteration 5000, lr = 0.005
I0621 12:20:34.203757 17579 solver.cpp:219] Iteration 5050 (0.706331 iter/s, 70.7883s/50 iters), loss = 0.00360182
I0621 12:20:34.203891 17579 solver.cpp:238]     Train net output #0: loss = 0.00488689 (* 1 = 0.00488689 loss)
I0621 12:20:34.203918 17579 sgd_solver.cpp:105] Iteration 5050, lr = 0.005
I0621 12:21:44.984733 17579 solver.cpp:219] Iteration 5100 (0.706414 iter/s, 70.78s/50 iters), loss = 0.00123698
I0621 12:21:44.984925 17579 solver.cpp:238]     Train net output #0: loss = 0.00108742 (* 1 = 0.00108742 loss)
I0621 12:21:44.984954 17579 sgd_solver.cpp:105] Iteration 5100, lr = 0.005
I0621 12:22:55.749979 17579 solver.cpp:219] Iteration 5150 (0.706571 iter/s, 70.7643s/50 iters), loss = 0.00111451
I0621 12:22:55.750133 17579 solver.cpp:238]     Train net output #0: loss = 0.000927563 (* 1 = 0.000927563 loss)
I0621 12:22:55.750164 17579 sgd_solver.cpp:105] Iteration 5150, lr = 0.005
I0621 12:24:06.525080 17579 solver.cpp:219] Iteration 5200 (0.706473 iter/s, 70.7741s/50 iters), loss = 0.00212938
I0621 12:24:06.525231 17579 solver.cpp:238]     Train net output #0: loss = 0.000666906 (* 1 = 0.000666906 loss)
I0621 12:24:06.525259 17579 sgd_solver.cpp:105] Iteration 5200, lr = 0.005
I0621 12:25:17.299425 17579 solver.cpp:219] Iteration 5250 (0.70648 iter/s, 70.7734s/50 iters), loss = 0.00186714
I0621 12:25:17.299558 17579 solver.cpp:238]     Train net output #0: loss = 0.00145644 (* 1 = 0.00145644 loss)
I0621 12:25:17.299588 17579 sgd_solver.cpp:105] Iteration 5250, lr = 0.005
I0621 12:26:28.080585 17579 solver.cpp:219] Iteration 5300 (0.706412 iter/s, 70.7802s/50 iters), loss = 0.00142983
I0621 12:26:28.080716 17579 solver.cpp:238]     Train net output #0: loss = 0.00113376 (* 1 = 0.00113376 loss)
I0621 12:26:28.080744 17579 sgd_solver.cpp:105] Iteration 5300, lr = 0.005
I0621 12:27:38.860240 17579 solver.cpp:219] Iteration 5350 (0.706427 iter/s, 70.7787s/50 iters), loss = 0.00196638
I0621 12:27:38.860384 17579 solver.cpp:238]     Train net output #0: loss = 0.00330031 (* 1 = 0.00330031 loss)
I0621 12:27:38.860412 17579 sgd_solver.cpp:105] Iteration 5350, lr = 0.005
I0621 12:28:49.632218 17579 solver.cpp:219] Iteration 5400 (0.706503 iter/s, 70.7711s/50 iters), loss = 0.00180905
I0621 12:28:49.632351 17579 solver.cpp:238]     Train net output #0: loss = 0.00129681 (* 1 = 0.00129681 loss)
I0621 12:28:49.632380 17579 sgd_solver.cpp:105] Iteration 5400, lr = 0.005
I0621 12:30:00.399999 17579 solver.cpp:219] Iteration 5450 (0.706545 iter/s, 70.7669s/50 iters), loss = 0.00176493
I0621 12:30:00.400142 17579 solver.cpp:238]     Train net output #0: loss = 0.00160263 (* 1 = 0.00160263 loss)
I0621 12:30:00.400171 17579 sgd_solver.cpp:105] Iteration 5450, lr = 0.005
I0621 12:31:09.772248 17579 solver.cpp:331] Iteration 5500, Testing net (#0)
I0621 12:31:21.732856 17579 solver.cpp:398]     Test net output #0: accuracy = 0.982353
I0621 12:31:21.732941 17579 solver.cpp:398]     Test net output #1: loss = 0.0764412 (* 1 = 0.0764412 loss)
I0621 12:31:23.143713 17579 solver.cpp:219] Iteration 5500 (0.604283 iter/s, 82.7428s/50 iters), loss = 0.00187317
I0621 12:31:23.143805 17579 solver.cpp:238]     Train net output #0: loss = 0.00226307 (* 1 = 0.00226307 loss)
I0621 12:31:23.143836 17579 sgd_solver.cpp:105] Iteration 5500, lr = 0.005
I0621 12:32:33.915535 17579 solver.cpp:219] Iteration 5550 (0.706504 iter/s, 70.771s/50 iters), loss = 0.00295814
I0621 12:32:33.915678 17579 solver.cpp:238]     Train net output #0: loss = 0.00175145 (* 1 = 0.00175145 loss)
I0621 12:32:33.915707 17579 sgd_solver.cpp:105] Iteration 5550, lr = 0.005
I0621 12:33:44.690107 17579 solver.cpp:219] Iteration 5600 (0.706477 iter/s, 70.7737s/50 iters), loss = 0.00208219
I0621 12:33:44.690253 17579 solver.cpp:238]     Train net output #0: loss = 0.00117668 (* 1 = 0.00117668 loss)
I0621 12:33:44.690285 17579 sgd_solver.cpp:105] Iteration 5600, lr = 0.005
I0621 12:34:55.507033 17579 solver.cpp:219] Iteration 5650 (0.706055 iter/s, 70.8161s/50 iters), loss = 0.00265896
I0621 12:34:55.507182 17579 solver.cpp:238]     Train net output #0: loss = 0.00207788 (* 1 = 0.00207788 loss)
I0621 12:34:55.507211 17579 sgd_solver.cpp:105] Iteration 5650, lr = 0.005
I0621 12:36:06.304216 17579 solver.cpp:219] Iteration 5700 (0.706252 iter/s, 70.7963s/50 iters), loss = 0.00155005
I0621 12:36:06.304364 17579 solver.cpp:238]     Train net output #0: loss = 0.00101981 (* 1 = 0.00101981 loss)
I0621 12:36:06.304394 17579 sgd_solver.cpp:105] Iteration 5700, lr = 0.005
I0621 12:37:17.095554 17579 solver.cpp:219] Iteration 5750 (0.70631 iter/s, 70.7905s/50 iters), loss = 0.00141027
I0621 12:37:17.095773 17579 solver.cpp:238]     Train net output #0: loss = 0.000834103 (* 1 = 0.000834103 loss)
I0621 12:37:17.095803 17579 sgd_solver.cpp:105] Iteration 5750, lr = 0.005
I0621 12:38:27.908466 17579 solver.cpp:219] Iteration 5800 (0.706096 iter/s, 70.8119s/50 iters), loss = 0.00183589
I0621 12:38:27.908722 17579 solver.cpp:238]     Train net output #0: loss = 0.00210585 (* 1 = 0.00210585 loss)
I0621 12:38:27.908752 17579 sgd_solver.cpp:105] Iteration 5800, lr = 0.005
I0621 12:39:38.712061 17579 solver.cpp:219] Iteration 5850 (0.706189 iter/s, 70.8026s/50 iters), loss = 0.00295246
I0621 12:39:38.712241 17579 solver.cpp:238]     Train net output #0: loss = 0.000794556 (* 1 = 0.000794556 loss)
I0621 12:39:38.712271 17579 sgd_solver.cpp:105] Iteration 5850, lr = 0.005
I0621 12:40:49.679965 17579 solver.cpp:219] Iteration 5900 (0.704553 iter/s, 70.967s/50 iters), loss = 0.00250187
I0621 12:40:49.680124 17579 solver.cpp:238]     Train net output #0: loss = 0.00147356 (* 1 = 0.00147356 loss)
I0621 12:40:49.680155 17579 sgd_solver.cpp:105] Iteration 5900, lr = 0.005
I0621 12:42:00.493460 17579 solver.cpp:219] Iteration 5950 (0.706089 iter/s, 70.8126s/50 iters), loss = 0.00204175
I0621 12:42:00.493615 17579 solver.cpp:238]     Train net output #0: loss = 0.00174106 (* 1 = 0.00174106 loss)
I0621 12:42:00.493644 17579 sgd_solver.cpp:105] Iteration 5950, lr = 0.005
I0621 12:43:09.888844 17579 solver.cpp:331] Iteration 6000, Testing net (#0)
I0621 12:43:21.977644 17579 solver.cpp:398]     Test net output #0: accuracy = 0.983333
I0621 12:43:21.977720 17579 solver.cpp:398]     Test net output #1: loss = 0.0727169 (* 1 = 0.0727169 loss)
I0621 12:43:21.985707 17579 compress_conv_layer.cu:174] 0.418673 1.90122e-10 0.977325
I0621 12:43:21.993676 17579 compress_conv_layer.cu:174] 0.418673 1.15962e-10 0.571074
I0621 12:43:22.002048 17579 compress_conv_layer.cu:174] 0.418673 2.08359e-11 0.766083
I0621 12:43:22.010332 17579 compress_conv_layer.cu:174] 0.418673 3.17307e-12 0.808004
I0621 12:43:22.023092 17579 compress_conv_layer.cu:174] 0.418673 1.01345e-11 0.471244
I0621 12:43:22.045251 17579 compress_conv_layer.cu:174] 0.418673 9.72178e-14 0.499028
I0621 12:43:22.088531 17579 compress_conv_layer.cu:174] 0.418673 1.76554e-13 0.491856
I0621 12:43:22.131727 17579 compress_conv_layer.cu:174] 0.418673 2.24845e-12 0.417456
I0621 12:43:22.175020 17579 compress_conv_layer.cu:174] 0.418673 1.95353e-12 0.443193
I0621 12:43:22.218130 17579 compress_conv_layer.cu:174] 0.418673 2.05352e-12 0.595228
I0621 12:43:22.261638 17579 compress_conv_layer.cu:174] 0.418673 5.65552e-12 0.472069
I0621 12:43:22.349975 17579 compress_conv_layer.cu:174] 0.418673 1.69177e-12 0.339038
I0621 12:43:22.535820 17579 compress_conv_layer.cu:174] 0.418673 3.48462e-12 0.301922
I0621 12:43:22.554466 17579 compress_conv_layer.cu:174] 0.418673 3.23979e-07 0.179116
I0621 12:43:22.792701 17579 compress_conv_layer.cu:174] 0.418673 1.90122e-10 0.977325
I0621 12:43:22.800671 17579 compress_conv_layer.cu:174] 0.418673 1.15962e-10 0.571074
I0621 12:43:22.808923 17579 compress_conv_layer.cu:174] 0.418673 2.08359e-11 0.766083
I0621 12:43:22.817044 17579 compress_conv_layer.cu:174] 0.418673 3.17307e-12 0.808004
I0621 12:43:22.829556 17579 compress_conv_layer.cu:174] 0.418673 1.01345e-11 0.471244
I0621 12:43:22.851295 17579 compress_conv_layer.cu:174] 0.418673 9.72178e-14 0.499028
I0621 12:43:22.893709 17579 compress_conv_layer.cu:174] 0.418673 1.76554e-13 0.491856
I0621 12:43:22.937196 17579 compress_conv_layer.cu:174] 0.418673 2.24845e-12 0.417456
I0621 12:43:22.980034 17579 compress_conv_layer.cu:174] 0.418673 1.95353e-12 0.443193
I0621 12:43:23.023468 17579 compress_conv_layer.cu:174] 0.418673 2.05352e-12 0.595228
I0621 12:43:23.066840 17579 compress_conv_layer.cu:174] 0.418673 5.65552e-12 0.472069
I0621 12:43:23.152981 17579 compress_conv_layer.cu:174] 0.418673 1.69177e-12 0.339038
I0621 12:43:23.332518 17579 compress_conv_layer.cu:174] 0.418673 3.48462e-12 0.301922
I0621 12:43:23.350677 17579 compress_conv_layer.cu:174] 0.418673 3.23979e-07 0.179116
I0621 12:43:23.588789 17579 compress_conv_layer.cu:174] 0.418673 1.90122e-10 0.977325
I0621 12:43:23.596743 17579 compress_conv_layer.cu:174] 0.418673 1.15962e-10 0.571074
I0621 12:43:23.604984 17579 compress_conv_layer.cu:174] 0.418673 2.08359e-11 0.766083
I0621 12:43:23.613080 17579 compress_conv_layer.cu:174] 0.418673 3.17307e-12 0.808004
I0621 12:43:23.625627 17579 compress_conv_layer.cu:174] 0.418673 1.01345e-11 0.471244
I0621 12:43:23.647192 17579 compress_conv_layer.cu:174] 0.418673 9.72178e-14 0.499028
I0621 12:43:23.689443 17579 compress_conv_layer.cu:174] 0.418673 1.76554e-13 0.491856
I0621 12:43:23.732264 17579 compress_conv_layer.cu:174] 0.418673 2.24845e-12 0.417456
I0621 12:43:23.775096 17579 compress_conv_layer.cu:174] 0.418673 1.95353e-12 0.443193
I0621 12:43:23.817809 17579 compress_conv_layer.cu:174] 0.418673 2.05352e-12 0.595228
I0621 12:43:23.860997 17579 compress_conv_layer.cu:174] 0.418673 5.65552e-12 0.472069
I0621 12:43:23.947358 17579 compress_conv_layer.cu:174] 0.418673 1.69177e-12 0.339038
I0621 12:43:24.127264 17579 compress_conv_layer.cu:174] 0.418673 3.48462e-12 0.301922
I0621 12:43:24.145511 17579 compress_conv_layer.cu:174] 0.418673 3.23979e-07 0.179116
I0621 12:43:24.383776 17579 compress_conv_layer.cu:174] 0.418673 1.90122e-10 0.977325
I0621 12:43:24.391758 17579 compress_conv_layer.cu:174] 0.418673 1.15962e-10 0.571074
I0621 12:43:24.400020 17579 compress_conv_layer.cu:174] 0.418673 2.08359e-11 0.766083
I0621 12:43:24.408123 17579 compress_conv_layer.cu:174] 0.418673 3.17307e-12 0.808004
I0621 12:43:24.420694 17579 compress_conv_layer.cu:174] 0.418673 1.01345e-11 0.471244
I0621 12:43:24.442209 17579 compress_conv_layer.cu:174] 0.418673 9.72178e-14 0.499028
I0621 12:43:24.484511 17579 compress_conv_layer.cu:174] 0.418673 1.76554e-13 0.491856
I0621 12:43:24.528093 17579 compress_conv_layer.cu:174] 0.418673 2.24845e-12 0.417456
I0621 12:43:24.570834 17579 compress_conv_layer.cu:174] 0.418673 1.95353e-12 0.443193
I0621 12:43:24.613816 17579 compress_conv_layer.cu:174] 0.418673 2.05352e-12 0.595228
I0621 12:43:24.657295 17579 compress_conv_layer.cu:174] 0.418673 5.65552e-12 0.472069
I0621 12:43:24.743820 17579 compress_conv_layer.cu:174] 0.418673 1.69177e-12 0.339038
I0621 12:43:24.923774 17579 compress_conv_layer.cu:174] 0.418673 3.48462e-12 0.301922
I0621 12:43:24.941999 17579 compress_conv_layer.cu:174] 0.418673 3.23979e-07 0.179116
I0621 12:43:25.180263 17579 compress_conv_layer.cu:174] 0.418673 1.90122e-10 0.977325
I0621 12:43:25.188180 17579 compress_conv_layer.cu:174] 0.418673 1.15962e-10 0.571074
I0621 12:43:25.196439 17579 compress_conv_layer.cu:174] 0.418673 2.08359e-11 0.766083
I0621 12:43:25.204496 17579 compress_conv_layer.cu:174] 0.418673 3.17307e-12 0.808004
I0621 12:43:25.216996 17579 compress_conv_layer.cu:174] 0.418673 1.01345e-11 0.471244
I0621 12:43:25.238574 17579 compress_conv_layer.cu:174] 0.418673 9.72178e-14 0.499028
I0621 12:43:25.286927 17579 compress_conv_layer.cu:174] 0.418673 1.76554e-13 0.491856
I0621 12:43:25.330509 17579 compress_conv_layer.cu:174] 0.418673 2.24845e-12 0.417456
I0621 12:43:25.374498 17579 compress_conv_layer.cu:174] 0.418673 1.95353e-12 0.443193
I0621 12:43:25.419068 17579 compress_conv_layer.cu:174] 0.418673 2.05352e-12 0.595228
I0621 12:43:25.462714 17579 compress_conv_layer.cu:174] 0.418673 5.65552e-12 0.472069
I0621 12:43:25.549850 17579 compress_conv_layer.cu:174] 0.418673 1.69177e-12 0.339038
I0621 12:43:25.729678 17579 compress_conv_layer.cu:174] 0.418673 3.48462e-12 0.301922
I0621 12:43:25.747793 17579 compress_conv_layer.cu:174] 0.418673 3.23979e-07 0.179116
I0621 12:43:25.978013 17579 solver.cpp:219] Iteration 6000 (0.584908 iter/s, 85.4835s/50 iters), loss = 0.0036605
I0621 12:43:25.978073 17579 solver.cpp:238]     Train net output #0: loss = 0.00386567 (* 1 = 0.00386567 loss)
I0621 12:43:25.978096 17579 sgd_solver.cpp:105] Iteration 6000, lr = 0.005
I0621 12:44:36.789361 17579 solver.cpp:219] Iteration 6050 (0.706109 iter/s, 70.8106s/50 iters), loss = 0.00232308
I0621 12:44:36.789564 17579 solver.cpp:238]     Train net output #0: loss = 0.00331218 (* 1 = 0.00331218 loss)
I0621 12:44:36.789594 17579 sgd_solver.cpp:105] Iteration 6050, lr = 0.005
I0621 12:45:47.597131 17579 solver.cpp:219] Iteration 6100 (0.706147 iter/s, 70.8067s/50 iters), loss = 0.00486995
I0621 12:45:47.597277 17579 solver.cpp:238]     Train net output #0: loss = 0.0137048 (* 1 = 0.0137048 loss)
I0621 12:45:47.597306 17579 sgd_solver.cpp:105] Iteration 6100, lr = 0.005
I0621 12:46:58.394688 17579 solver.cpp:219] Iteration 6150 (0.706249 iter/s, 70.7966s/50 iters), loss = 0.00409009
I0621 12:46:58.396597 17579 solver.cpp:238]     Train net output #0: loss = 0.00222605 (* 1 = 0.00222605 loss)
I0621 12:46:58.396626 17579 sgd_solver.cpp:105] Iteration 6150, lr = 0.005
I0621 12:48:09.191226 17579 solver.cpp:219] Iteration 6200 (0.706276 iter/s, 70.7938s/50 iters), loss = 0.00371997
I0621 12:48:09.191406 17579 solver.cpp:238]     Train net output #0: loss = 0.00551749 (* 1 = 0.00551749 loss)
I0621 12:48:09.191433 17579 sgd_solver.cpp:105] Iteration 6200, lr = 0.005
I0621 12:49:19.985281 17579 solver.cpp:219] Iteration 6250 (0.706284 iter/s, 70.793s/50 iters), loss = 0.00262763
I0621 12:49:19.985532 17579 solver.cpp:238]     Train net output #0: loss = 0.00554545 (* 1 = 0.00554545 loss)
I0621 12:49:19.985571 17579 sgd_solver.cpp:105] Iteration 6250, lr = 0.005
I0621 12:50:30.800992 17579 solver.cpp:219] Iteration 6300 (0.706069 iter/s, 70.8146s/50 iters), loss = 0.00220313
I0621 12:50:30.801157 17579 solver.cpp:238]     Train net output #0: loss = 0.00178042 (* 1 = 0.00178042 loss)
I0621 12:50:30.801187 17579 sgd_solver.cpp:105] Iteration 6300, lr = 0.005
I0621 12:51:41.598266 17579 solver.cpp:219] Iteration 6350 (0.706252 iter/s, 70.7963s/50 iters), loss = 0.0018233
I0621 12:51:41.598412 17579 solver.cpp:238]     Train net output #0: loss = 0.0024583 (* 1 = 0.0024583 loss)
I0621 12:51:41.598440 17579 sgd_solver.cpp:105] Iteration 6350, lr = 0.005
I0621 12:52:52.397428 17579 solver.cpp:219] Iteration 6400 (0.706233 iter/s, 70.7982s/50 iters), loss = 0.00160257
I0621 12:52:52.397590 17579 solver.cpp:238]     Train net output #0: loss = 0.00136704 (* 1 = 0.00136704 loss)
I0621 12:52:52.397619 17579 sgd_solver.cpp:105] Iteration 6400, lr = 0.005
I0621 12:54:03.203269 17579 solver.cpp:219] Iteration 6450 (0.706166 iter/s, 70.8049s/50 iters), loss = 0.00158822
I0621 12:54:03.203423 17579 solver.cpp:238]     Train net output #0: loss = 0.000690212 (* 1 = 0.000690212 loss)
I0621 12:54:03.203454 17579 sgd_solver.cpp:105] Iteration 6450, lr = 0.005
I0621 12:55:12.592778 17579 solver.cpp:331] Iteration 6500, Testing net (#0)
I0621 12:55:24.706760 17579 solver.cpp:398]     Test net output #0: accuracy = 0.979412
I0621 12:55:24.706843 17579 solver.cpp:398]     Test net output #1: loss = 0.0766006 (* 1 = 0.0766006 loss)
I0621 12:55:26.117578 17579 solver.cpp:219] Iteration 6500 (0.60304 iter/s, 82.9132s/50 iters), loss = 0.00206655
I0621 12:55:26.117668 17579 solver.cpp:238]     Train net output #0: loss = 0.00215143 (* 1 = 0.00215143 loss)
I0621 12:55:26.117694 17579 sgd_solver.cpp:105] Iteration 6500, lr = 0.005
I0621 12:56:36.909492 17579 solver.cpp:219] Iteration 6550 (0.706304 iter/s, 70.791s/50 iters), loss = 0.00215437
I0621 12:56:36.909647 17579 solver.cpp:238]     Train net output #0: loss = 0.00122341 (* 1 = 0.00122341 loss)
I0621 12:56:36.909679 17579 sgd_solver.cpp:105] Iteration 6550, lr = 0.005
I0621 12:57:47.700826 17579 solver.cpp:219] Iteration 6600 (0.706311 iter/s, 70.7904s/50 iters), loss = 0.00185899
I0621 12:57:47.700992 17579 solver.cpp:238]     Train net output #0: loss = 0.00223699 (* 1 = 0.00223699 loss)
I0621 12:57:47.701021 17579 sgd_solver.cpp:105] Iteration 6600, lr = 0.005
I0621 12:58:58.501634 17579 solver.cpp:219] Iteration 6650 (0.706216 iter/s, 70.7998s/50 iters), loss = 0.00385102
I0621 12:58:58.501775 17579 solver.cpp:238]     Train net output #0: loss = 0.00180985 (* 1 = 0.00180985 loss)
I0621 12:58:58.501806 17579 sgd_solver.cpp:105] Iteration 6650, lr = 0.005
I0621 13:00:09.303519 17579 solver.cpp:219] Iteration 6700 (0.706205 iter/s, 70.8009s/50 iters), loss = 0.00206156
I0621 13:00:09.303735 17579 solver.cpp:238]     Train net output #0: loss = 0.00217649 (* 1 = 0.00217649 loss)
I0621 13:00:09.303764 17579 sgd_solver.cpp:105] Iteration 6700, lr = 0.005
I0621 13:01:20.106057 17579 solver.cpp:219] Iteration 6750 (0.7062 iter/s, 70.8015s/50 iters), loss = 0.00201774
I0621 13:01:20.106200 17579 solver.cpp:238]     Train net output #0: loss = 0.00309068 (* 1 = 0.00309068 loss)
I0621 13:01:20.106233 17579 sgd_solver.cpp:105] Iteration 6750, lr = 0.005
I0621 13:02:30.901131 17579 solver.cpp:219] Iteration 6800 (0.706273 iter/s, 70.7941s/50 iters), loss = 0.00158746
I0621 13:02:30.901278 17579 solver.cpp:238]     Train net output #0: loss = 0.00075358 (* 1 = 0.00075358 loss)
I0621 13:02:30.901307 17579 sgd_solver.cpp:105] Iteration 6800, lr = 0.005
I0621 13:03:41.711542 17579 solver.cpp:219] Iteration 6850 (0.70612 iter/s, 70.8095s/50 iters), loss = 0.00164714
I0621 13:03:41.712393 17579 solver.cpp:238]     Train net output #0: loss = 0.0011168 (* 1 = 0.0011168 loss)
I0621 13:03:41.712420 17579 sgd_solver.cpp:105] Iteration 6850, lr = 0.005
I0621 13:04:52.517599 17579 solver.cpp:219] Iteration 6900 (0.706171 iter/s, 70.8044s/50 iters), loss = 0.0032393
I0621 13:04:52.517796 17579 solver.cpp:238]     Train net output #0: loss = 0.00314263 (* 1 = 0.00314263 loss)
I0621 13:04:52.517825 17579 sgd_solver.cpp:105] Iteration 6900, lr = 0.005
I0621 13:06:03.309377 17579 solver.cpp:219] Iteration 6950 (0.706307 iter/s, 70.7908s/50 iters), loss = 0.00351246
I0621 13:06:03.309573 17579 solver.cpp:238]     Train net output #0: loss = 0.00740387 (* 1 = 0.00740387 loss)
I0621 13:06:03.309607 17579 sgd_solver.cpp:105] Iteration 6950, lr = 0.005
I0621 13:07:12.705917 17579 solver.cpp:331] Iteration 7000, Testing net (#0)
I0621 13:07:24.658521 17579 solver.cpp:398]     Test net output #0: accuracy = 0.979412
I0621 13:07:24.658601 17579 solver.cpp:398]     Test net output #1: loss = 0.0766592 (* 1 = 0.0766592 loss)
I0621 13:07:26.080737 17579 solver.cpp:219] Iteration 7000 (0.604082 iter/s, 82.7702s/50 iters), loss = 0.002235
I0621 13:07:26.080847 17579 solver.cpp:238]     Train net output #0: loss = 0.00100848 (* 1 = 0.00100848 loss)
I0621 13:07:26.080873 17579 sgd_solver.cpp:105] Iteration 7000, lr = 0.005
I0621 13:08:36.946408 17579 solver.cpp:219] Iteration 7050 (0.70557 iter/s, 70.8647s/50 iters), loss = 0.00204048
I0621 13:08:36.946650 17579 solver.cpp:238]     Train net output #0: loss = 0.0036227 (* 1 = 0.0036227 loss)
I0621 13:08:36.946683 17579 sgd_solver.cpp:105] Iteration 7050, lr = 0.005
I0621 13:09:47.746294 17579 solver.cpp:219] Iteration 7100 (0.706226 iter/s, 70.7989s/50 iters), loss = 0.0018663
I0621 13:09:47.746428 17579 solver.cpp:238]     Train net output #0: loss = 0.00101917 (* 1 = 0.00101917 loss)
I0621 13:09:47.746455 17579 sgd_solver.cpp:105] Iteration 7100, lr = 0.005
I0621 13:10:58.617030 17579 solver.cpp:219] Iteration 7150 (0.705519 iter/s, 70.8698s/50 iters), loss = 0.00214059
I0621 13:10:58.617205 17579 solver.cpp:238]     Train net output #0: loss = 0.00171804 (* 1 = 0.00171804 loss)
I0621 13:10:58.617234 17579 sgd_solver.cpp:105] Iteration 7150, lr = 0.005
I0621 13:12:09.430024 17579 solver.cpp:219] Iteration 7200 (0.706095 iter/s, 70.812s/50 iters), loss = 0.00125584
I0621 13:12:09.430192 17579 solver.cpp:238]     Train net output #0: loss = 0.00211631 (* 1 = 0.00211631 loss)
I0621 13:12:09.430222 17579 sgd_solver.cpp:105] Iteration 7200, lr = 0.005
I0621 13:13:20.223603 17579 solver.cpp:219] Iteration 7250 (0.706288 iter/s, 70.7926s/50 iters), loss = 0.00160209
I0621 13:13:20.223747 17579 solver.cpp:238]     Train net output #0: loss = 0.00169719 (* 1 = 0.00169719 loss)
I0621 13:13:20.223776 17579 sgd_solver.cpp:105] Iteration 7250, lr = 0.005
I0621 13:14:31.024500 17579 solver.cpp:219] Iteration 7300 (0.706215 iter/s, 70.7999s/50 iters), loss = 0.00140254
I0621 13:14:31.024649 17579 solver.cpp:238]     Train net output #0: loss = 0.00176757 (* 1 = 0.00176757 loss)
I0621 13:14:31.024678 17579 sgd_solver.cpp:105] Iteration 7300, lr = 0.005
I0621 13:15:41.838012 17579 solver.cpp:219] Iteration 7350 (0.70609 iter/s, 70.8125s/50 iters), loss = 0.00157942
I0621 13:15:41.838260 17579 solver.cpp:238]     Train net output #0: loss = 0.00384954 (* 1 = 0.00384954 loss)
I0621 13:15:41.838296 17579 sgd_solver.cpp:105] Iteration 7350, lr = 0.005
I0621 13:16:52.647284 17579 solver.cpp:219] Iteration 7400 (0.706133 iter/s, 70.8082s/50 iters), loss = 0.00188173
I0621 13:16:52.647438 17579 solver.cpp:238]     Train net output #0: loss = 0.00225477 (* 1 = 0.00225477 loss)
I0621 13:16:52.647469 17579 sgd_solver.cpp:105] Iteration 7400, lr = 0.005
I0621 13:18:03.455596 17579 solver.cpp:219] Iteration 7450 (0.706142 iter/s, 70.8073s/50 iters), loss = 0.00191318
I0621 13:18:03.455865 17579 solver.cpp:238]     Train net output #0: loss = 0.000547536 (* 1 = 0.000547536 loss)
I0621 13:18:03.455905 17579 sgd_solver.cpp:105] Iteration 7450, lr = 0.005
I0621 13:19:12.846030 17579 solver.cpp:331] Iteration 7500, Testing net (#0)
I0621 13:19:24.909034 17579 solver.cpp:398]     Test net output #0: accuracy = 0.982353
I0621 13:19:24.909121 17579 solver.cpp:398]     Test net output #1: loss = 0.0731944 (* 1 = 0.0731944 loss)
I0621 13:19:24.917107 17579 compress_conv_layer.cu:174] 0.454693 1.89414e-10 0.973624
I0621 13:19:24.925093 17579 compress_conv_layer.cu:174] 0.454693 1.15524e-10 0.569124
I0621 13:19:24.933408 17579 compress_conv_layer.cu:174] 0.454693 2.07578e-11 0.763378
I0621 13:19:24.941632 17579 compress_conv_layer.cu:174] 0.454693 3.16116e-12 0.805106
I0621 13:19:24.954403 17579 compress_conv_layer.cu:174] 0.454693 1.00968e-11 0.469542
I0621 13:19:24.976423 17579 compress_conv_layer.cu:174] 0.454693 9.68519e-14 0.496993
I0621 13:19:25.019690 17579 compress_conv_layer.cu:174] 0.454693 1.75892e-13 0.489897
I0621 13:19:25.065870 17579 compress_conv_layer.cu:174] 0.454693 2.23999e-12 0.415878
I0621 13:19:25.109658 17579 compress_conv_layer.cu:174] 0.454693 1.94628e-12 0.441636
I0621 13:19:25.153291 17579 compress_conv_layer.cu:174] 0.454693 2.04572e-12 0.592847
I0621 13:19:25.196753 17579 compress_conv_layer.cu:174] 0.454693 5.63416e-12 0.47016
I0621 13:19:25.285570 17579 compress_conv_layer.cu:174] 0.454693 1.68543e-12 0.337634
I0621 13:19:25.473248 17579 compress_conv_layer.cu:174] 0.454693 3.47161e-12 0.30076
I0621 13:19:25.491827 17579 compress_conv_layer.cu:174] 0.454693 3.22785e-07 0.179921
I0621 13:19:25.730118 17579 compress_conv_layer.cu:174] 0.454693 1.89414e-10 0.973624
I0621 13:19:25.738086 17579 compress_conv_layer.cu:174] 0.454693 1.15524e-10 0.569124
I0621 13:19:25.746325 17579 compress_conv_layer.cu:174] 0.454693 2.07578e-11 0.763378
I0621 13:19:25.754465 17579 compress_conv_layer.cu:174] 0.454693 3.16116e-12 0.805106
I0621 13:19:25.767083 17579 compress_conv_layer.cu:174] 0.454693 1.00968e-11 0.469542
I0621 13:19:25.788642 17579 compress_conv_layer.cu:174] 0.454693 9.68519e-14 0.496993
I0621 13:19:25.830957 17579 compress_conv_layer.cu:174] 0.454693 1.75892e-13 0.489897
I0621 13:19:25.879009 17579 compress_conv_layer.cu:174] 0.454693 2.23999e-12 0.415878
I0621 13:19:25.922353 17579 compress_conv_layer.cu:174] 0.454693 1.94628e-12 0.441636
I0621 13:19:25.965757 17579 compress_conv_layer.cu:174] 0.454693 2.04572e-12 0.592847
I0621 13:19:26.009016 17579 compress_conv_layer.cu:174] 0.454693 5.63416e-12 0.47016
I0621 13:19:26.095296 17579 compress_conv_layer.cu:174] 0.454693 1.68543e-12 0.337634
I0621 13:19:26.275071 17579 compress_conv_layer.cu:174] 0.454693 3.47161e-12 0.30076
I0621 13:19:26.293265 17579 compress_conv_layer.cu:174] 0.454693 3.22785e-07 0.179921
I0621 13:19:26.531631 17579 compress_conv_layer.cu:174] 0.454693 1.89414e-10 0.973624
I0621 13:19:26.539613 17579 compress_conv_layer.cu:174] 0.454693 1.15524e-10 0.569124
I0621 13:19:26.547857 17579 compress_conv_layer.cu:174] 0.454693 2.07578e-11 0.763378
I0621 13:19:26.555969 17579 compress_conv_layer.cu:174] 0.454693 3.16116e-12 0.805106
I0621 13:19:26.568511 17579 compress_conv_layer.cu:174] 0.454693 1.00968e-11 0.469542
I0621 13:19:26.590028 17579 compress_conv_layer.cu:174] 0.454693 9.68519e-14 0.496993
I0621 13:19:26.632288 17579 compress_conv_layer.cu:174] 0.454693 1.75892e-13 0.489897
I0621 13:19:26.675056 17579 compress_conv_layer.cu:174] 0.454693 2.23999e-12 0.415878
I0621 13:19:26.718148 17579 compress_conv_layer.cu:174] 0.454693 1.94628e-12 0.441636
I0621 13:19:26.761386 17579 compress_conv_layer.cu:174] 0.454693 2.04572e-12 0.592847
I0621 13:19:26.804496 17579 compress_conv_layer.cu:174] 0.454693 5.63416e-12 0.47016
I0621 13:19:26.890614 17579 compress_conv_layer.cu:174] 0.454693 1.68543e-12 0.337634
I0621 13:19:27.070138 17579 compress_conv_layer.cu:174] 0.454693 3.47161e-12 0.30076
I0621 13:19:27.088251 17579 compress_conv_layer.cu:174] 0.454693 3.22785e-07 0.179921
I0621 13:19:27.326632 17579 compress_conv_layer.cu:174] 0.454693 1.89414e-10 0.973624
I0621 13:19:27.334599 17579 compress_conv_layer.cu:174] 0.454693 1.15524e-10 0.569124
I0621 13:19:27.342823 17579 compress_conv_layer.cu:174] 0.454693 2.07578e-11 0.763378
I0621 13:19:27.350940 17579 compress_conv_layer.cu:174] 0.454693 3.16116e-12 0.805106
I0621 13:19:27.363536 17579 compress_conv_layer.cu:174] 0.454693 1.00968e-11 0.469542
I0621 13:19:27.385033 17579 compress_conv_layer.cu:174] 0.454693 9.68519e-14 0.496993
I0621 13:19:27.427386 17579 compress_conv_layer.cu:174] 0.454693 1.75892e-13 0.489897
I0621 13:19:27.470257 17579 compress_conv_layer.cu:174] 0.454693 2.23999e-12 0.415878
I0621 13:19:27.513504 17579 compress_conv_layer.cu:174] 0.454693 1.94628e-12 0.441636
I0621 13:19:27.556637 17579 compress_conv_layer.cu:174] 0.454693 2.04572e-12 0.592847
I0621 13:19:27.599617 17579 compress_conv_layer.cu:174] 0.454693 5.63416e-12 0.47016
I0621 13:19:27.685686 17579 compress_conv_layer.cu:174] 0.454693 1.68543e-12 0.337634
I0621 13:19:27.865160 17579 compress_conv_layer.cu:174] 0.454693 3.47161e-12 0.30076
I0621 13:19:27.883301 17579 compress_conv_layer.cu:174] 0.454693 3.22785e-07 0.179921
I0621 13:19:28.121510 17579 compress_conv_layer.cu:174] 0.454693 1.89414e-10 0.973624
I0621 13:19:28.129492 17579 compress_conv_layer.cu:174] 0.454693 1.15524e-10 0.569124
I0621 13:19:28.137733 17579 compress_conv_layer.cu:174] 0.454693 2.07578e-11 0.763378
I0621 13:19:28.145824 17579 compress_conv_layer.cu:174] 0.454693 3.16116e-12 0.805106
I0621 13:19:28.158390 17579 compress_conv_layer.cu:174] 0.454693 1.00968e-11 0.469542
I0621 13:19:28.179865 17579 compress_conv_layer.cu:174] 0.454693 9.68519e-14 0.496993
I0621 13:19:28.222151 17579 compress_conv_layer.cu:174] 0.454693 1.75892e-13 0.489897
I0621 13:19:28.265017 17579 compress_conv_layer.cu:174] 0.454693 2.23999e-12 0.415878
I0621 13:19:28.308224 17579 compress_conv_layer.cu:174] 0.454693 1.94628e-12 0.441636
I0621 13:19:28.351333 17579 compress_conv_layer.cu:174] 0.454693 2.04572e-12 0.592847
I0621 13:19:28.394309 17579 compress_conv_layer.cu:174] 0.454693 5.63416e-12 0.47016
I0621 13:19:28.480324 17579 compress_conv_layer.cu:174] 0.454693 1.68543e-12 0.337634
I0621 13:19:28.659999 17579 compress_conv_layer.cu:174] 0.454693 3.47161e-12 0.30076
I0621 13:19:28.678186 17579 compress_conv_layer.cu:174] 0.454693 3.22785e-07 0.179921
I0621 13:19:28.908473 17579 solver.cpp:219] Iteration 7500 (0.585126 iter/s, 85.4517s/50 iters), loss = 0.00270951
I0621 13:19:28.908552 17579 solver.cpp:238]     Train net output #0: loss = 0.00485236 (* 1 = 0.00485236 loss)
I0621 13:19:28.908577 17579 sgd_solver.cpp:105] Iteration 7500, lr = 0.005
I0621 13:20:39.710201 17579 solver.cpp:219] Iteration 7550 (0.706206 iter/s, 70.8009s/50 iters), loss = 0.00303256
I0621 13:20:39.710345 17579 solver.cpp:238]     Train net output #0: loss = 0.00307125 (* 1 = 0.00307125 loss)
I0621 13:20:39.710377 17579 sgd_solver.cpp:105] Iteration 7550, lr = 0.005
I0621 13:21:50.520664 17579 solver.cpp:219] Iteration 7600 (0.70612 iter/s, 70.8095s/50 iters), loss = 0.00260253
I0621 13:21:50.520818 17579 solver.cpp:238]     Train net output #0: loss = 0.00106036 (* 1 = 0.00106036 loss)
I0621 13:21:50.520845 17579 sgd_solver.cpp:105] Iteration 7600, lr = 0.005
I0621 13:23:01.322531 17579 solver.cpp:219] Iteration 7650 (0.706206 iter/s, 70.8009s/50 iters), loss = 0.00196932
I0621 13:23:01.323209 17579 solver.cpp:238]     Train net output #0: loss = 0.00241036 (* 1 = 0.00241036 loss)
I0621 13:23:01.323236 17579 sgd_solver.cpp:105] Iteration 7650, lr = 0.005
I0621 13:24:12.119348 17579 solver.cpp:219] Iteration 7700 (0.706261 iter/s, 70.7953s/50 iters), loss = 0.00202271
I0621 13:24:12.119518 17579 solver.cpp:238]     Train net output #0: loss = 0.0034714 (* 1 = 0.0034714 loss)
I0621 13:24:12.119547 17579 sgd_solver.cpp:105] Iteration 7700, lr = 0.005
I0621 13:25:22.916810 17579 solver.cpp:219] Iteration 7750 (0.70625 iter/s, 70.7965s/50 iters), loss = 0.0024236
I0621 13:25:22.917029 17579 solver.cpp:238]     Train net output #0: loss = 0.00211924 (* 1 = 0.00211924 loss)
I0621 13:25:22.917059 17579 sgd_solver.cpp:105] Iteration 7750, lr = 0.005
I0621 13:26:35.681725 17579 solver.cpp:219] Iteration 7800 (0.687154 iter/s, 72.7639s/50 iters), loss = 0.00160554
I0621 13:26:35.686571 17579 solver.cpp:238]     Train net output #0: loss = 0.0018098 (* 1 = 0.0018098 loss)
I0621 13:26:35.686616 17579 sgd_solver.cpp:105] Iteration 7800, lr = 0.005
I0621 13:27:47.912919 17579 solver.cpp:219] Iteration 7850 (0.692276 iter/s, 72.2255s/50 iters), loss = 0.00207808
I0621 13:27:47.913166 17579 solver.cpp:238]     Train net output #0: loss = 0.00264567 (* 1 = 0.00264567 loss)
I0621 13:27:47.913208 17579 sgd_solver.cpp:105] Iteration 7850, lr = 0.005
I0621 13:28:58.783447 17579 solver.cpp:219] Iteration 7900 (0.705522 iter/s, 70.8695s/50 iters), loss = 0.00281666
I0621 13:28:58.783591 17579 solver.cpp:238]     Train net output #0: loss = 0.000670724 (* 1 = 0.000670724 loss)
I0621 13:28:58.783619 17579 sgd_solver.cpp:105] Iteration 7900, lr = 0.005
I0621 13:30:09.586781 17579 solver.cpp:219] Iteration 7950 (0.706191 iter/s, 70.8024s/50 iters), loss = 0.00329343
I0621 13:30:09.586925 17579 solver.cpp:238]     Train net output #0: loss = 0.00352323 (* 1 = 0.00352323 loss)
I0621 13:30:09.586953 17579 sgd_solver.cpp:105] Iteration 7950, lr = 0.005
I0621 13:31:18.986840 17579 solver.cpp:448] Snapshotting to binary proto file mobilenet/mobile_pruning_iter_8000.caffemodel
I0621 13:31:19.110004 17579 sgd_solver.cpp:273] Snapshotting solver state to binary proto file mobilenet/mobile_pruning_iter_8000.solverstate
I0621 13:31:19.165094 17579 solver.cpp:331] Iteration 8000, Testing net (#0)
I0621 13:31:31.177381 17579 solver.cpp:398]     Test net output #0: accuracy = 0.983333
I0621 13:31:31.177480 17579 solver.cpp:398]     Test net output #1: loss = 0.0749651 (* 1 = 0.0749651 loss)
I0621 13:31:32.591032 17579 solver.cpp:219] Iteration 8000 (0.602387 iter/s, 83.0032s/50 iters), loss = 0.00138859
I0621 13:31:32.591152 17579 solver.cpp:238]     Train net output #0: loss = 0.00093253 (* 1 = 0.00093253 loss)
I0621 13:31:32.591181 17579 sgd_solver.cpp:105] Iteration 8000, lr = 0.005
I0621 13:32:43.391903 17579 solver.cpp:219] Iteration 8050 (0.706215 iter/s, 70.8s/50 iters), loss = 0.00263699
I0621 13:32:43.392045 17579 solver.cpp:238]     Train net output #0: loss = 0.00422957 (* 1 = 0.00422957 loss)
I0621 13:32:43.392073 17579 sgd_solver.cpp:105] Iteration 8050, lr = 0.005
I0621 13:33:54.218776 17579 solver.cpp:219] Iteration 8100 (0.705956 iter/s, 70.8259s/50 iters), loss = 0.00232358
I0621 13:33:54.218957 17579 solver.cpp:238]     Train net output #0: loss = 0.00262397 (* 1 = 0.00262397 loss)
I0621 13:33:54.218989 17579 sgd_solver.cpp:105] Iteration 8100, lr = 0.005
I0621 13:35:05.032842 17579 solver.cpp:219] Iteration 8150 (0.706084 iter/s, 70.8131s/50 iters), loss = 0.00302174
I0621 13:35:05.032971 17579 solver.cpp:238]     Train net output #0: loss = 0.00154923 (* 1 = 0.00154923 loss)
I0621 13:35:05.033002 17579 sgd_solver.cpp:105] Iteration 8150, lr = 0.005
I0621 13:36:15.833197 17579 solver.cpp:219] Iteration 8200 (0.70622 iter/s, 70.7994s/50 iters), loss = 0.00259824
I0621 13:36:15.833411 17579 solver.cpp:238]     Train net output #0: loss = 0.00187344 (* 1 = 0.00187344 loss)
I0621 13:36:15.833441 17579 sgd_solver.cpp:105] Iteration 8200, lr = 0.005
I0621 13:37:26.647996 17579 solver.cpp:219] Iteration 8250 (0.706077 iter/s, 70.8138s/50 iters), loss = 0.001648
I0621 13:37:26.648211 17579 solver.cpp:238]     Train net output #0: loss = 0.00194392 (* 1 = 0.00194392 loss)
I0621 13:37:26.648239 17579 sgd_solver.cpp:105] Iteration 8250, lr = 0.005
I0621 13:38:37.452878 17579 solver.cpp:219] Iteration 8300 (0.706176 iter/s, 70.8039s/50 iters), loss = 0.00152157
I0621 13:38:37.453094 17579 solver.cpp:238]     Train net output #0: loss = 0.00247027 (* 1 = 0.00247027 loss)
I0621 13:38:37.453121 17579 sgd_solver.cpp:105] Iteration 8300, lr = 0.005
I0621 13:39:48.267570 17579 solver.cpp:219] Iteration 8350 (0.706078 iter/s, 70.8137s/50 iters), loss = 0.00256422
I0621 13:39:48.267724 17579 solver.cpp:238]     Train net output #0: loss = 0.00381992 (* 1 = 0.00381992 loss)
I0621 13:39:48.267752 17579 sgd_solver.cpp:105] Iteration 8350, lr = 0.005
I0621 13:40:59.101789 17579 solver.cpp:219] Iteration 8400 (0.705883 iter/s, 70.8333s/50 iters), loss = 0.00246189
I0621 13:40:59.107642 17579 solver.cpp:238]     Train net output #0: loss = 0.00232779 (* 1 = 0.00232779 loss)
I0621 13:40:59.107674 17579 sgd_solver.cpp:105] Iteration 8400, lr = 0.005
I0621 13:42:09.924033 17579 solver.cpp:219] Iteration 8450 (0.706059 iter/s, 70.8156s/50 iters), loss = 0.00187095
I0621 13:42:09.924760 17579 solver.cpp:238]     Train net output #0: loss = 0.000792472 (* 1 = 0.000792472 loss)
I0621 13:42:09.924789 17579 sgd_solver.cpp:105] Iteration 8450, lr = 0.005
I0621 13:43:19.304697 17579 solver.cpp:331] Iteration 8500, Testing net (#0)
I0621 13:43:31.389806 17579 solver.cpp:398]     Test net output #0: accuracy = 0.982353
I0621 13:43:31.389883 17579 solver.cpp:398]     Test net output #1: loss = 0.0718821 (* 1 = 0.0718821 loss)
I0621 13:43:32.800344 17579 solver.cpp:219] Iteration 8500 (0.603321 iter/s, 82.8747s/50 iters), loss = 0.00254642
I0621 13:43:32.800439 17579 solver.cpp:238]     Train net output #0: loss = 0.00229943 (* 1 = 0.00229943 loss)
I0621 13:43:32.800487 17579 sgd_solver.cpp:105] Iteration 8500, lr = 0.005
I0621 13:44:43.622037 17579 solver.cpp:219] Iteration 8550 (0.706007 iter/s, 70.8208s/50 iters), loss = 0.00133645
I0621 13:44:43.622191 17579 solver.cpp:238]     Train net output #0: loss = 0.00110912 (* 1 = 0.00110912 loss)
I0621 13:44:43.622221 17579 sgd_solver.cpp:105] Iteration 8550, lr = 0.005
I0621 13:45:54.425043 17579 solver.cpp:219] Iteration 8600 (0.706194 iter/s, 70.8021s/50 iters), loss = 0.00229866
I0621 13:45:54.425204 17579 solver.cpp:238]     Train net output #0: loss = 0.00109728 (* 1 = 0.00109728 loss)
I0621 13:45:54.425232 17579 sgd_solver.cpp:105] Iteration 8600, lr = 0.005
I0621 13:47:05.219490 17579 solver.cpp:219] Iteration 8650 (0.70628 iter/s, 70.7935s/50 iters), loss = 0.00196583
I0621 13:47:05.219683 17579 solver.cpp:238]     Train net output #0: loss = 0.00212614 (* 1 = 0.00212614 loss)
I0621 13:47:05.219713 17579 sgd_solver.cpp:105] Iteration 8650, lr = 0.005
I0621 13:48:16.025338 17579 solver.cpp:219] Iteration 8700 (0.706166 iter/s, 70.8049s/50 iters), loss = 0.00150555
I0621 13:48:16.025496 17579 solver.cpp:238]     Train net output #0: loss = 0.00246395 (* 1 = 0.00246395 loss)
I0621 13:48:16.025530 17579 sgd_solver.cpp:105] Iteration 8700, lr = 0.005
I0621 13:49:26.846521 17579 solver.cpp:219] Iteration 8750 (0.706013 iter/s, 70.8202s/50 iters), loss = 0.00265185
I0621 13:49:26.846669 17579 solver.cpp:238]     Train net output #0: loss = 0.0024656 (* 1 = 0.0024656 loss)
I0621 13:49:26.846698 17579 sgd_solver.cpp:105] Iteration 8750, lr = 0.005
I0621 13:50:37.646337 17579 solver.cpp:219] Iteration 8800 (0.706226 iter/s, 70.7988s/50 iters), loss = 0.0015463
I0621 13:50:37.646558 17579 solver.cpp:238]     Train net output #0: loss = 0.000845216 (* 1 = 0.000845216 loss)
I0621 13:50:37.646589 17579 sgd_solver.cpp:105] Iteration 8800, lr = 0.005
I0621 13:51:48.462074 17579 solver.cpp:219] Iteration 8850 (0.706068 iter/s, 70.8147s/50 iters), loss = 0.00246269
I0621 13:51:48.462296 17579 solver.cpp:238]     Train net output #0: loss = 0.00100654 (* 1 = 0.00100654 loss)
I0621 13:51:48.462327 17579 sgd_solver.cpp:105] Iteration 8850, lr = 0.005
I0621 13:52:59.266336 17579 solver.cpp:219] Iteration 8900 (0.706182 iter/s, 70.8033s/50 iters), loss = 0.00146333
I0621 13:52:59.266602 17579 solver.cpp:238]     Train net output #0: loss = 0.000763773 (* 1 = 0.000763773 loss)
I0621 13:52:59.266631 17579 sgd_solver.cpp:105] Iteration 8900, lr = 0.005
I0621 13:54:10.089849 17579 solver.cpp:219] Iteration 8950 (0.70599 iter/s, 70.8226s/50 iters), loss = 0.00161199
I0621 13:54:10.090023 17579 solver.cpp:238]     Train net output #0: loss = 0.000702614 (* 1 = 0.000702614 loss)
I0621 13:54:10.090050 17579 sgd_solver.cpp:105] Iteration 8950, lr = 0.005
I0621 13:55:19.484985 17579 solver.cpp:331] Iteration 9000, Testing net (#0)
I0621 13:55:31.547083 17579 solver.cpp:398]     Test net output #0: accuracy = 0.980392
I0621 13:55:31.547165 17579 solver.cpp:398]     Test net output #1: loss = 0.0720933 (* 1 = 0.0720933 loss)
I0621 13:55:31.554577 17579 compress_conv_layer.cu:174] 0.485894 1.88706e-10 0.970126
I0621 13:55:31.563197 17579 compress_conv_layer.cu:174] 0.485894 1.15089e-10 0.567107
I0621 13:55:31.571528 17579 compress_conv_layer.cu:174] 0.485894 2.06797e-11 0.760748
I0621 13:55:31.579740 17579 compress_conv_layer.cu:174] 0.485894 3.14945e-12 0.802131
I0621 13:55:31.592546 17579 compress_conv_layer.cu:174] 0.485894 1.00591e-11 0.467797
I0621 13:55:31.614667 17579 compress_conv_layer.cu:174] 0.485894 9.64859e-14 0.49523
I0621 13:55:31.658139 17579 compress_conv_layer.cu:174] 0.485894 1.75242e-13 0.48784
I0621 13:55:31.701442 17579 compress_conv_layer.cu:174] 0.485894 2.23154e-12 0.414321
I0621 13:55:31.744901 17579 compress_conv_layer.cu:174] 0.485894 1.93913e-12 0.439994
I0621 13:55:31.787871 17579 compress_conv_layer.cu:174] 0.485894 2.03792e-12 0.590501
I0621 13:55:31.831259 17579 compress_conv_layer.cu:174] 0.485894 5.61335e-12 0.468266
I0621 13:55:31.918337 17579 compress_conv_layer.cu:174] 0.485894 1.67909e-12 0.336202
I0621 13:55:32.101694 17579 compress_conv_layer.cu:174] 0.485894 3.4586e-12 0.299597
I0621 13:55:32.119858 17579 compress_conv_layer.cu:174] 0.485894 3.21591e-07 0.181085
I0621 13:55:32.358168 17579 compress_conv_layer.cu:174] 0.485894 1.88706e-10 0.970126
I0621 13:55:32.366161 17579 compress_conv_layer.cu:174] 0.485894 1.15089e-10 0.567107
I0621 13:55:32.374434 17579 compress_conv_layer.cu:174] 0.485894 2.06797e-11 0.760748
I0621 13:55:32.382549 17579 compress_conv_layer.cu:174] 0.485894 3.14945e-12 0.802131
I0621 13:55:32.395164 17579 compress_conv_layer.cu:174] 0.485894 1.00591e-11 0.467797
I0621 13:55:32.417104 17579 compress_conv_layer.cu:174] 0.485894 9.64859e-14 0.49523
I0621 13:55:32.459847 17579 compress_conv_layer.cu:174] 0.485894 1.75242e-13 0.48784
I0621 13:55:32.502709 17579 compress_conv_layer.cu:174] 0.485894 2.23154e-12 0.414321
I0621 13:55:32.545523 17579 compress_conv_layer.cu:174] 0.485894 1.93913e-12 0.439994
I0621 13:55:32.588234 17579 compress_conv_layer.cu:174] 0.485894 2.03792e-12 0.590501
I0621 13:55:32.631108 17579 compress_conv_layer.cu:174] 0.485894 5.61335e-12 0.468266
I0621 13:55:32.716691 17579 compress_conv_layer.cu:174] 0.485894 1.67909e-12 0.336202
I0621 13:55:32.897169 17579 compress_conv_layer.cu:174] 0.485894 3.4586e-12 0.299597
I0621 13:55:32.915285 17579 compress_conv_layer.cu:174] 0.485894 3.21591e-07 0.181085
I0621 13:55:33.153554 17579 compress_conv_layer.cu:174] 0.485894 1.88706e-10 0.970126
I0621 13:55:33.161530 17579 compress_conv_layer.cu:174] 0.485894 1.15089e-10 0.567107
I0621 13:55:33.169749 17579 compress_conv_layer.cu:174] 0.485894 2.06797e-11 0.760748
I0621 13:55:33.177845 17579 compress_conv_layer.cu:174] 0.485894 3.14945e-12 0.802131
I0621 13:55:33.190343 17579 compress_conv_layer.cu:174] 0.485894 1.00591e-11 0.467797
I0621 13:55:33.211917 17579 compress_conv_layer.cu:174] 0.485894 9.64859e-14 0.49523
I0621 13:55:33.254354 17579 compress_conv_layer.cu:174] 0.485894 1.75242e-13 0.48784
I0621 13:55:33.297477 17579 compress_conv_layer.cu:174] 0.485894 2.23154e-12 0.414321
I0621 13:55:33.340905 17579 compress_conv_layer.cu:174] 0.485894 1.93913e-12 0.439994
I0621 13:55:33.383903 17579 compress_conv_layer.cu:174] 0.485894 2.03792e-12 0.590501
I0621 13:55:33.427095 17579 compress_conv_layer.cu:174] 0.485894 5.61335e-12 0.468266
I0621 13:55:33.512986 17579 compress_conv_layer.cu:174] 0.485894 1.67909e-12 0.336202
I0621 13:55:33.693516 17579 compress_conv_layer.cu:174] 0.485894 3.4586e-12 0.299597
I0621 13:55:33.711658 17579 compress_conv_layer.cu:174] 0.485894 3.21591e-07 0.181085
I0621 13:55:33.949898 17579 compress_conv_layer.cu:174] 0.485894 1.88706e-10 0.970126
I0621 13:55:33.957864 17579 compress_conv_layer.cu:174] 0.485894 1.15089e-10 0.567107
I0621 13:55:33.966087 17579 compress_conv_layer.cu:174] 0.485894 2.06797e-11 0.760748
I0621 13:55:33.974200 17579 compress_conv_layer.cu:174] 0.485894 3.14945e-12 0.802131
I0621 13:55:33.986755 17579 compress_conv_layer.cu:174] 0.485894 1.00591e-11 0.467797
I0621 13:55:34.008348 17579 compress_conv_layer.cu:174] 0.485894 9.64859e-14 0.49523
I0621 13:55:34.050956 17579 compress_conv_layer.cu:174] 0.485894 1.75242e-13 0.48784
I0621 13:55:34.093858 17579 compress_conv_layer.cu:174] 0.485894 2.23154e-12 0.414321
I0621 13:55:34.136643 17579 compress_conv_layer.cu:174] 0.485894 1.93913e-12 0.439994
I0621 13:55:34.179163 17579 compress_conv_layer.cu:174] 0.485894 2.03792e-12 0.590501
I0621 13:55:34.221899 17579 compress_conv_layer.cu:174] 0.485894 5.61335e-12 0.468266
I0621 13:55:34.307698 17579 compress_conv_layer.cu:174] 0.485894 1.67909e-12 0.336202
I0621 13:55:34.488729 17579 compress_conv_layer.cu:174] 0.485894 3.4586e-12 0.299597
I0621 13:55:34.506886 17579 compress_conv_layer.cu:174] 0.485894 3.21591e-07 0.181085
I0621 13:55:34.744998 17579 compress_conv_layer.cu:174] 0.485894 1.88706e-10 0.970126
I0621 13:55:34.752949 17579 compress_conv_layer.cu:174] 0.485894 1.15089e-10 0.567107
I0621 13:55:34.761181 17579 compress_conv_layer.cu:174] 0.485894 2.06797e-11 0.760748
I0621 13:55:34.769302 17579 compress_conv_layer.cu:174] 0.485894 3.14945e-12 0.802131
I0621 13:55:34.781853 17579 compress_conv_layer.cu:174] 0.485894 1.00591e-11 0.467797
I0621 13:55:34.803423 17579 compress_conv_layer.cu:174] 0.485894 9.64859e-14 0.49523
I0621 13:55:34.846057 17579 compress_conv_layer.cu:174] 0.485894 1.75242e-13 0.48784
I0621 13:55:34.889053 17579 compress_conv_layer.cu:174] 0.485894 2.23154e-12 0.414321
I0621 13:55:34.932101 17579 compress_conv_layer.cu:174] 0.485894 1.93913e-12 0.439994
I0621 13:55:34.974614 17579 compress_conv_layer.cu:174] 0.485894 2.03792e-12 0.590501
I0621 13:55:35.017531 17579 compress_conv_layer.cu:174] 0.485894 5.61335e-12 0.468266
I0621 13:55:35.103410 17579 compress_conv_layer.cu:174] 0.485894 1.67909e-12 0.336202
I0621 13:55:35.284426 17579 compress_conv_layer.cu:174] 0.485894 3.4586e-12 0.299597
I0621 13:55:35.302587 17579 compress_conv_layer.cu:174] 0.485894 3.21591e-07 0.181085
I0621 13:55:35.532757 17579 solver.cpp:219] Iteration 9000 (0.585193 iter/s, 85.4419s/50 iters), loss = 0.00205605
I0621 13:55:35.532838 17579 solver.cpp:238]     Train net output #0: loss = 0.00142106 (* 1 = 0.00142106 loss)
I0621 13:55:35.532866 17579 sgd_solver.cpp:105] Iteration 9000, lr = 0.005
I0621 13:56:46.341279 17579 solver.cpp:219] Iteration 9050 (0.706137 iter/s, 70.8078s/50 iters), loss = 0.00265453
I0621 13:56:46.341428 17579 solver.cpp:238]     Train net output #0: loss = 0.00331047 (* 1 = 0.00331047 loss)
I0621 13:56:46.341456 17579 sgd_solver.cpp:105] Iteration 9050, lr = 0.005
I0621 13:57:57.140957 17579 solver.cpp:219] Iteration 9100 (0.706226 iter/s, 70.7988s/50 iters), loss = 0.00159691
I0621 13:57:57.141131 17579 solver.cpp:238]     Train net output #0: loss = 0.00261049 (* 1 = 0.00261049 loss)
I0621 13:57:57.141161 17579 sgd_solver.cpp:105] Iteration 9100, lr = 0.005
I0621 13:59:07.942931 17579 solver.cpp:219] Iteration 9150 (0.706204 iter/s, 70.8011s/50 iters), loss = 0.00185455
I0621 13:59:07.943140 17579 solver.cpp:238]     Train net output #0: loss = 0.00146443 (* 1 = 0.00146443 loss)
I0621 13:59:07.943172 17579 sgd_solver.cpp:105] Iteration 9150, lr = 0.005
I0621 14:00:18.745875 17579 solver.cpp:219] Iteration 9200 (0.706195 iter/s, 70.802s/50 iters), loss = 0.0031702
I0621 14:00:18.746156 17579 solver.cpp:238]     Train net output #0: loss = 0.00134542 (* 1 = 0.00134542 loss)
I0621 14:00:18.746187 17579 sgd_solver.cpp:105] Iteration 9200, lr = 0.005
I0621 14:01:29.562717 17579 solver.cpp:219] Iteration 9250 (0.706056 iter/s, 70.8159s/50 iters), loss = 0.00211704
I0621 14:01:29.562898 17579 solver.cpp:238]     Train net output #0: loss = 0.00124401 (* 1 = 0.00124401 loss)
I0621 14:01:29.562927 17579 sgd_solver.cpp:105] Iteration 9250, lr = 0.005
I0621 14:02:40.501390 17579 solver.cpp:219] Iteration 9300 (0.704843 iter/s, 70.9378s/50 iters), loss = 0.0020895
I0621 14:02:40.501541 17579 solver.cpp:238]     Train net output #0: loss = 0.000913018 (* 1 = 0.000913018 loss)
I0621 14:02:40.501572 17579 sgd_solver.cpp:105] Iteration 9300, lr = 0.005
I0621 14:03:51.286890 17579 solver.cpp:219] Iteration 9350 (0.706368 iter/s, 70.7846s/50 iters), loss = 0.00175007
I0621 14:03:51.287050 17579 solver.cpp:238]     Train net output #0: loss = 0.000677144 (* 1 = 0.000677144 loss)
I0621 14:03:51.287081 17579 sgd_solver.cpp:105] Iteration 9350, lr = 0.005
I0621 14:05:02.071315 17579 solver.cpp:219] Iteration 9400 (0.706379 iter/s, 70.7836s/50 iters), loss = 0.00189103
I0621 14:05:02.071501 17579 solver.cpp:238]     Train net output #0: loss = 0.00235173 (* 1 = 0.00235173 loss)
I0621 14:05:02.071537 17579 sgd_solver.cpp:105] Iteration 9400, lr = 0.005
I0621 14:06:12.859310 17579 solver.cpp:219] Iteration 9450 (0.706343 iter/s, 70.7871s/50 iters), loss = 0.00142654
I0621 14:06:12.859462 17579 solver.cpp:238]     Train net output #0: loss = 0.0013861 (* 1 = 0.0013861 loss)
I0621 14:06:12.859494 17579 sgd_solver.cpp:105] Iteration 9450, lr = 0.005
I0621 14:07:22.499333 17579 solver.cpp:331] Iteration 9500, Testing net (#0)
I0621 14:07:31.616621 17579 blocking_queue.cpp:49] Waiting for data
I0621 14:07:34.501096 17579 solver.cpp:398]     Test net output #0: accuracy = 0.981373
I0621 14:07:34.501193 17579 solver.cpp:398]     Test net output #1: loss = 0.0712594 (* 1 = 0.0712594 loss)
I0621 14:07:35.912396 17579 solver.cpp:219] Iteration 9500 (0.602032 iter/s, 83.0521s/50 iters), loss = 0.0021779
I0621 14:07:35.912506 17579 solver.cpp:238]     Train net output #0: loss = 0.00391045 (* 1 = 0.00391045 loss)
I0621 14:07:35.912539 17579 sgd_solver.cpp:105] Iteration 9500, lr = 0.005
I0621 14:08:46.709182 17579 solver.cpp:219] Iteration 9550 (0.706255 iter/s, 70.796s/50 iters), loss = 0.00180691
I0621 14:08:46.709350 17579 solver.cpp:238]     Train net output #0: loss = 0.00158352 (* 1 = 0.00158352 loss)
I0621 14:08:46.709383 17579 sgd_solver.cpp:105] Iteration 9550, lr = 0.005
I0621 14:09:57.506428 17579 solver.cpp:219] Iteration 9600 (0.706251 iter/s, 70.7964s/50 iters), loss = 0.00272136
I0621 14:09:57.506558 17579 solver.cpp:238]     Train net output #0: loss = 0.00335585 (* 1 = 0.00335585 loss)
I0621 14:09:57.506587 17579 sgd_solver.cpp:105] Iteration 9600, lr = 0.005
I0621 14:11:08.285586 17579 solver.cpp:219] Iteration 9650 (0.706432 iter/s, 70.7783s/50 iters), loss = 0.00198346
I0621 14:11:08.285758 17579 solver.cpp:238]     Train net output #0: loss = 0.00193804 (* 1 = 0.00193804 loss)
I0621 14:11:08.285789 17579 sgd_solver.cpp:105] Iteration 9650, lr = 0.005
I0621 14:12:19.086751 17579 solver.cpp:219] Iteration 9700 (0.706212 iter/s, 70.8002s/50 iters), loss = 0.00189696
I0621 14:12:19.086886 17579 solver.cpp:238]     Train net output #0: loss = 0.00456495 (* 1 = 0.00456495 loss)
I0621 14:12:19.086915 17579 sgd_solver.cpp:105] Iteration 9700, lr = 0.005
I0621 14:13:29.895509 17579 solver.cpp:219] Iteration 9750 (0.706136 iter/s, 70.8079s/50 iters), loss = 0.00212092
I0621 14:13:29.895660 17579 solver.cpp:238]     Train net output #0: loss = 0.0038955 (* 1 = 0.0038955 loss)
I0621 14:13:29.895689 17579 sgd_solver.cpp:105] Iteration 9750, lr = 0.005
I0621 14:14:40.675544 17579 solver.cpp:219] Iteration 9800 (0.706423 iter/s, 70.7791s/50 iters), loss = 0.00243147
I0621 14:14:40.675750 17579 solver.cpp:238]     Train net output #0: loss = 0.00122162 (* 1 = 0.00122162 loss)
I0621 14:14:40.675777 17579 sgd_solver.cpp:105] Iteration 9800, lr = 0.005
I0621 14:15:51.476200 17579 solver.cpp:219] Iteration 9850 (0.706218 iter/s, 70.7997s/50 iters), loss = 0.00202364
I0621 14:15:51.476541 17579 solver.cpp:238]     Train net output #0: loss = 0.00311891 (* 1 = 0.00311891 loss)
I0621 14:15:51.476572 17579 sgd_solver.cpp:105] Iteration 9850, lr = 0.005
I0621 14:17:02.288668 17579 solver.cpp:219] Iteration 9900 (0.706101 iter/s, 70.8114s/50 iters), loss = 0.001653
I0621 14:17:02.288864 17579 solver.cpp:238]     Train net output #0: loss = 0.000660795 (* 1 = 0.000660795 loss)
I0621 14:17:02.288893 17579 sgd_solver.cpp:105] Iteration 9900, lr = 0.005
I0621 14:18:13.079306 17579 solver.cpp:219] Iteration 9950 (0.706318 iter/s, 70.7897s/50 iters), loss = 0.00210354
I0621 14:18:13.079473 17579 solver.cpp:238]     Train net output #0: loss = 0.00342002 (* 1 = 0.00342002 loss)
I0621 14:18:13.079504 17579 sgd_solver.cpp:105] Iteration 9950, lr = 0.005
I0621 14:19:22.472460 17579 solver.cpp:331] Iteration 10000, Testing net (#0)
I0621 14:19:34.479360 17579 solver.cpp:398]     Test net output #0: accuracy = 0.980392
I0621 14:19:34.479447 17579 solver.cpp:398]     Test net output #1: loss = 0.0721103 (* 1 = 0.0721103 loss)
I0621 14:19:35.890094 17579 solver.cpp:219] Iteration 10000 (0.603794 iter/s, 82.8097s/50 iters), loss = 0.00147689
I0621 14:19:35.890204 17579 solver.cpp:238]     Train net output #0: loss = 0.00208735 (* 1 = 0.00208735 loss)
I0621 14:19:35.890228 17579 sgd_solver.cpp:105] Iteration 10000, lr = 0.005
I0621 14:20:46.670246 17579 solver.cpp:219] Iteration 10050 (0.706421 iter/s, 70.7793s/50 iters), loss = 0.00158687
I0621 14:20:46.670392 17579 solver.cpp:238]     Train net output #0: loss = 0.00250886 (* 1 = 0.00250886 loss)
I0621 14:20:46.670419 17579 sgd_solver.cpp:105] Iteration 10050, lr = 0.005
I0621 14:21:57.448992 17579 solver.cpp:219] Iteration 10100 (0.706436 iter/s, 70.7778s/50 iters), loss = 0.00176716
I0621 14:21:57.449182 17579 solver.cpp:238]     Train net output #0: loss = 0.00159977 (* 1 = 0.00159977 loss)
I0621 14:21:57.449211 17579 sgd_solver.cpp:105] Iteration 10100, lr = 0.005
I0621 14:23:08.237573 17579 solver.cpp:219] Iteration 10150 (0.706338 iter/s, 70.7876s/50 iters), loss = 0.00277044
I0621 14:23:08.237746 17579 solver.cpp:238]     Train net output #0: loss = 0.00351462 (* 1 = 0.00351462 loss)
I0621 14:23:08.237776 17579 sgd_solver.cpp:105] Iteration 10150, lr = 0.005
I0621 14:24:19.037626 17579 solver.cpp:219] Iteration 10200 (0.706223 iter/s, 70.7991s/50 iters), loss = 0.00160969
I0621 14:24:19.037771 17579 solver.cpp:238]     Train net output #0: loss = 0.000959873 (* 1 = 0.000959873 loss)
I0621 14:24:19.037801 17579 sgd_solver.cpp:105] Iteration 10200, lr = 0.005
I0621 14:25:29.808140 17579 solver.cpp:219] Iteration 10250 (0.706518 iter/s, 70.7696s/50 iters), loss = 0.00179189
I0621 14:25:29.808302 17579 solver.cpp:238]     Train net output #0: loss = 0.00148486 (* 1 = 0.00148486 loss)
I0621 14:25:29.808333 17579 sgd_solver.cpp:105] Iteration 10250, lr = 0.005
I0621 14:26:40.583429 17579 solver.cpp:219] Iteration 10300 (0.70647 iter/s, 70.7744s/50 iters), loss = 0.00102462
I0621 14:26:40.583561 17579 solver.cpp:238]     Train net output #0: loss = 0.0019415 (* 1 = 0.0019415 loss)
I0621 14:26:40.583590 17579 sgd_solver.cpp:105] Iteration 10300, lr = 0.005
I0621 14:27:51.365931 17579 solver.cpp:219] Iteration 10350 (0.706398 iter/s, 70.7816s/50 iters), loss = 0.00131839
I0621 14:27:51.366077 17579 solver.cpp:238]     Train net output #0: loss = 0.00311065 (* 1 = 0.00311065 loss)
I0621 14:27:51.366106 17579 sgd_solver.cpp:105] Iteration 10350, lr = 0.005
I0621 14:29:02.144646 17579 solver.cpp:219] Iteration 10400 (0.706436 iter/s, 70.7778s/50 iters), loss = 0.00112471
I0621 14:29:02.144783 17579 solver.cpp:238]     Train net output #0: loss = 0.00173583 (* 1 = 0.00173583 loss)
I0621 14:29:02.144816 17579 sgd_solver.cpp:105] Iteration 10400, lr = 0.005
I0621 14:30:12.922737 17579 solver.cpp:219] Iteration 10450 (0.706442 iter/s, 70.7772s/50 iters), loss = 0.00239119
I0621 14:30:12.922998 17579 solver.cpp:238]     Train net output #0: loss = 0.00145363 (* 1 = 0.00145363 loss)
I0621 14:30:12.923030 17579 sgd_solver.cpp:105] Iteration 10450, lr = 0.005
I0621 14:31:22.307869 17579 solver.cpp:331] Iteration 10500, Testing net (#0)
I0621 14:31:34.369242 17579 solver.cpp:398]     Test net output #0: accuracy = 0.984314
I0621 14:31:34.369324 17579 solver.cpp:398]     Test net output #1: loss = 0.0686301 (* 1 = 0.0686301 loss)
I0621 14:31:34.376785 17579 compress_conv_layer.cu:174] 0.513416 1.87998e-10 0.966527
I0621 14:31:34.385501 17579 compress_conv_layer.cu:174] 0.513416 1.14663e-10 0.565147
I0621 14:31:34.393920 17579 compress_conv_layer.cu:174] 0.513416 2.06017e-11 0.757449
I0621 14:31:34.402190 17579 compress_conv_layer.cu:174] 0.513416 3.13774e-12 0.799209
I0621 14:31:34.415124 17579 compress_conv_layer.cu:174] 0.513416 1.00213e-11 0.466205
I0621 14:31:34.437407 17579 compress_conv_layer.cu:174] 0.513416 9.61228e-14 0.493431
I0621 14:31:34.480954 17579 compress_conv_layer.cu:174] 0.513416 1.74591e-13 0.485854
I0621 14:31:34.524296 17579 compress_conv_layer.cu:174] 0.513416 2.22308e-12 0.412706
I0621 14:31:34.568397 17579 compress_conv_layer.cu:174] 0.513416 1.93197e-12 0.438405
I0621 14:31:34.611665 17579 compress_conv_layer.cu:174] 0.513416 2.03044e-12 0.588087
I0621 14:31:34.655083 17579 compress_conv_layer.cu:174] 0.513416 5.59253e-12 0.466379
I0621 14:31:34.743098 17579 compress_conv_layer.cu:174] 0.513416 1.67274e-12 0.334892
I0621 14:31:34.925719 17579 compress_conv_layer.cu:174] 0.513416 3.44559e-12 0.29845
I0621 14:31:34.943989 17579 compress_conv_layer.cu:174] 0.513416 3.20398e-07 0.182434
I0621 14:31:35.182564 17579 compress_conv_layer.cu:174] 0.513416 1.87998e-10 0.966527
I0621 14:31:35.190556 17579 compress_conv_layer.cu:174] 0.513416 1.14663e-10 0.565147
I0621 14:31:35.199043 17579 compress_conv_layer.cu:174] 0.513416 2.06017e-11 0.757449
I0621 14:31:35.207258 17579 compress_conv_layer.cu:174] 0.513416 3.13774e-12 0.799209
I0621 14:31:35.220026 17579 compress_conv_layer.cu:174] 0.513416 1.00213e-11 0.466205
I0621 14:31:35.241896 17579 compress_conv_layer.cu:174] 0.513416 9.61228e-14 0.493431
I0621 14:31:35.284776 17579 compress_conv_layer.cu:174] 0.513416 1.74591e-13 0.485854
I0621 14:31:35.328351 17579 compress_conv_layer.cu:174] 0.513416 2.22308e-12 0.412706
I0621 14:31:35.372218 17579 compress_conv_layer.cu:174] 0.513416 1.93197e-12 0.438405
I0621 14:31:35.415674 17579 compress_conv_layer.cu:174] 0.513416 2.03044e-12 0.588087
I0621 14:31:35.459520 17579 compress_conv_layer.cu:174] 0.513416 5.59253e-12 0.466379
I0621 14:31:35.546456 17579 compress_conv_layer.cu:174] 0.513416 1.67274e-12 0.334892
I0621 14:31:35.725702 17579 compress_conv_layer.cu:174] 0.513416 3.44559e-12 0.29845
I0621 14:31:35.743777 17579 compress_conv_layer.cu:174] 0.513416 3.20398e-07 0.182434
I0621 14:31:35.982061 17579 compress_conv_layer.cu:174] 0.513416 1.87998e-10 0.966527
I0621 14:31:35.990033 17579 compress_conv_layer.cu:174] 0.513416 1.14663e-10 0.565147
I0621 14:31:35.998270 17579 compress_conv_layer.cu:174] 0.513416 2.06017e-11 0.757449
I0621 14:31:36.006451 17579 compress_conv_layer.cu:174] 0.513416 3.13774e-12 0.799209
I0621 14:31:36.019120 17579 compress_conv_layer.cu:174] 0.513416 1.00213e-11 0.466205
I0621 14:31:36.041015 17579 compress_conv_layer.cu:174] 0.513416 9.61228e-14 0.493431
I0621 14:31:36.083719 17579 compress_conv_layer.cu:174] 0.513416 1.74591e-13 0.485854
I0621 14:31:36.126847 17579 compress_conv_layer.cu:174] 0.513416 2.22308e-12 0.412706
I0621 14:31:36.170367 17579 compress_conv_layer.cu:174] 0.513416 1.93197e-12 0.438405
I0621 14:31:36.214694 17579 compress_conv_layer.cu:174] 0.513416 2.03044e-12 0.588087
I0621 14:31:36.258380 17579 compress_conv_layer.cu:174] 0.513416 5.59253e-12 0.466379
I0621 14:31:36.345137 17579 compress_conv_layer.cu:174] 0.513416 1.67274e-12 0.334892
I0621 14:31:36.524837 17579 compress_conv_layer.cu:174] 0.513416 3.44559e-12 0.29845
I0621 14:31:36.543174 17579 compress_conv_layer.cu:174] 0.513416 3.20398e-07 0.182434
I0621 14:31:36.781656 17579 compress_conv_layer.cu:174] 0.513416 1.87998e-10 0.966527
I0621 14:31:36.789669 17579 compress_conv_layer.cu:174] 0.513416 1.14663e-10 0.565147
I0621 14:31:36.797946 17579 compress_conv_layer.cu:174] 0.513416 2.06017e-11 0.757449
I0621 14:31:36.806061 17579 compress_conv_layer.cu:174] 0.513416 3.13774e-12 0.799209
I0621 14:31:36.818742 17579 compress_conv_layer.cu:174] 0.513416 1.00213e-11 0.466205
I0621 14:31:36.840605 17579 compress_conv_layer.cu:174] 0.513416 9.61228e-14 0.493431
I0621 14:31:36.883347 17579 compress_conv_layer.cu:174] 0.513416 1.74591e-13 0.485854
I0621 14:31:36.926681 17579 compress_conv_layer.cu:174] 0.513416 2.22308e-12 0.412706
I0621 14:31:36.970479 17579 compress_conv_layer.cu:174] 0.513416 1.93197e-12 0.438405
I0621 14:31:37.014173 17579 compress_conv_layer.cu:174] 0.513416 2.03044e-12 0.588087
I0621 14:31:37.057636 17579 compress_conv_layer.cu:174] 0.513416 5.59253e-12 0.466379
I0621 14:31:37.143991 17579 compress_conv_layer.cu:174] 0.513416 1.67274e-12 0.334892
I0621 14:31:37.324493 17579 compress_conv_layer.cu:174] 0.513416 3.44559e-12 0.29845
I0621 14:31:37.342545 17579 compress_conv_layer.cu:174] 0.513416 3.20398e-07 0.182434
I0621 14:31:37.580898 17579 compress_conv_layer.cu:174] 0.513416 1.87998e-10 0.966527
I0621 14:31:37.588865 17579 compress_conv_layer.cu:174] 0.513416 1.14663e-10 0.565147
I0621 14:31:37.597105 17579 compress_conv_layer.cu:174] 0.513416 2.06017e-11 0.757449
I0621 14:31:37.605204 17579 compress_conv_layer.cu:174] 0.513416 3.13774e-12 0.799209
I0621 14:31:37.617764 17579 compress_conv_layer.cu:174] 0.513416 1.00213e-11 0.466205
I0621 14:31:37.639430 17579 compress_conv_layer.cu:174] 0.513416 9.61228e-14 0.493431
I0621 14:31:37.682066 17579 compress_conv_layer.cu:174] 0.513416 1.74591e-13 0.485854
I0621 14:31:37.725569 17579 compress_conv_layer.cu:174] 0.513416 2.22308e-12 0.412706
I0621 14:31:37.769192 17579 compress_conv_layer.cu:174] 0.513416 1.93197e-12 0.438405
I0621 14:31:37.812292 17579 compress_conv_layer.cu:174] 0.513416 2.03044e-12 0.588087
I0621 14:31:37.911306 17579 compress_conv_layer.cu:174] 0.513416 5.59253e-12 0.466379
I0621 14:31:38.001344 17579 compress_conv_layer.cu:174] 0.513416 1.67274e-12 0.334892
I0621 14:31:38.186311 17579 compress_conv_layer.cu:174] 0.513416 3.44559e-12 0.29845
I0621 14:31:38.205128 17579 compress_conv_layer.cu:174] 0.513416 3.20398e-07 0.182434
I0621 14:31:38.435864 17579 solver.cpp:219] Iteration 10500 (0.584714 iter/s, 85.512s/50 iters), loss = 0.0038113
I0621 14:31:38.435958 17579 solver.cpp:238]     Train net output #0: loss = 0.00159238 (* 1 = 0.00159238 loss)
I0621 14:31:38.435984 17579 sgd_solver.cpp:105] Iteration 10500, lr = 0.005
I0621 14:32:49.231798 17579 solver.cpp:219] Iteration 10550 (0.706264 iter/s, 70.7951s/50 iters), loss = 0.00317053
I0621 14:32:49.231982 17579 solver.cpp:238]     Train net output #0: loss = 0.00165853 (* 1 = 0.00165853 loss)
I0621 14:32:49.232013 17579 sgd_solver.cpp:105] Iteration 10550, lr = 0.005
I0621 14:34:00.015465 17579 solver.cpp:219] Iteration 10600 (0.706387 iter/s, 70.7827s/50 iters), loss = 0.00253886
I0621 14:34:00.015602 17579 solver.cpp:238]     Train net output #0: loss = 0.00576259 (* 1 = 0.00576259 loss)
I0621 14:34:00.015631 17579 sgd_solver.cpp:105] Iteration 10600, lr = 0.005
I0621 14:35:10.811610 17579 solver.cpp:219] Iteration 10650 (0.706262 iter/s, 70.7952s/50 iters), loss = 0.00424433
I0621 14:35:10.811796 17579 solver.cpp:238]     Train net output #0: loss = 0.00307099 (* 1 = 0.00307099 loss)
I0621 14:35:10.811823 17579 sgd_solver.cpp:105] Iteration 10650, lr = 0.005
I0621 14:36:21.616262 17579 solver.cpp:219] Iteration 10700 (0.706178 iter/s, 70.8037s/50 iters), loss = 0.00283711
I0621 14:36:21.616425 17579 solver.cpp:238]     Train net output #0: loss = 0.00197433 (* 1 = 0.00197433 loss)
I0621 14:36:21.616453 17579 sgd_solver.cpp:105] Iteration 10700, lr = 0.005
I0621 14:37:32.411626 17579 solver.cpp:219] Iteration 10750 (0.70627 iter/s, 70.7944s/50 iters), loss = 0.00214784
I0621 14:37:32.411834 17579 solver.cpp:238]     Train net output #0: loss = 0.00183451 (* 1 = 0.00183451 loss)
I0621 14:37:32.411864 17579 sgd_solver.cpp:105] Iteration 10750, lr = 0.005
I0621 14:38:43.204017 17579 solver.cpp:219] Iteration 10800 (0.7063 iter/s, 70.7914s/50 iters), loss = 0.00200603
I0621 14:38:43.204201 17579 solver.cpp:238]     Train net output #0: loss = 0.00128757 (* 1 = 0.00128757 loss)
I0621 14:38:43.204233 17579 sgd_solver.cpp:105] Iteration 10800, lr = 0.005
I0621 14:39:53.998679 17579 solver.cpp:219] Iteration 10850 (0.706277 iter/s, 70.7937s/50 iters), loss = 0.00200875
I0621 14:39:53.998843 17579 solver.cpp:238]     Train net output #0: loss = 0.00115062 (* 1 = 0.00115062 loss)
I0621 14:39:53.998872 17579 sgd_solver.cpp:105] Iteration 10850, lr = 0.005
I0621 14:41:04.777894 17579 solver.cpp:219] Iteration 10900 (0.706431 iter/s, 70.7783s/50 iters), loss = 0.00189832
I0621 14:41:04.778036 17579 solver.cpp:238]     Train net output #0: loss = 0.00489183 (* 1 = 0.00489183 loss)
I0621 14:41:04.778065 17579 sgd_solver.cpp:105] Iteration 10900, lr = 0.005
I0621 14:42:15.555577 17579 solver.cpp:219] Iteration 10950 (0.706446 iter/s, 70.7768s/50 iters), loss = 0.00144609
I0621 14:42:15.555735 17579 solver.cpp:238]     Train net output #0: loss = 0.000912748 (* 1 = 0.000912748 loss)
I0621 14:42:15.555765 17579 sgd_solver.cpp:105] Iteration 10950, lr = 0.005
I0621 14:43:24.922071 17579 solver.cpp:331] Iteration 11000, Testing net (#0)
I0621 14:43:36.910327 17579 solver.cpp:398]     Test net output #0: accuracy = 0.980392
I0621 14:43:36.910405 17579 solver.cpp:398]     Test net output #1: loss = 0.0700692 (* 1 = 0.0700692 loss)
I0621 14:43:38.321506 17579 solver.cpp:219] Iteration 11000 (0.604121 iter/s, 82.7649s/50 iters), loss = 0.00139135
I0621 14:43:38.321621 17579 solver.cpp:238]     Train net output #0: loss = 0.00100492 (* 1 = 0.00100492 loss)
I0621 14:43:38.321653 17579 sgd_solver.cpp:105] Iteration 11000, lr = 0.005
I0621 14:44:49.103665 17579 solver.cpp:219] Iteration 11050 (0.706401 iter/s, 70.7813s/50 iters), loss = 0.00316831
I0621 14:44:49.103812 17579 solver.cpp:238]     Train net output #0: loss = 0.00258446 (* 1 = 0.00258446 loss)
I0621 14:44:49.103842 17579 sgd_solver.cpp:105] Iteration 11050, lr = 0.005
I0621 14:45:59.890274 17579 solver.cpp:219] Iteration 11100 (0.706357 iter/s, 70.7857s/50 iters), loss = 0.00220963
I0621 14:45:59.890408 17579 solver.cpp:238]     Train net output #0: loss = 0.00103175 (* 1 = 0.00103175 loss)
I0621 14:45:59.890437 17579 sgd_solver.cpp:105] Iteration 11100, lr = 0.005
I0621 14:47:10.672935 17579 solver.cpp:219] Iteration 11150 (0.706397 iter/s, 70.7818s/50 iters), loss = 0.00192547
I0621 14:47:10.673079 17579 solver.cpp:238]     Train net output #0: loss = 0.0039325 (* 1 = 0.0039325 loss)
I0621 14:47:10.673107 17579 sgd_solver.cpp:105] Iteration 11150, lr = 0.005
I0621 14:48:21.464184 17579 solver.cpp:219] Iteration 11200 (0.706311 iter/s, 70.7903s/50 iters), loss = 0.00215467
I0621 14:48:21.464386 17579 solver.cpp:238]     Train net output #0: loss = 0.00237272 (* 1 = 0.00237272 loss)
I0621 14:48:21.464416 17579 sgd_solver.cpp:105] Iteration 11200, lr = 0.005
I0621 14:49:32.252508 17579 solver.cpp:219] Iteration 11250 (0.706341 iter/s, 70.7874s/50 iters), loss = 0.00154533
I0621 14:49:32.252655 17579 solver.cpp:238]     Train net output #0: loss = 0.00167686 (* 1 = 0.00167686 loss)
I0621 14:49:32.252682 17579 sgd_solver.cpp:105] Iteration 11250, lr = 0.005
I0621 14:50:43.044719 17579 solver.cpp:219] Iteration 11300 (0.706301 iter/s, 70.7913s/50 iters), loss = 0.00173337
I0621 14:50:43.044863 17579 solver.cpp:238]     Train net output #0: loss = 0.00259203 (* 1 = 0.00259203 loss)
I0621 14:50:43.044894 17579 sgd_solver.cpp:105] Iteration 11300, lr = 0.005
I0621 14:51:53.853204 17579 solver.cpp:219] Iteration 11350 (0.706139 iter/s, 70.8075s/50 iters), loss = 0.00238758
I0621 14:51:53.853452 17579 solver.cpp:238]     Train net output #0: loss = 0.00186074 (* 1 = 0.00186074 loss)
I0621 14:51:53.853487 17579 sgd_solver.cpp:105] Iteration 11350, lr = 0.005
I0621 14:53:04.639498 17579 solver.cpp:219] Iteration 11400 (0.706361 iter/s, 70.7853s/50 iters), loss = 0.00148986
I0621 14:53:04.639719 17579 solver.cpp:238]     Train net output #0: loss = 0.00128658 (* 1 = 0.00128658 loss)
I0621 14:53:04.639750 17579 sgd_solver.cpp:105] Iteration 11400, lr = 0.005
I0621 14:54:15.423629 17579 solver.cpp:219] Iteration 11450 (0.706383 iter/s, 70.7831s/50 iters), loss = 0.00201079
I0621 14:54:15.423802 17579 solver.cpp:238]     Train net output #0: loss = 0.00380235 (* 1 = 0.00380235 loss)
I0621 14:54:15.423831 17579 sgd_solver.cpp:105] Iteration 11450, lr = 0.005
I0621 14:55:24.793009 17579 solver.cpp:331] Iteration 11500, Testing net (#0)
I0621 14:55:36.753145 17579 solver.cpp:398]     Test net output #0: accuracy = 0.981373
I0621 14:55:36.753231 17579 solver.cpp:398]     Test net output #1: loss = 0.0707587 (* 1 = 0.0707587 loss)
I0621 14:55:38.163488 17579 solver.cpp:219] Iteration 11500 (0.604311 iter/s, 82.7388s/50 iters), loss = 0.00204567
I0621 14:55:38.163588 17579 solver.cpp:238]     Train net output #0: loss = 0.00236941 (* 1 = 0.00236941 loss)
I0621 14:55:38.163616 17579 sgd_solver.cpp:105] Iteration 11500, lr = 0.005
I0621 14:56:48.949445 17579 solver.cpp:219] Iteration 11550 (0.706363 iter/s, 70.7851s/50 iters), loss = 0.00162957
I0621 14:56:48.949604 17579 solver.cpp:238]     Train net output #0: loss = 0.00250794 (* 1 = 0.00250794 loss)
I0621 14:56:48.949635 17579 sgd_solver.cpp:105] Iteration 11550, lr = 0.005
I0621 14:57:59.734671 17579 solver.cpp:219] Iteration 11600 (0.706371 iter/s, 70.7843s/50 iters), loss = 0.00169795
I0621 14:57:59.734825 17579 solver.cpp:238]     Train net output #0: loss = 0.00186328 (* 1 = 0.00186328 loss)
I0621 14:57:59.734855 17579 sgd_solver.cpp:105] Iteration 11600, lr = 0.005
I0621 14:59:10.504828 17579 solver.cpp:219] Iteration 11650 (0.706522 iter/s, 70.7692s/50 iters), loss = 0.00158715
I0621 14:59:10.504992 17579 solver.cpp:238]     Train net output #0: loss = 0.00299413 (* 1 = 0.00299413 loss)
I0621 14:59:10.505022 17579 sgd_solver.cpp:105] Iteration 11650, lr = 0.005
I0621 15:00:21.272598 17579 solver.cpp:219] Iteration 11700 (0.706546 iter/s, 70.7668s/50 iters), loss = 0.002159
I0621 15:00:21.272737 17579 solver.cpp:238]     Train net output #0: loss = 0.00292446 (* 1 = 0.00292446 loss)
I0621 15:00:21.272765 17579 sgd_solver.cpp:105] Iteration 11700, lr = 0.005
I0621 15:01:32.040163 17579 solver.cpp:219] Iteration 11750 (0.706547 iter/s, 70.7667s/50 iters), loss = 0.00110908
I0621 15:01:32.040298 17579 solver.cpp:238]     Train net output #0: loss = 0.00188436 (* 1 = 0.00188436 loss)
I0621 15:01:32.040326 17579 sgd_solver.cpp:105] Iteration 11750, lr = 0.005
I0621 15:02:42.809231 17579 solver.cpp:219] Iteration 11800 (0.706532 iter/s, 70.7682s/50 iters), loss = 0.00166338
I0621 15:02:42.809376 17579 solver.cpp:238]     Train net output #0: loss = 0.00191687 (* 1 = 0.00191687 loss)
I0621 15:02:42.809404 17579 sgd_solver.cpp:105] Iteration 11800, lr = 0.005
I0621 15:03:53.574697 17579 solver.cpp:219] Iteration 11850 (0.706568 iter/s, 70.7646s/50 iters), loss = 0.00182613
I0621 15:03:53.574852 17579 solver.cpp:238]     Train net output #0: loss = 0.000986371 (* 1 = 0.000986371 loss)
I0621 15:03:53.574882 17579 sgd_solver.cpp:105] Iteration 11850, lr = 0.005
I0621 15:05:04.359637 17579 solver.cpp:219] Iteration 11900 (0.706374 iter/s, 70.784s/50 iters), loss = 0.00162855
I0621 15:05:04.359792 17579 solver.cpp:238]     Train net output #0: loss = 0.00239494 (* 1 = 0.00239494 loss)
I0621 15:05:04.359822 17579 sgd_solver.cpp:105] Iteration 11900, lr = 0.005
I0621 15:06:15.132238 17579 solver.cpp:219] Iteration 11950 (0.706497 iter/s, 70.7717s/50 iters), loss = 0.00191167
I0621 15:06:15.132362 17579 solver.cpp:238]     Train net output #0: loss = 0.00221301 (* 1 = 0.00221301 loss)
I0621 15:06:15.132392 17579 sgd_solver.cpp:105] Iteration 11950, lr = 0.005
I0621 15:07:24.495520 17579 solver.cpp:448] Snapshotting to binary proto file mobilenet/mobile_pruning_iter_12000.caffemodel
I0621 15:07:24.619750 17579 sgd_solver.cpp:273] Snapshotting solver state to binary proto file mobilenet/mobile_pruning_iter_12000.solverstate
I0621 15:07:24.675875 17579 solver.cpp:331] Iteration 12000, Testing net (#0)
I0621 15:07:36.632124 17579 solver.cpp:398]     Test net output #0: accuracy = 0.981373
I0621 15:07:36.632216 17579 solver.cpp:398]     Test net output #1: loss = 0.0734186 (* 1 = 0.0734186 loss)
I0621 15:07:36.639631 17579 compress_conv_layer.cu:174] 0.538035 1.87291e-10 0.962797
I0621 15:07:36.648283 17579 compress_conv_layer.cu:174] 0.538035 1.14236e-10 0.563012
I0621 15:07:36.656600 17579 compress_conv_layer.cu:174] 0.538035 2.05236e-11 0.754696
I0621 15:07:36.664836 17579 compress_conv_layer.cu:174] 0.538035 3.12603e-12 0.796218
I0621 15:07:36.677528 17579 compress_conv_layer.cu:174] 0.538035 9.98361e-12 0.464541
I0621 15:07:36.699554 17579 compress_conv_layer.cu:174] 0.538035 9.57671e-14 0.491662
I0621 15:07:36.742975 17579 compress_conv_layer.cu:174] 0.538035 1.73941e-13 0.483944
I0621 15:07:36.786229 17579 compress_conv_layer.cu:174] 0.538035 2.21462e-12 0.411104
I0621 15:07:36.829977 17579 compress_conv_layer.cu:174] 0.538035 1.92482e-12 0.436816
I0621 15:07:36.872961 17579 compress_conv_layer.cu:174] 0.538035 2.02296e-12 0.585744
I0621 15:07:36.915928 17579 compress_conv_layer.cu:174] 0.538035 5.57171e-12 0.464534
I0621 15:07:37.003077 17579 compress_conv_layer.cu:174] 0.538035 1.66648e-12 0.333472
I0621 15:07:37.185098 17579 compress_conv_layer.cu:174] 0.538035 3.43258e-12 0.297312
I0621 15:07:37.203322 17579 compress_conv_layer.cu:174] 0.538035 3.19204e-07 0.183715
I0621 15:07:37.441679 17579 compress_conv_layer.cu:174] 0.538035 1.87291e-10 0.962797
I0621 15:07:37.449642 17579 compress_conv_layer.cu:174] 0.538035 1.14236e-10 0.563012
I0621 15:07:37.457900 17579 compress_conv_layer.cu:174] 0.538035 2.05236e-11 0.754696
I0621 15:07:37.466001 17579 compress_conv_layer.cu:174] 0.538035 3.12603e-12 0.796218
I0621 15:07:37.478489 17579 compress_conv_layer.cu:174] 0.538035 9.98361e-12 0.464541
I0621 15:07:37.500046 17579 compress_conv_layer.cu:174] 0.538035 9.57671e-14 0.491662
I0621 15:07:37.542673 17579 compress_conv_layer.cu:174] 0.538035 1.73941e-13 0.483944
I0621 15:07:37.585731 17579 compress_conv_layer.cu:174] 0.538035 2.21462e-12 0.411104
I0621 15:07:37.628882 17579 compress_conv_layer.cu:174] 0.538035 1.92482e-12 0.436816
I0621 15:07:37.671528 17579 compress_conv_layer.cu:174] 0.538035 2.02296e-12 0.585744
I0621 15:07:37.714531 17579 compress_conv_layer.cu:174] 0.538035 5.57171e-12 0.464534
I0621 15:07:37.800264 17579 compress_conv_layer.cu:174] 0.538035 1.66648e-12 0.333472
I0621 15:07:37.979780 17579 compress_conv_layer.cu:174] 0.538035 3.43258e-12 0.297312
I0621 15:07:37.998111 17579 compress_conv_layer.cu:174] 0.538035 3.19204e-07 0.183715
I0621 15:07:38.236330 17579 compress_conv_layer.cu:174] 0.538035 1.87291e-10 0.962797
I0621 15:07:38.244283 17579 compress_conv_layer.cu:174] 0.538035 1.14236e-10 0.563012
I0621 15:07:38.252527 17579 compress_conv_layer.cu:174] 0.538035 2.05236e-11 0.754696
I0621 15:07:38.260653 17579 compress_conv_layer.cu:174] 0.538035 3.12603e-12 0.796218
I0621 15:07:38.273152 17579 compress_conv_layer.cu:174] 0.538035 9.98361e-12 0.464541
I0621 15:07:38.294785 17579 compress_conv_layer.cu:174] 0.538035 9.57671e-14 0.491662
I0621 15:07:38.337419 17579 compress_conv_layer.cu:174] 0.538035 1.73941e-13 0.483944
I0621 15:07:38.380676 17579 compress_conv_layer.cu:174] 0.538035 2.21462e-12 0.411104
I0621 15:07:38.424338 17579 compress_conv_layer.cu:174] 0.538035 1.92482e-12 0.436816
I0621 15:07:38.467234 17579 compress_conv_layer.cu:174] 0.538035 2.02296e-12 0.585744
I0621 15:07:38.510254 17579 compress_conv_layer.cu:174] 0.538035 5.57171e-12 0.464534
I0621 15:07:38.595942 17579 compress_conv_layer.cu:174] 0.538035 1.66648e-12 0.333472
I0621 15:07:38.775430 17579 compress_conv_layer.cu:174] 0.538035 3.43258e-12 0.297312
I0621 15:07:38.793644 17579 compress_conv_layer.cu:174] 0.538035 3.19204e-07 0.183715
I0621 15:07:39.032006 17579 compress_conv_layer.cu:174] 0.538035 1.87291e-10 0.962797
I0621 15:07:39.039978 17579 compress_conv_layer.cu:174] 0.538035 1.14236e-10 0.563012
I0621 15:07:39.048249 17579 compress_conv_layer.cu:174] 0.538035 2.05236e-11 0.754696
I0621 15:07:39.056363 17579 compress_conv_layer.cu:174] 0.538035 3.12603e-12 0.796218
I0621 15:07:39.068853 17579 compress_conv_layer.cu:174] 0.538035 9.98361e-12 0.464541
I0621 15:07:39.090286 17579 compress_conv_layer.cu:174] 0.538035 9.57671e-14 0.491662
I0621 15:07:39.132721 17579 compress_conv_layer.cu:174] 0.538035 1.73941e-13 0.483944
I0621 15:07:39.175591 17579 compress_conv_layer.cu:174] 0.538035 2.21462e-12 0.411104
I0621 15:07:39.218896 17579 compress_conv_layer.cu:174] 0.538035 1.92482e-12 0.436816
I0621 15:07:39.261740 17579 compress_conv_layer.cu:174] 0.538035 2.02296e-12 0.585744
I0621 15:07:39.305130 17579 compress_conv_layer.cu:174] 0.538035 5.57171e-12 0.464534
I0621 15:07:39.391088 17579 compress_conv_layer.cu:174] 0.538035 1.66648e-12 0.333472
I0621 15:07:39.570593 17579 compress_conv_layer.cu:174] 0.538035 3.43258e-12 0.297312
I0621 15:07:39.588742 17579 compress_conv_layer.cu:174] 0.538035 3.19204e-07 0.183715
I0621 15:07:39.827062 17579 compress_conv_layer.cu:174] 0.538035 1.87291e-10 0.962797
I0621 15:07:39.835011 17579 compress_conv_layer.cu:174] 0.538035 1.14236e-10 0.563012
I0621 15:07:39.843276 17579 compress_conv_layer.cu:174] 0.538035 2.05236e-11 0.754696
I0621 15:07:39.851393 17579 compress_conv_layer.cu:174] 0.538035 3.12603e-12 0.796218
I0621 15:07:39.863903 17579 compress_conv_layer.cu:174] 0.538035 9.98361e-12 0.464541
I0621 15:07:39.885378 17579 compress_conv_layer.cu:174] 0.538035 9.57671e-14 0.491662
I0621 15:07:39.927952 17579 compress_conv_layer.cu:174] 0.538035 1.73941e-13 0.483944
I0621 15:07:39.970800 17579 compress_conv_layer.cu:174] 0.538035 2.21462e-12 0.411104
I0621 15:07:40.014021 17579 compress_conv_layer.cu:174] 0.538035 1.92482e-12 0.436816
I0621 15:07:40.056430 17579 compress_conv_layer.cu:174] 0.538035 2.02296e-12 0.585744
I0621 15:07:40.099174 17579 compress_conv_layer.cu:174] 0.538035 5.57171e-12 0.464534
I0621 15:07:40.185129 17579 compress_conv_layer.cu:174] 0.538035 1.66648e-12 0.333472
I0621 15:07:40.365108 17579 compress_conv_layer.cu:174] 0.538035 3.43258e-12 0.297312
I0621 15:07:40.383395 17579 compress_conv_layer.cu:174] 0.538035 3.19204e-07 0.183715
I0621 15:07:40.613680 17579 solver.cpp:219] Iteration 12000 (0.584929 iter/s, 85.4804s/50 iters), loss = 0.00240016
I0621 15:07:40.613762 17579 solver.cpp:238]     Train net output #0: loss = 0.00360411 (* 1 = 0.00360411 loss)
I0621 15:07:40.613790 17579 sgd_solver.cpp:105] Iteration 12000, lr = 0.005
I0621 15:08:51.386274 17579 solver.cpp:219] Iteration 12050 (0.706497 iter/s, 70.7718s/50 iters), loss = 0.00259177
I0621 15:08:51.386504 17579 solver.cpp:238]     Train net output #0: loss = 0.00149407 (* 1 = 0.00149407 loss)
I0621 15:08:51.386543 17579 sgd_solver.cpp:105] Iteration 12050, lr = 0.005
I0621 15:10:02.168797 17579 solver.cpp:219] Iteration 12100 (0.706399 iter/s, 70.7815s/50 iters), loss = 0.00156377
I0621 15:10:02.168963 17579 solver.cpp:238]     Train net output #0: loss = 0.000914167 (* 1 = 0.000914167 loss)
I0621 15:10:02.168992 17579 sgd_solver.cpp:105] Iteration 12100, lr = 0.005
I0621 15:11:12.944772 17579 solver.cpp:219] Iteration 12150 (0.706464 iter/s, 70.7751s/50 iters), loss = 0.00336856
I0621 15:11:12.944913 17579 solver.cpp:238]     Train net output #0: loss = 0.00329954 (* 1 = 0.00329954 loss)
I0621 15:11:12.944942 17579 sgd_solver.cpp:105] Iteration 12150, lr = 0.005
I0621 15:12:23.723577 17579 solver.cpp:219] Iteration 12200 (0.706435 iter/s, 70.7779s/50 iters), loss = 0.00192468
I0621 15:12:23.723728 17579 solver.cpp:238]     Train net output #0: loss = 0.00419382 (* 1 = 0.00419382 loss)
I0621 15:12:23.723757 17579 sgd_solver.cpp:105] Iteration 12200, lr = 0.005
I0621 15:13:34.497519 17579 solver.cpp:219] Iteration 12250 (0.706484 iter/s, 70.773s/50 iters), loss = 0.00177432
I0621 15:13:34.498775 17579 solver.cpp:238]     Train net output #0: loss = 0.00159984 (* 1 = 0.00159984 loss)
I0621 15:13:34.498805 17579 sgd_solver.cpp:105] Iteration 12250, lr = 0.005
I0621 15:14:45.298853 17579 solver.cpp:219] Iteration 12300 (0.706222 iter/s, 70.7993s/50 iters), loss = 0.00249571
I0621 15:14:45.299049 17579 solver.cpp:238]     Train net output #0: loss = 0.00463379 (* 1 = 0.00463379 loss)
I0621 15:14:45.299082 17579 sgd_solver.cpp:105] Iteration 12300, lr = 0.005
I0621 15:15:56.086318 17579 solver.cpp:219] Iteration 12350 (0.706349 iter/s, 70.7865s/50 iters), loss = 0.00208
I0621 15:15:56.086465 17579 solver.cpp:238]     Train net output #0: loss = 0.00289873 (* 1 = 0.00289873 loss)
I0621 15:15:56.086494 17579 sgd_solver.cpp:105] Iteration 12350, lr = 0.005
I0621 15:17:06.870218 17579 solver.cpp:219] Iteration 12400 (0.706384 iter/s, 70.783s/50 iters), loss = 0.00172147
I0621 15:17:06.870355 17579 solver.cpp:238]     Train net output #0: loss = 0.00112528 (* 1 = 0.00112528 loss)
I0621 15:17:06.870385 17579 sgd_solver.cpp:105] Iteration 12400, lr = 0.005
I0621 15:18:17.673571 17579 solver.cpp:219] Iteration 12450 (0.70619 iter/s, 70.8025s/50 iters), loss = 0.00186006
I0621 15:18:17.673710 17579 solver.cpp:238]     Train net output #0: loss = 0.0015491 (* 1 = 0.0015491 loss)
I0621 15:18:17.673738 17579 sgd_solver.cpp:105] Iteration 12450, lr = 0.005
I0621 15:19:27.058852 17579 solver.cpp:331] Iteration 12500, Testing net (#0)
I0621 15:19:39.067214 17579 solver.cpp:398]     Test net output #0: accuracy = 0.986275
I0621 15:19:39.067279 17579 solver.cpp:398]     Test net output #1: loss = 0.0691164 (* 1 = 0.0691164 loss)
I0621 15:19:40.478415 17579 solver.cpp:219] Iteration 12500 (0.603837 iter/s, 82.8038s/50 iters), loss = 0.00175169
I0621 15:19:40.478525 17579 solver.cpp:238]     Train net output #0: loss = 0.00146773 (* 1 = 0.00146773 loss)
I0621 15:19:40.478556 17579 sgd_solver.cpp:105] Iteration 12500, lr = 0.005
I0621 15:20:51.266993 17579 solver.cpp:219] Iteration 12550 (0.706338 iter/s, 70.7877s/50 iters), loss = 0.00150857
I0621 15:20:51.267148 17579 solver.cpp:238]     Train net output #0: loss = 0.00180615 (* 1 = 0.00180615 loss)
I0621 15:20:51.267176 17579 sgd_solver.cpp:105] Iteration 12550, lr = 0.005
I0621 15:22:02.064658 17579 solver.cpp:219] Iteration 12600 (0.706247 iter/s, 70.7967s/50 iters), loss = 0.00239409
I0621 15:22:02.064792 17579 solver.cpp:238]     Train net output #0: loss = 0.00185575 (* 1 = 0.00185575 loss)
I0621 15:22:02.064821 17579 sgd_solver.cpp:105] Iteration 12600, lr = 0.005
I0621 15:23:12.886260 17579 solver.cpp:219] Iteration 12650 (0.706009 iter/s, 70.8207s/50 iters), loss = 0.00184957
I0621 15:23:12.886421 17579 solver.cpp:238]     Train net output #0: loss = 0.00329787 (* 1 = 0.00329787 loss)
I0621 15:23:12.886449 17579 sgd_solver.cpp:105] Iteration 12650, lr = 0.005
I0621 15:24:23.689837 17579 solver.cpp:219] Iteration 12700 (0.706189 iter/s, 70.8026s/50 iters), loss = 0.00175063
I0621 15:24:23.690001 17579 solver.cpp:238]     Train net output #0: loss = 0.00214332 (* 1 = 0.00214332 loss)
I0621 15:24:23.690030 17579 sgd_solver.cpp:105] Iteration 12700, lr = 0.005
I0621 15:25:34.481966 17579 solver.cpp:219] Iteration 12750 (0.706303 iter/s, 70.7912s/50 iters), loss = 0.00196093
I0621 15:25:34.482112 17579 solver.cpp:238]     Train net output #0: loss = 0.0012259 (* 1 = 0.0012259 loss)
I0621 15:25:34.482141 17579 sgd_solver.cpp:105] Iteration 12750, lr = 0.005
I0621 15:26:45.254066 17579 solver.cpp:219] Iteration 12800 (0.706502 iter/s, 70.7712s/50 iters), loss = 0.00176096
I0621 15:26:45.254201 17579 solver.cpp:238]     Train net output #0: loss = 0.00115602 (* 1 = 0.00115602 loss)
I0621 15:26:45.254231 17579 sgd_solver.cpp:105] Iteration 12800, lr = 0.005
I0621 15:27:56.037137 17579 solver.cpp:219] Iteration 12850 (0.706393 iter/s, 70.7821s/50 iters), loss = 0.00119063
I0621 15:27:56.037284 17579 solver.cpp:238]     Train net output #0: loss = 0.00110196 (* 1 = 0.00110196 loss)
I0621 15:27:56.037312 17579 sgd_solver.cpp:105] Iteration 12850, lr = 0.005
I0621 15:29:06.814282 17579 solver.cpp:219] Iteration 12900 (0.706452 iter/s, 70.7762s/50 iters), loss = 0.00237317
I0621 15:29:06.814456 17579 solver.cpp:238]     Train net output #0: loss = 0.00190299 (* 1 = 0.00190299 loss)
I0621 15:29:06.814486 17579 sgd_solver.cpp:105] Iteration 12900, lr = 0.005
I0621 15:30:17.591506 17579 solver.cpp:219] Iteration 12950 (0.706452 iter/s, 70.7763s/50 iters), loss = 0.00444652
I0621 15:30:17.591719 17579 solver.cpp:238]     Train net output #0: loss = 0.00383617 (* 1 = 0.00383617 loss)
I0621 15:30:17.591749 17579 sgd_solver.cpp:105] Iteration 12950, lr = 0.005
I0621 15:31:26.957868 17579 solver.cpp:331] Iteration 13000, Testing net (#0)
I0621 15:31:38.922497 17579 solver.cpp:398]     Test net output #0: accuracy = 0.982353
I0621 15:31:38.922590 17579 solver.cpp:398]     Test net output #1: loss = 0.0689222 (* 1 = 0.0689222 loss)
I0621 15:31:40.333403 17579 solver.cpp:219] Iteration 13000 (0.604297 iter/s, 82.7408s/50 iters), loss = 0.00225693
I0621 15:31:40.333542 17579 solver.cpp:238]     Train net output #0: loss = 0.00200873 (* 1 = 0.00200873 loss)
I0621 15:31:40.333573 17579 sgd_solver.cpp:105] Iteration 13000, lr = 0.005
I0621 15:32:51.109814 17579 solver.cpp:219] Iteration 13050 (0.706459 iter/s, 70.7755s/50 iters), loss = 0.00149195
I0621 15:32:51.109968 17579 solver.cpp:238]     Train net output #0: loss = 0.0019706 (* 1 = 0.0019706 loss)
I0621 15:32:51.109997 17579 sgd_solver.cpp:105] Iteration 13050, lr = 0.005
I0621 15:34:01.883213 17579 solver.cpp:219] Iteration 13100 (0.70649 iter/s, 70.7724s/50 iters), loss = 0.00239032
I0621 15:34:01.883435 17579 solver.cpp:238]     Train net output #0: loss = 0.00154345 (* 1 = 0.00154345 loss)
I0621 15:34:01.883468 17579 sgd_solver.cpp:105] Iteration 13100, lr = 0.005
I0621 15:35:12.688171 17579 solver.cpp:219] Iteration 13150 (0.706175 iter/s, 70.8039s/50 iters), loss = 0.00271145
I0621 15:35:12.688326 17579 solver.cpp:238]     Train net output #0: loss = 0.00353151 (* 1 = 0.00353151 loss)
I0621 15:35:12.688354 17579 sgd_solver.cpp:105] Iteration 13150, lr = 0.005
I0621 15:36:23.476289 17579 solver.cpp:219] Iteration 13200 (0.706343 iter/s, 70.7872s/50 iters), loss = 0.00262668
I0621 15:36:23.476496 17579 solver.cpp:238]     Train net output #0: loss = 0.0045656 (* 1 = 0.0045656 loss)
I0621 15:36:23.476552 17579 sgd_solver.cpp:105] Iteration 13200, lr = 0.005
I0621 15:37:34.263620 17579 solver.cpp:219] Iteration 13250 (0.706351 iter/s, 70.7864s/50 iters), loss = 0.00300043
I0621 15:37:34.265180 17579 solver.cpp:238]     Train net output #0: loss = 0.00416838 (* 1 = 0.00416838 loss)
I0621 15:37:34.265208 17579 sgd_solver.cpp:105] Iteration 13250, lr = 0.005
I0621 15:38:45.050503 17579 solver.cpp:219] Iteration 13300 (0.706369 iter/s, 70.7845s/50 iters), loss = 0.000947994
I0621 15:38:45.050662 17579 solver.cpp:238]     Train net output #0: loss = 0.00101167 (* 1 = 0.00101167 loss)
I0621 15:38:45.050693 17579 sgd_solver.cpp:105] Iteration 13300, lr = 0.005
I0621 15:39:55.827922 17579 solver.cpp:219] Iteration 13350 (0.706449 iter/s, 70.7765s/50 iters), loss = 0.00356014
I0621 15:39:55.828080 17579 solver.cpp:238]     Train net output #0: loss = 0.00768291 (* 1 = 0.00768291 loss)
I0621 15:39:55.828109 17579 sgd_solver.cpp:105] Iteration 13350, lr = 0.005
I0621 15:41:06.603093 17579 solver.cpp:219] Iteration 13400 (0.706472 iter/s, 70.7742s/50 iters), loss = 0.00145999
I0621 15:41:06.603240 17579 solver.cpp:238]     Train net output #0: loss = 0.00258292 (* 1 = 0.00258292 loss)
I0621 15:41:06.603267 17579 sgd_solver.cpp:105] Iteration 13400, lr = 0.005
I0621 15:42:17.379767 17579 solver.cpp:219] Iteration 13450 (0.706457 iter/s, 70.7757s/50 iters), loss = 0.00165106
I0621 15:42:17.379959 17579 solver.cpp:238]     Train net output #0: loss = 0.00260854 (* 1 = 0.00260854 loss)
I0621 15:42:17.379988 17579 sgd_solver.cpp:105] Iteration 13450, lr = 0.005
I0621 15:43:26.756909 17579 solver.cpp:331] Iteration 13500, Testing net (#0)
I0621 15:43:38.731631 17579 solver.cpp:398]     Test net output #0: accuracy = 0.983334
I0621 15:43:38.731703 17579 solver.cpp:398]     Test net output #1: loss = 0.0718369 (* 1 = 0.0718369 loss)
I0621 15:43:38.739717 17579 compress_conv_layer.cu:174] 0.560306 1.86583e-10 0.959219
I0621 15:43:38.747704 17579 compress_conv_layer.cu:174] 0.560306 1.13809e-10 0.560964
I0621 15:43:38.756000 17579 compress_conv_layer.cu:174] 0.560306 2.04464e-11 0.751644
I0621 15:43:38.764276 17579 compress_conv_layer.cu:174] 0.560306 3.11432e-12 0.79333
I0621 15:43:38.777119 17579 compress_conv_layer.cu:174] 0.560306 9.94588e-12 0.462794
I0621 15:43:38.799365 17579 compress_conv_layer.cu:174] 0.560306 9.54113e-14 0.489768
I0621 15:43:38.842720 17579 compress_conv_layer.cu:174] 0.560306 1.7329e-13 0.482122
I0621 15:43:38.886070 17579 compress_conv_layer.cu:174] 0.560306 2.20638e-12 0.409577
I0621 15:43:38.929497 17579 compress_conv_layer.cu:174] 0.560306 1.91766e-12 0.43513
I0621 15:43:38.972795 17579 compress_conv_layer.cu:174] 0.560306 2.01548e-12 0.583398
I0621 15:43:39.016211 17579 compress_conv_layer.cu:174] 0.560306 5.5509e-12 0.462767
I0621 15:43:39.103426 17579 compress_conv_layer.cu:174] 0.560306 1.6603e-12 0.332096
I0621 15:43:39.286658 17579 compress_conv_layer.cu:174] 0.560306 3.41973e-12 0.296174
I0621 15:43:39.304803 17579 compress_conv_layer.cu:174] 0.560306 3.1801e-07 0.184986
I0621 15:43:39.543102 17579 compress_conv_layer.cu:174] 0.560306 1.86583e-10 0.959219
I0621 15:43:39.551057 17579 compress_conv_layer.cu:174] 0.560306 1.13809e-10 0.560964
I0621 15:43:39.559321 17579 compress_conv_layer.cu:174] 0.560306 2.04464e-11 0.751644
I0621 15:43:39.567453 17579 compress_conv_layer.cu:174] 0.560306 3.11432e-12 0.79333
I0621 15:43:39.580020 17579 compress_conv_layer.cu:174] 0.560306 9.94588e-12 0.462794
I0621 15:43:39.601569 17579 compress_conv_layer.cu:174] 0.560306 9.54113e-14 0.489768
I0621 15:43:39.643889 17579 compress_conv_layer.cu:174] 0.560306 1.7329e-13 0.482122
I0621 15:43:39.686653 17579 compress_conv_layer.cu:174] 0.560306 2.20638e-12 0.409577
I0621 15:43:39.729461 17579 compress_conv_layer.cu:174] 0.560306 1.91766e-12 0.43513
I0621 15:43:39.772157 17579 compress_conv_layer.cu:174] 0.560306 2.01548e-12 0.583398
I0621 15:43:39.815261 17579 compress_conv_layer.cu:174] 0.560306 5.5509e-12 0.462767
I0621 15:43:39.900928 17579 compress_conv_layer.cu:174] 0.560306 1.6603e-12 0.332096
I0621 15:43:40.081770 17579 compress_conv_layer.cu:174] 0.560306 3.41973e-12 0.296174
I0621 15:43:40.099931 17579 compress_conv_layer.cu:174] 0.560306 3.1801e-07 0.184986
I0621 15:43:40.338291 17579 compress_conv_layer.cu:174] 0.560306 1.86583e-10 0.959219
I0621 15:43:40.346245 17579 compress_conv_layer.cu:174] 0.560306 1.13809e-10 0.560964
I0621 15:43:40.354506 17579 compress_conv_layer.cu:174] 0.560306 2.04464e-11 0.751644
I0621 15:43:40.362648 17579 compress_conv_layer.cu:174] 0.560306 3.11432e-12 0.79333
I0621 15:43:40.375188 17579 compress_conv_layer.cu:174] 0.560306 9.94588e-12 0.462794
I0621 15:43:40.396842 17579 compress_conv_layer.cu:174] 0.560306 9.54113e-14 0.489768
I0621 15:43:40.439290 17579 compress_conv_layer.cu:174] 0.560306 1.7329e-13 0.482122
I0621 15:43:40.482312 17579 compress_conv_layer.cu:174] 0.560306 2.20638e-12 0.409577
I0621 15:43:40.525473 17579 compress_conv_layer.cu:174] 0.560306 1.91766e-12 0.43513
I0621 15:43:40.568332 17579 compress_conv_layer.cu:174] 0.560306 2.01548e-12 0.583398
I0621 15:43:40.611508 17579 compress_conv_layer.cu:174] 0.560306 5.5509e-12 0.462767
I0621 15:43:40.697257 17579 compress_conv_layer.cu:174] 0.560306 1.6603e-12 0.332096
I0621 15:43:40.877877 17579 compress_conv_layer.cu:174] 0.560306 3.41973e-12 0.296174
I0621 15:43:40.895992 17579 compress_conv_layer.cu:174] 0.560306 3.1801e-07 0.184986
I0621 15:43:41.134299 17579 compress_conv_layer.cu:174] 0.560306 1.86583e-10 0.959219
I0621 15:43:41.142267 17579 compress_conv_layer.cu:174] 0.560306 1.13809e-10 0.560964
I0621 15:43:41.150507 17579 compress_conv_layer.cu:174] 0.560306 2.04464e-11 0.751644
I0621 15:43:41.158637 17579 compress_conv_layer.cu:174] 0.560306 3.11432e-12 0.79333
I0621 15:43:41.171245 17579 compress_conv_layer.cu:174] 0.560306 9.94588e-12 0.462794
I0621 15:43:41.192989 17579 compress_conv_layer.cu:174] 0.560306 9.54113e-14 0.489768
I0621 15:43:41.235476 17579 compress_conv_layer.cu:174] 0.560306 1.7329e-13 0.482122
I0621 15:43:41.278446 17579 compress_conv_layer.cu:174] 0.560306 2.20638e-12 0.409577
I0621 15:43:41.321660 17579 compress_conv_layer.cu:174] 0.560306 1.91766e-12 0.43513
I0621 15:43:41.365074 17579 compress_conv_layer.cu:174] 0.560306 2.01548e-12 0.583398
I0621 15:43:41.408927 17579 compress_conv_layer.cu:174] 0.560306 5.5509e-12 0.462767
I0621 15:43:41.494904 17579 compress_conv_layer.cu:174] 0.560306 1.6603e-12 0.332096
I0621 15:43:41.675446 17579 compress_conv_layer.cu:174] 0.560306 3.41973e-12 0.296174
I0621 15:43:41.693544 17579 compress_conv_layer.cu:174] 0.560306 3.1801e-07 0.184986
I0621 15:43:41.931843 17579 compress_conv_layer.cu:174] 0.560306 1.86583e-10 0.959219
I0621 15:43:41.939802 17579 compress_conv_layer.cu:174] 0.560306 1.13809e-10 0.560964
I0621 15:43:41.948034 17579 compress_conv_layer.cu:174] 0.560306 2.04464e-11 0.751644
I0621 15:43:41.956148 17579 compress_conv_layer.cu:174] 0.560306 3.11432e-12 0.79333
I0621 15:43:41.968690 17579 compress_conv_layer.cu:174] 0.560306 9.94588e-12 0.462794
I0621 15:43:41.990207 17579 compress_conv_layer.cu:174] 0.560306 9.54113e-14 0.489768
I0621 15:43:42.032536 17579 compress_conv_layer.cu:174] 0.560306 1.7329e-13 0.482122
I0621 15:43:42.075625 17579 compress_conv_layer.cu:174] 0.560306 2.20638e-12 0.409577
I0621 15:43:42.118983 17579 compress_conv_layer.cu:174] 0.560306 1.91766e-12 0.43513
I0621 15:43:42.162139 17579 compress_conv_layer.cu:174] 0.560306 2.01548e-12 0.583398
I0621 15:43:42.205323 17579 compress_conv_layer.cu:174] 0.560306 5.5509e-12 0.462767
I0621 15:43:42.290944 17579 compress_conv_layer.cu:174] 0.560306 1.6603e-12 0.332096
I0621 15:43:42.471750 17579 compress_conv_layer.cu:174] 0.560306 3.41973e-12 0.296174
I0621 15:43:42.490011 17579 compress_conv_layer.cu:174] 0.560306 3.1801e-07 0.184986
I0621 15:43:42.720367 17579 solver.cpp:219] Iteration 13500 (0.585895 iter/s, 85.3395s/50 iters), loss = 0.00387882
I0621 15:43:42.720437 17579 solver.cpp:238]     Train net output #0: loss = 0.00224307 (* 1 = 0.00224307 loss)
I0621 15:43:42.720461 17579 sgd_solver.cpp:105] Iteration 13500, lr = 0.005
I0621 15:44:53.507741 17579 solver.cpp:219] Iteration 13550 (0.706349 iter/s, 70.7865s/50 iters), loss = 0.00365284
I0621 15:44:53.507946 17579 solver.cpp:238]     Train net output #0: loss = 0.00270153 (* 1 = 0.00270153 loss)
I0621 15:44:53.507973 17579 sgd_solver.cpp:105] Iteration 13550, lr = 0.005
I0621 15:46:04.301456 17579 solver.cpp:219] Iteration 13600 (0.706287 iter/s, 70.7927s/50 iters), loss = 0.00299998
I0621 15:46:04.301630 17579 solver.cpp:238]     Train net output #0: loss = 0.00432911 (* 1 = 0.00432911 loss)
I0621 15:46:04.301659 17579 sgd_solver.cpp:105] Iteration 13600, lr = 0.005
I0621 15:47:15.079645 17579 solver.cpp:219] Iteration 13650 (0.706442 iter/s, 70.7772s/50 iters), loss = 0.00201936
I0621 15:47:15.079792 17579 solver.cpp:238]     Train net output #0: loss = 0.00210649 (* 1 = 0.00210649 loss)
I0621 15:47:15.079820 17579 sgd_solver.cpp:105] Iteration 13650, lr = 0.005
I0621 15:48:25.874024 17579 solver.cpp:219] Iteration 13700 (0.70628 iter/s, 70.7934s/50 iters), loss = 0.00173239
I0621 15:48:25.874171 17579 solver.cpp:238]     Train net output #0: loss = 0.00290106 (* 1 = 0.00290106 loss)
I0621 15:48:25.874199 17579 sgd_solver.cpp:105] Iteration 13700, lr = 0.005
I0621 15:49:36.654937 17579 solver.cpp:219] Iteration 13750 (0.706414 iter/s, 70.78s/50 iters), loss = 0.00305438
I0621 15:49:36.655074 17579 solver.cpp:238]     Train net output #0: loss = 0.00252759 (* 1 = 0.00252759 loss)
I0621 15:49:36.655102 17579 sgd_solver.cpp:105] Iteration 13750, lr = 0.005
I0621 15:50:47.441411 17579 solver.cpp:219] Iteration 13800 (0.706359 iter/s, 70.7855s/50 iters), loss = 0.00364847
I0621 15:50:47.441583 17579 solver.cpp:238]     Train net output #0: loss = 0.00835534 (* 1 = 0.00835534 loss)
I0621 15:50:47.441613 17579 sgd_solver.cpp:105] Iteration 13800, lr = 0.005
I0621 15:51:58.212347 17579 solver.cpp:219] Iteration 13850 (0.706514 iter/s, 70.77s/50 iters), loss = 0.00257684
I0621 15:51:58.212497 17579 solver.cpp:238]     Train net output #0: loss = 0.00338924 (* 1 = 0.00338924 loss)
I0621 15:51:58.212530 17579 sgd_solver.cpp:105] Iteration 13850, lr = 0.005
I0621 15:53:09.011173 17579 solver.cpp:219] Iteration 13900 (0.706236 iter/s, 70.7979s/50 iters), loss = 0.00208908
I0621 15:53:09.011342 17579 solver.cpp:238]     Train net output #0: loss = 0.00108921 (* 1 = 0.00108921 loss)
I0621 15:53:09.011371 17579 sgd_solver.cpp:105] Iteration 13900, lr = 0.005
I0621 15:54:19.791906 17579 solver.cpp:219] Iteration 13950 (0.706417 iter/s, 70.7798s/50 iters), loss = 0.00306016
I0621 15:54:19.792260 17579 solver.cpp:238]     Train net output #0: loss = 0.00356282 (* 1 = 0.00356282 loss)
I0621 15:54:19.792289 17579 sgd_solver.cpp:105] Iteration 13950, lr = 0.005
I0621 15:55:29.161680 17579 solver.cpp:331] Iteration 14000, Testing net (#0)
I0621 15:55:41.131580 17579 solver.cpp:398]     Test net output #0: accuracy = 0.980392
I0621 15:55:41.131651 17579 solver.cpp:398]     Test net output #1: loss = 0.0725857 (* 1 = 0.0725857 loss)
I0621 15:55:42.541878 17579 solver.cpp:219] Iteration 14000 (0.604239 iter/s, 82.7487s/50 iters), loss = 0.0014605
I0621 15:55:42.541985 17579 solver.cpp:238]     Train net output #0: loss = 0.00171449 (* 1 = 0.00171449 loss)
I0621 15:55:42.542011 17579 sgd_solver.cpp:105] Iteration 14000, lr = 0.005
I0621 15:56:53.318053 17579 solver.cpp:219] Iteration 14050 (0.706461 iter/s, 70.7753s/50 iters), loss = 0.00118014
I0621 15:56:53.318205 17579 solver.cpp:238]     Train net output #0: loss = 0.000630916 (* 1 = 0.000630916 loss)
I0621 15:56:53.318234 17579 sgd_solver.cpp:105] Iteration 14050, lr = 0.005
I0621 15:58:04.088024 17579 solver.cpp:219] Iteration 14100 (0.706524 iter/s, 70.769s/50 iters), loss = 0.00284229
I0621 15:58:04.088165 17579 solver.cpp:238]     Train net output #0: loss = 0.00187793 (* 1 = 0.00187793 loss)
I0621 15:58:04.088194 17579 sgd_solver.cpp:105] Iteration 14100, lr = 0.005
I0621 15:59:14.879700 17579 solver.cpp:219] Iteration 14150 (0.706307 iter/s, 70.7907s/50 iters), loss = 0.00376843
I0621 15:59:14.879843 17579 solver.cpp:238]     Train net output #0: loss = 0.00281596 (* 1 = 0.00281596 loss)
I0621 15:59:14.879887 17579 sgd_solver.cpp:105] Iteration 14150, lr = 0.005
I0621 16:00:25.683563 17579 solver.cpp:219] Iteration 14200 (0.706186 iter/s, 70.8029s/50 iters), loss = 0.00242917
I0621 16:00:25.683697 17579 solver.cpp:238]     Train net output #0: loss = 0.00435337 (* 1 = 0.00435337 loss)
I0621 16:00:25.683727 17579 sgd_solver.cpp:105] Iteration 14200, lr = 0.005
I0621 16:01:36.489442 17579 solver.cpp:219] Iteration 14250 (0.706165 iter/s, 70.8049s/50 iters), loss = 0.00140846
I0621 16:01:36.489605 17579 solver.cpp:238]     Train net output #0: loss = 0.00144844 (* 1 = 0.00144844 loss)
I0621 16:01:36.489636 17579 sgd_solver.cpp:105] Iteration 14250, lr = 0.005
I0621 16:02:47.274958 17579 solver.cpp:219] Iteration 14300 (0.706369 iter/s, 70.7846s/50 iters), loss = 0.00168309
I0621 16:02:47.275100 17579 solver.cpp:238]     Train net output #0: loss = 0.000514451 (* 1 = 0.000514451 loss)
I0621 16:02:47.275130 17579 sgd_solver.cpp:105] Iteration 14300, lr = 0.005
I0621 16:03:58.053129 17579 solver.cpp:219] Iteration 14350 (0.706442 iter/s, 70.7772s/50 iters), loss = 0.00120067
I0621 16:03:58.053269 17579 solver.cpp:238]     Train net output #0: loss = 0.00115848 (* 1 = 0.00115848 loss)
I0621 16:03:58.053298 17579 sgd_solver.cpp:105] Iteration 14350, lr = 0.005
I0621 16:05:08.838150 17579 solver.cpp:219] Iteration 14400 (0.706373 iter/s, 70.7841s/50 iters), loss = 0.00257492
I0621 16:05:08.838296 17579 solver.cpp:238]     Train net output #0: loss = 0.00223271 (* 1 = 0.00223271 loss)
I0621 16:05:08.838327 17579 sgd_solver.cpp:105] Iteration 14400, lr = 0.005
I0621 16:06:19.619027 17579 solver.cpp:219] Iteration 14450 (0.706415 iter/s, 70.7799s/50 iters), loss = 0.00314662
I0621 16:06:19.619174 17579 solver.cpp:238]     Train net output #0: loss = 0.00220849 (* 1 = 0.00220849 loss)
I0621 16:06:19.619202 17579 sgd_solver.cpp:105] Iteration 14450, lr = 0.005
I0621 16:07:28.987150 17579 solver.cpp:331] Iteration 14500, Testing net (#0)
I0621 16:07:40.512311 17579 blocking_queue.cpp:49] Waiting for data
I0621 16:07:40.994674 17579 solver.cpp:398]     Test net output #0: accuracy = 0.983333
I0621 16:07:40.994756 17579 solver.cpp:398]     Test net output #1: loss = 0.0704751 (* 1 = 0.0704751 loss)
I0621 16:07:42.405670 17579 solver.cpp:219] Iteration 14500 (0.60397 iter/s, 82.7856s/50 iters), loss = 0.00215613
I0621 16:07:42.405769 17579 solver.cpp:238]     Train net output #0: loss = 0.00158302 (* 1 = 0.00158302 loss)
I0621 16:07:42.405797 17579 sgd_solver.cpp:105] Iteration 14500, lr = 0.005
I0621 16:08:53.179527 17579 solver.cpp:219] Iteration 14550 (0.706484 iter/s, 70.773s/50 iters), loss = 0.00168299
I0621 16:08:53.179669 17579 solver.cpp:238]     Train net output #0: loss = 0.00217573 (* 1 = 0.00217573 loss)
I0621 16:08:53.179698 17579 sgd_solver.cpp:105] Iteration 14550, lr = 0.005
I0621 16:10:03.962918 17579 solver.cpp:219] Iteration 14600 (0.70639 iter/s, 70.7825s/50 iters), loss = 0.00158233
I0621 16:10:03.963065 17579 solver.cpp:238]     Train net output #0: loss = 0.000678776 (* 1 = 0.000678776 loss)
I0621 16:10:03.963093 17579 sgd_solver.cpp:105] Iteration 14600, lr = 0.005
I0621 16:11:14.743072 17579 solver.cpp:219] Iteration 14650 (0.706422 iter/s, 70.7792s/50 iters), loss = 0.00164315
I0621 16:11:14.743233 17579 solver.cpp:238]     Train net output #0: loss = 0.00178064 (* 1 = 0.00178064 loss)
I0621 16:11:14.743263 17579 sgd_solver.cpp:105] Iteration 14650, lr = 0.005
I0621 16:12:25.529244 17579 solver.cpp:219] Iteration 14700 (0.706362 iter/s, 70.7852s/50 iters), loss = 0.00319166
I0621 16:12:25.529399 17579 solver.cpp:238]     Train net output #0: loss = 0.00246896 (* 1 = 0.00246896 loss)
I0621 16:12:25.529430 17579 sgd_solver.cpp:105] Iteration 14700, lr = 0.005
I0621 16:13:36.328882 17579 solver.cpp:219] Iteration 14750 (0.706228 iter/s, 70.7987s/50 iters), loss = 0.0021604
I0621 16:13:36.331856 17579 solver.cpp:238]     Train net output #0: loss = 0.00297972 (* 1 = 0.00297972 loss)
I0621 16:13:36.331884 17579 sgd_solver.cpp:105] Iteration 14750, lr = 0.005
I0621 16:14:47.115927 17579 solver.cpp:219] Iteration 14800 (0.706381 iter/s, 70.7833s/50 iters), loss = 0.00208319
I0621 16:14:47.116063 17579 solver.cpp:238]     Train net output #0: loss = 0.00188893 (* 1 = 0.00188893 loss)
I0621 16:14:47.116096 17579 sgd_solver.cpp:105] Iteration 14800, lr = 0.005
I0621 16:15:57.898293 17579 solver.cpp:219] Iteration 14850 (0.7064 iter/s, 70.7814s/50 iters), loss = 0.00151746
I0621 16:15:57.898453 17579 solver.cpp:238]     Train net output #0: loss = 0.00143137 (* 1 = 0.00143137 loss)
I0621 16:15:57.898484 17579 sgd_solver.cpp:105] Iteration 14850, lr = 0.005
I0621 16:17:08.686187 17579 solver.cpp:219] Iteration 14900 (0.706345 iter/s, 70.7869s/50 iters), loss = 0.00137956
I0621 16:17:08.686328 17579 solver.cpp:238]     Train net output #0: loss = 0.00156646 (* 1 = 0.00156646 loss)
I0621 16:17:08.686357 17579 sgd_solver.cpp:105] Iteration 14900, lr = 0.005
I0621 16:18:19.465948 17579 solver.cpp:219] Iteration 14950 (0.706426 iter/s, 70.7788s/50 iters), loss = 0.00191844
I0621 16:18:19.466097 17579 solver.cpp:238]     Train net output #0: loss = 0.00121748 (* 1 = 0.00121748 loss)
I0621 16:18:19.466126 17579 sgd_solver.cpp:105] Iteration 14950, lr = 0.005
I0621 16:19:28.830555 17579 solver.cpp:331] Iteration 15000, Testing net (#0)
I0621 16:19:40.784317 17579 solver.cpp:398]     Test net output #0: accuracy = 0.980392
I0621 16:19:40.784395 17579 solver.cpp:398]     Test net output #1: loss = 0.0714651 (* 1 = 0.0714651 loss)
I0621 16:19:40.791735 17579 compress_conv_layer.cu:174] 0.580638 1.85877e-10 0.955656
I0621 16:19:40.800381 17579 compress_conv_layer.cu:174] 0.580638 1.13383e-10 0.558848
I0621 16:19:40.808691 17579 compress_conv_layer.cu:174] 0.580638 2.03709e-11 0.748927
I0621 16:19:40.816977 17579 compress_conv_layer.cu:174] 0.580638 3.10261e-12 0.790364
I0621 16:19:40.829742 17579 compress_conv_layer.cu:174] 0.580638 9.90815e-12 0.461035
I0621 16:19:40.851573 17579 compress_conv_layer.cu:174] 0.580638 9.50556e-14 0.487914
I0621 16:19:40.894444 17579 compress_conv_layer.cu:174] 0.580638 1.7264e-13 0.480044
I0621 16:19:40.937355 17579 compress_conv_layer.cu:174] 0.580638 2.19825e-12 0.408028
I0621 16:19:40.980211 17579 compress_conv_layer.cu:174] 0.580638 1.9105e-12 0.433505
I0621 16:19:41.023490 17579 compress_conv_layer.cu:174] 0.580638 2.008e-12 0.581066
I0621 16:19:41.066489 17579 compress_conv_layer.cu:174] 0.580638 5.53008e-12 0.460809
I0621 16:19:41.153563 17579 compress_conv_layer.cu:174] 0.580638 1.65412e-12 0.330697
I0621 16:19:41.336973 17579 compress_conv_layer.cu:174] 0.580638 3.40705e-12 0.295042
I0621 16:19:41.355182 17579 compress_conv_layer.cu:174] 0.580638 3.16817e-07 0.186189
I0621 16:19:41.592959 17579 compress_conv_layer.cu:174] 0.580638 1.85877e-10 0.955656
I0621 16:19:41.601290 17579 compress_conv_layer.cu:174] 0.580638 1.13383e-10 0.558848
I0621 16:19:41.609549 17579 compress_conv_layer.cu:174] 0.580638 2.03709e-11 0.748927
I0621 16:19:41.617715 17579 compress_conv_layer.cu:174] 0.580638 3.10261e-12 0.790364
I0621 16:19:41.630303 17579 compress_conv_layer.cu:174] 0.580638 9.90815e-12 0.461035
I0621 16:19:41.651845 17579 compress_conv_layer.cu:174] 0.580638 9.50556e-14 0.487914
I0621 16:19:41.694025 17579 compress_conv_layer.cu:174] 0.580638 1.7264e-13 0.480044
I0621 16:19:41.737001 17579 compress_conv_layer.cu:174] 0.580638 2.19825e-12 0.408028
I0621 16:19:41.779727 17579 compress_conv_layer.cu:174] 0.580638 1.9105e-12 0.433505
I0621 16:19:41.822602 17579 compress_conv_layer.cu:174] 0.580638 2.008e-12 0.581066
I0621 16:19:41.865682 17579 compress_conv_layer.cu:174] 0.580638 5.53008e-12 0.460809
I0621 16:19:41.951459 17579 compress_conv_layer.cu:174] 0.580638 1.65412e-12 0.330697
I0621 16:19:42.132760 17579 compress_conv_layer.cu:174] 0.580638 3.40705e-12 0.295042
I0621 16:19:42.150931 17579 compress_conv_layer.cu:174] 0.580638 3.16817e-07 0.186189
I0621 16:19:42.389318 17579 compress_conv_layer.cu:174] 0.580638 1.85877e-10 0.955656
I0621 16:19:42.397279 17579 compress_conv_layer.cu:174] 0.580638 1.13383e-10 0.558848
I0621 16:19:42.405560 17579 compress_conv_layer.cu:174] 0.580638 2.03709e-11 0.748927
I0621 16:19:42.413734 17579 compress_conv_layer.cu:174] 0.580638 3.10261e-12 0.790364
I0621 16:19:42.426354 17579 compress_conv_layer.cu:174] 0.580638 9.90815e-12 0.461035
I0621 16:19:42.448070 17579 compress_conv_layer.cu:174] 0.580638 9.50556e-14 0.487914
I0621 16:19:42.490491 17579 compress_conv_layer.cu:174] 0.580638 1.7264e-13 0.480044
I0621 16:19:42.533434 17579 compress_conv_layer.cu:174] 0.580638 2.19825e-12 0.408028
I0621 16:19:42.576050 17579 compress_conv_layer.cu:174] 0.580638 1.9105e-12 0.433505
I0621 16:19:42.618791 17579 compress_conv_layer.cu:174] 0.580638 2.008e-12 0.581066
I0621 16:19:42.661856 17579 compress_conv_layer.cu:174] 0.580638 5.53008e-12 0.460809
I0621 16:19:42.747701 17579 compress_conv_layer.cu:174] 0.580638 1.65412e-12 0.330697
I0621 16:19:42.928247 17579 compress_conv_layer.cu:174] 0.580638 3.40705e-12 0.295042
I0621 16:19:42.946585 17579 compress_conv_layer.cu:174] 0.580638 3.16817e-07 0.186189
I0621 16:19:43.184257 17579 compress_conv_layer.cu:174] 0.580638 1.85877e-10 0.955656
I0621 16:19:43.192580 17579 compress_conv_layer.cu:174] 0.580638 1.13383e-10 0.558848
I0621 16:19:43.200836 17579 compress_conv_layer.cu:174] 0.580638 2.03709e-11 0.748927
I0621 16:19:43.209041 17579 compress_conv_layer.cu:174] 0.580638 3.10261e-12 0.790364
I0621 16:19:43.221588 17579 compress_conv_layer.cu:174] 0.580638 9.90815e-12 0.461035
I0621 16:19:43.243060 17579 compress_conv_layer.cu:174] 0.580638 9.50556e-14 0.487914
I0621 16:19:43.284994 17579 compress_conv_layer.cu:174] 0.580638 1.7264e-13 0.480044
I0621 16:19:43.328382 17579 compress_conv_layer.cu:174] 0.580638 2.19825e-12 0.408028
I0621 16:19:43.371721 17579 compress_conv_layer.cu:174] 0.580638 1.9105e-12 0.433505
I0621 16:19:43.414836 17579 compress_conv_layer.cu:174] 0.580638 2.008e-12 0.581066
I0621 16:19:43.458137 17579 compress_conv_layer.cu:174] 0.580638 5.53008e-12 0.460809
I0621 16:19:43.543764 17579 compress_conv_layer.cu:174] 0.580638 1.65412e-12 0.330697
I0621 16:19:43.725013 17579 compress_conv_layer.cu:174] 0.580638 3.40705e-12 0.295042
I0621 16:19:43.743119 17579 compress_conv_layer.cu:174] 0.580638 3.16817e-07 0.186189
I0621 16:19:43.981317 17579 compress_conv_layer.cu:174] 0.580638 1.85877e-10 0.955656
I0621 16:19:43.989296 17579 compress_conv_layer.cu:174] 0.580638 1.13383e-10 0.558848
I0621 16:19:43.997547 17579 compress_conv_layer.cu:174] 0.580638 2.03709e-11 0.748927
I0621 16:19:44.005722 17579 compress_conv_layer.cu:174] 0.580638 3.10261e-12 0.790364
I0621 16:19:44.018255 17579 compress_conv_layer.cu:174] 0.580638 9.90815e-12 0.461035
I0621 16:19:44.039907 17579 compress_conv_layer.cu:174] 0.580638 9.50556e-14 0.487914
I0621 16:19:44.081881 17579 compress_conv_layer.cu:174] 0.580638 1.7264e-13 0.480044
I0621 16:19:44.124661 17579 compress_conv_layer.cu:174] 0.580638 2.19825e-12 0.408028
I0621 16:19:44.167263 17579 compress_conv_layer.cu:174] 0.580638 1.9105e-12 0.433505
I0621 16:19:44.210091 17579 compress_conv_layer.cu:174] 0.580638 2.008e-12 0.581066
I0621 16:19:44.257534 17579 compress_conv_layer.cu:174] 0.580638 5.53008e-12 0.460809
I0621 16:19:44.343792 17579 compress_conv_layer.cu:174] 0.580638 1.65412e-12 0.330697
I0621 16:19:44.524991 17579 compress_conv_layer.cu:174] 0.580638 3.40705e-12 0.295042
I0621 16:19:44.543081 17579 compress_conv_layer.cu:174] 0.580638 3.16817e-07 0.186189
I0621 16:19:44.773249 17579 solver.cpp:219] Iteration 15000 (0.586124 iter/s, 85.3062s/50 iters), loss = 0.00156525
I0621 16:19:44.773321 17579 solver.cpp:238]     Train net output #0: loss = 0.00197323 (* 1 = 0.00197323 loss)
I0621 16:19:44.773346 17579 sgd_solver.cpp:105] Iteration 15000, lr = 0.005
I0621 16:20:55.548451 17579 solver.cpp:219] Iteration 15050 (0.706471 iter/s, 70.7744s/50 iters), loss = 0.00237588
I0621 16:20:55.548652 17579 solver.cpp:238]     Train net output #0: loss = 0.00238492 (* 1 = 0.00238492 loss)
I0621 16:20:55.548683 17579 sgd_solver.cpp:105] Iteration 15050, lr = 0.005
I0621 16:22:06.319527 17579 solver.cpp:219] Iteration 15100 (0.706513 iter/s, 70.7701s/50 iters), loss = 0.00266833
I0621 16:22:06.319684 17579 solver.cpp:238]     Train net output #0: loss = 0.00295578 (* 1 = 0.00295578 loss)
I0621 16:22:06.319713 17579 sgd_solver.cpp:105] Iteration 15100, lr = 0.005
I0621 16:23:17.110956 17579 solver.cpp:219] Iteration 15150 (0.70631 iter/s, 70.7905s/50 iters), loss = 0.00250021
I0621 16:23:17.111096 17579 solver.cpp:238]     Train net output #0: loss = 0.00174019 (* 1 = 0.00174019 loss)
I0621 16:23:17.111125 17579 sgd_solver.cpp:105] Iteration 15150, lr = 0.005
I0621 16:24:27.896028 17579 solver.cpp:219] Iteration 15200 (0.706373 iter/s, 70.7841s/50 iters), loss = 0.00257095
I0621 16:24:27.896167 17579 solver.cpp:238]     Train net output #0: loss = 0.00155243 (* 1 = 0.00155243 loss)
I0621 16:24:27.896195 17579 sgd_solver.cpp:105] Iteration 15200, lr = 0.005
I0621 16:25:38.674748 17579 solver.cpp:219] Iteration 15250 (0.706437 iter/s, 70.7778s/50 iters), loss = 0.00215476
I0621 16:25:38.674918 17579 solver.cpp:238]     Train net output #0: loss = 0.00244504 (* 1 = 0.00244504 loss)
I0621 16:25:38.674953 17579 sgd_solver.cpp:105] Iteration 15250, lr = 0.005
I0621 16:26:49.480322 17579 solver.cpp:219] Iteration 15300 (0.706168 iter/s, 70.8046s/50 iters), loss = 0.00249065
I0621 16:26:49.480485 17579 solver.cpp:238]     Train net output #0: loss = 0.00625026 (* 1 = 0.00625026 loss)
I0621 16:26:49.480521 17579 sgd_solver.cpp:105] Iteration 15300, lr = 0.005
I0621 16:28:00.263348 17579 solver.cpp:219] Iteration 15350 (0.706393 iter/s, 70.7822s/50 iters), loss = 0.00206665
I0621 16:28:00.263502 17579 solver.cpp:238]     Train net output #0: loss = 0.00136753 (* 1 = 0.00136753 loss)
I0621 16:28:00.263538 17579 sgd_solver.cpp:105] Iteration 15350, lr = 0.005
I0621 16:29:11.043864 17579 solver.cpp:219] Iteration 15400 (0.706418 iter/s, 70.7796s/50 iters), loss = 0.0021609
I0621 16:29:11.044031 17579 solver.cpp:238]     Train net output #0: loss = 0.00109239 (* 1 = 0.00109239 loss)
I0621 16:29:11.044060 17579 sgd_solver.cpp:105] Iteration 15400, lr = 0.005
I0621 16:30:21.828805 17579 solver.cpp:219] Iteration 15450 (0.706374 iter/s, 70.7841s/50 iters), loss = 0.00172512
I0621 16:30:21.829026 17579 solver.cpp:238]     Train net output #0: loss = 0.00111854 (* 1 = 0.00111854 loss)
I0621 16:30:21.829056 17579 sgd_solver.cpp:105] Iteration 15450, lr = 0.005
I0621 16:31:31.208113 17579 solver.cpp:331] Iteration 15500, Testing net (#0)
I0621 16:31:43.160280 17579 solver.cpp:398]     Test net output #0: accuracy = 0.982353
I0621 16:31:43.160367 17579 solver.cpp:398]     Test net output #1: loss = 0.0722375 (* 1 = 0.0722375 loss)
I0621 16:31:44.570947 17579 solver.cpp:219] Iteration 15500 (0.604295 iter/s, 82.7411s/50 iters), loss = 0.00194359
I0621 16:31:44.571038 17579 solver.cpp:238]     Train net output #0: loss = 0.00177302 (* 1 = 0.00177302 loss)
I0621 16:31:44.571064 17579 sgd_solver.cpp:105] Iteration 15500, lr = 0.005
I0621 16:32:55.347198 17579 solver.cpp:219] Iteration 15550 (0.70646 iter/s, 70.7755s/50 iters), loss = 0.00196509
I0621 16:32:55.347357 17579 solver.cpp:238]     Train net output #0: loss = 0.00241235 (* 1 = 0.00241235 loss)
I0621 16:32:55.347386 17579 sgd_solver.cpp:105] Iteration 15550, lr = 0.005
I0621 16:34:06.132992 17579 solver.cpp:219] Iteration 15600 (0.706365 iter/s, 70.7849s/50 iters), loss = 0.00346023
I0621 16:34:06.133131 17579 solver.cpp:238]     Train net output #0: loss = 0.00547205 (* 1 = 0.00547205 loss)
I0621 16:34:06.133159 17579 sgd_solver.cpp:105] Iteration 15600, lr = 0.005
I0621 16:35:16.902014 17579 solver.cpp:219] Iteration 15650 (0.706532 iter/s, 70.7682s/50 iters), loss = 0.00266662
I0621 16:35:16.902164 17579 solver.cpp:238]     Train net output #0: loss = 0.00332799 (* 1 = 0.00332799 loss)
I0621 16:35:16.902194 17579 sgd_solver.cpp:105] Iteration 15650, lr = 0.005
I0621 16:36:27.677351 17579 solver.cpp:219] Iteration 15700 (0.706469 iter/s, 70.7745s/50 iters), loss = 0.00312365
I0621 16:36:27.677506 17579 solver.cpp:238]     Train net output #0: loss = 0.0016435 (* 1 = 0.0016435 loss)
I0621 16:36:27.677541 17579 sgd_solver.cpp:105] Iteration 15700, lr = 0.005
I0621 16:37:38.442198 17579 solver.cpp:219] Iteration 15750 (0.706574 iter/s, 70.764s/50 iters), loss = 0.00365902
I0621 16:37:38.442358 17579 solver.cpp:238]     Train net output #0: loss = 0.00144 (* 1 = 0.00144 loss)
I0621 16:37:38.442387 17579 sgd_solver.cpp:105] Iteration 15750, lr = 0.005
I0621 16:38:49.218883 17579 solver.cpp:219] Iteration 15800 (0.706456 iter/s, 70.7758s/50 iters), loss = 0.00230079
I0621 16:38:49.219194 17579 solver.cpp:238]     Train net output #0: loss = 0.00339161 (* 1 = 0.00339161 loss)
I0621 16:38:49.219224 17579 sgd_solver.cpp:105] Iteration 15800, lr = 0.005
I0621 16:39:59.999505 17579 solver.cpp:219] Iteration 15850 (0.706418 iter/s, 70.7796s/50 iters), loss = 0.00312787
I0621 16:39:59.999655 17579 solver.cpp:238]     Train net output #0: loss = 0.00449641 (* 1 = 0.00449641 loss)
I0621 16:39:59.999683 17579 sgd_solver.cpp:105] Iteration 15850, lr = 0.005
I0621 16:41:10.781468 17579 solver.cpp:219] Iteration 15900 (0.706403 iter/s, 70.7811s/50 iters), loss = 0.00116349
I0621 16:41:10.781651 17579 solver.cpp:238]     Train net output #0: loss = 0.00153165 (* 1 = 0.00153165 loss)
I0621 16:41:10.781680 17579 sgd_solver.cpp:105] Iteration 15900, lr = 0.005
I0621 16:42:21.556054 17579 solver.cpp:219] Iteration 15950 (0.706477 iter/s, 70.7737s/50 iters), loss = 0.00223434
I0621 16:42:21.556231 17579 solver.cpp:238]     Train net output #0: loss = 0.00124312 (* 1 = 0.00124312 loss)
I0621 16:42:21.556260 17579 sgd_solver.cpp:105] Iteration 15950, lr = 0.005
I0621 16:43:30.939100 17579 solver.cpp:448] Snapshotting to binary proto file mobilenet/mobile_pruning_iter_16000.caffemodel
I0621 16:43:31.064748 17579 sgd_solver.cpp:273] Snapshotting solver state to binary proto file mobilenet/mobile_pruning_iter_16000.solverstate
I0621 16:43:31.121712 17579 solver.cpp:331] Iteration 16000, Testing net (#0)
I0621 16:43:43.062804 17579 solver.cpp:398]     Test net output #0: accuracy = 0.984314
I0621 16:43:43.062891 17579 solver.cpp:398]     Test net output #1: loss = 0.070867 (* 1 = 0.070867 loss)
I0621 16:43:44.474290 17579 solver.cpp:219] Iteration 16000 (0.603011 iter/s, 82.9172s/50 iters), loss = 0.00232949
I0621 16:43:44.474381 17579 solver.cpp:238]     Train net output #0: loss = 0.00293219 (* 1 = 0.00293219 loss)
I0621 16:43:44.474411 17579 sgd_solver.cpp:105] Iteration 16000, lr = 0.005
I0621 16:44:55.256762 17579 solver.cpp:219] Iteration 16050 (0.706398 iter/s, 70.7817s/50 iters), loss = 0.00228976
I0621 16:44:55.257087 17579 solver.cpp:238]     Train net output #0: loss = 0.00101217 (* 1 = 0.00101217 loss)
I0621 16:44:55.257119 17579 sgd_solver.cpp:105] Iteration 16050, lr = 0.005
I0621 16:46:06.032877 17579 solver.cpp:219] Iteration 16100 (0.706463 iter/s, 70.7751s/50 iters), loss = 0.0015711
I0621 16:46:06.033033 17579 solver.cpp:238]     Train net output #0: loss = 0.00187574 (* 1 = 0.00187574 loss)
I0621 16:46:06.033061 17579 sgd_solver.cpp:105] Iteration 16100, lr = 0.005
I0621 16:47:16.803092 17579 solver.cpp:219] Iteration 16150 (0.706521 iter/s, 70.7693s/50 iters), loss = 0.00362928
I0621 16:47:16.803280 17579 solver.cpp:238]     Train net output #0: loss = 0.0110408 (* 1 = 0.0110408 loss)
I0621 16:47:16.803308 17579 sgd_solver.cpp:105] Iteration 16150, lr = 0.005
I0621 16:48:27.614001 17579 solver.cpp:219] Iteration 16200 (0.706115 iter/s, 70.81s/50 iters), loss = 0.00196237
I0621 16:48:27.614150 17579 solver.cpp:238]     Train net output #0: loss = 0.00466207 (* 1 = 0.00466207 loss)
I0621 16:48:27.614178 17579 sgd_solver.cpp:105] Iteration 16200, lr = 0.005
I0621 16:49:38.406738 17579 solver.cpp:219] Iteration 16250 (0.706296 iter/s, 70.7919s/50 iters), loss = 0.00240574
I0621 16:49:38.407217 17579 solver.cpp:238]     Train net output #0: loss = 0.00181558 (* 1 = 0.00181558 loss)
I0621 16:49:38.407248 17579 sgd_solver.cpp:105] Iteration 16250, lr = 0.005
I0621 16:50:49.204707 17579 solver.cpp:219] Iteration 16300 (0.706247 iter/s, 70.7968s/50 iters), loss = 0.00125483
I0621 16:50:49.204857 17579 solver.cpp:238]     Train net output #0: loss = 0.000193931 (* 1 = 0.000193931 loss)
I0621 16:50:49.204900 17579 sgd_solver.cpp:105] Iteration 16300, lr = 0.005
I0621 16:51:59.999917 17579 solver.cpp:219] Iteration 16350 (0.706271 iter/s, 70.7943s/50 iters), loss = 0.00111948
I0621 16:52:00.000052 17579 solver.cpp:238]     Train net output #0: loss = 0.000595521 (* 1 = 0.000595521 loss)
I0621 16:52:00.000082 17579 sgd_solver.cpp:105] Iteration 16350, lr = 0.005
I0621 16:53:10.779850 17579 solver.cpp:219] Iteration 16400 (0.706423 iter/s, 70.7791s/50 iters), loss = 0.00162027
I0621 16:53:10.780007 17579 solver.cpp:238]     Train net output #0: loss = 0.00295918 (* 1 = 0.00295918 loss)
I0621 16:53:10.780038 17579 sgd_solver.cpp:105] Iteration 16400, lr = 0.005
I0621 16:54:21.571722 17579 solver.cpp:219] Iteration 16450 (0.706304 iter/s, 70.791s/50 iters), loss = 0.0017483
I0621 16:54:21.571868 17579 solver.cpp:238]     Train net output #0: loss = 0.00133623 (* 1 = 0.00133623 loss)
I0621 16:54:21.571897 17579 sgd_solver.cpp:105] Iteration 16450, lr = 0.005
I0621 16:55:30.945355 17579 solver.cpp:331] Iteration 16500, Testing net (#0)
I0621 16:55:42.910764 17579 solver.cpp:398]     Test net output #0: accuracy = 0.982353
I0621 16:55:42.910847 17579 solver.cpp:398]     Test net output #1: loss = 0.0730968 (* 1 = 0.0730968 loss)
I0621 16:55:42.918267 17579 compress_conv_layer.cu:174] 0.599341 1.85191e-10 0.952114
I0621 16:55:42.926877 17579 compress_conv_layer.cu:174] 0.599341 1.12956e-10 0.556808
I0621 16:55:42.935174 17579 compress_conv_layer.cu:174] 0.599341 2.02954e-11 0.746332
I0621 16:55:42.943431 17579 compress_conv_layer.cu:174] 0.599341 3.0909e-12 0.787443
I0621 16:55:42.957231 17579 compress_conv_layer.cu:174] 0.599341 9.87102e-12 0.459535
I0621 16:55:42.979526 17579 compress_conv_layer.cu:174] 0.599341 9.46998e-14 0.48595
I0621 16:55:43.024296 17579 compress_conv_layer.cu:174] 0.599341 1.71989e-13 0.478326
I0621 16:55:43.067287 17579 compress_conv_layer.cu:174] 0.599341 2.19012e-12 0.406465
I0621 16:55:43.110488 17579 compress_conv_layer.cu:174] 0.599341 1.90335e-12 0.431967
I0621 16:55:43.153055 17579 compress_conv_layer.cu:174] 0.599341 2.00052e-12 0.578679
I0621 16:55:43.196439 17579 compress_conv_layer.cu:174] 0.599341 5.50926e-12 0.459056
I0621 16:55:43.283638 17579 compress_conv_layer.cu:174] 0.599341 1.64794e-12 0.329358
I0621 16:55:43.466469 17579 compress_conv_layer.cu:174] 0.599341 3.39436e-12 0.293912
I0621 16:55:43.484671 17579 compress_conv_layer.cu:174] 0.599341 3.15623e-07 0.187034
I0621 16:55:43.722916 17579 compress_conv_layer.cu:174] 0.599341 1.85191e-10 0.952114
I0621 16:55:43.730877 17579 compress_conv_layer.cu:174] 0.599341 1.12956e-10 0.556808
I0621 16:55:43.739135 17579 compress_conv_layer.cu:174] 0.599341 2.02954e-11 0.746332
I0621 16:55:43.747269 17579 compress_conv_layer.cu:174] 0.599341 3.0909e-12 0.787443
I0621 16:55:43.759764 17579 compress_conv_layer.cu:174] 0.599341 9.87102e-12 0.459535
I0621 16:55:43.781316 17579 compress_conv_layer.cu:174] 0.599341 9.46998e-14 0.48595
I0621 16:55:43.823863 17579 compress_conv_layer.cu:174] 0.599341 1.71989e-13 0.478326
I0621 16:55:43.866753 17579 compress_conv_layer.cu:174] 0.599341 2.19012e-12 0.406465
I0621 16:55:43.909919 17579 compress_conv_layer.cu:174] 0.599341 1.90335e-12 0.431967
I0621 16:55:43.952636 17579 compress_conv_layer.cu:174] 0.599341 2.00052e-12 0.578679
I0621 16:55:43.996043 17579 compress_conv_layer.cu:174] 0.599341 5.50926e-12 0.459056
I0621 16:55:44.083173 17579 compress_conv_layer.cu:174] 0.599341 1.64794e-12 0.329358
I0621 16:55:44.263312 17579 compress_conv_layer.cu:174] 0.599341 3.39436e-12 0.293912
I0621 16:55:44.281458 17579 compress_conv_layer.cu:174] 0.599341 3.15623e-07 0.187034
I0621 16:55:44.519702 17579 compress_conv_layer.cu:174] 0.599341 1.85191e-10 0.952114
I0621 16:55:44.527657 17579 compress_conv_layer.cu:174] 0.599341 1.12956e-10 0.556808
I0621 16:55:44.535909 17579 compress_conv_layer.cu:174] 0.599341 2.02954e-11 0.746332
I0621 16:55:44.544025 17579 compress_conv_layer.cu:174] 0.599341 3.0909e-12 0.787443
I0621 16:55:44.556535 17579 compress_conv_layer.cu:174] 0.599341 9.87102e-12 0.459535
I0621 16:55:44.578099 17579 compress_conv_layer.cu:174] 0.599341 9.46998e-14 0.48595
I0621 16:55:44.621259 17579 compress_conv_layer.cu:174] 0.599341 1.71989e-13 0.478326
I0621 16:55:44.664252 17579 compress_conv_layer.cu:174] 0.599341 2.19012e-12 0.406465
I0621 16:55:44.707533 17579 compress_conv_layer.cu:174] 0.599341 1.90335e-12 0.431967
I0621 16:55:44.750166 17579 compress_conv_layer.cu:174] 0.599341 2.00052e-12 0.578679
I0621 16:55:44.792912 17579 compress_conv_layer.cu:174] 0.599341 5.50926e-12 0.459056
I0621 16:55:44.878710 17579 compress_conv_layer.cu:174] 0.599341 1.64794e-12 0.329358
I0621 16:55:45.062861 17579 compress_conv_layer.cu:174] 0.599341 3.39436e-12 0.293912
I0621 16:55:45.081269 17579 compress_conv_layer.cu:174] 0.599341 3.15623e-07 0.187034
I0621 16:55:45.319700 17579 compress_conv_layer.cu:174] 0.599341 1.85191e-10 0.952114
I0621 16:55:45.327671 17579 compress_conv_layer.cu:174] 0.599341 1.12956e-10 0.556808
I0621 16:55:45.335893 17579 compress_conv_layer.cu:174] 0.599341 2.02954e-11 0.746332
I0621 16:55:45.344068 17579 compress_conv_layer.cu:174] 0.599341 3.0909e-12 0.787443
I0621 16:55:45.356647 17579 compress_conv_layer.cu:174] 0.599341 9.87102e-12 0.459535
I0621 16:55:45.378321 17579 compress_conv_layer.cu:174] 0.599341 9.46998e-14 0.48595
I0621 16:55:45.420990 17579 compress_conv_layer.cu:174] 0.599341 1.71989e-13 0.478326
I0621 16:55:45.464085 17579 compress_conv_layer.cu:174] 0.599341 2.19012e-12 0.406465
I0621 16:55:45.507596 17579 compress_conv_layer.cu:174] 0.599341 1.90335e-12 0.431967
I0621 16:55:45.550701 17579 compress_conv_layer.cu:174] 0.599341 2.00052e-12 0.578679
I0621 16:55:45.593895 17579 compress_conv_layer.cu:174] 0.599341 5.50926e-12 0.459056
I0621 16:55:45.680196 17579 compress_conv_layer.cu:174] 0.599341 1.64794e-12 0.329358
I0621 16:55:45.860033 17579 compress_conv_layer.cu:174] 0.599341 3.39436e-12 0.293912
I0621 16:55:45.878234 17579 compress_conv_layer.cu:174] 0.599341 3.15623e-07 0.187034
I0621 16:55:46.116504 17579 compress_conv_layer.cu:174] 0.599341 1.85191e-10 0.952114
I0621 16:55:46.124476 17579 compress_conv_layer.cu:174] 0.599341 1.12956e-10 0.556808
I0621 16:55:46.132705 17579 compress_conv_layer.cu:174] 0.599341 2.02954e-11 0.746332
I0621 16:55:46.140838 17579 compress_conv_layer.cu:174] 0.599341 3.0909e-12 0.787443
I0621 16:55:46.153303 17579 compress_conv_layer.cu:174] 0.599341 9.87102e-12 0.459535
I0621 16:55:46.174808 17579 compress_conv_layer.cu:174] 0.599341 9.46998e-14 0.48595
I0621 16:55:46.217171 17579 compress_conv_layer.cu:174] 0.599341 1.71989e-13 0.478326
I0621 16:55:46.260030 17579 compress_conv_layer.cu:174] 0.599341 2.19012e-12 0.406465
I0621 16:55:46.303553 17579 compress_conv_layer.cu:174] 0.599341 1.90335e-12 0.431967
I0621 16:55:46.346727 17579 compress_conv_layer.cu:174] 0.599341 2.00052e-12 0.578679
I0621 16:55:46.390213 17579 compress_conv_layer.cu:174] 0.599341 5.50926e-12 0.459056
I0621 16:55:46.476169 17579 compress_conv_layer.cu:174] 0.599341 1.64794e-12 0.329358
I0621 16:55:46.656461 17579 compress_conv_layer.cu:174] 0.599341 3.39436e-12 0.293912
I0621 16:55:46.674715 17579 compress_conv_layer.cu:174] 0.599341 3.15623e-07 0.187034
I0621 16:55:46.905093 17579 solver.cpp:219] Iteration 16500 (0.585944 iter/s, 85.3324s/50 iters), loss = 0.00263816
I0621 16:55:46.905179 17579 solver.cpp:238]     Train net output #0: loss = 0.00147672 (* 1 = 0.00147672 loss)
I0621 16:55:46.905207 17579 sgd_solver.cpp:105] Iteration 16500, lr = 0.005
I0621 16:56:57.702852 17579 solver.cpp:219] Iteration 16550 (0.706245 iter/s, 70.797s/50 iters), loss = 0.0023492
I0621 16:56:57.703049 17579 solver.cpp:238]     Train net output #0: loss = 0.00375708 (* 1 = 0.00375708 loss)
I0621 16:56:57.703078 17579 sgd_solver.cpp:105] Iteration 16550, lr = 0.005
I0621 16:58:08.488628 17579 solver.cpp:219] Iteration 16600 (0.706366 iter/s, 70.7849s/50 iters), loss = 0.00449795
I0621 16:58:08.488783 17579 solver.cpp:238]     Train net output #0: loss = 0.0168033 (* 1 = 0.0168033 loss)
I0621 16:58:08.488814 17579 sgd_solver.cpp:105] Iteration 16600, lr = 0.005
I0621 16:59:19.291441 17579 solver.cpp:219] Iteration 16650 (0.706195 iter/s, 70.8019s/50 iters), loss = 0.0027004
I0621 16:59:19.291601 17579 solver.cpp:238]     Train net output #0: loss = 0.00302323 (* 1 = 0.00302323 loss)
I0621 16:59:19.291630 17579 sgd_solver.cpp:105] Iteration 16650, lr = 0.005
I0621 17:00:30.098721 17579 solver.cpp:219] Iteration 16700 (0.706151 iter/s, 70.8064s/50 iters), loss = 0.00298666
I0621 17:00:30.098857 17579 solver.cpp:238]     Train net output #0: loss = 0.00439155 (* 1 = 0.00439155 loss)
I0621 17:00:30.098886 17579 sgd_solver.cpp:105] Iteration 16700, lr = 0.005
I0621 17:01:40.906024 17579 solver.cpp:219] Iteration 16750 (0.70615 iter/s, 70.8065s/50 iters), loss = 0.00177103
I0621 17:01:40.906204 17579 solver.cpp:238]     Train net output #0: loss = 0.00173633 (* 1 = 0.00173633 loss)
I0621 17:01:40.906234 17579 sgd_solver.cpp:105] Iteration 16750, lr = 0.005
I0621 17:03:01.061168 17579 solver.cpp:219] Iteration 16800 (0.623798 iter/s, 80.1542s/50 iters), loss = 0.00250646
I0621 17:03:01.061354 17579 solver.cpp:238]     Train net output #0: loss = 0.00277761 (* 1 = 0.00277761 loss)
I0621 17:03:01.061381 17579 sgd_solver.cpp:105] Iteration 16800, lr = 0.005
I0621 17:04:17.001340 17579 solver.cpp:219] Iteration 16850 (0.658428 iter/s, 75.9385s/50 iters), loss = 0.00198126
I0621 17:04:17.001479 17579 solver.cpp:238]     Train net output #0: loss = 0.000859419 (* 1 = 0.000859419 loss)
I0621 17:04:17.001507 17579 sgd_solver.cpp:105] Iteration 16850, lr = 0.005
I0621 17:05:27.815477 17579 solver.cpp:219] Iteration 16900 (0.706082 iter/s, 70.8133s/50 iters), loss = 0.00383165
I0621 17:05:27.815623 17579 solver.cpp:238]     Train net output #0: loss = 0.00421396 (* 1 = 0.00421396 loss)
I0621 17:05:27.815652 17579 sgd_solver.cpp:105] Iteration 16900, lr = 0.005
I0621 17:07:19.582779 17579 solver.cpp:219] Iteration 16950 (0.447363 iter/s, 111.766s/50 iters), loss = 0.00252583
I0621 17:07:19.582916 17579 solver.cpp:238]     Train net output #0: loss = 0.00245389 (* 1 = 0.00245389 loss)
I0621 17:07:19.582944 17579 sgd_solver.cpp:105] Iteration 16950, lr = 0.005
I0621 17:09:22.784488 17579 solver.cpp:331] Iteration 17000, Testing net (#0)
I0621 17:09:37.928470 17579 solver.cpp:398]     Test net output #0: accuracy = 0.982353
I0621 17:09:37.928558 17579 solver.cpp:398]     Test net output #1: loss = 0.0748317 (* 1 = 0.0748317 loss)
I0621 17:09:40.439721 17579 solver.cpp:219] Iteration 17000 (0.354976 iter/s, 140.855s/50 iters), loss = 0.00173818
I0621 17:09:40.439851 17579 solver.cpp:238]     Train net output #0: loss = 0.000991387 (* 1 = 0.000991387 loss)
I0621 17:09:40.439879 17579 sgd_solver.cpp:105] Iteration 17000, lr = 0.005
I0621 17:11:45.791734 17579 solver.cpp:219] Iteration 17050 (0.398881 iter/s, 125.351s/50 iters), loss = 0.00302176
I0621 17:11:45.791985 17579 solver.cpp:238]     Train net output #0: loss = 0.00224366 (* 1 = 0.00224366 loss)
I0621 17:11:45.792019 17579 sgd_solver.cpp:105] Iteration 17050, lr = 0.005
I0621 17:13:51.560461 17579 solver.cpp:219] Iteration 17100 (0.397562 iter/s, 125.767s/50 iters), loss = 0.00150358
I0621 17:13:51.560618 17579 solver.cpp:238]     Train net output #0: loss = 0.00139974 (* 1 = 0.00139974 loss)
I0621 17:13:51.560650 17579 sgd_solver.cpp:105] Iteration 17100, lr = 0.005
I0621 17:15:56.983412 17579 solver.cpp:219] Iteration 17150 (0.398658 iter/s, 125.421s/50 iters), loss = 0.00186242
I0621 17:15:56.983582 17579 solver.cpp:238]     Train net output #0: loss = 0.00296033 (* 1 = 0.00296033 loss)
I0621 17:15:56.983613 17579 sgd_solver.cpp:105] Iteration 17150, lr = 0.005
I0621 17:18:02.789248 17579 solver.cpp:219] Iteration 17200 (0.397445 iter/s, 125.804s/50 iters), loss = 0.00284342
I0621 17:18:02.789408 17579 solver.cpp:238]     Train net output #0: loss = 0.00131027 (* 1 = 0.00131027 loss)
I0621 17:18:02.789438 17579 sgd_solver.cpp:105] Iteration 17200, lr = 0.005
I0621 17:20:07.953161 17579 solver.cpp:219] Iteration 17250 (0.399483 iter/s, 125.162s/50 iters), loss = 0.0018945
I0621 17:20:07.953310 17579 solver.cpp:238]     Train net output #0: loss = 0.00155088 (* 1 = 0.00155088 loss)
I0621 17:20:07.953348 17579 sgd_solver.cpp:105] Iteration 17250, lr = 0.005
I0621 17:22:13.795459 17579 solver.cpp:219] Iteration 17300 (0.39733 iter/s, 125.84s/50 iters), loss = 0.00287333
I0621 17:22:13.795648 17579 solver.cpp:238]     Train net output #0: loss = 0.00275296 (* 1 = 0.00275296 loss)
I0621 17:22:13.795676 17579 sgd_solver.cpp:105] Iteration 17300, lr = 0.005
I0621 17:24:19.278422 17579 solver.cpp:219] Iteration 17350 (0.398468 iter/s, 125.481s/50 iters), loss = 0.00185482
I0621 17:24:19.278575 17579 solver.cpp:238]     Train net output #0: loss = 0.00228184 (* 1 = 0.00228184 loss)
I0621 17:24:19.278604 17579 sgd_solver.cpp:105] Iteration 17350, lr = 0.005
I0621 17:26:25.117673 17579 solver.cpp:219] Iteration 17400 (0.39734 iter/s, 125.837s/50 iters), loss = 0.00108135
I0621 17:26:25.117856 17579 solver.cpp:238]     Train net output #0: loss = 0.00101628 (* 1 = 0.00101628 loss)
I0621 17:26:25.117883 17579 sgd_solver.cpp:105] Iteration 17400, lr = 0.005
I0621 17:28:30.518316 17579 solver.cpp:219] Iteration 17450 (0.398729 iter/s, 125.398s/50 iters), loss = 0.00354697
I0621 17:28:30.518451 17579 solver.cpp:238]     Train net output #0: loss = 0.0083426 (* 1 = 0.0083426 loss)
I0621 17:28:30.518482 17579 sgd_solver.cpp:105] Iteration 17450, lr = 0.005
I0621 17:30:33.863059 17579 solver.cpp:331] Iteration 17500, Testing net (#0)
I0621 17:30:49.065951 17579 solver.cpp:398]     Test net output #0: accuracy = 0.979412
I0621 17:30:49.066046 17579 solver.cpp:398]     Test net output #1: loss = 0.0797891 (* 1 = 0.0797891 loss)
I0621 17:30:51.582687 17579 solver.cpp:219] Iteration 17500 (0.354452 iter/s, 141.063s/50 iters), loss = 0.00307066
I0621 17:30:51.582814 17579 solver.cpp:238]     Train net output #0: loss = 0.00146194 (* 1 = 0.00146194 loss)
I0621 17:30:51.582844 17579 sgd_solver.cpp:105] Iteration 17500, lr = 0.005
I0621 17:32:57.329586 17579 solver.cpp:219] Iteration 17550 (0.397631 iter/s, 125.745s/50 iters), loss = 0.00257155
I0621 17:32:57.329773 17579 solver.cpp:238]     Train net output #0: loss = 0.00197945 (* 1 = 0.00197945 loss)
I0621 17:32:57.329800 17579 sgd_solver.cpp:105] Iteration 17550, lr = 0.005
I0621 17:35:02.711155 17579 solver.cpp:219] Iteration 17600 (0.39879 iter/s, 125.379s/50 iters), loss = 0.00320526
I0621 17:35:02.711302 17579 solver.cpp:238]     Train net output #0: loss = 0.000461158 (* 1 = 0.000461158 loss)
I0621 17:35:02.711333 17579 sgd_solver.cpp:105] Iteration 17600, lr = 0.005
I0621 17:37:08.516837 17579 solver.cpp:219] Iteration 17650 (0.397446 iter/s, 125.803s/50 iters), loss = 0.00346538
I0621 17:37:08.516986 17579 solver.cpp:238]     Train net output #0: loss = 0.0029909 (* 1 = 0.0029909 loss)
I0621 17:37:08.517014 17579 sgd_solver.cpp:105] Iteration 17650, lr = 0.005
I0621 17:39:13.921473 17579 solver.cpp:219] Iteration 17700 (0.398717 iter/s, 125.402s/50 iters), loss = 0.00229019
I0621 17:39:13.922114 17579 solver.cpp:238]     Train net output #0: loss = 0.00305459 (* 1 = 0.00305459 loss)
I0621 17:39:13.922144 17579 sgd_solver.cpp:105] Iteration 17700, lr = 0.005
I0621 17:41:19.726299 17579 solver.cpp:219] Iteration 17750 (0.397448 iter/s, 125.803s/50 iters), loss = 0.00289993
I0621 17:41:19.726449 17579 solver.cpp:238]     Train net output #0: loss = 0.0101058 (* 1 = 0.0101058 loss)
I0621 17:41:19.726478 17579 sgd_solver.cpp:105] Iteration 17750, lr = 0.005
I0621 17:43:25.193413 17579 solver.cpp:219] Iteration 17800 (0.398518 iter/s, 125.465s/50 iters), loss = 0.0019319
I0621 17:43:25.193568 17579 solver.cpp:238]     Train net output #0: loss = 0.00108083 (* 1 = 0.00108083 loss)
I0621 17:43:25.193599 17579 sgd_solver.cpp:105] Iteration 17800, lr = 0.005
I0621 17:45:31.193033 17579 solver.cpp:219] Iteration 17850 (0.396834 iter/s, 125.997s/50 iters), loss = 0.00146401
I0621 17:45:31.193176 17579 solver.cpp:238]     Train net output #0: loss = 0.00220398 (* 1 = 0.00220398 loss)
I0621 17:45:31.193203 17579 sgd_solver.cpp:105] Iteration 17850, lr = 0.005
I0621 17:47:35.425628 17579 solver.cpp:219] Iteration 17900 (0.402475 iter/s, 124.231s/50 iters), loss = 0.00262031
I0621 17:47:35.425808 17579 solver.cpp:238]     Train net output #0: loss = 0.0026435 (* 1 = 0.0026435 loss)
I0621 17:47:35.425837 17579 sgd_solver.cpp:105] Iteration 17900, lr = 0.005
I0621 17:48:46.194068 17579 solver.cpp:219] Iteration 17950 (0.706538 iter/s, 70.7676s/50 iters), loss = 0.0016252
I0621 17:48:46.194221 17579 solver.cpp:238]     Train net output #0: loss = 0.00380351 (* 1 = 0.00380351 loss)
I0621 17:48:46.194249 17579 sgd_solver.cpp:105] Iteration 17950, lr = 0.005
I0621 17:49:55.696293 17579 solver.cpp:331] Iteration 18000, Testing net (#0)
I0621 17:50:07.704073 17579 solver.cpp:398]     Test net output #0: accuracy = 0.984314
I0621 17:50:07.704159 17579 solver.cpp:398]     Test net output #1: loss = 0.0725162 (* 1 = 0.0725162 loss)
I0621 17:50:07.711560 17579 compress_conv_layer.cu:174] 0.616657 1.84504e-10 0.94848
I0621 17:50:07.720201 17579 compress_conv_layer.cu:174] 0.616657 1.12529e-10 0.554709
I0621 17:50:07.728507 17579 compress_conv_layer.cu:174] 0.616657 2.022e-11 0.743383
I0621 17:50:07.736773 17579 compress_conv_layer.cu:174] 0.616657 3.07919e-12 0.78449
I0621 17:50:07.749517 17579 compress_conv_layer.cu:174] 0.616657 9.83459e-12 0.457785
I0621 17:50:07.771611 17579 compress_conv_layer.cu:174] 0.616657 9.4344e-14 0.484054
I0621 17:50:07.815454 17579 compress_conv_layer.cu:174] 0.616657 1.71339e-13 0.476447
I0621 17:50:07.859136 17579 compress_conv_layer.cu:174] 0.616657 2.18199e-12 0.404873
I0621 17:50:07.903620 17579 compress_conv_layer.cu:174] 0.616657 1.89619e-12 0.43037
I0621 17:50:07.947075 17579 compress_conv_layer.cu:174] 0.616657 1.99304e-12 0.576364
I0621 17:50:07.995026 17579 compress_conv_layer.cu:174] 0.616657 5.48845e-12 0.457318
I0621 17:50:08.089876 17579 compress_conv_layer.cu:174] 0.616657 1.64176e-12 0.328007
I0621 17:50:08.274725 17579 compress_conv_layer.cu:174] 0.616657 3.38168e-12 0.292782
I0621 17:50:08.293125 17579 compress_conv_layer.cu:174] 0.616657 3.14429e-07 0.188319
I0621 17:50:08.531790 17579 compress_conv_layer.cu:174] 0.616657 1.84504e-10 0.94848
I0621 17:50:08.539796 17579 compress_conv_layer.cu:174] 0.616657 1.12529e-10 0.554709
I0621 17:50:08.548105 17579 compress_conv_layer.cu:174] 0.616657 2.022e-11 0.743383
I0621 17:50:08.556360 17579 compress_conv_layer.cu:174] 0.616657 3.07919e-12 0.78449
I0621 17:50:08.569402 17579 compress_conv_layer.cu:174] 0.616657 9.83459e-12 0.457785
I0621 17:50:08.592053 17579 compress_conv_layer.cu:174] 0.616657 9.4344e-14 0.484054
I0621 17:50:08.636224 17579 compress_conv_layer.cu:174] 0.616657 1.71339e-13 0.476447
I0621 17:50:08.680135 17579 compress_conv_layer.cu:174] 0.616657 2.18199e-12 0.404873
I0621 17:50:08.724593 17579 compress_conv_layer.cu:174] 0.616657 1.89619e-12 0.43037
I0621 17:50:08.767966 17579 compress_conv_layer.cu:174] 0.616657 1.99304e-12 0.576364
I0621 17:50:08.811437 17579 compress_conv_layer.cu:174] 0.616657 5.48845e-12 0.457318
I0621 17:50:08.899307 17579 compress_conv_layer.cu:174] 0.616657 1.64176e-12 0.328007
I0621 17:50:09.084882 17579 compress_conv_layer.cu:174] 0.616657 3.38168e-12 0.292782
I0621 17:50:09.103224 17579 compress_conv_layer.cu:174] 0.616657 3.14429e-07 0.188319
I0621 17:50:09.341779 17579 compress_conv_layer.cu:174] 0.616657 1.84504e-10 0.94848
I0621 17:50:09.349771 17579 compress_conv_layer.cu:174] 0.616657 1.12529e-10 0.554709
I0621 17:50:09.358052 17579 compress_conv_layer.cu:174] 0.616657 2.022e-11 0.743383
I0621 17:50:09.366334 17579 compress_conv_layer.cu:174] 0.616657 3.07919e-12 0.78449
I0621 17:50:09.378970 17579 compress_conv_layer.cu:174] 0.616657 9.83459e-12 0.457785
I0621 17:50:09.400832 17579 compress_conv_layer.cu:174] 0.616657 9.4344e-14 0.484054
I0621 17:50:09.444161 17579 compress_conv_layer.cu:174] 0.616657 1.71339e-13 0.476447
I0621 17:50:09.488029 17579 compress_conv_layer.cu:174] 0.616657 2.18199e-12 0.404873
I0621 17:50:09.532244 17579 compress_conv_layer.cu:174] 0.616657 1.89619e-12 0.43037
I0621 17:50:09.574945 17579 compress_conv_layer.cu:174] 0.616657 1.99304e-12 0.576364
I0621 17:50:09.617805 17579 compress_conv_layer.cu:174] 0.616657 5.48845e-12 0.457318
I0621 17:50:09.703987 17579 compress_conv_layer.cu:174] 0.616657 1.64176e-12 0.328007
I0621 17:50:09.886060 17579 compress_conv_layer.cu:174] 0.616657 3.38168e-12 0.292782
I0621 17:50:09.904359 17579 compress_conv_layer.cu:174] 0.616657 3.14429e-07 0.188319
I0621 17:50:10.142171 17579 compress_conv_layer.cu:174] 0.616657 1.84504e-10 0.94848
I0621 17:50:10.155874 17579 compress_conv_layer.cu:174] 0.616657 1.12529e-10 0.554709
I0621 17:50:10.164362 17579 compress_conv_layer.cu:174] 0.616657 2.022e-11 0.743383
I0621 17:50:10.172688 17579 compress_conv_layer.cu:174] 0.616657 3.07919e-12 0.78449
I0621 17:50:10.185712 17579 compress_conv_layer.cu:174] 0.616657 9.83459e-12 0.457785
I0621 17:50:10.215787 17579 compress_conv_layer.cu:174] 0.616657 9.4344e-14 0.484054
I0621 17:50:10.259660 17579 compress_conv_layer.cu:174] 0.616657 1.71339e-13 0.476447
I0621 17:50:10.303972 17579 compress_conv_layer.cu:174] 0.616657 2.18199e-12 0.404873
I0621 17:50:10.350880 17579 compress_conv_layer.cu:174] 0.616657 1.89619e-12 0.43037
I0621 17:50:10.405979 17579 compress_conv_layer.cu:174] 0.616657 1.99304e-12 0.576364
I0621 17:50:10.453583 17579 compress_conv_layer.cu:174] 0.616657 5.48845e-12 0.457318
I0621 17:50:10.542567 17579 compress_conv_layer.cu:174] 0.616657 1.64176e-12 0.328007
I0621 17:50:10.763033 17579 compress_conv_layer.cu:174] 0.616657 3.38168e-12 0.292782
I0621 17:50:10.781397 17579 compress_conv_layer.cu:174] 0.616657 3.14429e-07 0.188319
I0621 17:50:11.024229 17579 compress_conv_layer.cu:174] 0.616657 1.84504e-10 0.94848
I0621 17:50:11.032320 17579 compress_conv_layer.cu:174] 0.616657 1.12529e-10 0.554709
I0621 17:50:11.040700 17579 compress_conv_layer.cu:174] 0.616657 2.022e-11 0.743383
I0621 17:50:11.048985 17579 compress_conv_layer.cu:174] 0.616657 3.07919e-12 0.78449
I0621 17:50:11.061882 17579 compress_conv_layer.cu:174] 0.616657 9.83459e-12 0.457785
I0621 17:50:11.084069 17579 compress_conv_layer.cu:174] 0.616657 9.4344e-14 0.484054
I0621 17:50:11.127362 17579 compress_conv_layer.cu:174] 0.616657 1.71339e-13 0.476447
I0621 17:50:11.170846 17579 compress_conv_layer.cu:174] 0.616657 2.18199e-12 0.404873
I0621 17:50:11.215040 17579 compress_conv_layer.cu:174] 0.616657 1.89619e-12 0.43037
I0621 17:50:11.258250 17579 compress_conv_layer.cu:174] 0.616657 1.99304e-12 0.576364
I0621 17:50:11.302073 17579 compress_conv_layer.cu:174] 0.616657 5.48845e-12 0.457318
I0621 17:50:11.388669 17579 compress_conv_layer.cu:174] 0.616657 1.64176e-12 0.328007
I0621 17:50:11.570909 17579 compress_conv_layer.cu:174] 0.616657 3.38168e-12 0.292782
I0621 17:50:11.589078 17579 compress_conv_layer.cu:174] 0.616657 3.14429e-07 0.188319
I0621 17:50:11.819694 17579 solver.cpp:219] Iteration 18000 (0.583944 iter/s, 85.6246s/50 iters), loss = 0.00216023
I0621 17:50:11.819825 17579 solver.cpp:238]     Train net output #0: loss = 0.00130679 (* 1 = 0.00130679 loss)
I0621 17:50:11.819856 17579 sgd_solver.cpp:105] Iteration 18000, lr = 0.005
I0621 17:51:22.708667 17579 solver.cpp:219] Iteration 18050 (0.705337 iter/s, 70.8881s/50 iters), loss = 0.00385326
I0621 17:51:22.708904 17579 solver.cpp:238]     Train net output #0: loss = 0.00595802 (* 1 = 0.00595802 loss)
I0621 17:51:22.708936 17579 sgd_solver.cpp:105] Iteration 18050, lr = 0.005
I0621 17:52:33.514113 17579 solver.cpp:219] Iteration 18100 (0.706171 iter/s, 70.8044s/50 iters), loss = 0.00261207
I0621 17:52:33.514266 17579 solver.cpp:238]     Train net output #0: loss = 0.00291805 (* 1 = 0.00291805 loss)
I0621 17:52:33.514294 17579 sgd_solver.cpp:105] Iteration 18100, lr = 0.005
I0621 17:53:44.382767 17579 solver.cpp:219] Iteration 18150 (0.70554 iter/s, 70.8677s/50 iters), loss = 0.0025514
I0621 17:53:44.383143 17579 solver.cpp:238]     Train net output #0: loss = 0.00385343 (* 1 = 0.00385343 loss)
I0621 17:53:44.383173 17579 sgd_solver.cpp:105] Iteration 18150, lr = 0.005
I0621 17:54:55.241804 17579 solver.cpp:219] Iteration 18200 (0.705639 iter/s, 70.8578s/50 iters), loss = 0.00473432
I0621 17:54:55.241996 17579 solver.cpp:238]     Train net output #0: loss = 0.00413764 (* 1 = 0.00413764 loss)
I0621 17:54:55.242038 17579 sgd_solver.cpp:105] Iteration 18200, lr = 0.005
I0621 17:56:06.195806 17579 solver.cpp:219] Iteration 18250 (0.704692 iter/s, 70.953s/50 iters), loss = 0.00224293
I0621 17:56:06.195978 17579 solver.cpp:238]     Train net output #0: loss = 0.00202651 (* 1 = 0.00202651 loss)
I0621 17:56:06.196007 17579 sgd_solver.cpp:105] Iteration 18250, lr = 0.005
I0621 17:57:17.018592 17579 solver.cpp:219] Iteration 18300 (0.705997 iter/s, 70.8218s/50 iters), loss = 0.00241265
I0621 17:57:17.018723 17579 solver.cpp:238]     Train net output #0: loss = 0.00360853 (* 1 = 0.00360853 loss)
I0621 17:57:17.018754 17579 sgd_solver.cpp:105] Iteration 18300, lr = 0.005
I0621 17:58:27.827498 17579 solver.cpp:219] Iteration 18350 (0.706135 iter/s, 70.808s/50 iters), loss = 0.00292242
I0621 17:58:27.827662 17579 solver.cpp:238]     Train net output #0: loss = 0.00266498 (* 1 = 0.00266498 loss)
I0621 17:58:27.827692 17579 sgd_solver.cpp:105] Iteration 18350, lr = 0.005
I0621 17:59:38.642596 17579 solver.cpp:219] Iteration 18400 (0.706074 iter/s, 70.8141s/50 iters), loss = 0.00254094
I0621 17:59:38.642751 17579 solver.cpp:238]     Train net output #0: loss = 0.00310676 (* 1 = 0.00310676 loss)
I0621 17:59:38.642781 17579 sgd_solver.cpp:105] Iteration 18400, lr = 0.005
I0621 18:00:49.450776 17579 solver.cpp:219] Iteration 18450 (0.706143 iter/s, 70.8072s/50 iters), loss = 0.00166716
I0621 18:00:49.450928 17579 solver.cpp:238]     Train net output #0: loss = 0.00288581 (* 1 = 0.00288581 loss)
I0621 18:00:49.450958 17579 sgd_solver.cpp:105] Iteration 18450, lr = 0.005
I0621 18:01:58.835152 17579 solver.cpp:331] Iteration 18500, Testing net (#0)
I0621 18:02:10.791421 17579 solver.cpp:398]     Test net output #0: accuracy = 0.980392
I0621 18:02:10.791499 17579 solver.cpp:398]     Test net output #1: loss = 0.0758264 (* 1 = 0.0758264 loss)
I0621 18:02:12.202567 17579 solver.cpp:219] Iteration 18500 (0.604225 iter/s, 82.7507s/50 iters), loss = 0.00221884
I0621 18:02:12.202661 17579 solver.cpp:238]     Train net output #0: loss = 0.00311072 (* 1 = 0.00311072 loss)
I0621 18:02:12.202688 17579 sgd_solver.cpp:105] Iteration 18500, lr = 0.005
I0621 18:03:22.988149 17579 solver.cpp:219] Iteration 18550 (0.706367 iter/s, 70.7847s/50 iters), loss = 0.00279975
I0621 18:03:22.988598 17579 solver.cpp:238]     Train net output #0: loss = 0.000346956 (* 1 = 0.000346956 loss)
I0621 18:03:22.988627 17579 sgd_solver.cpp:105] Iteration 18550, lr = 0.005
I0621 18:04:33.765367 17579 solver.cpp:219] Iteration 18600 (0.706455 iter/s, 70.776s/50 iters), loss = 0.00212763
I0621 18:04:33.765519 17579 solver.cpp:238]     Train net output #0: loss = 0.00225662 (* 1 = 0.00225662 loss)
I0621 18:04:33.765549 17579 sgd_solver.cpp:105] Iteration 18600, lr = 0.005
I0621 18:05:44.587011 17579 solver.cpp:219] Iteration 18650 (0.706008 iter/s, 70.8207s/50 iters), loss = 0.0028753
I0621 18:05:44.587162 17579 solver.cpp:238]     Train net output #0: loss = 0.00309954 (* 1 = 0.00309954 loss)
I0621 18:05:44.587191 17579 sgd_solver.cpp:105] Iteration 18650, lr = 0.005
I0621 18:06:55.413003 17579 solver.cpp:219] Iteration 18700 (0.705965 iter/s, 70.825s/50 iters), loss = 0.00163331
I0621 18:06:55.413141 17579 solver.cpp:238]     Train net output #0: loss = 0.00193114 (* 1 = 0.00193114 loss)
I0621 18:06:55.413170 17579 sgd_solver.cpp:105] Iteration 18700, lr = 0.005
I0621 18:08:06.209553 17579 solver.cpp:219] Iteration 18750 (0.706259 iter/s, 70.7956s/50 iters), loss = 0.00184576
I0621 18:08:06.209687 17579 solver.cpp:238]     Train net output #0: loss = 0.000993933 (* 1 = 0.000993933 loss)
I0621 18:08:06.209715 17579 sgd_solver.cpp:105] Iteration 18750, lr = 0.005
I0621 18:09:17.043341 17579 solver.cpp:219] Iteration 18800 (0.705887 iter/s, 70.8328s/50 iters), loss = 0.00160318
I0621 18:09:17.043493 17579 solver.cpp:238]     Train net output #0: loss = 0.002182 (* 1 = 0.002182 loss)
I0621 18:09:17.043531 17579 sgd_solver.cpp:105] Iteration 18800, lr = 0.005
I0621 18:10:27.835615 17579 solver.cpp:219] Iteration 18850 (0.706301 iter/s, 70.7913s/50 iters), loss = 0.00133492
I0621 18:10:27.835981 17579 solver.cpp:238]     Train net output #0: loss = 0.00152674 (* 1 = 0.00152674 loss)
I0621 18:10:27.836009 17579 sgd_solver.cpp:105] Iteration 18850, lr = 0.005
I0621 18:11:38.684311 17579 solver.cpp:219] Iteration 18900 (0.705741 iter/s, 70.8475s/50 iters), loss = 0.000992468
I0621 18:11:38.684494 17579 solver.cpp:238]     Train net output #0: loss = 0.000537787 (* 1 = 0.000537787 loss)
I0621 18:11:38.684530 17579 sgd_solver.cpp:105] Iteration 18900, lr = 0.005
I0621 18:12:49.543705 17579 solver.cpp:219] Iteration 18950 (0.705633 iter/s, 70.8584s/50 iters), loss = 0.00251908
I0621 18:12:49.543853 17579 solver.cpp:238]     Train net output #0: loss = 0.00139586 (* 1 = 0.00139586 loss)
I0621 18:12:49.543881 17579 sgd_solver.cpp:105] Iteration 18950, lr = 0.005
I0621 18:13:58.918779 17579 solver.cpp:331] Iteration 19000, Testing net (#0)
I0621 18:14:10.876147 17579 solver.cpp:398]     Test net output #0: accuracy = 0.981373
I0621 18:14:10.876237 17579 solver.cpp:398]     Test net output #1: loss = 0.0777907 (* 1 = 0.0777907 loss)
I0621 18:14:12.292016 17579 solver.cpp:219] Iteration 19000 (0.60425 iter/s, 82.7472s/50 iters), loss = 0.00204226
I0621 18:14:12.292112 17579 solver.cpp:238]     Train net output #0: loss = 0.00241979 (* 1 = 0.00241979 loss)
I0621 18:14:12.292140 17579 sgd_solver.cpp:105] Iteration 19000, lr = 0.005
I0621 18:15:23.351222 17579 solver.cpp:219] Iteration 19050 (0.703647 iter/s, 71.0583s/50 iters), loss = 0.00241032
I0621 18:15:23.351402 17579 solver.cpp:238]     Train net output #0: loss = 0.00308143 (* 1 = 0.00308143 loss)
I0621 18:15:23.351431 17579 sgd_solver.cpp:105] Iteration 19050, lr = 0.005
I0621 18:16:34.130797 17579 solver.cpp:219] Iteration 19100 (0.706428 iter/s, 70.7786s/50 iters), loss = 0.00181063
I0621 18:16:34.130941 17579 solver.cpp:238]     Train net output #0: loss = 0.00206932 (* 1 = 0.00206932 loss)
I0621 18:16:34.130970 17579 sgd_solver.cpp:105] Iteration 19100, lr = 0.005
I0621 18:17:44.919420 17579 solver.cpp:219] Iteration 19150 (0.706338 iter/s, 70.7877s/50 iters), loss = 0.00148031
I0621 18:17:44.919606 17579 solver.cpp:238]     Train net output #0: loss = 0.000559345 (* 1 = 0.000559345 loss)
I0621 18:17:44.919636 17579 sgd_solver.cpp:105] Iteration 19150, lr = 0.005
I0621 18:18:55.718377 17579 solver.cpp:219] Iteration 19200 (0.706235 iter/s, 70.798s/50 iters), loss = 0.00271964
I0621 18:18:55.718544 17579 solver.cpp:238]     Train net output #0: loss = 0.0037169 (* 1 = 0.0037169 loss)
I0621 18:18:55.718575 17579 sgd_solver.cpp:105] Iteration 19200, lr = 0.005
I0621 18:20:06.511430 17579 solver.cpp:219] Iteration 19250 (0.706294 iter/s, 70.7921s/50 iters), loss = 0.00198299
I0621 18:20:06.511602 17579 solver.cpp:238]     Train net output #0: loss = 0.00187943 (* 1 = 0.00187943 loss)
I0621 18:20:06.511636 17579 sgd_solver.cpp:105] Iteration 19250, lr = 0.005
I0621 18:21:17.304728 17579 solver.cpp:219] Iteration 19300 (0.706291 iter/s, 70.7923s/50 iters), loss = 0.00125719
I0621 18:21:17.304877 17579 solver.cpp:238]     Train net output #0: loss = 0.000767487 (* 1 = 0.000767487 loss)
I0621 18:21:17.304909 17579 sgd_solver.cpp:105] Iteration 19300, lr = 0.005
I0621 18:22:28.104018 17579 solver.cpp:219] Iteration 19350 (0.706231 iter/s, 70.7984s/50 iters), loss = 0.00194805
I0621 18:22:28.104168 17579 solver.cpp:238]     Train net output #0: loss = 0.000731442 (* 1 = 0.000731442 loss)
I0621 18:22:28.104197 17579 sgd_solver.cpp:105] Iteration 19350, lr = 0.005
I0621 18:23:38.894732 17579 solver.cpp:219] Iteration 19400 (0.706317 iter/s, 70.7898s/50 iters), loss = 0.00256152
I0621 18:23:38.894878 17579 solver.cpp:238]     Train net output #0: loss = 0.00122304 (* 1 = 0.00122304 loss)
I0621 18:23:38.894906 17579 sgd_solver.cpp:105] Iteration 19400, lr = 0.005
I0621 18:24:49.675817 17579 solver.cpp:219] Iteration 19450 (0.706413 iter/s, 70.7801s/50 iters), loss = 0.00169
I0621 18:24:49.675974 17579 solver.cpp:238]     Train net output #0: loss = 0.000885168 (* 1 = 0.000885168 loss)
I0621 18:24:49.676017 17579 sgd_solver.cpp:105] Iteration 19450, lr = 0.005
I0621 18:25:59.059689 17579 solver.cpp:331] Iteration 19500, Testing net (#0)
I0621 18:26:11.070791 17579 solver.cpp:398]     Test net output #0: accuracy = 0.979412
I0621 18:26:11.070881 17579 solver.cpp:398]     Test net output #1: loss = 0.0777638 (* 1 = 0.0777638 loss)
I0621 18:26:11.078305 17579 compress_conv_layer.cu:174] 0.632779 1.83817e-10 0.944901
I0621 18:26:11.086913 17579 compress_conv_layer.cu:174] 0.632779 1.1211e-10 0.552674
I0621 18:26:11.095230 17579 compress_conv_layer.cu:174] 0.632779 2.01445e-11 0.740738
I0621 18:26:11.103440 17579 compress_conv_layer.cu:174] 0.632779 3.06781e-12 0.781562
I0621 18:26:11.116195 17579 compress_conv_layer.cu:174] 0.632779 9.79816e-12 0.456184
I0621 18:26:11.138453 17579 compress_conv_layer.cu:174] 0.632779 9.39883e-14 0.482341
I0621 18:26:11.182163 17579 compress_conv_layer.cu:174] 0.632779 1.7069e-13 0.474465
I0621 18:26:11.225643 17579 compress_conv_layer.cu:174] 0.632779 2.17385e-12 0.403342
I0621 18:26:11.269598 17579 compress_conv_layer.cu:174] 0.632779 1.88904e-12 0.428688
I0621 18:26:11.313370 17579 compress_conv_layer.cu:174] 0.632779 1.98556e-12 0.574088
I0621 18:26:11.357120 17579 compress_conv_layer.cu:174] 0.632779 5.46763e-12 0.455484
I0621 18:26:11.444525 17579 compress_conv_layer.cu:174] 0.632779 1.63558e-12 0.326597
I0621 18:26:11.627868 17579 compress_conv_layer.cu:174] 0.632779 3.36899e-12 0.291664
I0621 18:26:11.646064 17579 compress_conv_layer.cu:174] 0.632779 3.13235e-07 0.189527
I0621 18:26:11.884275 17579 compress_conv_layer.cu:174] 0.632779 1.83817e-10 0.944901
I0621 18:26:11.892242 17579 compress_conv_layer.cu:174] 0.632779 1.1211e-10 0.552674
I0621 18:26:11.900475 17579 compress_conv_layer.cu:174] 0.632779 2.01445e-11 0.740738
I0621 18:26:11.908579 17579 compress_conv_layer.cu:174] 0.632779 3.06781e-12 0.781562
I0621 18:26:11.921136 17579 compress_conv_layer.cu:174] 0.632779 9.79816e-12 0.456184
I0621 18:26:11.942911 17579 compress_conv_layer.cu:174] 0.632779 9.39883e-14 0.482341
I0621 18:26:11.985601 17579 compress_conv_layer.cu:174] 0.632779 1.7069e-13 0.474465
I0621 18:26:12.028767 17579 compress_conv_layer.cu:174] 0.632779 2.17385e-12 0.403342
I0621 18:26:12.072118 17579 compress_conv_layer.cu:174] 0.632779 1.88904e-12 0.428688
I0621 18:26:12.114940 17579 compress_conv_layer.cu:174] 0.632779 1.98556e-12 0.574088
I0621 18:26:12.158290 17579 compress_conv_layer.cu:174] 0.632779 5.46763e-12 0.455484
I0621 18:26:12.244063 17579 compress_conv_layer.cu:174] 0.632779 1.63558e-12 0.326597
I0621 18:26:12.424736 17579 compress_conv_layer.cu:174] 0.632779 3.36899e-12 0.291664
I0621 18:26:12.442953 17579 compress_conv_layer.cu:174] 0.632779 3.13235e-07 0.189527
I0621 18:26:12.681183 17579 compress_conv_layer.cu:174] 0.632779 1.83817e-10 0.944901
I0621 18:26:12.689149 17579 compress_conv_layer.cu:174] 0.632779 1.1211e-10 0.552674
I0621 18:26:12.697402 17579 compress_conv_layer.cu:174] 0.632779 2.01445e-11 0.740738
I0621 18:26:12.705502 17579 compress_conv_layer.cu:174] 0.632779 3.06781e-12 0.781562
I0621 18:26:12.718125 17579 compress_conv_layer.cu:174] 0.632779 9.79816e-12 0.456184
I0621 18:26:12.739976 17579 compress_conv_layer.cu:174] 0.632779 9.39883e-14 0.482341
I0621 18:26:12.782838 17579 compress_conv_layer.cu:174] 0.632779 1.7069e-13 0.474465
I0621 18:26:12.825980 17579 compress_conv_layer.cu:174] 0.632779 2.17385e-12 0.403342
I0621 18:26:12.869302 17579 compress_conv_layer.cu:174] 0.632779 1.88904e-12 0.428688
I0621 18:26:12.912355 17579 compress_conv_layer.cu:174] 0.632779 1.98556e-12 0.574088
I0621 18:26:12.955636 17579 compress_conv_layer.cu:174] 0.632779 5.46763e-12 0.455484
I0621 18:26:13.041285 17579 compress_conv_layer.cu:174] 0.632779 1.63558e-12 0.326597
I0621 18:26:13.221565 17579 compress_conv_layer.cu:174] 0.632779 3.36899e-12 0.291664
I0621 18:26:13.239769 17579 compress_conv_layer.cu:174] 0.632779 3.13235e-07 0.189527
I0621 18:26:13.478087 17579 compress_conv_layer.cu:174] 0.632779 1.83817e-10 0.944901
I0621 18:26:13.486053 17579 compress_conv_layer.cu:174] 0.632779 1.1211e-10 0.552674
I0621 18:26:13.494340 17579 compress_conv_layer.cu:174] 0.632779 2.01445e-11 0.740738
I0621 18:26:13.502427 17579 compress_conv_layer.cu:174] 0.632779 3.06781e-12 0.781562
I0621 18:26:13.515012 17579 compress_conv_layer.cu:174] 0.632779 9.79816e-12 0.456184
I0621 18:26:13.536800 17579 compress_conv_layer.cu:174] 0.632779 9.39883e-14 0.482341
I0621 18:26:13.579442 17579 compress_conv_layer.cu:174] 0.632779 1.7069e-13 0.474465
I0621 18:26:13.622647 17579 compress_conv_layer.cu:174] 0.632779 2.17385e-12 0.403342
I0621 18:26:13.666174 17579 compress_conv_layer.cu:174] 0.632779 1.88904e-12 0.428688
I0621 18:26:13.709550 17579 compress_conv_layer.cu:174] 0.632779 1.98556e-12 0.574088
I0621 18:26:13.753083 17579 compress_conv_layer.cu:174] 0.632779 5.46763e-12 0.455484
I0621 18:26:13.838603 17579 compress_conv_layer.cu:174] 0.632779 1.63558e-12 0.326597
I0621 18:26:14.018749 17579 compress_conv_layer.cu:174] 0.632779 3.36899e-12 0.291664
I0621 18:26:14.036945 17579 compress_conv_layer.cu:174] 0.632779 3.13235e-07 0.189527
I0621 18:26:14.275203 17579 compress_conv_layer.cu:174] 0.632779 1.83817e-10 0.944901
I0621 18:26:14.283159 17579 compress_conv_layer.cu:174] 0.632779 1.1211e-10 0.552674
I0621 18:26:14.291458 17579 compress_conv_layer.cu:174] 0.632779 2.01445e-11 0.740738
I0621 18:26:14.299587 17579 compress_conv_layer.cu:174] 0.632779 3.06781e-12 0.781562
I0621 18:26:14.312153 17579 compress_conv_layer.cu:174] 0.632779 9.79816e-12 0.456184
I0621 18:26:14.333969 17579 compress_conv_layer.cu:174] 0.632779 9.39883e-14 0.482341
I0621 18:26:14.376902 17579 compress_conv_layer.cu:174] 0.632779 1.7069e-13 0.474465
I0621 18:26:14.420518 17579 compress_conv_layer.cu:174] 0.632779 2.17385e-12 0.403342
I0621 18:26:14.464493 17579 compress_conv_layer.cu:174] 0.632779 1.88904e-12 0.428688
I0621 18:26:14.507719 17579 compress_conv_layer.cu:174] 0.632779 1.98556e-12 0.574088
I0621 18:26:14.551062 17579 compress_conv_layer.cu:174] 0.632779 5.46763e-12 0.455484
I0621 18:26:14.636675 17579 compress_conv_layer.cu:174] 0.632779 1.63558e-12 0.326597
I0621 18:26:14.816979 17579 compress_conv_layer.cu:174] 0.632779 3.36899e-12 0.291664
I0621 18:26:14.835188 17579 compress_conv_layer.cu:174] 0.632779 3.13235e-07 0.189527
I0621 18:26:15.065631 17579 solver.cpp:219] Iteration 19500 (0.585558 iter/s, 85.3887s/50 iters), loss = 0.00349002
I0621 18:26:15.065723 17579 solver.cpp:238]     Train net output #0: loss = 0.00305203 (* 1 = 0.00305203 loss)
I0621 18:26:15.065749 17579 sgd_solver.cpp:105] Iteration 19500, lr = 0.005
I0621 18:27:25.850919 17579 solver.cpp:219] Iteration 19550 (0.706371 iter/s, 70.7844s/50 iters), loss = 0.00244549
I0621 18:27:25.851136 17579 solver.cpp:238]     Train net output #0: loss = 0.00137173 (* 1 = 0.00137173 loss)
I0621 18:27:25.851166 17579 sgd_solver.cpp:105] Iteration 19550, lr = 0.005
I0621 18:28:36.654026 17579 solver.cpp:219] Iteration 19600 (0.706194 iter/s, 70.8021s/50 iters), loss = 0.0034404
I0621 18:28:36.654166 17579 solver.cpp:238]     Train net output #0: loss = 0.0034682 (* 1 = 0.0034682 loss)
I0621 18:28:36.654194 17579 sgd_solver.cpp:105] Iteration 19600, lr = 0.005
I0621 18:29:47.448380 17579 solver.cpp:219] Iteration 19650 (0.706281 iter/s, 70.7934s/50 iters), loss = 0.00222743
I0621 18:29:47.448536 17579 solver.cpp:238]     Train net output #0: loss = 0.00229071 (* 1 = 0.00229071 loss)
I0621 18:29:47.448567 17579 sgd_solver.cpp:105] Iteration 19650, lr = 0.005
I0621 18:30:58.230475 17579 solver.cpp:219] Iteration 19700 (0.706403 iter/s, 70.7811s/50 iters), loss = 0.00152855
I0621 18:30:58.230625 17579 solver.cpp:238]     Train net output #0: loss = 0.00167476 (* 1 = 0.00167476 loss)
I0621 18:30:58.230657 17579 sgd_solver.cpp:105] Iteration 19700, lr = 0.005
I0621 18:32:09.004518 17579 solver.cpp:219] Iteration 19750 (0.706484 iter/s, 70.7731s/50 iters), loss = 0.00186187
I0621 18:32:09.004650 17579 solver.cpp:238]     Train net output #0: loss = 0.00249245 (* 1 = 0.00249245 loss)
I0621 18:32:09.004678 17579 sgd_solver.cpp:105] Iteration 19750, lr = 0.005
I0621 18:33:19.820149 17579 solver.cpp:219] Iteration 19800 (0.706069 iter/s, 70.8147s/50 iters), loss = 0.00303965
I0621 18:33:19.820315 17579 solver.cpp:238]     Train net output #0: loss = 0.00554335 (* 1 = 0.00554335 loss)
I0621 18:33:19.820343 17579 sgd_solver.cpp:105] Iteration 19800, lr = 0.005
I0621 18:34:52.858546 17579 solver.cpp:219] Iteration 19850 (0.53742 iter/s, 93.0371s/50 iters), loss = 0.0019874
I0621 18:34:52.858698 17579 solver.cpp:238]     Train net output #0: loss = 0.00150952 (* 1 = 0.00150952 loss)
I0621 18:34:52.858727 17579 sgd_solver.cpp:105] Iteration 19850, lr = 0.005
I0621 18:36:58.292927 17579 solver.cpp:219] Iteration 19900 (0.398623 iter/s, 125.432s/50 iters), loss = 0.00245573
I0621 18:36:58.293071 17579 solver.cpp:238]     Train net output #0: loss = 0.0046126 (* 1 = 0.0046126 loss)
I0621 18:36:58.293099 17579 sgd_solver.cpp:105] Iteration 19900, lr = 0.005
I0621 18:39:03.323253 17579 solver.cpp:219] Iteration 19950 (0.399911 iter/s, 125.028s/50 iters), loss = 0.00125289
I0621 18:39:03.323400 17579 solver.cpp:238]     Train net output #0: loss = 0.00160586 (* 1 = 0.00160586 loss)
I0621 18:39:03.323428 17579 sgd_solver.cpp:105] Iteration 19950, lr = 0.005
I0621 18:41:06.160854 17579 solver.cpp:448] Snapshotting to binary proto file mobilenet/mobile_pruning_iter_20000.caffemodel
I0621 18:41:06.296663 17579 sgd_solver.cpp:273] Snapshotting solver state to binary proto file mobilenet/mobile_pruning_iter_20000.solverstate
I0621 18:41:06.363984 17579 solver.cpp:331] Iteration 20000, Testing net (#0)
I0621 18:41:09.452919 17579 blocking_queue.cpp:49] Waiting for data
I0621 18:41:21.406375 17579 solver.cpp:398]     Test net output #0: accuracy = 0.977451
I0621 18:41:21.406453 17579 solver.cpp:398]     Test net output #1: loss = 0.081292 (* 1 = 0.081292 loss)
I0621 18:41:23.911399 17579 solver.cpp:219] Iteration 20000 (0.355655 iter/s, 140.586s/50 iters), loss = 0.00149435
I0621 18:41:23.911491 17579 solver.cpp:238]     Train net output #0: loss = 0.00174968 (* 1 = 0.00174968 loss)
I0621 18:41:23.911525 17579 sgd_solver.cpp:105] Iteration 20000, lr = 0.0005
I0621 18:43:29.215193 17579 solver.cpp:219] Iteration 20050 (0.399038 iter/s, 125.301s/50 iters), loss = 0.00237573
I0621 18:43:29.215355 17579 solver.cpp:238]     Train net output #0: loss = 0.00207245 (* 1 = 0.00207245 loss)
I0621 18:43:29.215384 17579 sgd_solver.cpp:105] Iteration 20050, lr = 0.0005
I0621 18:45:34.408797 17579 solver.cpp:219] Iteration 20100 (0.399389 iter/s, 125.191s/50 iters), loss = 0.00195391
I0621 18:45:34.408960 17579 solver.cpp:238]     Train net output #0: loss = 0.00354277 (* 1 = 0.00354277 loss)
I0621 18:45:34.408988 17579 sgd_solver.cpp:105] Iteration 20100, lr = 0.0005
I0621 18:47:40.004926 17579 solver.cpp:219] Iteration 20150 (0.398109 iter/s, 125.594s/50 iters), loss = 0.0017307
I0621 18:47:40.005076 17579 solver.cpp:238]     Train net output #0: loss = 0.000988423 (* 1 = 0.000988423 loss)
I0621 18:47:40.005103 17579 sgd_solver.cpp:105] Iteration 20150, lr = 0.0005
I0621 18:49:45.292287 17579 solver.cpp:219] Iteration 20200 (0.39909 iter/s, 125.285s/50 iters), loss = 0.0028513
I0621 18:49:45.292440 17579 solver.cpp:238]     Train net output #0: loss = 0.00138869 (* 1 = 0.00138869 loss)
I0621 18:49:45.292470 17579 sgd_solver.cpp:105] Iteration 20200, lr = 0.0005
I0621 18:51:50.868263 17579 solver.cpp:219] Iteration 20250 (0.398173 iter/s, 125.574s/50 iters), loss = 0.00326359
I0621 18:51:50.868409 17579 solver.cpp:238]     Train net output #0: loss = 0.00299288 (* 1 = 0.00299288 loss)
I0621 18:51:50.868438 17579 sgd_solver.cpp:105] Iteration 20250, lr = 0.0005
I0621 18:53:55.820086 17579 solver.cpp:219] Iteration 20300 (0.400162 iter/s, 124.949s/50 iters), loss = 0.00294951
I0621 18:53:55.820227 17579 solver.cpp:238]     Train net output #0: loss = 0.00306219 (* 1 = 0.00306219 loss)
I0621 18:53:55.820255 17579 sgd_solver.cpp:105] Iteration 20300, lr = 0.0005
I0621 18:56:01.419143 17579 solver.cpp:219] Iteration 20350 (0.3981 iter/s, 125.597s/50 iters), loss = 0.00182812
I0621 18:56:01.419301 17579 solver.cpp:238]     Train net output #0: loss = 0.00180889 (* 1 = 0.00180889 loss)
I0621 18:56:01.419343 17579 sgd_solver.cpp:105] Iteration 20350, lr = 0.0005
I0621 18:58:06.592308 17579 solver.cpp:219] Iteration 20400 (0.399454 iter/s, 125.171s/50 iters), loss = 0.00179884
I0621 18:58:06.592464 17579 solver.cpp:238]     Train net output #0: loss = 0.00160998 (* 1 = 0.00160998 loss)
I0621 18:58:06.592491 17579 sgd_solver.cpp:105] Iteration 20400, lr = 0.0005
I0621 19:00:12.197190 17579 solver.cpp:219] Iteration 20450 (0.398081 iter/s, 125.602s/50 iters), loss = 0.00158097
I0621 19:00:12.197325 17579 solver.cpp:238]     Train net output #0: loss = 0.00259568 (* 1 = 0.00259568 loss)
I0621 19:00:12.197352 17579 sgd_solver.cpp:105] Iteration 20450, lr = 0.0005
I0621 19:02:14.875270 17579 solver.cpp:331] Iteration 20500, Testing net (#0)
I0621 19:02:30.135699 17579 solver.cpp:398]     Test net output #0: accuracy = 0.980392
I0621 19:02:30.135778 17579 solver.cpp:398]     Test net output #1: loss = 0.0829449 (* 1 = 0.0829449 loss)
I0621 19:02:32.644826 17579 solver.cpp:219] Iteration 20500 (0.356011 iter/s, 140.445s/50 iters), loss = 0.00157421
I0621 19:02:32.644925 17579 solver.cpp:238]     Train net output #0: loss = 0.00165557 (* 1 = 0.00165557 loss)
I0621 19:02:32.644956 17579 sgd_solver.cpp:105] Iteration 20500, lr = 0.0005
I0621 19:04:37.572630 17579 solver.cpp:219] Iteration 20550 (0.400239 iter/s, 124.925s/50 iters), loss = 0.00158206
I0621 19:04:37.572782 17579 solver.cpp:238]     Train net output #0: loss = 0.00161679 (* 1 = 0.00161679 loss)
I0621 19:04:37.572809 17579 sgd_solver.cpp:105] Iteration 20550, lr = 0.0005
I0621 19:06:43.185528 17579 solver.cpp:219] Iteration 20600 (0.398055 iter/s, 125.611s/50 iters), loss = 0.0020838
I0621 19:06:43.185734 17579 solver.cpp:238]     Train net output #0: loss = 0.0037747 (* 1 = 0.0037747 loss)
I0621 19:06:43.185765 17579 sgd_solver.cpp:105] Iteration 20600, lr = 0.0005
I0621 19:08:48.385821 17579 solver.cpp:219] Iteration 20650 (0.399368 iter/s, 125.198s/50 iters), loss = 0.00144967
I0621 19:08:48.386168 17579 solver.cpp:238]     Train net output #0: loss = 0.00294542 (* 1 = 0.00294542 loss)
I0621 19:08:48.386198 17579 sgd_solver.cpp:105] Iteration 20650, lr = 0.0005
I0621 19:10:54.172792 17579 solver.cpp:219] Iteration 20700 (0.397505 iter/s, 125.785s/50 iters), loss = 0.00181774
I0621 19:10:54.172938 17579 solver.cpp:238]     Train net output #0: loss = 0.000970516 (* 1 = 0.000970516 loss)
I0621 19:10:54.172966 17579 sgd_solver.cpp:105] Iteration 20700, lr = 0.0005
I0621 19:12:59.519429 17579 solver.cpp:219] Iteration 20750 (0.398902 iter/s, 125.344s/50 iters), loss = 0.00160809
I0621 19:12:59.519584 17579 solver.cpp:238]     Train net output #0: loss = 0.00172116 (* 1 = 0.00172116 loss)
I0621 19:12:59.519613 17579 sgd_solver.cpp:105] Iteration 20750, lr = 0.0005
I0621 19:15:05.250674 17579 solver.cpp:219] Iteration 20800 (0.397678 iter/s, 125.73s/50 iters), loss = 0.00210961
I0621 19:15:05.250814 17579 solver.cpp:238]     Train net output #0: loss = 0.00252454 (* 1 = 0.00252454 loss)
I0621 19:15:05.250841 17579 sgd_solver.cpp:105] Iteration 20800, lr = 0.0005
I0621 19:16:35.393669 17579 solver.cpp:219] Iteration 20850 (0.554687 iter/s, 90.1409s/50 iters), loss = 0.00211952
I0621 19:16:35.393828 17579 solver.cpp:238]     Train net output #0: loss = 0.00123615 (* 1 = 0.00123615 loss)
I0621 19:16:35.393862 17579 sgd_solver.cpp:105] Iteration 20850, lr = 0.0005
I0621 19:17:46.159934 17579 solver.cpp:219] Iteration 20900 (0.706561 iter/s, 70.7653s/50 iters), loss = 0.00216348
I0621 19:17:46.160058 17579 solver.cpp:238]     Train net output #0: loss = 0.0020053 (* 1 = 0.0020053 loss)
I0621 19:17:46.160086 17579 sgd_solver.cpp:105] Iteration 20900, lr = 0.0005
I0621 19:18:56.924227 17579 solver.cpp:219] Iteration 20950 (0.70658 iter/s, 70.7634s/50 iters), loss = 0.0016224
I0621 19:18:56.924360 17579 solver.cpp:238]     Train net output #0: loss = 0.00120028 (* 1 = 0.00120028 loss)
I0621 19:18:56.924387 17579 sgd_solver.cpp:105] Iteration 20950, lr = 0.0005
I0621 19:20:06.283730 17579 solver.cpp:331] Iteration 21000, Testing net (#0)
I0621 19:20:18.244585 17579 solver.cpp:398]     Test net output #0: accuracy = 0.980392
I0621 19:20:18.244663 17579 solver.cpp:398]     Test net output #1: loss = 0.0827621 (* 1 = 0.0827621 loss)
I0621 19:20:18.252764 17579 compress_conv_layer.cu:174] 0.647859 1.83542e-10 0.943437
I0621 19:20:18.260781 17579 compress_conv_layer.cu:174] 0.647859 1.11941e-10 0.551947
I0621 19:20:18.269067 17579 compress_conv_layer.cu:174] 0.647859 2.01138e-11 0.739633
I0621 19:20:18.277361 17579 compress_conv_layer.cu:174] 0.647859 3.06309e-12 0.780221
I0621 19:20:18.290185 17579 compress_conv_layer.cu:174] 0.647859 9.78322e-12 0.455466
I0621 19:20:18.312583 17579 compress_conv_layer.cu:174] 0.647859 9.38472e-14 0.481533
I0621 19:20:18.356503 17579 compress_conv_layer.cu:174] 0.647859 1.70436e-13 0.473746
I0621 19:20:18.400614 17579 compress_conv_layer.cu:174] 0.647859 2.17046e-12 0.402747
I0621 19:20:18.444489 17579 compress_conv_layer.cu:174] 0.647859 1.88618e-12 0.428024
I0621 19:20:18.487332 17579 compress_conv_layer.cu:174] 0.647859 1.98259e-12 0.573231
I0621 19:20:18.530426 17579 compress_conv_layer.cu:174] 0.647859 5.45939e-12 0.454732
I0621 19:20:18.618015 17579 compress_conv_layer.cu:174] 0.647859 1.63306e-12 0.326009
I0621 19:20:18.802018 17579 compress_conv_layer.cu:174] 0.647859 3.36383e-12 0.291214
I0621 19:20:18.820286 17579 compress_conv_layer.cu:174] 0.647859 3.12746e-07 0.190066
I0621 19:20:19.058643 17579 compress_conv_layer.cu:174] 0.647859 1.83542e-10 0.943437
I0621 19:20:19.066601 17579 compress_conv_layer.cu:174] 0.647859 1.11941e-10 0.551947
I0621 19:20:19.074869 17579 compress_conv_layer.cu:174] 0.647859 2.01138e-11 0.739633
I0621 19:20:19.082973 17579 compress_conv_layer.cu:174] 0.647859 3.06309e-12 0.780221
I0621 19:20:19.095484 17579 compress_conv_layer.cu:174] 0.647859 9.78322e-12 0.455466
I0621 19:20:19.117065 17579 compress_conv_layer.cu:174] 0.647859 9.38472e-14 0.481533
I0621 19:20:19.159335 17579 compress_conv_layer.cu:174] 0.647859 1.70436e-13 0.473746
I0621 19:20:19.202167 17579 compress_conv_layer.cu:174] 0.647859 2.17046e-12 0.402747
I0621 19:20:19.245126 17579 compress_conv_layer.cu:174] 0.647859 1.88618e-12 0.428024
I0621 19:20:19.287820 17579 compress_conv_layer.cu:174] 0.647859 1.98259e-12 0.573231
I0621 19:20:19.331282 17579 compress_conv_layer.cu:174] 0.647859 5.45939e-12 0.454732
I0621 19:20:19.417767 17579 compress_conv_layer.cu:174] 0.647859 1.63306e-12 0.326009
I0621 19:20:19.599072 17579 compress_conv_layer.cu:174] 0.647859 3.36383e-12 0.291214
I0621 19:20:19.617317 17579 compress_conv_layer.cu:174] 0.647859 3.12746e-07 0.190066
I0621 19:20:19.855581 17579 compress_conv_layer.cu:174] 0.647859 1.83542e-10 0.943437
I0621 19:20:19.863510 17579 compress_conv_layer.cu:174] 0.647859 1.11941e-10 0.551947
I0621 19:20:19.871767 17579 compress_conv_layer.cu:174] 0.647859 2.01138e-11 0.739633
I0621 19:20:19.879884 17579 compress_conv_layer.cu:174] 0.647859 3.06309e-12 0.780221
I0621 19:20:19.892403 17579 compress_conv_layer.cu:174] 0.647859 9.78322e-12 0.455466
I0621 19:20:19.914028 17579 compress_conv_layer.cu:174] 0.647859 9.38472e-14 0.481533
I0621 19:20:19.956344 17579 compress_conv_layer.cu:174] 0.647859 1.70436e-13 0.473746
I0621 19:20:19.999181 17579 compress_conv_layer.cu:174] 0.647859 2.17046e-12 0.402747
I0621 19:20:20.042466 17579 compress_conv_layer.cu:174] 0.647859 1.88618e-12 0.428024
I0621 19:20:20.085448 17579 compress_conv_layer.cu:174] 0.647859 1.98259e-12 0.573231
I0621 19:20:20.128813 17579 compress_conv_layer.cu:174] 0.647859 5.45939e-12 0.454732
I0621 19:20:20.215378 17579 compress_conv_layer.cu:174] 0.647859 1.63306e-12 0.326009
I0621 19:20:20.396865 17579 compress_conv_layer.cu:174] 0.647859 3.36383e-12 0.291214
I0621 19:20:20.415191 17579 compress_conv_layer.cu:174] 0.647859 3.12746e-07 0.190066
I0621 19:20:20.653448 17579 compress_conv_layer.cu:174] 0.647859 1.83542e-10 0.943437
I0621 19:20:20.661444 17579 compress_conv_layer.cu:174] 0.647859 1.11941e-10 0.551947
I0621 19:20:20.669689 17579 compress_conv_layer.cu:174] 0.647859 2.01138e-11 0.739633
I0621 19:20:20.677841 17579 compress_conv_layer.cu:174] 0.647859 3.06309e-12 0.780221
I0621 19:20:20.690388 17579 compress_conv_layer.cu:174] 0.647859 9.78322e-12 0.455466
I0621 19:20:20.711973 17579 compress_conv_layer.cu:174] 0.647859 9.38472e-14 0.481533
I0621 19:20:20.754277 17579 compress_conv_layer.cu:174] 0.647859 1.70436e-13 0.473746
I0621 19:20:20.797463 17579 compress_conv_layer.cu:174] 0.647859 2.17046e-12 0.402747
I0621 19:20:20.841222 17579 compress_conv_layer.cu:174] 0.647859 1.88618e-12 0.428024
I0621 19:20:20.884426 17579 compress_conv_layer.cu:174] 0.647859 1.98259e-12 0.573231
I0621 19:20:20.927532 17579 compress_conv_layer.cu:174] 0.647859 5.45939e-12 0.454732
I0621 19:20:21.013694 17579 compress_conv_layer.cu:174] 0.647859 1.63306e-12 0.326009
I0621 19:20:21.194882 17579 compress_conv_layer.cu:174] 0.647859 3.36383e-12 0.291214
I0621 19:20:21.213140 17579 compress_conv_layer.cu:174] 0.647859 3.12746e-07 0.190066
I0621 19:20:21.451315 17579 compress_conv_layer.cu:174] 0.647859 1.83542e-10 0.943437
I0621 19:20:21.459291 17579 compress_conv_layer.cu:174] 0.647859 1.11941e-10 0.551947
I0621 19:20:21.467528 17579 compress_conv_layer.cu:174] 0.647859 2.01138e-11 0.739633
I0621 19:20:21.475656 17579 compress_conv_layer.cu:174] 0.647859 3.06309e-12 0.780221
I0621 19:20:21.488173 17579 compress_conv_layer.cu:174] 0.647859 9.78322e-12 0.455466
I0621 19:20:21.509764 17579 compress_conv_layer.cu:174] 0.647859 9.38472e-14 0.481533
I0621 19:20:21.552111 17579 compress_conv_layer.cu:174] 0.647859 1.70436e-13 0.473746
I0621 19:20:21.594890 17579 compress_conv_layer.cu:174] 0.647859 2.17046e-12 0.402747
I0621 19:20:21.638057 17579 compress_conv_layer.cu:174] 0.647859 1.88618e-12 0.428024
I0621 19:20:21.680549 17579 compress_conv_layer.cu:174] 0.647859 1.98259e-12 0.573231
I0621 19:20:21.723588 17579 compress_conv_layer.cu:174] 0.647859 5.45939e-12 0.454732
I0621 19:20:21.809833 17579 compress_conv_layer.cu:174] 0.647859 1.63306e-12 0.326009
I0621 19:20:21.991289 17579 compress_conv_layer.cu:174] 0.647859 3.36383e-12 0.291214
I0621 19:20:22.009519 17579 compress_conv_layer.cu:174] 0.647859 3.12746e-07 0.190066
I0621 19:20:22.239765 17579 solver.cpp:219] Iteration 21000 (0.586067 iter/s, 85.3145s/50 iters), loss = 0.00279585
I0621 19:20:22.239825 17579 solver.cpp:238]     Train net output #0: loss = 0.00106559 (* 1 = 0.00106559 loss)
I0621 19:20:22.239850 17579 sgd_solver.cpp:105] Iteration 21000, lr = 0.0005
I0621 19:21:33.001711 17579 solver.cpp:219] Iteration 21050 (0.706603 iter/s, 70.7611s/50 iters), loss = 0.00415932
I0621 19:21:33.001933 17579 solver.cpp:238]     Train net output #0: loss = 0.00367652 (* 1 = 0.00367652 loss)
I0621 19:21:33.001962 17579 sgd_solver.cpp:105] Iteration 21050, lr = 0.0005
I0621 19:22:43.770879 17579 solver.cpp:219] Iteration 21100 (0.706532 iter/s, 70.7682s/50 iters), loss = 0.00289759
I0621 19:22:43.771041 17579 solver.cpp:238]     Train net output #0: loss = 0.0031124 (* 1 = 0.0031124 loss)
I0621 19:22:43.771070 17579 sgd_solver.cpp:105] Iteration 21100, lr = 0.0005
I0621 19:23:54.579977 17579 solver.cpp:219] Iteration 21150 (0.706134 iter/s, 70.8081s/50 iters), loss = 0.00439248
I0621 19:23:54.580163 17579 solver.cpp:238]     Train net output #0: loss = 0.0023303 (* 1 = 0.0023303 loss)
I0621 19:23:54.580190 17579 sgd_solver.cpp:105] Iteration 21150, lr = 0.0005
I0621 19:25:05.359730 17579 solver.cpp:219] Iteration 21200 (0.706427 iter/s, 70.7788s/50 iters), loss = 0.00336274
I0621 19:25:05.360137 17579 solver.cpp:238]     Train net output #0: loss = 0.00360061 (* 1 = 0.00360061 loss)
I0621 19:25:05.360165 17579 sgd_solver.cpp:105] Iteration 21200, lr = 0.0005
I0621 19:26:16.150338 17579 solver.cpp:219] Iteration 21250 (0.70632 iter/s, 70.7894s/50 iters), loss = 0.00264217
I0621 19:26:16.150480 17579 solver.cpp:238]     Train net output #0: loss = 0.0024371 (* 1 = 0.0024371 loss)
I0621 19:26:16.150507 17579 sgd_solver.cpp:105] Iteration 21250, lr = 0.0005
I0621 19:27:26.919394 17579 solver.cpp:219] Iteration 21300 (0.706533 iter/s, 70.7681s/50 iters), loss = 0.00346489
I0621 19:27:26.919554 17579 solver.cpp:238]     Train net output #0: loss = 0.0025555 (* 1 = 0.0025555 loss)
I0621 19:27:26.919597 17579 sgd_solver.cpp:105] Iteration 21300, lr = 0.0005
I0621 19:28:37.686787 17579 solver.cpp:219] Iteration 21350 (0.70655 iter/s, 70.7664s/50 iters), loss = 0.00383317
I0621 19:28:37.686991 17579 solver.cpp:238]     Train net output #0: loss = 0.0030558 (* 1 = 0.0030558 loss)
I0621 19:28:37.687021 17579 sgd_solver.cpp:105] Iteration 21350, lr = 0.0005
I0621 19:29:48.458689 17579 solver.cpp:219] Iteration 21400 (0.706505 iter/s, 70.7709s/50 iters), loss = 0.00360919
I0621 19:29:48.458842 17579 solver.cpp:238]     Train net output #0: loss = 0.00718901 (* 1 = 0.00718901 loss)
I0621 19:29:48.458871 17579 sgd_solver.cpp:105] Iteration 21400, lr = 0.0005
I0621 19:30:59.240188 17579 solver.cpp:219] Iteration 21450 (0.706409 iter/s, 70.7805s/50 iters), loss = 0.00634913
I0621 19:30:59.246562 17579 solver.cpp:238]     Train net output #0: loss = 0.0111161 (* 1 = 0.0111161 loss)
I0621 19:30:59.246593 17579 sgd_solver.cpp:105] Iteration 21450, lr = 0.0005
I0621 19:32:08.605969 17579 solver.cpp:331] Iteration 21500, Testing net (#0)
I0621 19:32:20.563046 17579 solver.cpp:398]     Test net output #0: accuracy = 0.985294
I0621 19:32:20.563124 17579 solver.cpp:398]     Test net output #1: loss = 0.0812307 (* 1 = 0.0812307 loss)
I0621 19:32:21.973196 17579 solver.cpp:219] Iteration 21500 (0.604407 iter/s, 82.7257s/50 iters), loss = 0.00323495
I0621 19:32:21.973291 17579 solver.cpp:238]     Train net output #0: loss = 0.00640772 (* 1 = 0.00640772 loss)
I0621 19:32:21.973317 17579 sgd_solver.cpp:105] Iteration 21500, lr = 0.0005
I0621 19:33:32.738795 17579 solver.cpp:219] Iteration 21550 (0.706567 iter/s, 70.7647s/50 iters), loss = 0.00559016
I0621 19:33:32.738987 17579 solver.cpp:238]     Train net output #0: loss = 0.00116701 (* 1 = 0.00116701 loss)
I0621 19:33:32.739017 17579 sgd_solver.cpp:105] Iteration 21550, lr = 0.0005
I0621 19:34:43.517195 17579 solver.cpp:219] Iteration 21600 (0.70644 iter/s, 70.7774s/50 iters), loss = 0.00315259
I0621 19:34:43.517498 17579 solver.cpp:238]     Train net output #0: loss = 0.00196881 (* 1 = 0.00196881 loss)
I0621 19:34:43.517534 17579 sgd_solver.cpp:105] Iteration 21600, lr = 0.0005
I0621 19:35:54.295955 17579 solver.cpp:219] Iteration 21650 (0.706438 iter/s, 70.7777s/50 iters), loss = 0.00141882
I0621 19:35:54.296128 17579 solver.cpp:238]     Train net output #0: loss = 0.000830133 (* 1 = 0.000830133 loss)
I0621 19:35:54.296157 17579 sgd_solver.cpp:105] Iteration 21650, lr = 0.0005
I0621 19:37:05.085389 17579 solver.cpp:219] Iteration 21700 (0.70633 iter/s, 70.7885s/50 iters), loss = 0.00591848
I0621 19:37:05.085530 17579 solver.cpp:238]     Train net output #0: loss = 0.00394612 (* 1 = 0.00394612 loss)
I0621 19:37:05.085561 17579 sgd_solver.cpp:105] Iteration 21700, lr = 0.0005
I0621 19:38:15.860250 17579 solver.cpp:219] Iteration 21750 (0.706475 iter/s, 70.7739s/50 iters), loss = 0.00328496
I0621 19:38:15.860391 17579 solver.cpp:238]     Train net output #0: loss = 0.00249663 (* 1 = 0.00249663 loss)
I0621 19:38:15.860420 17579 sgd_solver.cpp:105] Iteration 21750, lr = 0.0005
I0621 19:39:26.634076 17579 solver.cpp:219] Iteration 21800 (0.706485 iter/s, 70.7729s/50 iters), loss = 0.00278301
I0621 19:39:26.634207 17579 solver.cpp:238]     Train net output #0: loss = 0.00616137 (* 1 = 0.00616137 loss)
I0621 19:39:26.634234 17579 sgd_solver.cpp:105] Iteration 21800, lr = 0.0005
I0621 19:40:37.412400 17579 solver.cpp:219] Iteration 21850 (0.70644 iter/s, 70.7774s/50 iters), loss = 0.00493426
I0621 19:40:37.412587 17579 solver.cpp:238]     Train net output #0: loss = 0.00294993 (* 1 = 0.00294993 loss)
I0621 19:40:37.412618 17579 sgd_solver.cpp:105] Iteration 21850, lr = 0.0005
I0621 19:41:48.198920 17579 solver.cpp:219] Iteration 21900 (0.706359 iter/s, 70.7855s/50 iters), loss = 0.00362227
I0621 19:41:48.199080 17579 solver.cpp:238]     Train net output #0: loss = 0.00338037 (* 1 = 0.00338037 loss)
I0621 19:41:48.199110 17579 sgd_solver.cpp:105] Iteration 21900, lr = 0.0005
I0621 19:42:58.983117 17579 solver.cpp:219] Iteration 21950 (0.706382 iter/s, 70.7832s/50 iters), loss = 0.00287797
I0621 19:42:58.983330 17579 solver.cpp:238]     Train net output #0: loss = 0.00186551 (* 1 = 0.00186551 loss)
I0621 19:42:58.983361 17579 sgd_solver.cpp:105] Iteration 21950, lr = 0.0005
I0621 19:44:08.352530 17579 solver.cpp:331] Iteration 22000, Testing net (#0)
I0621 19:44:20.334843 17579 solver.cpp:398]     Test net output #0: accuracy = 0.981373
I0621 19:44:20.334923 17579 solver.cpp:398]     Test net output #1: loss = 0.0831238 (* 1 = 0.0831238 loss)
I0621 19:44:21.746264 17579 solver.cpp:219] Iteration 22000 (0.604142 iter/s, 82.762s/50 iters), loss = 0.00307839
I0621 19:44:21.746387 17579 solver.cpp:238]     Train net output #0: loss = 0.00333359 (* 1 = 0.00333359 loss)
I0621 19:44:21.746417 17579 sgd_solver.cpp:105] Iteration 22000, lr = 0.0005
I0621 19:45:32.527719 17579 solver.cpp:219] Iteration 22050 (0.706409 iter/s, 70.7805s/50 iters), loss = 0.00323709
I0621 19:45:32.527868 17579 solver.cpp:238]     Train net output #0: loss = 0.00356892 (* 1 = 0.00356892 loss)
I0621 19:45:32.527896 17579 sgd_solver.cpp:105] Iteration 22050, lr = 0.0005
I0621 19:47:18.145562 17579 solver.cpp:219] Iteration 22100 (0.473411 iter/s, 105.617s/50 iters), loss = 0.00284356
I0621 19:47:18.145710 17579 solver.cpp:238]     Train net output #0: loss = 0.00146544 (* 1 = 0.00146544 loss)
I0621 19:47:18.145738 17579 sgd_solver.cpp:105] Iteration 22100, lr = 0.0005
I0621 19:48:28.924650 17579 solver.cpp:219] Iteration 22150 (0.706433 iter/s, 70.7781s/50 iters), loss = 0.00306514
I0621 19:48:28.924799 17579 solver.cpp:238]     Train net output #0: loss = 0.0031122 (* 1 = 0.0031122 loss)
I0621 19:48:28.924829 17579 sgd_solver.cpp:105] Iteration 22150, lr = 0.0005
I0621 19:49:45.464447 17579 solver.cpp:219] Iteration 22200 (0.653264 iter/s, 76.5388s/50 iters), loss = 0.00559012
I0621 19:49:45.464620 17579 solver.cpp:238]     Train net output #0: loss = 0.00387415 (* 1 = 0.00387415 loss)
I0621 19:49:45.464653 17579 sgd_solver.cpp:105] Iteration 22200, lr = 0.0005
I0621 19:52:06.678392 17579 solver.cpp:219] Iteration 22250 (0.35408 iter/s, 141.211s/50 iters), loss = 0.00265153
I0621 19:52:06.678619 17579 solver.cpp:238]     Train net output #0: loss = 0.00284646 (* 1 = 0.00284646 loss)
I0621 19:52:06.678649 17579 sgd_solver.cpp:105] Iteration 22250, lr = 0.0005
I0621 19:54:11.308612 17579 solver.cpp:219] Iteration 22300 (0.401192 iter/s, 124.629s/50 iters), loss = 0.00150106
I0621 19:54:11.308763 17579 solver.cpp:238]     Train net output #0: loss = 0.00211327 (* 1 = 0.00211327 loss)
I0621 19:54:11.308791 17579 sgd_solver.cpp:105] Iteration 22300, lr = 0.0005
I0621 19:56:39.190359 17579 solver.cpp:219] Iteration 22350 (0.338115 iter/s, 147.879s/50 iters), loss = 0.0024477
I0621 19:56:39.190495 17579 solver.cpp:238]     Train net output #0: loss = 0.00222933 (* 1 = 0.00222933 loss)
I0621 19:56:39.190529 17579 sgd_solver.cpp:105] Iteration 22350, lr = 0.0005
I0621 19:59:06.973448 17579 solver.cpp:219] Iteration 22400 (0.338341 iter/s, 147.78s/50 iters), loss = 0.00291711
I0621 19:59:06.973578 17579 solver.cpp:238]     Train net output #0: loss = 0.00188825 (* 1 = 0.00188825 loss)
I0621 19:59:06.973608 17579 sgd_solver.cpp:105] Iteration 22400, lr = 0.0005
I0621 20:01:34.841460 17579 solver.cpp:219] Iteration 22450 (0.338147 iter/s, 147.865s/50 iters), loss = 0.00227043
I0621 20:01:34.841622 17579 solver.cpp:238]     Train net output #0: loss = 0.00265398 (* 1 = 0.00265398 loss)
I0621 20:01:34.841652 17579 sgd_solver.cpp:105] Iteration 22450, lr = 0.0005
I0621 20:03:59.882087 17579 solver.cpp:331] Iteration 22500, Testing net (#0)
I0621 20:04:16.410442 17579 solver.cpp:398]     Test net output #0: accuracy = 0.982353
I0621 20:04:16.410532 17579 solver.cpp:398]     Test net output #1: loss = 0.0807306 (* 1 = 0.0807306 loss)
I0621 20:04:16.427767 17579 compress_conv_layer.cu:174] 0.662025 1.8348e-10 0.943074
I0621 20:04:16.443159 17579 compress_conv_layer.cu:174] 0.662025 1.11899e-10 0.551695
I0621 20:04:16.457443 17579 compress_conv_layer.cu:174] 0.662025 2.0106e-11 0.73934
I0621 20:04:16.471093 17579 compress_conv_layer.cu:174] 0.662025 3.06179e-12 0.779835
I0621 20:04:16.487735 17579 compress_conv_layer.cu:174] 0.662025 9.77932e-12 0.455303
I0621 20:04:16.513969 17579 compress_conv_layer.cu:174] 0.662025 9.38167e-14 0.481324
I0621 20:04:16.560844 17579 compress_conv_layer.cu:174] 0.662025 1.70375e-13 0.473573
I0621 20:04:16.608450 17579 compress_conv_layer.cu:174] 0.662025 2.16948e-12 0.402582
I0621 20:04:16.655709 17579 compress_conv_layer.cu:174] 0.662025 1.88553e-12 0.427846
I0621 20:04:16.701622 17579 compress_conv_layer.cu:174] 0.662025 1.98194e-12 0.573016
I0621 20:04:16.749516 17579 compress_conv_layer.cu:174] 0.662025 5.45744e-12 0.454545
I0621 20:04:16.841855 17579 compress_conv_layer.cu:174] 0.662025 1.63241e-12 0.325876
I0621 20:04:17.029904 17579 compress_conv_layer.cu:174] 0.662025 3.36253e-12 0.291099
I0621 20:04:17.051707 17579 compress_conv_layer.cu:174] 0.662025 3.12618e-07 0.190222
I0621 20:04:17.549739 17579 compress_conv_layer.cu:174] 0.662025 1.8348e-10 0.943074
I0621 20:04:17.567589 17579 compress_conv_layer.cu:174] 0.662025 1.11899e-10 0.551695
I0621 20:04:17.582118 17579 compress_conv_layer.cu:174] 0.662025 2.0106e-11 0.73934
I0621 20:04:17.593742 17579 compress_conv_layer.cu:174] 0.662025 3.06179e-12 0.779835
I0621 20:04:17.608638 17579 compress_conv_layer.cu:174] 0.662025 9.77932e-12 0.455303
I0621 20:04:17.633687 17579 compress_conv_layer.cu:174] 0.662025 9.38167e-14 0.481324
I0621 20:04:17.680272 17579 compress_conv_layer.cu:174] 0.662025 1.70375e-13 0.473573
I0621 20:04:17.727378 17579 compress_conv_layer.cu:174] 0.662025 2.16948e-12 0.402582
I0621 20:04:17.773682 17579 compress_conv_layer.cu:174] 0.662025 1.88553e-12 0.427846
I0621 20:04:17.818423 17579 compress_conv_layer.cu:174] 0.662025 1.98194e-12 0.573016
I0621 20:04:17.863526 17579 compress_conv_layer.cu:174] 0.662025 5.45744e-12 0.454545
I0621 20:04:17.953919 17579 compress_conv_layer.cu:174] 0.662025 1.63241e-12 0.325876
I0621 20:04:18.141106 17579 compress_conv_layer.cu:174] 0.662025 3.36253e-12 0.291099
I0621 20:04:18.161640 17579 compress_conv_layer.cu:174] 0.662025 3.12618e-07 0.190222
I0621 20:04:18.659603 17579 compress_conv_layer.cu:174] 0.662025 1.8348e-10 0.943074
I0621 20:04:18.678021 17579 compress_conv_layer.cu:174] 0.662025 1.11899e-10 0.551695
I0621 20:04:18.692752 17579 compress_conv_layer.cu:174] 0.662025 2.0106e-11 0.73934
I0621 20:04:18.704450 17579 compress_conv_layer.cu:174] 0.662025 3.06179e-12 0.779835
I0621 20:04:18.722546 17579 compress_conv_layer.cu:174] 0.662025 9.77932e-12 0.455303
I0621 20:04:18.748307 17579 compress_conv_layer.cu:174] 0.662025 9.38167e-14 0.481324
I0621 20:04:18.792536 17579 compress_conv_layer.cu:174] 0.662025 1.70375e-13 0.473573
I0621 20:04:18.839007 17579 compress_conv_layer.cu:174] 0.662025 2.16948e-12 0.402582
I0621 20:04:18.887303 17579 compress_conv_layer.cu:174] 0.662025 1.88553e-12 0.427846
I0621 20:04:18.933159 17579 compress_conv_layer.cu:174] 0.662025 1.98194e-12 0.573016
I0621 20:04:18.980389 17579 compress_conv_layer.cu:174] 0.662025 5.45744e-12 0.454545
I0621 20:04:19.069633 17579 compress_conv_layer.cu:174] 0.662025 1.63241e-12 0.325876
I0621 20:04:19.252828 17579 compress_conv_layer.cu:174] 0.662025 3.36253e-12 0.291099
I0621 20:04:19.274760 17579 compress_conv_layer.cu:174] 0.662025 3.12618e-07 0.190222
I0621 20:04:19.733600 17579 compress_conv_layer.cu:174] 0.662025 1.8348e-10 0.943074
I0621 20:04:19.749696 17579 compress_conv_layer.cu:174] 0.662025 1.11899e-10 0.551695
I0621 20:04:19.763478 17579 compress_conv_layer.cu:174] 0.662025 2.0106e-11 0.73934
I0621 20:04:19.775982 17579 compress_conv_layer.cu:174] 0.662025 3.06179e-12 0.779835
I0621 20:04:19.790908 17579 compress_conv_layer.cu:174] 0.662025 9.77932e-12 0.455303
I0621 20:04:19.816845 17579 compress_conv_layer.cu:174] 0.662025 9.38167e-14 0.481324
I0621 20:04:19.861652 17579 compress_conv_layer.cu:174] 0.662025 1.70375e-13 0.473573
I0621 20:04:19.907552 17579 compress_conv_layer.cu:174] 0.662025 2.16948e-12 0.402582
I0621 20:04:19.955245 17579 compress_conv_layer.cu:174] 0.662025 1.88553e-12 0.427846
I0621 20:04:20.002684 17579 compress_conv_layer.cu:174] 0.662025 1.98194e-12 0.573016
I0621 20:04:20.049866 17579 compress_conv_layer.cu:174] 0.662025 5.45744e-12 0.454545
I0621 20:04:20.139535 17579 compress_conv_layer.cu:174] 0.662025 1.63241e-12 0.325876
I0621 20:04:20.334249 17579 compress_conv_layer.cu:174] 0.662025 3.36253e-12 0.291099
I0621 20:04:20.354907 17579 compress_conv_layer.cu:174] 0.662025 3.12618e-07 0.190222
I0621 20:04:20.851004 17579 compress_conv_layer.cu:174] 0.662025 1.8348e-10 0.943074
I0621 20:04:20.870249 17579 compress_conv_layer.cu:174] 0.662025 1.11899e-10 0.551695
I0621 20:04:20.883539 17579 compress_conv_layer.cu:174] 0.662025 2.0106e-11 0.73934
I0621 20:04:20.895148 17579 compress_conv_layer.cu:174] 0.662025 3.06179e-12 0.779835
I0621 20:04:20.910107 17579 compress_conv_layer.cu:174] 0.662025 9.77932e-12 0.455303
I0621 20:04:20.936105 17579 compress_conv_layer.cu:174] 0.662025 9.38167e-14 0.481324
I0621 20:04:20.981719 17579 compress_conv_layer.cu:174] 0.662025 1.70375e-13 0.473573
I0621 20:04:21.030297 17579 compress_conv_layer.cu:174] 0.662025 2.16948e-12 0.402582
I0621 20:04:21.076753 17579 compress_conv_layer.cu:174] 0.662025 1.88553e-12 0.427846
I0621 20:04:21.124328 17579 compress_conv_layer.cu:174] 0.662025 1.98194e-12 0.573016
I0621 20:04:21.170894 17579 compress_conv_layer.cu:174] 0.662025 5.45744e-12 0.454545
I0621 20:04:21.259304 17579 compress_conv_layer.cu:174] 0.662025 1.63241e-12 0.325876
I0621 20:04:21.444278 17579 compress_conv_layer.cu:174] 0.662025 3.36253e-12 0.291099
I0621 20:04:21.464771 17579 compress_conv_layer.cu:174] 0.662025 3.12618e-07 0.190222
I0621 20:04:21.943053 17579 solver.cpp:219] Iteration 22500 (0.299224 iter/s, 167.099s/50 iters), loss = 0.00404979
I0621 20:04:21.943140 17579 solver.cpp:238]     Train net output #0: loss = 0.00518893 (* 1 = 0.00518893 loss)
I0621 20:04:21.943167 17579 sgd_solver.cpp:105] Iteration 22500, lr = 0.0005
I0621 20:06:49.852871 17579 solver.cpp:219] Iteration 22550 (0.33805 iter/s, 147.907s/50 iters), loss = 0.0043291
I0621 20:06:49.853160 17579 solver.cpp:238]     Train net output #0: loss = 0.00663439 (* 1 = 0.00663439 loss)
I0621 20:06:49.853189 17579 sgd_solver.cpp:105] Iteration 22550, lr = 0.0005
I0621 20:09:17.855562 17579 solver.cpp:219] Iteration 22600 (0.337838 iter/s, 148s/50 iters), loss = 0.0033944
I0621 20:09:17.855717 17579 solver.cpp:238]     Train net output #0: loss = 0.00352898 (* 1 = 0.00352898 loss)
I0621 20:09:17.855746 17579 sgd_solver.cpp:105] Iteration 22600, lr = 0.0005
I0621 20:11:45.739907 17579 solver.cpp:219] Iteration 22650 (0.338108 iter/s, 147.882s/50 iters), loss = 0.00543115
I0621 20:11:45.740077 17579 solver.cpp:238]     Train net output #0: loss = 0.00524344 (* 1 = 0.00524344 loss)
I0621 20:11:45.740109 17579 sgd_solver.cpp:105] Iteration 22650, lr = 0.0005
I0621 20:14:13.696019 17579 solver.cpp:219] Iteration 22700 (0.337949 iter/s, 147.951s/50 iters), loss = 0.00364214
I0621 20:14:13.696177 17579 solver.cpp:238]     Train net output #0: loss = 0.0060067 (* 1 = 0.0060067 loss)
I0621 20:14:13.696207 17579 sgd_solver.cpp:105] Iteration 22700, lr = 0.0005
I0621 20:16:31.818752 17579 solver.cpp:219] Iteration 22750 (0.362004 iter/s, 138.12s/50 iters), loss = 0.00717803
I0621 20:16:31.818899 17579 solver.cpp:238]     Train net output #0: loss = 0.00329366 (* 1 = 0.00329366 loss)
I0621 20:16:31.818928 17579 sgd_solver.cpp:105] Iteration 22750, lr = 0.0005
I0621 20:18:59.784648 17579 solver.cpp:219] Iteration 22800 (0.337922 iter/s, 147.963s/50 iters), loss = 0.0034896
I0621 20:18:59.784790 17579 solver.cpp:238]     Train net output #0: loss = 0.00585958 (* 1 = 0.00585958 loss)
I0621 20:18:59.784819 17579 sgd_solver.cpp:105] Iteration 22800, lr = 0.0005
I0621 20:21:27.765118 17579 solver.cpp:219] Iteration 22850 (0.337889 iter/s, 147.978s/50 iters), loss = 0.00477341
I0621 20:21:27.765779 17579 solver.cpp:238]     Train net output #0: loss = 0.0044756 (* 1 = 0.0044756 loss)
I0621 20:21:27.765810 17579 sgd_solver.cpp:105] Iteration 22850, lr = 0.0005
I0621 20:23:55.759937 17579 solver.cpp:219] Iteration 22900 (0.337855 iter/s, 147.993s/50 iters), loss = 0.0026276
I0621 20:23:55.760080 17579 solver.cpp:238]     Train net output #0: loss = 0.00165067 (* 1 = 0.00165067 loss)
I0621 20:23:55.760112 17579 sgd_solver.cpp:105] Iteration 22900, lr = 0.0005
I0621 20:26:23.709386 17579 solver.cpp:219] Iteration 22950 (0.33796 iter/s, 147.947s/50 iters), loss = 0.00491918
I0621 20:26:23.709554 17579 solver.cpp:238]     Train net output #0: loss = 0.00632616 (* 1 = 0.00632616 loss)
I0621 20:26:23.709585 17579 sgd_solver.cpp:105] Iteration 22950, lr = 0.0005
I0621 20:28:48.751981 17579 solver.cpp:331] Iteration 23000, Testing net (#0)
I0621 20:29:05.246840 17579 solver.cpp:398]     Test net output #0: accuracy = 0.985294
I0621 20:29:05.246927 17579 solver.cpp:398]     Test net output #1: loss = 0.0812509 (* 1 = 0.0812509 loss)
I0621 20:29:08.160464 17579 solver.cpp:219] Iteration 23000 (0.304047 iter/s, 164.448s/50 iters), loss = 0.0042613
I0621 20:29:08.160573 17579 solver.cpp:238]     Train net output #0: loss = 0.00349513 (* 1 = 0.00349513 loss)
I0621 20:29:08.160605 17579 sgd_solver.cpp:105] Iteration 23000, lr = 0.0005
I0621 20:31:36.110843 17579 solver.cpp:219] Iteration 23050 (0.337958 iter/s, 147.948s/50 iters), loss = 0.0045464
I0621 20:31:36.110997 17579 solver.cpp:238]     Train net output #0: loss = 0.00584161 (* 1 = 0.00584161 loss)
I0621 20:31:36.111027 17579 sgd_solver.cpp:105] Iteration 23050, lr = 0.0005
I0621 20:34:04.038133 17579 solver.cpp:219] Iteration 23100 (0.338011 iter/s, 147.924s/50 iters), loss = 0.0132355
I0621 20:34:04.038275 17579 solver.cpp:238]     Train net output #0: loss = 0.0033683 (* 1 = 0.0033683 loss)
I0621 20:34:04.038303 17579 sgd_solver.cpp:105] Iteration 23100, lr = 0.0005
I0621 20:36:31.937906 17579 solver.cpp:219] Iteration 23150 (0.338073 iter/s, 147.897s/50 iters), loss = 0.00351806
I0621 20:36:31.938040 17579 solver.cpp:238]     Train net output #0: loss = 0.00241748 (* 1 = 0.00241748 loss)
I0621 20:36:31.938067 17579 sgd_solver.cpp:105] Iteration 23150, lr = 0.0005
I0621 20:38:50.113045 17579 solver.cpp:219] Iteration 23200 (0.361867 iter/s, 138.173s/50 iters), loss = 0.00545332
I0621 20:38:50.113699 17579 solver.cpp:238]     Train net output #0: loss = 0.00334284 (* 1 = 0.00334284 loss)
I0621 20:38:50.113729 17579 sgd_solver.cpp:105] Iteration 23200, lr = 0.0005
I0621 20:41:18.061770 17579 solver.cpp:219] Iteration 23250 (0.33796 iter/s, 147.946s/50 iters), loss = 0.00263216
I0621 20:41:18.062052 17579 solver.cpp:238]     Train net output #0: loss = 0.00399616 (* 1 = 0.00399616 loss)
I0621 20:41:18.062079 17579 sgd_solver.cpp:105] Iteration 23250, lr = 0.0005
I0621 20:43:45.962951 17579 solver.cpp:219] Iteration 23300 (0.33807 iter/s, 147.898s/50 iters), loss = 0.00541393
I0621 20:43:45.963151 17579 solver.cpp:238]     Train net output #0: loss = 0.00718377 (* 1 = 0.00718377 loss)
I0621 20:43:45.963184 17579 sgd_solver.cpp:105] Iteration 23300, lr = 0.0005
I0621 20:46:13.801828 17579 solver.cpp:219] Iteration 23350 (0.338212 iter/s, 147.836s/50 iters), loss = 0.00542418
I0621 20:46:13.801980 17579 solver.cpp:238]     Train net output #0: loss = 0.00155367 (* 1 = 0.00155367 loss)
I0621 20:46:13.802014 17579 sgd_solver.cpp:105] Iteration 23350, lr = 0.0005
I0621 20:48:41.587888 17579 solver.cpp:219] Iteration 23400 (0.338333 iter/s, 147.783s/50 iters), loss = 0.00378122
I0621 20:48:41.588080 17579 solver.cpp:238]     Train net output #0: loss = 0.00780432 (* 1 = 0.00780432 loss)
I0621 20:48:41.588109 17579 sgd_solver.cpp:105] Iteration 23400, lr = 0.0005
I0621 20:51:09.291965 17579 solver.cpp:219] Iteration 23450 (0.338521 iter/s, 147.701s/50 iters), loss = 0.00356775
I0621 20:51:09.292125 17579 solver.cpp:238]     Train net output #0: loss = 0.00336893 (* 1 = 0.00336893 loss)
I0621 20:51:09.292158 17579 sgd_solver.cpp:105] Iteration 23450, lr = 0.0005
I0621 20:53:34.338582 17579 solver.cpp:331] Iteration 23500, Testing net (#0)
I0621 20:53:50.854995 17579 solver.cpp:398]     Test net output #0: accuracy = 0.985294
I0621 20:53:50.855096 17579 solver.cpp:398]     Test net output #1: loss = 0.0834192 (* 1 = 0.0834192 loss)
I0621 20:53:53.752676 17579 solver.cpp:219] Iteration 23500 (0.304029 iter/s, 164.458s/50 iters), loss = 0.00392137
I0621 20:53:53.752776 17579 solver.cpp:238]     Train net output #0: loss = 0.00264599 (* 1 = 0.00264599 loss)
I0621 20:53:53.752805 17579 sgd_solver.cpp:105] Iteration 23500, lr = 0.0005
I0621 20:56:21.590437 17579 solver.cpp:219] Iteration 23550 (0.338213 iter/s, 147.836s/50 iters), loss = 0.00395388
I0621 20:56:21.590611 17579 solver.cpp:238]     Train net output #0: loss = 0.0012404 (* 1 = 0.0012404 loss)
I0621 20:56:21.590643 17579 sgd_solver.cpp:105] Iteration 23550, lr = 0.0005
I0621 20:58:49.474905 17579 solver.cpp:219] Iteration 23600 (0.338108 iter/s, 147.882s/50 iters), loss = 0.00348194
I0621 20:58:49.475075 17579 solver.cpp:238]     Train net output #0: loss = 0.00150894 (* 1 = 0.00150894 loss)
I0621 20:58:49.475106 17579 sgd_solver.cpp:105] Iteration 23600, lr = 0.0005
I0621 21:01:07.684563 17579 solver.cpp:219] Iteration 23650 (0.361779 iter/s, 138.206s/50 iters), loss = 0.00474557
I0621 21:01:07.684734 17579 solver.cpp:238]     Train net output #0: loss = 0.00467973 (* 1 = 0.00467973 loss)
I0621 21:01:07.684764 17579 sgd_solver.cpp:105] Iteration 23650, lr = 0.0005
I0621 21:03:35.520720 17579 solver.cpp:219] Iteration 23700 (0.338219 iter/s, 147.833s/50 iters), loss = 0.00276713
I0621 21:03:35.520938 17579 solver.cpp:238]     Train net output #0: loss = 0.000698996 (* 1 = 0.000698996 loss)
I0621 21:03:35.520967 17579 sgd_solver.cpp:105] Iteration 23700, lr = 0.0005
I0621 21:06:03.297925 17579 solver.cpp:219] Iteration 23750 (0.338353 iter/s, 147.775s/50 iters), loss = 0.00272769
I0621 21:06:03.298104 17579 solver.cpp:238]     Train net output #0: loss = 0.00276051 (* 1 = 0.00276051 loss)
I0621 21:06:03.298131 17579 sgd_solver.cpp:105] Iteration 23750, lr = 0.0005
I0621 21:08:31.069124 17579 solver.cpp:219] Iteration 23800 (0.338367 iter/s, 147.769s/50 iters), loss = 0.00379419
I0621 21:08:31.069356 17579 solver.cpp:238]     Train net output #0: loss = 0.00445817 (* 1 = 0.00445817 loss)
I0621 21:08:31.069386 17579 sgd_solver.cpp:105] Iteration 23800, lr = 0.0005
I0621 21:10:58.830687 17579 solver.cpp:219] Iteration 23850 (0.338389 iter/s, 147.759s/50 iters), loss = 0.00344756
I0621 21:10:58.830875 17579 solver.cpp:238]     Train net output #0: loss = 0.00586765 (* 1 = 0.00586765 loss)
I0621 21:10:58.830905 17579 sgd_solver.cpp:105] Iteration 23850, lr = 0.0005
I0621 21:13:26.586887 17579 solver.cpp:219] Iteration 23900 (0.338404 iter/s, 147.752s/50 iters), loss = 0.00458568
I0621 21:13:26.587064 17579 solver.cpp:238]     Train net output #0: loss = 0.00335743 (* 1 = 0.00335743 loss)
I0621 21:13:26.587095 17579 sgd_solver.cpp:105] Iteration 23900, lr = 0.0005
I0621 21:15:54.418571 17579 solver.cpp:219] Iteration 23950 (0.338231 iter/s, 147.828s/50 iters), loss = 0.00378865
I0621 21:15:54.418790 17579 solver.cpp:238]     Train net output #0: loss = 0.0012905 (* 1 = 0.0012905 loss)
I0621 21:15:54.418826 17579 sgd_solver.cpp:105] Iteration 23950, lr = 0.0005
I0621 21:18:19.296072 17579 solver.cpp:448] Snapshotting to binary proto file mobilenet/mobile_pruning_iter_24000.caffemodel
I0621 21:18:19.423642 17579 sgd_solver.cpp:273] Snapshotting solver state to binary proto file mobilenet/mobile_pruning_iter_24000.solverstate
I0621 21:18:19.479697 17579 solver.cpp:331] Iteration 24000, Testing net (#0)
I0621 21:18:36.105165 17579 solver.cpp:398]     Test net output #0: accuracy = 0.983334
I0621 21:18:36.105253 17579 solver.cpp:398]     Test net output #1: loss = 0.0810385 (* 1 = 0.0810385 loss)
I0621 21:18:36.120260 17579 compress_conv_layer.cu:174] 0.675381 1.83417e-10 0.942715
I0621 21:18:36.137856 17579 compress_conv_layer.cu:174] 0.675381 1.11858e-10 0.551534
I0621 21:18:36.152979 17579 compress_conv_layer.cu:174] 0.675381 2.00981e-11 0.739009
I0621 21:18:36.164783 17579 compress_conv_layer.cu:174] 0.675381 3.06048e-12 0.779621
I0621 21:18:36.181780 17579 compress_conv_layer.cu:174] 0.675381 9.77542e-12 0.455266
I0621 21:18:36.208894 17579 compress_conv_layer.cu:174] 0.675381 9.37862e-14 0.481209
I0621 21:18:36.256150 17579 compress_conv_layer.cu:174] 0.675381 1.70314e-13 0.473436
I0621 21:18:36.303009 17579 compress_conv_layer.cu:174] 0.675381 2.1685e-12 0.402415
I0621 21:18:36.350721 17579 compress_conv_layer.cu:174] 0.675381 1.88488e-12 0.427667
I0621 21:18:36.398125 17579 compress_conv_layer.cu:174] 0.675381 1.98129e-12 0.572781
I0621 21:18:36.446359 17579 compress_conv_layer.cu:174] 0.675381 5.45549e-12 0.454372
I0621 21:18:36.537124 17579 compress_conv_layer.cu:174] 0.675381 1.63176e-12 0.325763
I0621 21:18:36.728792 17579 compress_conv_layer.cu:174] 0.675381 3.36123e-12 0.290984
I0621 21:18:36.751104 17579 compress_conv_layer.cu:174] 0.675381 3.12491e-07 0.190566
I0621 21:18:37.243288 17579 compress_conv_layer.cu:174] 0.675381 1.83417e-10 0.942715
I0621 21:18:37.259407 17579 compress_conv_layer.cu:174] 0.675381 1.11858e-10 0.551534
I0621 21:18:37.272423 17579 compress_conv_layer.cu:174] 0.675381 2.00981e-11 0.739009
I0621 21:18:37.286449 17579 compress_conv_layer.cu:174] 0.675381 3.06048e-12 0.779621
I0621 21:18:37.302538 17579 compress_conv_layer.cu:174] 0.675381 9.77542e-12 0.455266
I0621 21:18:37.329921 17579 compress_conv_layer.cu:174] 0.675381 9.37862e-14 0.481209
I0621 21:18:37.375478 17579 compress_conv_layer.cu:174] 0.675381 1.70314e-13 0.473436
I0621 21:18:37.422498 17579 compress_conv_layer.cu:174] 0.675381 2.1685e-12 0.402415
I0621 21:18:37.469316 17579 compress_conv_layer.cu:174] 0.675381 1.88488e-12 0.427667
I0621 21:18:37.515450 17579 compress_conv_layer.cu:174] 0.675381 1.98129e-12 0.572781
I0621 21:18:37.561635 17579 compress_conv_layer.cu:174] 0.675381 5.45549e-12 0.454372
I0621 21:18:37.650840 17579 compress_conv_layer.cu:174] 0.675381 1.63176e-12 0.325763
I0621 21:18:37.836765 17579 compress_conv_layer.cu:174] 0.675381 3.36123e-12 0.290984
I0621 21:18:37.856793 17579 compress_conv_layer.cu:174] 0.675381 3.12491e-07 0.190566
I0621 21:18:38.352481 17579 compress_conv_layer.cu:174] 0.675381 1.83417e-10 0.942715
I0621 21:18:38.369532 17579 compress_conv_layer.cu:174] 0.675381 1.11858e-10 0.551534
I0621 21:18:38.386212 17579 compress_conv_layer.cu:174] 0.675381 2.00981e-11 0.739009
I0621 21:18:38.399977 17579 compress_conv_layer.cu:174] 0.675381 3.06048e-12 0.779621
I0621 21:18:38.416571 17579 compress_conv_layer.cu:174] 0.675381 9.77542e-12 0.455266
I0621 21:18:38.441175 17579 compress_conv_layer.cu:174] 0.675381 9.37862e-14 0.481209
I0621 21:18:38.487793 17579 compress_conv_layer.cu:174] 0.675381 1.70314e-13 0.473436
I0621 21:18:38.535125 17579 compress_conv_layer.cu:174] 0.675381 2.1685e-12 0.402415
I0621 21:18:38.581614 17579 compress_conv_layer.cu:174] 0.675381 1.88488e-12 0.427667
I0621 21:18:38.630134 17579 compress_conv_layer.cu:174] 0.675381 1.98129e-12 0.572781
I0621 21:18:38.676167 17579 compress_conv_layer.cu:174] 0.675381 5.45549e-12 0.454372
I0621 21:18:38.769793 17579 compress_conv_layer.cu:174] 0.675381 1.63176e-12 0.325763
I0621 21:18:38.957192 17579 compress_conv_layer.cu:174] 0.675381 3.36123e-12 0.290984
I0621 21:18:38.977916 17579 compress_conv_layer.cu:174] 0.675381 3.12491e-07 0.190566
I0621 21:18:39.437099 17579 compress_conv_layer.cu:174] 0.675381 1.83417e-10 0.942715
I0621 21:18:39.453259 17579 compress_conv_layer.cu:174] 0.675381 1.11858e-10 0.551534
I0621 21:18:39.470907 17579 compress_conv_layer.cu:174] 0.675381 2.00981e-11 0.739009
I0621 21:18:39.484570 17579 compress_conv_layer.cu:174] 0.675381 3.06048e-12 0.779621
I0621 21:18:39.500694 17579 compress_conv_layer.cu:174] 0.675381 9.77542e-12 0.455266
I0621 21:18:39.524857 17579 compress_conv_layer.cu:174] 0.675381 9.37862e-14 0.481209
I0621 21:18:39.571045 17579 compress_conv_layer.cu:174] 0.675381 1.70314e-13 0.473436
I0621 21:18:39.618340 17579 compress_conv_layer.cu:174] 0.675381 2.1685e-12 0.402415
I0621 21:18:39.663986 17579 compress_conv_layer.cu:174] 0.675381 1.88488e-12 0.427667
I0621 21:18:39.711650 17579 compress_conv_layer.cu:174] 0.675381 1.98129e-12 0.572781
I0621 21:18:39.757906 17579 compress_conv_layer.cu:174] 0.675381 5.45549e-12 0.454372
I0621 21:18:39.848310 17579 compress_conv_layer.cu:174] 0.675381 1.63176e-12 0.325763
I0621 21:18:40.033983 17579 compress_conv_layer.cu:174] 0.675381 3.36123e-12 0.290984
I0621 21:18:40.054486 17579 compress_conv_layer.cu:174] 0.675381 3.12491e-07 0.190566
I0621 21:18:40.553966 17579 compress_conv_layer.cu:174] 0.675381 1.83417e-10 0.942715
I0621 21:18:40.570039 17579 compress_conv_layer.cu:174] 0.675381 1.11858e-10 0.551534
I0621 21:18:40.582953 17579 compress_conv_layer.cu:174] 0.675381 2.00981e-11 0.739009
I0621 21:18:40.597978 17579 compress_conv_layer.cu:174] 0.675381 3.06048e-12 0.779621
I0621 21:18:40.614150 17579 compress_conv_layer.cu:174] 0.675381 9.77542e-12 0.455266
I0621 21:18:40.639834 17579 compress_conv_layer.cu:174] 0.675381 9.37862e-14 0.481209
I0621 21:18:40.685463 17579 compress_conv_layer.cu:174] 0.675381 1.70314e-13 0.473436
I0621 21:18:40.731767 17579 compress_conv_layer.cu:174] 0.675381 2.1685e-12 0.402415
I0621 21:18:40.779167 17579 compress_conv_layer.cu:174] 0.675381 1.88488e-12 0.427667
I0621 21:18:40.825906 17579 compress_conv_layer.cu:174] 0.675381 1.98129e-12 0.572781
I0621 21:18:40.874023 17579 compress_conv_layer.cu:174] 0.675381 5.45549e-12 0.454372
I0621 21:18:40.964880 17579 compress_conv_layer.cu:174] 0.675381 1.63176e-12 0.325763
I0621 21:18:41.150969 17579 compress_conv_layer.cu:174] 0.675381 3.36123e-12 0.290984
I0621 21:18:41.174032 17579 compress_conv_layer.cu:174] 0.675381 3.12491e-07 0.190566
I0621 21:18:41.649443 17579 solver.cpp:219] Iteration 24000 (0.298994 iter/s, 167.228s/50 iters), loss = 0.00743689
I0621 21:18:41.649566 17579 solver.cpp:238]     Train net output #0: loss = 0.00996504 (* 1 = 0.00996504 loss)
I0621 21:18:41.649597 17579 sgd_solver.cpp:105] Iteration 24000, lr = 0.0005
I0621 21:21:09.405189 17579 solver.cpp:219] Iteration 24050 (0.338403 iter/s, 147.753s/50 iters), loss = 0.00348857
I0621 21:21:09.405534 17579 solver.cpp:238]     Train net output #0: loss = 0.000706974 (* 1 = 0.000706974 loss)
I0621 21:21:09.405565 17579 sgd_solver.cpp:105] Iteration 24050, lr = 0.0005
I0621 21:23:27.639008 17579 solver.cpp:219] Iteration 24100 (0.361712 iter/s, 138.232s/50 iters), loss = 0.00521399
I0621 21:23:27.639225 17579 solver.cpp:238]     Train net output #0: loss = 0.00356342 (* 1 = 0.00356342 loss)
I0621 21:23:27.639256 17579 sgd_solver.cpp:105] Iteration 24100, lr = 0.0005
I0621 21:25:55.661833 17579 solver.cpp:219] Iteration 24150 (0.337796 iter/s, 148.018s/50 iters), loss = 0.00562503
I0621 21:25:55.661993 17579 solver.cpp:238]     Train net output #0: loss = 0.0116068 (* 1 = 0.0116068 loss)
I0621 21:25:55.662022 17579 sgd_solver.cpp:105] Iteration 24150, lr = 0.0005
I0621 21:28:23.635066 17579 solver.cpp:219] Iteration 24200 (0.337905 iter/s, 147.971s/50 iters), loss = 0.00375673
I0621 21:28:23.635226 17579 solver.cpp:238]     Train net output #0: loss = 0.00464255 (* 1 = 0.00464255 loss)
I0621 21:28:23.635260 17579 sgd_solver.cpp:105] Iteration 24200, lr = 0.0005
I0621 21:30:51.566659 17579 solver.cpp:219] Iteration 24250 (0.338003 iter/s, 147.928s/50 iters), loss = 0.00553325
I0621 21:30:51.566807 17579 solver.cpp:238]     Train net output #0: loss = 0.00539554 (* 1 = 0.00539554 loss)
I0621 21:30:51.566835 17579 sgd_solver.cpp:105] Iteration 24250, lr = 0.0005
I0621 21:33:19.498013 17579 solver.cpp:219] Iteration 24300 (0.338001 iter/s, 147.929s/50 iters), loss = 0.00529276
I0621 21:33:19.498150 17579 solver.cpp:238]     Train net output #0: loss = 0.00310441 (* 1 = 0.00310441 loss)
I0621 21:33:19.498178 17579 sgd_solver.cpp:105] Iteration 24300, lr = 0.0005
I0621 21:35:47.411159 17579 solver.cpp:219] Iteration 24350 (0.338041 iter/s, 147.911s/50 iters), loss = 0.00423921
I0621 21:35:47.411314 17579 solver.cpp:238]     Train net output #0: loss = 0.0024209 (* 1 = 0.0024209 loss)
I0621 21:35:47.411344 17579 sgd_solver.cpp:105] Iteration 24350, lr = 0.0005
I0621 21:38:15.329466 17579 solver.cpp:219] Iteration 24400 (0.338031 iter/s, 147.915s/50 iters), loss = 0.00494204
I0621 21:38:15.329627 17579 solver.cpp:238]     Train net output #0: loss = 0.00152477 (* 1 = 0.00152477 loss)
I0621 21:38:15.329668 17579 sgd_solver.cpp:105] Iteration 24400, lr = 0.0005
I0621 21:40:43.311048 17579 solver.cpp:219] Iteration 24450 (0.337886 iter/s, 147.979s/50 iters), loss = 0.00545692
I0621 21:40:43.311252 17579 solver.cpp:238]     Train net output #0: loss = 0.00165032 (* 1 = 0.00165032 loss)
I0621 21:40:43.311281 17579 sgd_solver.cpp:105] Iteration 24450, lr = 0.0005
I0621 21:43:08.404302 17579 solver.cpp:331] Iteration 24500, Testing net (#0)
I0621 21:43:24.902521 17579 solver.cpp:398]     Test net output #0: accuracy = 0.982353
I0621 21:43:24.902608 17579 solver.cpp:398]     Test net output #1: loss = 0.0827819 (* 1 = 0.0827819 loss)
I0621 21:43:27.825378 17579 solver.cpp:219] Iteration 24500 (0.30393 iter/s, 164.512s/50 iters), loss = 0.00450706
I0621 21:43:27.825475 17579 solver.cpp:238]     Train net output #0: loss = 0.00228562 (* 1 = 0.00228562 loss)
I0621 21:43:27.825505 17579 sgd_solver.cpp:105] Iteration 24500, lr = 0.0005
I0621 21:45:46.014909 17579 solver.cpp:219] Iteration 24550 (0.361829 iter/s, 138.187s/50 iters), loss = 0.00349807
I0621 21:45:46.015071 17579 solver.cpp:238]     Train net output #0: loss = 0.00272011 (* 1 = 0.00272011 loss)
I0621 21:45:46.015100 17579 sgd_solver.cpp:105] Iteration 24550, lr = 0.0005
I0621 21:48:13.921033 17579 solver.cpp:219] Iteration 24600 (0.338058 iter/s, 147.904s/50 iters), loss = 0.00522448
I0621 21:48:13.921172 17579 solver.cpp:238]     Train net output #0: loss = 0.00839724 (* 1 = 0.00839724 loss)
I0621 21:48:13.921200 17579 sgd_solver.cpp:105] Iteration 24600, lr = 0.0005
I0621 21:50:41.904736 17579 solver.cpp:219] Iteration 24650 (0.337879 iter/s, 147.982s/50 iters), loss = 0.00671605
I0621 21:50:41.904877 17579 solver.cpp:238]     Train net output #0: loss = 0.0175733 (* 1 = 0.0175733 loss)
I0621 21:50:41.904906 17579 sgd_solver.cpp:105] Iteration 24650, lr = 0.0005
I0621 21:53:09.883425 17579 solver.cpp:219] Iteration 24700 (0.337892 iter/s, 147.976s/50 iters), loss = 0.00487048
I0621 21:53:09.883617 17579 solver.cpp:238]     Train net output #0: loss = 0.00777726 (* 1 = 0.00777726 loss)
I0621 21:53:09.883644 17579 sgd_solver.cpp:105] Iteration 24700, lr = 0.0005
I0621 21:55:37.743392 17579 solver.cpp:219] Iteration 24750 (0.338164 iter/s, 147.857s/50 iters), loss = 0.00391307
I0621 21:55:37.743554 17579 solver.cpp:238]     Train net output #0: loss = 0.00633733 (* 1 = 0.00633733 loss)
I0621 21:55:37.743587 17579 sgd_solver.cpp:105] Iteration 24750, lr = 0.0005
I0621 21:58:05.683845 17579 solver.cpp:219] Iteration 24800 (0.33798 iter/s, 147.938s/50 iters), loss = 0.007112
I0621 21:58:05.683976 17579 solver.cpp:238]     Train net output #0: loss = 0.0020983 (* 1 = 0.0020983 loss)
I0621 21:58:05.684005 17579 sgd_solver.cpp:105] Iteration 24800, lr = 0.0005
I0621 22:00:33.599104 17579 solver.cpp:219] Iteration 24850 (0.338038 iter/s, 147.913s/50 iters), loss = 0.00815042
I0621 22:00:33.599257 17579 solver.cpp:238]     Train net output #0: loss = 0.00591446 (* 1 = 0.00591446 loss)
I0621 22:00:33.599289 17579 sgd_solver.cpp:105] Iteration 24850, lr = 0.0005
I0621 22:03:01.560184 17579 solver.cpp:219] Iteration 24900 (0.337935 iter/s, 147.957s/50 iters), loss = 0.00282681
I0621 22:03:01.560344 17579 solver.cpp:238]     Train net output #0: loss = 0.00305751 (* 1 = 0.00305751 loss)
I0621 22:03:01.560376 17579 sgd_solver.cpp:105] Iteration 24900, lr = 0.0005
I0621 22:05:29.536468 17579 solver.cpp:219] Iteration 24950 (0.337898 iter/s, 147.974s/50 iters), loss = 0.00265801
I0621 22:05:29.536613 17579 solver.cpp:238]     Train net output #0: loss = 0.00155712 (* 1 = 0.00155712 loss)
I0621 22:05:29.536643 17579 sgd_solver.cpp:105] Iteration 24950, lr = 0.0005
I0621 22:07:44.832197 17579 solver.cpp:331] Iteration 25000, Testing net (#0)
I0621 22:07:53.714588 17579 blocking_queue.cpp:49] Waiting for data
I0621 22:08:01.353013 17579 solver.cpp:398]     Test net output #0: accuracy = 0.97451
I0621 22:08:01.353098 17579 solver.cpp:398]     Test net output #1: loss = 0.090573 (* 1 = 0.090573 loss)
I0621 22:08:04.280912 17579 solver.cpp:219] Iteration 25000 (0.323119 iter/s, 154.742s/50 iters), loss = 0.00403601
I0621 22:08:04.280999 17579 solver.cpp:238]     Train net output #0: loss = 0.00232441 (* 1 = 0.00232441 loss)
I0621 22:08:04.281029 17579 sgd_solver.cpp:105] Iteration 25000, lr = 0.0005
I0621 22:10:32.320010 17579 solver.cpp:219] Iteration 25050 (0.337757 iter/s, 148.035s/50 iters), loss = 0.00344204
I0621 22:10:32.320163 17579 solver.cpp:238]     Train net output #0: loss = 0.00406249 (* 1 = 0.00406249 loss)
I0621 22:10:32.320194 17579 sgd_solver.cpp:105] Iteration 25050, lr = 0.0005
I0621 22:13:00.274893 17579 solver.cpp:219] Iteration 25100 (0.337947 iter/s, 147.952s/50 iters), loss = 0.00675179
I0621 22:13:00.275094 17579 solver.cpp:238]     Train net output #0: loss = 0.00739352 (* 1 = 0.00739352 loss)
I0621 22:13:00.275122 17579 sgd_solver.cpp:105] Iteration 25100, lr = 0.0005
I0621 22:15:28.238667 17579 solver.cpp:219] Iteration 25150 (0.337927 iter/s, 147.961s/50 iters), loss = 0.00446682
I0621 22:15:28.238807 17579 solver.cpp:238]     Train net output #0: loss = 0.00414218 (* 1 = 0.00414218 loss)
I0621 22:15:28.238838 17579 sgd_solver.cpp:105] Iteration 25150, lr = 0.0005
I0621 22:17:56.140452 17579 solver.cpp:219] Iteration 25200 (0.338069 iter/s, 147.899s/50 iters), loss = 0.00459019
I0621 22:17:56.140614 17579 solver.cpp:238]     Train net output #0: loss = 0.00305301 (* 1 = 0.00305301 loss)
I0621 22:17:56.140643 17579 sgd_solver.cpp:105] Iteration 25200, lr = 0.0005
I0621 22:20:24.061530 17579 solver.cpp:219] Iteration 25250 (0.338024 iter/s, 147.918s/50 iters), loss = 0.00516801
I0621 22:20:24.065013 17579 solver.cpp:238]     Train net output #0: loss = 0.00552368 (* 1 = 0.00552368 loss)
I0621 22:20:24.065043 17579 sgd_solver.cpp:105] Iteration 25250, lr = 0.0005
I0621 22:22:51.986470 17579 solver.cpp:219] Iteration 25300 (0.338021 iter/s, 147.92s/50 iters), loss = 0.0048563
I0621 22:22:51.986620 17579 solver.cpp:238]     Train net output #0: loss = 0.00192377 (* 1 = 0.00192377 loss)
I0621 22:22:51.986647 17579 sgd_solver.cpp:105] Iteration 25300, lr = 0.0005
I0621 22:25:19.998397 17579 solver.cpp:219] Iteration 25350 (0.337817 iter/s, 148.009s/50 iters), loss = 0.00432222
I0621 22:25:19.998612 17579 solver.cpp:238]     Train net output #0: loss = 0.00389653 (* 1 = 0.00389653 loss)
I0621 22:25:19.998641 17579 sgd_solver.cpp:105] Iteration 25350, lr = 0.0005
I0621 22:27:47.764915 17579 solver.cpp:219] Iteration 25400 (0.338379 iter/s, 147.763s/50 iters), loss = 0.00709378
I0621 22:27:47.765820 17579 solver.cpp:238]     Train net output #0: loss = 0.00772836 (* 1 = 0.00772836 loss)
I0621 22:27:47.765851 17579 sgd_solver.cpp:105] Iteration 25400, lr = 0.0005
I0621 22:30:05.936831 17579 solver.cpp:219] Iteration 25450 (0.361876 iter/s, 138.169s/50 iters), loss = 0.00874485
I0621 22:30:05.936967 17579 solver.cpp:238]     Train net output #0: loss = 0.0130808 (* 1 = 0.0130808 loss)
I0621 22:30:05.936997 17579 sgd_solver.cpp:105] Iteration 25450, lr = 0.0005
I0621 22:32:30.901893 17579 solver.cpp:331] Iteration 25500, Testing net (#0)
I0621 22:32:47.243053 17579 solver.cpp:398]     Test net output #0: accuracy = 0.975491
I0621 22:32:47.243129 17579 solver.cpp:398]     Test net output #1: loss = 0.0851785 (* 1 = 0.0851785 loss)
I0621 22:32:47.258060 17579 compress_conv_layer.cu:174] 0.688015 1.83355e-10 0.942375
I0621 22:32:47.275600 17579 compress_conv_layer.cu:174] 0.688015 1.11816e-10 0.551411
I0621 22:32:47.291056 17579 compress_conv_layer.cu:174] 0.688015 2.00903e-11 0.738749
I0621 22:32:47.302786 17579 compress_conv_layer.cu:174] 0.688015 3.05918e-12 0.779292
I0621 22:32:47.318063 17579 compress_conv_layer.cu:174] 0.688015 9.77151e-12 0.4553
I0621 22:32:47.342713 17579 compress_conv_layer.cu:174] 0.688015 9.37557e-14 0.48105
I0621 22:32:47.390679 17579 compress_conv_layer.cu:174] 0.688015 1.70253e-13 0.473196
I0621 22:32:47.440240 17579 compress_conv_layer.cu:174] 0.688015 2.16782e-12 0.402232
I0621 22:32:47.488849 17579 compress_conv_layer.cu:174] 0.688015 1.88423e-12 0.427487
I0621 22:32:47.534744 17579 compress_conv_layer.cu:174] 0.688015 1.98064e-12 0.572574
I0621 22:32:47.583328 17579 compress_conv_layer.cu:174] 0.688015 5.45353e-12 0.454182
I0621 22:32:47.673835 17579 compress_conv_layer.cu:174] 0.688015 1.63111e-12 0.32564
I0621 22:32:47.860646 17579 compress_conv_layer.cu:174] 0.688015 3.35993e-12 0.290869
I0621 22:32:47.880631 17579 compress_conv_layer.cu:174] 0.688015 3.12363e-07 0.190857
I0621 22:32:48.374955 17579 compress_conv_layer.cu:174] 0.688015 1.83355e-10 0.942375
I0621 22:32:48.391886 17579 compress_conv_layer.cu:174] 0.688015 1.11816e-10 0.551411
I0621 22:32:48.408555 17579 compress_conv_layer.cu:174] 0.688015 2.00903e-11 0.738749
I0621 22:32:48.422806 17579 compress_conv_layer.cu:174] 0.688015 3.05918e-12 0.779292
I0621 22:32:48.437721 17579 compress_conv_layer.cu:174] 0.688015 9.77151e-12 0.4553
I0621 22:32:48.461695 17579 compress_conv_layer.cu:174] 0.688015 9.37557e-14 0.48105
I0621 22:32:48.506649 17579 compress_conv_layer.cu:174] 0.688015 1.70253e-13 0.473196
I0621 22:32:48.551815 17579 compress_conv_layer.cu:174] 0.688015 2.16782e-12 0.402232
I0621 22:32:48.598881 17579 compress_conv_layer.cu:174] 0.688015 1.88423e-12 0.427487
I0621 22:32:48.647086 17579 compress_conv_layer.cu:174] 0.688015 1.98064e-12 0.572574
I0621 22:32:48.693392 17579 compress_conv_layer.cu:174] 0.688015 5.45353e-12 0.454182
I0621 22:32:48.783977 17579 compress_conv_layer.cu:174] 0.688015 1.63111e-12 0.32564
I0621 22:32:48.967794 17579 compress_conv_layer.cu:174] 0.688015 3.35993e-12 0.290869
I0621 22:32:48.989135 17579 compress_conv_layer.cu:174] 0.688015 3.12363e-07 0.190857
I0621 22:32:49.486615 17579 compress_conv_layer.cu:174] 0.688015 1.83355e-10 0.942375
I0621 22:32:49.502732 17579 compress_conv_layer.cu:174] 0.688015 1.11816e-10 0.551411
I0621 22:32:49.515632 17579 compress_conv_layer.cu:174] 0.688015 2.00903e-11 0.738749
I0621 22:32:49.530715 17579 compress_conv_layer.cu:174] 0.688015 3.05918e-12 0.779292
I0621 22:32:49.546500 17579 compress_conv_layer.cu:174] 0.688015 9.77151e-12 0.4553
I0621 22:32:49.572727 17579 compress_conv_layer.cu:174] 0.688015 9.37557e-14 0.48105
I0621 22:32:49.618532 17579 compress_conv_layer.cu:174] 0.688015 1.70253e-13 0.473196
I0621 22:32:49.664635 17579 compress_conv_layer.cu:174] 0.688015 2.16782e-12 0.402232
I0621 22:32:49.711988 17579 compress_conv_layer.cu:174] 0.688015 1.88423e-12 0.427487
I0621 22:32:49.759135 17579 compress_conv_layer.cu:174] 0.688015 1.98064e-12 0.572574
I0621 22:32:49.807163 17579 compress_conv_layer.cu:174] 0.688015 5.45353e-12 0.454182
I0621 22:32:49.896335 17579 compress_conv_layer.cu:174] 0.688015 1.63111e-12 0.32564
I0621 22:32:50.078224 17579 compress_conv_layer.cu:174] 0.688015 3.35993e-12 0.290869
I0621 22:32:50.097682 17579 compress_conv_layer.cu:174] 0.688015 3.12363e-07 0.190857
I0621 22:32:50.591158 17579 compress_conv_layer.cu:174] 0.688015 1.83355e-10 0.942375
I0621 22:32:50.607765 17579 compress_conv_layer.cu:174] 0.688015 1.11816e-10 0.551411
I0621 22:32:50.623344 17579 compress_conv_layer.cu:174] 0.688015 2.00903e-11 0.738749
I0621 22:32:50.635906 17579 compress_conv_layer.cu:174] 0.688015 3.05918e-12 0.779292
I0621 22:32:50.652173 17579 compress_conv_layer.cu:174] 0.688015 9.77151e-12 0.4553
I0621 22:32:50.676434 17579 compress_conv_layer.cu:174] 0.688015 9.37557e-14 0.48105
I0621 22:32:50.722167 17579 compress_conv_layer.cu:174] 0.688015 1.70253e-13 0.473196
I0621 22:32:50.769239 17579 compress_conv_layer.cu:174] 0.688015 2.16782e-12 0.402232
I0621 22:32:50.817245 17579 compress_conv_layer.cu:174] 0.688015 1.88423e-12 0.427487
I0621 22:32:50.863962 17579 compress_conv_layer.cu:174] 0.688015 1.98064e-12 0.572574
I0621 22:32:50.909247 17579 compress_conv_layer.cu:174] 0.688015 5.45353e-12 0.454182
I0621 22:32:50.999084 17579 compress_conv_layer.cu:174] 0.688015 1.63111e-12 0.32564
I0621 22:32:51.186640 17579 compress_conv_layer.cu:174] 0.688015 3.35993e-12 0.290869
I0621 22:32:51.208497 17579 compress_conv_layer.cu:174] 0.688015 3.12363e-07 0.190857
I0621 22:32:51.707835 17579 compress_conv_layer.cu:174] 0.688015 1.83355e-10 0.942375
I0621 22:32:51.723922 17579 compress_conv_layer.cu:174] 0.688015 1.11816e-10 0.551411
I0621 22:32:51.736753 17579 compress_conv_layer.cu:174] 0.688015 2.00903e-11 0.738749
I0621 22:32:51.751755 17579 compress_conv_layer.cu:174] 0.688015 3.05918e-12 0.779292
I0621 22:32:51.768234 17579 compress_conv_layer.cu:174] 0.688015 9.77151e-12 0.4553
I0621 22:32:51.793540 17579 compress_conv_layer.cu:174] 0.688015 9.37557e-14 0.48105
I0621 22:32:51.840067 17579 compress_conv_layer.cu:174] 0.688015 1.70253e-13 0.473196
I0621 22:32:51.888253 17579 compress_conv_layer.cu:174] 0.688015 2.16782e-12 0.402232
I0621 22:32:51.934341 17579 compress_conv_layer.cu:174] 0.688015 1.88423e-12 0.427487
I0621 22:32:51.980587 17579 compress_conv_layer.cu:174] 0.688015 1.98064e-12 0.572574
I0621 22:32:52.028489 17579 compress_conv_layer.cu:174] 0.688015 5.45353e-12 0.454182
I0621 22:32:52.120028 17579 compress_conv_layer.cu:174] 0.688015 1.63111e-12 0.32564
I0621 22:32:52.303093 17579 compress_conv_layer.cu:174] 0.688015 3.35993e-12 0.290869
I0621 22:32:52.323837 17579 compress_conv_layer.cu:174] 0.688015 3.12363e-07 0.190857
I0621 22:32:52.800890 17579 solver.cpp:219] Iteration 25500 (0.299651 iter/s, 166.861s/50 iters), loss = 0.00719754
I0621 22:32:52.800978 17579 solver.cpp:238]     Train net output #0: loss = 0.00601134 (* 1 = 0.00601134 loss)
I0621 22:32:52.801007 17579 sgd_solver.cpp:105] Iteration 25500, lr = 0.0005
I0621 22:35:20.680541 17579 solver.cpp:219] Iteration 25550 (0.338122 iter/s, 147.876s/50 iters), loss = 0.00438885
I0621 22:35:20.680775 17579 solver.cpp:238]     Train net output #0: loss = 0.00336613 (* 1 = 0.00336613 loss)
I0621 22:35:20.680804 17579 sgd_solver.cpp:105] Iteration 25550, lr = 0.0005
I0621 22:37:48.696595 17579 solver.cpp:219] Iteration 25600 (0.337808 iter/s, 148.013s/50 iters), loss = 0.00607098
I0621 22:37:48.696753 17579 solver.cpp:238]     Train net output #0: loss = 0.00157875 (* 1 = 0.00157875 loss)
I0621 22:37:48.696780 17579 sgd_solver.cpp:105] Iteration 25600, lr = 0.0005
I0621 22:40:16.650321 17579 solver.cpp:219] Iteration 25650 (0.33795 iter/s, 147.951s/50 iters), loss = 0.00516255
I0621 22:40:16.650523 17579 solver.cpp:238]     Train net output #0: loss = 0.00376474 (* 1 = 0.00376474 loss)
I0621 22:40:16.650552 17579 sgd_solver.cpp:105] Iteration 25650, lr = 0.0005
I0621 22:42:44.606091 17579 solver.cpp:219] Iteration 25700 (0.337945 iter/s, 147.953s/50 iters), loss = 0.00504644
I0621 22:42:44.606254 17579 solver.cpp:238]     Train net output #0: loss = 0.00509187 (* 1 = 0.00509187 loss)
I0621 22:42:44.606282 17579 sgd_solver.cpp:105] Iteration 25700, lr = 0.0005
I0621 22:45:12.540679 17579 solver.cpp:219] Iteration 25750 (0.337994 iter/s, 147.932s/50 iters), loss = 0.00494719
I0621 22:45:12.540930 17579 solver.cpp:238]     Train net output #0: loss = 0.0029721 (* 1 = 0.0029721 loss)
I0621 22:45:12.540958 17579 sgd_solver.cpp:105] Iteration 25750, lr = 0.0005
I0621 22:47:40.502629 17579 solver.cpp:219] Iteration 25800 (0.337931 iter/s, 147.959s/50 iters), loss = 0.0103747
I0621 22:47:40.502779 17579 solver.cpp:238]     Train net output #0: loss = 0.00707057 (* 1 = 0.00707057 loss)
I0621 22:47:40.502810 17579 sgd_solver.cpp:105] Iteration 25800, lr = 0.0005
I0621 22:50:08.411309 17579 solver.cpp:219] Iteration 25850 (0.338053 iter/s, 147.906s/50 iters), loss = 0.00573469
I0621 22:50:08.411466 17579 solver.cpp:238]     Train net output #0: loss = 0.00424444 (* 1 = 0.00424444 loss)
I0621 22:50:08.411495 17579 sgd_solver.cpp:105] Iteration 25850, lr = 0.0005
I0621 22:52:26.437863 17579 solver.cpp:219] Iteration 25900 (0.362256 iter/s, 138.024s/50 iters), loss = 0.0106539
I0621 22:52:26.438024 17579 solver.cpp:238]     Train net output #0: loss = 0.00431174 (* 1 = 0.00431174 loss)
I0621 22:52:26.438053 17579 sgd_solver.cpp:105] Iteration 25900, lr = 0.0005
I0621 22:54:54.315943 17579 solver.cpp:219] Iteration 25950 (0.338123 iter/s, 147.875s/50 iters), loss = 0.00627547
I0621 22:54:54.316121 17579 solver.cpp:238]     Train net output #0: loss = 0.0063126 (* 1 = 0.0063126 loss)
I0621 22:54:54.316154 17579 sgd_solver.cpp:105] Iteration 25950, lr = 0.0005
I0621 22:57:19.164149 17579 solver.cpp:331] Iteration 26000, Testing net (#0)
I0621 22:57:35.737253 17579 solver.cpp:398]     Test net output #0: accuracy = 0.977451
I0621 22:57:35.737354 17579 solver.cpp:398]     Test net output #1: loss = 0.092558 (* 1 = 0.092558 loss)
I0621 22:57:38.626263 17579 solver.cpp:219] Iteration 26000 (0.304308 iter/s, 164.307s/50 iters), loss = 0.00995316
I0621 22:57:38.626363 17579 solver.cpp:238]     Train net output #0: loss = 0.0056856 (* 1 = 0.0056856 loss)
I0621 22:57:38.626396 17579 sgd_solver.cpp:105] Iteration 26000, lr = 0.0005
I0621 23:00:06.497992 17579 solver.cpp:219] Iteration 26050 (0.338135 iter/s, 147.87s/50 iters), loss = 0.00561939
I0621 23:00:06.498162 17579 solver.cpp:238]     Train net output #0: loss = 0.00224946 (* 1 = 0.00224946 loss)
I0621 23:00:06.498191 17579 sgd_solver.cpp:105] Iteration 26050, lr = 0.0005
I0621 23:02:34.292978 17579 solver.cpp:219] Iteration 26100 (0.33831 iter/s, 147.793s/50 iters), loss = 0.00923554
I0621 23:02:34.293154 17579 solver.cpp:238]     Train net output #0: loss = 0.0108579 (* 1 = 0.0108579 loss)
I0621 23:02:34.293184 17579 sgd_solver.cpp:105] Iteration 26100, lr = 0.0005
I0621 23:05:02.061378 17579 solver.cpp:219] Iteration 26150 (0.338372 iter/s, 147.766s/50 iters), loss = 0.00819821
I0621 23:05:02.061544 17579 solver.cpp:238]     Train net output #0: loss = 0.0150225 (* 1 = 0.0150225 loss)
I0621 23:05:02.061574 17579 sgd_solver.cpp:105] Iteration 26150, lr = 0.0005
I0621 23:07:29.911648 17579 solver.cpp:219] Iteration 26200 (0.338185 iter/s, 147.848s/50 iters), loss = 0.00402059
I0621 23:07:29.911870 17579 solver.cpp:238]     Train net output #0: loss = 0.00421219 (* 1 = 0.00421219 loss)
I0621 23:07:29.911903 17579 sgd_solver.cpp:105] Iteration 26200, lr = 0.0005
I0621 23:09:57.766494 17579 solver.cpp:219] Iteration 26250 (0.338174 iter/s, 147.853s/50 iters), loss = 0.00641739
I0621 23:09:57.766710 17579 solver.cpp:238]     Train net output #0: loss = 0.0128978 (* 1 = 0.0128978 loss)
I0621 23:09:57.766741 17579 sgd_solver.cpp:105] Iteration 26250, lr = 0.0005
I0621 23:12:25.623181 17579 solver.cpp:219] Iteration 26300 (0.33817 iter/s, 147.855s/50 iters), loss = 0.00894727
I0621 23:12:25.623386 17579 solver.cpp:238]     Train net output #0: loss = 0.00428029 (* 1 = 0.00428029 loss)
I0621 23:12:25.623416 17579 sgd_solver.cpp:105] Iteration 26300, lr = 0.0005
I0621 23:14:43.744036 17579 solver.cpp:219] Iteration 26350 (0.362005 iter/s, 138.12s/50 iters), loss = 0.00805405
I0621 23:14:43.744240 17579 solver.cpp:238]     Train net output #0: loss = 0.00827801 (* 1 = 0.00827801 loss)
I0621 23:14:43.744269 17579 sgd_solver.cpp:105] Iteration 26350, lr = 0.0005
I0621 23:17:11.601092 17579 solver.cpp:219] Iteration 26400 (0.33817 iter/s, 147.855s/50 iters), loss = 0.0050324
I0621 23:17:11.601279 17579 solver.cpp:238]     Train net output #0: loss = 0.00386533 (* 1 = 0.00386533 loss)
I0621 23:17:11.601308 17579 sgd_solver.cpp:105] Iteration 26400, lr = 0.0005
I0621 23:19:39.474342 17579 solver.cpp:219] Iteration 26450 (0.338134 iter/s, 147.87s/50 iters), loss = 0.00651725
I0621 23:19:39.474504 17579 solver.cpp:238]     Train net output #0: loss = 0.00330303 (* 1 = 0.00330303 loss)
I0621 23:19:39.474540 17579 sgd_solver.cpp:105] Iteration 26450, lr = 0.0005
I0621 23:22:04.465175 17579 solver.cpp:331] Iteration 26500, Testing net (#0)
I0621 23:22:20.989441 17579 solver.cpp:398]     Test net output #0: accuracy = 0.981373
I0621 23:22:20.989538 17579 solver.cpp:398]     Test net output #1: loss = 0.085334 (* 1 = 0.085334 loss)
I0621 23:22:23.901692 17579 solver.cpp:219] Iteration 26500 (0.304091 iter/s, 164.424s/50 iters), loss = 0.00498687
I0621 23:22:23.901787 17579 solver.cpp:238]     Train net output #0: loss = 0.00447528 (* 1 = 0.00447528 loss)
I0621 23:22:23.901818 17579 sgd_solver.cpp:105] Iteration 26500, lr = 0.0005
I0621 23:24:51.788908 17579 solver.cpp:219] Iteration 26550 (0.338102 iter/s, 147.884s/50 iters), loss = 0.00612414
I0621 23:24:51.789067 17579 solver.cpp:238]     Train net output #0: loss = 0.00689586 (* 1 = 0.00689586 loss)
I0621 23:24:51.789110 17579 sgd_solver.cpp:105] Iteration 26550, lr = 0.0005
I0621 23:27:19.787292 17579 solver.cpp:219] Iteration 26600 (0.337851 iter/s, 147.994s/50 iters), loss = 0.00662298
I0621 23:27:19.787432 17579 solver.cpp:238]     Train net output #0: loss = 0.0107945 (* 1 = 0.0107945 loss)
I0621 23:27:19.787462 17579 sgd_solver.cpp:105] Iteration 26600, lr = 0.0005
I0621 23:29:47.825983 17579 solver.cpp:219] Iteration 26650 (0.337758 iter/s, 148.035s/50 iters), loss = 0.00430315
I0621 23:29:47.826144 17579 solver.cpp:238]     Train net output #0: loss = 0.00411609 (* 1 = 0.00411609 loss)
I0621 23:29:47.826174 17579 sgd_solver.cpp:105] Iteration 26650, lr = 0.0005
I0621 23:32:15.618583 17579 solver.cpp:219] Iteration 26700 (0.338322 iter/s, 147.788s/50 iters), loss = 0.00646101
I0621 23:32:15.618755 17579 solver.cpp:238]     Train net output #0: loss = 0.00417676 (* 1 = 0.00417676 loss)
I0621 23:32:15.618788 17579 sgd_solver.cpp:105] Iteration 26700, lr = 0.0005
I0621 23:34:43.429631 17579 solver.cpp:219] Iteration 26750 (0.338276 iter/s, 147.808s/50 iters), loss = 0.0100086
I0621 23:34:43.429772 17579 solver.cpp:238]     Train net output #0: loss = 0.00816306 (* 1 = 0.00816306 loss)
I0621 23:34:43.429801 17579 sgd_solver.cpp:105] Iteration 26750, lr = 0.0005
I0621 23:37:01.695602 17579 solver.cpp:219] Iteration 26800 (0.361629 iter/s, 138.263s/50 iters), loss = 0.00586393
I0621 23:37:01.695740 17579 solver.cpp:238]     Train net output #0: loss = 0.00449115 (* 1 = 0.00449115 loss)
I0621 23:37:01.695768 17579 sgd_solver.cpp:105] Iteration 26800, lr = 0.0005
I0621 23:39:29.609259 17579 solver.cpp:219] Iteration 26850 (0.338039 iter/s, 147.912s/50 iters), loss = 0.00478154
I0621 23:39:29.609410 17579 solver.cpp:238]     Train net output #0: loss = 0.00315497 (* 1 = 0.00315497 loss)
I0621 23:39:29.609442 17579 sgd_solver.cpp:105] Iteration 26850, lr = 0.0005
I0621 23:41:57.569782 17579 solver.cpp:219] Iteration 26900 (0.337935 iter/s, 147.957s/50 iters), loss = 0.00719504
I0621 23:41:57.569959 17579 solver.cpp:238]     Train net output #0: loss = 0.00431518 (* 1 = 0.00431518 loss)
I0621 23:41:57.569993 17579 sgd_solver.cpp:105] Iteration 26900, lr = 0.0005
I0621 23:44:25.403556 17579 solver.cpp:219] Iteration 26950 (0.338224 iter/s, 147.831s/50 iters), loss = 0.00508085
I0621 23:44:25.403745 17579 solver.cpp:238]     Train net output #0: loss = 0.0026869 (* 1 = 0.0026869 loss)
I0621 23:44:25.403777 17579 sgd_solver.cpp:105] Iteration 26950, lr = 0.0005
I0621 23:46:50.381808 17579 solver.cpp:331] Iteration 27000, Testing net (#0)
I0621 23:47:06.838034 17579 solver.cpp:398]     Test net output #0: accuracy = 0.976471
I0621 23:47:06.838125 17579 solver.cpp:398]     Test net output #1: loss = 0.0868191 (* 1 = 0.0868191 loss)
I0621 23:47:06.854827 17579 compress_conv_layer.cu:174] 0.7 1.83292e-10 0.942055
I0621 23:47:06.872850 17579 compress_conv_layer.cu:174] 0.7 1.11774e-10 0.551229
I0621 23:47:06.885869 17579 compress_conv_layer.cu:174] 0.7 2.00825e-11 0.738617
I0621 23:47:06.902045 17579 compress_conv_layer.cu:174] 0.7 3.05788e-12 0.779145
I0621 23:47:06.918498 17579 compress_conv_layer.cu:174] 0.7 9.76761e-12 0.455204
I0621 23:47:06.943584 17579 compress_conv_layer.cu:174] 0.7 9.37253e-14 0.480892
I0621 23:47:06.991160 17579 compress_conv_layer.cu:174] 0.7 1.70192e-13 0.472959
I0621 23:47:07.039583 17579 compress_conv_layer.cu:174] 0.7 2.16717e-12 0.402082
I0621 23:47:07.086377 17579 compress_conv_layer.cu:174] 0.7 1.88358e-12 0.427313
I0621 23:47:07.134057 17579 compress_conv_layer.cu:174] 0.7 1.97999e-12 0.57233
I0621 23:47:07.180147 17579 compress_conv_layer.cu:174] 0.7 5.45158e-12 0.453947
I0621 23:47:07.272060 17579 compress_conv_layer.cu:174] 0.7 1.63046e-12 0.325496
I0621 23:47:07.458173 17579 compress_conv_layer.cu:174] 0.7 3.35863e-12 0.290755
I0621 23:47:07.479883 17579 compress_conv_layer.cu:174] 0.7 3.12235e-07 0.191221
I0621 23:47:07.977326 17579 compress_conv_layer.cu:174] 0.7 1.83292e-10 0.942055
I0621 23:47:07.994664 17579 compress_conv_layer.cu:174] 0.7 1.11774e-10 0.551229
I0621 23:47:08.007678 17579 compress_conv_layer.cu:174] 0.7 2.00825e-11 0.738617
I0621 23:47:08.021386 17579 compress_conv_layer.cu:174] 0.7 3.05788e-12 0.779145
I0621 23:47:08.037777 17579 compress_conv_layer.cu:174] 0.7 9.76761e-12 0.455204
I0621 23:47:08.062937 17579 compress_conv_layer.cu:174] 0.7 9.37253e-14 0.480892
I0621 23:47:08.109287 17579 compress_conv_layer.cu:174] 0.7 1.70192e-13 0.472959
I0621 23:47:08.155084 17579 compress_conv_layer.cu:174] 0.7 2.16717e-12 0.402082
I0621 23:47:08.201231 17579 compress_conv_layer.cu:174] 0.7 1.88358e-12 0.427313
I0621 23:47:08.248536 17579 compress_conv_layer.cu:174] 0.7 1.97999e-12 0.57233
I0621 23:47:08.295241 17579 compress_conv_layer.cu:174] 0.7 5.45158e-12 0.453947
I0621 23:47:08.390358 17579 compress_conv_layer.cu:174] 0.7 1.63046e-12 0.325496
I0621 23:47:08.578151 17579 compress_conv_layer.cu:174] 0.7 3.35863e-12 0.290755
I0621 23:47:08.598309 17579 compress_conv_layer.cu:174] 0.7 3.12235e-07 0.191221
I0621 23:47:09.089170 17579 compress_conv_layer.cu:174] 0.7 1.83292e-10 0.942055
I0621 23:47:09.099125 17579 compress_conv_layer.cu:174] 0.7 1.11774e-10 0.551229
I0621 23:47:09.110013 17579 compress_conv_layer.cu:174] 0.7 2.00825e-11 0.738617
I0621 23:47:09.125082 17579 compress_conv_layer.cu:174] 0.7 3.05788e-12 0.779145
I0621 23:47:09.141427 17579 compress_conv_layer.cu:174] 0.7 9.76761e-12 0.455204
I0621 23:47:09.166402 17579 compress_conv_layer.cu:174] 0.7 9.37253e-14 0.480892
I0621 23:47:09.212033 17579 compress_conv_layer.cu:174] 0.7 1.70192e-13 0.472959
I0621 23:47:09.260694 17579 compress_conv_layer.cu:174] 0.7 2.16717e-12 0.402082
I0621 23:47:09.306769 17579 compress_conv_layer.cu:174] 0.7 1.88358e-12 0.427313
I0621 23:47:09.352432 17579 compress_conv_layer.cu:174] 0.7 1.97999e-12 0.57233
I0621 23:47:09.400102 17579 compress_conv_layer.cu:174] 0.7 5.45158e-12 0.453947
I0621 23:47:09.490598 17579 compress_conv_layer.cu:174] 0.7 1.63046e-12 0.325496
I0621 23:47:09.673377 17579 compress_conv_layer.cu:174] 0.7 3.35863e-12 0.290755
I0621 23:47:09.694644 17579 compress_conv_layer.cu:174] 0.7 3.12235e-07 0.191221
I0621 23:47:10.187067 17579 compress_conv_layer.cu:174] 0.7 1.83292e-10 0.942055
I0621 23:47:10.205404 17579 compress_conv_layer.cu:174] 0.7 1.11774e-10 0.551229
I0621 23:47:10.218516 17579 compress_conv_layer.cu:174] 0.7 2.00825e-11 0.738617
I0621 23:47:10.231428 17579 compress_conv_layer.cu:174] 0.7 3.05788e-12 0.779145
I0621 23:47:10.247445 17579 compress_conv_layer.cu:174] 0.7 9.76761e-12 0.455204
I0621 23:47:10.272299 17579 compress_conv_layer.cu:174] 0.7 9.37253e-14 0.480892
I0621 23:47:10.317332 17579 compress_conv_layer.cu:174] 0.7 1.70192e-13 0.472959
I0621 23:47:10.362494 17579 compress_conv_layer.cu:174] 0.7 2.16717e-12 0.402082
I0621 23:47:10.409943 17579 compress_conv_layer.cu:174] 0.7 1.88358e-12 0.427313
I0621 23:47:10.455904 17579 compress_conv_layer.cu:174] 0.7 1.97999e-12 0.57233
I0621 23:47:10.505355 17579 compress_conv_layer.cu:174] 0.7 5.45158e-12 0.453947
I0621 23:47:10.594938 17579 compress_conv_layer.cu:174] 0.7 1.63046e-12 0.325496
I0621 23:47:10.779999 17579 compress_conv_layer.cu:174] 0.7 3.35863e-12 0.290755
I0621 23:47:10.800261 17579 compress_conv_layer.cu:174] 0.7 3.12235e-07 0.191221
I0621 23:47:11.300340 17579 compress_conv_layer.cu:174] 0.7 1.83292e-10 0.942055
I0621 23:47:11.317876 17579 compress_conv_layer.cu:174] 0.7 1.11774e-10 0.551229
I0621 23:47:11.329144 17579 compress_conv_layer.cu:174] 0.7 2.00825e-11 0.738617
I0621 23:47:11.341984 17579 compress_conv_layer.cu:174] 0.7 3.05788e-12 0.779145
I0621 23:47:11.356026 17579 compress_conv_layer.cu:174] 0.7 9.76761e-12 0.455204
I0621 23:47:11.382591 17579 compress_conv_layer.cu:174] 0.7 9.37253e-14 0.480892
I0621 23:47:11.428369 17579 compress_conv_layer.cu:174] 0.7 1.70192e-13 0.472959
I0621 23:47:11.474735 17579 compress_conv_layer.cu:174] 0.7 2.16717e-12 0.402082
I0621 23:47:11.522693 17579 compress_conv_layer.cu:174] 0.7 1.88358e-12 0.427313
I0621 23:47:11.568382 17579 compress_conv_layer.cu:174] 0.7 1.97999e-12 0.57233
I0621 23:47:11.615041 17579 compress_conv_layer.cu:174] 0.7 5.45158e-12 0.453947
I0621 23:47:11.704371 17579 compress_conv_layer.cu:174] 0.7 1.63046e-12 0.325496
I0621 23:47:11.888151 17579 compress_conv_layer.cu:174] 0.7 3.35863e-12 0.290755
I0621 23:47:11.910461 17579 compress_conv_layer.cu:174] 0.7 3.12235e-07 0.191221
I0621 23:47:12.391633 17579 solver.cpp:219] Iteration 27000 (0.299426 iter/s, 166.986s/50 iters), loss = 0.00467756
I0621 23:47:12.391724 17579 solver.cpp:238]     Train net output #0: loss = 0.00736118 (* 1 = 0.00736118 loss)
I0621 23:47:12.391752 17579 sgd_solver.cpp:105] Iteration 27000, lr = 0.0005
I0621 23:49:40.320652 17579 solver.cpp:219] Iteration 27050 (0.338005 iter/s, 147.927s/50 iters), loss = 0.00673656
I0621 23:49:40.320830 17579 solver.cpp:238]     Train net output #0: loss = 0.00459555 (* 1 = 0.00459555 loss)
I0621 23:49:40.320861 17579 sgd_solver.cpp:105] Iteration 27050, lr = 0.0005
I0621 23:52:08.279050 17579 solver.cpp:219] Iteration 27100 (0.337939 iter/s, 147.956s/50 iters), loss = 0.0049117
I0621 23:52:08.279203 17579 solver.cpp:238]     Train net output #0: loss = 0.00345694 (* 1 = 0.00345694 loss)
I0621 23:52:08.279235 17579 sgd_solver.cpp:105] Iteration 27100, lr = 0.0005
I0621 23:54:36.336184 17579 solver.cpp:219] Iteration 27150 (0.337716 iter/s, 148.053s/50 iters), loss = 0.0048732
I0621 23:54:36.336335 17579 solver.cpp:238]     Train net output #0: loss = 0.00328196 (* 1 = 0.00328196 loss)
I0621 23:54:36.336364 17579 sgd_solver.cpp:105] Iteration 27150, lr = 0.0005
I0621 23:57:04.273901 17579 solver.cpp:219] Iteration 27200 (0.337987 iter/s, 147.935s/50 iters), loss = 0.0077595
I0621 23:57:04.274040 17579 solver.cpp:238]     Train net output #0: loss = 0.00504235 (* 1 = 0.00504235 loss)
I0621 23:57:04.274071 17579 sgd_solver.cpp:105] Iteration 27200, lr = 0.0005
I0621 23:59:22.414517 17579 solver.cpp:219] Iteration 27250 (0.361957 iter/s, 138.138s/50 iters), loss = 0.0059111
I0621 23:59:22.414675 17579 solver.cpp:238]     Train net output #0: loss = 0.00622225 (* 1 = 0.00622225 loss)
I0621 23:59:22.414705 17579 sgd_solver.cpp:105] Iteration 27250, lr = 0.0005
I0622 00:01:50.361726 17579 solver.cpp:219] Iteration 27300 (0.337964 iter/s, 147.945s/50 iters), loss = 0.0105861
I0622 00:01:50.361933 17579 solver.cpp:238]     Train net output #0: loss = 0.0119838 (* 1 = 0.0119838 loss)
I0622 00:01:50.361964 17579 sgd_solver.cpp:105] Iteration 27300, lr = 0.0005
I0622 00:04:18.215989 17579 solver.cpp:219] Iteration 27350 (0.338177 iter/s, 147.852s/50 iters), loss = 0.00748935
I0622 00:04:18.216145 17579 solver.cpp:238]     Train net output #0: loss = 0.00439028 (* 1 = 0.00439028 loss)
I0622 00:04:18.216172 17579 sgd_solver.cpp:105] Iteration 27350, lr = 0.0005
I0622 00:06:46.195911 17579 solver.cpp:219] Iteration 27400 (0.337888 iter/s, 147.978s/50 iters), loss = 0.00774102
I0622 00:06:46.196038 17579 solver.cpp:238]     Train net output #0: loss = 0.00836622 (* 1 = 0.00836622 loss)
I0622 00:06:46.196068 17579 sgd_solver.cpp:105] Iteration 27400, lr = 0.0005
I0622 00:09:14.152081 17579 solver.cpp:219] Iteration 27450 (0.337944 iter/s, 147.953s/50 iters), loss = 0.00662373
I0622 00:09:14.152235 17579 solver.cpp:238]     Train net output #0: loss = 0.00313553 (* 1 = 0.00313553 loss)
I0622 00:09:14.152262 17579 sgd_solver.cpp:105] Iteration 27450, lr = 0.0005
I0622 00:11:39.145287 17579 solver.cpp:331] Iteration 27500, Testing net (#0)
I0622 00:11:55.681046 17579 solver.cpp:398]     Test net output #0: accuracy = 0.980392
I0622 00:11:55.681123 17579 solver.cpp:398]     Test net output #1: loss = 0.0870652 (* 1 = 0.0870652 loss)
I0622 00:11:58.576447 17579 solver.cpp:219] Iteration 27500 (0.304097 iter/s, 164.421s/50 iters), loss = 0.0128818
I0622 00:11:58.576548 17579 solver.cpp:238]     Train net output #0: loss = 0.00871409 (* 1 = 0.00871409 loss)
I0622 00:11:58.576581 17579 sgd_solver.cpp:105] Iteration 27500, lr = 0.0005
I0622 00:14:26.442566 17579 solver.cpp:219] Iteration 27550 (0.338148 iter/s, 147.864s/50 iters), loss = 0.00641656
I0622 00:14:26.442708 17579 solver.cpp:238]     Train net output #0: loss = 0.00360027 (* 1 = 0.00360027 loss)
I0622 00:14:26.442754 17579 sgd_solver.cpp:105] Iteration 27550, lr = 0.0005
I0622 00:16:54.447664 17579 solver.cpp:219] Iteration 27600 (0.337832 iter/s, 148.002s/50 iters), loss = 0.0062776
I0622 00:16:54.447829 17579 solver.cpp:238]     Train net output #0: loss = 0.00308645 (* 1 = 0.00308645 loss)
I0622 00:16:54.447857 17579 sgd_solver.cpp:105] Iteration 27600, lr = 0.0005
I0622 00:19:21.827088 17579 solver.cpp:219] Iteration 27650 (0.339267 iter/s, 147.377s/50 iters), loss = 0.00872977
I0622 00:19:21.827239 17579 solver.cpp:238]     Train net output #0: loss = 0.00407303 (* 1 = 0.00407303 loss)
I0622 00:19:21.827270 17579 sgd_solver.cpp:105] Iteration 27650, lr = 0.0005
I0622 00:21:40.581212 17579 solver.cpp:219] Iteration 27700 (0.360354 iter/s, 138.752s/50 iters), loss = 0.00724376
I0622 00:21:40.581377 17579 solver.cpp:238]     Train net output #0: loss = 0.00547591 (* 1 = 0.00547591 loss)
I0622 00:21:40.581406 17579 sgd_solver.cpp:105] Iteration 27700, lr = 0.0005
I0622 00:24:08.437238 17579 solver.cpp:219] Iteration 27750 (0.338173 iter/s, 147.853s/50 iters), loss = 0.0116498
I0622 00:24:08.437389 17579 solver.cpp:238]     Train net output #0: loss = 0.0128816 (* 1 = 0.0128816 loss)
I0622 00:24:08.437423 17579 sgd_solver.cpp:105] Iteration 27750, lr = 0.0005
I0622 00:26:36.311013 17579 solver.cpp:219] Iteration 27800 (0.338133 iter/s, 147.871s/50 iters), loss = 0.00340349
I0622 00:26:36.311184 17579 solver.cpp:238]     Train net output #0: loss = 0.00375106 (* 1 = 0.00375106 loss)
I0622 00:26:36.311218 17579 sgd_solver.cpp:105] Iteration 27800, lr = 0.0005
I0622 00:29:04.260560 17579 solver.cpp:219] Iteration 27850 (0.337959 iter/s, 147.947s/50 iters), loss = 0.00686267
I0622 00:29:04.260742 17579 solver.cpp:238]     Train net output #0: loss = 0.00960092 (* 1 = 0.00960092 loss)
I0622 00:29:04.260771 17579 sgd_solver.cpp:105] Iteration 27850, lr = 0.0005
I0622 00:31:32.167659 17579 solver.cpp:219] Iteration 27900 (0.338056 iter/s, 147.904s/50 iters), loss = 0.00811994
I0622 00:31:32.167847 17579 solver.cpp:238]     Train net output #0: loss = 0.00810553 (* 1 = 0.00810553 loss)
I0622 00:31:32.167879 17579 sgd_solver.cpp:105] Iteration 27900, lr = 0.0005
I0622 00:34:00.136194 17579 solver.cpp:219] Iteration 27950 (0.337917 iter/s, 147.965s/50 iters), loss = 0.00545604
I0622 00:34:00.136358 17579 solver.cpp:238]     Train net output #0: loss = 0.00482096 (* 1 = 0.00482096 loss)
I0622 00:34:00.136392 17579 sgd_solver.cpp:105] Iteration 27950, lr = 0.0005
I0622 00:36:25.130363 17579 solver.cpp:448] Snapshotting to binary proto file mobilenet/mobile_pruning_iter_28000.caffemodel
I0622 00:36:25.255012 17579 sgd_solver.cpp:273] Snapshotting solver state to binary proto file mobilenet/mobile_pruning_iter_28000.solverstate
I0622 00:36:25.311342 17579 solver.cpp:331] Iteration 28000, Testing net (#0)
I0622 00:36:41.719676 17579 solver.cpp:398]     Test net output #0: accuracy = 0.983333
I0622 00:36:41.719769 17579 solver.cpp:398]     Test net output #1: loss = 0.0828592 (* 1 = 0.0828592 loss)
I0622 00:36:44.625433 17579 solver.cpp:219] Iteration 28000 (0.303975 iter/s, 164.487s/50 iters), loss = 0.0107777
I0622 00:36:44.625540 17579 solver.cpp:238]     Train net output #0: loss = 0.00305143 (* 1 = 0.00305143 loss)
I0622 00:36:44.625573 17579 sgd_solver.cpp:105] Iteration 28000, lr = 0.0005
I0622 00:39:12.507298 17579 solver.cpp:219] Iteration 28050 (0.338112 iter/s, 147.88s/50 iters), loss = 0.00637123
I0622 00:39:12.507447 17579 solver.cpp:238]     Train net output #0: loss = 0.00770323 (* 1 = 0.00770323 loss)
I0622 00:39:12.507479 17579 sgd_solver.cpp:105] Iteration 28050, lr = 0.0005
I0622 00:41:38.902729 17579 solver.cpp:219] Iteration 28100 (0.341548 iter/s, 146.392s/50 iters), loss = 0.0060587
I0622 00:41:38.902885 17579 solver.cpp:238]     Train net output #0: loss = 0.00799335 (* 1 = 0.00799335 loss)
I0622 00:41:38.902915 17579 sgd_solver.cpp:105] Iteration 28100, lr = 0.0005
I0622 00:43:58.790572 17579 solver.cpp:219] Iteration 28150 (0.357434 iter/s, 139.886s/50 iters), loss = 0.00704827
I0622 00:43:58.790787 17579 solver.cpp:238]     Train net output #0: loss = 0.0033906 (* 1 = 0.0033906 loss)
I0622 00:43:58.790817 17579 sgd_solver.cpp:105] Iteration 28150, lr = 0.0005
I0622 00:46:26.731171 17579 solver.cpp:219] Iteration 28200 (0.337983 iter/s, 147.937s/50 iters), loss = 0.00906303
I0622 00:46:26.731318 17579 solver.cpp:238]     Train net output #0: loss = 0.00243218 (* 1 = 0.00243218 loss)
I0622 00:46:26.731351 17579 sgd_solver.cpp:105] Iteration 28200, lr = 0.0005
I0622 00:48:54.676731 17579 solver.cpp:219] Iteration 28250 (0.337968 iter/s, 147.943s/50 iters), loss = 0.00600839
I0622 00:48:54.676898 17579 solver.cpp:238]     Train net output #0: loss = 0.0133795 (* 1 = 0.0133795 loss)
I0622 00:48:54.676929 17579 sgd_solver.cpp:105] Iteration 28250, lr = 0.0005
I0622 00:51:22.584452 17579 solver.cpp:219] Iteration 28300 (0.338055 iter/s, 147.905s/50 iters), loss = 0.00902148
I0622 00:51:22.584619 17579 solver.cpp:238]     Train net output #0: loss = 0.00991212 (* 1 = 0.00991212 loss)
I0622 00:51:22.584653 17579 sgd_solver.cpp:105] Iteration 28300, lr = 0.0005
I0622 00:53:50.544782 17579 solver.cpp:219] Iteration 28350 (0.337935 iter/s, 147.958s/50 iters), loss = 0.00532615
I0622 00:53:50.544924 17579 solver.cpp:238]     Train net output #0: loss = 0.00628373 (* 1 = 0.00628373 loss)
I0622 00:53:50.544955 17579 sgd_solver.cpp:105] Iteration 28350, lr = 0.0005
I0622 00:56:18.513240 17579 solver.cpp:219] Iteration 28400 (0.337914 iter/s, 147.967s/50 iters), loss = 0.00589272
I0622 00:56:18.513380 17579 solver.cpp:238]     Train net output #0: loss = 0.00428414 (* 1 = 0.00428414 loss)
I0622 00:56:18.513411 17579 sgd_solver.cpp:105] Iteration 28400, lr = 0.0005
I0622 00:58:46.412557 17579 solver.cpp:219] Iteration 28450 (0.338075 iter/s, 147.896s/50 iters), loss = 0.0104705
I0622 00:58:46.412709 17579 solver.cpp:238]     Train net output #0: loss = 0.0089026 (* 1 = 0.0089026 loss)
I0622 00:58:46.412739 17579 sgd_solver.cpp:105] Iteration 28450, lr = 0.0005
I0622 01:01:11.405220 17579 solver.cpp:331] Iteration 28500, Testing net (#0)
I0622 01:01:27.912461 17579 solver.cpp:398]     Test net output #0: accuracy = 0.985294
I0622 01:01:27.912554 17579 solver.cpp:398]     Test net output #1: loss = 0.0830486 (* 1 = 0.0830486 loss)
I0622 01:01:27.930061 17579 compress_conv_layer.cu:174] 0.711401 1.8323e-10 0.941725
I0622 01:01:27.945503 17579 compress_conv_layer.cu:174] 0.711401 1.11733e-10 0.551067
I0622 01:01:27.960726 17579 compress_conv_layer.cu:174] 0.711401 2.00747e-11 0.738469
I0622 01:01:27.972944 17579 compress_conv_layer.cu:174] 0.711401 3.05658e-12 0.778688
I0622 01:01:27.990083 17579 compress_conv_layer.cu:174] 0.711401 9.76371e-12 0.455136
I0622 01:01:28.014708 17579 compress_conv_layer.cu:174] 0.711401 9.36948e-14 0.480616
I0622 01:01:28.061017 17579 compress_conv_layer.cu:174] 0.711401 1.70131e-13 0.472803
I0622 01:01:28.106606 17579 compress_conv_layer.cu:174] 0.711401 2.16652e-12 0.401947
I0622 01:01:28.153100 17579 compress_conv_layer.cu:174] 0.711401 1.88293e-12 0.427123
I0622 01:01:28.199271 17579 compress_conv_layer.cu:174] 0.711401 1.97933e-12 0.572084
I0622 01:01:28.245522 17579 compress_conv_layer.cu:174] 0.711401 5.44963e-12 0.453705
I0622 01:01:28.334805 17579 compress_conv_layer.cu:174] 0.711401 1.62981e-12 0.325342
I0622 01:01:28.520792 17579 compress_conv_layer.cu:174] 0.711401 3.35732e-12 0.290634
I0622 01:01:28.542454 17579 compress_conv_layer.cu:174] 0.711401 3.12107e-07 0.191791
I0622 01:01:29.039903 17579 compress_conv_layer.cu:174] 0.711401 1.8323e-10 0.941725
I0622 01:01:29.055995 17579 compress_conv_layer.cu:174] 0.711401 1.11733e-10 0.551067
I0622 01:01:29.068891 17579 compress_conv_layer.cu:174] 0.711401 2.00747e-11 0.738469
I0622 01:01:29.082738 17579 compress_conv_layer.cu:174] 0.711401 3.05658e-12 0.778688
I0622 01:01:29.098577 17579 compress_conv_layer.cu:174] 0.711401 9.76371e-12 0.455136
I0622 01:01:29.125036 17579 compress_conv_layer.cu:174] 0.711401 9.36948e-14 0.480616
I0622 01:01:29.170912 17579 compress_conv_layer.cu:174] 0.711401 1.70131e-13 0.472803
I0622 01:01:29.216776 17579 compress_conv_layer.cu:174] 0.711401 2.16652e-12 0.401947
I0622 01:01:29.260531 17579 compress_conv_layer.cu:174] 0.711401 1.88293e-12 0.427123
I0622 01:01:29.305984 17579 compress_conv_layer.cu:174] 0.711401 1.97933e-12 0.572084
I0622 01:01:29.352082 17579 compress_conv_layer.cu:174] 0.711401 5.44963e-12 0.453705
I0622 01:01:29.442168 17579 compress_conv_layer.cu:174] 0.711401 1.62981e-12 0.325342
I0622 01:01:29.625800 17579 compress_conv_layer.cu:174] 0.711401 3.35732e-12 0.290634
I0622 01:01:29.646144 17579 compress_conv_layer.cu:174] 0.711401 3.12107e-07 0.191791
I0622 01:01:30.141077 17579 compress_conv_layer.cu:174] 0.711401 1.8323e-10 0.941725
I0622 01:01:30.157807 17579 compress_conv_layer.cu:174] 0.711401 1.11733e-10 0.551067
I0622 01:01:30.170615 17579 compress_conv_layer.cu:174] 0.711401 2.00747e-11 0.738469
I0622 01:01:30.186025 17579 compress_conv_layer.cu:174] 0.711401 3.05658e-12 0.778688
I0622 01:01:30.202181 17579 compress_conv_layer.cu:174] 0.711401 9.76371e-12 0.455136
I0622 01:01:30.227051 17579 compress_conv_layer.cu:174] 0.711401 9.36948e-14 0.480616
I0622 01:01:30.274005 17579 compress_conv_layer.cu:174] 0.711401 1.70131e-13 0.472803
I0622 01:01:30.320869 17579 compress_conv_layer.cu:174] 0.711401 2.16652e-12 0.401947
I0622 01:01:30.369313 17579 compress_conv_layer.cu:174] 0.711401 1.88293e-12 0.427123
I0622 01:01:30.416263 17579 compress_conv_layer.cu:174] 0.711401 1.97933e-12 0.572084
I0622 01:01:30.462023 17579 compress_conv_layer.cu:174] 0.711401 5.44963e-12 0.453705
I0622 01:01:30.551971 17579 compress_conv_layer.cu:174] 0.711401 1.62981e-12 0.325342
I0622 01:01:30.735075 17579 compress_conv_layer.cu:174] 0.711401 3.35732e-12 0.290634
I0622 01:01:30.759073 17579 compress_conv_layer.cu:174] 0.711401 3.12107e-07 0.191791
I0622 01:01:31.258247 17579 compress_conv_layer.cu:174] 0.711401 1.8323e-10 0.941725
I0622 01:01:31.274343 17579 compress_conv_layer.cu:174] 0.711401 1.11733e-10 0.551067
I0622 01:01:31.287226 17579 compress_conv_layer.cu:174] 0.711401 2.00747e-11 0.738469
I0622 01:01:31.301079 17579 compress_conv_layer.cu:174] 0.711401 3.05658e-12 0.778688
I0622 01:01:31.318198 17579 compress_conv_layer.cu:174] 0.711401 9.76371e-12 0.455136
I0622 01:01:31.343570 17579 compress_conv_layer.cu:174] 0.711401 9.36948e-14 0.480616
I0622 01:01:31.389935 17579 compress_conv_layer.cu:174] 0.711401 1.70131e-13 0.472803
I0622 01:01:31.436480 17579 compress_conv_layer.cu:174] 0.711401 2.16652e-12 0.401947
I0622 01:01:31.482424 17579 compress_conv_layer.cu:174] 0.711401 1.88293e-12 0.427123
I0622 01:01:31.529485 17579 compress_conv_layer.cu:174] 0.711401 1.97933e-12 0.572084
I0622 01:01:31.577489 17579 compress_conv_layer.cu:174] 0.711401 5.44963e-12 0.453705
I0622 01:01:31.672040 17579 compress_conv_layer.cu:174] 0.711401 1.62981e-12 0.325342
I0622 01:01:31.859915 17579 compress_conv_layer.cu:174] 0.711401 3.35732e-12 0.290634
I0622 01:01:31.880430 17579 compress_conv_layer.cu:174] 0.711401 3.12107e-07 0.191791
I0622 01:01:32.371776 17579 compress_conv_layer.cu:174] 0.711401 1.8323e-10 0.941725
I0622 01:01:32.390619 17579 compress_conv_layer.cu:174] 0.711401 1.11733e-10 0.551067
I0622 01:01:32.405401 17579 compress_conv_layer.cu:174] 0.711401 2.00747e-11 0.738469
I0622 01:01:32.418993 17579 compress_conv_layer.cu:174] 0.711401 3.05658e-12 0.778688
I0622 01:01:32.435286 17579 compress_conv_layer.cu:174] 0.711401 9.76371e-12 0.455136
I0622 01:01:32.459991 17579 compress_conv_layer.cu:174] 0.711401 9.36948e-14 0.480616
I0622 01:01:32.505110 17579 compress_conv_layer.cu:174] 0.711401 1.70131e-13 0.472803
I0622 01:01:32.553558 17579 compress_conv_layer.cu:174] 0.711401 2.16652e-12 0.401947
I0622 01:01:32.600338 17579 compress_conv_layer.cu:174] 0.711401 1.88293e-12 0.427123
I0622 01:01:32.645403 17579 compress_conv_layer.cu:174] 0.711401 1.97933e-12 0.572084
I0622 01:01:32.691107 17579 compress_conv_layer.cu:174] 0.711401 5.44963e-12 0.453705
I0622 01:01:32.781271 17579 compress_conv_layer.cu:174] 0.711401 1.62981e-12 0.325342
I0622 01:01:32.964716 17579 compress_conv_layer.cu:174] 0.711401 3.35732e-12 0.290634
I0622 01:01:32.986958 17579 compress_conv_layer.cu:174] 0.711401 3.12107e-07 0.191791
I0622 01:01:33.470814 17579 solver.cpp:219] Iteration 28500 (0.299302 iter/s, 167.055s/50 iters), loss = 0.00787552
I0622 01:01:33.470906 17579 solver.cpp:238]     Train net output #0: loss = 0.00837397 (* 1 = 0.00837397 loss)
I0622 01:01:33.470934 17579 sgd_solver.cpp:105] Iteration 28500, lr = 0.0005
I0622 01:03:57.036501 17579 solver.cpp:219] Iteration 28550 (0.348278 iter/s, 143.563s/50 iters), loss = 0.00646728
I0622 01:03:57.036677 17579 solver.cpp:238]     Train net output #0: loss = 0.00464668 (* 1 = 0.00464668 loss)
I0622 01:03:57.036710 17579 sgd_solver.cpp:105] Iteration 28550, lr = 0.0005
I0622 01:06:19.645400 17579 solver.cpp:219] Iteration 28600 (0.350616 iter/s, 142.606s/50 iters), loss = 0.0096772
I0622 01:06:19.645692 17579 solver.cpp:238]     Train net output #0: loss = 0.00686223 (* 1 = 0.00686223 loss)
I0622 01:06:19.645722 17579 sgd_solver.cpp:105] Iteration 28600, lr = 0.0005
I0622 01:08:47.532568 17579 solver.cpp:219] Iteration 28650 (0.338101 iter/s, 147.885s/50 iters), loss = 0.0092117
I0622 01:08:47.532722 17579 solver.cpp:238]     Train net output #0: loss = 0.00420677 (* 1 = 0.00420677 loss)
I0622 01:08:47.532752 17579 sgd_solver.cpp:105] Iteration 28650, lr = 0.0005
I0622 01:11:15.496075 17579 solver.cpp:219] Iteration 28700 (0.337927 iter/s, 147.961s/50 iters), loss = 0.0076401
I0622 01:11:15.496245 17579 solver.cpp:238]     Train net output #0: loss = 0.0037155 (* 1 = 0.0037155 loss)
I0622 01:11:15.496282 17579 sgd_solver.cpp:105] Iteration 28700, lr = 0.0005
I0622 01:13:43.380264 17579 solver.cpp:219] Iteration 28750 (0.338108 iter/s, 147.882s/50 iters), loss = 0.00645829
I0622 01:13:43.380496 17579 solver.cpp:238]     Train net output #0: loss = 0.00426415 (* 1 = 0.00426415 loss)
I0622 01:13:43.380544 17579 sgd_solver.cpp:105] Iteration 28750, lr = 0.0005
I0622 01:16:11.367278 17579 solver.cpp:219] Iteration 28800 (0.337873 iter/s, 147.985s/50 iters), loss = 0.00832769
I0622 01:16:11.367491 17579 solver.cpp:238]     Train net output #0: loss = 0.0051595 (* 1 = 0.0051595 loss)
I0622 01:16:11.367523 17579 sgd_solver.cpp:105] Iteration 28800, lr = 0.0005
I0622 01:18:39.298820 17579 solver.cpp:219] Iteration 28850 (0.338 iter/s, 147.929s/50 iters), loss = 0.0131174
I0622 01:18:39.299047 17579 solver.cpp:238]     Train net output #0: loss = 0.00915052 (* 1 = 0.00915052 loss)
I0622 01:18:39.299077 17579 sgd_solver.cpp:105] Iteration 28850, lr = 0.0005
I0622 01:21:07.260161 17579 solver.cpp:219] Iteration 28900 (0.337932 iter/s, 147.959s/50 iters), loss = 0.00795753
I0622 01:21:07.260318 17579 solver.cpp:238]     Train net output #0: loss = 0.0124226 (* 1 = 0.0124226 loss)
I0622 01:21:07.260347 17579 sgd_solver.cpp:105] Iteration 28900, lr = 0.0005
I0622 01:23:35.277871 17579 solver.cpp:219] Iteration 28950 (0.337803 iter/s, 148.015s/50 iters), loss = 0.00732463
I0622 01:23:35.278031 17579 solver.cpp:238]     Train net output #0: loss = 0.00730435 (* 1 = 0.00730435 loss)
I0622 01:23:35.278060 17579 sgd_solver.cpp:105] Iteration 28950, lr = 0.0005
I0622 01:26:00.269676 17579 solver.cpp:331] Iteration 29000, Testing net (#0)
I0622 01:26:15.560850 17579 solver.cpp:398]     Test net output #0: accuracy = 0.982353
I0622 01:26:15.560943 17579 solver.cpp:398]     Test net output #1: loss = 0.0867786 (* 1 = 0.0867786 loss)
I0622 01:26:17.498085 17579 solver.cpp:219] Iteration 29000 (0.308228 iter/s, 162.217s/50 iters), loss = 0.0119629
I0622 01:26:17.498188 17579 solver.cpp:238]     Train net output #0: loss = 0.00320447 (* 1 = 0.00320447 loss)
I0622 01:26:17.498215 17579 sgd_solver.cpp:105] Iteration 29000, lr = 0.0005
I0622 01:28:41.038378 17579 solver.cpp:219] Iteration 29050 (0.348341 iter/s, 143.538s/50 iters), loss = 0.0133236
I0622 01:28:41.038539 17579 solver.cpp:238]     Train net output #0: loss = 0.0129785 (* 1 = 0.0129785 loss)
I0622 01:28:41.038566 17579 sgd_solver.cpp:105] Iteration 29050, lr = 0.0005
I0622 01:31:08.890794 17579 solver.cpp:219] Iteration 29100 (0.338181 iter/s, 147.85s/50 iters), loss = 0.00731916
I0622 01:31:08.891047 17579 solver.cpp:238]     Train net output #0: loss = 0.0068264 (* 1 = 0.0068264 loss)
I0622 01:31:08.891079 17579 sgd_solver.cpp:105] Iteration 29100, lr = 0.0005
I0622 01:33:36.798979 17579 solver.cpp:219] Iteration 29150 (0.338055 iter/s, 147.905s/50 iters), loss = 0.00887996
I0622 01:33:36.799125 17579 solver.cpp:238]     Train net output #0: loss = 0.0142974 (* 1 = 0.0142974 loss)
I0622 01:33:36.799155 17579 sgd_solver.cpp:105] Iteration 29150, lr = 0.0005
I0622 01:36:04.692831 17579 solver.cpp:219] Iteration 29200 (0.338088 iter/s, 147.89s/50 iters), loss = 0.00585875
I0622 01:36:04.693018 17579 solver.cpp:238]     Train net output #0: loss = 0.00352803 (* 1 = 0.00352803 loss)
I0622 01:36:04.693048 17579 sgd_solver.cpp:105] Iteration 29200, lr = 0.0005
I0622 01:38:32.550137 17579 solver.cpp:219] Iteration 29250 (0.33817 iter/s, 147.854s/50 iters), loss = 0.00777742
I0622 01:38:32.550310 17579 solver.cpp:238]     Train net output #0: loss = 0.00828166 (* 1 = 0.00828166 loss)
I0622 01:38:32.550360 17579 sgd_solver.cpp:105] Iteration 29250, lr = 0.0005
I0622 01:41:00.485805 17579 solver.cpp:219] Iteration 29300 (0.337991 iter/s, 147.933s/50 iters), loss = 0.0112663
I0622 01:41:00.485975 17579 solver.cpp:238]     Train net output #0: loss = 0.0124753 (* 1 = 0.0124753 loss)
I0622 01:41:00.486004 17579 sgd_solver.cpp:105] Iteration 29300, lr = 0.0005
I0622 01:43:28.464073 17579 solver.cpp:219] Iteration 29350 (0.337893 iter/s, 147.976s/50 iters), loss = 0.00910106
I0622 01:43:28.464216 17579 solver.cpp:238]     Train net output #0: loss = 0.0164224 (* 1 = 0.0164224 loss)
I0622 01:43:28.464246 17579 sgd_solver.cpp:105] Iteration 29350, lr = 0.0005
I0622 01:45:56.400717 17579 solver.cpp:219] Iteration 29400 (0.337988 iter/s, 147.934s/50 iters), loss = 0.00940941
I0622 01:45:56.400871 17579 solver.cpp:238]     Train net output #0: loss = 0.0114509 (* 1 = 0.0114509 loss)
I0622 01:45:56.400900 17579 sgd_solver.cpp:105] Iteration 29400, lr = 0.0005
I0622 01:48:24.158613 17579 solver.cpp:219] Iteration 29450 (0.338398 iter/s, 147.755s/50 iters), loss = 0.00910181
I0622 01:48:24.158812 17579 solver.cpp:238]     Train net output #0: loss = 0.0135644 (* 1 = 0.0135644 loss)
I0622 01:48:24.158841 17579 sgd_solver.cpp:105] Iteration 29450, lr = 0.0005
I0622 01:50:39.386216 17579 solver.cpp:331] Iteration 29500, Testing net (#0)
I0622 01:50:55.849247 17579 solver.cpp:398]     Test net output #0: accuracy = 0.980392
I0622 01:50:55.849333 17579 solver.cpp:398]     Test net output #1: loss = 0.0845041 (* 1 = 0.0845041 loss)
I0622 01:50:58.779355 17579 solver.cpp:219] Iteration 29500 (0.323376 iter/s, 154.619s/50 iters), loss = 0.00667674
I0622 01:50:58.779451 17579 solver.cpp:238]     Train net output #0: loss = 0.0125082 (* 1 = 0.0125082 loss)
I0622 01:50:58.779484 17579 sgd_solver.cpp:105] Iteration 29500, lr = 0.0005
I0622 01:53:26.788256 17579 solver.cpp:219] Iteration 29550 (0.337824 iter/s, 148.006s/50 iters), loss = 0.00620431
I0622 01:53:26.788415 17579 solver.cpp:238]     Train net output #0: loss = 0.00355684 (* 1 = 0.00355684 loss)
I0622 01:53:26.788444 17579 sgd_solver.cpp:105] Iteration 29550, lr = 0.0005
I0622 01:55:54.723536 17579 solver.cpp:219] Iteration 29600 (0.337992 iter/s, 147.932s/50 iters), loss = 0.00555473
I0622 01:55:54.723726 17579 solver.cpp:238]     Train net output #0: loss = 0.00317647 (* 1 = 0.00317647 loss)
I0622 01:55:54.723755 17579 sgd_solver.cpp:105] Iteration 29600, lr = 0.0005
I0622 01:58:22.658493 17579 solver.cpp:219] Iteration 29650 (0.337993 iter/s, 147.932s/50 iters), loss = 0.00575518
I0622 01:58:22.658646 17579 solver.cpp:238]     Train net output #0: loss = 0.00789517 (* 1 = 0.00789517 loss)
I0622 01:58:22.658676 17579 sgd_solver.cpp:105] Iteration 29650, lr = 0.0005
I0622 02:00:50.561589 17579 solver.cpp:219] Iteration 29700 (0.338066 iter/s, 147.9s/50 iters), loss = 0.00766794
I0622 02:00:50.561734 17579 solver.cpp:238]     Train net output #0: loss = 0.00998924 (* 1 = 0.00998924 loss)
I0622 02:00:50.561764 17579 sgd_solver.cpp:105] Iteration 29700, lr = 0.0005
I0622 02:03:18.520020 17579 solver.cpp:219] Iteration 29750 (0.337939 iter/s, 147.956s/50 iters), loss = 0.00671135
I0622 02:03:18.520175 17579 solver.cpp:238]     Train net output #0: loss = 0.00592426 (* 1 = 0.00592426 loss)
I0622 02:03:18.520206 17579 sgd_solver.cpp:105] Iteration 29750, lr = 0.0005
I0622 02:05:46.407729 17579 solver.cpp:219] Iteration 29800 (0.338103 iter/s, 147.884s/50 iters), loss = 0.00623382
I0622 02:05:46.407897 17579 solver.cpp:238]     Train net output #0: loss = 0.00415074 (* 1 = 0.00415074 loss)
I0622 02:05:46.407929 17579 sgd_solver.cpp:105] Iteration 29800, lr = 0.0005
I0622 02:08:14.366804 17579 solver.cpp:219] Iteration 29850 (0.337941 iter/s, 147.955s/50 iters), loss = 0.00541185
I0622 02:08:14.367008 17579 solver.cpp:238]     Train net output #0: loss = 0.00664622 (* 1 = 0.00664622 loss)
I0622 02:08:14.367041 17579 sgd_solver.cpp:105] Iteration 29850, lr = 0.0005
I0622 02:10:42.307307 17579 solver.cpp:219] Iteration 29900 (0.337985 iter/s, 147.936s/50 iters), loss = 0.00863176
I0622 02:10:42.307461 17579 solver.cpp:238]     Train net output #0: loss = 0.0101805 (* 1 = 0.0101805 loss)
I0622 02:10:42.307492 17579 sgd_solver.cpp:105] Iteration 29900, lr = 0.0005
I0622 02:13:00.466269 17579 solver.cpp:219] Iteration 29950 (0.361909 iter/s, 138.156s/50 iters), loss = 0.0100304
I0622 02:13:00.466420 17579 solver.cpp:238]     Train net output #0: loss = 0.00579203 (* 1 = 0.00579203 loss)
I0622 02:13:00.466450 17579 sgd_solver.cpp:105] Iteration 29950, lr = 0.0005
I0622 02:15:25.513794 17579 solver.cpp:331] Iteration 30000, Testing net (#0)
I0622 02:15:41.015135 17579 blocking_queue.cpp:49] Waiting for data
I0622 02:15:42.004375 17579 solver.cpp:398]     Test net output #0: accuracy = 0.980392
I0622 02:15:42.004453 17579 solver.cpp:398]     Test net output #1: loss = 0.0868887 (* 1 = 0.0868887 loss)
I0622 02:15:44.929378 17579 solver.cpp:219] Iteration 30000 (0.304025 iter/s, 164.46s/50 iters), loss = 0.00654125
I0622 02:15:44.929471 17579 solver.cpp:238]     Train net output #0: loss = 0.0047049 (* 1 = 0.0047049 loss)
I0622 02:15:44.929499 17579 sgd_solver.cpp:105] Iteration 30000, lr = 0.0005
I0622 02:18:12.955694 17579 solver.cpp:219] Iteration 30050 (0.337782 iter/s, 148.025s/50 iters), loss = 0.00702304
I0622 02:18:12.955934 17579 solver.cpp:238]     Train net output #0: loss = 0.00557827 (* 1 = 0.00557827 loss)
I0622 02:18:12.955963 17579 sgd_solver.cpp:105] Iteration 30050, lr = 0.0005
I0622 02:20:40.864037 17579 solver.cpp:219] Iteration 30100 (0.338053 iter/s, 147.906s/50 iters), loss = 0.00638617
I0622 02:20:40.864181 17579 solver.cpp:238]     Train net output #0: loss = 0.00731175 (* 1 = 0.00731175 loss)
I0622 02:20:40.864214 17579 sgd_solver.cpp:105] Iteration 30100, lr = 0.0005
I0622 02:23:08.710829 17579 solver.cpp:219] Iteration 30150 (0.338195 iter/s, 147.844s/50 iters), loss = 0.00732926
I0622 02:23:08.711014 17579 solver.cpp:238]     Train net output #0: loss = 0.00610498 (* 1 = 0.00610498 loss)
I0622 02:23:08.711042 17579 sgd_solver.cpp:105] Iteration 30150, lr = 0.0005
I0622 02:25:36.615795 17579 solver.cpp:219] Iteration 30200 (0.338062 iter/s, 147.902s/50 iters), loss = 0.00599137
I0622 02:25:36.616060 17579 solver.cpp:238]     Train net output #0: loss = 0.00666746 (* 1 = 0.00666746 loss)
I0622 02:25:36.616089 17579 sgd_solver.cpp:105] Iteration 30200, lr = 0.0005
I0622 02:28:04.478823 17579 solver.cpp:219] Iteration 30250 (0.338158 iter/s, 147.86s/50 iters), loss = 0.00886318
I0622 02:28:04.479017 17579 solver.cpp:238]     Train net output #0: loss = 0.00205021 (* 1 = 0.00205021 loss)
I0622 02:28:04.479048 17579 sgd_solver.cpp:105] Iteration 30250, lr = 0.0005
I0622 02:30:32.498980 17579 solver.cpp:219] Iteration 30300 (0.337799 iter/s, 148.017s/50 iters), loss = 0.00789369
I0622 02:30:32.499136 17579 solver.cpp:238]     Train net output #0: loss = 0.00347003 (* 1 = 0.00347003 loss)
I0622 02:30:32.499166 17579 sgd_solver.cpp:105] Iteration 30300, lr = 0.0005
I0622 02:33:00.472800 17579 solver.cpp:219] Iteration 30350 (0.337905 iter/s, 147.971s/50 iters), loss = 0.009329
I0622 02:33:00.472962 17579 solver.cpp:238]     Train net output #0: loss = 0.00947858 (* 1 = 0.00947858 loss)
I0622 02:33:00.472990 17579 sgd_solver.cpp:105] Iteration 30350, lr = 0.0005
I0622 02:35:18.705036 17579 solver.cpp:219] Iteration 30400 (0.361716 iter/s, 138.23s/50 iters), loss = 0.0133321
I0622 02:35:18.705168 17579 solver.cpp:238]     Train net output #0: loss = 0.00899508 (* 1 = 0.00899508 loss)
I0622 02:35:18.705196 17579 sgd_solver.cpp:105] Iteration 30400, lr = 0.0005
I0622 02:37:46.688956 17579 solver.cpp:219] Iteration 30450 (0.337882 iter/s, 147.981s/50 iters), loss = 0.0122905
I0622 02:37:46.689095 17579 solver.cpp:238]     Train net output #0: loss = 0.0109328 (* 1 = 0.0109328 loss)
I0622 02:37:46.689123 17579 sgd_solver.cpp:105] Iteration 30450, lr = 0.0005
I0622 02:40:11.741572 17579 solver.cpp:331] Iteration 30500, Testing net (#0)
I0622 02:40:28.189429 17579 solver.cpp:398]     Test net output #0: accuracy = 0.980392
I0622 02:40:28.189524 17579 solver.cpp:398]     Test net output #1: loss = 0.0894096 (* 1 = 0.0894096 loss)
I0622 02:40:31.113364 17579 solver.cpp:219] Iteration 30500 (0.304097 iter/s, 164.421s/50 iters), loss = 0.00694032
I0622 02:40:31.113456 17579 solver.cpp:238]     Train net output #0: loss = 0.00975073 (* 1 = 0.00975073 loss)
I0622 02:40:31.113485 17579 sgd_solver.cpp:105] Iteration 30500, lr = 0.0005
I0622 02:42:59.000355 17579 solver.cpp:219] Iteration 30550 (0.338103 iter/s, 147.884s/50 iters), loss = 0.0107698
I0622 02:42:59.000531 17579 solver.cpp:238]     Train net output #0: loss = 0.0128074 (* 1 = 0.0128074 loss)
I0622 02:42:59.000562 17579 sgd_solver.cpp:105] Iteration 30550, lr = 0.0005
I0622 02:45:26.912401 17579 solver.cpp:219] Iteration 30600 (0.338046 iter/s, 147.909s/50 iters), loss = 0.00978395
I0622 02:45:26.912564 17579 solver.cpp:238]     Train net output #0: loss = 0.0200363 (* 1 = 0.0200363 loss)
I0622 02:45:26.912593 17579 sgd_solver.cpp:105] Iteration 30600, lr = 0.0005
I0622 02:47:54.864114 17579 solver.cpp:219] Iteration 30650 (0.337955 iter/s, 147.949s/50 iters), loss = 0.01053
I0622 02:47:54.864315 17579 solver.cpp:238]     Train net output #0: loss = 0.0035723 (* 1 = 0.0035723 loss)
I0622 02:47:54.864346 17579 sgd_solver.cpp:105] Iteration 30650, lr = 0.0005
I0622 02:50:22.891582 17579 solver.cpp:219] Iteration 30700 (0.337783 iter/s, 148.024s/50 iters), loss = 0.00848012
I0622 02:50:22.891742 17579 solver.cpp:238]     Train net output #0: loss = 0.0128765 (* 1 = 0.0128765 loss)
I0622 02:50:22.891772 17579 sgd_solver.cpp:105] Iteration 30700, lr = 0.0005
I0622 02:52:50.840188 17579 solver.cpp:219] Iteration 30750 (0.337965 iter/s, 147.944s/50 iters), loss = 0.00894766
I0622 02:52:50.840359 17579 solver.cpp:238]     Train net output #0: loss = 0.004958 (* 1 = 0.004958 loss)
I0622 02:52:50.840389 17579 sgd_solver.cpp:105] Iteration 30750, lr = 0.0005
I0622 02:55:17.664505 17579 solver.cpp:219] Iteration 30800 (0.34055 iter/s, 146.821s/50 iters), loss = 0.00751409
I0622 02:55:17.664682 17579 solver.cpp:238]     Train net output #0: loss = 0.00459258 (* 1 = 0.00459258 loss)
I0622 02:55:17.664711 17579 sgd_solver.cpp:105] Iteration 30800, lr = 0.0005
I0622 02:57:36.837687 17579 solver.cpp:219] Iteration 30850 (0.359271 iter/s, 139.171s/50 iters), loss = 0.00752989
I0622 02:57:36.837831 17579 solver.cpp:238]     Train net output #0: loss = 0.0117412 (* 1 = 0.0117412 loss)
I0622 02:57:36.837860 17579 sgd_solver.cpp:105] Iteration 30850, lr = 0.0005
I0622 03:00:04.679329 17579 solver.cpp:219] Iteration 30900 (0.338208 iter/s, 147.838s/50 iters), loss = 0.00686543
I0622 03:00:04.679494 17579 solver.cpp:238]     Train net output #0: loss = 0.00500699 (* 1 = 0.00500699 loss)
I0622 03:00:04.679530 17579 sgd_solver.cpp:105] Iteration 30900, lr = 0.0005
I0622 03:02:32.631243 17579 solver.cpp:219] Iteration 30950 (0.337954 iter/s, 147.949s/50 iters), loss = 0.00748391
I0622 03:02:32.631382 17579 solver.cpp:238]     Train net output #0: loss = 0.0124054 (* 1 = 0.0124054 loss)
I0622 03:02:32.631412 17579 sgd_solver.cpp:105] Iteration 30950, lr = 0.0005
I0622 03:04:57.615202 17579 solver.cpp:331] Iteration 31000, Testing net (#0)
I0622 03:05:14.068202 17579 solver.cpp:398]     Test net output #0: accuracy = 0.981373
I0622 03:05:14.068291 17579 solver.cpp:398]     Test net output #1: loss = 0.0787124 (* 1 = 0.0787124 loss)
I0622 03:05:16.983330 17579 solver.cpp:219] Iteration 31000 (0.304231 iter/s, 164.349s/50 iters), loss = 0.00962648
I0622 03:05:16.983436 17579 solver.cpp:238]     Train net output #0: loss = 0.00408547 (* 1 = 0.00408547 loss)
I0622 03:05:16.983467 17579 sgd_solver.cpp:105] Iteration 31000, lr = 0.0005
I0622 03:07:44.888097 17579 solver.cpp:219] Iteration 31050 (0.338062 iter/s, 147.902s/50 iters), loss = 0.00617103
I0622 03:07:44.888238 17579 solver.cpp:238]     Train net output #0: loss = 0.00637932 (* 1 = 0.00637932 loss)
I0622 03:07:44.888267 17579 sgd_solver.cpp:105] Iteration 31050, lr = 0.0005
I0622 03:10:12.872988 17579 solver.cpp:219] Iteration 31100 (0.337881 iter/s, 147.981s/50 iters), loss = 0.0122148
I0622 03:10:12.873139 17579 solver.cpp:238]     Train net output #0: loss = 0.0346877 (* 1 = 0.0346877 loss)
I0622 03:10:12.873172 17579 sgd_solver.cpp:105] Iteration 31100, lr = 0.0005
I0622 03:12:40.731003 17579 solver.cpp:219] Iteration 31150 (0.338169 iter/s, 147.855s/50 iters), loss = 0.00594869
I0622 03:12:40.731144 17579 solver.cpp:238]     Train net output #0: loss = 0.00805237 (* 1 = 0.00805237 loss)
I0622 03:12:40.731173 17579 sgd_solver.cpp:105] Iteration 31150, lr = 0.0005
I0622 03:15:08.630391 17579 solver.cpp:219] Iteration 31200 (0.338074 iter/s, 147.896s/50 iters), loss = 0.00664748
I0622 03:15:08.630545 17579 solver.cpp:238]     Train net output #0: loss = 0.00301162 (* 1 = 0.00301162 loss)
I0622 03:15:08.630578 17579 sgd_solver.cpp:105] Iteration 31200, lr = 0.0005
I0622 03:17:34.700318 17579 solver.cpp:219] Iteration 31250 (0.342309 iter/s, 146.067s/50 iters), loss = 0.0109962
I0622 03:17:34.700451 17579 solver.cpp:238]     Train net output #0: loss = 0.0110683 (* 1 = 0.0110683 loss)
I0622 03:17:34.700480 17579 sgd_solver.cpp:105] Iteration 31250, lr = 0.0005
I0622 03:19:54.677413 17579 solver.cpp:219] Iteration 31300 (0.357206 iter/s, 139.975s/50 iters), loss = 0.0128619
I0622 03:19:54.677629 17579 solver.cpp:238]     Train net output #0: loss = 0.012754 (* 1 = 0.012754 loss)
I0622 03:19:54.677656 17579 sgd_solver.cpp:105] Iteration 31300, lr = 0.0005
I0622 03:22:22.614012 17579 solver.cpp:219] Iteration 31350 (0.33799 iter/s, 147.934s/50 iters), loss = 0.00804175
I0622 03:22:22.614181 17579 solver.cpp:238]     Train net output #0: loss = 0.00519851 (* 1 = 0.00519851 loss)
I0622 03:22:22.614215 17579 sgd_solver.cpp:105] Iteration 31350, lr = 0.0005
I0622 03:24:50.589915 17579 solver.cpp:219] Iteration 31400 (0.3379 iter/s, 147.973s/50 iters), loss = 0.00489534
I0622 03:24:50.590062 17579 solver.cpp:238]     Train net output #0: loss = 0.00432406 (* 1 = 0.00432406 loss)
I0622 03:24:50.590095 17579 sgd_solver.cpp:105] Iteration 31400, lr = 0.0005
I0622 03:27:18.520274 17579 solver.cpp:219] Iteration 31450 (0.338004 iter/s, 147.927s/50 iters), loss = 0.00575905
I0622 03:27:18.520427 17579 solver.cpp:238]     Train net output #0: loss = 0.00640255 (* 1 = 0.00640255 loss)
I0622 03:27:18.520455 17579 sgd_solver.cpp:105] Iteration 31450, lr = 0.0005
I0622 03:29:43.527086 17579 solver.cpp:331] Iteration 31500, Testing net (#0)
I0622 03:29:59.892213 17579 solver.cpp:398]     Test net output #0: accuracy = 0.979412
I0622 03:29:59.892302 17579 solver.cpp:398]     Test net output #1: loss = 0.0884042 (* 1 = 0.0884042 loss)
I0622 03:30:02.805938 17579 solver.cpp:219] Iteration 31500 (0.304354 iter/s, 164.282s/50 iters), loss = 0.0078726
I0622 03:30:02.806043 17579 solver.cpp:238]     Train net output #0: loss = 0.0069645 (* 1 = 0.0069645 loss)
I0622 03:30:02.806076 17579 sgd_solver.cpp:105] Iteration 31500, lr = 0.0005
I0622 03:32:30.769763 17579 solver.cpp:219] Iteration 31550 (0.337927 iter/s, 147.961s/50 iters), loss = 0.00386346
I0622 03:32:30.769930 17579 solver.cpp:238]     Train net output #0: loss = 0.00422184 (* 1 = 0.00422184 loss)
I0622 03:32:30.769974 17579 sgd_solver.cpp:105] Iteration 31550, lr = 0.0005
I0622 03:34:58.710490 17579 solver.cpp:219] Iteration 31600 (0.33798 iter/s, 147.938s/50 iters), loss = 0.00702446
I0622 03:34:58.710654 17579 solver.cpp:238]     Train net output #0: loss = 0.00423997 (* 1 = 0.00423997 loss)
I0622 03:34:58.710685 17579 sgd_solver.cpp:105] Iteration 31600, lr = 0.0005
I0622 03:37:26.710389 17579 solver.cpp:219] Iteration 31650 (0.337845 iter/s, 147.997s/50 iters), loss = 0.00980763
I0622 03:37:26.710552 17579 solver.cpp:238]     Train net output #0: loss = 0.0133787 (* 1 = 0.0133787 loss)
I0622 03:37:26.710583 17579 sgd_solver.cpp:105] Iteration 31650, lr = 0.0005
I0622 03:39:51.721635 17579 solver.cpp:219] Iteration 31700 (0.344806 iter/s, 145.009s/50 iters), loss = 0.00502444
I0622 03:39:51.721804 17579 solver.cpp:238]     Train net output #0: loss = 0.00736249 (* 1 = 0.00736249 loss)
I0622 03:39:51.721833 17579 sgd_solver.cpp:105] Iteration 31700, lr = 0.0005
I0622 03:42:12.587280 17579 solver.cpp:219] Iteration 31750 (0.354956 iter/s, 140.863s/50 iters), loss = 0.00776669
I0622 03:42:12.587455 17579 solver.cpp:238]     Train net output #0: loss = 0.00735484 (* 1 = 0.00735484 loss)
I0622 03:42:12.587486 17579 sgd_solver.cpp:105] Iteration 31750, lr = 0.0005
I0622 03:44:40.402756 17579 solver.cpp:219] Iteration 31800 (0.338266 iter/s, 147.813s/50 iters), loss = 0.00571027
I0622 03:44:40.402951 17579 solver.cpp:238]     Train net output #0: loss = 0.00185852 (* 1 = 0.00185852 loss)
I0622 03:44:40.402987 17579 sgd_solver.cpp:105] Iteration 31800, lr = 0.0005
I0622 03:47:08.184305 17579 solver.cpp:219] Iteration 31850 (0.338344 iter/s, 147.779s/50 iters), loss = 0.00626583
I0622 03:47:08.184501 17579 solver.cpp:238]     Train net output #0: loss = 0.00778023 (* 1 = 0.00778023 loss)
I0622 03:47:08.184542 17579 sgd_solver.cpp:105] Iteration 31850, lr = 0.0005
I0622 03:49:35.956202 17579 solver.cpp:219] Iteration 31900 (0.338369 iter/s, 147.768s/50 iters), loss = 0.00709094
I0622 03:49:35.956449 17579 solver.cpp:238]     Train net output #0: loss = 0.0111444 (* 1 = 0.0111444 loss)
I0622 03:49:35.956478 17579 sgd_solver.cpp:105] Iteration 31900, lr = 0.0005
I0622 03:52:03.763366 17579 solver.cpp:219] Iteration 31950 (0.338284 iter/s, 147.805s/50 iters), loss = 0.00604863
I0622 03:52:03.763523 17579 solver.cpp:238]     Train net output #0: loss = 0.00351685 (* 1 = 0.00351685 loss)
I0622 03:52:03.763555 17579 sgd_solver.cpp:105] Iteration 31950, lr = 0.0005
I0622 03:54:28.780505 17579 solver.cpp:448] Snapshotting to binary proto file mobilenet/mobile_pruning_iter_32000.caffemodel
I0622 03:54:28.909749 17579 sgd_solver.cpp:273] Snapshotting solver state to binary proto file mobilenet/mobile_pruning_iter_32000.solverstate
I0622 03:54:28.966764 17579 solver.cpp:331] Iteration 32000, Testing net (#0)
I0622 03:54:45.517437 17579 solver.cpp:398]     Test net output #0: accuracy = 0.981373
I0622 03:54:45.517524 17579 solver.cpp:398]     Test net output #1: loss = 0.0870948 (* 1 = 0.0870948 loss)
I0622 03:54:48.450078 17579 solver.cpp:219] Iteration 32000 (0.303611 iter/s, 164.684s/50 iters), loss = 0.00579425
I0622 03:54:48.450176 17579 solver.cpp:238]     Train net output #0: loss = 0.00594311 (* 1 = 0.00594311 loss)
I0622 03:54:48.450209 17579 sgd_solver.cpp:105] Iteration 32000, lr = 0.0005
I0622 03:57:16.298786 17579 solver.cpp:219] Iteration 32050 (0.338189 iter/s, 147.847s/50 iters), loss = 0.00428263
I0622 03:57:16.298938 17579 solver.cpp:238]     Train net output #0: loss = 0.00820373 (* 1 = 0.00820373 loss)
I0622 03:57:16.298967 17579 sgd_solver.cpp:105] Iteration 32050, lr = 0.0005
I0622 03:59:44.255717 17579 solver.cpp:219] Iteration 32100 (0.337941 iter/s, 147.955s/50 iters), loss = 0.00771936
I0622 03:59:44.255897 17579 solver.cpp:238]     Train net output #0: loss = 0.00576364 (* 1 = 0.00576364 loss)
I0622 03:59:44.255926 17579 sgd_solver.cpp:105] Iteration 32100, lr = 0.0005
I0622 04:02:08.776831 17579 solver.cpp:219] Iteration 32150 (0.345975 iter/s, 144.519s/50 iters), loss = 0.00436817
I0622 04:02:08.777009 17579 solver.cpp:238]     Train net output #0: loss = 0.00659378 (* 1 = 0.00659378 loss)
I0622 04:02:08.777039 17579 sgd_solver.cpp:105] Iteration 32150, lr = 0.0005
I0622 04:04:30.562729 17579 solver.cpp:219] Iteration 32200 (0.352651 iter/s, 141.783s/50 iters), loss = 0.00636958
I0622 04:04:30.562862 17579 solver.cpp:238]     Train net output #0: loss = 0.00363777 (* 1 = 0.00363777 loss)
I0622 04:04:30.562891 17579 sgd_solver.cpp:105] Iteration 32200, lr = 0.0005
I0622 04:06:58.464978 17579 solver.cpp:219] Iteration 32250 (0.338066 iter/s, 147.9s/50 iters), loss = 0.0079528
I0622 04:06:58.465131 17579 solver.cpp:238]     Train net output #0: loss = 0.00549625 (* 1 = 0.00549625 loss)
I0622 04:06:58.465162 17579 sgd_solver.cpp:105] Iteration 32250, lr = 0.0005
I0622 04:09:26.318552 17579 solver.cpp:219] Iteration 32300 (0.338178 iter/s, 147.851s/50 iters), loss = 0.00578962
I0622 04:09:26.318692 17579 solver.cpp:238]     Train net output #0: loss = 0.0082436 (* 1 = 0.0082436 loss)
I0622 04:09:26.318720 17579 sgd_solver.cpp:105] Iteration 32300, lr = 0.0005
I0622 04:11:54.320364 17579 solver.cpp:219] Iteration 32350 (0.33784 iter/s, 147.999s/50 iters), loss = 0.00411531
I0622 04:11:54.320580 17579 solver.cpp:238]     Train net output #0: loss = 0.00190066 (* 1 = 0.00190066 loss)
I0622 04:11:54.320621 17579 sgd_solver.cpp:105] Iteration 32350, lr = 0.0005
I0622 04:14:22.089427 17579 solver.cpp:219] Iteration 32400 (0.338371 iter/s, 147.767s/50 iters), loss = 0.00855642
I0622 04:14:22.089577 17579 solver.cpp:238]     Train net output #0: loss = 0.00821765 (* 1 = 0.00821765 loss)
I0622 04:14:22.089607 17579 sgd_solver.cpp:105] Iteration 32400, lr = 0.0005
I0622 04:16:49.936331 17579 solver.cpp:219] Iteration 32450 (0.338191 iter/s, 147.846s/50 iters), loss = 0.00802959
I0622 04:16:49.936538 17579 solver.cpp:238]     Train net output #0: loss = 0.00777318 (* 1 = 0.00777318 loss)
I0622 04:16:49.936574 17579 sgd_solver.cpp:105] Iteration 32450, lr = 0.0005
I0622 04:19:14.988807 17579 solver.cpp:331] Iteration 32500, Testing net (#0)
I0622 04:19:31.562005 17579 solver.cpp:398]     Test net output #0: accuracy = 0.979412
I0622 04:19:31.562098 17579 solver.cpp:398]     Test net output #1: loss = 0.0858366 (* 1 = 0.0858366 loss)
I0622 04:19:34.493079 17579 solver.cpp:219] Iteration 32500 (0.303851 iter/s, 164.554s/50 iters), loss = 0.00607166
I0622 04:19:34.493176 17579 solver.cpp:238]     Train net output #0: loss = 0.00696853 (* 1 = 0.00696853 loss)
I0622 04:19:34.493206 17579 sgd_solver.cpp:105] Iteration 32500, lr = 0.0005
I0622 04:22:02.377130 17579 solver.cpp:219] Iteration 32550 (0.338108 iter/s, 147.882s/50 iters), loss = 0.0114334
I0622 04:22:02.377310 17579 solver.cpp:238]     Train net output #0: loss = 0.00463297 (* 1 = 0.00463297 loss)
I0622 04:22:02.377341 17579 sgd_solver.cpp:105] Iteration 32550, lr = 0.0005
I0622 04:24:25.930727 17579 solver.cpp:219] Iteration 32600 (0.348308 iter/s, 143.551s/50 iters), loss = 0.00711981
I0622 04:24:25.930886 17579 solver.cpp:238]     Train net output #0: loss = 0.0113589 (* 1 = 0.0113589 loss)
I0622 04:24:25.930912 17579 sgd_solver.cpp:105] Iteration 32600, lr = 0.0005
I0622 04:26:48.476202 17579 solver.cpp:219] Iteration 32650 (0.350774 iter/s, 142.542s/50 iters), loss = 0.00257335
I0622 04:26:48.481580 17579 solver.cpp:238]     Train net output #0: loss = 0.00180691 (* 1 = 0.00180691 loss)
I0622 04:26:48.481611 17579 sgd_solver.cpp:105] Iteration 32650, lr = 0.0005
I0622 04:29:16.359136 17579 solver.cpp:219] Iteration 32700 (0.338127 iter/s, 147.873s/50 iters), loss = 0.00756118
I0622 04:29:16.359313 17579 solver.cpp:238]     Train net output #0: loss = 0.0116579 (* 1 = 0.0116579 loss)
I0622 04:29:16.359344 17579 sgd_solver.cpp:105] Iteration 32700, lr = 0.0005
I0622 04:31:44.134387 17579 solver.cpp:219] Iteration 32750 (0.338359 iter/s, 147.772s/50 iters), loss = 0.0107292
I0622 04:31:44.134541 17579 solver.cpp:238]     Train net output #0: loss = 0.0147087 (* 1 = 0.0147087 loss)
I0622 04:31:44.134569 17579 sgd_solver.cpp:105] Iteration 32750, lr = 0.0005
I0622 04:34:11.876574 17579 solver.cpp:219] Iteration 32800 (0.338435 iter/s, 147.739s/50 iters), loss = 0.00505551
I0622 04:34:11.876747 17579 solver.cpp:238]     Train net output #0: loss = 0.0084824 (* 1 = 0.0084824 loss)
I0622 04:34:11.876780 17579 sgd_solver.cpp:105] Iteration 32800, lr = 0.0005
I0622 04:36:39.712316 17579 solver.cpp:219] Iteration 32850 (0.338223 iter/s, 147.832s/50 iters), loss = 0.00506986
I0622 04:36:39.712469 17579 solver.cpp:238]     Train net output #0: loss = 0.00481573 (* 1 = 0.00481573 loss)
I0622 04:36:39.712502 17579 sgd_solver.cpp:105] Iteration 32850, lr = 0.0005
I0622 04:39:07.537171 17579 solver.cpp:219] Iteration 32900 (0.338244 iter/s, 147.822s/50 iters), loss = 0.00725273
I0622 04:39:07.537333 17579 solver.cpp:238]     Train net output #0: loss = 0.00649355 (* 1 = 0.00649355 loss)
I0622 04:39:07.537361 17579 sgd_solver.cpp:105] Iteration 32900, lr = 0.0005
I0622 04:41:35.369361 17579 solver.cpp:219] Iteration 32950 (0.338228 iter/s, 147.829s/50 iters), loss = 0.00800632
I0622 04:41:35.369539 17579 solver.cpp:238]     Train net output #0: loss = 0.00405433 (* 1 = 0.00405433 loss)
I0622 04:41:35.369572 17579 sgd_solver.cpp:105] Iteration 32950, lr = 0.0005
I0622 04:44:00.308243 17579 solver.cpp:331] Iteration 33000, Testing net (#0)
I0622 04:44:16.815250 17579 solver.cpp:398]     Test net output #0: accuracy = 0.980392
I0622 04:44:16.815330 17579 solver.cpp:398]     Test net output #1: loss = 0.0838618 (* 1 = 0.0838618 loss)
I0622 04:44:19.724566 17579 solver.cpp:219] Iteration 33000 (0.304225 iter/s, 164.352s/50 iters), loss = 0.00857508
I0622 04:44:19.724651 17579 solver.cpp:238]     Train net output #0: loss = 0.00320095 (* 1 = 0.00320095 loss)
I0622 04:44:19.724678 17579 sgd_solver.cpp:105] Iteration 33000, lr = 0.0005
I0622 04:46:42.846143 17579 solver.cpp:219] Iteration 33050 (0.349361 iter/s, 143.118s/50 iters), loss = 0.00611062
I0622 04:46:42.846295 17579 solver.cpp:238]     Train net output #0: loss = 0.00483479 (* 1 = 0.00483479 loss)
I0622 04:46:42.846324 17579 sgd_solver.cpp:105] Iteration 33050, lr = 0.0005
I0622 04:49:05.798375 17579 solver.cpp:219] Iteration 33100 (0.349772 iter/s, 142.95s/50 iters), loss = 0.00556669
I0622 04:49:05.798585 17579 solver.cpp:238]     Train net output #0: loss = 0.00678048 (* 1 = 0.00678048 loss)
I0622 04:49:05.798615 17579 sgd_solver.cpp:105] Iteration 33100, lr = 0.0005
I0622 04:51:33.763593 17579 solver.cpp:219] Iteration 33150 (0.337925 iter/s, 147.962s/50 iters), loss = 0.0135435
I0622 04:51:33.763746 17579 solver.cpp:238]     Train net output #0: loss = 0.00597821 (* 1 = 0.00597821 loss)
I0622 04:51:33.763774 17579 sgd_solver.cpp:105] Iteration 33150, lr = 0.0005
I0622 04:54:01.713845 17579 solver.cpp:219] Iteration 33200 (0.337958 iter/s, 147.947s/50 iters), loss = 0.00738926
I0622 04:54:01.714020 17579 solver.cpp:238]     Train net output #0: loss = 0.0101507 (* 1 = 0.0101507 loss)
I0622 04:54:01.714049 17579 sgd_solver.cpp:105] Iteration 33200, lr = 0.0005
I0622 04:56:29.593094 17579 solver.cpp:219] Iteration 33250 (0.338121 iter/s, 147.876s/50 iters), loss = 0.00516924
I0622 04:56:29.593261 17579 solver.cpp:238]     Train net output #0: loss = 0.00440454 (* 1 = 0.00440454 loss)
I0622 04:56:29.593291 17579 sgd_solver.cpp:105] Iteration 33250, lr = 0.0005
I0622 04:58:57.447262 17579 solver.cpp:219] Iteration 33300 (0.338176 iter/s, 147.852s/50 iters), loss = 0.00780497
I0622 04:58:57.450690 17579 solver.cpp:238]     Train net output #0: loss = 0.00382542 (* 1 = 0.00382542 loss)
I0622 04:58:57.450721 17579 sgd_solver.cpp:105] Iteration 33300, lr = 0.0005
I0622 05:01:25.338574 17579 solver.cpp:219] Iteration 33350 (0.3381 iter/s, 147.885s/50 iters), loss = 0.00946364
I0622 05:01:25.338735 17579 solver.cpp:238]     Train net output #0: loss = 0.00187819 (* 1 = 0.00187819 loss)
I0622 05:01:25.338764 17579 sgd_solver.cpp:105] Iteration 33350, lr = 0.0005
I0622 05:03:53.227036 17579 solver.cpp:219] Iteration 33400 (0.338099 iter/s, 147.885s/50 iters), loss = 0.00920855
I0622 05:03:53.227190 17579 solver.cpp:238]     Train net output #0: loss = 0.00333962 (* 1 = 0.00333962 loss)
I0622 05:03:53.227233 17579 sgd_solver.cpp:105] Iteration 33400, lr = 0.0005
I0622 05:06:21.203976 17579 solver.cpp:219] Iteration 33450 (0.337896 iter/s, 147.974s/50 iters), loss = 0.00470719
I0622 05:06:21.204119 17579 solver.cpp:238]     Train net output #0: loss = 0.0063053 (* 1 = 0.0063053 loss)
I0622 05:06:21.204147 17579 sgd_solver.cpp:105] Iteration 33450, lr = 0.0005
I0622 05:08:46.263255 17579 solver.cpp:331] Iteration 33500, Testing net (#0)
I0622 05:09:00.777031 17579 solver.cpp:398]     Test net output #0: accuracy = 0.981373
I0622 05:09:00.777123 17579 solver.cpp:398]     Test net output #1: loss = 0.0838314 (* 1 = 0.0838314 loss)
I0622 05:09:02.745950 17579 solver.cpp:219] Iteration 33500 (0.309523 iter/s, 161.539s/50 iters), loss = 0.00618692
I0622 05:09:02.746049 17579 solver.cpp:238]     Train net output #0: loss = 0.00880934 (* 1 = 0.00880934 loss)
I0622 05:09:02.746083 17579 sgd_solver.cpp:105] Iteration 33500, lr = 0.0005
I0622 05:11:26.537187 17579 solver.cpp:219] Iteration 33550 (0.347731 iter/s, 143.789s/50 iters), loss = 0.00593763
I0622 05:11:26.537379 17579 solver.cpp:238]     Train net output #0: loss = 0.00421344 (* 1 = 0.00421344 loss)
I0622 05:11:26.537410 17579 sgd_solver.cpp:105] Iteration 33550, lr = 0.0005
I0622 05:13:54.464751 17579 solver.cpp:219] Iteration 33600 (0.33801 iter/s, 147.925s/50 iters), loss = 0.00807959
I0622 05:13:54.464931 17579 solver.cpp:238]     Train net output #0: loss = 0.00360408 (* 1 = 0.00360408 loss)
I0622 05:13:54.464963 17579 sgd_solver.cpp:105] Iteration 33600, lr = 0.0005
I0622 05:16:22.231940 17579 solver.cpp:219] Iteration 33650 (0.338378 iter/s, 147.764s/50 iters), loss = 0.00745683
I0622 05:16:22.232115 17579 solver.cpp:238]     Train net output #0: loss = 0.00550422 (* 1 = 0.00550422 loss)
I0622 05:16:22.232148 17579 sgd_solver.cpp:105] Iteration 33650, lr = 0.0005
I0622 05:18:50.029119 17579 solver.cpp:219] Iteration 33700 (0.338308 iter/s, 147.795s/50 iters), loss = 0.0058377
I0622 05:18:50.029361 17579 solver.cpp:238]     Train net output #0: loss = 0.00395615 (* 1 = 0.00395615 loss)
I0622 05:18:50.029397 17579 sgd_solver.cpp:105] Iteration 33700, lr = 0.0005
I0622 05:21:17.760200 17579 solver.cpp:219] Iteration 33750 (0.33846 iter/s, 147.728s/50 iters), loss = 0.00627744
I0622 05:21:17.760418 17579 solver.cpp:238]     Train net output #0: loss = 0.00477761 (* 1 = 0.00477761 loss)
I0622 05:21:17.760448 17579 sgd_solver.cpp:105] Iteration 33750, lr = 0.0005
I0622 05:23:45.681212 17579 solver.cpp:219] Iteration 33800 (0.338027 iter/s, 147.917s/50 iters), loss = 0.00497776
I0622 05:23:45.681368 17579 solver.cpp:238]     Train net output #0: loss = 0.00590954 (* 1 = 0.00590954 loss)
I0622 05:23:45.681396 17579 sgd_solver.cpp:105] Iteration 33800, lr = 0.0005
I0622 05:26:13.578969 17579 solver.cpp:219] Iteration 33850 (0.338078 iter/s, 147.895s/50 iters), loss = 0.00566529
I0622 05:26:13.579969 17579 solver.cpp:238]     Train net output #0: loss = 0.0132005 (* 1 = 0.0132005 loss)
I0622 05:26:13.579999 17579 sgd_solver.cpp:105] Iteration 33850, lr = 0.0005
I0622 05:28:41.492353 17579 solver.cpp:219] Iteration 33900 (0.338042 iter/s, 147.91s/50 iters), loss = 0.00749824
I0622 05:28:41.492518 17579 solver.cpp:238]     Train net output #0: loss = 0.00548112 (* 1 = 0.00548112 loss)
I0622 05:28:41.492549 17579 sgd_solver.cpp:105] Iteration 33900, lr = 0.0005
I0622 05:31:09.387681 17579 solver.cpp:219] Iteration 33950 (0.338083 iter/s, 147.893s/50 iters), loss = 0.0109763
I0622 05:31:09.387852 17579 solver.cpp:238]     Train net output #0: loss = 0.0210866 (* 1 = 0.0210866 loss)
I0622 05:31:09.387887 17579 sgd_solver.cpp:105] Iteration 33950, lr = 0.0005
I0622 05:33:24.763977 17579 solver.cpp:331] Iteration 34000, Testing net (#0)
I0622 05:33:41.230092 17579 solver.cpp:398]     Test net output #0: accuracy = 0.983333
I0622 05:33:41.230178 17579 solver.cpp:398]     Test net output #1: loss = 0.083675 (* 1 = 0.083675 loss)
I0622 05:33:44.151234 17579 solver.cpp:219] Iteration 34000 (0.323079 iter/s, 154.761s/50 iters), loss = 0.00690859
I0622 05:33:44.151350 17579 solver.cpp:238]     Train net output #0: loss = 0.00665732 (* 1 = 0.00665732 loss)
I0622 05:33:44.151381 17579 sgd_solver.cpp:105] Iteration 34000, lr = 0.0005
I0622 05:36:12.001242 17579 solver.cpp:219] Iteration 34050 (0.338188 iter/s, 147.847s/50 iters), loss = 0.00646779
I0622 05:36:12.001384 17579 solver.cpp:238]     Train net output #0: loss = 0.0147285 (* 1 = 0.0147285 loss)
I0622 05:36:12.001412 17579 sgd_solver.cpp:105] Iteration 34050, lr = 0.0005
I0622 05:38:39.843521 17579 solver.cpp:219] Iteration 34100 (0.338204 iter/s, 147.84s/50 iters), loss = 0.0070557
I0622 05:38:39.843652 17579 solver.cpp:238]     Train net output #0: loss = 0.00723509 (* 1 = 0.00723509 loss)
I0622 05:38:39.843683 17579 sgd_solver.cpp:105] Iteration 34100, lr = 0.0005
I0622 05:41:07.757982 17579 solver.cpp:219] Iteration 34150 (0.33804 iter/s, 147.912s/50 iters), loss = 0.00543611
I0622 05:41:07.758118 17579 solver.cpp:238]     Train net output #0: loss = 0.00599667 (* 1 = 0.00599667 loss)
I0622 05:41:07.758150 17579 sgd_solver.cpp:105] Iteration 34150, lr = 0.0005
I0622 05:43:35.541362 17579 solver.cpp:219] Iteration 34200 (0.338341 iter/s, 147.78s/50 iters), loss = 0.00737059
I0622 05:43:35.541524 17579 solver.cpp:238]     Train net output #0: loss = 0.00533117 (* 1 = 0.00533117 loss)
I0622 05:43:35.541554 17579 sgd_solver.cpp:105] Iteration 34200, lr = 0.0005
I0622 05:46:03.380722 17579 solver.cpp:219] Iteration 34250 (0.338214 iter/s, 147.836s/50 iters), loss = 0.00842988
I0622 05:46:03.380864 17579 solver.cpp:238]     Train net output #0: loss = 0.0082622 (* 1 = 0.0082622 loss)
I0622 05:46:03.380894 17579 sgd_solver.cpp:105] Iteration 34250, lr = 0.0005
I0622 05:48:31.344120 17579 solver.cpp:219] Iteration 34300 (0.337929 iter/s, 147.96s/50 iters), loss = 0.00457229
I0622 05:48:31.344271 17579 solver.cpp:238]     Train net output #0: loss = 0.00390192 (* 1 = 0.00390192 loss)
I0622 05:48:31.344305 17579 sgd_solver.cpp:105] Iteration 34300, lr = 0.0005
I0622 05:50:59.195655 17579 solver.cpp:219] Iteration 34350 (0.338185 iter/s, 147.848s/50 iters), loss = 0.00443401
I0622 05:50:59.195888 17579 solver.cpp:238]     Train net output #0: loss = 0.0027259 (* 1 = 0.0027259 loss)
I0622 05:50:59.195919 17579 sgd_solver.cpp:105] Iteration 34350, lr = 0.0005
I0622 05:53:27.039083 17579 solver.cpp:219] Iteration 34400 (0.338201 iter/s, 147.841s/50 iters), loss = 0.00372001
I0622 05:53:27.039270 17579 solver.cpp:238]     Train net output #0: loss = 0.00415592 (* 1 = 0.00415592 loss)
I0622 05:53:27.039299 17579 sgd_solver.cpp:105] Iteration 34400, lr = 0.0005
I0622 05:55:45.014971 17579 solver.cpp:219] Iteration 34450 (0.362389 iter/s, 137.973s/50 iters), loss = 0.00510688
I0622 05:55:45.015154 17579 solver.cpp:238]     Train net output #0: loss = 0.0032951 (* 1 = 0.0032951 loss)
I0622 05:55:45.015184 17579 sgd_solver.cpp:105] Iteration 34450, lr = 0.0005
I0622 05:58:09.948343 17579 solver.cpp:331] Iteration 34500, Testing net (#0)
I0622 05:58:26.402729 17579 solver.cpp:398]     Test net output #0: accuracy = 0.980392
I0622 05:58:26.402807 17579 solver.cpp:398]     Test net output #1: loss = 0.0810441 (* 1 = 0.0810441 loss)
I0622 05:58:29.319519 17579 solver.cpp:219] Iteration 34500 (0.304317 iter/s, 164.302s/50 iters), loss = 0.00811047
I0622 05:58:29.319643 17579 solver.cpp:238]     Train net output #0: loss = 0.0061148 (* 1 = 0.0061148 loss)
I0622 05:58:29.319675 17579 sgd_solver.cpp:105] Iteration 34500, lr = 0.0005
I0622 06:00:57.204337 17579 solver.cpp:219] Iteration 34550 (0.338106 iter/s, 147.882s/50 iters), loss = 0.00517638
I0622 06:00:57.204531 17579 solver.cpp:238]     Train net output #0: loss = 0.00230178 (* 1 = 0.00230178 loss)
I0622 06:00:57.204566 17579 sgd_solver.cpp:105] Iteration 34550, lr = 0.0005
I0622 06:03:25.074630 17579 solver.cpp:219] Iteration 34600 (0.338142 iter/s, 147.867s/50 iters), loss = 0.00653751
I0622 06:03:25.074790 17579 solver.cpp:238]     Train net output #0: loss = 0.00728 (* 1 = 0.00728 loss)
I0622 06:03:25.074821 17579 sgd_solver.cpp:105] Iteration 34600, lr = 0.0005
I0622 06:05:52.831518 17579 solver.cpp:219] Iteration 34650 (0.338399 iter/s, 147.755s/50 iters), loss = 0.00462935
I0622 06:05:52.831683 17579 solver.cpp:238]     Train net output #0: loss = 0.00553507 (* 1 = 0.00553507 loss)
I0622 06:05:52.831712 17579 sgd_solver.cpp:105] Iteration 34650, lr = 0.0005
I0622 06:08:20.798502 17579 solver.cpp:219] Iteration 34700 (0.33792 iter/s, 147.964s/50 iters), loss = 0.00518227
I0622 06:08:20.798658 17579 solver.cpp:238]     Train net output #0: loss = 0.00950638 (* 1 = 0.00950638 loss)
I0622 06:08:20.798687 17579 sgd_solver.cpp:105] Iteration 34700, lr = 0.0005
I0622 06:10:48.754853 17579 solver.cpp:219] Iteration 34750 (0.337945 iter/s, 147.953s/50 iters), loss = 0.00385362
I0622 06:10:48.755002 17579 solver.cpp:238]     Train net output #0: loss = 0.0029852 (* 1 = 0.0029852 loss)
I0622 06:10:48.755030 17579 sgd_solver.cpp:105] Iteration 34750, lr = 0.0005
I0622 06:13:16.662667 17579 solver.cpp:219] Iteration 34800 (0.338054 iter/s, 147.905s/50 iters), loss = 0.0056531
I0622 06:13:16.662829 17579 solver.cpp:238]     Train net output #0: loss = 0.00457634 (* 1 = 0.00457634 loss)
I0622 06:13:16.662858 17579 sgd_solver.cpp:105] Iteration 34800, lr = 0.0005
I0622 06:15:44.688599 17579 solver.cpp:219] Iteration 34850 (0.337785 iter/s, 148.023s/50 iters), loss = 0.00565097
I0622 06:15:44.688746 17579 solver.cpp:238]     Train net output #0: loss = 0.00494449 (* 1 = 0.00494449 loss)
I0622 06:15:44.688778 17579 sgd_solver.cpp:105] Iteration 34850, lr = 0.0005
I0622 06:18:02.831167 17579 solver.cpp:219] Iteration 34900 (0.36195 iter/s, 138.141s/50 iters), loss = 0.00651942
I0622 06:18:02.831318 17579 solver.cpp:238]     Train net output #0: loss = 0.00578703 (* 1 = 0.00578703 loss)
I0622 06:18:02.831346 17579 sgd_solver.cpp:105] Iteration 34900, lr = 0.0005
I0622 06:20:30.886512 17579 solver.cpp:219] Iteration 34950 (0.337722 iter/s, 148.051s/50 iters), loss = 0.00844913
I0622 06:20:30.886664 17579 solver.cpp:238]     Train net output #0: loss = 0.01537 (* 1 = 0.01537 loss)
I0622 06:20:30.886696 17579 sgd_solver.cpp:105] Iteration 34950, lr = 0.0005
I0622 06:22:55.937618 17579 solver.cpp:331] Iteration 35000, Testing net (#0)
I0622 06:23:12.450881 17579 solver.cpp:398]     Test net output #0: accuracy = 0.979412
I0622 06:23:12.450963 17579 solver.cpp:398]     Test net output #1: loss = 0.0800802 (* 1 = 0.0800802 loss)
I0622 06:23:15.349727 17579 solver.cpp:219] Iteration 35000 (0.304025 iter/s, 164.46s/50 iters), loss = 0.00961551
I0622 06:23:15.349833 17579 solver.cpp:238]     Train net output #0: loss = 0.0102855 (* 1 = 0.0102855 loss)
I0622 06:23:15.349864 17579 sgd_solver.cpp:105] Iteration 35000, lr = 0.0005
I0622 06:25:43.213685 17579 solver.cpp:219] Iteration 35050 (0.338153 iter/s, 147.862s/50 iters), loss = 0.00527138
I0622 06:25:43.213841 17579 solver.cpp:238]     Train net output #0: loss = 0.00407628 (* 1 = 0.00407628 loss)
I0622 06:25:43.213871 17579 sgd_solver.cpp:105] Iteration 35050, lr = 0.0005
I0622 06:28:11.080217 17579 solver.cpp:219] Iteration 35100 (0.33815 iter/s, 147.864s/50 iters), loss = 0.00728037
I0622 06:28:11.080368 17579 solver.cpp:238]     Train net output #0: loss = 0.00798662 (* 1 = 0.00798662 loss)
I0622 06:28:11.080399 17579 sgd_solver.cpp:105] Iteration 35100, lr = 0.0005
I0622 06:30:38.986817 17579 solver.cpp:219] Iteration 35150 (0.338058 iter/s, 147.903s/50 iters), loss = 0.00752253
I0622 06:30:38.987040 17579 solver.cpp:238]     Train net output #0: loss = 0.00371097 (* 1 = 0.00371097 loss)
I0622 06:30:38.987072 17579 sgd_solver.cpp:105] Iteration 35150, lr = 0.0005
I0622 06:33:06.948906 17579 solver.cpp:219] Iteration 35200 (0.337931 iter/s, 147.959s/50 iters), loss = 0.00625505
I0622 06:33:06.949054 17579 solver.cpp:238]     Train net output #0: loss = 0.00371269 (* 1 = 0.00371269 loss)
I0622 06:33:06.949082 17579 sgd_solver.cpp:105] Iteration 35200, lr = 0.0005
I0622 06:35:34.788656 17579 solver.cpp:219] Iteration 35250 (0.338211 iter/s, 147.837s/50 iters), loss = 0.00625045
I0622 06:35:34.788807 17579 solver.cpp:238]     Train net output #0: loss = 0.00710665 (* 1 = 0.00710665 loss)
I0622 06:35:34.788852 17579 sgd_solver.cpp:105] Iteration 35250, lr = 0.0005
I0622 06:38:02.491412 17579 solver.cpp:219] Iteration 35300 (0.338524 iter/s, 147.7s/50 iters), loss = 0.00595105
I0622 06:38:02.491580 17579 solver.cpp:238]     Train net output #0: loss = 0.00211446 (* 1 = 0.00211446 loss)
I0622 06:38:02.491612 17579 sgd_solver.cpp:105] Iteration 35300, lr = 0.0005
I0622 06:40:20.873229 17579 solver.cpp:219] Iteration 35350 (0.361327 iter/s, 138.379s/50 iters), loss = 0.00552118
I0622 06:40:20.873373 17579 solver.cpp:238]     Train net output #0: loss = 0.00276519 (* 1 = 0.00276519 loss)
I0622 06:40:20.873401 17579 sgd_solver.cpp:105] Iteration 35350, lr = 0.0005
I0622 06:42:48.857445 17579 solver.cpp:219] Iteration 35400 (0.337878 iter/s, 147.982s/50 iters), loss = 0.00459836
I0622 06:42:48.857553 17579 solver.cpp:238]     Train net output #0: loss = 0.00492607 (* 1 = 0.00492607 loss)
I0622 06:42:48.857583 17579 sgd_solver.cpp:105] Iteration 35400, lr = 0.0005
I0622 06:45:16.907608 17579 solver.cpp:219] Iteration 35450 (0.337727 iter/s, 148.048s/50 iters), loss = 0.00681136
I0622 06:45:16.907797 17579 solver.cpp:238]     Train net output #0: loss = 0.00207865 (* 1 = 0.00207865 loss)
I0622 06:45:16.907824 17579 sgd_solver.cpp:105] Iteration 35450, lr = 0.0005
I0622 06:47:42.082165 17579 solver.cpp:331] Iteration 35500, Testing net (#0)
I0622 06:47:48.660681 17579 blocking_queue.cpp:49] Waiting for data
I0622 06:47:58.567405 17579 solver.cpp:398]     Test net output #0: accuracy = 0.980392
I0622 06:47:58.567477 17579 solver.cpp:398]     Test net output #1: loss = 0.081796 (* 1 = 0.081796 loss)
I0622 06:48:01.472769 17579 solver.cpp:219] Iteration 35500 (0.303835 iter/s, 164.563s/50 iters), loss = 0.00812017
I0622 06:48:01.472863 17579 solver.cpp:238]     Train net output #0: loss = 0.0176311 (* 1 = 0.0176311 loss)
I0622 06:48:01.472889 17579 sgd_solver.cpp:105] Iteration 35500, lr = 0.0005
I0622 06:50:29.513245 17579 solver.cpp:219] Iteration 35550 (0.337752 iter/s, 148.038s/50 iters), loss = 0.00655872
I0622 06:50:29.513453 17579 solver.cpp:238]     Train net output #0: loss = 0.0081584 (* 1 = 0.0081584 loss)
I0622 06:50:29.513484 17579 sgd_solver.cpp:105] Iteration 35550, lr = 0.0005
I0622 06:52:57.347442 17579 solver.cpp:219] Iteration 35600 (0.338223 iter/s, 147.831s/50 iters), loss = 0.00442708
I0622 06:52:57.347620 17579 solver.cpp:238]     Train net output #0: loss = 0.00536552 (* 1 = 0.00536552 loss)
I0622 06:52:57.347651 17579 sgd_solver.cpp:105] Iteration 35600, lr = 0.0005
I0622 06:55:25.206568 17579 solver.cpp:219] Iteration 35650 (0.338166 iter/s, 147.856s/50 iters), loss = 0.00462777
I0622 06:55:25.206755 17579 solver.cpp:238]     Train net output #0: loss = 0.00360689 (* 1 = 0.00360689 loss)
I0622 06:55:25.206787 17579 sgd_solver.cpp:105] Iteration 35650, lr = 0.0005
I0622 06:57:53.028524 17579 solver.cpp:219] Iteration 35700 (0.338252 iter/s, 147.819s/50 iters), loss = 0.00619074
I0622 06:57:53.028723 17579 solver.cpp:238]     Train net output #0: loss = 0.0201297 (* 1 = 0.0201297 loss)
I0622 06:57:53.028754 17579 sgd_solver.cpp:105] Iteration 35700, lr = 0.0005
I0622 07:00:19.762871 17579 solver.cpp:219] Iteration 35750 (0.340761 iter/s, 146.731s/50 iters), loss = 0.00657675
I0622 07:00:19.763036 17579 solver.cpp:238]     Train net output #0: loss = 0.0066383 (* 1 = 0.0066383 loss)
I0622 07:00:19.763067 17579 sgd_solver.cpp:105] Iteration 35750, lr = 0.0005
I0622 07:02:39.024688 17579 solver.cpp:219] Iteration 35800 (0.359043 iter/s, 139.259s/50 iters), loss = 0.00441025
I0622 07:02:39.024791 17579 solver.cpp:238]     Train net output #0: loss = 0.00732812 (* 1 = 0.00732812 loss)
I0622 07:02:39.024818 17579 sgd_solver.cpp:105] Iteration 35800, lr = 0.0005
I0622 07:05:06.999510 17579 solver.cpp:219] Iteration 35850 (0.337902 iter/s, 147.972s/50 iters), loss = 0.00748167
I0622 07:05:06.999670 17579 solver.cpp:238]     Train net output #0: loss = 0.00607803 (* 1 = 0.00607803 loss)
I0622 07:05:06.999701 17579 sgd_solver.cpp:105] Iteration 35850, lr = 0.0005
I0622 07:07:34.902748 17579 solver.cpp:219] Iteration 35900 (0.338065 iter/s, 147.9s/50 iters), loss = 0.00441701
I0622 07:07:34.902894 17579 solver.cpp:238]     Train net output #0: loss = 0.0052627 (* 1 = 0.0052627 loss)
I0622 07:07:34.902922 17579 sgd_solver.cpp:105] Iteration 35900, lr = 0.0005
I0622 07:10:02.885334 17579 solver.cpp:219] Iteration 35950 (0.337884 iter/s, 147.98s/50 iters), loss = 0.00593918
I0622 07:10:02.885481 17579 solver.cpp:238]     Train net output #0: loss = 0.00331562 (* 1 = 0.00331562 loss)
I0622 07:10:02.885512 17579 sgd_solver.cpp:105] Iteration 35950, lr = 0.0005
I0622 07:12:27.944200 17579 solver.cpp:448] Snapshotting to binary proto file mobilenet/mobile_pruning_iter_36000.caffemodel
I0622 07:12:28.071074 17579 sgd_solver.cpp:273] Snapshotting solver state to binary proto file mobilenet/mobile_pruning_iter_36000.solverstate
I0622 07:12:28.127452 17579 solver.cpp:331] Iteration 36000, Testing net (#0)
I0622 07:12:44.659835 17579 solver.cpp:398]     Test net output #0: accuracy = 0.980392
I0622 07:12:44.659919 17579 solver.cpp:398]     Test net output #1: loss = 0.0821328 (* 1 = 0.0821328 loss)
I0622 07:12:47.576562 17579 solver.cpp:219] Iteration 36000 (0.303604 iter/s, 164.688s/50 iters), loss = 0.00778521
I0622 07:12:47.576656 17579 solver.cpp:238]     Train net output #0: loss = 0.00764953 (* 1 = 0.00764953 loss)
I0622 07:12:47.576683 17579 sgd_solver.cpp:105] Iteration 36000, lr = 0.0005
I0622 07:15:15.524524 17579 solver.cpp:219] Iteration 36050 (0.337963 iter/s, 147.945s/50 iters), loss = 0.00621515
I0622 07:15:15.524657 17579 solver.cpp:238]     Train net output #0: loss = 0.00362671 (* 1 = 0.00362671 loss)
I0622 07:15:15.524686 17579 sgd_solver.cpp:105] Iteration 36050, lr = 0.0005
I0622 07:17:43.495177 17579 solver.cpp:219] Iteration 36100 (0.337911 iter/s, 147.968s/50 iters), loss = 0.00827606
I0622 07:17:43.495332 17579 solver.cpp:238]     Train net output #0: loss = 0.00443793 (* 1 = 0.00443793 loss)
I0622 07:17:43.495362 17579 sgd_solver.cpp:105] Iteration 36100, lr = 0.0005
I0622 07:20:11.367784 17579 solver.cpp:219] Iteration 36150 (0.338135 iter/s, 147.87s/50 iters), loss = 0.00459805
I0622 07:20:11.368023 17579 solver.cpp:238]     Train net output #0: loss = 0.00657769 (* 1 = 0.00657769 loss)
I0622 07:20:11.368058 17579 sgd_solver.cpp:105] Iteration 36150, lr = 0.0005
I0622 07:22:37.047710 17579 solver.cpp:219] Iteration 36200 (0.343225 iter/s, 145.677s/50 iters), loss = 0.00553474
I0622 07:22:37.047870 17579 solver.cpp:238]     Train net output #0: loss = 0.00937787 (* 1 = 0.00937787 loss)
I0622 07:22:37.047900 17579 sgd_solver.cpp:105] Iteration 36200, lr = 0.0005
I0622 07:24:57.337306 17579 solver.cpp:219] Iteration 36250 (0.356413 iter/s, 140.287s/50 iters), loss = 0.00332095
I0622 07:24:57.337451 17579 solver.cpp:238]     Train net output #0: loss = 0.00537715 (* 1 = 0.00537715 loss)
I0622 07:24:57.337479 17579 sgd_solver.cpp:105] Iteration 36250, lr = 0.0005
I0622 07:27:25.168211 17579 solver.cpp:219] Iteration 36300 (0.338231 iter/s, 147.828s/50 iters), loss = 0.00546847
I0622 07:27:25.168364 17579 solver.cpp:238]     Train net output #0: loss = 0.00900382 (* 1 = 0.00900382 loss)
I0622 07:27:25.168392 17579 sgd_solver.cpp:105] Iteration 36300, lr = 0.0005
I0622 07:29:53.096143 17579 solver.cpp:219] Iteration 36350 (0.338009 iter/s, 147.925s/50 iters), loss = 0.00440106
I0622 07:29:53.096305 17579 solver.cpp:238]     Train net output #0: loss = 0.0065902 (* 1 = 0.0065902 loss)
I0622 07:29:53.096333 17579 sgd_solver.cpp:105] Iteration 36350, lr = 0.0005
I0622 07:32:21.044868 17579 solver.cpp:219] Iteration 36400 (0.337959 iter/s, 147.947s/50 iters), loss = 0.0102283
I0622 07:32:21.045044 17579 solver.cpp:238]     Train net output #0: loss = 0.00247008 (* 1 = 0.00247008 loss)
I0622 07:32:21.045073 17579 sgd_solver.cpp:105] Iteration 36400, lr = 0.0005
I0622 07:34:48.928948 17579 solver.cpp:219] Iteration 36450 (0.338109 iter/s, 147.881s/50 iters), loss = 0.00488339
I0622 07:34:48.929129 17579 solver.cpp:238]     Train net output #0: loss = 0.00144607 (* 1 = 0.00144607 loss)
I0622 07:34:48.929177 17579 sgd_solver.cpp:105] Iteration 36450, lr = 0.0005
I0622 07:37:13.902523 17579 solver.cpp:331] Iteration 36500, Testing net (#0)
I0622 07:37:30.400733 17579 solver.cpp:398]     Test net output #0: accuracy = 0.982353
I0622 07:37:30.400822 17579 solver.cpp:398]     Test net output #1: loss = 0.0795042 (* 1 = 0.0795042 loss)
I0622 07:37:33.313913 17579 solver.cpp:219] Iteration 36500 (0.30417 iter/s, 164.382s/50 iters), loss = 0.00768891
I0622 07:37:33.314028 17579 solver.cpp:238]     Train net output #0: loss = 0.00550973 (* 1 = 0.00550973 loss)
I0622 07:37:33.314060 17579 sgd_solver.cpp:105] Iteration 36500, lr = 0.0005
I0622 07:40:01.093106 17579 solver.cpp:219] Iteration 36550 (0.338349 iter/s, 147.776s/50 iters), loss = 0.00404816
I0622 07:40:01.093268 17579 solver.cpp:238]     Train net output #0: loss = 0.00518664 (* 1 = 0.00518664 loss)
I0622 07:40:01.093297 17579 sgd_solver.cpp:105] Iteration 36550, lr = 0.0005
I0622 07:42:28.878043 17579 solver.cpp:219] Iteration 36600 (0.338335 iter/s, 147.783s/50 iters), loss = 0.00610215
I0622 07:42:28.878206 17579 solver.cpp:238]     Train net output #0: loss = 0.00898077 (* 1 = 0.00898077 loss)
I0622 07:42:28.878239 17579 sgd_solver.cpp:105] Iteration 36600, lr = 0.0005
I0622 07:44:54.131836 17579 solver.cpp:219] Iteration 36650 (0.344232 iter/s, 145.251s/50 iters), loss = 0.00548155
I0622 07:44:54.131992 17579 solver.cpp:238]     Train net output #0: loss = 0.0037403 (* 1 = 0.0037403 loss)
I0622 07:44:54.132021 17579 sgd_solver.cpp:105] Iteration 36650, lr = 0.0005
I0622 07:47:14.926520 17579 solver.cpp:219] Iteration 36700 (0.355134 iter/s, 140.792s/50 iters), loss = 0.00660553
I0622 07:47:14.926683 17579 solver.cpp:238]     Train net output #0: loss = 0.00672049 (* 1 = 0.00672049 loss)
I0622 07:47:14.926712 17579 sgd_solver.cpp:105] Iteration 36700, lr = 0.0005
I0622 07:49:42.840888 17579 solver.cpp:219] Iteration 36750 (0.338039 iter/s, 147.912s/50 iters), loss = 0.00559561
I0622 07:49:42.841076 17579 solver.cpp:238]     Train net output #0: loss = 0.00229329 (* 1 = 0.00229329 loss)
I0622 07:49:42.841106 17579 sgd_solver.cpp:105] Iteration 36750, lr = 0.0005
I0622 07:52:10.738965 17579 solver.cpp:219] Iteration 36800 (0.338076 iter/s, 147.896s/50 iters), loss = 0.00645276
I0622 07:52:10.739104 17579 solver.cpp:238]     Train net output #0: loss = 0.0117527 (* 1 = 0.0117527 loss)
I0622 07:52:10.739135 17579 sgd_solver.cpp:105] Iteration 36800, lr = 0.0005
I0622 07:54:38.668593 17579 solver.cpp:219] Iteration 36850 (0.338004 iter/s, 147.927s/50 iters), loss = 0.00946471
I0622 07:54:38.668736 17579 solver.cpp:238]     Train net output #0: loss = 0.00847034 (* 1 = 0.00847034 loss)
I0622 07:54:38.668767 17579 sgd_solver.cpp:105] Iteration 36850, lr = 0.0005
I0622 07:57:06.656656 17579 solver.cpp:219] Iteration 36900 (0.337871 iter/s, 147.985s/50 iters), loss = 0.00429861
I0622 07:57:06.656792 17579 solver.cpp:238]     Train net output #0: loss = 0.00351536 (* 1 = 0.00351536 loss)
I0622 07:57:06.656821 17579 sgd_solver.cpp:105] Iteration 36900, lr = 0.0005
I0622 07:59:34.641917 17579 solver.cpp:219] Iteration 36950 (0.337877 iter/s, 147.983s/50 iters), loss = 0.00678685
I0622 07:59:34.642068 17579 solver.cpp:238]     Train net output #0: loss = 0.00925063 (* 1 = 0.00925063 loss)
I0622 07:59:34.642097 17579 sgd_solver.cpp:105] Iteration 36950, lr = 0.0005
I0622 08:01:59.557312 17579 solver.cpp:331] Iteration 37000, Testing net (#0)
I0622 08:02:16.052856 17579 solver.cpp:398]     Test net output #0: accuracy = 0.981373
I0622 08:02:16.052927 17579 solver.cpp:398]     Test net output #1: loss = 0.0797101 (* 1 = 0.0797101 loss)
I0622 08:02:18.982661 17579 solver.cpp:219] Iteration 37000 (0.304251 iter/s, 164.338s/50 iters), loss = 0.00593069
I0622 08:02:18.982769 17579 solver.cpp:238]     Train net output #0: loss = 0.0052851 (* 1 = 0.0052851 loss)
I0622 08:02:18.982796 17579 sgd_solver.cpp:105] Iteration 37000, lr = 0.0005
I0622 08:04:46.922905 17579 solver.cpp:219] Iteration 37050 (0.337982 iter/s, 147.937s/50 iters), loss = 0.00716643
I0622 08:04:46.923105 17579 solver.cpp:238]     Train net output #0: loss = 0.00670425 (* 1 = 0.00670425 loss)
I0622 08:04:46.923138 17579 sgd_solver.cpp:105] Iteration 37050, lr = 0.0005
I0622 08:07:11.327652 17579 solver.cpp:219] Iteration 37100 (0.346255 iter/s, 144.402s/50 iters), loss = 0.00718162
I0622 08:07:11.327805 17579 solver.cpp:238]     Train net output #0: loss = 0.0049563 (* 1 = 0.0049563 loss)
I0622 08:07:11.327838 17579 sgd_solver.cpp:105] Iteration 37100, lr = 0.0005
I0622 08:09:33.025672 17579 solver.cpp:219] Iteration 37150 (0.35287 iter/s, 141.695s/50 iters), loss = 0.00496136
I0622 08:09:33.025825 17579 solver.cpp:238]     Train net output #0: loss = 0.00461421 (* 1 = 0.00461421 loss)
I0622 08:09:33.025857 17579 sgd_solver.cpp:105] Iteration 37150, lr = 0.0005
I0622 08:12:00.904666 17579 solver.cpp:219] Iteration 37200 (0.33812 iter/s, 147.876s/50 iters), loss = 0.00402102
I0622 08:12:00.904889 17579 solver.cpp:238]     Train net output #0: loss = 0.00261755 (* 1 = 0.00261755 loss)
I0622 08:12:00.904925 17579 sgd_solver.cpp:105] Iteration 37200, lr = 0.0005
I0622 08:14:28.866845 17579 solver.cpp:219] Iteration 37250 (0.33793 iter/s, 147.96s/50 iters), loss = 0.00961927
I0622 08:14:28.867085 17579 solver.cpp:238]     Train net output #0: loss = 0.0079031 (* 1 = 0.0079031 loss)
I0622 08:14:28.867115 17579 sgd_solver.cpp:105] Iteration 37250, lr = 0.0005
I0622 08:16:56.766957 17579 solver.cpp:219] Iteration 37300 (0.338071 iter/s, 147.898s/50 iters), loss = 0.0075792
I0622 08:16:56.767199 17579 solver.cpp:238]     Train net output #0: loss = 0.00446947 (* 1 = 0.00446947 loss)
I0622 08:16:56.767235 17579 sgd_solver.cpp:105] Iteration 37300, lr = 0.0005
I0622 08:19:24.680668 17579 solver.cpp:219] Iteration 37350 (0.338041 iter/s, 147.911s/50 iters), loss = 0.00505132
I0622 08:19:24.680817 17579 solver.cpp:238]     Train net output #0: loss = 0.00366128 (* 1 = 0.00366128 loss)
I0622 08:19:24.680846 17579 sgd_solver.cpp:105] Iteration 37350, lr = 0.0005
I0622 08:21:52.701745 17579 solver.cpp:219] Iteration 37400 (0.337796 iter/s, 148.019s/50 iters), loss = 0.00444965
I0622 08:21:52.701952 17579 solver.cpp:238]     Train net output #0: loss = 0.00546849 (* 1 = 0.00546849 loss)
I0622 08:21:52.701982 17579 sgd_solver.cpp:105] Iteration 37400, lr = 0.0005
I0622 08:24:20.601531 17579 solver.cpp:219] Iteration 37450 (0.338074 iter/s, 147.897s/50 iters), loss = 0.0089874
I0622 08:24:20.601682 17579 solver.cpp:238]     Train net output #0: loss = 0.00772794 (* 1 = 0.00772794 loss)
I0622 08:24:20.601711 17579 sgd_solver.cpp:105] Iteration 37450, lr = 0.0005
I0622 08:26:45.538661 17579 solver.cpp:331] Iteration 37500, Testing net (#0)
I0622 08:27:02.052733 17579 solver.cpp:398]     Test net output #0: accuracy = 0.981373
I0622 08:27:02.052809 17579 solver.cpp:398]     Test net output #1: loss = 0.0800448 (* 1 = 0.0800448 loss)
I0622 08:27:04.978194 17579 solver.cpp:219] Iteration 37500 (0.304183 iter/s, 164.375s/50 iters), loss = 0.00797991
I0622 08:27:04.978302 17579 solver.cpp:238]     Train net output #0: loss = 0.00985131 (* 1 = 0.00985131 loss)
I0622 08:27:04.978334 17579 sgd_solver.cpp:105] Iteration 37500, lr = 0.0005
I0622 08:29:28.528169 17579 solver.cpp:219] Iteration 37550 (0.348317 iter/s, 143.548s/50 iters), loss = 0.00591135
I0622 08:29:28.528314 17579 solver.cpp:238]     Train net output #0: loss = 0.0167376 (* 1 = 0.0167376 loss)
I0622 08:29:28.528344 17579 sgd_solver.cpp:105] Iteration 37550, lr = 0.0005
I0622 08:31:51.252923 17579 solver.cpp:219] Iteration 37600 (0.350331 iter/s, 142.722s/50 iters), loss = 0.00537264
I0622 08:31:51.253067 17579 solver.cpp:238]     Train net output #0: loss = 0.00503278 (* 1 = 0.00503278 loss)
I0622 08:31:51.253096 17579 sgd_solver.cpp:105] Iteration 37600, lr = 0.0005
I0622 08:34:19.106227 17579 solver.cpp:219] Iteration 37650 (0.338179 iter/s, 147.851s/50 iters), loss = 0.0028795
I0622 08:34:19.106385 17579 solver.cpp:238]     Train net output #0: loss = 0.00330043 (* 1 = 0.00330043 loss)
I0622 08:34:19.106415 17579 sgd_solver.cpp:105] Iteration 37650, lr = 0.0005
I0622 08:36:47.032902 17579 solver.cpp:219] Iteration 37700 (0.338011 iter/s, 147.924s/50 iters), loss = 0.00409087
I0622 08:36:47.033082 17579 solver.cpp:238]     Train net output #0: loss = 0.00355525 (* 1 = 0.00355525 loss)
I0622 08:36:47.033112 17579 sgd_solver.cpp:105] Iteration 37700, lr = 0.0005
I0622 08:39:14.942637 17579 solver.cpp:219] Iteration 37750 (0.33805 iter/s, 147.907s/50 iters), loss = 0.0037115
I0622 08:39:14.942800 17579 solver.cpp:238]     Train net output #0: loss = 0.00673302 (* 1 = 0.00673302 loss)
I0622 08:39:14.942829 17579 sgd_solver.cpp:105] Iteration 37750, lr = 0.0005
I0622 08:41:42.786895 17579 solver.cpp:219] Iteration 37800 (0.338199 iter/s, 147.842s/50 iters), loss = 0.00300473
I0622 08:41:42.787041 17579 solver.cpp:238]     Train net output #0: loss = 0.00316746 (* 1 = 0.00316746 loss)
I0622 08:41:42.787072 17579 sgd_solver.cpp:105] Iteration 37800, lr = 0.0005
I0622 08:44:10.695232 17579 solver.cpp:219] Iteration 37850 (0.338054 iter/s, 147.906s/50 iters), loss = 0.00801503
I0622 08:44:10.695394 17579 solver.cpp:238]     Train net output #0: loss = 0.00601083 (* 1 = 0.00601083 loss)
I0622 08:44:10.695423 17579 sgd_solver.cpp:105] Iteration 37850, lr = 0.0005
I0622 08:46:38.666127 17579 solver.cpp:219] Iteration 37900 (0.33791 iter/s, 147.968s/50 iters), loss = 0.00411397
I0622 08:46:38.666272 17579 solver.cpp:238]     Train net output #0: loss = 0.00131933 (* 1 = 0.00131933 loss)
I0622 08:46:38.666301 17579 sgd_solver.cpp:105] Iteration 37900, lr = 0.0005
I0622 08:49:06.573268 17579 solver.cpp:219] Iteration 37950 (0.338056 iter/s, 147.905s/50 iters), loss = 0.00633601
I0622 08:49:06.573411 17579 solver.cpp:238]     Train net output #0: loss = 0.00344752 (* 1 = 0.00344752 loss)
I0622 08:49:06.573442 17579 sgd_solver.cpp:105] Iteration 37950, lr = 0.0005
I0622 08:51:31.630580 17579 solver.cpp:331] Iteration 38000, Testing net (#0)
I0622 08:51:47.411115 17579 solver.cpp:398]     Test net output #0: accuracy = 0.981373
I0622 08:51:47.411202 17579 solver.cpp:398]     Test net output #1: loss = 0.083368 (* 1 = 0.083368 loss)
I0622 08:51:49.369782 17579 solver.cpp:219] Iteration 38000 (0.307137 iter/s, 162.794s/50 iters), loss = 0.003363
I0622 08:51:49.369876 17579 solver.cpp:238]     Train net output #0: loss = 0.00329312 (* 1 = 0.00329312 loss)
I0622 08:51:49.369907 17579 sgd_solver.cpp:105] Iteration 38000, lr = 0.0005
I0622 08:54:12.852766 17579 solver.cpp:219] Iteration 38050 (0.34848 iter/s, 143.48s/50 iters), loss = 0.00340986
I0622 08:54:12.852968 17579 solver.cpp:238]     Train net output #0: loss = 0.00489364 (* 1 = 0.00489364 loss)
I0622 08:54:12.852998 17579 sgd_solver.cpp:105] Iteration 38050, lr = 0.0005
I0622 08:56:40.770159 17579 solver.cpp:219] Iteration 38100 (0.338034 iter/s, 147.914s/50 iters), loss = 0.00755469
I0622 08:56:40.770321 17579 solver.cpp:238]     Train net output #0: loss = 0.00411988 (* 1 = 0.00411988 loss)
I0622 08:56:40.770354 17579 sgd_solver.cpp:105] Iteration 38100, lr = 0.0005
I0622 08:59:08.756119 17579 solver.cpp:219] Iteration 38150 (0.337876 iter/s, 147.983s/50 iters), loss = 0.00598111
I0622 08:59:08.756307 17579 solver.cpp:238]     Train net output #0: loss = 0.00689129 (* 1 = 0.00689129 loss)
I0622 08:59:08.756335 17579 sgd_solver.cpp:105] Iteration 38150, lr = 0.0005
I0622 09:01:36.584264 17579 solver.cpp:219] Iteration 38200 (0.338237 iter/s, 147.826s/50 iters), loss = 0.00601979
I0622 09:01:36.584406 17579 solver.cpp:238]     Train net output #0: loss = 0.00294723 (* 1 = 0.00294723 loss)
I0622 09:01:36.584436 17579 sgd_solver.cpp:105] Iteration 38200, lr = 0.0005
I0622 09:04:04.495888 17579 solver.cpp:219] Iteration 38250 (0.338047 iter/s, 147.908s/50 iters), loss = 0.0063375
I0622 09:04:04.496026 17579 solver.cpp:238]     Train net output #0: loss = 0.0043234 (* 1 = 0.0043234 loss)
I0622 09:04:04.496057 17579 sgd_solver.cpp:105] Iteration 38250, lr = 0.0005
I0622 09:06:32.366381 17579 solver.cpp:219] Iteration 38300 (0.33814 iter/s, 147.868s/50 iters), loss = 0.00547527
I0622 09:06:32.366546 17579 solver.cpp:238]     Train net output #0: loss = 0.00408318 (* 1 = 0.00408318 loss)
I0622 09:06:32.366590 17579 sgd_solver.cpp:105] Iteration 38300, lr = 0.0005
I0622 09:09:00.281301 17579 solver.cpp:219] Iteration 38350 (0.338038 iter/s, 147.912s/50 iters), loss = 0.00405588
I0622 09:09:00.281438 17579 solver.cpp:238]     Train net output #0: loss = 0.00340265 (* 1 = 0.00340265 loss)
I0622 09:09:00.281466 17579 sgd_solver.cpp:105] Iteration 38350, lr = 0.0005
I0622 09:11:28.290326 17579 solver.cpp:219] Iteration 38400 (0.337823 iter/s, 148.006s/50 iters), loss = 0.00545163
I0622 09:11:28.290482 17579 solver.cpp:238]     Train net output #0: loss = 0.00211565 (* 1 = 0.00211565 loss)
I0622 09:11:28.290510 17579 sgd_solver.cpp:105] Iteration 38400, lr = 0.0005
I0622 09:13:56.326344 17579 solver.cpp:219] Iteration 38450 (0.337762 iter/s, 148.033s/50 iters), loss = 0.00628834
I0622 09:13:56.326926 17579 solver.cpp:238]     Train net output #0: loss = 0.00485741 (* 1 = 0.00485741 loss)
I0622 09:13:56.326957 17579 sgd_solver.cpp:105] Iteration 38450, lr = 0.0005
I0622 09:16:11.789813 17579 solver.cpp:331] Iteration 38500, Testing net (#0)
I0622 09:16:28.319818 17579 solver.cpp:398]     Test net output #0: accuracy = 0.979412
I0622 09:16:28.319887 17579 solver.cpp:398]     Test net output #1: loss = 0.0839699 (* 1 = 0.0839699 loss)
I0622 09:16:31.206796 17579 solver.cpp:219] Iteration 38500 (0.322835 iter/s, 154.878s/50 iters), loss = 0.0048681
I0622 09:16:31.206885 17579 solver.cpp:238]     Train net output #0: loss = 0.00840907 (* 1 = 0.00840907 loss)
I0622 09:16:31.206915 17579 sgd_solver.cpp:105] Iteration 38500, lr = 0.0005
I0622 09:18:59.090806 17579 solver.cpp:219] Iteration 38550 (0.338109 iter/s, 147.881s/50 iters), loss = 0.0040252
I0622 09:18:59.090952 17579 solver.cpp:238]     Train net output #0: loss = 0.00743701 (* 1 = 0.00743701 loss)
I0622 09:18:59.090982 17579 sgd_solver.cpp:105] Iteration 38550, lr = 0.0005
I0622 09:21:27.091101 17579 solver.cpp:219] Iteration 38600 (0.337844 iter/s, 147.997s/50 iters), loss = 0.00437941
I0622 09:21:27.091298 17579 solver.cpp:238]     Train net output #0: loss = 0.00399651 (* 1 = 0.00399651 loss)
I0622 09:21:27.091328 17579 sgd_solver.cpp:105] Iteration 38600, lr = 0.0005
I0622 09:23:54.987185 17579 solver.cpp:219] Iteration 38650 (0.338082 iter/s, 147.893s/50 iters), loss = 0.00518304
I0622 09:23:54.987350 17579 solver.cpp:238]     Train net output #0: loss = 0.00408669 (* 1 = 0.00408669 loss)
I0622 09:23:54.987381 17579 sgd_solver.cpp:105] Iteration 38650, lr = 0.0005
I0622 09:26:22.854372 17579 solver.cpp:219] Iteration 38700 (0.338148 iter/s, 147.864s/50 iters), loss = 0.00307502
I0622 09:26:22.854574 17579 solver.cpp:238]     Train net output #0: loss = 0.00132434 (* 1 = 0.00132434 loss)
I0622 09:26:22.854609 17579 sgd_solver.cpp:105] Iteration 38700, lr = 0.0005
I0622 09:28:50.785185 17579 solver.cpp:219] Iteration 38750 (0.338001 iter/s, 147.929s/50 iters), loss = 0.0080527
I0622 09:28:50.785323 17579 solver.cpp:238]     Train net output #0: loss = 0.0155556 (* 1 = 0.0155556 loss)
I0622 09:28:50.785352 17579 sgd_solver.cpp:105] Iteration 38750, lr = 0.0005
I0622 09:31:18.640975 17579 solver.cpp:219] Iteration 38800 (0.338174 iter/s, 147.853s/50 iters), loss = 0.00649027
I0622 09:31:18.641131 17579 solver.cpp:238]     Train net output #0: loss = 0.00571425 (* 1 = 0.00571425 loss)
I0622 09:31:18.641160 17579 sgd_solver.cpp:105] Iteration 38800, lr = 0.0005
I0622 09:33:46.615190 17579 solver.cpp:219] Iteration 38850 (0.337903 iter/s, 147.971s/50 iters), loss = 0.00420989
I0622 09:33:46.615376 17579 solver.cpp:238]     Train net output #0: loss = 0.00403173 (* 1 = 0.00403173 loss)
I0622 09:33:46.615407 17579 sgd_solver.cpp:105] Iteration 38850, lr = 0.0005
I0622 09:36:14.425041 17579 solver.cpp:219] Iteration 38900 (0.338281 iter/s, 147.806s/50 iters), loss = 0.0041406
I0622 09:36:14.425240 17579 solver.cpp:238]     Train net output #0: loss = 0.00587498 (* 1 = 0.00587498 loss)
I0622 09:36:14.425268 17579 sgd_solver.cpp:105] Iteration 38900, lr = 0.0005
I0622 09:38:32.302093 17579 solver.cpp:219] Iteration 38950 (0.362652 iter/s, 137.873s/50 iters), loss = 0.00383589
I0622 09:38:32.302265 17579 solver.cpp:238]     Train net output #0: loss = 0.00357323 (* 1 = 0.00357323 loss)
I0622 09:38:32.302295 17579 sgd_solver.cpp:105] Iteration 38950, lr = 0.0005
I0622 09:40:57.280900 17579 solver.cpp:331] Iteration 39000, Testing net (#0)
I0622 09:41:13.775557 17579 solver.cpp:398]     Test net output #0: accuracy = 0.982353
I0622 09:41:13.775643 17579 solver.cpp:398]     Test net output #1: loss = 0.0827579 (* 1 = 0.0827579 loss)
I0622 09:41:16.698668 17579 solver.cpp:219] Iteration 39000 (0.304152 iter/s, 164.392s/50 iters), loss = 0.0039862
I0622 09:41:16.698762 17579 solver.cpp:238]     Train net output #0: loss = 0.00288853 (* 1 = 0.00288853 loss)
I0622 09:41:16.698792 17579 sgd_solver.cpp:105] Iteration 39000, lr = 0.0005
I0622 09:43:44.599108 17579 solver.cpp:219] Iteration 39050 (0.338072 iter/s, 147.898s/50 iters), loss = 0.00496515
I0622 09:43:44.599267 17579 solver.cpp:238]     Train net output #0: loss = 0.00833725 (* 1 = 0.00833725 loss)
I0622 09:43:44.599297 17579 sgd_solver.cpp:105] Iteration 39050, lr = 0.0005
I0622 09:46:12.464013 17579 solver.cpp:219] Iteration 39100 (0.338153 iter/s, 147.862s/50 iters), loss = 0.00306087
I0622 09:46:12.464171 17579 solver.cpp:238]     Train net output #0: loss = 0.00405891 (* 1 = 0.00405891 loss)
I0622 09:46:12.464200 17579 sgd_solver.cpp:105] Iteration 39100, lr = 0.0005
I0622 09:48:40.298666 17579 solver.cpp:219] Iteration 39150 (0.33822 iter/s, 147.833s/50 iters), loss = 0.00381115
I0622 09:48:40.298805 17579 solver.cpp:238]     Train net output #0: loss = 0.00551212 (* 1 = 0.00551212 loss)
I0622 09:48:40.298835 17579 sgd_solver.cpp:105] Iteration 39150, lr = 0.0005
I0622 09:51:08.214740 17579 solver.cpp:219] Iteration 39200 (0.338037 iter/s, 147.913s/50 iters), loss = 0.00491132
I0622 09:51:08.214895 17579 solver.cpp:238]     Train net output #0: loss = 0.00496893 (* 1 = 0.00496893 loss)
I0622 09:51:08.214926 17579 sgd_solver.cpp:105] Iteration 39200, lr = 0.0005
I0622 09:53:36.087783 17579 solver.cpp:219] Iteration 39250 (0.338134 iter/s, 147.87s/50 iters), loss = 0.00462823
I0622 09:53:36.087988 17579 solver.cpp:238]     Train net output #0: loss = 0.00425209 (* 1 = 0.00425209 loss)
I0622 09:53:36.088023 17579 sgd_solver.cpp:105] Iteration 39250, lr = 0.0005
I0622 09:56:03.888902 17579 solver.cpp:219] Iteration 39300 (0.338299 iter/s, 147.798s/50 iters), loss = 0.00477547
I0622 09:56:03.889948 17579 solver.cpp:238]     Train net output #0: loss = 0.00470916 (* 1 = 0.00470916 loss)
I0622 09:56:03.889976 17579 sgd_solver.cpp:105] Iteration 39300, lr = 0.0005
I0622 09:58:31.945094 17579 solver.cpp:219] Iteration 39350 (0.337716 iter/s, 148.054s/50 iters), loss = 0.00357351
I0622 09:58:31.945236 17579 solver.cpp:238]     Train net output #0: loss = 0.00156995 (* 1 = 0.00156995 loss)
I0622 09:58:31.945263 17579 sgd_solver.cpp:105] Iteration 39350, lr = 0.0005
I0622 10:00:50.049356 17579 solver.cpp:219] Iteration 39400 (0.362052 iter/s, 138.102s/50 iters), loss = 0.00634728
I0622 10:00:50.049497 17579 solver.cpp:238]     Train net output #0: loss = 0.00600728 (* 1 = 0.00600728 loss)
I0622 10:00:50.049532 17579 sgd_solver.cpp:105] Iteration 39400, lr = 0.0005
I0622 10:03:18.060708 17579 solver.cpp:219] Iteration 39450 (0.337817 iter/s, 148.009s/50 iters), loss = 0.00407414
I0622 10:03:18.061339 17579 solver.cpp:238]     Train net output #0: loss = 0.00617015 (* 1 = 0.00617015 loss)
I0622 10:03:18.061367 17579 sgd_solver.cpp:105] Iteration 39450, lr = 0.0005
I0622 10:05:42.967166 17579 solver.cpp:331] Iteration 39500, Testing net (#0)
I0622 10:05:59.576179 17579 solver.cpp:398]     Test net output #0: accuracy = 0.978432
I0622 10:05:59.576268 17579 solver.cpp:398]     Test net output #1: loss = 0.0827663 (* 1 = 0.0827663 loss)
I0622 10:06:02.492000 17579 solver.cpp:219] Iteration 39500 (0.304083 iter/s, 164.429s/50 iters), loss = 0.00486812
I0622 10:06:02.492097 17579 solver.cpp:238]     Train net output #0: loss = 0.0028145 (* 1 = 0.0028145 loss)
I0622 10:06:02.492128 17579 sgd_solver.cpp:105] Iteration 39500, lr = 0.0005
I0622 10:08:30.391176 17579 solver.cpp:219] Iteration 39550 (0.338078 iter/s, 147.895s/50 iters), loss = 0.0050723
I0622 10:08:30.391337 17579 solver.cpp:238]     Train net output #0: loss = 0.00493537 (* 1 = 0.00493537 loss)
I0622 10:08:30.391371 17579 sgd_solver.cpp:105] Iteration 39550, lr = 0.0005
I0622 10:10:58.333562 17579 solver.cpp:219] Iteration 39600 (0.337975 iter/s, 147.94s/50 iters), loss = 0.00511142
I0622 10:10:58.339962 17579 solver.cpp:238]     Train net output #0: loss = 0.00867966 (* 1 = 0.00867966 loss)
I0622 10:10:58.339993 17579 sgd_solver.cpp:105] Iteration 39600, lr = 0.0005
I0622 10:13:26.168365 17579 solver.cpp:219] Iteration 39650 (0.338233 iter/s, 147.827s/50 iters), loss = 0.00485173
I0622 10:13:26.168510 17579 solver.cpp:238]     Train net output #0: loss = 0.0093234 (* 1 = 0.0093234 loss)
I0622 10:13:26.168545 17579 sgd_solver.cpp:105] Iteration 39650, lr = 0.0005
I0622 10:15:54.142315 17579 solver.cpp:219] Iteration 39700 (0.337903 iter/s, 147.972s/50 iters), loss = 0.00465623
I0622 10:15:54.142468 17579 solver.cpp:238]     Train net output #0: loss = 0.00343862 (* 1 = 0.00343862 loss)
I0622 10:15:54.142498 17579 sgd_solver.cpp:105] Iteration 39700, lr = 0.0005
I0622 10:18:22.048020 17579 solver.cpp:219] Iteration 39750 (0.338064 iter/s, 147.901s/50 iters), loss = 0.00449671
I0622 10:18:22.048180 17579 solver.cpp:238]     Train net output #0: loss = 0.00497675 (* 1 = 0.00497675 loss)
I0622 10:18:22.048213 17579 sgd_solver.cpp:105] Iteration 39750, lr = 0.0005
I0622 10:20:49.178097 17579 solver.cpp:219] Iteration 39800 (0.339841 iter/s, 147.128s/50 iters), loss = 0.00374687
I0622 10:20:49.178268 17579 solver.cpp:238]     Train net output #0: loss = 0.0077549 (* 1 = 0.0077549 loss)
I0622 10:20:49.178299 17579 sgd_solver.cpp:105] Iteration 39800, lr = 0.0005
I0622 10:23:08.102314 17579 solver.cpp:219] Iteration 39850 (0.359912 iter/s, 138.923s/50 iters), loss = 0.00879196
I0622 10:23:08.102445 17579 solver.cpp:238]     Train net output #0: loss = 0.00384789 (* 1 = 0.00384789 loss)
I0622 10:23:08.102473 17579 sgd_solver.cpp:105] Iteration 39850, lr = 0.0005
I0622 10:24:04.383134 17579 solver.cpp:448] Snapshotting to binary proto file mobilenet/mobile_pruning_iter_39870.caffemodel
I0622 10:24:04.512305 17579 sgd_solver.cpp:273] Snapshotting solver state to binary proto file mobilenet/mobile_pruning_iter_39870.solverstate
I0622 10:24:04.569326 17579 solver.cpp:295] Optimization stopped early.
I0622 10:24:04.569371 17579 caffe.cpp:259] Optimization Done.
